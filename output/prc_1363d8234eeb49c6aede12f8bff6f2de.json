{
  "sdl_source_type": "PRC",
  "sdl_date": "2020-08-26T00:00:00",
  "countryPublished": "Liberia",
  "conference": "Lorraine's tickle's we Adesuwa",
  "originalAuthorName": "Gytis o Afra",
  "title": "weeing cherubic",
  "declaredTags": "methods|cyber dead hand|MITRE interns|employee voice",
  "releaseReason": "Byelorussia's/Tipperary's",
  "docName": "RO_74_8200",
  "fundingCenter": 27,
  "resourceURL": "https://placebos.com",
  "fundingDepartment": "eg10",
  "caseNumber": "44-5248",
  "publicationDate": "10/24/2017 12:00:00 AM",
  "releaseYear": 2003,
  "releaseStatement": "Advertising/Recruiting",
  "approver": "$Lanelle $Boem",
  "handCarry": 4,
  "authorDivision": "mm25",
  "copyrightOwner": "Yaneth Lochstampfer",
  "lastModifiedDate": "6/22/2010 12:00:00 AM",
  "releaseDate": "4/19/2015 12:00:00 AM",
  "onMitrePublicSrvr": 0,
  "projectNumber": "4462VGLS24",
  "materialType": "Paper",
  "publicationType": "Book",
  "authorCenter": 12,
  "originalAuthorID": "Marybel",
  "mitrePublicServer": 0,
  "subjectTerminology": "Business Process Engineering",
  "dateEntered": "4/17/2005 12:00:00 AM",
  "documentInfoURL": "https://Harding gangly aortae vivider senior.com",
  "softShell": 0,
  "publishedOnNonMITREServer": 0,
  "priorCaseNumbers": "CASE1: 17-4622|CASE1: 18-0562|CASE1: 17-3768",
  "organization": "ox81",
  "authorDepartment": "ph56",
  "publicationYear": 2010,
  "sensitivity": "Public",
  "copyrightText": "(c) 2016 The MITRE Corporation All Rights Reserved",
  "fundingSource": "FAA FFRDC Contracts",
  "level1": "MITRE Legacy",
  "fundingDivision": "killjoy typewrite talker reviving posters",
  "publishedOutsideUSA": 0,
  "level3": "no67",
  "level2": "na94",
  "sdl_id": "1363d8234eeb49c6aede12f8bff6f2de",
  "text": "T6-R1 Over the course of the three-day data collection days, the controllers experienced traffic file 4\\nwith en route initiation, while pilots were trained. For the remainder of the day, controllers\\nexperienced the other six traffic files with the flight deck participants. The block order of the\\ntraffic files was counter-balanced across participant groups. Off-nominal events were introduced for the controllers through pseudo-pilot action. Each day\\neach controller experienced an event where the termination or suspension of IM was required.\\nThe pseudo-pilot was told to acknowledge the IM clearance from the feeder controller but to\\nfly a constant speed without engaging IM. The trail aircraft held its speed and started\\nencroaching upon the lead aircraft (which eventually led to a separation issue) until the\\ncontroller intervened. The issue started to evolve in the feeder controllers airspace, but the\\nspacing issue may not have been fully realized until the final controllers airspace based on the\\nslow progression of the overtake. Table 3-6 shows the traffic file run order and traffic overtake\\nevents for the three groups of controllers. 3-51 Table 3-6. Controller Independent Variable Exposure by Day, Traffic File, and Run Note: Traffic overtake conditions are highlighted in orange. Group Operation IM Tools A Controller Role /B Controller Role\\nBaseline NA Feeder/Final D1-T4-R1\\nBaseline NA Final/Feeder D1-T4-R2\\nIM En Route Initiation TSAS tools Feeder/Feeder D4-T4-RC1\\nIM En Route Initiation TSAS tools and slot marker color change Feeder/Feeder D3-T4-RC1\\nIM En Route Initiation TSAS tools, slot marker color change, and ETA differential Feeder/Feeder D5-T4-RC1\\nIM TSAS tools Feeder/Final D3-T4-R1 D4-T5-R1 D5-T6-R1\\nIM TSAS tools and slot marker color change Feeder/Final D3-T1-R2 D4-T6-R2 D5-T4-R2\\nIM TSAS tools, slot marker color change, and ETA differential Feeder/Final D3-T2-R3 D4-T4-R3 D5-T1-R3\\nIM TSAS tools Final/Feeder D3-T3-R4 D4-T1-R4 D5-T2-R4\\nIM TSAS tools and slot marker color change Final/Feeder D3-T5-R5 D4-T2-R5 D5-T3-R5\\nIM TSAS tools, slot marker color change, and ETA differential Final/Feeder D3-T6-R6 D4-T3-R6 D5-T5-R6\\nBaseline NA Feeder/Final D1-T4-R1\\nBaseline NA Final/Feeder D1-T4-R2\\nIM En Route Initiation TSAS tools Feeder/Feeder D3-T4-RC1\\nIM En Route Initiation TSAS tools and slot marker color change Feeder/Feeder D5-T4-RC1\\nIM En Route Initiation TSAS tools, slot marker color change, and ETA differential Feeder/Feeder D4-T4-RC1\\nIM TSAS tools Feeder/Final D3-T4-R2 D4-T1-R2 D5-T6-R2\\nIM TSAS tools and slot marker color change Feeder/Final D3-T1-R3 D4-T2-R3 D5-T4-R3\\nIM TSAS tools, slot marker color change, and ETA differential Feeder/Final D3-T6-R1 D4-T4-R1 D5-T5-R1\\nIM TSAS tools Final/Feeder D3-T3-R5 D4-T5-R5 D5-T2-R5\\nIM TSAS tools and slot marker color change Final/Feeder D3-T5-R6 D4-T6-R6 D5-T3-R6\\nIM TSAS tools, slot marker color change, and ETA differential Final/Feeder D3-T2-R4 D4-T3-R4 D5-T1-R4\\nBaseline NA Feeder/Final D1-T4-R1\\nBaseline NA Final/Feeder D1-T4-R2\\nIM En Route Initiation TSAS tools Feeder/Feeder D5-T4-RC1\\nIM En Route Initiation TSAS tools and slot marker color change Feeder/Feeder D4-T4-RC1\\nIM En Route Initiation TSAS tools, slot marker color change, and ETA differential Feeder/Feeder D3-T4-RC1\\nIM TSAS tools Feeder/Final D3-T4-R3 D4-T1-R3 D5-T2-R3\\nIM TSAS tools and slot marker color change Feeder/Final D3-T5-R1 D4-T6-R1 D5-T4-R1\\nIM TSAS tools, slot marker color change, and ETA differential Feeder/Final D3-T6-R2 D4-T4-R2 D5-T1-R2\\nIM TSAS tools Final/Feeder D3-T3-R6 D4-T5-R6 D5-T6-R6\\nIM TSAS tools and slot marker color change Final/Feeder D3-T1-R4 D4-T2-R4 D5-T3-R4\\nIM TSAS tools, slot marker color change, and ETA differential Final/Feeder D3-T2-R5 D4-T3-R5 D5-T5-R5 (D)ay-(T)raffic File-(R)un Order 1 2 3 3-52 A summary of each data collection day (1 day for pilots; 3 days for controllers) is provided in\\nTable 3-7. Table 3-7. Data Collection Day Details Traffic\\nFile(s) Flight Crew (2 per day) Controllers (3 per day) 4\\n(with en route\\ninitiation) Introductory Briefing and Background\\nQuestionnaire. Training in lab Controller role:\\nA Feeder; B- Feeder\\nScenario:\\nTSAS and IM en route initiation\\nIndependent variable (order varied between days):\\n(1) Basic,\\n(2) Basic+ cue, or\\n(3) Basic+ cue and prediction 1, 2, 3, 4,\\n5, and 6 Pilot role (remained fixed):\\nPF; PM\\nOperation (order varied within day):\\n(1) Baseline No IM (x2 runs)\\n(2) IM (x10 runs)\\nTools (order varied within day):\\nMin CDTI then Min CDTI+ or\\nMin CDTI+ then Min CDTI Controller role (swapped after 3rd scenario):\\nFeeder; Final\\nOperation (traffic file order varied within day):\\nTSAS and IM (x6)\\nTools (order varied within day):\\n(1) Basic,\\n(2) Basic+ cue, or\\n(3) Basic+ cue and prediction 3.6 Data Collection\\nFour methods of data collection were used for this simulation: paper questionnaires, system\\nrecorded data, observations, and final debriefs (when chosen by the participants). Three types\\nof questionnaires were used, including: 1. Demographics: Upon arrival, participants were asked to fill out a demographics\\nquestionnaire which captured participants experience. Controllers and pilots had\\nseparate questionnaires. 2. Post- scenario: After each run / scenario, participants were asked to fill out a\\nquestionnaire based on the run / scenario just experienced. All post-scenario\\nquestionnaires included the Bedford Workload Rating Scale (Roscoe, 1984) along with\\nadditional rating scale and yes / no questions with a comment field for each. The\\ncontroller questionnaires included the Controller Acceptance Rating Scale (Lee, Kerns,\\nBone, and Nickelson, 2001). Pilot participants completed a post-scenario questionnaire\\nafter each run during a scenario (two runs per scenario) and controllers completed this\\nquestionnaire after each scenario. Separate post-scenario questionnaires were used for\\nthe baseline and IM scenarios. Controllers and pilots also had separate questionnaires\\n(Appendix B). 3. Post-simulation: After the final scenario, participants were asked to complete the longer,\\nfinal questionnaire covering all the scenarios experienced. The questionnaire included a\\nseries of rating-scale and yes / no questions with a comment field for each. Controllers\\nand pilots had separate questionnaires (Appendix C). 3-53 In these questionnaires, participants were asked to provide subjective feedback on areas such\\nas the overall IM concept, workload, situation awareness, head down / scan time, displays,\\ncommunications, and simulation realism. Objective metric data was automatically recorded by the simulation platform or by the\\nobservers and included: ATC o Interactions with displays Inputs for IM initiation, rejection, suspension, resumption, and termination o IM initiation delay o Location of IM initiations, rejections, suspensions, resumptions, and terminations All aircraft o Schedule conformance o Slot marker deviation o Events below the applicable separation standard o Frequency of infeasible / no speed events o Time on the RNAV procedure o Spacing error at key locations o How well the ASG was maintained o Arrival rates / throughput Participant aircraft o IM speeds o MCP selected speed o Distance to ABP o Frequency of IM terminations o Interactions with displays (e.g., TTF selection and data entry) 4-1 4 Results\\nThis section begins with a description of the analysis method for both subjective and objective\\ndata. It then describes baseline scenarios and the operations (terminal metering and RNP RF\\nturns) that form the operational foundation for IM. It then covers the objective data, including:\\nthe conduct of IM operations (mainly controller actions related to IM), IM speeds (for\\nparticipant pilot aircraft) and flight crew actions related to those speeds, and aircraft spacing\\nand separation results (for pseudo-pilot and participant pilot aircraft). Subjective data for both\\npilots and controllers is covered next (e.g., acceptability of IM, displays, responsibilities). Time\\non RNAV arrivals and communication results are then provided, followed by en route IM\\ninitiation results, as related to controllers. Finally, the section ends with results for the\\nparticipants assessments of the simulation. 4.1 Analysis Method 4.1.1 Subjective Data\\nThe subjective results are based on responses to the statements from both the post-scenario\\nand post-simulation questionnaires. The post-simulation questionnaires comprise most of the\\ndata so in these cases, the source will not be noted unless it helps for clarity. Any data from the\\npost-scenario questionnaires will be noted. Controller and pilot comments were included if they\\nwere enlightening or if a sufficient number of participants made similar comments. Controller results are based on nine participants while pilot results are based on 18\\nparticipants. Controller responses are divided by the independent variable of controller role.\\nPilot responses are usually combined (as role was not a planned independent variable), unless\\nthere was a clear reason to report the roles separately. Some questions in the questionnaires were yes / no with an opportunity for open-ended\\ncomments. Most response-scale items were statements with 100 hash marks (without numeric\\nlabels) and an opportunity to provide open-ended comments. The scale was anchored on the\\nleft with the label Strongly Disagree and on the right with the label Strongly Agree (Figure\\n4-1). Figure 4-1. 100-Point Agreement Scale Most items were presented as a statement, and participants were asked to rate their level of\\nagreement. Participants were told to draw a straight line anywhere on the scale, including\\nbetween the lines and right on the end points. During data reduction, responses were rounded\\nto the nearest single digit between 0 and 100. In the presentation of the results, any responses\\nbelow the midpoint (i.e., lower than 50) on the scale were considered to be on the disagree\\nside while any responses above the midpoint (i.e., higher than 50) on the scale were considered 4-2 to be on the agree side. Any responses at the midpoint (i.e., equal to 50) were considered to\\nbe neutral (Figure 4-2). Figure 4-2. 100-Point Agreement Scale Agreement Rating Breakdown When presenting results on the 100-point agreement scale in the post-simulation\\nquestionnaires, the following terminology / methodology is used to describe the levels of\\nagreement. All [controllers / pilots] [agreed / disagreed] o All of the participants are on the agree or disagree side of the scale The majority (n; %) of [controllers / pilots] [agreed / disagreed] o Low variability, e.g., SD of less than approximately 25 (unless one value is driving a\\nSD slightly higher) [Controller / Pilot] responses were variable but the majority (n; %) [agreed / disagreed] o Responses have a SD of greater than approximately 25 and distribution is relatively\\nbiased in",
  "updated_at": "3/31/2006 12:00:00 AM",
  "created_at": "3/8/2017 12:00:00 AM"
}
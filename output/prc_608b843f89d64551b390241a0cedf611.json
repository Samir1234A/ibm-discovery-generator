{
  "sdl_source_type": "PRC",
  "sdl_date": "2020-05-28T00:00:00",
  "countryPublished": "Croatia",
  "conference": "heavy moisturized ee Yarel",
  "originalAuthorName": "Kendal g Chukhin",
  "title": "Pitt hardtop's Demeter",
  "declaredTags": "CSG|shared aviation information|software design|organizational and environmental variables|bundled payments",
  "releaseReason": "folder/underachieved",
  "docName": "QT_63_5382",
  "fundingCenter": 74,
  "resourceURL": "https://happier.com",
  "fundingDepartment": "aq89",
  "caseNumber": "28-3117",
  "publicationDate": "8/25/2017 12:00:00 AM",
  "releaseYear": 2018,
  "releaseStatement": "Conference/Workshop",
  "approver": "$Belisaria $Votke",
  "handCarry": 1,
  "authorDivision": "dw83",
  "copyrightOwner": "Gon√ßalo Hauptvogel",
  "lastModifiedDate": "10/1/2013 12:00:00 AM",
  "releaseDate": "3/17/2011 12:00:00 AM",
  "onMitrePublicSrvr": 0,
  "projectNumber": "2928VVII29",
  "materialType": "Article",
  "publicationType": "Article",
  "authorCenter": 56,
  "originalAuthorID": "Simone",
  "mitrePublicServer": 0,
  "subjectTerminology": "Sensing and Signal Processing (General)",
  "dateEntered": "2/23/2001 12:00:00 AM",
  "documentInfoURL": "https://pudgiest mealier tireder largesse's formulates.com",
  "softShell": 0,
  "publishedOnNonMITREServer": 0,
  "priorCaseNumbers": "CASE1: 17-3768|CASE1: 18-0562|CASE1: 16-2039",
  "organization": "hr79",
  "authorDepartment": "xd65",
  "publicationYear": 2018,
  "sensitivity": "Public",
  "copyrightText": "(c) 2016 The MITRE Corporation All Rights Reserved",
  "fundingSource": "CAMH FFRDC Contracts",
  "level1": "HR, Strat Comm & BD Ops/Dev",
  "fundingDivision": "debunk cocoa Adele's shot route",
  "publishedOutsideUSA": 0,
  "level3": "fj88",
  "level2": "bh73",
  "sdl_id": "608b843f89d64551b390241a0cedf611",
  "text": "systems for such users (e.g., Figure 3: Annotation, clustering, and tag mapping. Figure 4: Inducing a model for each feature from facts and contentions. citizens not represented by attorneys familiar with the domain) requires extensive usability analysis. Another proviso is that this study doesnt rule out the possibility that highlighting produced by a different predictive model might be more useful for decision support. Perhaps the most illuminating comments by participants were that they had difficulty understanding the connection between the highlighted text and the issue that they were supposed to decide. These comments, and the overall results of study, indicate that use- ful decision support should help the user understand the connection between relevant portions of the case record and the issues of the case. 4 SCALE: SEMI-SUPERVISED CASE ANNOTATION FOR LEGAL EXPLANATIONS The results of the evaluation of NFE suggest that an effective deci- sion support system for prediction explanations must identify not just relevant case text, but fact patterns and issues that connect the text to the predicted outcome. To achieve this capability in Semi-Supervised Methods for Explainable Legal Prediction ICAIL19, June 2019, Montreal, QB, CA Figure 5: Inducing and applying feature-to-issue models. the WIPO domain without individually annotating every case, we have developed a novel approach based on exploiting regularities in opinion structures. This approach is based on several observations about the consistency of language across separate cases and within different sections of the same case. First, we observe that the relatively stereotyped language of administrative case decisions means that statements with similar legal effect in different cases tend to be close to each other in semantic-embedding space [22]. Thus, annotation tags applied to a subset of cases can bemapped to an entire corpus, with accuracy and completeness that depends on the consistency of the case language within the corpus, the typicality of the annotated cases, and the threshold for semantic similarity. Second, most factual-finding or legal-ruling sentences correspond semantically to one or more sentences in the contentions section. This is a manifestation of the inherent property of cases that findings and rulings resolve contentions by parties. Third, the polarity of each finding and rule, that is, which party it supports, depends on sentences in the facts section. Thus, machine-learning techniques developed to predict the overall outcome of the case can be applied as well to predict the polarity of individual findings and rulings. Finally, in many administrative domains the Findings or Decision sections of cases are subdivided into predictable subsections, each resolving one of the elements (issues) that a Complainant must establish. In WIPO cases, there are 4 subsections. Considering each subsection separately permits the overall decision to be broken into separate steps, improving the comprehensibility. Our key hypothesis is that these document regularities can be exploited to project annotations on a representative set of decisions onto the entire corpus, and that the resulting semi-automated cor- pus can be exploited to identify the case features (1) to predict the issues on which the decision will turn and the decision itself, (2) to justify a prediction in terms of the features of the particular case, and (3) to identify prior cases whose facts and contentions are most relevant to a given case. As shown in Figure 3, Step 1 of the SCALE procedure consists of manual annotation of the Findings section of a representative set of cases. All sentences in the corpus in close proximity to a tagged sentence in the semantic-embedding space are identified Figure 6: Analysis of a new case. UDNDRP repre- sents Section 4 of the Uniform Domain Name Dispute Resolution Policy (https://www.icann.org/resources/pages/ policy-2012-02-25-en). in Step 2, and in Step 3 the corresponding tags themselves are mapped to all similar sentences from the Findings section of some case. The result of these steps is an annotation of the Findings section of every case in the corpus. These mapped annotations will almost certainly be less accurate than manual annotations; the actual accuracy will depend on the details of both the original annotation and the clustering itself. However, we hypothesize that the mapped annotations are accurate enough for prediction, triage, and decision support. Figure 4 shows the next step, inducing a separate model for each feature from the case description, i.e., the Facts and Contentions. In Step 5, shown in Figure 5, feature-to-issue models are induced for each of the high-level issues. Finally, Figure 6 illustrates how the prediction for a new case proceeds by predicting features from Facts and Contentions, predicting issue-decisions based on features, and finally predicting the transfer decision based on the issues. The SCALE approach differs from NFE in it that involves reason- ing about case features induced from the case description which can be used to explain and justify a prediction. Our initial imple- mentation involves annotation of 16,092 WIPO decisions. 5 ANNOTATION A key goal of SCALE is a methodology that permits development of explainable legal prediction systems by agencies that lack the resources to engineer domain-specific feature sets, a process that requires both extensive expertise in the particular legal domain and experience in feature engineering. Instead, SCALE requires only the linguistic skills necessary to annotate the decision portion of representative cases, a much simpler process. Our annotation schema for WIPO decisions consists of three lay- ers: Argument Elements, Issues, and Factors (sub-issues).5 Tags are applied to clauses and sentences, as opposed to shorter units such as noun phrases, in order to identify the complete linguistic propo- sition corresponding to the annotation label. The MITRE Annota- tion Toolkit (MAT) is used to perform the annotation (http://mat- annotation.sourceforge.net/). 5We are also currently exploring a fourth layer, Evidence, which captures the evidence\\ncited in support of the Factor or Issue. As this exploration is still underway and the Evidence tag set continues to expand, it will not be discussed further here. https://www.icann.org/resources/pages/policy-2012-02-25-en\\nhttps://www.icann.org/resources/pages/policy-2012-02-25-en ICAIL19, June 2019, Montreal, QB, CA Branting, Pfaff, Weiss, Brown, Pfeifer, Chakraborty, Ferro, and Yeh 5.1 Argument Elements Although our approach to predictive-text identification is to lever- age the Factual Findings and Legal Findings, the annotation schema is designed to capture the full range of argument elements present. These argument elements are as follows: (1) Policy (2) Contention (3) Factual Finding (4) Legal Finding (5) Case Rule (6) Decision We have found that with these six argument elements, the major- ity of sentences within the \\\"Discussion and Findings\\\" and \\\"Decision\\\" sections of WIPO cases can be assigned an argument element label. These argument elements are not specific to WIPO decisions, and should have utility in other domains. 5.2 Issues Each Argument Element tag is assigned an Issue. The Issue tags include the three required elements that the complainant must establish in order to prevail in a WIPO case. These issues are docu- mented in the Uniform Domain Name Dispute Resolution Policy, paragraph 46, and form the backbone of every decision: (i) ICS: Domain name is Identical or Confusingly Similar to a trademark or service mark in which the complainant has rights (ii) NRLI: Respondent No Rights or Legitimate Interests in respect of the domain name. (iii) Bad Faith: Domain name has been registered and is being used in Bad Faith. For element (ii), NRLI, although the dispute is typically ap- proached from the point of view of the complainant demonstrating that the respondent has NRLI, it is very often the case that the panel considers the rights or legitimate interests of the complainant and/or the respondent. In that case, RLI is available as an Issue tag. In addition, the domain name resolution procedure allows for situations in which the complainant abuses the process by filing the complaint in bad faith (CIBF).7 The schema thus consists of five Issue tags, plus an Other cate- gory: ICS NRLI RLI BadFaith CIBF OTHER 5.3 Factors In our annotation scheme Factors are the elements which we hy- pothesize will prove most useful for explainable legal prediction. 6https://www.icann.org/resources/pages/policy-2012-02-25-en#4.\\n7See 15(e) of the Rules for Uniform Domain Name Dispute Resolution Policy for CIBF, https://www.icann.org/resources/pages/udrp-rules-2015-03-11-en Figure 7: Four text spans annotated with factual and legal- findings features. The factors and corresponding tags are specific to the WIPO issues. For ICS, the ICANN policy does not explicitly identify specific fac- tors that will be considered by the panel, so our tag set for ICS is derived from factors commonly observed in the data, such as CownsTM (Complainant owns Trademark) and TMentire (Trade- mark is contained in its entirety within the Domain Name). For NRLI/RLI, the policy establishes three factors, and for Bad Faith, four factors. Each of these has a corresponding tag. For example, under NRLI there is PriorBizUse from 4(c)(i) of the policy (Bona fide business use of Domain Name or demonstrable preparations to do so, prior to notice of the dispute) and under BadFaith there is Confusion4CommGain from 4(b)(iv) of the policy For commercial gain from confusion with complainants mark). The tag set also includes labels for other common factors observed in the data, such as PrimaFacieEst (Prima Facie Case Established). For CIBF, two factor tags are available:",
  "updated_at": "1/6/2011 12:00:00 AM",
  "created_at": "10/16/1993 12:00:00 AM"
}
{
  "sdl_source_type": "MPL",
  "productName": "triples Gestapo",
  "uploadedate": "2019-01-21T00:00:00",
  "productUrl": "http://trueing.com",
  "creatorNames": "Eufronio j Muhlenbeck;Genis h Bakihanoff;Fuqiang f Bretal;Tatiane q Wrona",
  "uploaded": "2012-07-21T00:00:00",
  "sdl_extracted_summary": "    \"text\": \" Prepared for:\\nDepartment of Homeland Security Dynamic Data Map Technical Report May 8, 2018 Authors: \\nJason Veneman\\nBrian Tivnan The Homeland Security Systems Engineering and Development Institute (HSSEDI)TM Operated by The MITRE Corporation Approved for Public Release; Distribution Unlimited.\\nCase Number 18-1675 / DHS reference number 16-J-00184-08 This document is a product of the Homeland Security Systems Engineering and Development Institute (HSSEDI). i Homeland Security Systems Engineering & Development Institute\\nThe Homeland Security Act of 2002 (Section 305 of PL 107-296, as codified in 6 U.S.C. 185), herein \\nreferred to as the Act, authorizes the Secretary of the Department of Homeland Security (DHS), acting \\nthrough the Under Secretary for Science and Technology, to establish one or more federally funded \\nresearch and development centers (FFRDCs) to provide independent analysis of homeland security issues. \\nMITRE Corp. operates the Homeland Security Systems Engineering and Development Institute (HSSEDI) \\nas an FFRDC for DHS under contract HSHQDC-14-D-00006. The HSSEDI FFRDC provides the government with the necessary systems engineering and development \\nexpertise to conduct complex acquisition planning and development; concept exploration, \\nexperimentation and evaluation; information technology, communications and cyber security processes, \\nstandards, methodologies and protocols; systems architecture and integration; quality and performance \\nreview, best practices and performance measures and metrics; and, independent test and evaluation \\nactivities. The HSSEDI FFRDC also works with and supports other federal, state, local, tribal, public and \\nprivate sector organizations that make up the homeland security enterprise. The HSSEDI FFRDCs \\nresearch is undertaken by mutual consent with DHS and is organized as a set of discrete tasks. This report \\npresents the results of research and analysis conducted under: HSHQDC-16-J-00184\\nNext Generation Cyber Infrastructure (NGCI) Apex Cyber Risk Metrics and Threat Model Assessment This HSSEDI task order is to enable DHS Science and Technology Directorate (S&T) to facilitate \\nimprovement of cybersecurity within the Financial Services Sector (FSS). To support NGCI Apex use \\ncases and provide a common frame of reference for community interaction to supplement institution-\\nspecific threat models, HSSEDI developed an integrated suite of threat models identifying attacker \\nmethods from the level of a single FSS institution up to FSS systems-of-systems, and a corresponding \\ncyber wargaming framework linking technical and business views. HSSEDI assessed risk metrics and risk \\nassessment frameworks, provided recommendations toward development of scalable cybersecurity risk \\nmetrics to meet the needs of the NGCI Apex program, and developed representations depicting the \\ninterdependencies and data flows within the FSS. The results presented in this report do not necessarily reflect official DHS opinion or policy. For more information about this publication contact: Homeland Security Systems Engineering & Development Institute The MITRE Corporation\\n7515 Colshire Drive\\nMcLean, VA 22102 Email: HSSEDI_info@mitre.org http://www.mitre.org/HSSEDI mailto:hssedi_info@mitre.org\\nhttp://www.mitre.org/HSSEDI ii Abstract\\nThe Homeland Security Systems Engineering and Development Institute (HSSEDI) assists the \\nDepartment of Homeland Security (DHS) Science and Technology Directorate (S&T) in the \\nexecution of the Next Generation Cyber Infrastructure (NGCI) Apex program. HSSEDI \\ndeveloped a comprehensive data map of an essential subsector of the Financial Services Sector \\n(FSS), namely the capital markets. This data map provides a foundational component for an \\nextensive NGCI testing program. \\nHSSEDI concludes this report with a set of three recommendations for the NGCI Apex program \\nto enhance its representational testing environment: HSSEDI recommends that the NGCI Apex program expand this dynamic data map into \\nan exhaustive depiction of workloads and time criticality for a small set of known market \\nevents when the market infrastructure experienced particularly heavy workloads and \\ndelays. HSSEDI recommends that the NGCI Apex program use these known market events and \\nHSSEDIs Threat Model to inform detailed test scenarios for use in the representational \\ntesting environment. HSSEDI recommends that the NGCI Apex program integrate this dynamic data map with \\nHSSEDIs previous technical reports on Cybersecurity Risk Metrics Survey and the \\nFinancial Systems Mapping to provide a comprehensive treatment of the systemic risk \\nfacing the FSS. Key Words \\nNext Generation Cyber Infrastructure (NGCI) Apex program1.\\nCritical Infrastructures2.\\nFinancial Services Sector (FSS)3.\\nCapital Markets4.\\nNational Market System (NMS)5. iii iv Table of Contents \\n1 Project Overview \\n2 Overview of the Capital Markets and Related Infrastructure \\n2.2 Interdependence Across the Financial Services Sector \\n3.1 Single Asset Analysis \\n3.2 Multi-asset Analysis \\n3.3 Bandwidth \\n3.4 Infrastructure \\n3.5 Dynamic Message Traffic \\n3.6 Data Source \\n3.7 Dynamic Data Behavior Impacts of High Traffic \\nList of Acronyms \\nFigure 1. Geographic location of the primary exchange data centers in New Jersey \\nFigure 2. Interconnections between the exchanges \\nFigure 3. Relationships and numbers of investors and exchanges \\nFigure 4. Interdependence across the Financial Service Sector \\nFigure 5. Apple stock price on August 11, 2015 \\nFigure 6. Apple stock trades per second on August 11, 2015 \\nFigure 7. Apple stock dollars traded per second on August 11, 2015 \\nFigure 8. Apple stock cumulative dollars traded on August 11, 2015 \\nFigure 9. Cumulative volume by exchange for AAPL shares \\nFigure 10. Quote messages per second in seconds since midnight \\nFigure 11. Frequency of observed message types \\nFigure 12. Rates of messages for all tickers in a single day \\nFigure 13. Visualization of messages passing between exchanges and to an observer \\nFigure 14. Sequential frames from a video of market dynamics in action \\nFigure 15. Number of SIP locks as a function of capacity \\nFigure 16. Number of SIP crosses as a function of capacity \\nTable 1. Top 10 trading days from January 2010 through February 2018 \\nTable 2. Total notional value of trades January 2010 through February 2018 by date \\nTable 3. Total trades from January 2010 through February 2018 at each exchange \\n2 HSSEDI, \\\" Enhanced Cyber Threat Model for Financial Services Sector (FSS) Institutions,\\\" The MITRE Corporation, McLean, \\nVA, March 2018.\\n3 HSSEDI, \\\"Financial System Mapping (Final),\\\" The MITRE Corporation, McLean, VA, March 2018. Project Overview1\\nThe Next Generation Cyber Infrastructure (NGCI) Apex Program seeks to accelerate the \\nadoption of cyber technologies proven to be effective for mitigating information technology (IT) \\nsecurity risk. Initially, the focal, critical infrastructure for the NGCI Program is the Financial \\nServices Sector (FSS). The FSS is one of the most interdependent of the critical infrastructures, \\ncomprised of intensely competing organizations which collectively hold the nations economic \\nsecurity in their decision-making related to technology implementation. The goals of the NGCI \\nprogram are to 1) increase financial sector-wide situational understanding of evolving IT security \\nrisk and the technology associated with mitigating that risk; 2) improve the ability to understand \\nand link compromises in the underlying cyber infrastructure to sub-sector operations; 3) enable \\ngreater information flows between sub-sectors as well as across the entire sector; and 4) enable \\nFSS institutions to detect and neutralize adversaries more quickly and effectively than is \\ncurrently possible. To achieve these goals, the NGCI program requires an extensive testing \\nprogram beyond testing at the level of individual institutions. \\nTherefore, the NGCI Apex Program Management Office tasked the Homeland Security Systems \\nEngineering and Development Institute (HSSEDI) to perform workload modeling which \\ndescribes the data dynamics within and between systems to provide a basis for workloads in the \\nrepresentational testing environment. As such, HSSEDI developed a comprehensive data map of \\nthe capital markets subsector of the FSS, thereby providing a foundational component for an \\nextensive testing program in support of the NGCI Apex program. Here, the term map conveys a \\nguide to the mechanisms of the generation and flow of market activity data from one financial \\ninstitution to another across an entire subsector of the FSS. The specific objective of this report is \\nto identify and depict the scale and time criticality of essential business functions in a central \\nsubsector of the FSS. To achieve this objective, HSSEDI performed extensive analyses on a \\ndataset which is both authoritative and exhaustive. Because the capital markets subsector is often \\nidentified as one of the most technologically advanced within the FSS, this report identifies \\nworkloads that could appropriately serve as surrogates or upper bounds in the representational \\ntesting environment. \\nIn this way, this report complements the objectives of previous HSSEDI products for the NGCI \\nprogram, namely the Cyber Risk Metrics Survey and Assessment, and Implementation Plan1, the \\nEnhanced Cyber Threat Model for Financial Services Sector (FSS) Institutions2, and the \\nFinancial System Mapping3. The objective of the cyber risk metrics survey and assessment task is \\nto identify risk metrics and assessment frameworks that could be candidates to measure the \\nsystemic impact of the NGCI Apex program on the FSS. The objective of the threat models \\nsurvey and assessment task is to identify threat models and frameworks that could be candidates \\nto inform systemic testing in the NGCI Apex program. Finally, the objective of the financial \\nsystem mapping task is to identify and depict the intrinsically interdependent nature of the \\nsubsectors which comprise the Financial Services Sector. ii Task Overview for the Dynamic Data Map 1.1\\nThe purpose of the task is to develop a comprehensive data map of a subsector of the FSS, \\nthereby providing a foundational component for an extensive testing program in support of the \\nNGCI Apex program. This technical report describes and analyzes the data dynamics within and \\nbetween financial systems to provide a basis for workloads in the representational testing \\nenvironment. \\nTo accomplish this task",
  "sdl_date": "2020-07-16T00:00:00",
  "countryPublished": "Bhutan",
  "conference": "fang's democratization dv Andzelika",
  "originalAuthorName": "Obdulio c Krusekopp",
  "title": "speedup Sue's hallucinogenics sift",
  "declaredTags": "systems engineering|floating|scheduling|Flight Management Systems",
  "releaseReason": "tablespoon/segueing",
  "docName": "PR_98_4376",
  "fundingCenter": 41,
  "resourceURL": "https://fermenting.com",
  "fundingDepartment": "or30",
  "caseNumber": "55-5690",
  "publicationDate": "4/9/2020 12:00:00 AM",
  "releaseYear": 2014,
  "releaseStatement": "Public Collaboration/Benchmarking/Standards Body",
  "approver": "$Meriyem $Seckel",
  "handCarry": 3,
  "authorDivision": "dx30",
  "copyrightOwner": "Eutiquio Duurkoop",
  "lastModifiedDate": "6/14/2013 12:00:00 AM",
  "releaseDate": "12/29/2012 12:00:00 AM",
  "onMitrePublicSrvr": 0,
  "projectNumber": "6124TCAC93",
  "materialType": "Book",
  "publicationType": "Book",
  "authorCenter": 31,
  "originalAuthorID": "Ramute",
  "mitrePublicServer": 0,
  "subjectTerminology": "Computer Systems Organization (General)",
  "dateEntered": "6/5/2004 12:00:00 AM",
  "documentInfoURL": "https://tidbits denotation kiosk's droopier microprocessors.com",
  "softShell": 0,
  "publishedOnNonMITREServer": 0,
  "priorCaseNumbers": "CASE4  17-3133",
  "organization": "cj95",
  "authorDepartment": "bv48",
  "publicationYear": 2007,
  "sensitivity": "Public",
  "copyrightText": "(c) 2016 The MITRE Corporation All Rights Reserved",
  "fundingSource": "FAA FFRDC Contracts",
  "level1": "MITRE National Security Sector",
  "fundingDivision": "disharmonious berths Mendez's regularity Lebanon",
  "publishedOutsideUSA": 0,
  "level3": "mj28",
  "level2": "jv36",
  "sdl_id": "87f703e0e0b54488b512daded05291ee",
  "text": "responses. The majority (80%) of TRACON controllers agreed (M=76.5; SD=19.8) that they were \\ncomfortable allowing an IM Trail Aircraft to manage its own speed to achieve the desired \\nspacing goal at the FAF. Two controllers neither agreed nor disagreed. From the open-ended comments, at least three of the lower ratings appeared to be a result of \\ncontrollers not being allowed to manually keep the IM Trail Aircraft between the limits when it \\nbecame apparent that a Caution Alert was imminent. xii\\n Traffic Awareness6.2.4\\nAt the end of Day 1 and Day 2, controllers were asked about the acceptability of their overall \\nlevel of traffic awareness with respect to the IM Lead Aircraft, IM Trail Aircraft, and Other \\nAircraft. Their responses were examined with respect to monitor configuration. Response \\nMeans and Standard Deviations are summarized in Table 5-6. Scale responses are shown in \\nFigure 5-7. Only Week 2-3 TRACON controller responses were included in the analysis. Table 5-6. Controller Responses to Traffic Awareness Acceptability: Aircraft Type Monitor Configuration Separate Combined\\nIM Lead Aircraft Sample Size (n) 7 7 Mean (M) 95.4 90.9 Standard Deviation (SD) 4.7 8.2 IM Trail Aircraft\\nSample Size (n) 7 7 Mean (M) 83.7 87.3 Standard Deviation (SD) 18.7 15.3 Other Aircraft\\nSample Size (n) 7 7 Mean (M) 82.9 88.0 Standard Deviation (SD) 23.5 8.4 Figure 5-7. My overall level of traffic awareness today was acceptable with respect to [IM Lead Aircraft \\n IM Trail Aircraft / Other Aircraft]. xiii\\n Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed their overall level of traffic awareness was acceptable \\nwith respect to all aircraft types for both monitor configurations, except for Separate Monitors / \\nOther Aircraft. In this case, the one participant that disagreed noted in the open-ended \\ncomments: Difficult to determine distance between successive lead aircraft. This participant \\nhas TRACON experience, though is currently assigned to a Tower position. This may help explain \\nthe lower rating. The overall results do not suggest any apparent differences in acceptability by monitor \\nconfiguration among aircraft types. However, Lead Aircraft response variability for the IM Lead \\nAircraft appeared to be lower for the Separate Monitor configuration than for all the other \\ncases. Other open-ended comments for this question included: (Non-NCT TRACON / Separate): Trails do not need to be monitored as closely because \\nthere is automation to ensure separation. Focus can be spent elsewhere.\\n(Non-NCT TRACON / Combined): Definitely was more aware of the trail aircraft because \\nof the new procedures. But spacing required more attention to the lead aircraft \\nfollowing other pairs.\\n(Non-NCT TRACON / Combined): As the day went on, I focused more on distance \\nbetween pairs as opposed to the aircraft in the PA. This was easy because of the alerts \\nand warnings. Separation6.2.5\\nThis section summarizes the subjective questionnaire data with respect to controller confidence \\nof ensuring separation within the IM PA pairs. It also includes the objective data analysis with \\nrespect to observed separation violations within and between the IM PA pairs on the arrivals. Subjective Data Assessment6.2.5.1\\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \\nmonitor configurations, controllers were asked: overall, I was confident that I could assess \\nwhether the separation between the IM Trail Aircraft and their Lead Aircraft would be \\nmaintained. Responses are shown for all TRACON (NCT and non-NCT combined) and Tower \\nOnly. Response Means and Standard Deviations are summarized in Table 5-7. Scale responses \\nare shown in Figure 5-8. Table 5-7. Monitor Controller Responses to Confidence in Assessing Separation between IM Trail and \\ntheir Lead Aircraft Participant Experience TRACON Tower\\nSample Size (n) 10 2 xiv\\n Mean (M) 77.9 75.5 Standard Deviation (SD) 21.1  Figure 5-8. Overall, I was confident that I could assess whether the separation between the IM Trail \\nAircraft and their Lead Aircraft would be maintained. Note: o indicates NCT Controller responses. When asked if they could assess whether the separation between the IM Trail Aircraft and their \\nLead Aircraft would be maintained, the majority (80%) of TRACON controllers agreed (M=77.9; \\nSD=21.1). One TRACON controller disagreed and commented: Need CSL & WSL sooner. It is \\nunclear why CSL was noted since it was present at the start of the IM PA operation. Though not \\nshown, further analysis suggests the subjective separation assessment did not appear to be \\naffected by varying the alert timing. Another open-ended comment from a TRACON controller noted: Relying on the automation. \\nWithout it, I could not at this proximity. Objective Data Assessment6.2.5.2\\nAs noted in Section 4.5.7.2, the simulation recorded aircraft state data and PTT click data for \\neach scenario. This data was then post-processed to determine if any losses of separation \\noccurred and if so, whether monitor configuration or IM PA Tool configuration had any effect. \\nThis data only includes the Nominal and Alert Timing scenarios for Weeks 2-3 due to scenario \\nchanges after Week 1. The Day 3 Lateral Deviation scenarios were not included in the post-\\nprocessing analysis due to their complexity. There was one controller in Week 3 who had \\nconsiderable experience at a major tower, but no TRACON experience. This participants \\nseparation data is not included and 21 runs (across seven controller participants) were \\nevaluated for the Day 1-2 Nominal scenarios. The same number of runs, 21, were also evaluated \\nfor the Day 3 Alert Timing scenarios. Separation was considered within and between IM PA pairs. Within IM PA Pairs. Here, separation was considered lost if a trail aircraft crossed a CSL \\nor WSL boundary before a controller contacted it to provide breakout instructions. \\nContact was determined to have occurred if there was a PTT click between the time of a \\nCaution Alert and the aircraft crossing either safety limit. xv\\n Between Pairs. Here, separation was defined per the minima as described in Section \\n4.3.3. If the spacing between any non-IM PA combination of aircraft went below than \\nthe Wake Turbulence or MRS minima, it was considered a separation violation. The post-processing involved an automated script that examined the traffic data and flagged \\ninstances where the above separation definitions were violated. Each resulting case was then \\nverified manually against the controller display video capture videos and/or other MITRE \\nvisualization tools. MITRE controller subject matter expert (SME) input was used to make a final \\ndetermination of the instances that should count as violations. Across all the scenarios, the \\nnumber of separation violations that were observed is summarized in Table 5-8: Table 5-8. Number of Observed Separation Violations (Weeks 2-3) Separation Violations Within IM PA \\nPairs Between \\nPairs Day 1-2 Nominal 0 10 Day 3 Alert Timing 1 2 Within IM PA Pair Separation Violations For the seven TRACON Week 2-3 participants, there were zero IM PA separation violations \\nobserved for the 21 evaluated Day 1-2 Nominal scenarios. For the 21 evaluated Week 2-3, Day 3 Alert Timing scenarios, 5 cases were observed in which an \\nIM Trail Aircraft crossed a safety limit line while it was still being displayed. These may have \\nbeen cases, however, where the controller prioritized communicating a break out instruction to \\nthe aircraft before terminating IM PA in the automation. A controller PTT click was observed \\nbetween the time of the Caution Alert and the time of the crossing. As described in Section \\n5.1.2, due to the lack of override capability, it was also possible that the controller was blocked \\nand therefore the break out instruction could not be provided to the IM Trail Aircraft before IM \\nPA was terminated and the safety limit line was crossed. These cases were therefore not \\ncounted as violations as the controller may have in effect terminated the operation before the \\nline was crossed. Further analysis was performed to examine how soon the PTT click happened \\nin these cases before the crossing occurred. The results are shown in Table 5-9. Table 5-9. Day 3 Alert Timing Safety Limit Exceedances with PTT Response (Weeks 2-3) Case Alert Timing Safety Limit Crossed Time Between \\nPreceding PTT click and Crossing\\n1 25/15 WSL 8 sec\\n2 25/15 CSL 11 sec\\n3 25/15 CSL 9 sec\\n4 25/15 CSL 17 sec xvi\\n 5 25/15 WSL 9 sec M 10.8 sec\\nSD 3.6 sec Only a single separation violation case was observed for the 21 evaluated Week 2-3, Day 3 Alert \\nTiming scenarios, and it involved the 25/15 sec alert timing. In this scenario, an IM Trail Aircraft, \\nAAL2435, was deliberately designed to maintain a faster-than-normal speed on the approach so \\nthat the IM PA alerts would be triggered relative to its CSL. Shortly after the Predictive Alert was \\ndisplayed, the controller issued a 30 kt speed reduction to this aircraft. Per the instructions to \\nthe participants, the controller should then have terminated IM PA and broken the aircraft out. \\nHowever, the controller elected to keep the IM PA active and watch the situation. The aircraft \\nbegan to implement the 30 kt speed reduction but due to a simulation artifact, did not reduce \\nfurther to its final approach speed after the FAF. A",
  "updated_at": "9/4/2019 12:00:00 AM",
  "created_at": "3/23/1997 12:00:00 AM"
}
{
  "sdl_source_type": "PWS",
  "source_library": "SRC-glosses",
  "file_name": "fresco's.ext",
  "document_url": "http://chieferstream's.com",
  "uploaded_by": "Edison j Arexendi",
  "last_modified": "4/25/2014",
  "sdl_date": "2020-06-15T00:00:00",
  "countryPublished": "Thailand",
  "conference": "alienable catalyzes km Zitounia",
  "originalAuthorName": "Chaya k Turcan",
  "title": "fuddle's pap's pain",
  "declaredTags": "airspace|FMS|acquisition|health care",
  "releaseReason": "overcompensation/Chrysler's",
  "docName": "PE_97_5084",
  "fundingCenter": 45,
  "resourceURL": "https://cubit.com",
  "fundingDepartment": "pm11",
  "caseNumber": "69-4300",
  "publicationDate": "8/14/2019 12:00:00 AM",
  "releaseYear": 2007,
  "releaseStatement": "Conference/Workshop",
  "approver": "$Mallie $Muhammad",
  "handCarry": 0,
  "authorDivision": "lm38",
  "copyrightOwner": "Haitam Jamain",
  "lastModifiedDate": "12/13/2013 12:00:00 AM",
  "releaseDate": "3/7/2002 12:00:00 AM",
  "onMitrePublicSrvr": 0,
  "projectNumber": "3889ILSC27",
  "materialType": "Article",
  "publicationType": "Paper",
  "authorCenter": 74,
  "originalAuthorID": "Katja",
  "mitrePublicServer": 0,
  "subjectTerminology": "Air Traffic Management",
  "dateEntered": "3/11/2014 12:00:00 AM",
  "documentInfoURL": "https://tracking shammies yellowing electrocardiograph Alphecca's.com",
  "softShell": 0,
  "publishedOnNonMITREServer": 0,
  "priorCaseNumbers": "CASE1: 13-0202|CASE1: 18-0296",
  "organization": "mw13",
  "authorDepartment": "oj94",
  "publicationYear": 1990,
  "sensitivity": "Public",
  "copyrightText": "(c) 2016 The MITRE Corporation All Rights Reserved",
  "fundingSource": "NSEC MOIE",
  "level1": "MITRE Public Sector",
  "fundingDivision": "Khoikhoi's disfigure tinker azaleas locoweed",
  "publishedOutsideUSA": 0,
  "level3": "us89",
  "level2": "mq27",
  "sdl_id": "778667463bfb4e119ee84a10d3daf3e2",
  "text": "severed if o , = 0. There are many benefits of the SNN construct. First, SNN is built upon the k-NN relationship, which provides automatic density scaling because nearest is insensitive to local scale [20]. Secondly, as a secondary metric built upon shared neighbors, it can overcome limitations in primary distance metrics due to contrast loss in high dimensions [32]. Lastly, SNN has been proven to be resilient to the hub phenomenon affecting data mining in high dimensional spaces if used for distance prescaling [33]. Note that whereas the HSI extrinsic dimension (number of bands) can be on the order of hundreds, the intrinsic (or inherent) dimensionality is often much less, typically on the order of tens of dimensions (or less) as demonstrated in [8]. Lower spatial resolution HSI data, especially of urban scenes, generally has higher intrinsic dimension [8] so it is prudent to study methods more resistant to challenges associated with the curse of dimensionality. Conversely, as a secondary metric, SNN similarity is more computationally expensive to the point of being prohibitive if performing neighborhood intersection over every node. Calculating the SNN graph from every pixel takes pGh +\\nGhkSiG time, where the quadratic is the result of the pairwise \\ndistance calculation and the log term is from the intersection over the entire dataset. However, SNN construction can be performed in reasonable time if working from an initial mutual k-NN construct or other method to reduce the number of required intersections such as starting with a limited, but higher value for k or spatially limiting the pixels that can be connected [25]. In this case SNN is an edge reweighting scheme vice a primary metric scaling. Fig. 5 demonstrates the effectiveness of counting shared neighbors on the example Deluanay triangulation from Fig. 2. Notice the edge weights have been adjusted such that nodes in regions of similar density are more strongly connected whereas those in transition (intercluster) regions are deweighted. \\nAs described above, edge weights are simply the number of shared nearest neighbors. However, this construct does not utilize any information about the ordering of nodes within neighborhood lists. Clearly two nodes that have the same closest neighbor are more likely to be similar than two whose shared neighbor is the closest for one point and farthest from the other. The SNN metric may be adjusted to include k-NN rank information [30], wherein edge weights are redefined as { }\\n,)1()1( )()( \\n ++=\\njNNiNNv ij nkmkw\\nI (9) where k denotes the size of the NN set, and m and n are the ranks (positions) of the common neighbors in and respectively, so ) 1, 8h4. Each \\ncomponent of the summation in (7) has the same form, 8 r + 1. The first part produces a scalar inversely \\nproportional to ranking, i.e., lower ranks result in higher scalars, but spans [0,k-1]. The addition of one aligns component contributions to [1,k], so that there are no zero components. The user may threshold the SNN weights as part of a clustering algorithm or leave the weights as is for operations requiring connected graphs in subsequent processing (e.g., target detection). In the latter case, there are fewer artificial connections created during post processing to ensure connectivity. Fig. 6 illustrates the utility of rank dependent weights with a simple toy example. Notice the simple SNN count produces the same edge weight of two for ) , )9 , and )9 despite the fact is not in the same cluster \\nas and 9. The rank dependent SNN similarity measure shows that \\n4 Ranked component contributions can also be added if multiplication is too severe [30]. Fig. 5. SNN rescaling of the Delaunay triangulation from Fig. 2. Notice the stronger relationships between intracluster nodes and weaker relationships between intercluster nodes. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \\n 9 and 9 are much more similar than and or and 9, \\nin line with our expectations. It is interesting to note that this particular situation is avoided by an initial construction that uses mutual k nearest neighbors, i.e., edges to node disappear because \\n and 8. The mutuality constraint used in the construction of initial edges not only provides protection against edges spanning regions of different density, but also maintains a balance in nearest neighbor list size. Imbalanced nearest neighbor lists facilitate dissimilar nodes appearing more similar than those that are similar. For example, Fig. 7 shows a case where the neighborhood size and geometric configuration is such that there is an imbalance in the intersections between pairs of nodes. In this case, or 9 occupy a position in each others \\nnearest neighbor lists. This reduces the number of possible nearest neighbors in the intersection by one for each node. Node doesnt have either and 9 in its nearest neighbor \\nlist, hence has a larger number of nearest neighbors left from which to form a neighborhood intersection set with other nodes. This imbalance creates an extra term in the sum from (9) for which may result in a higher similarity score. In this \\ncase, and 9 can be more similar to than to each other \\n(edge ik is weighted from two common neighbors edges, where edges ij and kj are weighted from three). Note that the magnitudes of the imbalance effect decreases with increasing neighborhood size, so regions of low density are impacted the most e.g., lower density regions from adaptive nearest neighbor techniques. The SNN similarity variants above do not account for the distance (or similarity) between nodes either, only their overlapping neighborhoods and ranks. A node may have the same rank with respect to two other nodes, but have vastly different distances (similarities) to those nodes. In this case it seems appropriate that this node contributes differently to the SNN score for each of the nodes. A modified metric based on work by Moellic et al. [34] uses the shared NN count, rank, and node similarity given by { }\\n,)1()1( )()( \\n ++=\\njNNiNNv jvivij dsimnkdsimmkw\\nI (10) where dsim is a dissimilarity measure between nodes. The more dissimilar the nodes, the larger the subtracted term, hence the smaller the component contribution. Similar nodes (low dissimilarity, small distance) result in smaller values being subtracted from k, increasing the component contribution. In this work, the cosine distance will be used as the dissimilarity metric to promote higher scores for those neighbors that may have varying illumination. The sensitivity of cosine distance to dark pixel selection is mitigated by the fact only nearest neighbors are subject to the metric. The asymmetric neighborhood variants are given by simply replacing the ks in (9) and (10) by 8 and 8 respectively. B. Mutual Proximity Graphs Introduced by Schnitzer et al. [28], mutual proximity (MP) transforms distances into similarities such that pixels with similar nearest neighbors are brought closer together, whereas those with dissimilar nearest neighbors are pushed farther apart. This is akin to local scaling except mutual proximity is a global vice local transformation. To calculate MP, the distances between and all other \\nnodes , ? , are assumed to originate from a known \\nprobability density function (pdf). Using a nodes distance distribution, pdf(?), any distance, ?, can therefore be \\ninterpreted as the probability is a neighbor of by ),(1)(1)( ijijij CDFPP ==> (11) where tuv is the cumulative distribution function of pdf(?. \\nThe probability a random node is a nearest neighbor of node i therefore increases with decreasing distance (codensity metrics can also be used). This is represented graphically in Fig 8 for a normally distributed pdf. \\nFig. 7. The lack of an initial mutual constraint can lead to unexpected neighborhood intersection size. Vertices and 9 are mutual neighbors, so \\nthey have one fewer (3) neighbors available from which to form an intersection than node which has four. Fig. 6. Rank-dependent SNN similarity uses k-NN rank information to refine the similarity measure beyond simple counts alone. Notice that , , and 9 all share the same SNN count prior to reweighting despite the \\napparent community structure, whereas weights are more representative of community structure after reweighting. Dotted circles touching the edge of a node denote its 3-NN. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \\n 10 Thus, the probability a randomly drawn node, 9, is closer to \\n than can be determined by simply checking if w? >\\n?9 > w? > ?9. The pdfs for and are naturally different hence w? >\\n? and w? > ? will not be the same. This is similar to the \\ndirected relationships that emerge in k-NN graphs where may be a nearest neighbor of , but may not be a nearest \\nneighbor of . Calculating mutual proximity is conceptually \\nsimple; count the number of nodes, v, having distance > ? to \\nboth and and then divide by the number of nodes to \\nnormalize the probability (12) [28]. Obviously ? = ?. n vv\\nMP",
  "updated_at": "3/7/2009 12:00:00 AM",
  "created_at": "12/20/2001 12:00:00 AM"
}
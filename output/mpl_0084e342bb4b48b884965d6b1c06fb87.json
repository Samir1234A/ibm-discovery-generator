{
  "sdl_source_type": "MPL",
  "productName": "stretcher's Z's",
  "uploadedate": "2015-07-16T00:00:00",
  "productUrl": "http://evidencing.com",
  "creatorNames": "Youssef c Weis;Lokapala s Querencias;Shandra e Laborn;Abdelah w Kalikhov",
  "uploaded": "2015-02-05T00:00:00",
  "sdl_extracted_summary": "(5) Medium (3) Low (1) 1\\nMany/Complex Interfaces Many or complex interfaces Many and/or complex interfaces may need capacity planned more carefully >4 interfaces and/or 1 complex interface >=2-4 system interfaces\\n<2 system interfaces 1 complex interface\\n5 2 High WAN Use\\nSignificant amount of WAN transmission Extensive use of WAN to transmit data may need to be engineered and tested more extensively\\n>155 Mb/sec (OC3) >=52-155 Mb/sec (OC1+)\\n<52 Mb/sec OC1 3 3 Multiple HW Platforms/ Locations Multiple hardware platforms and/or locations Multiple hardware platforms and/or locations may be more complex to manage >2 HW platforms/locations 2 HW platforms/locations 1 HW platform/location\\n2 HW locations 3 4\\nShared Infrastructure\\nShared infrastructure Shared infrastructure may need capacity planned more carefully All components on shared infrastructure Some components on shared infrastructure No components on shared infrastructure\\nnot shared 1 5 Disaster Recovery\\nExtensive disaster recovery Extensive disaster recovery (DR) capabilities may need capacity planned more carefully\\n>=50 GB replicated >=50 GB backed up <50 GB replicated or backed up\\n70 GB backup 3 6 Large User Base Many users Many users may need capacity planned more carefully >200 users >=50-200 users <50 users 20 users 1 7 Workload Stability\\nSignificant workload change Significant workload change may need capacity planned more carefully\\n>25% workload change >=10-25% workload change\\n<10% workload change 5% workload change\\n1 8 Monitoring\\nMonitoring in place/planned Monitoring capabilities implemented/planned, may have stringent performance requirements Performance and error monitoring\\nOnly error monitoring No monitoring no monitoring 1 Performance Operations Criteria and Metrics Definitions Service Metrics System Info Rating # Criteria Name Criteria Definition Criteria Justification High (5) Medium (3) Low (1) 1\\nMany/Complex Interfaces Many or complex interfaces Many and/or complex interfaces may need capacity planned more carefully >4 interfaces and/or 1 complex interface >=2-4 system interfaces\\n<2 system interfaces 1 complex interface\\n5 2 High WAN Use\\nSignificant amount of WAN transmission Extensive use of WAN to transmit data may need to be engineered and tested more extensively\\n>155 Mb/sec (OC3) >=52-155 Mb/sec (OC1+)\\n<52 Mb/sec OC1 3 3 Multiple HW Platforms/ Locations Multiple hardware platforms and/or locations Multiple hardware platforms and/or locations may be more complex to manage >2 HW platforms/locations 2 HW platforms/locations 1 HW platform/location\\n2 HW locations 3 4\\nShared Infrastructure\\nShared infrastructure Shared infrastructure may need capacity planned more carefully All components on shared infrastructure Some components on shared infrastructure No components on shared infrastructure\\nnot shared 1 5 Disaster Recovery\\nExtensive disaster recovery Extensive disaster recovery (DR) capabilities may need capacity planned more carefully\\n>=50 GB replicated >=50 GB backed up <50 GB replicated or backed up\\n70 GB backup 3 6 Customer Facing Many users Many users may need capacity planned more carefully Customer facing Not customer facing\\nnot customer facing\\n1 7 Workload Stability\\nSignificant workload change Significant workload change may need capacity planned more carefully\\n>25% workload change >=10-25% workload change\\n<10% workload change 5% workload change\\n1 8 Monitoring\\nMonitoring in place/planned Monitoring capabilities implemented/planned, may have stringent performance requirements Performance and error monitoring\\nOnly error monitoring No monitoring no monitoring 1 Criteria # Cross-Reference 1 2 3 4 5 6 7 8 System PE Service Many/Complex \\nInterfaces High WAN Use Many Lines of Code Many Performance Reqs Code Not Stable Prior Problem Tickets New System Mainframe Sample System 32 5 3 3 5 3 5 5 3 Criteria # Cross-Reference 1 2 3 4 5 6 7 System CP Service Many/Complex \\nInterfaces High WAN Use Multiple HW Platforms/ Locations Shared Infrastructure Disaster Recovery Large User Base Workload Stability Sample System 17 5 3 3 1 3 1 1 Criteria # Cross-Reference 1 2 3 4 5 6 7 8 System PO Service Many/Complex \\nInterfaces High WAN Use Multiple OS Platforms/ Locations Shared Infrastructure Disaster Recovery Customer Facing Business Critical Monitoring Sample System 13 1 3 2 1 3 1 1 1 Gold Service > 21 Silver Service > 14 Bronze Service > 0 System PE Service CP Service PO Service Sample System 32 17 13 4.3 Activities for Service Levels Detailed activities for each Performance Management area are defined by the spreadsheet based on calculated service levels. Table 4 shows some color-coded activities for PE, along with lead organizations, and associated SDLC artifacts. For the top service level (Gold), all activities are done (color-coded in gold, silver, and bronze). The Silver service level activities are color- coded in silver and bronze. The Bronze service level activities are in bronze. Only the first three SDLC phases are shown. Table 4: Performance Engineering Activities 5. Summary The Performance Management Service Level and Activities Calculator is intended to be used as a first cut at service level definitions and used during the requirements definition process. The spreadsheet criteria and activities can be customized for each organizations priorities. It can also be used as a first step towards an enterprise-wide standard Performance Management program. Since it is often difficult to make this first step, the Service Level and Activities Calculator can provide a simple tool for developing service levels and defining activities to manage to these service levels. Performance Engineering Activities Phase Lead Organization SDLC Artifacts 1 Define Business Need 0 Project Office End-to-End Costing Spreadsheet (E2E) Develop a business case for the system understand the business problem being addressed by the system, identify and meet with stakeholders, define a high level solution E300 Capital Asset Plan and Business Case Summary Coordinate with CP steps 1-2 (convert business needs into initial system capacity estimates for costing and capital asset plan) and PM steps 1-2 (convert business needs into performance management needs) Solution Concept 2 Convert Business Needs to Performance Needs/Standards Engineering Define high level performance metrics for throughput, response time, processing time, and utilization (CPU, memory, storage, network) Incorporate performance metrics into high level solution Coordinate with CP step 1-2 (convert business needs into initial system capacity estimates for the solution concept) 3 Tailor PE Activities for Project Plan 1 Engineering E300 Capital Asset Plan and Business Case \\nSummary (updated) Determine system service type (bronze, silver, gold) via criteria Acquisition Management Plan Define specific PE activities for system based on service type 4 Incorporate PE Activities into Project Plan Project Office Approve PE activities and incorporate into project plan, acquisition plan, and business case Determine PE activities' schedule, including coordination with other Performance Management activities 5 Decompose Requirements into Detailed Performance Requirements 2 Engineering Business System Architecture Report \\n(BSAR) Translate business requirements into performance and capacity requirements, including use cases and assumptions Business System Requirements Report (BSRR) Develop performance & capacity sections of Business System Reports Business System Concept Report (BSCR) Introduction\\n Performance Management Definition\\n Performance Management Areas Development of Performance Management Program\\n Activities and Service Levels\\n Scenarios Service Level and Activities Calculator\\n Criteria, Metrics, System Information, and Service Rating\\n Service Level Calculation\\n Activities for Service Levels Summary \",",
  "sdl_date": "2020-03-23T00:00:00",
  "countryPublished": "Sao Tome & Principe",
  "conference": "mucked profiled ul Saleta",
  "originalAuthorName": "Ladislau q Peerenboom",
  "title": "diplomatic apparels",
  "declaredTags": "SIMEX|hero carousel|CW RF E-field strength",
  "releaseReason": "arrangements/digger",
  "docName": "YD_61_9860",
  "fundingCenter": 29,
  "resourceURL": "https://perfectible.com",
  "fundingDepartment": "fl48",
  "caseNumber": "40-1431",
  "publicationDate": "8/16/2019 12:00:00 AM",
  "releaseYear": 2011,
  "releaseStatement": "Peer-reviewed Publication/Journal",
  "approver": "$Ilinca $Porquer",
  "handCarry": 0,
  "authorDivision": "up19",
  "copyrightOwner": "Dorthe Ruiz",
  "lastModifiedDate": "11/20/2002 12:00:00 AM",
  "releaseDate": "5/25/2010 12:00:00 AM",
  "onMitrePublicSrvr": 0,
  "projectNumber": "4903JGVV86",
  "materialType": "Book",
  "publicationType": "Book",
  "authorCenter": 13,
  "originalAuthorID": "Lynsey",
  "mitrePublicServer": 0,
  "subjectTerminology": "Aviation and Aeronautics (General)",
  "dateEntered": "9/4/2003 12:00:00 AM",
  "documentInfoURL": "https://Menuhin diacritics policed Brent tunic's.com",
  "softShell": 0,
  "publishedOnNonMITREServer": 0,
  "priorCaseNumbers": "CASE2: 17-2450|CASE1: 16-0818",
  "organization": "yp97",
  "authorDepartment": "rc20",
  "publicationYear": 2019,
  "sensitivity": "Public",
  "copyrightText": "(c) 2016 The MITRE Corporation All Rights Reserved",
  "fundingSource": "FAA FFRDC Contracts",
  "level1": "Programs & Technology",
  "fundingDivision": "sleepiness's spew's unmaking providential schusses",
  "publishedOutsideUSA": 0,
  "level3": "ma72",
  "level2": "ii28",
  "sdl_id": "0084e342bb4b48b884965d6b1c06fb87",
  "text": "were also asked\\nwhether the overall activity was effective for evaluating IM during terminal metering. The\\nmajority (8/9; 89%) of controllers agreed (M=81.7; SD=18.3), and the majority (16/17; 94%;\\nmissing=1) of pilots agreed (M=85.8; SD=13.9). Figure 4-78 depicts these results. Figure 4-78. Summary of Controller and Pilot Responses on Simulation Assessment\\nStatements 5-1 5 Discussion 5.1 IM During Terminal Metering\\nTerminal metering was of more interest (from a research perspective) for the controller\\nparticipants, than the pilot participants, because it was new to them. Also, terminal metering\\nwas less of an issue for the flight crews because it was relatively transparent to them because\\nthey conduct IM operations in the same manner in and out of metering environments.\\nTherefore, the flight crew questions and replies are more relevant in consideration of IM\\noperations, while the controller replies cut across the entire environment of terminal metering,\\nRNP RF turns, and IM. Majorities of both controllers and pilots reported IM during terminal metering was\\noperationally desirable and acceptable. A majority of controllers reported IM was compatible\\nwith terminal metering operations (as seen with: Rognin et al., 2005; Callantine et al., 2012;\\nPeterson et al., 2012; Baxley et al., 2016). At times, the IM / relative spacing operation was very\\nsimilar to the behavior of controllers who transition from an absolute spacing operation to a\\nrelative spacing operation in the later stages of approach and landing during terminal metering\\noperations (as seen with: Callantine et al., 2012). Controllers also reported that it was acceptable to receive aircraft from both a (simulated) en\\nroute controller and a (participant) feeder controller. The majority of controllers reported they\\nwere confident both IM and non-IM aircraft would be handed off with minimal problems,\\nthough non-IM aircraft received higher / more positive ratings. Controllers did not appear to\\nhave issues with two different ABPs, nor spacing / separation issues with IM aircraft that were\\nstill in the achieve stage when passing the merge point. Controllers found mixed IM (~60%) and non-IM equipage acceptable. The percentage of IM\\naircraft in this simulation was higher than other work done in the past that also found mixed IM\\nand non-IM equipage to be acceptable (e.g., Callantine et al., 2012). Therefore, this level as well\\nas lower levels such as those seen in early NASA ATD-1 simulations (e.g., 3 aircraft per scenario,\\n10 20%) appear to be acceptable. However, equipage levels higher than 60% appear to be\\nmore desirable based on controller feedback from this simulation. The majority of controllers and pilots reported that roles and responsibilities were clear. The\\nmajority of both groups also reported that overall workload was acceptable, though the pilot\\nresults were more variable. The majority of controllers and pilots reported acceptable traffic\\nawareness, and associated monitoring, for IM and non-IM aircraft. However, though controller\\nresponses were variable, the majority reported that their monitoring increased with IM aircraft.\\nThis may indicate some level of distrust of IM aircraft or a shift from actively controlling to\\nmonitoring aircraft. While IM during terminal metering appears acceptable, a few issues were noted about the\\noverall metering environment with IM and structured arrivals that join the final approach\\ncourse with speeds and altitudes for the flight crew to fly. Controllers noted that this\\nenvironment created a relatively low workload environment and that it could cause controllers 5-2 to act more as monitors and be less engaged. They also reported RNP RF turns as challenging\\nin general based on an aircraft joining the final approach course late in the approach / at the\\nFAF. 5.2 IM Conduct 5.2.1 Controllers\\nOf all the IM clearances proposed by the terminal metering system, 97% were initiated by the\\ncontrollers. Of the 3% rejected, over half were by one controller. The capture then maintain\\nclearances were rejected less often than the achieve-by clearance types, and were initiated\\napproximately 11 seconds faster and earlier in the airspace. This seems likely due to the\\ndifferent geometries of the two clearance types. In the capture then maintain operations,\\naircraft are on the same path (likely easier to visualize) and the clearance information is\\nreduced (likely easier to read and interpret21). Thipphavong et al. (2013) also found controllers\\nwere more likely to initiate IM when the IM trail aircraft and the lead were on the same route\\nas is seen in the capture then maintain clearance type. Less than 1% of IM operations were suspended and of those, less than half were resumed. Over\\nhalf of the suspensions were from one controller. One quarter of the suspensions were due to\\nspacing concerns. Other known reasons were related to increasing efficiency and vectoring the\\nlead. Controller terminations of IM occurred in approximately 4% of the IM operations and the\\nmost frequent reasons were the same as those for suspensions. There were 4% fewer\\nterminations for achieve-by operations and they occurred over 1.5 minutes later in the airspace\\nas compared to capture then maintain operations. Few differences were found between the\\ndifferent controller tool sets. The majority of controllers reported: (1) they were confident both IM and non-IM aircraft\\nwould remain outside their separation requirement, (2) the spacing achieved by IM and non-IM\\naircraft was acceptable, (3) they were able to detect spacing / separation issues developing,\\nand (4) it was clear aircraft were working toward appropriate spacing. However, for all four\\nstatements, non-IM aircraft had more positive ratings and / or lower variability. Additionally,\\nobservations and comments showed controllers did not appear to feel entirely comfortable\\nallowing aircraft to conduct IM, especially when close to the separation standard. Controllers\\nreported some discomfort in not actively managing the aircraft speed and not knowing when\\naircraft would change speeds. Few differences were found for controller actions or replies based on controller role. Overall,\\nIM operations for controllers went well, with almost all clearances issued and initiated, and\\nvery few operations suspended or terminated. However, some level of discomfort in IM\\noperations was observed. Based on reports from controllers, the issue seemed to be related to\\nnot actively issuing speeds to IM aircraft and thus not knowing what speeds would be flown\\nand when. 21 This same situation is possibly seen when comparing the results noted in Bone et al. (2007) and Penhallegon and\\nBone (2008). See Section 2.5.1.2. 5-3 5.2.2 Flight Crew\\nThe achieve-by operations had a rate of 1.5 speeds per minute while capture operations had a\\nrate of approximately two per minute. The majority of pilots reported these rates as acceptable\\nas was the case in past simulations (e.g., Swieringa et al., 2014; Kibler et al., 2015). About 6%\\nfewer IM speed conformance advisories were issued for the achieve stage as compared to the\\nmaintain stage. For the achieve-by stage, IM speeds occurred more frequently the closer the\\naircraft was to the ABP. For the capture stage, IM speeds were fairly evenly distributed across\\nthe entirety of the stage. IM speed reversals (a speed decrease followed by speed increase) can be challenging (i.e.,\\nconfusing and annoying) for flight crews. Speed increases can also be challenging in arrival and\\napproach operations when flight crews normally only decelerate and have to configure the\\naircraft for landing (i.e., deployment of flaps). The observer noted that pilots had issues with IM\\nspeeds that required an acceleration after the aircraft started the configuration for landing. This\\nissue has been noted in other IM activities (e.g., Penhallegon, Bone, and Stassen, 2016b). Only\\n3% of the IM speeds were reversals but 17% of the IM speeds were speed increases. Fewer of\\nboth occurred for the achieve stage as compared to the maintain stage, and most speed\\nreversals occurred later in the operation and when in the final controllers airspace. The majority of the pilots reported that it was clear the IM speeds were driving toward\\nachieving and maintaining the ASG, though responses were variable and the observer noted\\nthat participants had issues with this. Regardless, the majority of pilots reported the spacing\\nachieved / maintained was acceptable and that they were able to detect whether they would\\nremain within tolerances for the ASG. About half the pilots reported trying to out-guess the IM algorithm, though only a few reported\\nchoosing to fly a speed other than the IM speed. As with the controllers, IM operations went well for the flight crews with most clearances being\\nflown and few reports of unable. However, some level of distrust in the IM algorithm\\noperations was observed. Based on reports from pilots, the issue seemed to be related to the\\nquestion of feasibility of the IM operation. 5.3 Aircraft Spacing and Separation\\nIn general, aircraft entered the feeder controllers airspace slightly ahead of schedule on\\naverage (as described in Section 3.1.6). On average, aircraft were also ahead of, but within 3\\nseconds of, schedule at the constraint points of DERVL and RHYAN. Aircraft stayed ahead of\\nschedule at the FAF / YOKXO by approximately 7 seconds (for IM aircraft) and 5 seconds (for\\nnon-IM aircraft). Aircraft were in their slot markers about half time in the feeder controllers airspace but IM\\naircraft were inside for less time (46%) than non-IM aircraft (54%). When aircraft were outside\\nof their slot markers, they were generally ahead of the slot markers (ahead of schedule). At the\\nhandoff from the feeder to final controller, aircraft were on average within 2 seconds of their\\nslot marker centers. Both IM and non-IM aircraft were in the slot markers approximately 18% of\\nthe time in the feeder controllers airspace. Again, when aircraft were out of the slot markers, 5-4 they were generally ahead of the slot markers (ahead of schedule). Wynnyk",
  "updated_at": "3/17/2019 12:00:00 AM",
  "created_at": "7/11/1997 12:00:00 AM"
}
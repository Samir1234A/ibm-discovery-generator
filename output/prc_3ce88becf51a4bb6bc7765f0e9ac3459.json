{
  "sdl_source_type": "PRC",
  "sdl_date": "2020-08-25T00:00:00",
  "countryPublished": "Samoa",
  "conference": "outside Cypriot's vi Mamta",
  "originalAuthorName": "Abelino s Mardi",
  "title": "glads Zamenhof",
  "declaredTags": "airport departure delay|CAMH|consensus|NAS",
  "releaseReason": "suctions/seduction",
  "docName": "TN_43_5152",
  "fundingCenter": 10,
  "resourceURL": "https://blotter's.com",
  "fundingDepartment": "et54",
  "caseNumber": "64-7290",
  "publicationDate": "11/4/2020 12:00:00 AM",
  "releaseYear": 2008,
  "releaseStatement": "Other",
  "approver": "$Adella $Yablunsky",
  "handCarry": 4,
  "authorDivision": "hx29",
  "copyrightOwner": "Xuefang Zhitluhin",
  "lastModifiedDate": "6/14/2013 12:00:00 AM",
  "releaseDate": "3/30/2007 12:00:00 AM",
  "onMitrePublicSrvr": 0,
  "projectNumber": "4338DTJG87",
  "materialType": "Paper",
  "publicationType": "Paper",
  "authorCenter": 87,
  "originalAuthorID": "Snezha",
  "mitrePublicServer": 0,
  "subjectTerminology": "Systems Engineering (General)",
  "dateEntered": "8/10/2002 12:00:00 AM",
  "documentInfoURL": "https://scrabble's tokens Vladimir petitions temptations.com",
  "softShell": 0,
  "publishedOnNonMITREServer": 0,
  "priorCaseNumbers": "CASE1: 14-3139",
  "organization": "vd48",
  "authorDepartment": "it65",
  "publicationYear": 1992,
  "sensitivity": "Public",
  "copyrightText": "(c) 2016 The MITRE Corporation All Rights Reserved",
  "fundingSource": "DHS FFRDC Contracts",
  "level1": "Corporate Ops & Transformation",
  "fundingDivision": "discount lipread hairnet macram√© rattlesnakes",
  "publishedOutsideUSA": 0,
  "level3": "ju21",
  "level2": "dx52",
  "sdl_id": "3ce88becf51a4bb6bc7765f0e9ac3459",
  "text": "    \"text\": \" 1 1. Systems Engineer, Lead\\n2. Group Leader, Operations Research, Principal\\n3. Data Analytics, Sr. \\n4. This paper builds on work initially performed by MITRE in 2013. [1] Evaluating National Airspace System (NAS) Performance in \\nContext Simon H. Heitin1, Wayne W. Cooper2, and Chih-Sheng Chou3 The MITRE Corporation, Mclean, VA, 22102, USA FAA analysts are faced with a problem of scale in knowing where to effectively spend \\ntheir time and effort for post-operations analysis. They seek to identify areas for \\nimprovement where performance is consistently below what is expected, and potential best \\npractices where performance is consistently above what is expected. However, defining \\nperformance expectations is challenging because performance metrics are very sensitive to \\ncertain factors that are outside of the FAAs control (i.e., weather and demand). This study \\nseeks to provide a statistical model for defining performance expectations that account for \\nexogenous factors. It further defines statistical tests for detecting when performance \\nexpectations are being consistently violated. The results could be deployed in automation to \\nhelp FAA analysts detect performance issues quickly so that they can direct resources for \\nin-depth analysis and solution development. Problem StatementI. \\nThe Federal Aviation Administration (FAA) monitors National Airspace System (NAS) performance using a variety \\nof metrics including airport departure delay, taxi-out time, and on-time performance. These metrics are published in \\nAviation System Performance Metrics (ASPM) daily reports. FAA managers routinely use these reports to answer \\nthree related questions: 1. Was performance at an airport on a specific day in line with conditions in the NAS on that day? \\n2. Has performance at an airport changed over time?\\n3. Did FAA Traffic Flow Management (TFM) actions on a specific day reduce the impact of system constraints? (E.g., did restrictions imposed on individual airport operations improve overall NAS system \\nperformance?) This paper proposes a systematic approach for answering the first two questions4.[1] Obtaining meaningful \\nanswers to these will, in turn, isolate specific areas of the NAS to which the third question should be focused to \\nefficiently obtain an operationally meaningful answer. Airport performance on an individual day may be driven largely by that days weather or demand. The same is \\ntrue for performance over months, seasons or years. Consequently, a direct comparison of current performance \\nmetrics between a recent month and the corresponding month in another year may not meaningfully identify the \\ntrend in performance. For example, the impact of weather in the most recent June may be significantly more severe \\nthan that of the previous years June. Unless the metrics being used for the comparison account for this difference, \\nthe resulting trend may largely be driven this weather input factor. A performance metric which explicitly accounts \\nfor the impact of weather would enable a more meaningful comparison. More generally, current airport performance metrics fail to enable FAA managers to efficiently monitor airport \\nperformance due to their failure to account for system conditions. System conditions include all factors that affect the \\nbalance between flight demand and system capacity. These factors include: (1) forecasted weather (2) actual weather, 2 and (3) filed flight plans. Forecasted weather is the basis of the system capacity used by FAA managers to determine \\nmost TFM actions, as these decisions must be made well in advance of a predicted problem. Actual weather \\ndetermines the maximum system capacity that was ultimately achievable during operations. Filed flight plans are the \\nbasis for determining the demand experienced during operations. These three factors are largely outside FAA control \\nand are referred to in this study as exogenous factors. This study is limited to the second and third factors (actual \\nweather and filed flight demand) but may be expanded in the future to include the first factor (forecasted weather). While current airport performance metrics include weather factors along with performance metrics, the \\nrelationship between the two must be calculated by the analyst. For example, a severe thunderstorm may impact \\nstandard arrival routes one hundred (100) nautical miles from an airport. An analyst may correctly determine that \\nflight times for arrivals to that airport should increase due to the use of longer than normal routes to avoid these \\nstorms. However, the analyst has no formal, repeatable method for estimating the magnitude of the increase in flight \\ntimes attributable to the weather based on its severity. In addition, failure to incorporate the effect of weather in \\ncalculating the metric means that automation cannot be fully utilized to identify locations and times justifying the \\nexpenditure of limited analysis resources. The FAA actively monitors at least ten (10) metrics at the thirty (30) Core \\nairports. This means that hundreds of performance metrics of potential interest to management can be monitored \\ncontinuously for anomalies. The scale of this problem makes it difficult to systematically identify trends without \\nautomation. Currently, a subjective decision must be made regarding which events/airports should be investigated \\nmore closely by allocating limited analysis resources. The proposed process seeks to inform this decision reliably in \\na way that may be implemented in automation. The goal of this study is to develop an automated process to inform the FAAs decision of how best to deploy \\nlimited resources for post-operations analysis. It seeks to do this by providing a statistical methodology that identifies \\nevents (time-periods and locations) where specific FAA performance metrics differed from what would be expected \\nwhen accounting for the weather and demand. These anomalous events would be candidates for a further intensive \\nand more detailed analysis to identify root causes. The results of these more targeted intensive analyses can be used \\nto inform both future procedural improvements and identify best practices for TFM. AssumptionsII. \\nDaily performance at a given airport is statistically independent of exogenous conditions on other days: normally, A. \\nchanges to flight operations such as delays and cancellations are resolved by the end of the operational day, so \\nthat normal operations can resume the following day, even after severe weather or high traffic volume. This is \\nnot always the case: hurricanes and major snow events can disrupt normal operations for more than one day, but \\nthese events are unusual. \\nThe exogenous factors of demand and weather dominate the other factors under the control of the FAA. These B. \\nfactors explain most of the statistical variation in the KPI, and as such provide a reasonable estimate of the \\nnormal range of behavior when looking at the distribution of the regression model residual errors. The goal, \\ndescribed later in this paper, of reaching a model R2 of 50% or more is one way of ensuring that this assumption \\nis reasonable.\\nVariation in a daily value for a performance metric can be represented as a linear function of the exogenous C. \\nfactors that are used to describe it. This assumption allows the well-defined and understood statistical approach of \\nlinear regression modeling to be used. [2] \\nLong-term trends in relative system performance are measured with respect to a specific historical baseline D. \\nperiod. The choice of this baseline period will affect results. If performance in baseline period #1 is better than in \\nbaseline period #2, the relative performance of a more recent period may be different when measured against a \\nmodel developed for period #1 than period #2. The analysis approach evaluates performance by airport and by day. The daily level of granularity was chosen \\nfor analysis because operational days are generally independent (see assumption A above). At the beginning of the \\nday, airlines and other users usually have their airframes in the correct location to achieve their planned schedule. As \\nthe day progresses, there may be unforeseen disruptions, but there is generally enough time after the afternoon \\ndemand peak to sort out the effects of those disruptions. Evaluation within a day would be a more challenging question because it would require accounting for the time- 3 5. The KPIs and names were developed for this paper and do not map directly to ASPM performance metrics. lag effect of weather and demand on each performance metric. It is expected that the chosen, daily level of \\ngranularity is sufficient for informing the decision of where to deploy further analysis resources. Data SourcesIII. \\nKey Performance indexes (KPIs) and exogenous factors were calculated using several FAA data sources. These data are stored in the following tables:\\nIndividual ASPM flights [3]: This table records detailed flight attributes from ASPM, including:A. \\n1) Origin and destination airport (O-D),\\n2) Actual Out, Off, On, In (OOOI) event times (i.e., airport gate departure (Out), airport runway departure (Off), airport runway arrival (On) and airport gate arrival (In), \\n3) Air carrier scheduled Out and In times, and \\n4) Nominal taxi out and taxi-in times. Individual Traffic Flow Management System (TFMS) flights: This table records actual airborne time as well as B. \\nthe flight track distance (MITRE-calculated) from origin to destination. The track distance is calculated as the \\ndistance between each radar track location update (TZ message) for that flight in TFMS.\\nASPM airport quarter-hour metrics [4]: this table collects quarter-hourly values of:C. The number of flights that intend to arrive/depart (ARRDEMAND, DEPDEMAND), 1) \\n2) The counts of actual arrival",
  "updated_at": "3/16/2015 12:00:00 AM",
  "created_at": "4/29/1999 12:00:00 AM"
}
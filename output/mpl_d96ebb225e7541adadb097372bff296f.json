{
  "sdl_source_type": "MPL",
  "productName": "accrual stabilized",
  "uploadedate": "2014-07-28T00:00:00",
  "productUrl": "http://maria.com",
  "creatorNames": "Contacto y Norton;Albrecht n Hurtaran",
  "uploaded": "2010-02-13T00:00:00",
  "sdl_extracted_summary": "and logic errors following manual modification. Validation of the changes is performed by American Institute of Aeronautics and Astronautics 6 loading the newly updated adaptation into the Plan-View Graphical User Interface (PGUI) and the Timeline Graphical \\nUser Interface (TGUI) and overlaying live traffic, which represents how the adaptation will be viewed by the TMCs \\nwhen using the operational TBFM system. Following this validation, the changes are reviewed to ensure impacts to \\nadjacent facilities and other potential operational issues are considered prior to implementation. When changing TBFM adaptation for a new or modified PBN procedure design, nominal interior routes are defined \\nfor each runway configuration and aircraft type. These routes consist of a lateral path, as well as speed and altitude \\nrestrictions based on published STARS, published approaches, and SOPs for the facility. The accurate definition of \\nthese nominal interior routes is critical to enabling the TBFM system to produce Estimated Time of Arrival (ETAs) \\nand Scheduled Time of Arrival (STAs) that are realistic and aligned with the anticipated traffic loads for the airport. \\nWhile some upcoming capabilities (e.g., TSAS) will provide improved definitions of interior routes as well as PBN \\nroutes, not all routes that are currently published will fully address all discontinuities that currently exist between \\nSTARs and IAPs. This will require TBFM adaptation designers to address these discontinuities based on making \\ninformed data driven decisions. III. Integrated Design Capability Needs Analysis \\nFollowing the survey of current processes and tools for conducting PBN and TBFM adaptation design, the research consisted of a needs analysis to help derive the requirements for the envisioned integrated procedure design and arrival \\nmanagement DST adaptation design and evaluation tool, referred to as the integrated design capability from here \\non. Since the operational deployment of TBFM, many PBN projects have needed to consider TBFM adaptation \\nparameters and configurations to ensure interoperability gaps are not present. However, the existing process for PBN \\ndesign and implementation does not explicitly account for adapting the PBN designs in TBFM adaptation. \\nAdditionally, TBFM can often be considered late in the procedure implementation process and result in rework to \\nensure compatibility with the sites TBFM adaptation and that desired benefits are being realized. The groups \\nexecuting this work today are not ignoring the interdependence of these two key concepts, but the lack of defined \\nprocesses introduces the risk of inconsistent methods and inefficiency on the path to achieving the desired operational \\nbenefits. This highlights a need for a standardized integrated PBN and TBFM design process (refer to Figure 3) to \\nhelp ensure that the goals of NextGen and the PBN NAS strategy can be realized. \\nFigure 3. Current and Desired PBN and DST Design Process In addition to the process shortfalls discussed above, the Needs Analysis focused on the current tools used to \\nperform PBN and TBFM design. One identified tool shortfall is that limited capabilities exist for assessing PBN and \\nTBFM performance during design activities. The primary method currently used to assess the performance of PBN \\nand TBFM operations prior to implementation is conducting HITL simulations. HITL simulations help validate the \\noperational acceptance of new procedures by including stakeholders, such as air traffic controllers and TMCs, in the \\nevaluations while also helping validate the successful integration of these procedures into the TBFM site adaptation. \\nHowever, conducting HITL simulations is a complex, resource intensive activity that may not be feasible for every \\nintegrated design activity being conducted. When HITL simulations are not feasible, there is a gap in the existing \\ncapabilities to assess the performance of PBN and TBFM operations. American Institute of Aeronautics and Astronautics 7 In design projects where HITL simulations are utilized, projects may still benefit from upfront PBN and TBFM \\ndesign analyses to help identify a set of most promising candidate designs to model during HITL simulations. \\nExamples of PBN and TBFM analyses that would benefit from integrated design include methods of quantifying delay \\nand identifying problematic areas in TBFM site adaptation, iterative analysis where arrival rates and delay distribution \\nparameters are adjusted to better achieve performance objectives, and assessing common PBN flight efficiency \\nmeasures, such as optimized profile descent (OPD) compliance, level-offs, and fuel burn when TBFM is being used. \\nPresently, these types of analyses are performed using data collected from HITL simulations or during post-\\nimplementation analysis to evaluate the success of the development and implementation activities. Having greater \\ninsight into how the new operations would perform earlier in the design process may help improve the final designs \\nand save time and rework compared to the current processes being employed. Another shortfall observed is that the TBFM adaptation can be complex and cumbersome to work with. This \\nchallenge is largely attributed to the structure of the adaptation and that many changes require the modification of \\nmore than one file, increasing the likelihood for human error. Additionally, it can be difficult to interpret the contents \\nof site adaptation as the PGUI and TGUI displays are the only methods of visualizing this data. Adaptation details \\nregarding different site configurations and underlying scheduling parameters are not easily accessible using current \\nmethods, requiring designers to retrieve this information from the adaptation files themselves. The combination of a \\ncomplex structure and limited tools for visualization requires designers to employ an iterative process that can be error \\nprone and resource intensive. IV. Concept for an Integrated Design Capability \\nThe Integrated Design Capability is a software system intended for users supporting PBN and TBFM development and implementation activities for the FAA. A needs analysis has shown that current processes and tools are not \\nsufficient to support integrated PBN and TBFM design. The intended user groups for the system are responsible for \\nsuccessfully implementing operational changes to achieve desired performance benefits at sites throughout the NAS. \\nThe concept of integrating PBN and TBFM design elements is emerging and, therefore; a new system is envisioned \\nto satisfy the evolving needs and applications. The envisioned system will be capable of ingesting TBFM adaptation data and depicting geo-referenced adaptation \\nelements and the underlying data parameters to the user. The system will also support access and visualization of \\nnavigation data sources, as well as, PBN data elements sufficient to model operational scenarios throughout the NAS. \\nThe combination of the TBFM adaptation and PBN navigation data within a single system will enable integrated \\ndesign applications (refer to Figure 4). With PBN and TBFM data available to the system, scenario generation capabilities will support a variety of \\nmodeling functions. Users will generate operational scenarios to help explore the performance of proposed PBN and \\nTBFM designs. Given a scenario, TBFM scheduling algorithms will be used to provide insight into how the \\noperational TBFM system will respond to the modeled traffic. A schedule will produce ETAs and STAs for each flight \\nat key points within the TBFM adaptation and designed route structures. These times will enable the computation of \\ndemand and delay-based metrics to provide insight into how TBFM may perform under the modeled configuration \\nand traffic scenario. \\nFigure 4. Integrated PBN & DST Design Concept The envisioned systems capabilities will support a broad set of applications for the users supporting PBN and \\nTBFM development and implementation activities. The system may be used to perform pre-implementation analysis American Institute of Aeronautics and Astronautics 8 by analyzing the current TBFM and PBN infrastructure at a site and evaluating scenarios using historical traffic \\ninformation to identify areas for improvement. Once a design project is undertaken, the system will support iterative \\ndesign and analysis to help achieve desired performance measures. The result of iterative design activities will inform \\nthe scenarios and configurations evaluated during HITL simulations, which will further refine the designs for review \\nand potential buy-in from stakeholders. Lastly, the system will support post-implementation analysis where simulated \\ntraffic along the newly implemented procedures and site adaptation are compared against the desired operational \\noutcomes envisioned during the design phase. V. Integrated Time Based Metering Design Capability \\nOptimization of aircraft arrival schedules has been the subject of numerous studies in the past, however, there is no comprehensive analysis tool that accounts for both the design of the airspace procedures as well as the arrival \\nmanagement scheduling logic. The research and resulting capability presented as part of this work aims to provide a \\nmeans for performing both airspace procedure design as well as account for the arrival management (i.e., TBFM) \\ndesign as part of an integrated, lightweight design environment. To accomplish this goal, a set of initial design \\nrequirements has been identified. These requirements were based on information collected during a study of current \\nprocesses and tools used to conduct procedure development, TBFM adaptation development, and the results of the \\nneeds analysis. The requirements are meant to address the shortfalls observed in that study and to help realize the \\nenvisioned system described in the preliminary Concept of Operations (Section IV). The requirements were then used \\nto inform the software design and were organized into the following areas: Adaptation Visualization & Modification \\nThe adaptation visualization requirements focus on the key areas identified in the needs analysis related to",
  "sdl_date": "2020-10-31T00:00:00",
  "countryPublished": "Ecuador",
  "conference": "rockier celibate vy Ivane",
  "originalAuthorName": "Isidor w Oyonarte",
  "title": "needle Forest's convulsions",
  "declaredTags": "simulation experiment|Human Language Technology|ADS-B antenna",
  "releaseReason": "heartwarming/robuster",
  "docName": "LO_32_3432",
  "fundingCenter": 80,
  "resourceURL": "https://granule's.com",
  "fundingDepartment": "jp76",
  "caseNumber": "23-3785",
  "publicationDate": "12/11/2019 12:00:00 AM",
  "releaseYear": 2012,
  "releaseStatement": "Peer-reviewed Publication/Journal",
  "approver": "$Kyara $Timkaev",
  "handCarry": 1,
  "authorDivision": "ln88",
  "copyrightOwner": "Servita Meischner",
  "lastModifiedDate": "2/8/2005 12:00:00 AM",
  "releaseDate": "5/29/2001 12:00:00 AM",
  "onMitrePublicSrvr": 0,
  "projectNumber": "9002QJHO84",
  "materialType": "Article",
  "publicationType": "Article",
  "authorCenter": 22,
  "originalAuthorID": "Guobin",
  "mitrePublicServer": 0,
  "subjectTerminology": "Network Architectures",
  "dateEntered": "9/8/2006 12:00:00 AM",
  "documentInfoURL": "https://languors Galahad megachurch suspended brochure's.com",
  "softShell": 0,
  "publishedOnNonMITREServer": 0,
  "priorCaseNumbers": "CASE3  17-2945|CASE1: 16-4753|CASE3  17-2945|CASE1: 15-3140",
  "organization": "mx88",
  "authorDepartment": "mq62",
  "publicationYear": 1991,
  "sensitivity": "Public",
  "copyrightText": "(c) 2016 The MITRE Corporation All Rights Reserved",
  "fundingSource": "DHS FFRDC Contracts",
  "level1": "MITRE Public Sector",
  "fundingDivision": "crumple phonologists lands Gloria's throbs",
  "publishedOutsideUSA": 0,
  "level3": "pn74",
  "level2": "bw13",
  "sdl_id": "d96ebb225e7541adadb097372bff296f",
  "text": "    \"text\": \" UP JORS software Latex paper template version 0.1 Software paper for submission to the Journal of Open Research Software To complete this template, please replace the blue text with your own. The paper has three main sections: (1) Overview; (2) Availability; (3) Reuse potential. Please submit the completed paper to: editor.jors@ubiquitypress.com (1) Overview Title Transplant2Mongo: A Python module to manage and store Organ Procurement and Transplantation Network (OPTN) data in MongoDB 1 Paper Authors 1. Harvey, Christine 2. Weigel, Robert PhD Paper Author Roles and Affiliations 1. Lead High Performance and Analytical Computing Engineer, The MITRE Cor- poration and PhD Student, George Mason University 2. Professor, George Mason University Abstract The transplant2mongo Python module allows users to transform Standard Trans- plant Analysis and Research (STAR) data files from the Organ Procurement and Transplantation Network (OPTN) into a MongoDB schema [1,2] . The STAR data are a collection of tab-separated files with inter-related records that is not designed for complex query. Any researcher planning to use data from an OPTN STAR files can use transplant2mongo to convert the information into a MongoDB docu- ment for analysis using open-source tools. The source code for transplant2mongo is available on GitHub at https://github.com/ceharvs/transplant2mongo and includes sample data files for initial testing and data query. Keywords Python; OPTN; UNOS; organ transplant; health care; analysis; MongoDB Introduction The Organ Procurement and Transplantation Network (OPTN) keeps a record of all organ donations, transplants, and waiting list registrations since 1987 in the United States [1]. This complex data set can be used to review, query, and ana- lyze the US organ donation system over time and across various factors. The total 1Approved for Public Release; Distribution Unlimited. Case Number 18-0298. c MITRE Corporation is provided for identification purposes only and is not intended to convey or imply MITREs concurrence with, or support for, the positions, opinions, or viewpoints expressed by the author. https://github.com/ceharvs/transplant2mongo UP JORS software Latex paper template version 0.1 database is around 9GB and contains records on hundreds of thousands of donors and over a million patients [2]. The transplant2mongo software translates data from OPTN Standard Transplant Analysis and Research (STAR) files into a Mon- goDB database. OTPN STAR files are designed to be analyzed and processed in either SPSS or SAS, according to the OPTN [2], which are both proprietary tools. This software was developed to allow researchers to use open-source software to manage the dataset and perform an analysis. transplant2mongo transforms the raw tab-separated value (TSV) STAR files into documents stored in a MongoDB database. Translating the data allows any user without specialized software to ex- plore and perform analysis on this complex and interconnected dataset. Due to the sensitive nature of STAR file data, the development of these tools was completed in a secure lab environment at The MITRE Corporation and the code repository does not include any STAR files. Using Python to complete the data transformation and MongoDB as a final repository for the data allows users to make use of only open-source tools. Python and the included modules read in the data from the STAR TSV files and convert it to MongoDB documents . Special consid- eration was made to process the data and remove erroneous symbols and characters that are not compatible with MongoDB. The resulting MongoDB has been used to perform analysis of the OPTN dataset and the results of the analysis will be considered in a future publication. Implementation and architecture This software was developed on a CentOS machine using Python 2.7 and MongoDB 2.6 in a secure lab environment, suitable for the sensitive data files. This tool was developed and tested using OPTN STAR file data from June 2014 and March 2015. The general file configuration of OPTN STAR files can be seen in Figure 1. Users of this tool may not have the complete UNOS STAR files, and may only have certain subsets of this information. In this case, the Makefile can be edited so that only a subset of the STAR files are processed. As shown in Figure 1, the TSV files are all stored in the highlighted, Delimited Text Files folder. All data processed with the tool should be contained in this folder. This folder contains a sub-folder for each of the data types: Deceased Donor, Intestine, Kidney Pancreas Kidney-Pancreas, Liver, Living Donor, and Thoracic. The Kidney Pancreas Kidney-Pancreas sub-folder contains in- formation on all patients and transplant recipients for kidney and pancreas, and combined kidney/pancreas transplants. The Thoracic folder includes data on both heart and lung transplant patients. The deceased donor and living donor fold- ers contain details on all organ donors, while the other folders provide data on all patients registered to the waiting list and those who received a transplant. Each of these major groups are represented as collections in the database with the patient or donor information as documents and the sub-folders as sub-documents. UP JORS software Latex paper template version 0.1 Figure 1: Structure of the OPTN STAR files. MongoDB was chosen as the database due to the NoSQL format, allowing multiple patient fields to be combined into a single document with multiple sub-documents. Many of the fields have changed over the years and many of the patient fields are missing information, making this data suitable for NoSQL storage. Alternatively, a SQL database system could be used. With a structured database implementation the number of columns would be very large and there would be many NULL fields in the database. A Makefile is used to build the database from the contents of the Delimited Text Files folder. The Makefile has targets for cleaning, processing, and importing the data into a specified MongoDB database. A linked directory using a symbolic link is used to avoid unnecessary parsing of spaces in the file names. Users need to specify their database location and name in the Makefile before execution. The default interface is localhost and database name is organ data. Users also need to define their components, which specifies the STAR files that the researcher has access to from UNOS. These values are selected from the following list: deceased, living, intestine, kidpan, liver, and thoracic. Data are copied from the original location and file structures are flattened to establish a simple structure for parsing. UP JORS software Latex paper template version 0.1 Once the data is in place, another Python script is run to generate JSON and add the documents into a MongoDB database. For the base files, the main donor or organ data files, the add patients.py script is run to generate major documents in the appropriate tables. For files that contain sub-document information such as follow-up visits or medications, the supplemental data.py script adds this infor- mation as a sub-document to the main patient or donor document. This script uses a unique identifier, such as DONOR ID, TRR ID CODE, or WL ID CODE, to match the supplemental data file entry with a unique record for the donor or organ type. Once a match is found, the supplemental data is added to the document in the database. The TSV files, having the extension .DAT, only contain data and do not include column names, therefore columns are determined by the .htm files corresponding to each .DAT files. Data are cleaned before insertion into the database. The cleaning process is han- dled in the Python scripts add patients.py and supplemental data.py, which use the clean string function. These scripts remove extraneous values such as extra commas, quotations, and new lines. The scripts also create Python datetime objects from potential date strings and convert strings to integers when possible. The scripts do not assume a particular data type for any column. The database contains many different columns and the typing is automatically determined by Python and MongoDB. All data is originally imported as a string. The Python scripts check if the data is a date or an integer, and if not, the data are kept as strings. Following execution of each of the import scripts, follow-up scripts are run to add age bins to all age fields of the data for fast and simple aggregation of the data. Quality control The scripts have been tested on two distinct UNOS STAR file data sets from 2014 and 2015. Each script prints out the number of lines in the file and then the number of patient documents successfully imported into the database. With the two testing sets, the line count results match the imported entry counts in all scenarios with the exception of a particular data file where a new line is hidden with quotation marks and the reported file length is one more than the imported record count. The data were manually confirmed in this situation and manual spot checks of all the data were performed. The Github repository includes sample data that can be used for testing the instal- lation. These data contain no real patient information and were generated by the developers of the software. The",
  "updated_at": "3/10/1997 12:00:00 AM",
  "created_at": "1/26/1997 12:00:00 AM"
}
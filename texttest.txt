    "text": " Approved for Public Release; Distribution Unlimited. Case Number 16-4179. Information Flow, Distributed Systems, and Refinement, by Example Joshua D. Guttman The MITRE Corporation and Worcester Polytechnic Institute 1 Introduction Non-interference is one of the foundational notions of security stretching back to Goguen and Meseguer [3]. Roughly, a set of activities C is non-interfering with a set D if any possible behavior at D is compatible with anything that could have occurred at C. One also speaks of no information flow from C to D in this case. Many hands further developed the idea and its variants (e.g. [15,12]), which also flourished within the process calculus context [6,13,1,2]. A. W. Roscoe con- tributed a characteristically distinctive idea to this discussion, in collaboration with J. Woodcock and L. Wulf. The idea was that a system is secure for flow from C to D when, after hiding behaviors at the source C, the destination D experiences the system as deterministic [8,11]. In the CSP tradition, a process is deterministic if, after engaging in a sequence t of events, it can refuse an event a, then it always refuses the event a after engaging in t [9]. One advantage of this approach via determinism is that it disposed of the so-called refinement paradox of non-interference (for which C. Morgan [7] cites J. Jacob [6], who does not use the term). Namely, a system might display non- interference, but refine to a system that caused impermissible information flows. Refinement does not preserve ignorance, in Morgans words. However, if the system is already deterministic to the destination, no refinement can provide the destination with information about the behavior of the source. Unfortunately, non-interference is too strong a property to be desirable except rarely. One rarely would design a system that has the activities C,D when C should not interfere with D in any way at all. One would instead like to design systems in which there are at least clear limitations on how that interference may occur. For instance, perhaps there is a responsible intermediary M such that C may influence M and M may then decide what information to make visible to the destination D. Thus, writing may influence directly as ;, we have C ;M ; D, although C ; D. In this case, the may-influence relation is not transitive. One may view this intransitive non-interference as a kind of declassification, one in which the permissible intermediaries are trusted to decide what information may reach the destination. From this point of view, it is a kind of who declassification, in which the policy identifies which domains M are permitted to choose what information to allow to pass from C to D [14]. A second advantage of Roscoes determinism idea turned out to be its sur- prising and attractive applicability to intransitive non-interference, developed This technical data was produced for the U.S. Government under Contract. No. W15P7T-13-C-A802, and is subject to the Rights in Technical Data-Noncommercial Items clause at DFARS (FEB 2012) c with M. Goldsmith [10]. Non-interference given an intransitive may-influence relation meant that, hiding the behavior of the sensitive source C, and fixing the behavior of the permissible intermediary M , the destination D again experiences the system as deterministic. However, suppose we have explicit specifications of what we would like to permit D to learn about C? For instance, the buyer should be able to learn what the president had for breakfast, so as to replenish the larder, but not who she vetted for the court opening. This is called what declassification, since the content determines what D may learn and what not. The determinism point of view does not seem to provide an explanation of what declassification, which would be attractive. We think it also attractive to recast the notions in a context that makes the graph structure of distributed systems explicit, and allows us to use the graph structure as a guide to information flow properties [4]. In this paper, we aim to explain, largely by example, three aspects of information flow in distributed systems that are governed by what declassification policies: 1. How to define policies bounding what declassification, i.e. upper bounds on information flow, and also functionality goals expressed as lower bounds on information flow; 2. How to represent distributed systems as directed graphs in which the nodes are processing elements and the arcs are message channels, in which these policies are meaningful; 3. How to ensure that these conclusions are preserved when a system is refined using a surprisingly simple but still useful principle. Functionality goals as lower bounds on information flow are new in this paper, as is the simple refinement principle. 2 An Example System We will consider a system EpiDB with very simple, but nevertheless useful, behavior. We do not focus on the realism of EpiDB, as we will use it simply to stimulate intuition for the information flow considerations at hand. EpiDB is suggested by a related unpublished demonstration system written by two colleagues. 2.1 The EpiDB idea EpiDB serves as a database for epidemiological information. Imagine that health- care providers deposit two kinds of records into the system. First, we have a table of disease records, that say of a particular person that they had a particular disease during a period of time. Second, we have a table of personal encounter records, that say of an unordered pair of people that they had an encounter on a particular date, or that they encounter each other habitually, possibly because they belong to the same family or school class. EpiDB will be used by public health analysts who seek to understand the propagation of diseases through this population. Thus, an analyst A asks a query about a person p1, a disease d, and a time t0. If that query is permitted from A, and p1 had the disease d at a time t1 near t0, then the system will return a set of tuples pp2, e2, t2q such that p2 encountered p1 at time e2, and had disease d at time t2, where e2 and t2 are near t0. For simplicity, we will choose a parameter , and take -near to mean that |t1 t| . Thus, the query takes a sort of join on the two tables, containing the disease and personal encounter records, restricted to times near t0. If the query is permitted from A but p1 did not have the disease d near t0, it returns a distinctive value unsick denying the diagnosis. If the query is impermissible from A, it returns a distinctive value imperm denying permission. Perhaps some analysts are responsible only for certain diseases, and if they start querying for sexually transmitted diseases instead of influenza (e.g.), they are letting their curiosity get the better of them. Alternatively, some analysts may be authorized to ask about some patients but not others, or some time periods. In this example system, we will assume that permission is independent of the contents of the database, and does not change as it operates. If the databases state consists of the tables of disease records with con- tents T d and personal encounter records with contents T e, then we will write anspA, q, T d, T eq for the result when query q pp1, d, t0q is received on c, where: anspc, q, T d, T eq $ & % unsick if not sick -near t0\nimperm if not permitted tpp2, e2, t2q : Dt1 . pp1, d, t1q P T\nd, pp2, d, t2q P T d, ptp1, p2u, e2q P T\ne, and t1, t2, e2 are -near t0u To simplify the statement of information flow upper and lower bounds, we will assume one type of coordination between the analysts and the data provider. Namely, we will assume that the data provider remains up-to-date, while the analysts are not concerned with very recent events. Thus, we will assume that if an analyst ever makes a query q about a time t, and a provider ever deposits a record r concerning a related time t1 t ` 2, then in fact the system received r before q. As a consequence, no query ever has a result that would have been altered by records received subsequently. In particular, the analyst can never detect the order of arrival of records by a sequence of queries. 2.2 Simplest EpiDB system Thus, the simplest version of our system EpiDB takes the form shown in Fig. 1, in which a provider PR delivers data into the database E itself, which can be queried by an analyst A1. We assume that E starts empty, so that its contents at any time is just what PR has delivered over channel 3. We regard the whole graph as the system, rather than simply the node E, partly because in subsequent steps there are additional nodes, but also because Analyst DB Provider A1 1\n**\nE 2 kk PR\n3oo Fig. 1. Schematic System EpiDB the security and functionality goals
of the system are about A1 and PR. In particular, A1 is authorized to learn certain aspects of the behavior of PR. A1\ncan learn which records PR has submitted that are relevant to a permissible query. If PR submits records that are not related to any permissible query of A1, then EpiDB is obliged to ensure that they can have no effect on what A1\nobserves on channels 1, 2. We do not need to specify the behavior of A1 and PR, since the goals should hold regardless of their actions. Thus, we regard them as always willing to send or receive any message on their outgoing or incoming channels. By contrast, E has a specification. We can describe it as a state machine where the state includes two sets of tuples, representing the tables T d, T e. An additional state component records the not-yet-processed query pp1, d, t0q or else K if every query has already received a response. A new record rd, re may be deposited at any moment, even between receiving a query and answering it, so this state component remembers any as-yet unanswered query. We do, however, maintain the upper bound t of the times mentioned in all queries we have re- ceived; we refuse to receive a new record whose time does not exceed t` 2. We record this maximum query time in the state component m, and we require that when a record r is received, its time is greater than m` 2. We write timepqq or timeprq for the last component of q, r, which is its time component. We give the labeled transition relation in Fig. 2. Notice that E does not accept a new query until it has answered the previous one, and restored K to the first state component. Also, channel 2 carries a set of records pp2, e2, t2q, or else a symbol unsick , imperm. 2.3 The intended information flow EpiDB is intended to limit information flow from the provider PR to the analyst A1. In particular, the access control system is intended to limit flow to infor- mation for which A1 is authorized. The remainder of the system is intended to maximize flow subject to authorization, and relevance to the queries A1 asks. For definiteness, we will assume that each analyst A has been assigned: personspAq: A set of persons of interest for A; diseasespAq: A set of diseases A is authorized to consider; startpAq: an earliest time about which to query; and finishpAq: a most recent time about which to query. Pre-State Label (channel, message) Post-State pK, T d, T e, mq p1, qq pq, T d, T e, m1q pq, T d, T e, mq p2, aq pK, T d, T e, mq px, T d, T e, mq p3, rdq px, T\nd\nY trdu, T e, mq px, T d, T e, mq p3, req px, T\nd, T e Y treu, mq where a anspA1, q, T\nd, T eq, m1 maxpm, timepqqq q is a non-K query, x is any value, and rd, re are respectively a disease record and an encounter record, with timeprdq, timepreq m` 2 Fig. 2. Labeled transition relation for E Since A will be able to learn about disease records within of the time t0 in a query, we will write IntpAq rstartpAq, finishpAq`s to define the the interval of disease records A is authorized to learn about. The analyst A who queries p, d, t will learn whether p had disease d at time t1 near t, as long as p P personspAq, d P diseasespAq, and t1 P IntpAq. Or more precisely, A learns whether PR has registered this fact in the relevant portion of its run. The set of permissible queries creates a region R0 of the space of disease records that A can learn about directly. The relevant portion of PRs run also contains a set of encounter records of the form ptp, p1u, eq, and these records create an adjacency relation between records rd P R0 and other disease records involving p\n1, d, and a nearby time t1. We will refer to the set of disease records adjacent to R0 as R1. Essentially, the authorization mechanism entails that A should learn nothing about what disease records and encounter records PR has submitted, except as they help to determine R0 and R1. In particular, PR messages that provide encounter records not connected to R0 should be invisible to A. Moreover, given a set of encounter records, PR messages that provide disease records not in R0\nor R1 are also invisible. In particular, As observations as a consequence of a single query must re- main unchanged, regardless of variation in PRs messages containing encounter records unconnected to R0 and regardless of variation in disease records not in R0 YR1. A query imposes no ordering requirement on PRs messages. By submitting a sequence of queries, A can learn conjunctions of the con- clusions returned by the individual queries. But by the timing constraints, A cannot exclude any particular order in which the records may have arrived. In particular, a record can have been absent from an earlier response if it is found in a later response. Thus, the purpose of the EpiDB system is essentially a what-declassification, where the regions R0, R1 for each permissible query q determine what aspects of the sensitive PR runs should be declassified and made available to the analyst A asking q. LO, CH,DA,ST , EV sndr : CH LO rcpt : CH LO chan : EV CH msg : EV DA lts : LO lts Table 1. Signature of frames Later (Section 5) we will refine the schematic version of EpiDB from Figs. 1 2 into a more complex system with separate components that guide an efficient and reliable implementation. 3 Information Flow in the Frame Model In this section, we will summarize the key notions of [4]. Systems (or frames), represented as directed graphs, have executions; the local portions of an execu- tion are called local runs; and an observer who sees one local run is trying to infer information at a source, by determining what local runs at that source are compatible with the observations. An information flow specification, which we call a blur, is a specific kind of closure condition on the set of compatible local runs at the information source. 3.1 Frames and Executions We formalize systems such as EpiDB by structures we call frames. A frame F consists of a directed graph, the nodes (or locations) of which are processing elements each defined by a labeled transition system, and the arcs of which carry messages. An execution of a frame F is a partially ordered set of events, where each event e has a channel chanpeq and a message msgpeq. The events associated with a single node nmust be linearly ordered, and moreover must form a possible trace of ltspnq. However, events on two channels that are not attached to a common node may be unordered, unless some causal sequence of events connects them. We will use the words node and location synonymously. Definition 1. Let LO, CH,DA,ST , EV be domains that we will call locations, channels, data, states, and events, resp. 1. A labeled transition relation is a ternary relation ; ST EV ST . A labeled transition system is a pair p;, s0q of a labeled transition relation and an initial state s0 P ST . lts is the set of labeled transition systems.\n2. When ` P LO, we define chansp`q tc P CH : sndrpcq ` or rcptpcq `u.\n3. A frame is a structure F containing the domains and functions shown in Table 1 satisfying the following properties:\n(a) For all e1, e2 P EV, if chanpe1q chanpe2q and msgpe1q msgpe2q, then for all ` P LO and s, s1 P ST , s\ne1\n;` s 1 iff s\ne2\n;` s 1. (b) For all s, s1 P ST , e P EV, and ` P LO, s\ne\n;` s 1 implies chanpeq P chansp`q.\nwhere we let p;`, initialp`qq ltsp`q. {{{ The histories of an lts p;, s0q are all finite or infinite alternating sequences\nh xs0, e0, s1, . . . , si, ei, si`1, . . .y starting with s0, such that psj , ej , sj`1q P ; whenever ej is well defined. In particular, sj`1 is well defined whenever ej\nis, so that h does not end with an event ej . A trace of p;, s0q is a finite or infinite sequence of events tr xe0, e1 . . .y such that there is a history h where tr enumerates the events in h. An execution is a partially ordered set of events thatwhen projected onto chansp`qalways yields a trace for `. Definition 2. A pE,q is an execution for a frame F , written A P ExcpFq, iff E EV and is a well-founded partial ordering on E, and, for all ` P LO, letting trAp`q be the set te P E : chanpeq
P chansp`qu, 1. trAp`q is linearly ordered by ; and 2. trAp`q ordered by is a trace of ltsp`q. {{{ When LO is finite, the well-founded condition is redundant. If A pE,q is an execution, and 1 is a partial order that is stronger than , i.e. 1, then A1 pE,1q is also an execution. The weakest partial order is generated from the sequential traces of the individual locations, and extended to events at other locations when they share an event on some channel that connects them. However, any strengthening of this order determines another execution based on the same set E of events. Our notion of execution ignores what states the locations ` reach after en- gaging in the events trAp`q, and thus ignores the effects of nondeterminism. A similar theory can be developed including the resulting states, which would let us talk about refusals as well as traces, but we will postpone that opportunity for now. We have here a synchronous notion of communication; a message m passes over channel c only if both endpoints can take a transition with label c,m. Thus, the sender learns that the recipient is willing to accept m over c now. Information flows over channels in both directions. 3.2 Local Runs and Compatibility We can now define what an observer with access to a particular set of channels sees, or what a source of information does. We will assume that the observer or the source has access to a set of channels C CH. Often C is of the form C chansp`q for some ` P LO or C \n `PL chansp`q for some L LO, but this is not always the case. A local run at C is just the result of restricting the events in some execution to the channels C. Definition 3. Let B pE,Rq be a partially ordered set of events, and C CH. 1. The restriction B | C is pB0, R0q, where B0 te P E : chanpeq P Cu, and R0 R X pB0 B0q.\n2. B is a C-run of F iff for some A P ExcpFq, B A | C.\n3. C-runspFq tB : B is a C-run of Fu. We write C-runs when F is understood, and, when C is understood, we speak of local runs. B2 extends B1, when B1 pE1,1q and B2 pE2,2q are p.o. sets, iff E1 E2; 12 XpE1 E1q; and te : De1 P E1 . e 2 e1u E1. {{{ Fix some frame F . What an observer at D knows is that some B P D-runspFq occurred, since she observed some B. She wants to consider what local runs are still possible at some source D CH. These are the members of D-runspFq that are restrictions of executions that also restrict to B. Definition 4. Let C,D CH and D P D-runs. 1. A local run B P C-runs is compatible with D iff, for some A P Exc, A | C B and A | D D.\n2. JCDpDq tB P C-runs : B is compatible with Du. {{{ We use the letter J to indicate that these B can occur jointly with D. The subscripts indicate that information would flow from C to D if JCDpDq fails to have suitable closure properties. The subscript D adjacent to the argument D is meant to remind that D P D-runs, as a kind of type-annotation; the left-most subscript C is a reminder of the type of the local runs in the result. 3.3 Blurs to Limit Information Flow Generally speaking, when JCDpDq is large for all D P D-runs, then there is little flow from C to D. The observations at D leave open many possibilities for what could have happened at C. We can make precise what the observer at D cannot learn by considering closure operators on sets of local C-runs. We think of the observers vision as blurred insofar as she cannot distinguish a local C-run from other members of a closed set. Thus, the relation of coarsening on closure operators represents the observers loss of resolution as information flow decreases. Generally speaking, a closure operator obeys three properties. Each set in included in its closure; closure is idempotent ; and closure is monotonic with re- spect to the inclusion relation. We found that information flow respects the graph structure of frames when we strengthen the montonicity property somewhat [4]. We call operators that satisfy these strengthened conditions blur operators. Definition 5. A function on sets is a blur operator iff it satisfies: Inclusion: For all sets S, S pSq; Idempotence: is idempotent, i.e. for all sets S, ppSqq pSq; and Union: commutes with unions: If tSauaPI is a family indexed by I, then p\n aPI Saq \n aPI pSaq. S is -blurred iff is a blur operator and S pSq. {{{ Observe that\n aPI pSaq p\n aPI Saq is equivalent to monotonicity, so that the union property is effectively monotonicity plus a converse. The union property ensures that is determined by its action on singletons. Since S \n aPStau, pSq \n aPS ptauq. Blur operators form a lattice under pointwise inclusion, which provides a way to compare the flow of information in different situations. Thus, allows at least as much information flow as if pSq pSq for every S. The EpiDB blur. In the case of EpiDB, we are interested in a blur on the local runs at channel 3, i.e. C t3u. Since, by the union property, we only need to define ptBuq for singletons of a B P C-runs, we must say which local runs B1 should be indistinguishable from B for the observer on channels 1, 2, i.e. A1. However, Section 2.3 already makes clear which B1 this should be. Analyst A1\nhas permissions defined in terms of personspA1q, diseasespA1q, and IntpA1q. Define R0pBq to be the set of disease records pp, d, tq delivered in B such that p P personspA1q, d P diseasespA1q, and t P IntpA1q. Define R1pBq to be the set of disease records pp1, d, t1q in B such that there is an encounter record ptp, p1u, eq in B with t, e, t1 successively -near. Then ptBuq tB1 : R0pBq R0pB\n1q and R1pBq R1pB 1qu We can also express this more operationally: pSq is closed under 1. permutations; 2. adding: (a) records submitted elsewhere in B; (b) encounter records not connecting R0pBq to any disease record in B; (c) disease records rd pp, d, tq such that i. p R personspA1q, d R diseasespA1q, or t R IntpA1q, and ii. rd is not connected to R0pBq by an encounter record; 3. omitting records of the same kinds. Limited flow. The blur notion suggests a restricted information flow notion, and moreover the latter respects the graph structure. Specifically, limiting what information flows to a cut set in the graph guarantees the same limit applies to observers beyond that cut set. Definition 6. Let obs, src CH and : Ppsrc-runsq Ppsrc-runsq. F -limits src-to-obs flow iff is a blur operator, and, for every B P obs-runs JsrcobspBq is -blurred. This notion respects the graph structure of the frame F . First, since effectively information can flow in either direction over a channel, we consider the undi- rected graph ungrpFq pV,Eq where the vertices V are the locations, V LO, and where an undirected edge p`1, `2q exists iff, for some c P CH, sndrpcq `1\nand rcptpcq `2 or vice versa. Now, for C0, C1, C2 CH, let us say that C1 is a cut between C0 and C1 iff, for every path p through ungrpFq that starts at a c0 P C0 and ends at a c2 P C2, p traverses some c1 P C1. Now: Theorem 1 (Cut-Blur Principle, [4]). Let src, cut, obs CH, where cut is a cut between src and obs in F . If F -limits src-to-cut flow, then F -limits src-to-obs flow. There is also a two-frame version of the same idea. Here, F2 agrees with F1 on the portion of the graph that lies from src to cut, and on the lts of those locations. As\nlong as F2 does not exercise possibilities at cut that F1 does not, then -limited flow is preserved. We write CHi,LOi, C-runsi, etc. for the channels, locations, local runs etc. of Fi. Theorem 2 ([4]). Let src, cut CH1 in F1. Let F2 be a frame, with src, cut CH2, and such that, if p is any path in ungrpF1q starting at some c0 P src and traversing no arc in cut, and p reaches c P CH1, then: 1. c P CH2, sndr1pcq P LO2, and rcpt1pcq P LO2; 2. sndr2pcq sndr1pcq, and rcpt2pcq rcpt1pcq; 3. lts1psndr1pcqq lts2psndr2pcqq and lts1prcpt1pcqq lts2prcpt2pcqq. Let obs CH2 be such that cut is a cut between src and obs in F2. If cut-runs2 cut-runs1, and F1 -limits src-to-cut flow, then F2 -limits src-to-obs flow. In fact, the cut-blur principle is a corollary of this; when we equate F2 F1,
the assumptions necessarily hold. This principle is useful for localizing the enforcement of -limiting to the portion of the system lying between src and cut. It says that we can freely vary the structure of the remainder of the system, just so long as we do not force cut to engage in new local behaviors. For instance, if we consider cut t1, 2u and src t3u in either Fig. 1 or Fig. 4, it says that we can freely expand the node A1\ninto multiple nodes and arcs, as long as cut remains a cut. The assumption that cut-runs2 cut-runs1 is immediate here, since we assume that A1 may attempt any sequence of communications anyway. 4 Questions and Answers We would now like a corresponding way to specify functionality goals, i.e. lower bounds on information flow between a source and an observer. For instance, if A1 is permitted to submit a query q pp, d, tq over channel 1, then A1 really should be able to learn from the system what the answer is, as of the time of this interaction. Thus, the system is guaranteeing that a local run over channels 1, 2 can always extend to one in which A1 submits query q and receives a symbol or set S of records over channel 2. And this answer tells A1 whether PR has sub- mitted a nearby disease record, and, in the stream of records PR has submitted on channel 3, what other disease records are adjacent via encounter records. Thus, the response is compatible with a set of local PR runs, and serves to notify A1 that no other type of run remains possible. We will call a classification like this a question about a set of channels such as the PRs channel set t3u. Definition 7. A family of sets Q is a question about a set of channels C CH in F iff\n Q C-runspFq. In our example, we can regard each permitted query q pp, d, tq as determining a question Q about PRs channel 3. Namely, two B,B1 P t3u-runs belong to the same X P Q iff either: in both B and B1, p is not sick with d at t, or else in both p is sick, with the same sick acquaintances and the same timings. We can regard an impermissible query as determining a question also, but it is the trivial, singleton family tt3u-runsu. Thus, each query q determines a question Qq about channel 3. An observer at D may want to determine which member of this family Q obtains. That is, the observer would like to extend the current local run so that the systems behavior will determine an A P Q that must have been found at C. This may require D to engage in certain events that ask about Q, after which the systems behavior will lead to the information. Naturally, the events that pose the question must be within the power of the observer at D. Definition 8. F answers Q for D CH iff (i) Q is a question about C in F , and (ii), for every D P D-runs, there is an extension D1 of D and a family R of finite extensions of D1 such that: 1. For all A P Exc, if A | C D, then there exists an extension A1 of A such that A1 | C D1; 2. for every E P R, there exists a X P Q such that JCDpEq X; and 3. for every extension E of D1, there exists a E0 P R such that either E extends E0 or E0 extends E. The first of these clauses ensures that the observer can always request the system to answer Q. The second ensures that an observation in R selects some answer to the question, although there may be more than one right answer. The second says that the observations that determine an answer bar the tree of all extensions of D1, so that any sufficiently long extension will have selected an answer. Evidently, EpiDB answers the question Qq for each q. The extension D\n1 to a local A1-run D consists in waiting for an answer on channel 2 to a previous, unanswered question (if any), and then submitting q on channel 1. The family R is then the set of local runs in which D1 is extended by a symbol or set of records. Of course, if a frame -blurs flow from C, then an answerable question about C can never be more informative than a -blurred question: Lemma 1. Let Q be a question about C in F . Suppose that F answers Q for D CH, and that F -limits C-to-D flow. Then there is a Q1 such that Q is a coarsening of Q1, F answers Q1 for D, and for every X P Q1, X is -blurred. Indeed, Q1 can be chosen so that a pair of D-runs that can receive the same answer in Q can receive the same answer in Q1. Proof. For each choice of D1 and R, collect the sets JCDpRq for R P R; let Q1 be the resulting collection. Since F -limits C-to-D flow, each JCDpRq is -blurred. To preserve can receive the same answer, coarsen that Q1 by taking unions: In particular say that R,R1 P R are Q-similar, which we will write R Q R\n1, if there is an X P Q such that JCDpRq X and JCDpR\n1q X. Define Q1R t\n R1QR JCDpR\n1q : R P Ru. The union property of blurs ensures that the resulting sets are -blurred. Now let Q1 collect Q1R from each choice of D\n1 and R. [\\ In our EpiDB example, the questions Qq are already -blurred. 5 Refining EpiDB Although the simple presentation of EpiDB in Figs. 12 makes it clear why it will meet its information flow goalsboth upper bounds and lower boundsthey are very far from a reasonable implementation. A reasonable implementation should have a number of different properties: It should be implemented via a number of virtual machines, so that its components can be responsive under high loads; It should separate an index from the actual archive that stores the data, to allow fast retrieval despite large quantities of data; It should separate critical services such as authorization from more vulner- able components that must service potentially malicious connections from analysts and providers. All of these considerations militate for breaking the component E in Fig. 1 into a collection of cooperating components that interact via message channels. This decomposition fits the frame model very naturally, since the connections among these components are easy to define statically. Step 1: Separating Authorization. A natural thing to do first is to identify a distinct component that uses the credentials of A1 and the query q to make an authorization decision. For instance, these credentials could be certificates used in a bilateral TLS handshake. The authorization service can emit a cryptographic token that will be consulted by components in later expansions. Fig. 3 shows the resulting frame graph. Now the state of AR reflects whether authorization has been requested by the current query, and if so, the value of the resulting token. The behavior of the system on its channels 1, 2, 3 is actually unchanged: In particular, given a local run D on channels 1, 2, the set of compatible local runs on channel 3, Jt3ut1,2upDq is the same for the two systems. Since the information flow of the system is defined solely in terms of Jpq, any desired upper and lower bounds on flow are necessarily preserved. A1 1 **\nE 2 kk 4 PR\n3oo AU 5 JJ Fig. 3. EpiDB with authorization service separated A refined EpiDB architecture. After several stages of refinement, we ob- tain a system of the form shown in Fig. 4. It breaks down the database into components with specialized responsibilities: QC is a query controller. It accepts queries from A1, passes requests to the index controller IC, which extracts records from the archive controller AC that are accumulated at QC. It returns the resulting sets to A1. IC is an index controller. It maintains an association between keys pi naming people and a list of disease record numbers for those people. It has a similar association from people to encounter records. When given a person and a table name, it passes a list of record numbers to AC for retrieval. AC is an archive controller. It maintains a store of records for each table, orga- nized by record number. IG is an ingress controller. It maintains the maximum record number used so far. It receives new records from the provider PR, assigns the next record number, and sends the record and number to AC. It notifies IC of the new association of this record number with the relevant pis. AU is the authorization service. QC contacts AU for each new query, obtaining a signed authorization token that accompanies QCs messages
to IC. These tokens also appear in the system audit logs, if an audit subsystem is added. The self-loop channels 8, 9 allow QC and AC to signal certain internal events. The only other channel needing explanation is 6. At the beginning of processing any query, QC uses channel 6 to request the current maximum record number from AC, which maintains this. QC then limits all records retrieved to ones below this maximum. Hence, even when new records are being deposited by PR and IG concurrently, the query elicits consistent information reflecting the state of the database at the time of that maximum record number. Channel 12 is used only to propagate the maximum query time (shown as m in Fig. 2) to the ingress controller. Again, the functional correctness criterion for this system is just that the same local runs should be possible on its two external interfaces, and with the same compatibility relations Jt3ut1,2upDq.\n1 The practical requirement for the 1 By an interface, we just mean a set of channels, often but not necessarily near each other in the graph. A1 1 ++\nQC 2 kk 4 8 6 ++ 10\n$$ AC 7 kk 9 12 ++\nIG13kk 14{{ PR\n3oo AU 5 JJ IC 11 OO Fig. 4. Refined architecture for EpiDB system designer to meet is that the index and archive controllers IC,AC should cooperate to maintain the database accurately, which is well understood. The interface-preserving refinement principle. This refinement strategy is simple and easily formalized. When F1, F2 are frames, we write J\ni\nCDpq for the compatibility function in Fi. Theorem 3. Suppose that F1 and F2 are two frames, and C,D CH1 X CH2. If D-runs1 D-runs2, and for all D P D-runsi, J\n1\nCDpDq J 2\nCDpDq, then: 1. F1 -limits C-to-D flow iff F1 -limits C-to-D flow;\n2. F1 answers Q for D iff F2 answers Q for D. This follows directly from the forms of the definitions. However, it is useful. For instance, it immediately follows that the properties of the system are preserved in case the system serves more than one analyst. In Fig. 5, we present an augmented system containing multiple analysts. However, since the behaviors on the interfaces 1, 2 and 3 are unaffected, Thm. 3 immedi- ately entails that the augmented system continues to meet its goals for A1. By symmetry, it meets the same goals for the other Ai. As another example, the system we have described has no audit mechanism built in. However, having designed the system and established its information flow properties, we can add nodes and channels to perform audit without chang- ing the local runs and compatibility functions for the interfaces 1, 2 and 3. This A2 A3 vv A1 1 ++\nQC 2 kk JJ 66 4 6 ++ 10\n$$ AC 7 kk\n12 ++ IG13kk 14{{ PR\n3oo AU 5 JJ IC 11 OO Fig. 5. EpiDB augmented with multiple analysts. Channels 8, 9 omitted as clutter provides a clear argument for orthogonality of design that has sometimes eluded secure systems methodology. 6 Conclusion We have discussed the frame model, and illustrated how to use it to establish what-declassification policies, or information flow upper bounds. The same ideas lead to a natural approach for showing lower bounds, i.e. that a system really answers questions which may be posed on one of these interfaces. However, the frame model gives an abstraction of a possible system: How can one determine that an actual system displays the structure and behavior of a given frame as designed? In particular, two central items are needed. First, the active components of the actual system should correlate with the nodes of the frame. The behaviors of each component should conform to the lts of the\ncorrelated node. Second, the message-passing activity of the system should occur along channels identified in the frame. There should be no other interactions, whether between components of the system or between components and the external world. Similarly, to build a real system using a frame as specification, one needs, first, a way to build local programs that conform to an lts specification, and various\nfamiliar ideas such as reactive programming and event-handling libraries appear helpful. In any case, the programming here is purely sequential and independent of any shared state interactions. How then to establish, second, that the components interact with each other, and only with each other, as specified in the graph? This requires cryptographic support, both for secrecy to ensure that messages between components canot leak to the external world, and for authenticity to ensure that a component cannot receive a message off a channel unless its peer transmitted onto the channel. A protocol is needed also to ensure that message passing approximates the synchronous semantics the model uses. Indeed, there is an additional role for cryptography, which is to provide at- testation, i.e. digitally signed evidence that a node is genuine and under the control of the expected code. The Trusted Platform Modules were intended as an anchor for this sort of evidence, and user-level trusted execution environments (TEEs) such as Intels Software Guard Extensions provide a simpler framework for achieving attestations [5]. TEEs provide symmetric cryptographic support to protect a thread and local memory, encrypting pages as they leave the pro- cessors cache. Moreover, the processor provides digital signatures that attest to the code in control of the TEE. These attestations allow components to validate one another, to ensure that they are affiliated in the pattern stipulated in their model. The attestations also allow an external party to decide to believe this also, before making a decision as to whether to deliver data into the system, or accept it from the system. Thus, in addition to hardware support, we need to be able to use cryptographic protocols in the right way; another area in which A. W. Roscoe has also made his contributions. Acknowledgments. I am grateful to Paul D. Rowe and John D. Ramsdell, with whom I discussed many of these ideas. In particular, John Ramsdell worked out the successive frame versions summarized in the figures. References 1. Riccardo Focardi and Roberto Gorrieri. The compositional security checker: A tool for the verification of information flow security properties. IEEE Transactions on Software Engineering, 23(9), September 1997. 2. Riccardo Focardi and Roberto Gorrieri. Classification of security properties. In Foundations of Security Analysis and Design, pages 331396. Springer, 2001. 3. Joseph A. Goguen and Jose Meseguer. Security policies and security models. In IEEE Symposium on Security and Privacy, 1982. 4. Joshua D. Guttman and Paul D. Rowe. A cut principle for information flow. In IEEE Computer Security Foundations. IEEE Computer Society Press, July 2015. 5. Intel. Intel Software Guard Extensions (Intel SGX). https://software.intel. com/en-us/sgx, 2016. 6. Jeremy Jacob. Security specifications. In IEEE Symp. Security and Privacy, pages 1423. IEEE Computer Society, 1988. 7. Carroll Morgan. The shadow knows: Refinement of ignorance in sequential pro- grams. In Mathematics of program construction, pages 359378. Springer, 2006. 8. A. W. Roscoe. CSP and determinism in security modelling. In IEEE Security and Privacy, pages 114127. IEEE, 1995. 9. A. W. Roscoe. The Theory and Practice of Concurrency. Prentice-Hall, 1997. 10. A. W. Roscoe and M. H. Goldsmith. What is intransitive noninterference? In 12th IEEE Computer Security Foundations Workshop, pages 228238. IEEE CS Press, June 1999. 11. A.W. Roscoe, J.C.P. Woodcock, and L. Wulf. Non-interference through determin- ism. Journal of Computer Security, pages 2753, 1996. 12. John Rushby. Noninterference, transitivity, and channel-control security policies. SRI International, Computer Science Laboratory, 1992. 13. P. Y. A. Ryan. A CSP formulation of noninterference and unwinding. In IEEE CSFW 3, June 1990. 14. Andrei Sabelfeld and David Sands. Declassification: Dimensions and principles. Journal of Computer Security, 17(5):517548, 2009. 15. David Sutherland. A model of information. In 9th National Computer Security Conference. National Institute of Standards and Technology, 1986. https://software.intel.com/en-us/sgx\nhttps://software.intel.com/en-us/sgx Information Flow, Distributed Systems, and Refinement, by Example ",
    "text": "test",
    "text": " () IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 1 \nAbstractThe past decade has seen the emergence of many hyperspectral image (HSI) analysis algorithms based on graph theory and derived manifold coordinates. The performance of these algorithms is inextricably tied to the graphical model constructed from the spectral data, i.e., the community structure of the spectral data must be well represented to extract meaningful information. This paper provides a survey of many spectral graph generation techniques currently used in the hyperspectral community and discusses their advantages and disadvantages for hyperspectral analysis. A focus is provided on techniques influenced by spectral density from which the concept of community structure arises. Two density weighted graph construction techniques not previously used in hyperspectral imaging, shared nearest neighbors (SNN) and mutual proximity (MP), are also introduced and compared. Density-based graph generation is demonstrated to be more effective than fixed sized lists on multiple HSI classification examples. Additionally, application of many complex edge-reweighting techniques often does not improve the health of nearest neighbor lists, placing doubt on their use for HSI data as currently defined. \nIndex Terms graph theory, hyperspectral imaging, imaging spectroscopy, manifold, spectral density I. INTRODUCTION YPERSPECTRAL imaging (HSI) produces spectral radiance measurements for each spatial location in the acquired scene. The spectral measurement for a particular scene location (pixel) is called a spectrum which contains information about the properties of the sensed area at many wavelengths (typically hundreds) and may be thought of as a vector in a d dimensional space, , where d is the number of spectral \nbands [1]. The spectrum, = , , , \n, may be \nanalyzed in its native spectral radiance space or may be \nPaper received xx September, 2016; revised paper received xx November, 2016; accepted for publication xx June 2017. This work was performed under the direction of George Mason University. J. Stevens is an image scientist in the Space and Intelligence Systems division of Harris Corporation, Reston, VA USA. He is currently a student at George mason University, Fairfax, VA USA in the computational sciences and informatics department (e-mail: jsteveng@gmu.edu). R. Resmini is a research scientist in the Advanced ISR Solutions Department of the MITRE Corporation, McLean, Virginia, USA, and an Associate Professor in the College of Science at George Mason University, Fairfax, Virginia, USA (e-mail: rresmini@gmu.edu). D. Messinger is currently a Professor, the Xerox Chair in Imaging Science, and Director of the Chester F. Carlson Center for Imaging Science at the Rochester Institute of Technology, Rochester, USA (e-mail: messinger@cis.rit.edu). Digital Object Identifier: xx.xxx.xx converted into physical units such as reflectivity or emissivity. The aggregate collection of all such radiance measurements or derived physical units is called a hypercube, a three dimensional structure comprised of two spatial (x,y) dimensions and a wavelength dimension (). The rich spectral \ncontent of these data enable greater material discrimination than possible with multispectral data. Spectral image analysis algorithms developed over the past 25 years are primarily based on statistical and geometric subspace or mixing models. A brief qualitative description of the statistical and geometric models is provided below whereas the reader is referred to [2]-[5] for excellent technical reviews of common statistical, subspace, and mixing model algorithms for target detection, anomaly detection, classification, and change detection. Statistical models treat each spectrum as a d-D random vector. Each vector (spectrum) is a realization of a random spectral distribution and thus lives within a region of hyperspace delineated by a probability density function. Many parametric probability density functions possess elliptical symmetry, are fast, and simple to implement with the multivariate normal distribution (MVN) being the most common in the HSI literature [6]. Stochastic expectation maximization (SEM), the Reed-Xiaoli (RX) detector, and the spectral matched filter (SMF) are common statistical methods making use of the multivariate normal model for classification, anomaly detection, and target detection respectively [2][5]. However, hyperspectral data approximation by parametric statistical models, especially the MVN, is diminishing with increasing spatial and spectral resolution [6][7], so techniques not reliant on parametric models need to be developed. Geometric models treat each spectrum as a deterministic point in . A hyperspectral image may therefore be \ninterpreted as a scattered set of points in d-D hyperspace. Hyperspectral imaging typically acquires hundreds of bands (dimensions), but significant band-to-band correlation exists and the data usually reside in a lower dimensional subspace, , where [8]. Subspace basis vectors can be \nconstructed from pure materials in the scene called endmembers [9][10] or from eigenvectors of the spectral covariance matrix [1][2]. These methods are called linear mixture models and vector subspace models respectively. In the former case, the basis may not be orthogonal, whereas in the latter, the basis is guaranteed to be orthogonal by the Eigen or singular value decomposition of the spectral covariance matrix. Algorithms based on these geometric models treat Spectral-Density Based Graph Construction Techniques for Hyperspectral Image Analysis Jeffrey R. Stevens, Ronald G. Resmini, and David X. Messinger H IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 2 either the background spectra, target spectra, or both, as existing within subspaces. Some common examples are the adaptive and Generalized Likelihood Ratio Test (GLRT) subspace detectors [2]. The statistical and geometric algorithms discussed thus far are linear methods, hence may be ineffective at modeling nonlinearities present in HSI data. The three most common causes of nonlinearities in hyperspectral data are (1) variations in material reflectivity with illumination and viewing angle, i.e., the bidirectional reflectance distribution function (BRDF), (2) transmissive media such as water, and (3) intimate mixing found in many soils [10][11]. New methods are therefore required to analyze data exhibiting nonlinearities and lack of adherence to the MVN. In 2005, Bachmann et al. [11] from the Naval Research Laboratory explored a new geometric perspective in hyperspectral analysis. They viewed spectra as vertices (nodes) in an d-D graph, where edges represent pixel similarity. Their method models hyperspace geometry (or structure) without the limitations of strict statistical forms or linear subspaces. Bachmann first applied methods derived from these graphs towards the classification of wetland HSI imagery exhibiting nonlinear behavior [11][12]. Several researchers have continued the development of graph-based techniques due to the ideas presented in Bachmanns seminal papers [7][13][19]. The success of any graph-based analysis is intimately tied to the quality of the graph constructed from the spectral data [13]. Edges must be judiciously chosen to accurately model community structure inherent in the data without over (under) connecting the nodes. Many of these graph construction techniques are founded on the k-nearest neighbor (k-NN) relationship because of its adaptability to both scale and density as well as its ability to follow clusters of arbitrary shape. We will compare and contrast these methods in this paper with the intent to provide a consolidated reference for these techniques. The remainder of this paper is as follows. Section II provides a survey of spectral graph construction techniques found in the hyperspectral remote sensing literature. Two new spectral graph construction techniques are introduced in Section III, each with multiple variants. A performance evaluation of the spectral graph construction techniques presented in Sections II and III is provided in Section IV. Conclusions and directions of future study are provided in Section V. II. HSI GRAPH CONSTRUCTION TECHNIQUES Hyperspectral data does not natively exist as a graph, therefore must be converted into graphical form by selection of a function or heuristic in order to enable graph-based analysis. In this section, we first introduce some graphical terminology and then detail many common graph construction techniques found in the hyperspectral remote sensing literature. A graph, = , , in its simplest form is defined as a pair \nof two finite sets: a vertex (or node) set and an edge set, denoted V and E respectively. Vertices are simply points in d- D space determined by the coordinates of each spectrum. The size of the vertex set, ||, is simply the number of pixels in the \nhyperspectral image. We denote a general vertex by an italics , whereas specific vertices (pixels) are indicated using \nsubscripts, e.g., . Note that the terms node, vertex, and pixel \nare used interchangeably throughout the text based on the context of the discussion. The edge set may be either directed or undirected. Directed edges (and hence graphs) utilize ordered pairs of points indicating the source and sink of the edge, i.e., , represents an edge from to . The ordering is \nirrelevant for undirected edges. For our purposes, all edges are undirected and simply indicate a relationship between pixels. Undirected graphs without loops ( and multiple edges \nbetween the same endpoints are called simple graphs [14] and are the focus of our investigation. Central to all spectral graph construction techniques is the concept of a vertex neighborhood. A neighborhood, , is a \nset of vertices that are related (deemed similar) to the vertex
being examined by some heuristic or analytical method. Edges are constructed between a vertex and all vertices in its neighborhood. Vertices with edges between them are said to be adjacent. A multitude of methods exist to define this neighborhood and the size of the edge set, ||, can vary \ngreatly between methods for the same set of vertices. Vertex adjacency may be represented by multiple means, e.g., matrices, linked lists, or arrays of arrays. Of particular interest in spectral imaging is the adjacency matrix, ! =\n\", where \" = 1 if an edge exists between and , and zero \notherwise. ! is therefore an n x n symmetric matrix for \nundirected graphs, where n is the number of pixels in the image. An HSI image with 10% pixels has an adjacency matrix \nof size 10&'. The need for efficient encoding and/or \napproximation is evident. Edges may also be encoded with the strength of the relationship between vertices by replacing the unitary edge contributions in !, with the value of a distance (similarity) \nmetric1. This weighted adjacency (affinity) matrix, ( =\n), is composed of non-negative scalar values where \n , , and zero otherwise. A graph may therefore be \ndefined as = , , ), where w is a mapping associating \neach edge of unitary contribution in ! with a positive number \nrepresenting vertex distance (similarity), i.e., ): 0,, or \nsimply = ,.. In the subsections to follow, we will first focus on basic graph construction techniques and then migrate to those influenced by data density because it leads to the concept of clusters, i.e., community structure. \n1 Distance measures quantify the separation between two objects such that 0,, where = 0 indicates identical objects. Similarity measures \nquantify the similarity, s, between two objects where larger values indicate objects that are more alike, where typically 0 1 0,1. Edge weight matrices for \ndistance and similarity matrices are called adjacency and affinity matrices respectively. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 3 A. -Threshold Graphs (aka -NN Graphs) The threshold graph is very simple to construct and the fastest of all described methods. Given all pairwise distances (or similarities), an undirected edge is placed between two nodes if the distance, , , (or similarity) between them is \nless (greater) than, 1, where 1 > 0 is a user defined constant. \nSpecifically, , is added to the edge set, , if lies \nwithin the hypersphere of radius 1 constructed about in \nspectral space. Mathematically, this may be stated , \n 33 , 1 and . The similarity based equation \nis obtained by replacing , with 0 , and switching \nthe direction of the inequality. This technique is not adaptive to scale or density because 1 is a fixed global threshold [15], \ngenerally producing unconnected graphs. Hyperspectral data typically displays a multitude of densities hence this technique is not widely used, but is instructional in understanding other graph construction techniques. B. k Nearest Neighbor (k-NN) Graphs Nearest neighbor graphs are very common graphical construction techniques. An edge is placed between and if \n is among the k nearest neighbors of . The user defined \nparameter, k, is a global parameter indicating the number of edges exiting , i.e., its out degree. Given each node has its \nown set of k nearest neighbors, this relationship is not symmetric and therefore produces directed edges leading to an asymmetric adjacency matrix [16]. These graphs are also called directed k-NN graphs for this reason. Construction of the k-NN graph is conceptually very simple, but computationally expensive due to the evaluation of all pairwise distances and subsequent sorting. Many traditional indexing methods (e.g., R-tree, k-d tree) fail in high dimensional spaces such that exhaustive searching for nearest neighbors can outperform even the most complex indexing scheme [17]. As such, several fast nearest neighbor methods have been developed to generate approximate or exact k-NN lists [18]. k-NN graphs are locally adaptive to both density and scale which makes them particularly well suited to model clusters of varying density [19] or follow mixing trends between clusters. Unfortunately, a global k-NN construction tends to over connect vertices in low density regions since the nearest neighbor may span a significant distance (or similarity). Another difficulty is selection of the user defined parameter k; values from 5 to 60 are common [13][19]. Selecting k too high tends to over connect the graph, whereas selecting k too low leaves the graph disjoint. This sensitivity to k is true of many k- NN variants and has promoted the development of adaptive algorithms that provide node-specific values, 8. \nWe are restricting analysis to simple graphs and therefore need to modify the asymmetric adjacency matrix resulting from the directed k-NN relationship. There are two means of creating simple graphs from directed k-NN graphs, producing symmetric adjacency matrices: symmetry and mutuality. An added benefit of symmetric adjacency matrices is that memory requirements are cut in half because only the upper or lower triangular portions of the adjacency matrix need be stored. This can be quite substantial for even average sized HSI cubes. Generation of the symmetric k-NN graph is a trivial extension of the directed k-NN graph, where all vertex pairs, , , are connected if 9 orororor \n 9, where 9 represents the k nearest neighborhood \nof vertex . As a result, each node will have at least k \nneighbors with the node degree being proportional to the nodes local density. Forcing a symmetric adjacency in this manner (bidirectional extension) may connect clusters of varying density and edges can still span large regions of spectral space to overly connect outlier nodes. Stringers, long chains of single nodes, can also extend from virtually anywhere if the conditions are right. This can produce a larger subgraph diameter if they extend from cluster edges. Generation of the mutual k-NN graph is also a trivial extension of the directed k-NN graph, where all node pairs , , are connected if 9 and 9, i.e., \nonly existing bidirectional edges are retained. The resultant adjacency matrix is symmetric and a subset (subgraph) of the directed k-NN adjacency matrix (graph). Forcing adjacency symmetry in this manner reduces the possibility of connecting clusters of varying density; hence edges typically do not span large regions of feature space, leaving outlier nodes unconnected from denser regions [15]. C. Density Weighted k-NN (DW k-NN) Graphs Dense groupings of points in feature (spectral) space share similar attributes of similar magnitude and are therefore related. It makes intuitive sense these similar intracluster nodes should be more heavily connected than extracluster nodes. HSI data clusters exist at varying scales and density, so adaptive algorithms are desired. The definition of density itself may also need to be change because traditional Euclidean density becomes meaningless in high dimensional spaces due to the exponential growth in d-D volume [20]. Kameshwaran and Malarvizhi [21] state density based measures are the key to finding nonlinear structure, and we will find they are used extensively in HSI graph generation. Mercovich [13] introduced the concept of density weighted k-nearest neighbors to encode stronger relationships between similar nodes and promote more effective clustering by minimizing the impact of extracluster pixels. All pixels are assigned a codensity (distance) score given by ,\n1 1\n)( max minminmax \n= \n +\n= k kk iki w\nkk v (1) where k represents the indices of node <0 nearest neighbors \nprovided in non-decreasing order, and kmin and kmax define the range of k values to average. Mercovich set 8=> = 1 such \nthat ? represents the average distance of the pixels \n8=@A neighbors. A node-specific number of neighbors, 8, is \nassigned to each node based on its position in the histogram of IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 4 codensity scores (indicated by the nodes z-score). Mercovich found assignments based on integral z-score values from the range [-3,3] worked well for HSI clustering. Fig. 1a shows a representative Gaussian codensity distribution and the node specific connectivity count, 8 assigned by this method. \nAssigning 8 in this manner results in a large number of nodes with ~8=@A/2 edges and much fewer nodes with 1 or \n8=@A edges as shown in Fig. 1(b). The mapping is a quantized \ninverse function of codensity where pixels residing in lower density regions (higher codensity) receive few edges (towards 1) and pixels in high density regions (low codensity) receive more edges (towards kmax). Mercovich notes that codensity distributions can take on non-normal forms based on scene content, but the normal assumption (through use of z-score) worked well for clustering2. HSI codensity distributions can approach normal \n2 While some codensity distributions may appear relatively normal, they are never rigorously normal. We verified this by testing 56 chips of varying scene content, from different sensors, and GSDs via the Komolgorov-Smirnov test with increasing number of bands as seen in Fig.
1(a) (145 band visible to shortwave infrared dataset with bad bands removed) if the data has higher intrinsic dimensionality [22]. However, codensity distributions from a small number of bands are generally not normal and care must be taken because non- normal behavior changes the intended mapping of z-score based methods. In these situations the cumulative density function (CDF) may be used instead of z-score providing a method to drive connections from kmax to 1 independent of the codensity functional form while maintaining the intended mapping. D. Adaptive Nearest Neighbor (ANN) Graphs The natural nearest neighbor (NNN) graph described by Zou and Zhu [23] provides a data-driven parameter-free method for the generation of node specific connectivity, 8. This \nmethod was first applied to hyperspectral imagery by Ziemann et al. [24] while exploring target detection methods based on manifold approximations recovered from spectral data. The novel aspect of NNN is that there are no user defined parameters and the algorithm autonomously produces a node- specific connectivity proportional to local density. Natural nearest neighbors maintains a list of the number of times node has been identified as a neighbor by another \nnode, , the reverse nearest neighbors of . This list of \ncounts, 8, is built by sequentially examining the vector of rth \nnearest neighbors for every pixel where E = 1, , 8=@A. For \nexample, the first iteration adds edges between each node and its first nearest neighbor. 8 is incremented anytime pixel i \nappears as pixel js rth neighbor. This process continues until every pixel has been declared a neighbor by another pixel. Naturally, nodes located in regions of high spectral density appear as neighbors of other nodes more often than those in low density regions so their connectivity counts, 8, will be \nhigher. Once the stopping criterion has been met, the algorithm connects each node to its 8 neighbors given by F, \nwhere each pixel is guaranteed to be a member of a connected component of at least two pixels by the termination criterion. As a result, pixels with high 8 counts will be highly \nconnected and pixels with low 8 counts will be weakly \nconnected, corresponding to high and low density regions respectively. Like k-NN, this method generally produces unconnected graphs so post processing methods to ensure connectivity must be employed for analytical techniques requiring connected graphs. As intuitively appealing as the NNN construction may be, it does suffer from a pathological case that can produce prohibitively long execution times and much less useful graphs. Assume there is one node in the data far away from every other node. Given NNN iterates until each node has been declared a neighbor by another node, and the isolated node is \n(=0.005). In no instance did the test report normality under these loose conditions. Most codensity distributions were unimodal with a positive skew. However, z-score use under unimodal conditions is still a reasonable approximation. (a) (b) Fig. 1. Marked up unimodal codensity distribution. The right hand axis shows the number of node-specific connections for a 30-NN graph (k=30, six z-score regions, kmin=1, kmax=5). Codensity distribution vs. pixel specific connectivity (a) and sorted codensity (solid line) vs. the number of node specific neighbors (dotted line) (b). IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 5 so far away, it will take G 1 iterations until termination, \nproducing a complete graph. This sensitivity to noise and anomalous pixels led Ziemann et al. [7] to add another stopping criterion. Iteration is terminated if the node specific connectivity list 8 , is \nunchanged after examining the rth nearest neighbor. The algorithm as described in [7] is provided below where GGF is the rth nearest neighbor of pixel i, F is the set of \nr neighbors of the ith pixel, and J'E is the number of nodes \nthat have yet to be declared a neighbor by another node, i.e., those with 8 = 0. 1) Initialize \nE = 1, 8 = 0, GG' = , ' = , G = ||, J'0 = 0 2) Find nearest neighbors , calculate the ELM nearest neighbor, GGF, and set \n F = FN& {GGF}. 3) Identify reverse nearest neighbor counts , count the number of times i occurs in F, =\n1, , G and set 8 = RSTGU. \na. if J'E J'E 1 continue to 3b else end \nb. If such that 8 = 0 then increment r and return to step 2 else proceed to step 4. 4) Build graph Connect to its 8 nearest neighbors The additional stopping criterion (3a.) helps deter prohibitively long run times. However, changing a single node at each iteration could still produce long execution times, but this has not been observed in practice. Ziemanns variant is called the adaptive nearest neighbor (ANN) graph and is the starting point for many adaptive methods to follow. ANN may still produce isolated pixels and additional post processing may be required to ensure graph connectivity for some types of analyses. E. Edge Reweighting Methods The graph construction methods described in Sections II-A- D all create a graph, = ,., wherein edge weights, ) , \nare encoded by the metric used to determine distance (or similarity) to each node. These metrics are called primary metrics as they are used to determine initial edges of the graph. One may also change the edge weights based on some function or heuristic to reinforce particular properties of the primary metric space. In this study, we focus on changing edge weights (called edge reweighting) based on a measure of local spectral density, producing spectral-density weighted secondary metrics. Reweighting do not change the structure of the graph, only the weights assigned to the edges, so in essence they are not graph construction techniques per se, but are addressed as such for continuity of the discussion. Note some reweighting schemes we will encounter can sever edges by setting ) = 0, \nso they could be considered construction methods in their own right (Sections II-F and III-A). The non-iterative contextual dissimilarity measure (NICDM) introduced by Jegou et al. [37] rescales distances based on measures of each nodes local scale as shown in (2). This method has not been used on HSI data, but provides a nice introduction for multiple methods to come. ji ji jiij vvd\nvvNICDMw \n),( ),( == (2) The spectral Euclidean distance, , , is rescaled by the \ngeometric mean of the local scaling parameters for each pixel, a and b . Jegou defines the local scaling as the distance to the \nkth nearest neighbor, but we offer any of the codensity measurements described in Section II-C as viable local scale (a) (b) (c) Fig. 2. Example dataset displaying two clusters of different density (a), edges of a Delaunay triangulation weighted by Euclidean distance (b), and ZMP locally adaptive rescaling (c). Notice the increases similarity between nodes in the regions of similar density. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 6 metrics. Pixels i and j are therefore only similar if the spectral Euclidean distance between them is small relative each pixels local spectral scale3. Zelnik-Manor and Perona (ZMP) [27] introduce a locally adaptive scaling that transforms primary distance metrics into scaled affinities by taking the exponential of the negative squared NICDM as shown in (3), i.e., a radial basis function (also called a diffusion kernel) in spectral distance with parameters b and b . \n \n \n== ji ji jiij vvd\nvvZMPw 2),(\nexp),( (3) Parameters are defined as per (2), but the negative exponential results in a rescaled space wherein the new similarity, 0 0,1. Zelnik-Manor also used the distance to \nthe kth nearest neighbor, but again any scale determination method of Section II-C is possible. This method is also known as non-local means in the image processing literature if the sum of the weights for each pixel is normalized to one [40]. We model an example after that of Schnitzer et al. [28] to demonstrate the effectiveness of locally adaptive scaling. Fig. 2(a) displays a simple 2D grid consisting of two clusters of differing density; one existing within the other. A Delaunay triangulation is used to define edges between the vertices, with edge weights initially set to the Euclidean distance between the vertices. Note that a Delaunay triangulation is used to emphasize weight rescaling vice potential differences due to graph construction techniques (missing edges). Fig. 2(b) shows edges weighted by similarity, i.e., the shorter the distance, the more similar the nodes and the thicker the edge. Notice nodes in the less dense outer cluster (background) appear as dissimilar despite being quite similar (same average distances and density) to their surroundings. The thickest edges (shortest distances) are in the dense center cluster. Fig. 2(c) shows the resultant edge weights after the application of ZMP locally adaptive scaling. Notice the stronger relationship between pixels within each cluster and the weaker
edges in transition regions. F. Spatial/Spectral Methods Fan and Messinger [25] describe a graph-based hyperspectral image classification technique based on a split/merge paradigm using normalized cuts with a locally adaptive spatial/spectral graph. The spatial/spectral similarity graph is based on a Shi and Malik [26] construction composed of the product of feature similarity and spatial proximity terms. Fan and Messingers adaptation replaces the feature space term (left) with a ZMP variant using locally adaptive scaling as shown in (4). \n3 NICDM is not a distance metric as it only satisfies positivity and symmetry axioms, but not the triangle inequality, see [37]. \n\n \n\n \n \n \n \n= 2 2\n2 exp\n),( exp\nd ji jiij ji ij vv c vvd\nw \n (4) The left hand side of (4) represents a Gaussian weighted locally-scaled spectral Euclidean distance, i.e., a spectral diffusion function similar to that in the ZMP method. The local scaling parameters, a and b, are defined in [27] as the \ndistance to the kth nearest neighbor; however in this treatment the number of nearest neighbors, 8, is determined by the \nadaptive nearest neighbor method (Section II-D). The additional scaling term in the denominator of (4), R, is \nan integer indicating the number of common neighbors between nodes i and j. This offers some protection from joining disparate regions by increasing the weight between nodes in the same cluster. Fig, 3 shows two cases where the weight between AC is increased compared to that of AB despite being the same distance away because A and C have common neighbors. In Fig 3a, the shared neighbor adjustment drives down the weight for edge AB despite pixel A and B having the same density. Whereas in Fig 3b, the weight is reduced more due to the smaller relative density of pixel B to pixel A (bc <\nbe. The right hand side of (4) is a spatial diffusion (dampening) adjustment that performs two tasks: 1) it promotes connections between spatially proximal pixels (small ), \nenforcing spatial coherence present in imagery and 2) inhibits growth of larger disjoint scene-wide clusters despite any apparent spectral similarity. As such, the graph becomes overly segmented and must undergo a merging step to generate a classification map. The spatial dampening constant, b, limits the size of \nspatially contiguous regions and is the only user-defined parameter. Gillis and Bowles [29] encode both spatial and spectral information into weights associated with only spatial neighbors. Constructing the graph in this way reduces the number of edges and facilitates faster solutions due to sparser matrix operations. The weights are defined by spectrally- modified spatial diffusion kernel given by (5) for all pixels \nFig. 3. Weight adjustment based on common nearest neighbors [modified from 25]. Intuitively nodes A and C are more similar than nodes A and B due to community structure. This aspect is reinforced via use of shared nearest neighbors in determining the edge weights. (a) clusters of similar density separated in space and (b) close clusters of dissimilar density further amplifying separation due to the smaller scale associated with pixel B. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 7 within the r x r region centered on the pixel of interest. \n \n \n= \n 2 exp)exp(\nji ijij vv\nw (5) g denotes the spectral angle between and , h \nis the squared spatial distance, and is a user defined scaling parameter. The weighting has a similar general form to that described in Fan and Messinger, but the weights are only encoded for those pixels within the r x r spatial neighborhood. A spatial/spectral approach called locally weighted nearest neighbors is described by Mercovich in [13]. In this method, pixels are connected to their 8 = i + k nearest neighbors, \nwhere g represents the number of global neighbors determined by the k-NN algorithm (any of the k-NN methods previously described would suffice) and l represents the number of local neighbors confined to a window centered on the pixel. The spectral angle between the test pixel and all pixels within a user-defined local spatial neighborhood is computed and the l pixels with the smallest spectral angle are also connected to the test pixel. Fig. 4 provides a synthetic example indicating the local and global pixels with red triangles and green dots at the pixel center respectively. A pixels local neighborhood is indicated by a dotted black box centered on the pixel of interested. The best global neighbors may also be the best local neighbors, so each pixel is not guaranteed to have an out degree of k. This graph is also directed and must be made symmetric by one of the two methods previously discussed in Section II-B. Mercovich describes method performance with five local and 25 global neighbors. Increasing local connectivity in this manner facilitates segmentation, clustering, and classification if regions demonstrate spatial coherence. Additionally, using spectral angle within a local region may help connect pixels composed of similar materials but with varying illumination (in and out of shadow). III. NEW METHODS FOR HSI GRAPH CONSTRUCTION In this section, we describe several new spectral-density based graph construction techniques stemming from algorithms in the data mining literature. Any of the spatial weighting techniques discussed in Section II-F may also be applied along with the technique to generate spatial/spectral variants. A. Shared Nearest Neighbor (SNN) Graphs The SNN similarity introduced by Jarvis and Patrick [30] is based on the premise that similar nodes should have overlapping neighborhoods. Hence the similarity of two nodes, as measured by some primary similarity measure, is reinforced, or confirmed, by the presence of common (shared) neighbors. SNN is a nonlinear technique that can be very effective in the presence of clusters not well modeled by symmetric parametric distributions due to its ability to find regions of varying shape and density [30], and is widely used in the data mining community [31]. The strength of the similarity between two nodes may therefore be recast in terms of the number of shared neighbors, i.e., the higher the number of shared neighbors, the more similar the nodes. Given a vertex set V consisting of G =\n|| vertices and a neighborhood size k, where 8 m, let the k \nneighborhood set of vertex i be represented as 9 , \nand define the SNN similarity as the size of the neighborhood intersection between two nodes i and j (6). )()(),( jNNiNNjiSNN kk I= (6) Whereas the initial implementation of SNN used fixed neighborhood sets (constant k), we recognize asymmetric neighborhoods as simply a generalization resulting from the use of adaptive density-based methods. We therefore define the more general density-based adaptive SNN measure as ,)()(),( jNNiNNjiSNN kjki I= (7) where ki and kj are the size of the neighborhoods generated for vertices i and j respectively from any of the density-based node-connectivity techniques from Section II. A SNN cosine similarity [32] may also be defined and is given by ,\n),( ),cos(\nkjki jiSNN kjki IVIV\njiSNN ji \n= \n= (8) where IVv is the edge indicator vector for node v and ki, kj, and o , are as defined in (6) and (7). \nFrom an imaging spectroscopy perspective, whereas symmetric globular clusters may exist in isolated regions of uniform material type, the presence of significant mixing can result in asymmetrically extended non-globular regions in hyperspace rendering description by parametric forms difficult; hence the need to explore methods invariant to cluster shape. The concept of overlapping neighborhood counts was first \nFig. 4. Locally weighted nearest neighbors connects a pixel with seven global and two local neighbors [13]. This construct reinforces the spatial coherence found in imagery while permitting global connection to the most similar pixels. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 8 used in HSI graph construction by Fan and Messinger [25] to modify the strength of a Gaussian-diffusion spectral similarity measure derived from Euclidean distance (Section II-F). This treatment differs in that the spectral similarity is based entirely on SNN counts and variations thereof. Creation of the SNN graph is conceptually simple, but more computationally expensive than the methods discussed thus far due to intersection of nearest neighbor sets for counting shared neighbors. The SNN similarity is therefore a secondary metric generated from a primary distance (or similarity) metric. The steps required to generate a SNN graph based on the SNN similarity are given below. 1) Compute the pairwise (dis)similarity matrix A primary distance (similarity) measure is used to define initial edges. 2) Construct a mutual k-NN graph Mutuality is imposed to avoid edges crossing regions of differing density (cf. Section II-B) and decrease computation time through a reduction in the number of required set intersections. 3) Redefine edge weights with the SNN (secondary) metric \nThe number of neighbors shared by the two nodes becomes the new edge weight, replacing the (dis)similarity score from the primary metric. Note that initial edges can be
severed if o , = 0. There are many benefits of the SNN construct. First, SNN is built upon the k-NN relationship, which provides automatic density scaling because nearest is insensitive to local scale [20]. Secondly, as a secondary metric built upon shared neighbors, it can overcome limitations in primary distance metrics due to contrast loss in high dimensions [32]. Lastly, SNN has been proven to be resilient to the hub phenomenon affecting data mining in high dimensional spaces if used for distance prescaling [33]. Note that whereas the HSI extrinsic dimension (number of bands) can be on the order of hundreds, the intrinsic (or inherent) dimensionality is often much less, typically on the order of tens of dimensions (or less) as demonstrated in [8]. Lower spatial resolution HSI data, especially of urban scenes, generally has higher intrinsic dimension [8] so it is prudent to study methods more resistant to challenges associated with the curse of dimensionality. Conversely, as a secondary metric, SNN similarity is more computationally expensive to the point of being prohibitive if performing neighborhood intersection over every node. Calculating the SNN graph from every pixel takes pGh +\nGhkSiG time, where the quadratic is the result of the pairwise \ndistance calculation and the log term is from the intersection over the entire dataset. However, SNN construction can be performed in reasonable time if working from an initial mutual k-NN construct or other method to reduce the number of required intersections such as starting with a limited, but higher value for k or spatially limiting the pixels that can be connected [25]. In this case SNN is an edge reweighting scheme vice a primary metric scaling. Fig. 5 demonstrates the effectiveness of counting shared neighbors on the example Deluanay triangulation from Fig. 2. Notice the edge weights have been adjusted such that nodes in regions of similar density are more strongly connected whereas those in transition (intercluster) regions are deweighted. \nAs described above, edge weights are simply the number of shared nearest neighbors. However, this construct does not utilize any information about the ordering of nodes within neighborhood lists. Clearly two nodes that have the same closest neighbor are more likely to be similar than two whose shared neighbor is the closest for one point and farthest from the other. The SNN metric may be adjusted to include k-NN rank information [30], wherein edge weights are redefined as { }\n,)1()1( )()( \n ++=\njNNiNNv ij nkmkw\nI (9) where k denotes the size of the NN set, and m and n are the ranks (positions) of the common neighbors in and respectively, so ) 1, 8h4. Each \ncomponent of the summation in (7) has the same form, 8 r + 1. The first part produces a scalar inversely \nproportional to ranking, i.e., lower ranks result in higher scalars, but spans [0,k-1]. The addition of one aligns component contributions to [1,k], so that there are no zero components. The user may threshold the SNN weights as part of a clustering algorithm or leave the weights as is for operations requiring connected graphs in subsequent processing (e.g., target detection). In the latter case, there are fewer artificial connections created during post processing to ensure connectivity. Fig. 6 illustrates the utility of rank dependent weights with a simple toy example. Notice the simple SNN count produces the same edge weight of two for ) , )9 , and )9 despite the fact is not in the same cluster \nas and 9. The rank dependent SNN similarity measure shows that \n4 Ranked component contributions can also be added if multiplication is too severe [30]. Fig. 5. SNN rescaling of the Delaunay triangulation from Fig. 2. Notice the stronger relationships between intracluster nodes and weaker relationships between intercluster nodes. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 9 and 9 are much more similar than and or and 9, \nin line with our expectations. It is interesting to note that this particular situation is avoided by an initial construction that uses mutual k nearest neighbors, i.e., edges to node disappear because \n and 8. The mutuality constraint used in the construction of initial edges not only provides protection against edges spanning regions of different density, but also maintains a balance in nearest neighbor list size. Imbalanced nearest neighbor lists facilitate dissimilar nodes appearing more similar than those that are similar. For example, Fig. 7 shows a case where the neighborhood size and geometric configuration is such that there is an imbalance in the intersections between pairs of nodes. In this case, or 9 occupy a position in each others \nnearest neighbor lists. This reduces the number of possible nearest neighbors in the intersection by one for each node. Node doesnt have either and 9 in its nearest neighbor \nlist, hence has a larger number of nearest neighbors left from which to form a neighborhood intersection set with other nodes. This imbalance creates an extra term in the sum from (9) for which may result in a higher similarity score. In this \ncase, and 9 can be more similar to than to each other \n(edge ik is weighted from two common neighbors edges, where edges ij and kj are weighted from three). Note that the magnitudes of the imbalance effect decreases with increasing neighborhood size, so regions of low density are impacted the most e.g., lower density regions from adaptive nearest neighbor techniques. The SNN similarity variants above do not account for the distance (or similarity) between nodes either, only their overlapping neighborhoods and ranks. A node may have the same rank with respect to two other nodes, but have vastly different distances (similarities) to those nodes. In this case it seems appropriate that this node contributes differently to the SNN score for each of the nodes. A modified metric based on work by Moellic et al. [34] uses the shared NN count, rank, and node similarity given by { }\n,)1()1( )()( \n ++=\njNNiNNv jvivij dsimnkdsimmkw\nI (10) where dsim is a dissimilarity measure between nodes. The more dissimilar the nodes, the larger the subtracted term, hence the smaller the component contribution. Similar nodes (low dissimilarity, small distance) result in smaller values being subtracted from k, increasing the component contribution. In this work, the cosine distance will be used as the dissimilarity metric to promote higher scores for those neighbors that may have varying illumination. The sensitivity of cosine distance to dark pixel selection is mitigated by the fact only nearest neighbors are subject to the metric. The asymmetric neighborhood variants are given by simply replacing the ks in (9) and (10) by 8 and 8 respectively. B. Mutual Proximity Graphs Introduced by Schnitzer et al. [28], mutual proximity (MP) transforms distances into similarities such that pixels with similar nearest neighbors are brought closer together, whereas those with dissimilar nearest neighbors are pushed farther apart. This is akin to local scaling except mutual proximity is a global vice local transformation. To calculate MP, the distances between and all other \nnodes , ? , are assumed to originate from a known \nprobability density function (pdf). Using a nodes distance distribution, pdf(?), any distance, ?, can therefore be \ninterpreted as the probability is a neighbor of by ),(1)(1)( ijijij CDFPP ==> (11) where tuv is the cumulative distribution function of pdf(?. \nThe probability a random node is a nearest neighbor of node i therefore increases with decreasing distance (codensity metrics can also be used). This is represented graphically in Fig 8 for a normally distributed pdf. \nFig. 7. The lack of an initial mutual constraint can lead to unexpected neighborhood intersection size. Vertices and 9 are mutual neighbors, so \nthey have one fewer (3) neighbors available from which to form an intersection than node which has four. Fig. 6. Rank-dependent SNN similarity uses k-NN rank information to refine the similarity measure beyond simple counts alone. Notice that , , and 9 all share the same SNN count prior to reweighting despite the \napparent community structure, whereas weights are more representative of community structure after reweighting. Dotted circles touching the edge of a node denote its 3-NN. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 10 Thus, the probability a randomly drawn node, 9, is closer to \n than can be determined by simply checking if w? >\n?9 > w? > ?9. The pdfs for and are naturally different hence w? >\n? and w? > ? will not be the same. This is similar to the \ndirected relationships that emerge in k-NN graphs where may be a nearest neighbor of , but may not be a nearest \nneighbor of . Calculating mutual proximity is conceptually \nsimple; count the number of nodes, v, having distance > ? to \nboth and and then divide by the number of nodes to \nnormalize the probability (12) [28]. Obviously ? = ?. n vv\nMP
jijvijiv ij }:{}:{\n)( \n >>\n= I\n (12) A mutual proximity reweighting for the Delaunay example from Fig. 2 is presented in Fig. 9. Counting exercises on large datasets can be computationally expensive, therefore we wish to find efficiencies wherever possible. For example, if we assume independent codensity distributions, then mutual proximity can be easily calculated via the product of the marginal distributions as ,)()()( jijijiijI PPMP >>= (13) where the subscript I indicates independent marginal distributions. Independence did not adversely affect results on standard machine learning datasets in [28]. Similar tests on HSI data are discussed in Section IV. Euclidean distance is approximately normal due to the central limit theorem if features (bands) are generated from independent and identically distributed data (i.i.d.) [37]. Whereas most data is not i.i.d., Schnitzer et al. [28] point out this approximation increases in accuracy with increasing intrinsic dimensionality. The empirical distribution may always be used if the data are not reasonably modeled by an analytical distribution, but at the expense of computation time. The computational complexity of mutual proximity is pGh due to the evaluation of all pairwise distances and \nintersections. Rescaling takes additional time, but if we can assume the marginal distributions follow a functional form, we can use a pixel subset, S, to estimate the distributional parameters (o G). This reduces the number of rescaling \ncalculations to S*n, resulting in linear rescaling complexity. IV. GRAPH CONSTRUCTION PERFORMANCE We examined the performance of many graph construction techniques described in Sections II and III to determine which algorithms best preserve community structure of the data by answering four questions. Which method is best for symmetrifying adjacency (or \naffinity) matrices: mutuality or symmetry? Are spectral-density based adaptive construction \ntechniques better than fixed neighborhood sizes for the same number of edges? Does edge reweighting after edge selection improve \nthe community structure of neighborhood lists? Does prescaling primary metrics prior k-NN graph \nconstruction improve performance? Algorithms described for instructional purposes only were not evaluated. A. Metrics A simple majority-rules k-NN classification is used to test the performance of each graph construction technique and a summary confusion metric representing the percentage of incorrect class assignments is reported for each combination of image and graph type5. Ties were broken by assignment to the class with the shortest distance from the test pixel. Whereas this metric establishes summary classification \n5 We use the k-NN classifier as a metric indicating the health (or uniformity) of k-NN lists, not to achieve the best absolute classification accuracy. Fig. 8. The probability a random node with a given distance is closest to node i is given by the shaded area to the right, so node j, with ? = x b units \nfrom node i has a mutual probability of ~83.3%. Fig. 9. Mutual proximity rescaling of Delaunay triangulation from Fig. 2. Notice the stronger relationship between intracluster nodes and weaker relationships between intercluster nodes. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 11 performance for each graph construction technique, it shows limited difference between algorithms starting with the same set of initial edges, i.e., many of the adaptive techniques discussed in Sections II and III start with an ANN graph. As such, their k-NN lists are identical so their majority-rules scores are the same (tie results may differ based on the metric). The only difference between these graphs are the edge weights after post processing, so these are referred to as edge reweighting schemes and produce secondary weights (metrics). To circumvent this problem, an additional test examines the structure of the k-NN list themselves. The simplest form of this test assigns a score to each nearest neighbor (j) based on its rank in pixel is k-NN list as 8 \nE\"G8 + 1, . The rank-based pixel scores are summed \nand normalized to produce values in the interval 0, 8. \nScaling to 8 ensures pixels with high similarity to many \nneighbors are given more weight than pixels with high similarity to small number of neighbors. Edge reweighting methods such as ZMP, MP, and SNN reshuffle the order of k-NN lists such that spectrally similar pixels more aligned with the density of the test pixel move closer whereas those in regions of differing density move farther away. As such, the above metric characterizes reshuffling by increasing the overall score when pixels of the same class as the test pixel move to lower ranks (closer to the test pixel) and dissimilar pixels move to higher ranks (farther away). While intuitively appealing, the metric does suffer from a shortcoming related to use of integer ranks. Two pixels that change ranks due to extremely small differences in their secondary edge weights will be assigned disproportionate changes in score due to integer ranking. Additionally, the metric is insensitive to the case when pixels change weights dramatically, but retain their current ranking. To combat both disproportionate changes in scoring or lack of changing ranks, an additional step is taken during metric construction. The first and last scores (ranks) are locked at the number of neighbors for the test pixel 8, and one \nrespectively. All pixels that fall in between are interpolated to their floating-point positions in rank space spanned by the first and last pixels. This interpolated rank is then used as the pixel score. In this way, pixels that change rank due to small differences in secondary weights are assigned scores that are virtually identical. This adjusted rank metric also handles the case when pixels retain their original rankings but shift relative to the test pixel, changing their resultant scores even though the ranks are unchanged. The improved (adjusted rank) metric is illustrated in Fig. 10 for a pixel with 19 neighbors. As can been seen in Fig. 10, the adjusted rank scores of the two leftmost pixels are virtually the same because their distances from the pixel of interest are nearly identical. This is not true of the rank-only metric that shows an integer separation in score. Additionally, there appears to be a separation between nearest neighbors into at least two clusters. Those in the cluster closest to the test pixel are assigned much larger relative weights than those pixels appearing to the right of the apparent cluster division (bars indicate the magnitude of the difference). Note that this metric is appropriate for NN lists of the same size, so this will only be used for the edge reweighting tests. A simpler neighborhood health metric that overcomes the requirement for the same sized NN lists is the y-edge ratio, \ndefined as the number of edges between vertices with differing class labels normalized by the number of edges in the graph [39]. Lower scores are thus indicative of more uniform NN lists. This metric is good for measureing changes in global k- NN health from prescaling tests as it quantifies the change in number of edges to similar pixels without being influenced by weighted ranks as above, which can be problematic comparing NN lists of differing sizes for the same pixel, e.g., ANN with prescaled metrics. Additionally, one may simply count the number of pixels with improved neighborhood health scores from any metric. While not indicative of the degree to which any edge weight changed, this metric gives a good indication of the number of pixels impacted by reweighting or rescaling schemes. \nFig. 10. Rank-based and adjusted rank metric for evaluating the structure of k-NN lists. Notice that integral rank-based adjustments artificially increase node separation between the first two pixels, whereas fractional positions achieve weightings in line with node separation indicated by the distance metric. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 12 B. Data Several datasets with substantial ground truth coverage acquired from the Purdue Multispec website [35], the Telecommunications and Remote Sensing Laboratory, Pavia University via the Grupo de Inteligencia Computacional (GIC) University of Pas Vasco, Spain website [36], and the National Institute of Standards and Technology (NIST)-Mitre Corporation partnership [38] were used for the performance evaluation (Table I). Atmospheric absorption bands were removed from all airborne datasets prior to evaluation. Some images were subsetted around regions of dense ground truth coverage to avoid unneeded calculation or reduced in scale by nearest neighbor resampling to increase spatial diveristy. An example data set and associated ground truth map are shown in Fig. 11(a) and (b) respectively. Unclassified ground truth pixels are not evaluated, but pixels assigned to the unclassified class by the k-NN classifier are. Graph construction methods are penalized for this occurrence despite the fact these could be correct classifications, i.e., it is possible unclassified pixels are the same material as the test pixel, but are simply not recorded in the ground truth map. The number of pixels assigned to the unclassified class is algorithm dependent, so those pixels are included to ensure a consistent metric. C. Results We present several studies addressing the
questions discussed at the start of Section IV to determine graph- construction practices required to promote the health of nearest neighbor lists. Adjacency Symmetrification Method Recall, we restricted ourselves to simple graphs hence all edges need to be bidirectional (or undirected). Two methods were described in Section II-B for converting asymmetric (directed) adjacency matrices into symmetric (bidirectional or undirected) variants; symmetry and mutuality. The symmetry method forces all directed edges to be bidirectional, while the mutuality constraint only retains existing bidirectional edges. Confusion metric comparison for graphs having symmetric and mutual variants provides a direct measure of method performance for any k. Differential confusion scores (symmetric minus mutual confusion) for graph and image combinations are provided in Table II. Seventy-one percent of the tests display an increase in performance (positive differential confusion) when using mutual vs. symmetric variants of the same graph type. Symmetry outperforms mutuality in the Salinas A and uScene examples for some graphs, but by smaller margins than the mutuality gains for most other graphs. The Salinas A and uScene scenes are uniform scenes with limited complexity suggesting that symmetry may have a slight advantage when scenes have large regions of similar materials. The largest differential confusion scores (upwards of 13%) are for the fixed k graph on more complex scenes. The k values shown in Table II are the maximum 8 returned by the ANN algorithm, i.e., the fixed k is set \nsuch that all pixels have the same out degree as the maximum ANN 8. Using the average 8 value from ANN produces \nsimilar results, but the percentage of tests displaying positive confusion differential drops to 63% (all graph scores for Salinas A and uScene are now negative) and the maximum differential confusion drops to ~9%. Neighborhood sizes were on the order of 25 to 41 for the average 8 tests. \n(a) \n(b) Fig. 11. Purdues Indian Pines data set used to assess classification accuracy, (a) true color image (b) class map. Black regions indicate unclassified pixels that were not evaluated. TABLE I CLASSIFICATION ACCURACY DATA SETS Dataset Sensor Data Type \nGSD [m] \nBands Source Salinas A AVIRIS radiance 3.7 204 GIC Salinas AVIRIS radiance 3.7 204 GIC Indian Pines AVIRIS radiance 20 193 Purdue Pavia ROSIS reflectance 1.3 102 GIC Pavia Univ. ROSIS reflectance 1.3 102 GIC uScene SOC710 reflectance 1.3E-4 80 Mitre The reference section provides websites for downloading test data. Mitre provided data is from a partnership with NIST. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 13 \nTable II indicates that construction techniques enforcing adjacency symmetry by mutuality vice superset symmetry are superior for capturing community structure in HSI data. This result is intuitive based on discussion in Section II indicating the mutuality constraint provides protection from edges crossing regions of disparate densities, therefore promoting cluster uniformity. However, less intuitively obvious is the possible loss of connectivity following mixing trends present in HSI data, which appears to be less important than the gain from preventing edges crossing regions of disparate density for these data. Note that ground truth data is often not completely characterized and many transition regions are often set to unclassified. The magnitude of confusion reduction is correlated with scene complexity suggesting high dimensional complex data benefits more from the mutuality-based construction. Density-weighted construction methods generally have lower differential confusion scores than the fixed k method indicating spectral-density weighting does a better job connecting intracluster pixels so there is less to be gained from the mutuality constraint. Lower differential confusion by the adaptive techniques is due to higher edge allocation in denser regions more likely consisting of the same material, whereas pixels in less dense regions are assigned fewer edges. Additionally, the general pattern of reduced differential confusion scores moving left to right in Table 1 is consistent across a broad range of k values where ANN typically has the smallest differential confusion, followed by the DW k-NN techniques, and then fixed k-NN suggesting fixed k nearest neighbor lists have more intercluster edges than their adaptive counterparts. Many of the graph construction techniques discussed in Sections II and III enforce mutuality, hence already take advantage of this potential increase in performance. Further analyses will be largely restricted to mutual variants due to these results. Adaptive vs. Fixed Nearest Neighbor Lists The previous section quantified the benefit attained by invoking mutuality for adjacency matrix symmetrification; however those tests did not ensure the same number of edges for each graph construction method. This section investigates adaptive and fixed k method effectiveness while ensuring the number of edges are approximately the same before mutuality is invoked, i.e., the average number of edges from the ANN algorithm, 8, is assigned as the fixed k so each adjacency \nmatrix has essentially the same sparsity. Note that fixing the number of edges for the DW k-NN techniques involves distributing the total number of edges from ANN to each pixel based on the images codensity distribution and is not as simple as assigning 8 to kmax for those algorithms. \nInvestigation of the y-edge ratio with the aforementioned 8 assignments is used to demonstrate differences in the \nnumber of intercluster edges resulting from each algorithm. Table III displays differential y-edge ratios for each method \nacross the same six datasets, where the differential is taken as the fixed k method ratio minus the adaptive method y-edge \nratio. Positive values in the right side of Table III indicate the adaptive technique creates fewer intercluster (more intracluster) edges than the fixed k technique which enables higher classification accuracy. \nThe three rightmost columns of Table III show that adaptive techniques have lower y-edge ratios than fixed k techniques. \nThis was expected given these algorithms allocate more edges in dense similar regions hence increasing the probability of connecting intracluster nodes. An interesting result is the performance of the ANN algorithm which has a very small difference in the number of intercluster edges. The rate of intercluster edge additions has exceeded that of the fixed k method indicating we are in a regime by which performance of the ANN algorithm may actually begin to decrease with respect to the fixed k methods. This effect increases with decreasing k, but at the expense of a larger number of isolated subgraphs. Taken as a whole, we see that neighborhood health is higher for the adaptive vs. fixed neighborhood methods for the same adjacency-matrix sparsity as evidenced by 83% of the tests displaying positive y-edge ratios. The average confusion score \nis provided in Table III to assess the benefit achieved from lower y-edge ratios, where we have subtracted the adaptive \nneighborhood confusion scores from the fixed confusion scores and summed over all three density weighted methods. Increased neighborhood health facilitates decreased confusion as shown in the average differential confusion score column for the Pavia and Pavia University scenes. However, the fixed k method does outperform the more complicated adaptive methods on the less complex data sets of Salinas A and Scene, TABLE II ADJACENCY SYMMETRIZATION BY MUTUALITY VS. SYMMETRY Dataset k k-NN DW k-NN \nDW k-NN w/CDF \nANN Salinas A 71 0.01 0.00 -0.01 -0.01 Salinas 116 0.03 0.02 0.01 0.00 Indian Pines 97 0.06 0.04 0.04 0.02 Pavia 196 0.05 0.04 0.01 0.01 Pavia Univ. 106 0.13 0.10 0.05 0.05 uScene 220 0.01 -0.01 0.00 -0.01 Table values represent the differential confusion between symmetric and mutual variants of the same graph creation method. A higher percentage of positive values indicates the mutuality criterion outperforms the symmetric criterion. TABLE III ADAPTIVE VS. FIXED NEIGHBORHOOD SIZES Dataset \nFixed k Avg. Conf. \nDW k-NN DW k-NN w/CDF \nANN Salinas A 25 -0.01 0.01 0.03 0.00 Salinas 33 0.00 0.02 0.06 0.01 Indian Pines 30 0.00 0.01 0.04 0.00 Pavia 41 0.01 0.03 0.08 0.02 Pavia Univ. 29 0.02 0.01 0.03 0.00 uScene 34 -0.02 0.01 0.01 0.01 Table values represent the differential y-edge ratio between fixed and \nadaptive graph variants. A high percentage of positive values (83%) indicates the adaptive method selects fewer intercluster edges; hence promoting better classification performance. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 14 also supporting use of a fixed k methods for less complex, more uniform scenes. The Salinas and Indian Pines datasets are of intermediate complexity, and show no change in confusion score despite the apparent healthier neighborhoods indicating more edges were added to pixels that would have already been declared a given class; hence introducing additional complexity and computation time for no added benefit. These results suggest the graph construction algorithm for classification tasks should be chosen based on data characteristics instead always selecting the same method. Edge Reweighting Effectiveness Simple confusion tests only demonstrate classification performance, therefore cannot be used to evaluate the impact of edge reweighting because the nearest neighbor lists (and hence the classification results) are the same. Examination of the structure of the k-NN
lists themselves provides evidence pixel weights in each neighborhood list have improved via edge reweighting techniques such that distances (similarities) of pixels like the test pixel are decreased (increased), whereas those unlike the test pixel are increased (decreased). The metric used to perform this analysis was presented in Section IV-A, wherein the structure of the neighborhoods themselves is investigated with respect to cluster uniformity and separation when class labels are available. Seven graph construction techniques making use of edge reweighting were applied to the six images from our previous studies; an eighth, ANN, was used as an unweighted control. Both the weighted rank and improved pixel count metrics introduced in Section IV-A produced effectively the same conclusionthat edge reweighting (post edge selection) is detrimental to the community structure of the neighborhood lists. In short, more pixels had the structure of their nearest neighbor lists degenerate instead of improve. In one case, Indian Pines, upwards of 23% of the ground truth pixels with labels had their community structure decline as shown in Fig 12. The leftmost side of the bars in Fig. 12 is read down and the inset black bar is read up, where the lower and upper x axes are the percentage of pixels with improved neighborhood health scores and the average rank-adjusted scores respectively. Algorithms are labeled to the left and data sets to the right. Some patterns are evident in Fig. 12. ANN occupies six of the top seven positions \nindicating NN lists are healthier without reweighting. SNN variants are closer to the top of the list showing \nthe power of counting shared neighbors, but on average, are no better than not reweighting. The most complex scenes (Pavia and PaviaU) occupy \nmore of the upper positions suggesting there is more relative benefit for complex scenes. Reweighting techniques utilizing codensity typically \noffer poorer performance. A graph construction method that reinforces inherent community structure facilitates accurate analysis; however in this case it appears edge reweighting, by any method, does not improve community structuresurprising. This is contrary to what may be inferred from other papers [25][29]. However, graph construction methods used in those analyses was always followed by an analysis algorithm, i.e., the viability of the new graph construction technique itself was not the focus of the effort. Results in this section suggest those methods may perform better with a simpler graph construction method; avoiding the additional complexity and computation time. \nAnomaly and target detection methods rely more heavily on weighted inter-relationships between pixels than classification algorithms. In order to more fully assess graph-construction method impacts on these algorithms, intracluster manifold distance measures and connected component structure will need to be evaluated. This is the topic of a future paper continuing this analysis. \nFig. 12. Edge reweighting effectiveness plotted as the percentage of valid ground truth pixels with improved weighted-rank scores (post reweighting minus per reweighting) for many edge reweighting methods across six datasets. The upper x axis represents the average rank-adjusted score and is represented by the inset black bars. In nearly all cases, edge reweighting is detrimental to the health of the community structure in the data. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 15 Primary Metric Prescaling or Edge Reweighting In Section II, we discussed edge reweighting and primary metric scaling. The former is applied to edges that were previously determined, whereas the latter is applied to primary metrics prior to edge selection; all examples shown thus far are based on reweighting preselected edges. Scaling metrics prior to edge selection facilitates inclusion of other information density and/or shared neighborsin the ranking process, so k- NN lists generated from prescaled primary metrics will differ. Pixels in regions of similar density and spectral similarity should be brought closer together, whereas others are pushed away. As appealing as this may be, it often requires a primary metric for all pairwise distances (or similarities). This takes pGh time so is not feasible even for modest size images \nunless approximations can be made. However, to be complete, it is reasonable to explore how much performance is potentially sacrificed for speed by performing a primary metric scaling on a full primary metric matrix. The same six images and four graph construction techniques from the first two studies are used to demonstrate differences in the number of intercluster edges resulting from ZMP prescaling and its effect on classification accuracy. Fig. 13 displays differential y-edge ratios plotted against differential confusion \nscores, where the differentials are taken as the no prescaling ratio value minus the ZMP prescaled values. \nAs can been seen in Fig 13., scaling the primary distance metric via ZMP prior to graph construction is actually detrimental to the health of neighborhood lists, i.e., most tests display a negative y-edge ratio (quadrants II and III) indicating ZMP prescaling creates more intercluster (fewer intracluster) edges than simply using the primary metric. This is consistent with the results in the previous section, but surprising given the success of density weighting in other fields [27][28]. The Fig 13. Scatterplot agrees with theory, suggesting a positive correlation between differential y-edge ratios and \ndifferential confusion. The slope of the regression line through these data is 0.51 indicating introduction of some new false edges is tolerable until a noticeable change in confusion ratio is observed. Perfect correlation would only result in population of quadrants I and III in Fig. 13, but given the addition and deletion of edges may or may not change class assignments, we acknowledge differential confusion is variable based on the distribution of edges amongst the pixels. The mutual proximity method with the Gaussian independent assumption performed much worse than the ZMP method indicating the Gaussian assumption is not appropriate for these data, which is to be expected given pixels do not exhibit normal distance distributions despite theoretic asymptotic behavior indicated by the central limit theorem. To explore this concept further, prescaling by mutual proximity with the empirical distribution was tested on the Salinas A and Indian Pines data. Note that empirical mutual proximity uses the distribution of the data itself to determine the probability of pixels being neighbors and is not impacted by user selection of some arbitrary number of neighbors to average. Empirical mutual proximity demonstrated the highest performance of all prescaling methods (albeit, only on par with no prescaling) indicating that perhaps codensity-based measures are not best representation of local scale for hyperspectral data. This result warrants more study given it indicates a potential expectation change compared to previous efforts. Flexer and Schnitzer [28] studied a broad range of public machine learning datasets spanning low to very high intrinsic (hundreds) and extrinsic (thousands) dimensionality. Lower intrinsic-dimensional data in their results displayed a similar occurrence where there can be no gain, and often a reduction in performance for lower intrinsic dimensionality data (however, shown not to be statistically significant in their study). HSI typically exhibits low intrinsic dimension (single digits to tens of dimensions) [8], so it possible we are seeing the same effect here. Their results did show significant improvement for higher intrinsic dimensionality data, so additional testing is warranted on more diverse higher dimensionality data. The choice of edge reweighting or metric prescaling (for appropriate imagery) may be decided by the number of pixels to be analyzed since quadratic run time is often prohibitive for even modest sized images. However, some of these routines execute quicker using fast nearest neighbor routines by first returning a larger number of neighbors than required followed by edge reweighting and subsequent edge selection. V. CONCLUSIONS AND PATH FORWARD This paper has provided a survey of many common HSI graph construction techniques with emphasis on their characteristics related to common hyperspectral analyses. The Fig. 13. Differential y-edge ratio plotted versus the differential confusion \nscore; differentials are taken as no prescaling minus ZMP density-weighted prescaling. Negative values for either axes indicates prescaling with ZMP is detrimental to neighborhood health. Most scene and graph type combinations shown display a negative y-edge ratio stating more intercluster pixels are \nconnected by ZMP prescaling. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 16 shared nearest neighbors and mutual proximity techniques from the data mining literature were also introduced and described along with several variants of those basic techniques. Many graph construction practices were analyzed to reveal characteristics most beneficial to the health of neighborhood lists. Specifically, invoking mutuality was shown to be superior to symmetry for symmetrifying adjacency matrices except in scenes with low complexity. Adaptive density weighted graph- construction methods outperform fixed neighborhood graphs in complex scenes, but also shown to be poor options for scenes with low scene complexity. Advanced reweighting and primary metric prescaling techniques were shown to actually damage the community structure of spectral graphs, so are detrimental to classification tasks. Neighborhood health metrics are good indicators for classification related tasks, but not complete for analyses
that utilize edge weights or require connected graphs. As such, future efforts will quantitatively explore graph characteristics more important to hyperspectral anomaly and target detection, detailing which construction techniques are best suited for each task through analysis of the connected component structure and manifold distances on these graphs. REFERENCES [1] J. Schott, Spectroscopic Image Analysis (chapter10) in Remote Sensing \n The Image Chain Approach 2nd ed., Oxford University Press, 2007, p. 414. ISBN 978-0-19-517817-3. [2] D. Manolakis, D. Marden, and G. Shaw. Hyperspectral Image Processing \nfor Automatic Target Detection Applications. Lincoln Laboratory Journal. vol 14(1), pp. 79-116, 2003. Available: http://www.ll.mit.edu/publications/journal/pdf/vol14_no1/14_1hyperspec tralprocessing.pdf [3] D. Manolakis,, R. Lockwood, T. Cooley, and J. Jacobson, \"Is There a \nBest Hyperspectral Detection Algorithm?\" SPIE Newsroom (2009). [4] S. Matteoli, M. Diani, and G. Corsini, \"A tutorial overview of anomaly \ndetection in hyperspectral images,\" IEEE Aerospace and Electronic Systems Magazine, vol. 25, no. 7, pp. 5-27, 2010. [5] M. Eismann,. Hyperspectral Image Classification (chapter 13) & \nHyerspectral Target Detction (chapter 14), in Hyperspectral Remote Sensing. Bellingham, WA: SPIE, 2012. [6] A. Schlamm and D. Messinger, An empirical estimate of the \nmultivariate normality of hyperspectral image data, in Proc. of the SPIE 8048, Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XVII, 80481J (May 20, 2011), pp. . doi:10.1117/12.881642. [7] A. Ziemann and D. Messinger, Hyperspectral target detection using \ngraph theory models and manifold geometry via an adaptive implementation of locally linear embedding, Proc. SPIE. 9088, Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XX, 90880B. (June 13, 2014), pp. . doi: 10.1117/12.2050382. [8] A. Schlamm, R. Resmini, D. Messinger, and B. Basener, A comparison \nstudy of dimension estimation algorithms, in Proc. of the SPIE 7695, Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XVI 76952D (April 23, 2010), pp. . doi: 10.1117/12.849125. [9] J. W. Boardman, Automating spectral unmixing of AVIRIS data using \nconvex geometry concepts, Summaries of the Fourth Annual JPL Airborne Geoscience Workshop, vol. 1, pp. 1114, Jet Propulsion Laboratory, Pasadena, CA, 1994(3). [10] N. Keshava, A Survey of Spectral Unmixing Algorithms, Lincoln \nLaboratory Journal, vol 14(1), pp. 55-78, 2003. http://www.ll.mit.edu/publications/journal/pdf/vol14_no1/14_1survey.pdf [11] C. Bachmann, T. Ainsworth, R. Fusina, Exploiting manifold geometry \nin hyperspectral imagery. IEEE Transactions on Geoscience and Remote Sensing, Vol:43, Issue:3, 2005, pp 441454. DOI: 10.1109/TGRS.2004.842292. [12] C. Bachmann, T. Ainsworth., and R. Fusina, Improved Manifold \nCoordinate Representations of Large-Scale Hyperspectral Scenes. IEEE Transactions on Geoscience and Remote Sensing, Vol:44, Issue:10, Part 1, 2006, pp 2786 2803. DOI: 10.1109/TGRS.2006.881801. [13] R. Mercovich, J. Albano, and D. Messinger. \"Techniques for the graph \nrepresentation of spectral imagery.\" presented at Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS), 2011 3rd Workshop on. IEEE, 2011. [14] D. West,, Fundamental Concepts, in Introduction to Graph Theory, 2nd \nEd. Prentice Hall, 2001, pg 2. ISBN: 0-13-014400-2. [15] P. Kontschieder, M. Donoser, and H. Bischof, \"Improving affinity \nmatrices by modified mutual kNN-Graphs.\" 33rd workshop of the Austrian association for pattern recognition (AAPR/OAGM). 2009. [16] U. von Luxburg, \"A tutorial on spectral clustering,\" Statistics and \nComputing, December 2007, Volume 17, Issue 4, pp 395-416. [17] A. Hinneburg, C. Aggarwal, and D. Keim. \"What is the nearest neighbor \nin high dimensional spaces?\" in Proc. Of the 26th International Conference on Very Large Databases, Cairo Egypt, 2000, 99. 506-515 (2000). [18] C. Merkwirth, U. Parlitz, and Werner Lauterborn. \"Fast nearest-neighbor \nsearching for nonlinear signal processing.\" Physical Review E 62.2 (2000): pp 2089-2097. [19] J. Albano and D. Messinger, \"Euclidean commute time distance \nembedding and its application to spectral anomaly detection,\" in Proc. SPIE Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XVIII, 83902G (May 8, 2012), pp. . doi: 10.1117/12.918411. [20] L. Ertz, M. Steinbach, and V. Kumar, \"Finding clusters of different \nsizes, shapes, and densities in noisy, high dimensional data.\" In Proc. of SIAM International Conference on Data Mining, 2003. [21] K. Kameshwaran and K. Malarvizhi, \"Survey on Clustering Techniques \nin Data Mining.\" International Journal of Computer Science and Information Technologies (2014): 2272-2276. [22] D. Francois, V. Wertz, and M. Verleysen, \"The Concentration of \nFractional Distances,\" Knowledge and Data Engineering, IEEE Transactions on, vol.19, no.7, pp.873,886, July 2007. doi: 10.1109/TKDE.2007.1037. [23] X. Zou, and Q. Zhu, \"Adaptive neighborhood graph for ltsa learning \nalgorithm without free-parameter.\" International Journal of Computer Applications 19.4 (2011): 28-33. [24] A. Ziemann, D. Messinger, and J. Albano, \"Target detection performed \non manifold approximations recovered from hyperspectral data,\" in Proc. SPIE Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XIX, 874319, (May 18, 2013), pp. . doi: 10.1117/12.2015780. [25] L. Fan and D. Messinger, Graph based hyperspectral image \nsegmentation with improved affinity matrix, in Proc. SPIE. 9088, Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XX, 908802. (June 13, 2014), pp. . doi: 10.1117/12.2050397. [26] J. Shi and J. Malik, \"Normalized cuts and image segmentation,\" Pattern \nAnalysis and Machine Intelligence, IEEE Transactions on , vol.22, no.8, pp.888,905, Aug 2000. [27] L. Zelnick-Manor and P. Perona, Self-tuning spectral clustering, in \nAdvances in Neural Information Processing Systems (NIPS), pages 1601- 1608. MIT Press 2004. [28] D. Schnitzer, A. Flexer, M. Schedl, and G. Widmer. \"Local and global \nscaling reduce hubs in space.\" The Journal of Machine Learning Research 13, no. 1 (2012): 2871-2902. [29] D. Gillis and J. Bowles, Hyperspectral image segmentation using \nspatial-spectral graphs, in Proc. SPIE. 8390, Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XVIII, 83901Q. (May 08, 2012), pp. . doi: 10.1117/12.919743. [30] R. Jarvis and E. Patrick. \"Clustering using a similarity measure based on \nshared near neighbors.\" Computers, IEEE Transactions on 100, no. 11 (1973): 1025-1034. [31] A. Patidar, J. Agrawal, and N. Mishra, \"Analysis of different similarity \nmeasure functions and their impacts on shared nearest neighbor clustering approach.\" International Journal of Computer Applications 40, no. 16 (2012). [32] M. Houle, H. Kriegel, P. Krger, E. Schubert, and A. Zimek, \"Can shared-\nneighbor distances defeat the curse of dimensionality?\" in Scientific and Statistical Database Management, pp. 482-500. Springer Berlin Heidelberg, 2010. http://www.ll.mit.edu/publications/journal/pdf/vol14_no1/14_1hyperspectralprocessing.pdf\nhttp://www.ll.mit.edu/publications/journal/pdf/vol14_no1/14_1hyperspectralprocessing.pdf\nhttp://www.ll.mit.edu/publications/journal/pdf/vol14_no1/14_1survey.pdf IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. xx, NO. yy, MONTH 201x. DOI:xxxx Approved for Public Release; Distribution Unlimited. Case Number 16-3868 \n 17 [33] A. Flexer and D. Schnitzer. \"Can shared nearest neighbors reduce \nhubness in high-dimensional spaces?\" In Data Mining Workshops (ICDMW), 2013 IEEE 13th International Conference on, pp. 460-467. IEEE, 2013. [34] P. Mollic, J. Haugeard, G. Pittel, Image Clustering Based on a Shared \nNearest Neighbors Approach for Tagged Collections, in Proc. of the 2008 international conference on Content-based image and video retrieval, pp:269-278 ISBN:978-1-60558-070-8 , 2008. [35] M. Baumgardner, L. Biehl, D. Landgrebe, 220 Band AVIRIS \nHyperspectral Image Data Set: June 12, 1992 Indian Pine Test Site 3. Purdue University Research Repository. doi:10.4231/R7RX991C https://purr.purdue.edu/publications/1947/1. 2015. [36] Grupo de Inteligencia Computacional (GIC) University of Pas Vasco, \nSpain. HSI Ground Truth Website http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Se nsing_Scenes [37] H. Jegou, C. Schmid, H. Harzallah, and J. Verbeek. \"Accurate image \nsearch using the contextual dissimilarity measure.\" Pattern Analysis and Machine Intelligence, IEEE Transactions on 32, no. 1 (2010): pp 2-11. [38] D. Allen, R. Resmini, C. Deloye, and J. Stevens, A microscene approach \nto the evaluation of hyperspectral system level performance. In Proc. of the SPIE, Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XIX, S.S. Shen and P.E. Lewis, eds., v. 8743, doi: http://dx.doi.org/10.1117/12.2015834, Baltimore, MD, 29 April-3 May, 2013. [39] K. Ozaki, M. Shimbo, M. Komachi, and Y. Matsumoto, \"Using the \nmutual k-nearest neighbor graphs for semi-supervised classification of natural language data.\" In Proc. of the fifteenth conference on computational natural language learning. Association for Computational Linguistics, 2011. [40] A. Buades, B. Coll, and J. Morel. \"A non-local algorithm for image \ndenoising.\" In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, vol. 2, pp. 60-65. Jeffrey R. Stevens received the B.S. and M.S. degrees in electrical engineering from the State University of New York (SUNY) at Buffalo in 1992 and 1994 respectively, and is currently pursuing a Ph.D. in computational science and informatics at George Mason University in Fairfax, Virginia, USA. He is currently an Image Scientist in the Space and Intelligence Systems division of the Harris Corporation, Reston, Virginia, USA. Mr. Stevens research focuses on processing and analysis of remotely sensed spectral and lidar data. Ronald G. Resmini received the B.S. degree in geology from Northeastern University, Boston, Massachusetts, USA in 1984, the M.S. degree in geology from Boston College, Chestnut Hill, Massachusetts, USA, in 1989, and the the Ph.D. degree in geology from Johns Hopkins University, Baltimore, Maryland, USA in 1993. He is currently a Research Scientist in the Advanced ISR Solutions Department of the MITRE Corporation, McLean, Virginia, USA, and an Associate Professor in the College of Science at George Mason University, Fairfax, Virginia, USA. Dr. Resmini specializes in visible to infrared multi- and hyperspectral remote sensing, the geological and geophysical sciences, and the analysis, design, and development of algorithms for processing and analysis of remotely sensed information. His recent efforts have focused on the design, development, and testing of algorithms for resolved and subpixel target detection, identification, and characterization in hyperspectral data with emphasis
on linear and nonlinear spectral mixing models and statistical signal processing techniques. His other research interests include mathematical modeling of natural processes observed in remotely sensed data and the application and evaluation of radiative transfer models as applied to the spectral remote sensing of the earth's surface. David W. Messinger received a Bachelors degree in Physics from Clarkson University in Potsdam, New York, USA and a Ph.D. in Physics from Rensselaer Polytechnic Institute in Tory, New York, USA. He has worked as an Analyst for XonTech Inc., on the National Missile Defense Program for Northrop Grumman and was an Intelligence Community Postdoctoral Research Fellow. He is currently a Professor, the Xerox Chair in Imaging Science, and Director of the Chester F. Carlson Center for Imaging Science at the Rochester Institute of Technology where he was previously the Director of the Digital Imaging and Remote Sensing Laboratory. He has published over 100 scholarly articles. Dr. Messinger is an Associate Editor of the journal Optical Engineering, a Senior Member of SPIE, serves as the co-Chair of the SPIE conference Algorithms and Technology for Multispectral, Hyperspectral, and Ultraspectral Imaging, on the technical committee of the Department of Energy Conference on Data Analysis (CODA) and is a member of the USGIF Academic Advisory Board. His personal research focuses on projects related to remotely sensed spectral image analysis using physics-based approaches and advanced mathematical techniques with particular emphasis on the use of data driven techniques from the graph theory and manifold learning literatures. https://purr.purdue.edu/publications/1947/1\nhttp://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes\nhttp://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes INTRODUCTION\n HSI Graph Construction Techniques\n -Threshold Graphs (aka -NN Graphs)\n k Nearest Neighbor (k-NN) Graphs\n Density Weighted k-NN (DW k-NN) Graphs\n Adaptive Nearest Neighbor (ANN) Graphs\n Initialize\n =1, = Find nearest neighbors\n , calculate the Identify reverse nearest neighbor counts\n , count the number of times i occurs in \n Build graph Edge Reweighting Methods\n Spatial/Spectral Methods New Methods for HSI Graph Construction\n Shared Nearest Neighbor (SNN) Graphs\n Compute the pairwise (dis)similarity matrix A primary distance (similarity) measure is used to define initial edges.\n Construct a mutual k-NN graph Mutuality is imposed to avoid edges crossing regions of differing density (cf. \\)\n Redefine edge weights with the SNN (secondary) metric The number of neighbors shared by the two nodes becomes the new edge weight, replacing the (dis)similarity score from the primary metric.\n Mutual Proximity Graphs\n Graph Construction Performance\n Metrics\n Data\n Results Conclusions and Path Forward ",
    "text": " [ OPPORTUNITIES FOR IMPACT ] The threats to our nation have changed dramatically since our nuclear arsenal was first \ndesigned and fielded more than three decades ago. MITRE recommends that before \nthe United States spends $1 trillion over the next 30 years to modernize its nuclear \nenterprise, it conduct a Nuclear Posture Review (NPR) to reassess and revise its policy, \nstrategy, capabilities, and force posture. The NPR will help the administration re-focus \nthe nations nuclear enterprise to better respond to the worlds currentand future\ncomplex and turbulent environment. A Case for Action Our nuclear TRIAD has served America well. It has provided the cornerstone of our extended strategic deterrence policy of deter, assure, and strike. We deter potential adversaries with our overwhelming capability, assure our allies and partners that our arsenal is there to protect them, and serve notice of our resolve to strike with these weapons should deterrence fail and we or our allies/partners are threatened. However, the TRIAD was designed over 30 years ago. Since then, the threats to our nation have changed markedly. Our near-peer competitors such as China and Russia have improved their offensive capabilities and their strategy of how and when to use them. They have also applied advanced technology to improve their defensive capabilities against our strategic weapon systems, strategic communications, and command and control infrastructure. Their progress jeopardizes our ability to sustain a credible nuclear deterrent. In addition, there has been a marked increase in the number of nuclear-capable nation-states such as North Korea and Pakistan. While they do not currently pose an existential threat to the United States, we must establish well-conceived nuclear and non-nuclear, kinetic and non-kinetic response options to any potential aggression against us or our allies. Whereas in the past we could focus on just the one mission of survival against a first strike, we now need the tools (planning and execution applications, concepts of operation [CONOPS], and weapons) to execute across a continuum of options. Issues posed by regional proliferation, the emerging \npossibility of limited use in regional conflicts, and concerns \nby many of our allies about our extended deterrence guarantee, \nall introduce complexities and challenges not seen since the early \ndays of the Cold War.GENERAL JOHN E. HYTEN, USAF COMMANDER, UNITED STATES STRATEGIC COMMAND, SEPTEMBER 2016 Understanding the Problem Three decades ago, when the United States completed developing and fielding its nuclear weapon systems, our nuclear world was simpler. Deter, Assure, Strike Building Nuclear Deterrence for the 21st Century The MITRE Corporation is a not-for-profit organization chartered to work in the public interest. We apply our skills in systems engineering, research and development, and information technology to help the government address issues of critical national importance. The MITRE Corporation www.mitre.org In the era of mutually assured destruction, we focused on surviving a massive, first-strike attack from the Soviet Union. Today, the new capabilities of our adversaries require that we have a much more flexible set of deterrence and response options. The ability to plan and execute this wide range of responsesfrom conventional to nuclear, from kinetic to non-kinetic, where conventional forces work in complete coordination with the nuclear forcesis our biggest challenge. The Services have recognized the need to modernize the nuclear enterprise and have embarked on an ambitious set of programs to field new weapon systems and the command, control, and communications infrastructure to enable them by 2030. Unfortunately, the current modernization plans underway are primarily based upon the same performance requirements and CONOPS that were used to address Cold War realities. Consequently, if plans remain unchanged, the capability we will field in 2030 will be very similar to our legacy systemsjust with new hardware. This will not address the realities of the threat environment in 2030. Recommendations for the New \nAdministration and Agency Leaders Since its inception in 1958, The MITRE Corporation has been supporting the nations strategic deterrent capability in the areas of CONOPS exploration; mission capability definition; requirements analysis; and individual systems design, development, procurement, and test. Based upon that experience and the environment summarized above, MITRE recommends the following: The Services should rapidly address gaps and shortfalls in our current strategic systems in order to be able to fight todays fight. The administration should request a Nuclear Posture Review to establish new U.S. nuclear policy, strategies, capabilities, and force posture in conjunction with other national power capabilities. The NPR can benefit from the current Defense Science Board Summer Study on Nuclear Deterrence in the 21st Centurys Multi-Polar, Multi- Threat Strategic Environment, which will address many of the technical challenges involved and inform the NPR on the art of the possible. The NPR should assess all aspects of our nuclear deterrent, including: - All elements of the TRIAD, including the communications and command and control infrastructure - Potential new delivery capabilities, in addition to ballistic missile, bomber, and air-launched cruise missile delivery vehicles - Closer interoperability between conventional forces and nuclear forces to provide to the President a wealth of conventional/nuclear, kinetic/non-kinetic options (e.g., cyber, info ops) to respond to a range of conventional and nuclear attacks. The resultant perspective will allow the DoD and DoE to re-focus the nuclear enterprise strategy and modernization planand help them determine the necessary budgets so they can engage with Congress for funding. The Departments of Defense and Energy should drive innovation and investments in the critical capabilities required for a revised strategic deterrent policy. For further ideas about applying the guidance in this paper \nto your agencys particular needs, contact federaltransition@\nmitre.org. ",
    "text": " ecosystem: a system or group of interconnected \nelements; a complex set of relationships We work in a global ecosystemone that requires diverse, experienced people and strong partnerships to solve the complex challenges that face our nation and the world. I invite you to read more about MITREs research and work in this ecosystem and our crucial role as an innovation bridge. Sincerely, Alfred Grasso, President\nand Chief Executive Officer\nThe MITRE Corporation Ours Is a \nHigher Ambition Our Vision\nTo create a stronger nation and a better world by contributing to breakthroughs in safety and security. Our Mission\nOne public-interest company, working with industry and academia to advance and apply science, technology, systems engineering, and strategy, enabling government and the private sector to make better decisions and implement solutions to complex challenges of national and global significance. Our Goals\n Deliver transformational solutions that drive mission success and advance global leadership Set the standard for systems engineering excellence around the world Be a world-class organization 1T h e M I T R E C o r p o r a t i o n 4 6 10\nLetter from\nthe CEO Mission \nAchievements The FFRDC \nEcosystem Table of Contents 2 M I T R E 2 0 1 6 A n n u a l R e p o r t 42 50 54 58\nCutting-Edge \nR&D \nPeople 2016 at \na Glance Partnering \nfor Impact 3 Letter from the \nPresident and CEO Alfred Grasso 4 M I T R E 2 0 1 6 A n n u a l R e p o r t The phrase global village, popularized many years ago now, did not begin to describe how much the world would be interconnected. A challenge in one country now presents a challenge for the world. In \ncyberspace, on the battlefield, in hospitals, cities, courts, financial systems, in the air and beyond, we are truly a global ecosystem. MITRE is uniquely qualified to meet the challenges of todays world. With our own ecosystem of seven federally funded research and development centers, we are able to look across the federal government and the globe to the benefit of all of our sponsors. We serve as an innovation bridgeconnecting sponsors to sponsors, solutions to problems, technology to industry, and partners to opportunities. This year our sponsors celebrated a number of significant accomplishments. Whether safeguarding the United States from missile debris, protecting our assets in physical space and cyberspace, empowering patients and veterans, increasing the speed of justice and the economy, or ensuring safe and secure air travel, MITRE was instrumental in helping our sponsors achieve mission success. Our Innovation Program is the cornerstone of these successes, and we continue to break new ground as we seek to solve the problems of tomorrow today. This years MITRE Challenge of Countering Unauthorized Unmanned Aircraft Systems (UAS) brought participants from around the world, and weve just recently launched our second challenge on the Unique Identification of Internet of Things Devices. This year also marked change within our organization: our Board named Dr. John Hamre, former U.S. Deputy Secretary of Defense, to serve as Chairman. John has served on the Board since 2000, and he has brought to MITRE a remarkable understanding of national security issues at the highest levels. MITRE will be well served by his deep knowledge and experience. John succeeds The Honorable Charles Robb, who is retiring after 15 years with MITREservice that came after a distinguished political career of more than a quarter century. We will miss his wisdom and guidance and are grateful for his service. Finally, we were pleased to open the doors to our newest McLean campus building in 2016. MITRE 4 is a modern, green facility with cutting-edge laboratories and collaborative spaces for employees and guests. In the pages ahead, we take a closer look at the challenges of 2016 and beyond and our contributions to our sponsors and international partners successes within this global ecosystem in which we work. Regards, 5T h e M I T R E C o r p o r a t i o n We Operate \nFFRDCs MITRE manages a powerful ecosystem of federally funded research and development centers (FFRDCs) for multiple U.S. government sponsors to solve global challenges. Operating multiple FFRDCs across the federal space allows us to share capabilities, solutions, and innovations to the benefit of all our sponsors and the public. National Security Engineering Center (DoD) Center for Advanced Aviation System \n Development (FAA) Center for Enterprise Modernization (Treasury/IRS/VA) Homeland Security Systems Engineering and \n Development Institute (DHS) Judiciary Engineering and Modernization \n Center (Federal Judiciary) CMS Alliance to Modernize Healthcare \n (CMS/HHS) National Cybersecurity FFRDC (NIST) Federal \nAcquisition \nRegulation \n35.017: Federally \nFunded Research \nand Development \nCenters An FFRDC meets some special long-term research or development need that cannot be met as effectively by existing in-house or contractor resources. FFRDCs enable agencies to use private sector resources to accomplish tasks that are integral to the mission and operation of the sponsoring agency. 6 M I T R E 2 0 1 6 A n n u a l R e p o r t FFRDC \nDifferentiators We are a not-for-profit organization We form long- term, strategic partnerships with industry, academia, and governments We have continuity and depth We are chartered in the public interest We are free from organizational and commercial conflicts of interest We are an innovation bridge We are committed to excellence and integrity above all else We have \ncontinuity and \ndepth We are char-\ntered in the \npublic interest We are free from \norganizational \nand commercial \nconicts of \ninterest We form \nlong-term, strate-\ngic partnerships \nwith industry, \nacademia, and \ngovernments We are an innova-\ntion bridge We are built on \ntraditional values We have \ncontinuity and \ndepth We are char-\ntered in the \npublic interest We are free from \norganizational \nand commercial \nconicts of \ninterest We form \nlong-term, strate-\ngic partnerships \nwith industry, \nacademia, and \ngovernments We are an innova-\ntion bridge We are built on \ntraditional values We have \ncontinuity and \ndepth We are char-\ntered in the \npublic interest We are free from \norganizational \nand commercial \nconicts of \ninterest We form \nlong-term, strate-\ngic partnerships \nwith industry, \nacademia, and \ngovernments We are an innova-\ntion bridge We are built on \ntraditional values We have \ncontinuity and \ndepth We are char-\ntered in the \npublic interest We are free from \norganizational \nand commercial \nconicts of \ninterest We form \nlong-term, strate-\ngic partnerships \nwith industry, \nacademia, and \ngovernments We are an innova-\ntion bridge We are built on \ntraditional values We have \ncontinuity and \ndepth We are char-\ntered in the \npublic interest We are free from \norganizational \nand commercial \nconicts of \ninterest We form \nlong-term, strate-\ngic partnerships \nwith industry, \nacademia, and \ngovernments We are an innova-\ntion bridge We are built on \ntraditional values We have \ncontinuity and \ndepth We are char-\ntered in the \npublic interest We are free from \norganizational \nand commercial \nconicts of \ninterest We form \nlong-term, strate-\ngic partnerships \nwith industry, \nacademia, and \ngovernments We are an innova-\ntion bridge We are built on \ntraditional values We have \ncontinuity and \ndepth We are char-\ntered in the \npublic interest We are free from \norganizational \nand commercial \nconicts of \ninterest We form \nlong-term, strate-\ngic partnerships \nwith industry, \nacademia, and \ngovernments We are an innova-\ntion bridge We are built on \ntraditional values 7T h e M I T R E C o r p o r a t i o n GLOBAL SAFETY\n& SECURITY GLOBAL\nAVIATION GLOBAL\nCYBER GLOBAL\nHEALTH RESEARCH &\nDEVELOPMENT GLOBAL\nECONOMY GLOBAL\nJUSTICE The Public VA CMS/\nHHS DoD NIST FAA DHS COURTS Treasury/\nIRS Industry Academia Other \nFFRDCs,\nUARCs International\nPartners Mission Stakeholders We work in a global ecosystem:\nOur modern FFRDCs help connect government and the world 8 M I T R E 2 0 1 6 A n n u a l R e p o r t GLOBAL SAFETY\n& SECURITY GLOBAL\nAVIATION GLOBAL\nCYBER GLOBAL\nHEALTH RESEARCH &\nDEVELOPMENT GLOBAL\nECONOMY GLOBAL\nJUSTICE The Public VA CMS/\nHHS DoD NIST FAA DHS COURTS Treasury/\nIRS Industry Academia Other \nFFRDCs,\nUARCs International\nPartners Mission Stakeholders We work in a global ecosystem:\nOur modern FFRDCs help connect government and the world 9T h e M I T R E C o r p o r a t i o n 10 M I T R E 2 0 1 6 A n n u a l R e p o r t Many of the hardest and most FFRDC-worthy challenges span programs and sponsors. To solve these challenges, we help our sponsors harness the advances happening outside their walls and collaborate in partnership with stakeholders across industry, academia, and other nonprofits in the United States and around the world. Mission Achievements, \nGlobal Challenges 11T h e M I T R E C o r p o r a t i o n Digital Communications \nfor Safer Skies This transition has already resulted in reduced delays In 2016, the FAA began rolling out a safer and more efficient information exchange between air traffic controllers and pilots. \nThrough the Data Communications Programor Data Commthe FAA is now supplementing its voice-based communication system with data capabilities. MITRE worked with
the FAA and the aviation community to develop the operational concepts and procedures and the requirements for these Data Comm capabilities. We also performed operational testing to help ensure the successful integration and use of data communications throughout U.S. airspace. In 2016, the FAA provided Data Comm capabilities for use at 56 airports across the country. This has already resulted in shorter communication times, faster taxi-outs, and reduced delays. By the end of 2018, as many as 2,400 aircraft will be equipped with Data Comm capabilities. In 2019, the FAA plans to implement Data Comm services in its high-altitude air traffic control centers, extending the advantages of these services even further. n 12 M I T R E 2 0 1 6 A n n u a l R e p o r t 2,400 \naircraft will be equipped with \nData Comm Capabilities by 2018 13T h e M I T R E C o r p o r a t i o n 14 M I T R E 2 0 1 6 A n n u a l R e p o r t Tapping the Potential of \nNew Space Capabilities 1,100 active satellites are currently orbiting Earth Constellations of commercial satellites are imaging Earth with increasing frequency and accuracy. Theyre providing content for \nnavigation systems, business analytics, and global economics. This has led to a New Space vision: diverse commercial satellite imagery and analysis as low-cost commodities available to all. Multiple government agencies are seeking to tap the potential of New Space. The possibilities are far-reaching: mission planning, reconnaissance operations, disaster relief, resource conservation, and transportation security. MITRE is playing a vital role in helping the government take advantage of this emerging markets promise. MITRE is providing technical modeling and analysis to help government sponsors decide how and when to incorporate commercial space into their overall missions, investments, and acquisition strategies. We are also developing mission-driven analytics to add mission value from commercial offerings. Were piloting these in operational prototypes to address novel applications for our nations most challenging problems. n 15T h e M I T R E C o r p o r a t i o n Combating the Growing \nThreat to Our Space Assets AFSPC, MITRE, Aerospace Corp., Lincoln Lab, and RAND helped create a Space Enterprise Vision Today, the United States must be prepared for attacks on our national security space systems as they travel through space. \nChinas recent demonstrations of anti-satellite weapons are the most visible examples of the emerging threats to our space assets. In response, the Air Force Space Command (AFSPC) asked for MITREs help in creating a Space Enterprise Vision (SEV) outlining how the military should address the increasing dangers to communications, navigation, and other space-based capabilities. The AFSPC brought together a team of FFRDCs to support that effort, asking MITRE to serve as co-lead. In October 2016, the team delivered the SEV to AFSPC, and it quickly gained acceptance across senior levels of the DoD and intelligence community. The SEV is now being used to guide planning choices, resource decisions, and requirements development across the DoD and the intelligence community. n 16 M I T R E 2 0 1 6 A n n u a l R e p o r t Space assets \ninclude communications, \nnavigation, surveillance, \nmeteorological sensing, and \nthreat detection 17T h e M I T R E C o r p o r a t i o n 18 M I T R E 2 0 1 6 A n n u a l R e p o r t Transforming Indonesias \nAviation System In 2015, Indonesia launched an effort to modernize all aspects of its civil aviation operations. The International Air Transport \nAssociation (IATA) predicts that Indonesia will become one of the worlds 10 largest passenger markets by 2020 and the fifth largest domestic market by 2034. Indonesias modernization program will therefore have long-term benefits. The initiativeknown as Indonesia Modernization of Air Navigation Services (IMANS)calls for developing new operations concepts, implementing advanced air traffic management systems, updating procedures, and better integrating Indonesias operations with those of other nations in the region. Starting in November 2015, MITRE worked with AirNav Indonesiathe countrys air navigation service providerto expedite the identification and deployment of the capabilities needed to fulfill the IMANS vision. In September 2016, MITRE provided a comprehensive concept of operations for the modernization effort. n IATA predicts that Indonesia will become one of the worlds 10 largest passenger markets by 2020 MITREs work in the Asia Pacific region is helping deliver harmonized aviation \nsolutions 19T h e M I T R E C o r p o r a t i o n Judicial Analytics \nCreates Cost Savings Under the federal district courts Multidistrict Litigation (MDL) system, all pending civil cases of a similar type are transferred to a single judge. \nIn some MDLs, a court can receive upward of 6,000 new filings each day and face a backlog of up to 80,000 pending complaints. To better manage its own cases, one MDL court sought to capture pertinent items of data from each pending case file. This effort, the Office of the Clerk determined, would require 14 new staff, take four months to complete, and cost $400,000. The challenge was that the case documents are processed as PDF files, a format from which most automated systems cannot reliably retrieve specific data. Thats where MITREs expertise and independent status came in. After one week, nearly 95 percent of the desired data was compiled, eliminating the need for the costly solution the MDL court had originally anticipated. n A court can \nreceive upward of \n6,000 new filings each day 20 M I T R E 2 0 1 6 A n n u a l R e p o r t 21T h e M I T R E C o r p o r a t i o n 22 M I T R E 2 0 1 6 A n n u a l R e p o r t In 2015, almost 300 million \nrecords were leaked, \nand more than $1 billion \nwas stolen worldwide by cyber hackers Protecting Taxpayer \nIdentities Get Transcript enables users to obtain their tax transcripts online As Americans increasingly rely on the Internet for their business transactions, the amount of personal information accessible online \nhas grown substantially, making it vulnerable to hacking. Many users business transactions require copies of their tax returns. The IRS therefore offers a service, Get Transcript, to enable users to quickly obtain copies of their tax transcripts online. This past year, when the IRS was strengthening the security features of the Get Transcript application, it called on MITRE to evaluate the systems security to assess its readiness for deployment. MITREs cybersecurity experts tested all components of the Get Transcript system as well as its supporting eAuthentication service, which verifies the users identity, and identified a few areas for improvement. In particular, we recommended the use of the latest multi- factor authentication techniques to prevent unauthorized access. The IRS acted on MITREs independent recommendations, thus providing greater protections for taxpayer data. Taxpayers everywhere are the beneficiaries of the IRSs and MITREs diligence. n 23T h e M I T R E C o r p o r a t i o n Analyzing Social Media to \nPrevent Terrorist Attacks In December 2015, homegrown extremists inspired by a foreign terrorist group killed 14 people and injured 22 others in an attack in San Bernardino, California. How were they inspired? \nVia social media and the Internet. To help prevent such attacks both at home and abroad, the federal government immediately created a team to examine how social media analytics could be applied to the screening and vetting of individuals traveling or seeking immigration benefits. The team included personnel from DHS, the U.S. Citizenship and Immigration Services, and the MITRE-operated Homeland Security Systems Engineering and Development Institute (HSSEDITM) FFRDC. The team members used their knowledge of media, international social media sites, and language processing to review open source and social media analytic capabilities and technologies. Ultimately, they evaluated more than 270 social media tools for their potential for addressing critical mission areas. They highlighted solutions for accessing some 30 social media platforms on the Internet and darknets, using data sets in more than 120 languages. They also discovered problems with existing analytic capabilities, which were quickly improved for government agencies use. The teams work is now serving as the national testbed for establishing the DHS Social Media Center. Their work also helped DHS improve its capabilities, achieve operational efficiencies, and lower costs through the automation of advanced analytics, thereby advancing the agencys overall goals. n Facebook has over 1.7 billion active users 24 M I T R E 2 0 1 6 A n n u a l R e p o r t 25T h e M I T R E C o r p o r a t i o n 26 M I
T R E 2 0 1 6 A n n u a l R e p o r t Enabling Big Changes in \nMedicare Payment 2017 brings merit-based incentives for clinicians In October 2016, the Centers for Medicare & Medicaid Services (CMS) released rules overhauling how the agency pays physicians and other \nclinicians. Called the Quality Payment Program, the new approach rewards the delivery of high-quality care through two interrelated pathways: Advanced Alternative Payment Models (APMs) and the Merit- based Incentive Payment System (MIPS). MITRE provided CMS with strategic guidance for the design of MIPS, which rewards quality and efficiency improvement efforts and the use of electronic health record technology. We also contributed to the development of the Advanced APMs, which provide added incentives to deliver high-quality and cost-effective care. Recognizing that true delivery system reform requires working with a range of healthcare stakeholders, CMS asked MITRE to convene the Health Care Payment Learning and Action Network, which includes health plans, providers, patients, employers, consumers, states, federal agencies, and other partners. These stakeholders are now working together to promote the adoption of alternative payment models to achieve better care and smarter spending. n 27T h e M I T R E C o r p o r a t i o n Using Data to \nDefeat Drug Fraud Approximately 78 Americans die every day from opioid overdoses. More than half of these deaths stem from the misuse \nof prescription opioid pain relievers. Federal and state government agencies have launched a variety of efforts to address the opioid abuse epidemic. One of these, the Prescription Drug Monitoring Program (PDMP), gives individual states the ability to collect data about controlled substance transactions. MITRE researchers saw the PDMP as a means to identify prescription fraud schemes involving patients, prescribers, and pharmacies. A MITRE team worked with the state of Indiana to apply advanced analytics to more than 12 million transactions registered with the Indiana Board of Pharmacy. They used that information to create two Web-based tools. One assists prescribers in determining a patients risk of drug-seeking behavior to help catch doctor shoppers. The other scores providers for potential fraud to help predict where fraud is most likely to occur. Preventing more fraud and abuse will save more lives. n As much as \n$72 billion a year goes toward drug \naddiction \ntreatment 28 M I T R E 2 0 1 6 A n n u a l R e p o r t Approximately 78 \nAmericans die every day from opioid \noverdoses 29T h e M I T R E C o r p o r a t i o n 30 M I T R E 2 0 1 6 A n n u a l R e p o r t Applying Safety Science \nto Child Welfare Every year, as many as 2,000 U.S. children die as the result of abuse or neglect. MITRE is partnering with the Department of \nHealth and Human Services (HHS) to prevent these tragic deaths through data sharing and analysis. MITRE has already successfully partnered with government and industry to use an information sharing and analysis approach to improve aviation safety and to prevent avoidable patient safety events in medical facilities. To achieve these outcomes, we collect data from a variety of sources and analyze it to identify safety issues. We are conducting an analysis for HHS to assess the potential benefits of this approach in the field of child welfare. While our long-term vision is to develop national partnerships for the sharing of child welfare and related data, we are also working at the local level. For example, we are collaborating with the County of San Diegos Health and Human Services Agency to develop a system to collect and analyze child welfare, medical, and substance abuse data. Our effort there is generating important insights and will help to refine our efforts and approach at the national level. n Every day, 4 to 8 \nchildren in the U.S. die from abuse or neglect MITRE is \npartnering with \nHHS to prevent tragedies through \ndata sharing and analysis 31T h e M I T R E C o r p o r a t i o n Cyber Lab Helps Secure \nthe Smart Home In 2016 MITRE worked with the National Institute of Standards and Technology (NIST) to create a state-of-the-art lab at the National \nCybersecurity Center of Excellence (NCCoE) to address the threats to security and privacy posed by the Internet of Things (IoT). The term IoT refers to devices equipped with software, sensors, and effectors networked with one another via the Internet. Although these networked devices can improve efficiency in the home, they also carry security risks. The new Consumer IoT Initiative (CITI) lab functions as a simulated smart home to enable researchers to explore these challenges. Leveraging MITREs trusted adviser role, researchers can then develop strategies for securing consumers security and privacy, as well as countermeasures to address the adverse impact a large group of compromised IoT devices can have on the Internet itself. CITI is now fully operational and welcomes research topics from industry, NIST, and other sponsors. Results from the labs experiments will inform and enhance NCCoEs efforts to help U.S. industry apply secure technologies that enable consumers to enjoy the many benefits of a smart home without sacrificing security and privacy. n IoT: MITRE helps balance benefit and risk 32 M I T R E 2 0 1 6 A n n u a l R e p o r t 33T h e M I T R E C o r p o r a t i o n More than 4.6 million \nveterans live \nin rural areas 34 M I T R E 2 0 1 6 A n n u a l R e p o r t Assisting Veterans \nin Rural Areas MITRE is helping demonstrate the art of the possible for managing care The Veterans Health Administration (VHA) asked MITRE to come up with a system that would improve the provision \nof care to the 30 percent of the nations veterans who live in rural areasa setting with unique healthcare challenges. In response, MITRE helped create and pilot a system focused on rural veterans receiving home healthcare. Today, the Department of Veterans Affairs (VA) contracts with home health agencies for these services. Coordinating that care is a manual process involving paper forms and phone calls. This often results in missed communications, inconsistencies in the patient record, and delays in the provision of care. To address these issues, MITRE automated the process in a secure Web-based environment to enable VA and home health providers to electronically share plans of care, record patient observations, reconcile medication discrepancies, and facilitate the communication of additional orders. This pilot is demonstrating the art of the possible for managing care in the community, reducing costs, and improving patient safety, and it positions the VHA as a national leader in moving toward patient-centered plans of care. n 35T h e M I T R E C o r p o r a t i o n Patching Vulnerabilities in \nOur Digital Infrastructure Over 30,000 NIST practice guides have been downloaded to date The recent denial-of-service attacks on the Internet routing company Dyn shut down major swaths of the Internet, exposing \nvulnerabilities in our digital infrastructure. What if the targets had been the power grid or the financial sector? To safeguard the nation from such scenarios, MITRE works with NIST to accelerate the adoption of advanced security technologies. MITRE is helping the National Cybersecurity Center of Excellence (NCCoE) to engage new collaborators to drive awareness and promote early adoption of new technologies and standards. In 2016, we assisted NCCoE in publishing four practice guides on such industry-identified challenges as Securing Electronic Health Records on Mobile Devices and Identity and Access Management for Electric Utilities. Our efforts also helped NCCoE increase its key stakeholder relationships by 68 percent and garnered some 30,000 practice guide downloads. In addition, MITRE developed new ways to rapidly share NCCoEs pragmatic solutions. For example, our video of the Attribute-Based Access Control practice guide has been viewed more than 2,000 times on the NIST YouTube channel. n 36 M I T R E 2 0 1 6 A n n u a l R e p o r t In October 2016, a distributed denial- of-service attack shut down dozens of popular websites 37T h e M I T R E C o r p o r a t i o n Communications \nTesting North of the Arctic Circle 38 M I T R E 2 0 1 6 A n n u a l R e p o r t Melting icecaps are creating access for trade routes, cruise ships, and natural resource exploration, all of which \nimply missions for the Department of Defense. MITRE is helping the DoD ensure that communications capabilities are available for those potential Arctic missions. Last June, MITRE supported testing with U.S. Northern Command in Barrow,
Alaska, to evaluate the performance of commercial and military communications capabilities in this demanding environment. Testing revealed several unanticipated problems, including coverage gaps, atmospheric anomalies, and unexplained interference. These problems all play havoc with the ability to establish reliable communication paths. The testing informed emergency planning for the first commercial cruise ship that traversed the Northern Passage in August. MITRE is investing in Arctic communications research to inform communications models and identify investment areas that may include a combination of current and future commercial, military, satellite, radio frequency, and terrestrial systems. MITRE is also integrating multi-domain expertise for satellite communications, space weather, antenna modeling, and rapid prototyping to build antenna and radio capabilities to overcome the Arctic performance challenges identified during testing. n Communications capabilities are critical to potential Arctic missions 39T h e M I T R E C o r p o r a t i o n Technology to Protect \nEurope from Missile Threats NATO Allies in Europe are under increasing threat of missile attacks from the Middle East and others in the Eastern Hemisphere. The \nUnited States has committed to field strategically located land-based Ballistic Missile Defense interceptors as part of the European Phased Adaptive Approach to deter or counter those threats. Called Aegis Ashore, the capability integrates a maritime engagement system with a ground- based missile defense capability. Supporting U.S. Navy and Missile Defense Agency (MDA) sponsors, MITRE provided the technical and systems engineering expertise to help field the first systemin Romaniain December 2015. MDA used a modular approach to support a relocatable capability. The Romanian deck house was assembled in New Jersey, and once a successful test firing was accomplished at a facility in Hawaii, it was disassembled, transported, and reassembled on-site in Romania. Drawing on lessons learned from the Aegis Ashore system in Romania, MITRE is a trusted contributor and is working to help MDA build and test a second system, scheduled to go live in Poland in 2018. n aegis \n( ) noun: protection, \nbacking, or support 40 M I T R E 2 0 1 6 A n n u a l R e p o r t 41T h e M I T R E C o r p o r a t i o n 42 M I T R E 2 0 1 6 A n n u a l R e p o r t Cutting-Edge \nR&D\nWith increasing needs in almost every area of the federal space, the public needs an understanding of emerging challenges and technologies. With digital engagement on the rise, and the rate of technology and data change increasing at explosive, exponential rates, we offer a global whole of planet approach to solving problems. 43T h e M I T R E C o r p o r a t i o n MITREs R&D program is designed to: MITRE Innovation Program: \nPreparing for the Challenges \nof the Future Today \nIn our independent R&D program, we work in almost 100 technical fields as well as multiple domains, from air traffic control to healthcare management to cybersecurity to financial fraud. Our R&D program supports \nand complements MITREs direct work for sponsors, focusing on near-, mid-, and far-term challenges. We strive to identify areas in which new technologies and capabilities can dramatically improve our sponsors capabilities, and part of our R&D funding is devoted to exploring technologies beyond the leading edge. Anticipate trends in technology and next-generation requirements and help \nsponsors adapt their programs for the future Develop prototype tools and methodologies, from biotechnology to sophisticated \nmodeling and simulation environments, to support sponsor work Share research results broadly through publications, conferences, and \nparticipation in standards bodies and technology exchange events Work closely with sponsors, using real data in experiments and bringing in end \nusers to test our prototypes Share MITRE intellectual property with the government and license it to industry, \nas appropriate, to spur product introductions that meet our sponsors needs Collaborate with government, academia, and industryfrom technology \nincubators to established companies 44 M I T R E 2 0 1 6 A n n u a l R e p o r t Investing in the Future\nMITRE has 18 mission-focused and core technology innovation areas: Agile Enterprises Anti-Access/Area-Denial (A2AD) Aviation and Transportation Communications and Networking Critical Infrastructure Security and Resilience Cyber Community Research and Transition Cyber Effects Cybersecurity Data to Decisions Electronic Systems and Technology Future of Command and Control Health Transformation Information Technology Integrated Sensing, Processing, and Exploitation International Research and Development Software Engineering Technology Futures Trustworthy Autonomy 45T h e M I T R E C o r p o r a t i o n 2016 Tech Transfer executed 125 \nlicenses \nduring FY16 MITRE understands that, as we work on critical issues in our sponsors interest, we must serve as an innovation bridge in discovering externally developed technologies of interest \nwhile simultaneously transferring the innovations that we develop. Recognizing that our innovations often need to be instantiated in supported commercial products, we enacted our technology transfer policy in 1971, well before the more recent legislation in this area. Our technology transfer program is an effective way to direct MITRE-developed technologies into the hands of commercial companies that will make them available to our sponsorsand in many cases the publicas affordable, supported products because full-scale development and commercialization are not part of MITREs mission. The program is also a catalyst for economic growth and potential job creation, so we return additional value from the receipt of federal funds. As a result, there are many avenues through which MITREs intellectual property reaches those who need and can use it to deliver outcomes. n 46 M I T R E 2 0 1 6 A n n u a l R e p o r t MITRE does do interesting research and thought work \n168 350 261 338 Estimated New Jobs Per Year Commercialization 5 15\n10 10 10 7 23 60 27\n32 400 350 300 250 200 150 100 50 0 60 50 40 30 20 10 0 FY 12 FY 13 FY 14 FY 15 FY 16 CY07 CY08 CY09 CY10 CY11 CY12 CY13 CY14 CY15 CY16 183\n168 350 261 338 Estimated New Jobs Per Year Commercialization 5 15\n10 10 10 7 23 60 27\n32 47T h e M I T R E C o r p o r a t i o n The MITRE \nChallenge Projected value of the drone industry by 2020: $127 \nbillion MITREs Countering Unauthorized UAS Challenge attracted a variety of innovators from around the world. The use of small Unmanned Aircraft Systems (UAS) within the United States \nand across the globe is growing quickly. Government, industry, and hobbyists are finding many ways to use these small aircraft. However, we are also seeing unauthorized usesresulting in drones that potentially threaten the safety of aircraft in the national airspace and create security concerns by operating near sensitive locations. The potential for nefarious use of this technology has become a major safety and security concern for multiple federal agencies. The MITRE Challenge team put out a call for solutions to detect and safely interdict small UAS (weighing less than 5 lbs.) that pose a potential safety or security threat in urban areas. We asked for innovative solutions that were affordable, technologically scalable, and workable in domestic environments. Forty-two contestants from eight countries submitted white papers outlining their approach, and the Challenge Team and a panel of domain and technical experts from MITRE and U.S. federal agencies selected eight finalists to compete in a live flight event in August at the Marine Corps Base Quantico Urban Training Center. A MITRE red team flew the same four scenarios against each team; the scenarios featured different drones and techniques that represented realistic attack schemes. We achieved our goal to help the government and MITRE better understand the state of technologies that could be deployed across the United States and in foreign urban environments, and we will continue to work with sponsors to find and adapt the best solutions. n 48 M I T R E 2 0 1 6 A n n u a l R e p o r t MITREs Unique \nIdentification of IoT Devices \nChallenge \nattracted participants from 33 countries \naround the world Gartner forecasts there will be 21 billion connected things worldwide by 2020 Internet of Things (IoT) devicesfrom garage door openers to medical monitors to factory alertsare becoming more and \nmore ubiquitous. Unfortunately, so are warnings of the devices cyber vulnerabilities and actual attacks. The IoTs innumerable interconnections of devices, or things, will lead to new efficiencies and capabilities, but the ability to manage the IoT to ensure security and privacy within different operating systems and environments poses significant challenges. The MITRE Challenge put out a call for possible solutions to this potential threat so our sponsors can reap the benefits of this technological evolution, while minimizing the risks. Winners will be announced in early 2017. n 49T h e M I T R E C o r p
o r a t i o n 50 M I T R E 2 0 1 6 A n n u a l R e p o r t The challenges and opportunities of today and the future are best addressed by networks of organizations. MITRE, consistent with our public interest charter, works with a variety of businesses, organizations, and institutions to both form and contribute to partnerships between the public and private sectors that achieve outcomes for our government and the public it serves. Partnering \nfor Impact 51T h e M I T R E C o r p o r a t i o n Corporate\nSocial Responsibility Public-Private \nCollaboration Advancing\nKnowledge \n& Practice Research &\nInnovation Global Safety \n& Security Mission\nOutcomes NASA Allied\nMinds NVTC ASPI World Bank ANSPs ACT-\nIAC MIT-LL Sandia JHU\nAPL Mass\nInnovation Bridge RAND Atlas\nHealth McKinsey\n& Co. NCCoE GMU Johns\nHopkins Stanford UVA UMUC University of\nMontreal STEM\nInitiatives We Partner \nAround the Globe The University of Montreals Cyberjustice Laboratory signed a memorandum of understanding with MITRE to enhance access to justice and support the rule of law locally and abroad. MITRE has been working with McKinsey & Co. as a partner and leader in strategic analysis and organizational change across our health and human services program on areas such as improving the sustainability of rural healthcare and transforming public health surveillance. 2016 Highlights Massachusetts Innovation Bridge is a partnership between the Commonwealth and MITRE that will help federal agencies solve the nations most difficult challenges by tapping into world-leading innovation and high-tech ecosystem in Massachusetts, while creating new business opportunities in the Commonwealth. 52 M I T R E 2 0 1 6 A n n u a l R e p o r t Corporate\nSocial Responsibility Public-Private \nCollaboration Advancing\nKnowledge \n& Practice Research &\nInnovation Global Safety \n& Security Mission\nOutcomes NASA Allied\nMinds NVTC ASPI World Bank ANSPs ACT-\nIAC MIT-LL Sandia JHU\nAPL Mass\nInnovation Bridge RAND Atlas\nHealth McKinsey\n& Co. NCCoE GMU Johns\nHopkins Stanford UVA UMUC University of\nMontreal STEM\nInitiatives MITRE collaborates with the Northern Virginia Technology Council (NVTC) on the Veterans Employment Initiative, which includes VETWORKING, a free boot camp designed to support veterans with a seamless transition from active duty to a successful career. The MITRE Corporation and the Canberra-based Australian Strategic Policy Institute (ASPI) announced their agreement to cooperate for the advancement of shared Australian and U.S. interests. Both are not-for-profit entities that work in the public interest by addressing complex, national-level challenges for government. An agreement between Allied Minds and MITRE gives Allied Minds a first look at and exclusive access to certain technologies in MITREs intellectual property portfolio. Allied Minds relationship with MITRE is one of several arrangements that Allied Minds has with federally funded research labs, each of which is structured to help create a platform for technology transfer, as well as new company creation. 53T h e M I T R E C o r p o r a t i o n 54 M I T R E 2 0 1 6 A n n u a l R e p o r t We employee a diverse group of highly educated professionals who combine first-rate technical and organizational know-how with an enthusiasm for serving in the public interest. \nPeople 55T h e M I T R E C o r p o r a t i o n At MITRE, we believe that bringing together bright individuals with a variety of backgrounds, perspectives, and work styles leads to the most innovative solutions. By drawing on a wealth of experiences and ideas, we ensure that no potential solution gets overlooked. Put innovative tools into the hands of talented people in a collaborative environment, and there are no problems they cant solve. Our People 56 M I T R E 2 0 1 6 A n n u a l R e p o r t MITRE is committed to fostering a culture of diversity and inclusion. That commitment is embedded in our corporate values and in our goals. We believe our diverse workforce helps MITRE realize its fullest potential. People \nby the Numbers 8,205 \ntotal staff 85% \nsay MITRE \nis a Great Place \nto Work Read more in MITREs 2016 Corporate Social Responsibility Report 57T h e M I T R E C o r p o r a t i o n 58 M I T R E 2 0 1 6 A n n u a l R e p o r t 2016 was marked by numerous awards, media interactions, and growth. 2016 at \na Glance 59T h e M I T R E C o r p o r a t i o n 2016 Workplace \nAwards & Recognition STEM Workforce Diversity Magazine: Top 50 Employers NVTC Veterans Employment Initiative Veteran Service Award Commuter Connections Employer Recognition Award 2016 Washington Post Top Workplaces 2016 Computerworld 100 Best Places to Work in IT 2016 InformationWeek Elite 100 for Innovative Technology Forbes: Americas Best Employers San Antonio Express-News Top Workplaces for 2016 Massachusetts ECO Program Pinnacle Award 2016 Boston Globe Top Places to Work 60 M I T R E 2 0 1 6 A n n u a l R e p o r t 61T h e M I T R E C o r p o r a t i o n Financial and Staffing Data 7,613\n7,190 7,345 7,678 586\n660 725\n788 2012 2013 2014 2015 2016 2012 2013 2014 2015 2016 2012 2013 2014 2015 2016 8,205 832 $1,600 $900 $0 0 9,000 $0 1,421 1,383 1,365\n1,484 1,542 Total Staff \n(Year-End) Total Assets \n($ in millions) Total Revenue \n($ in millions) MITREs revenue from operations increased 3.9% from $1,484 million in fiscal year 2015 to $1,542 million in fiscal year 2016. The year-over-year \nincrease in revenue was driven primarily by increased work mainly with the Departments of Defense, Homeland Security, and Health and Human \nServices and Medicare & Medicaid Services areas. This growth more than offset the reduction of revenue due to MITREs conclusion of the \nindependent assessment of the Department of Veterans Affairs healthcare system through the Veterans Access, Choice, and Accountability Act \nof 2014 (known as VA Choice). Assets increased year-over-year by $44 million, driven primarily by increases to property, plant, and equipment \nrelated to ongoing building construction as the company works to consolidate its McLean, Virginia, operations onto its main campus. Staff \npopulation increased year-over-year, which reflects current and anticipated demand and shifts in the work program. $ 62 M I T R E 2 0 1 6 A n n u a l R e p o r t Locations MITRE is headquartered in Bedford, Massachusetts, and McLean, Virginia, with our newly established R&D site in Singapore. We have sites across the country and the world. MITRE 4 opened in fall 2016 and consolidates nearly all McLean-based employees on one campus, enhancing our collaboration and knowledge sharing. The environmentally friendly building is dedicated to long-term chairman James Schlesinger and includes several cutting- edge laboratories devoted to innovation and experimentation. 63T h e M I T R E C o r p o r a t i o n MITREs leaders manage the governments investment in us wisely, ethically, and responsibly. Our executive team together with our Board of Trustees brings the high level of expertise needed to tackle the governments biggest challenges and achieve mission success. \nLeadership 64 M I T R E 2 0 1 6 A n n u a l R e p o r t With\nAppreciation The Honorable Charles Robb joined MITREs board in 2001, and during his tenure he brought valuable insight as the first U.S. Senator to simultaneously serve on the Armed Services, Foreign Relations, and Intelligence committees. We were fortunate to have his leadership as vice chairman from 2006 through 2014 and as chairman until his retirement in October 2016. To recognize his service to the company, we have dedicated the auditorium in the new MITRE 4 building in his name and are establishing a National Merit scholarship for the children of MITRE employees. 65T h e M I T R E C o r p o r a t i o n Executive \nTeam Mr. Alfred Grasso\nPresident and \nChief Executive Officer Mr. Richard Byrne\nSenior Vice President, Programs and \nTechnology, Center for Connected \nGovernment Ms. Julie Bowen\nVice President, General Counsel, \nand Corporate Secretary Mr. James Cook\nVice President and Director, \nCenter for Enterprise Modernization Dr. Gregory Crawford\nVice President, Joint and Services \nPortfolio, National Security \nEngineering Center Mr. John M. Kreger\nVice President and Director, Homeland \nSecurity Systems Engineering and \nDevelopment Institute Mr. Joel Jacobs\nVice President and \nChief Information Officer Mr. Mark Kontos\nSenior Vice President, Chief Financial \nOfficer, and Treasurer Dr. Stephen Huffman\nSenior Vice President and General \nManager, Center for National Security, \nand Director, National Security \nEngineering Center Mr. Robert Jensen\nVice President and Director, \nCMS Alliance to Modernize Healthcare Ms. Julie Gravallese\nVice President and Chief Human \nResources Officer Mr. Paul Bielski\nExecutive Director, Judiciary \nEngineering and Modernization Center 66 M I T R E 2 0 1 6 A n n u a l R e
p o r t Ms. Sarah MacConduibh\nVice President, Air Force Portfolio, \nNational Security Engineering Center Dr. Mark Maybury\nVice President and Director, \nNational Cybersecurity FFRDC, \nand Chief Security Officer Dr. Jason Providakes\nSenior Vice President and General \nManager, Center for Connected \nGovernment Ms. Lillian Zarrelli Ryals\nDirector, Senior Vice President, and \nGeneral Manager, Center for Advanced \nAviation System Development Mr. John A. Wilson\nVice President, Programs and \nTechnology, Center for National \nSecurity Mr. Peter Sherlock\nSenior Vice President, \nPrograms and Technology, \nCenter for National Security Dr. William LaPlante\nVice President, Intelligence Portfolio, \nNational Security Engineering Center Dr. Jay Schnitzer\nVice President and Chief \nTechnology Officer Mr. Joseph Sinnott\nExecutive Director, Center for \nAdvanced Aviation System \nDevelopment 67T h e M I T R E C o r p o r a t i o n Ms. Michle Flournoy\nCo-Founder, Center for a New \nAmerican Security Senior Adviser, Boston Consulting \nGroup Previous positions:\nUnder Secretary of Defense for Policy President, Center for a New American \nSecurity Senior Adviser, Center for Strategic \nand International Studies Mr. George C. Halvorson \nPrevious position:\nChairman and Chief Executive \nOfficer, Kaiser Permanente Dr. John J. Hamre\nPresident and Chief Executive \nOfficer, Center for Strategic and \nInternational Studies Previous position:\nDeputy Secretary of Defense (Named Chairman in 2017) Mr. David G. Fubini\nSenior Lecturer, Harvard \nBusiness School Director Emeritus, McKinsey \n& Company Gen. C. Robert Kehler, \nU.S. Air Force (Ret. )\nPrevious positions:\nCommander, U.S. Strategic \nCommand Commander, Air Force \nSpace Command Dr. George Campbell, Jr.\nPrevious positions:\nPresident, The Cooper Union for the \nAdvancement of Science and Art President and CEO, National \nAction Council for Minorities in \nEngineering, Inc. U.S. Delegate, International \nTelecommunications Union Adm. Edmund P. \nGiambastiani, Jr., \nU.S. Navy (Ret.)\nPrevious positions:\nSeventh Vice Chairman of the Joint \nChiefs of Staff NATO Supreme Allied Commander \nTransformation Commander, U.S. Joint Forces \nCommand Mr. Robert R. Everett \nHonorary Member\nPrevious position: \nPresident, The MITRE Corporation Ms. Jane F. Garvey\nNorth America Chairman, Meridiam \nInfrastructure Previous positions:\nExecutive Director, JP Morgan \nSecurities, Infrastructure Advisory \nGroup Administrator, Federal \nAviation Administration Acting Administrator, \nFederal Highway Administration (Retired from Board in 2016) Dr. Donald M. Kerr \nVice Chairman\nPrevious positions:\nPrincipal Deputy Director of \nNational Intelligence Director, National \nReconnaissance Office Deputy Director for Science \nand Technology, Central \nIntelligence Agency Mr. Nicholas M. Donofrio\nPrevious position:\nIBM Executive Vice President, \nInnovation and Technology Mr. Alfred Grasso\nPresident and Chief \nExecutive Officer, \nThe MITRE Corporation Board of Trustees 68 M I T R E 2 0 1 6 A n n u a l R e p o r t Mr. John P. Stenbit\nPrevious positions:\nAssistant Secretary of Defense for \nCommand, Control, Communications, \nand Intelligence Executive Vice President, TRW Senator Charles S. Robb \nChairman\nDistinguished Professor of Law \nand Public Policy, George Mason \nUniversity, School of Law Previous positions:\nU.S. Senator Governor of Virginia (Retired from Board in 2016) Gen. Robert T. Marsh, \nU.S. Air Force (Ret. ) \nHonorary Member\nPrevious positions:\nExecutive Director, Air Force Aid Society Commander, Air Force Systems \nCommand Gen. Montgomery C. Meigs, \nU.S. Army (Ret. )\nVisiting Professor in the Lyndon B. \nJohnson School of Public Affairs, \nUniversity of Texas Previous positions:\nPresident and Chief Executive \nOfficer, Business Executives for \nNational Security \nDirector, Joint IED Defeat \nOrganization, Office of the \nSecretary of Defense Mr. Cleve L. Killingsworth\nPrevious positions:\nChairman and Chief Executive Officer, \nBlue Cross Blue Shield of Massachusetts President and Chief Executive Officer, \nHealth Alliance Plan Dean Elizabeth Rindskopf Parker\nDean Emerita of the McGeorge School \nof Law at the University of the Pacific Previous positions:\nGeneral Counsel, National Security Agency Principal Deputy Legal Adviser, \nU.S. Department of State General Counsel, \nCentral Intelligence Agency Ms. Mary Schapiro\nVice Chairman, Advisory Board of \nPromontory Financial Group Previous positions:\nChair, U.S. Securities and \nExchange Commission Chair, Commodity Futures \nTrading Commission Chair and CEO, National Association \nof Securities Dealers Mr. Rodney Slater\nPartner, Patton Boggs Previous positions:\nU.S. Secretary of Transportation Director, Federal Highway \nAdministration Ms. Cathy Minehan\nManaging Director of Arlington \nAdvisory Partners, LLC Previous Positions Dean, Simmons College \nSchool of Management President and CEO, Federal \nReserve Bank of Boston The Honorable Mike Rogers\nNational Security Commentator Previous Positions Congressman Founder, Mike Rogers Center for \nIntelligence and Global Affairs 69T h e M I T R E C o r p o r a t i o n Army Advisory Board \nGEN John Campbell, USA (Ret) \nGEN William Hartzog, USA (Ret)\nGEN Gordon Sullivan, USA (Ret)\nGEN John H. Tilelli, USA (Ret) \nGEN Scott Wallace, USA (Ret) Air Force Advisory Board\nGen John D.W. Corley, USAF (Ret)\nGen Ronald R. Fogleman, USAF (Ret)\nGen Donald Hoffman, USAF (Ret) \nLt Gen Kenneth Minihan, USAF (Ret)\nGen Norton Schwartz, USAF (Ret) Homeland Security Advisory Board \nThe Hon. Martin C. Faga\nADM James M. Loy, USCG (Ret)\nMs. Michelle Mrdeza\nThe Hon. Paul Schneider\nMr. C. Stewart Verdery, Jr. Aviation Advisory Committee\nMr. Mark Baker\nMr. Edward Bolen\nMr. Peter Bunce\nMr. Lorne Cass\nThe Hon. Susan Coughlin\nThe Hon. Craig Fuller\nMr. Tracy Lee\nMr. Jeffrey Martin\nThe Hon. Rodney Slater Advisory \nBoards 70 M I T R E 2 0 1 6 A n n u a l R e p o r t Intelligence Advisory Board\nThe Hon. Charles Allen\nThe Hon. Martin C. Faga\nMr. Mark Giuliano\nMrs. Mary Margaret Graham\nDr. Donald Kerr \nLt Gen Kenneth Minihan, USAF (Ret)\nVADM Robert Murrett, USN (Ret)\nMs. Teresa Shea Naval Advisory Board \nVADM Barry Costello, USN (Ret)\nADM Gregory (Grog) Johnson, USN (Ret) \nLtGen Bruce Barry Knutson, USMC (Ret) National Cybersecurity FFRDC Executive Council\nChancellor Robert Caret\nDr. Freeman Hrabowski\nDr. Wallace Loh\nMs. Teresa Lupinek \nMs. Tina Madarang\nMs. Susan Marinoff 71T h e M I T R E C o r p o r a t i o n Sustainability The MITRE Corporation is committed to the development of a sustainable environment. \nThe printing company is certified by the Forest Stewardship Council. The 2016 MITRE Annual Report was printed using paper with 10% post-consumer recycled fiber \non McCoy Silk, manufactured by Sappi Fine Paper North America, in the USA. www.mitre.org Approved for Public Release. Distribution unlimited. Case number 16-4474. Photos and illustrations by MITRE Corporate Communications and Public Affairs. \nAdditional photos courtesy of defense.gov, va.gov, Wikimedia, and thinkstock.com. Produced by MITRE Corporate Communications and Public Affairs. Sustainability 72 M I T R E 2 0 1 6 A n n u a l R e p o r t MITRE connects through multiple social media channels. Find out more about us through our Facebook, Linked In, Twitter, Google Circles, and YouTube pages. Find out more 73T h e M I T R E C o r p o r a t i o n ",
    "text": " Lets Use Technology Transfer to Drive Growth Vicki A. Barbur and Barry A. Costa, The MITRE Corporation The U.S. government invests some $135B each year to advance science and technology (S&T) as the basis \nfor breakthrough knowledge development and new innovations, of which around 20-30 % is invested in \nsuccessful technology transfer. This federally-funded research delivers a portfolio of outcomes whose \nbenefits therefore need to be maximized for growth and economic development. While there are many legitimate cases where the intellectual property (IP) generated as result of such \nwork should remain with the funded originator, there are also many cases where everyone would benefit \nif the IP, the product of federal investment, were shared with other parties via the mechanism routinely \nreferred to as Technology Transfer. This process involves either making the IP freely available as open \nsource, or entering into a formal licensing agreement with a third party. By pursuing such approaches, the \nknowledge and/or capability gained through the federal investment can be leveraged by other \napplications beyond just those that were originally intended. In combination with other new discoveries, \nit contributes to the pipeline for future generations of innovation. Such a channel is a hallmark of \nscientific progressand also helps an entrepreneurial ecosystem developthereby growing businesses, \ncreating new jobs, and boosting the U.S. economy. In practice, however, Technology Transfer typically has not been a high priority within federal research \nprograms, even though it is often an integral part of legislation and charters that set forth the conditions \nfor such federal investment. Many federal employees have only a limited understanding of Technology \nTransfer. Often, it is not required by agency leadership, and there has been no sustained push to ensure \nthat additional, value-added outcomes are delivered successfully on a consistent basis until now; the \nintent is that we see some change. In todays global, hyper-competitive innovation marketplace, however, our nation should be maximizing \nthe impact of every federal dollar spent on research and development. In order to achieve this, we must \nincrease our emphasis on obtaining full value from these investments. All new government-funded R&D \ninitiatives should have an outcome-focused philosophy at their core, and federal R&D program managers \nshould be given additional training to increase their awareness and adoption of Technology Transfer \nprotocols. Too often today, federal managers are unaware of opportunities to maximize the benefits of the research \nresults which they manage routinely. Instead, their focus has been on the more traditional aspects of \ntheir role, such as ensuring that funding and contractual obligations are in order, timelines and budgets \nare met, and successful innovations transition to the government customer. The end result is that further \ninnovations that could be spun off to maximize the return on the original investmentbringing new \nproducts to market and generating significant economic benefitsremain, in effect, locked up and sitting \non the shelf. Moreover, in many cases, this IP is left legally unprotected, due to the lack of a strategy to \nsafeguard it. A successful example that illustrates the value of Technology Transfer comes from the Federal Aviation \nAdministration (FAA and its Federally Funded Research and Development Center (FFRDC), the Center for \nAdvanced Aviation System Development (CAASD), operated by The MITRE Corporation). The FAA \nsponsored CAASDs effort to develop a prototype system that would provide small aircraft with the same \nlevel of situational awareness in the air that larger planes with costly and sophisticated systems \nenjoy. CAASD developed the Universal Access Transceiver Beacon Radio (UBR), which affordably Approved for Public Release; Distribution Unlimited. Case Number 16-4693 \n Approved for Public Release; Distribution Unlimited. Case Number 16-4693 \n incorporates the communitys standard Automatic Dependent Surveillance-Broadcast (ADS-B) \ntechnology. ADS-B, which was developed under the FAAs NextGEN initiative and leverages GPS satellites \nto feed critical flight data directly to the cockpit, helped address several important operational and safety \nneeds, both for the FAA and for small aircraft operators. MITRE has since licensed this technology to \nmore than 20 companies, which now offer a variety of affordable UBRs. Transferring the results of this \nfederally-funded research has created a new market, revolutionized private aviation, and increased safety \nin the skies. To secure prolonged growth, we need to make sure that Technology Transfer receives more emphasis \nand support in the future. Additionally, we need to encourage every government program to consider \nTechnology Transfer as a natural outcome and an opportunity to drive economic development through \nincreased manufacturing and new jobs. While there are some success stories similar to that of the UBR, \nmuch more can be done to generate additional benefits from valuable government investment. Our aim \nshould be to capitalize on research outcomes much more broadlyboth internally within the federal \nspace, as well as externally within the private sector. It is clearly of interest to the taxpayer to see that \nthese major investments benefit a wider community. Barry A. Costa and Vicki A. Barbur Ph.D. are members of the Technology Transfer Office at The MITRE Corporation ",
    "text": " () Trust, Public-Private Partnerships, and \nTransportation Safety: Applicability of the Aviation Model for Rail \nTransportation Laurence Audenaerd \nPatricia Massimini \nGregory Orrell \nJanuary 2017 MP 1 6 07 5 4 MIT R E P R O D U C T Approved for Public Release; Distribution Unlimited. Case Number 16-4791 Center for Advanced Aviation System Development ii Executive Summary \nWith a continuous decline in fatal accidents since the 1950s, the aviation industry during the mid-1990s viewed aviation as an extremely safe mode of transportation. High-profile accidents by United States air carriers that occurred during 1994 to 1996 however called into question whether the aviation accident record could reliably stand as the measure of safety health and culture. As a result, the Federal Aviation Administration undertook a unique approach to collaborating with industry to promote aviation safety by developing rigorous Safety Management Systems. This effort culminated in a highly successful public-private partnership devoted to continuous improvement in aviation safety. The Department of Transportation recognizes the success of the aviation model, wants to build on that success, and is proactively looking for opportunities to use the lessons learned from aviation in the rest of the transportation system. Given the many similarities between air and rail transportation, recent high-profile railroad accidents raise the question of whether rail transportation may benefit from using aviations collaborative approach to safety. This paper describes the factors contributing to the success of that approach, including instilling a safety management system and culture, evolving the regulatory and legal framework, and collaboratively sharing and learning from data. Through the sponsorship of the Federal Aviation Administration, The MITRE Corporations Center for Advanced Aviation System Development pioneered safety data sharing and analytics to identify and address proactively accident precursors. To understand the evolution of this approach, we present the historical context of the necessary human and system elements of the aviation domain, along with an analysis of how the Federal Aviation Administration-industry trust relationship evolved into the current culture, and how MITRE evolved our role. We also draw parallels between aviation and rail transportation and describe opportunities for applying aviations approach to rail safety. iii Table of Contents \n1 Introduction \nFigure 2-1. Safety Reporting and Positive Culture in SMS \nAir and rail transportation are highly effective in providing safe, high-speed service to long- distance destinations. Beyond their obvious differences of aluminum-wing-on-air and steel- wheel-on-rail, these industries share many characteristics. In both cases, the public has been fascinated by their elegance and convenience, yet also apprehensive of the associated dangers. While every transportation fatality is indeed a tragedy, fear and a lack of tolerance for multiple fatal outcomes in commercial transportation drive the emphasis on continuing to lower the probability of aircraft or train accidents [1]. Improving safety within both of these transportation modes remains an extremely high priority, and accident rates have impressively reduced over their histories. Two decades ago, when the aviation community witnessed six major high-profile accidents in two years, a White House investigatory commission recommended how to proceedsummed up in the opening sentence: Change. [2] When the Federal Aviation Administration (FAA) responded by adopting a more collaborative approach to aviation safety, the trust the FAA fostered within the U.S. aviation industry facilitated a partnership that further reduced accident rates to unprecedented lows. The last fatal accident involving a scheduled U.S. commercial passenger air carrier occurred in February 2009 [2]. The last fatal accident involving a scheduled U.S. commercial freight air carrier occurred in August 2013 [3]. Low accident rates have led other transportation agencies to take note. Leadership within the National Highway Traffic Safety Administration (NHTSA) asked of FAA, What did you do to make commercial aviation so safe? We want that safety record. We want our trend line to flat linejust like you [4]. In comparison to highways, rail transportation is very safe [5]. So why should the rail community adopt the aviation systems approach to safety to fix something that, by many accounts, is not broken? The rail industry continues to maintain a strong commitment to continuously improving safety by rooting out the causal factors of rail accidents. Innovative methods for the inspection of infrastructure and rolling stock can now generate vast data sets to predict failures before they happen. But no amount of inspection could have prevented the 2013 accident in Lac-Mgantic, Quebec, or the 2015 Amtrak derailment in Philadelphia, Pennsylvania [6] [7]. Even Positive Train Control (PTC) systems, which are being implemented to intervene in many cases of human error, may have directly prevented only the latter event. Because PTC is capable of generating vast amounts of operational data, it could contribute by providing valuable insights when fused with other data sources to address accidents it was not designed to prevent. By applying lessons learned from our experiences in aviation, the MITRE Corporations Center for Advanced Aviation System Development (MITRE CAASD) asserts that, given the many similarities between air and rail transportation, the rail industry is poised to benefit greatly from a similar collaborative and data-driven approach to safety. We assert that this is achievable through effective application of the principles of Safety Management Systems (SMS), an understanding of aviations successful public-private partnership, collaborative data-sharing and analytics, all underpinned by a positive safety culture. To understand the evolution of this arrangement, we describe the historical context of the behavioral, technical, and regulatory elements. We also provide an analysis of how the industry-government trust relationship evolved into the current approach. We envision that lessons learned from aviations safety history could accelerate the integration of these processes into the rail domain. 2-1 2 Safety Framework in Aviation \nThe FAA describes SMS as a formalized and proactive approach to system safety, as does the International Civil Aviation Organization [8]. Prescribing a framework for a manufacturer or service provider to integrate safety management into its day-to-day business activities, SMS provides the necessary components to enhance safety and to ensure regulatory compliance. SMS features processes that identify potential breakdowns before an unsafe condition can result. It promotes informed changes in an organization and a positive culture of collaboration to expose new opportunities for reliable information capture. Additionally, the scalability of SMS enables its broad use regardless of organizational size, and it can act as a vehicle for strengthening management-labor relations [9]. SMS comprises four key components [10]: Safety Policy outlines the processes required to achieve the desired safety outcomes. By establishing senior management commitment to these processes, this component establishes and promotes safety culture throughout the organization. Safety Risk Management (SRM) is a formalized process to assess system design by identifying and analyzing hazards as well as to establish controls to manage those risks. Safety Assurance requires information capture to ensure that risk controls, designed through the SRM process, achieve their intended objectives throughout the system life cycle. Safety Assurance also includes revealing hazards/controls not previously identified during the SRM process. Safety Promotion requires creating a positive safety culture environment to enable the achievement of safety objectives. SMS relies on both human and machine detection to discover safety hazards within the operational system. Data from a variety of sensors can be assembled to present high-precision pictures of the system with much more accuracy than by human detection. SMS is designed to rely on these data, but also on the human ability to anticipate hazardous outcomes from perturbations in the system and expose these detections. We illustrate safety reporting and positive culture in SMS in Figure 2-1, depicting both human (left loop) and automated machine sensors (right loop). These two inputs comprise safety hazard data that an analysis team can use to identify hazards, precursors, root causes, and the necessary corrective actions. The success of this process often depends on the richness of the data collected from both sources. Multiple accounts of the same event yield more depth and are enriched by multiple sensor systems capturing events or by multiple witnesses submitting detailed reports. Richness of data alone is insufficient for an effective SMS; the data must be trustworthy and reliable. Both forms of sensinghuman and machinerequire investment, management, and upkeep to operate reliably. Capturing reliable information from human sensors requires investment in training and in a positive safety culture that promotes action and trust. Following accidents, a commonly heard remark is, I knew that was going to happen eventually. This remark indicates that individuals closest to the accident were able to identify hazards but lacked the authority, motivation, or efficacy to pursue corrective actions [11]. 2-2 Figure 2-1. SMS Safety Data Capture Process The four components of SMS tie to one another by a currency of trust. As Barnard (2013) describes, a natural tension exists between the desire to obtain safety data from one of the persons most likely to be aware of a specific incidentthe person who made a mistakeand the desire to penalize such persons for their mistakes. [12]. The success of an SMS program hinges on trust. Employees who are reporting on safety hazards or events must trust that they will remain free
from punishment by management. And management must trust employees to provide reports, and not simply ignore safety hazards or foretell events. This type of organizational culture that actively protects those who report hazards (except in cases constituting criminal behavior or willful disregard for safety) defines just culture [13]. Punitive culture has roots in the Industrial Revolution, and we understand it well. The potential for punishment raises awareness in employees, and motivates care before acting. On the other hand, an employees fear of being blamed or punished for errant actions can degrade trust, and reduce his or her willingness to report on the associated hazardous situations. Trust and information-sharing provide the basis of a positive safety culture. When an organization places high priority on proactive safety, and values trust and information-sharing, the workforce perceives and responds to that priority eliciting a safety climate [14]. With an adequate level of trust and commitment, employees feel incentivized and empowered to report risks and share knowledge of risk factors without fear of reprisals (unless their actions were unlawful or reckless) [15]. Reported events become instructive, transforming the organizations knowledge and ability to gauge risk. Combined Sources Safety Hazard Data Human Operational Experience System State Sensor Data Sustaining the Process\nMaintains or Updates Safety Policy Monitoring Known Processes Identifying New Threats Promotes Positive Culture P\no\ns\nit\niv e\n R e\nin fo\nrc e\nm e\nn t C\no\nrr e\nc\nti\nv\ne A\nc\nti\no\nn\n I m\np le\nm e\nn te\nd N\no\nn -P\nu n\nit\niv e\n A s\ns\nu\nra n\nc\ne D\ne m\no\nn s\ntr a\nte d\n M g\nm t\nC o\nm m\nit\nm e\nn t In\nv\ne\ns\ntm e\nn t \na n\nd\n M a\nin te\nn a\nn\nc\ne C\nh a\nn g\ne M\ng m\nt\nfo r \nN e\nw T\ne\nc\nh n\no\nlo g\ny H\nu m\na n\n D a\nta S\no u\nrc e\n L o\no p A\nu to\nm a\nte d\n D a\nta S\no u\nrc e\n L o\no p SMS Data Capture Process Analysis Identifies Safety Hazard Precursors and Root Causes Management Ensures Corrective Actions Taken 3-1 3 A Historical Basis for a Collaborative Safety Partnership \nEarly in aviation and rail history, policy-makers reacted primarily to major accidents and exhibited a blame-based safety culture. Industry introduced safety technology with trepidation, mainly when tragedy insisted on quick adoption. As the decades progressed, the government began to show progressive signs of investing in research programs to dissect safety hazards. Early examples in aviation during the 1940s were simply an experimental testing of safety concepts, such as stall warning devices and approach lighting systems. In 1956, when a well-publicized midair collision occurred in clear and uncongested skies over the Grand Canyon (an accident that punctuated a string of sixty-five midair collisions in just over five years), it was clear that more aviation safety research was critically needed. Around that same time, railroads were changing rapidly. Mergers of large and small railroads were occurring that blended safety methods from each proponent together, with mixed results. Like the aviation field, a string of 20 high-profile rail accidents in the 1950s punctuated the need for further safety improvements. The 1960s marked a significant shift in the safety mindset in aviation and rail. At the close of the 1950s, in response to a string of aviation accidents and public concern, the Department of Transportation Act (DOT) of 1966 set up the FAA and Federal Railroad Administration (FRA). FAA made the commitment to intensify air traffic safety methods, safety policy, and forward- thinking safety research. With the advancement of safety data collection technology such as secondary surveillance radar systems and Cockpit Voice Recorders to accompany the widespread use of aircraft Flight Data Recorders, FAA identified the need to partner with trusted independent advisory organizations to provide expert analytics. In 1961 FAA employed the help of Flight Safety Foundation to investigate the mid-air collision epidemic and compile statistical data, perform analyses, and provide recommendations. The study was based on pilot reporting and identities were protected from FAA to encourage pilot participation. This approach led to generating information regarding more than 2,500 incidents over a one-year study period. The final report recommended that FAA continues the collection of anonymized reports; however, the program did not extend beyond the study period [16]. At the end of the decade, FAA began a four-year study on the causes of near midair collisions. This study employed a non-punitive, cooperative reporting approach. To encourage participation, FAA granted limited immunity from disciplinary action to any person involved in a voluntarily reported near midair collision during the study. However, when the pilot study period terminated in 1972, so did the reporting immunity policy. During this period, the FRA also made strong commitments to rail safety. The NTSB would later show that during this period about a third of collisions and derailments were attributed to incorrect operating practices and employee negligence [17]. By assuming the powers of the Interstate Commerce Commissions Bureau of Railroad Safety, the FRA sought to shift the focus of rail safety regulation to people familiar with the industry [18]. Public pressure over rail accidents also prompted Congressional investigations, which concluded that the vast majority of accidents were caused by factors that were not covered under existing statutes. The result of this shift in focus was the Federal Railroad Safety Act of 1970 which gave the FRA rulemaking authority to \"promote safety in all areas of railroad operations and to reduce railroad related accidents, and to reduce deaths and injuries to persons and damage to property caused by accidents involving any carrier of hazardous materials.\" [19] Annual safety records 3-2 became a requirement for certification of railroads from the States to the Secretary of Transportation. The government listed highway-rail grade crossing incidents as the top safety task to research and address. These remain a top safety priority today. Class I railroads formed under the Regional Rail Reorganization Act of 1973 [20] required railroads to adopt safety procedures and cultures from merging railroads. In the early 1970s, public confidence in the aviation system started to unravel, fueled mostly by the increasing number of hijackings and high-profile accidents. By the end of 1974 (aviations worst year for fatalities), a biting congressional report and television documentary illustrated the agencys sluggishness on safety issues and further raised public concern [21] [22]. Prompted by these criticisms, in 1975, FAA established the Aviation Safety Reporting Program (ASRP) to enable pilots or controllers to identify any potentially unsafe conditions and not simply to report near midair collisions. To again encourage reporting, this broader safety program employed the same arrangement used during the midair collision program: granting immunity from disciplinary action for those reporting promptly. FAA retained the right to take appropriate punitive action in cases of gross negligence or willful disregard for safety. Due to limited protections granted under the aviation reporting program, the aviation community still feared disciplinary consequences and employees submitted very few reports [16]. The next year, FAA transferred control of the program to a neutral third partythe National Aeronautics and Space Administration (NASA)to handle the data, protect confidentiality, and process reports. The FAA intended to overcome fears that genuine anonymity and immunity were not being provided. The government named the program the Aviation Safety Reporting System (ASRS). This program is the aviation equivalent to rails Confidential Close Call Reporting System (C3RS) managed by NASA [23]. In terms of technology and its role during this timeframe, the growing introduction of computers in aviation, safety-related sensing equipment, and data-recording technology rapidly expanded capabilities for weather sensing, communications, on-board collision avoidance, and flight tracking. Air Traffic Control (ATC) radar systems saw increased abilities to detect, record, and share flight data between radar facilities, and the amount of data collected by Flight Data Recorders expanded. In rail, the FRA enacted the Rail Safety Improvement Act (RSIA) of 1988 [24]. This act mandated event recorders on the railroads, requiring rail operators to record locomotive control inputs and other safety-related data. Building on tensions from the previous decade, aviation in the 1980s experienced growing mistrust amidst the airlines, the government regulators, and the traveling public. Labor strikes by airline pilots and air traffic controllers, significant airline merger activity, and widespread industry drug and alcohol abuse continued to stoke the discord between workforce, management, regulator, and public [25]. In other circumstances FAA delegated technical assessments directly to the manufacturers, relying on localized trust-relationships rather than directly assessing technology [26]. This behavior served to undermine the overall ability of the FAA to effectively regulate the industry. In 1988, a Congressional report recognized a need for industry collaboration and recommended key safety management and system operating improvements considering the new order set by the Airline Deregulation Act of 1978: Airlines themselves keep vital safety information, and FAA could benefit from working more closely with airline data, although ensuring the confidentiality of the air carrier data 3-3 is crucial. FAA could encourage improved air carrier presorting of sensitive safety data, such as incidents, by guaranteeing that no penalties will result from reported information and by making non-reporting a violation. Additionally, access to airline computer systems, such as maintenance management systems, could enhance FAAs monitoring capabilities. One major airline already provides FAA
on-line access to its computerized maintenance database. [27] The underlying concept resembles the core of the current-day public-private partnership model, but the recommendation lacked a key ingredient trust. By insisting that airlines grant FAA direct access to airline computer management systems and penalizing non-reporting, the recommendation revealed the governments lack of trust for the industry and its need to assert authority over the industry. The mechanism for a collaborative safety process may have been prescribed, but without an investment in building trust as a foundation, the industry maintained its status quo for nearly another decade. As in the past, tragedy spawned action. During a period between July 1994 and July 1996, six high-profile major accidents occurred, resulting in 737 fatalities. Midway through this string of accidents, in January 1995, FAA held an industry-wide summit setting a goal of zero accidents through key areas, including safety, maintenance, and operational data collection and sharing. This decision later culminated in the Aviation Safety Action Program (ASAP). ASAP was enabled through the agreement with airlines and pilots associations to begin the Flight Operations Quality Assurance (FOQA) program, which collects Flight Data Recorder data to analyze safety trends rather than conduct only post-incident investigations. It granted FAA access to the data, with pilot identities deleted. Following the ValuJet crash in the Florida Everglades in May 1996 and the midair explosion of TWA Flight 800 two months later, President Clinton announced the White House Commission on Aviation Safety and Security to review the state of aviation safety. The findings of the Commission challenged the government and industry to reduce the accident rate by 80 percent over ten years [2]. A Congressional commission, the National Civil Aviation Review Commission, followed up in December of 1996 with a recommendation that FAA and industry work together to develop a comprehensive, integrated safety plan to implement existing safety recommendations [28]. These government reports recognized that the forecasted air traffic demand would exceed the limitations of existing safety strategies. The FAA responded with an approach that was a radical departure from the typical model in which the industry was regulated from a position of authority. The decision to engage in collaborative efforts to develop mitigations provided the framework for the formation of a public-private partnership for aviation safety. 4-1 4 Ingredients for a Collaborative Partnership \nFAA enabled the creation of a public-private partnership by separating the internal safety improvement organization from the regulatory organization. This separation permitted the safety improvement organization within FAA to create a partnership with industry based on equality. Formed in 1998 as the Commercial Aviation Safety Team (CAST), this unique group committed to working together to sift through large numbers of proposed safety improvements [29]. Their initial goal was to prioritize mitigations by impact, feasibility, and cost through consensus agreement. Rather than being forcibly required by regulatory compliance, implementation was voluntary. Examples include aircraft and avionics manufacturers committing to functionality improvements and airlines upgrading airframes and changing flight crew training [30]. Since its inception, participation in CAST grew to include virtually all government and industry sectors of aviation, which enabled the implementation of CAST safety enhancements to be impactful and widespread. As stated, the original CAST goal was very aggressive: to reduce the commercial aviation fatality rate in the United States by 80 percent in 10 years. CAST tackled this challenge by developing a process to identify and prioritize top safety areas through analyses of accidents and incidents and the chain of events leading up to them. Once an underlying problem was understood, the CAST membership identified and implemented high-leverage interventions or safety enhancements to reduce the fatality rate in these areas. This model has been extremely successful for the U.S. aviation industry. Accident data from 1998 to 2008 show that the fatal accident rate (with one or more fatalities per departure) of commercial air travel has been reduced in the U.S. by 83 percent, exceeding the original CAST goal. Since then, CAST has set new goals: to reduce the U.S. commercial aviation fatal accident rate by at least 50 percent between 2010 and 2025 and to work with international partners to reduce fatality risk in worldwide commercial aviation [31]. The analysis of commercial aviation accidents provided a solid foundation for the initial CAST focus. The CAST approach was so successful that fatal accidents became a rarity. That required an innovative approach to broadening the initial focus. The group turned their sights to more prognostic analyses using events that did not result in accidents but provided an indication of safety risk. This required operators to continually collect data through the voluntary programs enacted earlier, such as the FOQA and ASAP and its ATC analog, the Air Traffic Safety Action Program. These rich sources of information provide insight into millions of operations and help to identify potential systemic safety issues and trends. Traditionally, the sponsoring airline or FAA organizations kept these data sources. These organizations were willing to share these data sources at the national level and analyze them collectively and collaboratively to identify risks proactively. Determining the accident precursors would require dedicated technical expertise to mine and analyze this massive and constantly growing data set. So the Aviation Safety Information Analysis and Sharing (ASIAS) program was initiated in 2007 to perform the data analytics. Learning from past experiences, FAA once again decided on employing a neutral third partyits Federally Funded Research and Development Center (FFRDC) operated by MITRE CAASDto house, protect, and analyze the data supporting the needs of the CAST partnership. 4-2 Data sharing in the ASIAS program was entirely voluntary. Starting with seven participants, it has grown remarkably widespread. Currently, FAA and most air carriers, manufacturers, associations, and employee groups contribute data or advisory support. In fact, more than 40 airlines representing 99 percent of commercial aviation operations voluntarily contribute proprietary data. MITRE CAASD handles the data under strict confidentiality protections and uses data in aggregate analyses of systemic safety problems. MITRE CAASD mines and analyzes vast databases to track previously identified risks that require continuous monitoring, or to identify new risks or threats that have not been revealed by forensic investigations. The ASIAS program monitors known risks, those which have been identified previously and currently controlled. ASIAS analyzes the uneventful flights (those that did not experience an accident or significant safety event) to monitor for these known risks, which are precursors that have shown links to accidents. These risks include a characterization of the rate of occurrence of these precursors, and conditions for these precursors to occur. ASIAS participants and CAST use the information from known risk monitoring to track the effectiveness of mitigations that were implemented to reduce these risks and to provide an alert if there is an upward trend in a known risk. In one example, ASIAS extracted information about safety system alerts that warn pilots about terrain proximity. ASIAS metrics, based on captured flight parameters, were used to identify hotspots (areas of greatest alerts concentration). Combined with an analysis of voluntary text reports from pilots and controllers, the data sources reconstruct conditions that lead to alerts. With this information, CAST collectively developed safety enhancements for aircraft equipment upgrades and proposed route changes to reduce the frequency of proximity to terrain warnings. Once mitigations are in place, ASIAS continues to monitor these known risks to measure the effectiveness of the mitigation. The ASIAS program also seeks to identify latent risks, which are those that may have been present for years, setting up conditions that could ultimately result in an accident. An example of a latent risk is aircraft wing flap misconfiguration (or reconfiguration) during takeoff. While the importance of correct flap configuration is well understood, ASIAS first measured the incidence of misconfiguration during takeoff using a large data set from airline operations. The new information about the rate of occurrence and the conditions associated with these events contributed to the FAA issuing an official Safety Alert for Operators and CAST efforts to develop new mitigations to reduce the incidence [32]. Finally, the ASIAS program assesses the potential for emerging risks associated with the introduction of new operations and equipment, which may inadvertently contribute to unintended effects or anomalies. ASIAS analysts identify aspects of new operations and equipment that have safety relevance so that new threats can be identified early and resolved before they contribute to an accident. The public-private partnership has produced numerous aviation system safety benefits. CAST developed more than 100 safety enhancements, with the majority supported by detailed ASIAS analytics. By combining incident reporting with detailed data on operational activities, the identification of precursors has been much more successful via collaboration than within individual organizations alone [33]. 5-1 5 Structuring the Collaborative Public-Private Partnership \nWe structure the collaborative public-private partnership for data sharing and safety improvement based on the CAST and ASIAS model. The public-private partnership convenes through a consensus decision-making group including representatives from both industry and regulators. These individuals work together to make consensus decisions (Figure 5-1 top-center box) on salient safety-related issues in the form of
policy recommendations and voluntary corrective actions or mitigations. In the aviation model, CAST is the public-private partnership, and the ASIAS program is the neutral third-party analytical support. The success of this model hinges on a shared trust between all of the parties involved. In this model, the ability of the neutral third party to steward data in a manner that shields it from regulatory inspection and public access granted via the Freedom of Information Act (FOIA) enables industry partners trust. The industry agreement to provide industry perspectives and participate in consensus decisions is also a critical element of this models success. The contributions the parties make (also labeled in Figure 5-1) consist of the industry membership providing operational data and individuals confidential reports. While optional for the success of the program, the CAST model enables industry partners direct access to specifically approved benchmarks (shown as the dashed line in Figure 5-1). The regulators provide government-collected data and direction in the form of safety-related research needs. Also, in this model, the regulators provide funding to the neutral third party for their analytical services, although other structures could likely be as successful. Finally, the consensus decision- making group contributes goals and requirements to the analytical third party and in return receives alerts, metrics, trends, and precursors. The neutral third party does not identify and communicate mitigations, however. Consensus decisions in the Public-Private Partnership develop the identification and communication of mitigations. Figure 5-1. Structure for a Public-Private Partnership for Safety 5-2 Four high-level stages are necessary to enable a successful partnership, which is as follows: Identify Barriers: Determine laws and policies that prevent non-punitive reporting of incidents (free of disciplinary actions), and get buy-in from legal and operational personnel. Decisions on how culpability is handled, are required. Develop Policies: Develop confidential reporting procedures and structures to enable de- identification/protection from FOIA and other legal proceedings. Remove barriers to make reporting easy, determining what is mandatory, what is voluntary, whether follow- up interviews are allowed, etc. Specify Actions: Define specific roles and responsibilities for implementing and maintaining a safety culture. Establish governance for handling sensitive data, and the design, training, and usage of reporting forms and data repository systems. Analyze and Implement: Build data analytics and information-sharing methods. Educate stakeholders about lessons learned. Implement learning into decision-making and policy. Continue to measure safety improvements. The development of a successful partnership requires investment by all parties within industry organizations, and by the government regulator. The efforts are not without cost, but the cost is far less than those related to fatal accidents. In a successful partnership, each industry member: Implements SMS (or an analogous structured, formalized safety management process) \nused to identify and control risks; Captures safety-related data from automated sensor technology; Institutes a confidential safety hazard reporting system; Fosters a positive, non-punitive safety culture; and Develops capacity for data capture and transmission to enable data fusion, mining, and \nanalytics. In parallel, the government regulator enables an equal partnership role specifically for improving safety. A public-private partnership features industry forums to share safety information collaboratively, form agreements on common statements of fact and implement mitigations. The underlying ingredient in the above elements is the level of trust between the regulator and the regulated, and the general industry attitude toward sharing information among industry organizations for a shared benefit. The maturity of the partnership is not developed instantaneously but rather evolves over time with trust. 6-1 6 Potential for Collaborative Partnership in the U.S. Rail Sector \nAviation and rail operating structures have many similarities due to their overall mission of providing long-distance transportation. Rail and air vehicles travel along strictly defined networks between terminal areas or transfer points while maintaining vehicle-to-vehicle separation distances for efficiency and safety. Both systems employ analogous centralized traffic control regimes communicating to vehicles operated by multi-person crews. Commercial air traffic flow is under positive control, a method that continuously tracks and collectively directs vehicle movements to ensure safe separation in three dimensions. Railroads employ a two- dimensional block-occupancy control model. Rights-of-way divide into discrete segments, and vehicle performance, track geometry, and the location of preceding trains governs train movements between blocks. The North American railroad and airline industries each have a small number of major business entities formed by a flurry of mergers and acquisitions, supported by many smaller service entities. These similarities encourage us to examine other similarities that motivate or show evidence of a collaborative partnership in the rail sector. The rail sector, like aviation, maintains a strong commitment to safety and has experienced a steady decline in fatal accident rates despite periods of rising and falling demand. Both industries monitor and manage accident causes, and in the case of rail, derailment rates have not risen [34]. From 1975 to 2010, per capita fatality risk (i.e., the probability that any one member of society dies on the associated mode) has declined by roughly two-thirds in railroading and by four-fifths in aviation [35]. The rail industrys workplace fatality rate is equal to that of aviation, at 0.06 per 1000 workers [35]. Despite these statistics, the FRA and major representative industry organizations including the Association of American Railroads (AAR) and the American Short Line and Regional Railroad Association (ASLRRA) remain unsatisfied with the current record [36] [37] [38]. The Rail Safety Improvement Act of 2008 (RSIA [2008]) and recent accidents are large motivational forces behind improving safety. Railroads in the United Kingdom (UK), across the European Union, in Australia, and in North America apply SMS. Because the rail networks intermix, policy-making activities across North America have strong implications for the U.S. rail sector. In Canada, the 1999 amendment to the Rail Safety Act of 1985 required railroads to implement SMS and move away from a compliance-based approach. The purpose of this amendment was to foster success that depended on a partnership between industry and regulator and that railroads would benefit from an increased competitive advantage, reduced regulatory oversight, and improved relationships, partnerships, and collaboration. [39]. However, a 2007 Rail Safety Act Review panel and a more recent review following the high-profile accident in 2013 in Lac-Mgantic, Quebec revealed that railroads lacked implementation consistency and expressed skepticism about the regulators intentions [39] [40]. As with aviation, railroads have been increasingly applying technology across all aspects of the industry. Technology uptake in rail takes longer than in aviation due to much longer life cycles that enable much older rolling stock and locomotives to continue easily operating in the system. Focused research has revealed that track or wheel defects contribute greatly to accidents and derailments [34]. Currently, the major Class I railroads are investing in innovative efforts to capture safety data relating to the dynamics of infrastructure and rolling stock through an array of advanced trackside sensors [41] and via unmanned aircraft systems [42] to predict failures and causal factors. The massive development efforts involved in PTC are designed to intervene in operations to control operational risks and address human errors. With the rapid expansion of 6-2 sensor technology usage, the potential for a secondary use of this inspection data and those required to support PTC implementation and operations creates an opportunity for further safety benefits. As PTC is rolled out in the system, collected data could be used to analyze not just PTC events, but also to frame the environmental conditions associated with accidents, incidents, or contributory factors. Analogous to aviation near midair collisions, PTC intervention events can provide information into what could be happening that leads up to potential derailments or collisions. Developed in parallel to the CAST public-private partnership, the UKs Confidential Information Reporting and Analysis System (CIRAS) model borrowed from past experiences of confidential reporting in aviation. CIRAS addresses what had been identified as a lack of adequate feedback for incident reporting. Efforts to develop CIRAS began in 1995 as a result of a report regarding the under-reporting of safety-related incidents by ScotRail employees due to the blame culture perceived at that time [43]. Soon after CIRAS produced promising results at ScotRail, many other railways in the UK joined the program. In 1999, the decision to mandate the program nationally followed a high-profile accident in central London that shook public confidence [44]. In the U.S., following a House Transportation and Infrastructure Committee report in 2007 that revealed rail safety reporting issues [45], the FRA began a pilot program. This program involves collaborating with the DOT and NASA to develop a system, equivalent to ASRS, for railroad safety. It was entitled the C3RS, as mentioned in Section 3. Piloted by seven passenger railroads (AMTRAK and those around the Boston, New York, and Chicago metropolitan areas), the FRA demonstration project was intended to improve railroad safety by allowing railroad companies to report close calls without being penalized by FRA. By design, before inclusion into the database, reports were de-identified and then reviewed for completeness. Successful initial results indicate that the program is expanding after lessons learned are incorporated [46]. For instance, the committee found that limitations with the effectiveness of the C3RS
system were often its lack of corroborating reports [47]. In the last several years, there have been mixed indications regarding the establishment of a positive safety culture in the railroad industry. News media cited court cases of freight railroads unreasonably firing workers for raising safety concerns [48] [49] or simply reporting on-the-job injuries [50]. One Class I railroad was accused of firing whistle-blowers and pressuring workers to ignore critical safety checks [51]. There were examples of a highly positive safety culture throughout the industry, with many found in passenger railroads possibly as a consequence of market demands for safe transportation [52] [15]. As recently as this year, FRA identified deficiencies in the safety culture at the company level, the industry level, and the level of regulatory agency oversight. FRA is actively seeking to understand the problems, gaps in the industry and regulatory oversight, and the barriers to implementation of safety culture initiatives [53]. The railroads also recognize that broad changes are in order and have invested heavily in improving safety culture. Ongoing FRA-sponsored safety culture demonstrations [54] enable lessons learned to develop a better industry-wide reporting system, which requires high-quality data inputs and collaboration from the industry as a whole. The use of a neutral third party for dedicated analytics would support industry and regulator collaboration. Visualization of national trends is possible with an industry-wide data reporting system. This better focuses safety efforts and regulatory development where needed. Knowing the issues will allow for a targeted response, resulting in less over-regulation across the industry and focused mitigation options for the railroads. 6-3 Examples of successful U.S. public-private collaborations between the FRA and the rail industry currently exist. The AARs Transportation Technology Center, Inc. operates an industry research testing facility under contract with the FRA. Similarly, the ASLRRA developed the Short Line Safety Institute, a non-profit supported by FRA and Congressional funding, to enhance and improve safety in all respects on short line and regional railroads across North America. [36] At the request of the FRA, a voluntary educational partnership, entitled the Switching Operations Fatality Analysis (SOFA) working group, was formed in 1998 between AAR, ASLRRA, and labor unions with the explicit goal of eliminating all switching fatalities. Their focus was similar in nature to that of early CAST efforts: to review select fatal accident cases to determine common mitigation strategies. The intention of the group was that findings and recommendations were to be used voluntarily, not in formal rulemaking processes. While SOFA has been successful as a collaborative partnership, a 2011 report found room for improvement: ideally, reductions in switching operation fatalities would be directly attributable to SOFA interventions [55]. In the last few years, both the government and industry have been demonstrating proactive safety. The FRA endorses the advancement of proactive approaches for early identification and reduction of risk, and this year it has taken action to mandate safety PTC for certain rail operations, as well as System Safety Programs for U.S. commuter and intercity passenger railroads. The FRA also issued a Notice of Proposed Rulemaking in 2015 regarding the mandate of Risk Reduction Programs for U.S. freight railroads. AAR cites on their website that with record levels of private spending on capital improvements and maintenance over the last five years and more than $600 billion spent since 1980, Americas privately owned freight railroads are at the forefront of advancing safety. Despite this progress, some laws and regulations unique to railroading pose challenges to a successful transition to a safety culture in rail transportation. For example, the Federal Employers Liability Act of 1908 (FELA) was long ago adopted to protect injured railroad workers but requires claimants to prove negligence by the railroad; otherwise, workers are responsible for their injuries [56] [57]. By pitting worker versus railroad, a dynamic builds that may oppose a positive safety climate. Attention is needed to changing the business environment and other barriers impacting a successful collaborative environment. Fortunately, as demonstrated throughout the history of aviation, laws can be changed. Another challenge falls in the area of secure and effective handling of event reporting and collected data. Methods and analytics that accurately involve the what, where and when of events are critical but protecting the who is of utmost importance. In cases where there are mishandling of reporting, the delicate trust relationships, central to success, could easily break down. A regulator or manager seeks to penalize employee errors, secured data becomes compromised, or analyses lack sufficient quality. Learning from experiences and leading practices across both domains will be key to the successful collaborative partnership for rail safety. As with any positive, successful relationship, it requires trust and hard work. 7-1 7 Conclusions \nAviation safety has benefitted immensely from developing a trust between industry and government, enabled by the successful partnership, a strong commitment to implementing SMS, and a positive safety culture. Given the similarities between air and rail transportation, a similar approach could benefit rail safety. This paper offers lessons learned from aviation, provides examples of technology and other investments to augment causal analysis, and raises the need for shifts in culture and legal and regulatory frameworks. SMS implementation and the adoption of a safety culture require commitment and dedication. Behavioral and technological change hinges on continued maintenance and investment in SMS implementation and safety culture commitment. Developing and nurturing trust between industry, labor, and government lead to new policies, increased reporting of safety-related incidents, insight into causal factors, and data-driven decisions on effective mitigations. There is evidence of some shifting in the rail domain, and continued evolution is needed. Finally, while evidence of working partnerships built in the rail industry has led to some success, the dynamic seems to retain the authoritative role of the regulator and the emphasis on inspection. With the increasing adoption of high technology in railroading, an opportunity exists for rail safety to borrow from the modal similarities and lessons learned over the past 20 years in aviation safety. A significant amount of industry attention has been on PTC and its design, benefits, and challenges, with little discussion looking at the change implications and the potential for revealing new safety risks, or the value of the data generated by PTC and similar systems [56]. With the improved development and implementation of PTC, the potential to take a collaborative approach could be used to proactively determine and control the emerging risks associated with the advent of PTC. Additionally, the opportunity to tailor the system design to support advanced, collaborative safety analytics could allow railroads to realize secondary benefits of the system, beyond the current designs. Data regarding track locations, locomotive and train location and performance, signal and switch status, PTC settings and performance, and corridor scheduling could all contribute to identifying the risks for rail operations. A collaborative approach to rail safety is underway, and through targeted measures, time, and commitment this approach seems likely to achieve reduced accident rates. 8-1 8 References [1] E. Wilson, Everyone Loves a Good Train Wreck: Why We Cant Look Away, New York: Macmillan Publishers, 2012. [2] White House Commission on Aviation Safety and Security, Final Report to President Clinton Vice President Al Gore, Chairman, February 12, 1997. [3] NTSB, Crash During a Nighttime Non-Precision Instrument Approach to Landing, UPS Flight 1354, 2013. [Online]. Available: https://www.ntsb.gov/investigations/accidentreports/pages/AAR1402.aspx. [Accessed December 2016]. [4] P. Gilligan, Its All About Trust, Dallas Fort Worth, 2016. [5] Bureau of Transportation Statistics, National Transportation Statistics 2016 Table 2-1., U.S. Department of Transportation, 2016. [6] Transportation Safety Board of Canada, Lac-Mgantic runaway train and derailment investigation summary, Railway Investigation Report R13D0054, 2014. [7] E. Fitzsimmons and J. Keller, Why an Amtrak Train Derailed in Philadelphia, New York Times, May 17, 2016. [8] Federal Aviation Administration, Safety Management System Manual v. 4.0. FAA Air Traffic Organization, 2014. [9] Federal Transit Administration, Safety Management Systems: Why SMS?, Brochure, 2016. [10] K. Hollinger, Safety Management Systems for Aviation Practitioners: Real-World Lessons, AIAA Library of Flight, 2013. [11] N. Keren et al., \"Can Level of Safety Climate Predict Level of Orientation Toward Safety in a Decision Making Task? Safety Science Vol. 49, pp. 1312-1323, 2019. [12] D. Y. Barnard, Legal Issues Related to Developing Safety Management Systems and Safety Risk Management at U.S. Airports, Transportation Research Board ACRP Legal Research Digest No. 19, January 2013. [13] S. Dekker, Just Culture: Balancing Safety and Accountability, 2nd Edition, Ashgate Publishing Ltd., 2012. [14] T. Farrington-Darby et al., Understanding Safety Culture and Strategies for Improvement in Railway Maintenance, edited by J. Wilson, et al., Aldershot, Eng.: Ashgate Publishing, Ltd., 2015. [15] H. Roberts et al., TCRP Report 174: Improving Safety Culture in Public Transporation, Transportation Research Board of the National Academies, Washington, D.C., 2015. 8-2 [16] Federal Aviation Administration, FAA Historical Chronography: Civil Aviation and the Federal Government, 1926-1996, Government Printing Office, 1998. [17] Federal Aviation Administration, 1997-2015 Update to FAA Historical Chronography: Civil Aviation and the Federal Government, 1926-1996, Government Printing Office, 2016. [18] M. Hansen, C. McAndrews, and E. Berkeley, History of Aviation Safety Oversight in the United
States, DOT/FAA/AR-08/39 NEXTOR-University of California at Berkeley, July 2008. [19] United States Code (1970), Public Law 91-458, Railroad Safety Act of 1970, [Online]. Available: http://uscode.house.gov/statutese/pl/91/458.pdf. [Accessed December 2016]. [20] United States Code (1973), Public Law No. 93-236, 101 et seq. (Jan. 2, 197445 US.C. 701 et seq. (Supp. I, 1974), [Online]. Available: https://www.law.cornell.edu/uscode/text/45/701. [Accessed December 2016]. [21] Federal Railroad Administration, Confidential Close Call Reporting System (C3RS), 2002. [Online]. Available: https://www.fra.dot.gov/Page/P0347. [Accessed December 2016]. [22] United States Code (1988), Rail Safety Improvement Act of 1988, Public Law 100-42, [Online]. Available: https://www.govtrack.us/congress/bills/100/s1539/text. [Accessed December 2016]. [23] E. A. Haine, Disaster in the Air, Associated University Presses, 2000. [24] J. Downer, Trust and Technology: The Social Foundations of Aviation Regulation, The British Journal of Sociology Volume 61, Issue 1, 2010. [25] U. C. O. o. T. Assessment, Safe Skies for Tomorrow: Aviation-Safety in a Competitive Environment, U.S. Government Printing Office, Washington, D.C., 1988. [26] National Civil Aviation Review Commission, Avoiding Aviation Gridlock and Reducing the Accident Rate, December 1997. [27] Transportation Research Board, Commercial Aviation Safety Team: A Unique Government-Industry Partnership, in TR News, No. 203, Washington, D.C., Transportation Research Board of the National Academies, July 1999, pp. 4-10. [28] W. Rosenkrans, No Turning Back, Safety Oversight. Aero Safety World, November 2011. [29] Federal Aviation Administration, CAST Fact Sheet, April 12, 2016. [30] Federal Aviation Administration, SAFO 14005: 14 CFR Part 121 Operators Flap Misconfiguration Events, November 25, 2014. [31] W. Rosenkrans, Common Cause, Strategic Issues. Aero Safety World, August 2009. 8-3 [32] R. Anderson and C. Barkan, Railroad Accident Rates for Use in Transportation Risk Analysis, in Transportation Research Record, No. 1863, Washington, D.C., Transportation Research Board of the National Academies, 2004, pp. 88-98. [33] I. Savage, Comparing the Fatality Risks in United States Transportation Across Modes and Over Time, in Transportation Economics 43, 2013, pp. 9-22. [34] Federal Railroad Administration, Research and Development Strategic Plan FY13-FY17. [35] Association of American Railroads, in Railroads: Moving America Safely, June 2016. [36] Short Line Safety Institute, Press Release, ASLRRA Names Five Industry Experts and Assessor for Short Line Safety Institute, January 22, 2015. [37] Transport Canada, Stronger Ties: A Shared Commitment to Railway Safety, in Railway Safety Act Review Secretariat, Ottawa, Canada, November 2007. [38] B. Campell, Little progress on rail safety in wake of Lac Mgantic, in Toronto Star, April 14, 2016. [39] Transportation Technology Center, Inc., in Annual Report, Pueblo, CO, 2016. [40] M. Wanek-Libman, FAA, BNSF Partner on Use of Drones, in Railway Age, March 8, 2015. [41] M. Wilsdon and H. Muir, CIRAS History and Issues Arising During Development, in Rail Human Factors, edited by J. Wilson et al., Aldershot, Eng., Ashgate Publishing, Ltd., 2005. [42] C. Batchelor, Rail Industry Agrees on Safety Improvement Plan, The Financial Times, 26 October 1999. [43] F. G. M. Ackermans, Corporate Safety and Regulatory Affairs, CP, Statement to U.S. House of Representatives, Committee on Transportation and Infrastructure, October 25, 2007. [44] Federal Railroad Administration, C3RS is Implementing Corrective Actions and Expanding Within the Railroad Industry, Report RR-08, April 2016. [45] J. e. a. Multer, Developing an Effective Corrective Action Process: Lessons Learned from Operating a Confidential Close Call Reporting System, DOT/FRA/ORD 13/12, 2013. [46] M. Carter, Railroad whistle-blower awarded $1.25M, The Seattle Times, July 1, 2015. [47] K. Lydersen, Oil Boom Raises Safety Concerns for Whistleblower Railworker, In These Times, February 14, 2014. [48] R. McCabe, Ports and Rail: Norfolk Southern told to pay another fired employee, The Virginian-Pilot, August 9, 2012. [49] A. Ahearn, Ex-employees claim a major U.S. freight railroad company has ignored key safety checks, PRI, July 21, 2014. 8-4 [50] K. O'Connor, Safety Culture Oversight in Transportation, Presentation Slide Materials. NJ Transit Rail Operations, 2013. [51] Federal Railroad Administration, FRA-HF-003 R&D Safety Culture Strategic Roadmap and Implementation Plan, Broad Agency Announcement Appendix C, March 2016. [52] J. J. Samuels et al., Special Report 316: Evaluation of the Federal Railroad Administration Research and Development Program, Transportation Research Board of the National Academies, Washington, D.C., 2015. [53] Federal Railroad Administration, Findings and Advisories of the SOFA Working Group, Volumes I & II, April 2011. [54] Brotherhood of Railroad Signalmen, About the Federal Employers Liability Act, March 2011. [55] United States Code of Regulations (1908), Federal Employers Liability Act, Title 45 U.S.C. 51. Retrieved December 2016, [Online]. Available: http://uscode.house.gov/view.xhtml?path=/prelim@title45/chapter2&edition=prelim. [56] C. Van Dyke, Impacts of Positive Train Control and Implications for Further Research, Presentation at INFORMS Annual Meeting, Austin, TX, 2010. Appendix A Abbreviations and Acronyms Definition AAR Association of American Railroads ASIAS Aviation Safety Information Analysis and Sharing ASLRRA American Short Line and Regional Railroad Association ASRP/ASRS Aviation Safety Reporting Program/System ATC Air Traffic Control ATSAP Air Traffic Safety Action Program C3RS Confidential Close Call Reporting System CAST Commercial Aviation Safety Team CIRAS Confidential Information Reporting and Analysis System DOT Department of Transportation FAA Federal Aviation Administration FELA Federal Employers Liability Act of 1908 FFRDC Federally Funded Research and Development Center FOIA Freedom of Information Act FOQA Flight Operations Quality Assurance FRA Federal Railroad Administration NASA National Aeronautics and Space Administration NHTSA National Highway Traffic Safety Administration PTC Positive Train Control RSIA Rail Safety Improvement Act SMS Safety Management System SOFA Switching Operation Fatality Analysis SRM Safety Risk Management U.S. United States UK United Kingdom Introduction\n Safety Framework in Aviation\n A Historical Basis for a Collaborative Safety Partnership\n Ingredients for a Collaborative Partnership\n Structuring the Collaborative Public-Private Partnership\n Potential for Collaborative Partnership in the U.S. Rail Sector\n Conclusions\n References\n Abbreviations and Acronyms ",
    "text": " () Approved for Public Release Distribution Unlimited Case Number 16-4263 Enabling an Agile Enterprise with \nModel-Based Systems Engineering \n(MBSE) and Discrete-Event \nSimulation (DES) Version 1.0 \n12/22/2016 Hart, Norwood, Dandashi \nDecember 2016 D O C U ME N T N U MB E R MTR160427 M IT R E P R O D U C T The views, opinions and/or findings contained in this report are those of The MITRE Corporation and should not be construed as an official government position, policy, or decision, unless designated by other documentation. All rights reserved. Location: McLean, VA Approved for Public Release Distribution Unlimited Case Number 16-4263 i Approved for Public Release Distribution Unlimited Case Number 16-4263 Table of Contents 1. Executive Summary \nTo analyze complex systems, stakeholders apply ad-hoc methods to model their systems and transfer their inputs to simulation engineers. What is needed is a holistic approach that enables an agile approach to analytics. Systems are tested and validated against the technical requirements, and then they are delivered. Such an approach integrates the validation requirements as an active part, allowing engineers and operators to evaluate and ultimately validate alternative approaches in an agile environment, which are optimized, feasible, and valid by their design. This paper describes a pilot project to study the feasibility of an approach that supports architecture development trade- off analyses incorporating sponsor data with MBSE tools as a first step towards a holistic approach to analytics. This approach allows for integrated analysis of model data in the context of a common architecture. The pilot (and approach) described in this paper produced an integrated model containing architecture artifacts, operational constraints, and requirements within an MBSE tool repository that allowed validation of requirements as an integrated part of the architecture development process. The model was executed to enable evaluation over the various mission threads and related operational constraints thus allowing architecture trade-off analyses based on operational metrics. With this approach, analysis results are documented as part of the model and are reproducible. In FY16 the MITRE team engaged an Army sponsor using an MBSE approach for evaluating radio architecture suitability utilizing as-is Army deployment architecture, mission essential requirements and one mission specific MEDEVAC thread. The approach and prototype have been transitioned to an Army sponsor (ASA(ALT) SOSE&I) for use on a direct project. The pilot model described in this paper can be used as an exemplar for codifying an analysis plan in the context of an integrated architectural model which includes structural architecture and attributes, requirements, and constraints for evaluation. The natural progression within MBSE is to move functional operation threads from an architectural environment to a simulation environment for further numerical based analyses. Currently, this is accomplished using various methods, many of which are proprietary one-time methods constitute a re-occurring expense. Exploring the operational context is necessary for architectural relevance. Extending that analysis to performance evaluation in DES is also necessary and should be performed in a manner such that model data is automatically moved from an operational context architecture model to a DES model and back (to adjust the overall architecture of the system based on DES-based analysis results). In FY17, we will continue to collaborate with industry and academia to define an interchange mapping between SysMLs XMI export format and DES, with the goal of evolving this mapping to a standard specification. This MITRE research work and its product (an industry standard) will produce a modeling environment that supports the broadest range of Model-based Systems Engineering activities from requirements gathering to training, Verification and Validation, through testing, and Operations and Maintenance. Success will impact government enterprises as they respond to opportunities and threats grounded in well-formed models and validated information to conduct what-if analyses. iii Approved for Public Release Distribution Unlimited Case Number 16-4263 2. Acknowledgments \nThis work is supported through MITRE Independent Research and Development. The views expressed are those of the authors and do not reflect official positions of the MITRE Corporation or the U.S. Government. The authors thank Drs. Rob Pitsko, Chris Glazner and Ernie Page for their vision and enthusiastic support for this research. We also thank our Army operational and technical Subject Matter Expert Dr. Brian Soeder. 1 Approved for Public Release Distribution Unlimited Case Number 16-4263 1. Introduction \nTo analyze complex systems, stakeholders apply ad-hoc methods to model their systems and transfer their inputs to simulation engineers. What is needed is a holistic approach that enables an agile approach to analytics. This paper describes a pilot project to study the feasibility of an approach that supports architecture development trade-off analyses incorporating sponsor data with MBSE tools as a first step towards a holistic approach to analytics. Such an approach allows for integrated analysis of model data in the context of a common architecture. The pilot (and approach) described in this paper produced an integrated model containing architecture artifacts, operational constraints, and requirements within an MBSE tool repository that allowed validation of requirements as an integrated part of the architecture development process. The model was executed to enable evaluation over the various mission threads and related operational constraints thus allowing architecture trade-off analyses based on operational metrics. With this approach, analysis results are documented as part of the model and are reproducible. The approach described in this paper and applied during the pilot project will enable a government Enterprise to respond to opportunities and threats based on an agile, repeatable process and analysis capability. 2. Pilot Project 1.1 Problem Description An Army sponsor oversees equipment acquisition, development and deployment (e.g., fielding). Their need is to optimize the acquisition decisions by procuring and distributing the equipment to support mission needs under the constraints of budgets and procurement timelines. This presents the sponsor with a multi-dimensional optimization challenge, where the decision parameters are highly interrelated and the stakeholder needs must be met to ensure successful mission outcomes. Currently, the Army sponsor process involves gathering all needed data in a spreadsheet and performing day-long permutation analysis, using heuristic techniques and trial and error methods to achieve a procurement decision. This approach has provided sub-optimal results since, under the best intentions, it has led to deployment of equipment to echelons where the equipment may be operationally or technically interoperable. The sponsors approach is to review and adjust mission command required capabilities and solutions to deliver good enough and affordable Army network capabilities that are synchronized and fielded to better enable our formations and Soldiers to fight. 1.2 Stakeholder Needs and Current Army Approach The Army sponsor needs to identify voice and data communications requirements by platform, allocated waveforms, and provide radio hardware in order to build a Network Design by formation type. With the current approach, the Army has focused their effort on Table of Organization and Equipment (TOE) deployable units ~ i.e., projected combat power. A spreadsheet is used to list all identified elements. The goal is to identify required capabilities by echelon for dismounted leaders and soldiers, platforms and command posts, and to recommend Mission Essential and Mission 2 Approved for Public Release Distribution Unlimited Case Number 16-4263 Enhancing capabilities (MEME)1. The aim is to optimize Benefit versus Cost over time while meeting the yearly budget and fielding a common baseline(s) to more units. Currently, the sponsor uses the data in the spreadsheet to analyze what capability is delivered for alternative Infantry Brigade Combat Team (IBCT) procurements and fielding options. The process is manual, labor intensive, and prone to errors of omission. The Army sponsor would like to be able to compare an IBCT architecture quantitatively while leveraging Main Communications Node (MCN) performance analysis metrics and Army Traffic Model (ATM) data. 3. Research Approach and Pilot Model \nThis MITRE Innovation Program (MIP) sponsored research identified an MBSE approach, conducted a pilot project and proposed a solution to an Army sponsor that can be organized into four (4) phases: 1. Conduct mission thread analysis to identify the contexts and constraints most important to \nthe user. 2. Conduct structural analysis based on the system architecture (e.g., can all required \ncapabilities be provided in the form of system functionality, i.e., by mapping of the operational view of the mission thread and system view of the proposed solution?) 3. Conduct dynamic analysis based on the execution of the structural architecture and mission \nthread model. 4. Present the results of the analysis to a decision maker using formats that support interactive \ndata visualization methods. To enable the sponsor to make informed equipment acquisition decisions, the approach includes representing requirements, the constraints used to dynamically evaluate the requirements and the architecture structure that is used as the context for performing various types of analyses. We identified three (3) types of analysis impactful in the sponsor context and prototyped the first 2 types: Architecture analysis Evaluated architecture deployment suitability of a structural as-is \narchitecture. Requirements and evaluation constraints for measuring node suitability were defined in the model. Each node in the architecture node graph was then evaluated based on node attributes as well as node placement
and context within the whole architectural node graph. The resultant model provides an overall architecture suitability measure as well as individual node pass/fail results, based on specified requirements. Total suitability as well as detailed pass/fail results can then be exported as spreadsheets and further visualized using bar charts and other interactive data visualization methods to support agile decision making. 1 MEME (Mission Essential and Mission Enhancing): Capabilities that enable leaders and commanders to effectively execute mission command tasks at the tactical-edge of the modern battlefield; must be integrated into BCTs in the near-term. Mission Enhancing: Capabilities that further expand the capacity of tactical leaders on the battlefield; BCTs can assume risk in the near- term by delaying immediate integration and/or extending development (in resource constrained environment). 3 Approved for Public Release Distribution Unlimited Case Number 16-4263 Proposed architectural changes can be made using the spreadsheets and then used to auto- update and inform architectural changes in the model. Mission Thread analysis Created an executable mission animation thread using SysML for \nan Army MEDEVAC scenario. This animation allowed the authors to evaluate a functional thread through the architecture model to understand mission sequencing, operational impact, and completion criteria. Additional threads can be added following same pattern. The third type of analysis is an ongoing effort and consists of mission performance analysis using Discrete Event Simulation (DES). When completed, this effort will enable a user to import vetted architecture mission threads into a DES without having to recreate the threads using DES tools, while maintaining end-to-end traceability back to the architectural model and stakeholder needs. Further, factors not represented in the architecture, such as environment, threats and failures can be examined more efficiently in the high-performance DES environment. Integration into the high- performance DES environment exceeded the scope of this exploratory pilot. The following subsections describe the model that was developed during this pilot project using Army sponsor data. The results are presented in Section 0. 1.3 Model-Based Solution 1.3.1 Model Description We started with a System Architecture Model (SAM) to provide the overall context in which the analysis takes place. By integrating high fidelity analysis through a consistently defined architecture, several system configurations can be analyzed to provide insight into key system characteristics that are not evident though analysis alone. Further, automation of analysis allows more options to be considered in a timely manner. The model provides a systematic approach for managing the inter-dependencies of system properties, constraints on those properties and required outcomes spanning across a system to support multi-dimensional analysis. The model captures the final solution as well as the rational and excluded solutions, thereby preserving both formal and tacit knowledge. Such an electronically integrated model and data allows for the automation of otherwise time consuming analysis setup, thus allowing more time for actual analysis and incorporation of iterative stakeholder feedback. 1.3.2 Model Inputs from the Sponsor The following sets of data were provided by the Army Sponsor: Network Basis of Issue (NBOI) Data Radio Architecture data for every node in an Army \nBrigade in spreadsheet format. This includes the physical radios assigned to each node and radio frequency (RF)2 / subnet configurations of each radio. Note1: RF is usually represented by an image called waveform, which is the term used throughout the rest of this paper. Note2: For the pilot model only a portion of the entire NBOI data was used. MEME (Mission Essential and Mission Enhancing) Requirements Requirements for \nconnectivity based on the role of each node. \n2 RF: any of the electromagnetic wave frequencies that lie in the range extending from below 3 kilohertz to about 300 gigahertz and that include the frequencies used for communications signals (as for radio and television broadcasting and cell-phone and satellite transmissions) or radar signals (https://www.merriam-webster.com/dictionary/radio%20frequency). 4 Approved for Public Release Distribution Unlimited Case Number 16-4263 MEDEVAC Mission Thread The thread of connected nodes needed to successfully \ncomplete a MEDEVAC mission. Figure 1 illustrates the three sets of Army provided data and how the data was used to populate the model that was developed using No Magics MagicDraw SysML Modeling tool.3 \nFigure 1. Army provided data feeding the Model 1.3.3 Model Structure Army organizations are structured hierarchically. This hierarchy is represented in the model by a Block Definition Diagram. Every organization is represented as a Block (hereafter called a node following Army nomenclature) and is named with the unique ID from the Army NBOI data to maintain traceability. Figure 2 represents the hierarchy of the nodes contained in this model. \n3 http://www.nomagic.com/ 5 Approved for Public Release Distribution Unlimited Case Number 16-4263 Figure 2. Army Brigade hierarchy represented in a Block Definition Diagram Every node in the model has properties that map to values in the NBOI data. Nodes also have properties whose values are derived from the analysis conducted on the model. The properties defined for each node are shown in Figure 3 below. \nFigure 3. The NBOI Node block from which every node inherits properties To work with various configurations of architectures, multiple instances of the entire architecture were generated. The default values for each nodes properties were imported from the NBOI data. However, the properties can be changed to perform trade-off analyses and to dynamically determine architecture configurations that fully satisfy the requirements and complete mission threads. By changing the waveform / sub-net configuration of the radios at each node, the list of nodes it can communicate with is changed. 2 Analysis and Results 2.1 MEME Requirements Analysis Description The Army Sponsor provided a spreadsheet that contained MEME requirements. A snippet of the spread sheet is shown in Figure 4 below (cell values have been blanked out). The circled cells are explained below. 6 Approved for Public Release Distribution Unlimited Case Number 16-4263 Figure 4. Snippet of Original MEME Spreadsheet To set up the model and support requirements analysis: A customized MEMERequirement stereotype was defined in the model to capture additional \nrequirements metadata (to augment those defined by the SysML language). The identified metadata properties were mapped as MEMERequirement properties. \no Starting with the MEME Cells circled in Figure 4, the new properties were defined using a <<MEMEReq>> stereotype, and o Several <<enumeration>> stereotypes and were tied to rows or columns in the \nMEME spreadsheet. The enumeration MEMERoleKind is a list of values from Col B. These are \nused to populate the new requirement property by the same name. MEMEOrgCatKind enumerations correspond to Col A, while \nMEMEOpCatKind enumerations come from Row 4. SysML Constraints Blocks were created to codify the rules for evaluating the various \nRequirements for validation and were linked to the corresponding requirement. There is also a Verdict property that was used for storing the results from the analysis. \nIn this pilot, we focused on analyzing Requirements, but the approach described here can be applied to any important program data such as cost, power, risks, security, etc. The pilot model focused on voice line-of-site radio connection requirements. The MEME role is indicative of a role a node makes, but is not a one to one correspondence. After this model set up was completed, Army requirements were imported from the MEME spreadsheet into the model. 7 Approved for Public Release Distribution Unlimited Case Number 16-4263 Each node in the model must satisfy the requirement that maps to its role. The set of requirements from the Armys spreadsheet is traced to a node in the model that is expected to meet the requirement or play a role in achieving it. The model also defined a library of reusable constraints that can be applied to any requirement. These constraints provide the construct through which analysis can be performed on whether a specific configuration (deployment of specific radio/wave form to a node) will enable the node to meet the communication requirements it needs to accomplish its mission. The constraints were applied during the parametric analysis described below. Figure 5. The library of constraint blocks used in the parametric analysis 8 Approved for Public Release Distribution Unlimited Case Number 16-4263 2.2 Parametric Analysis Description Figure 6 below is a parametric diagram that illustrates how various constraints take inputs and produce outputs after executing to produce the values for the derived properties based on the execution. This process includes five steps: 1. The node properties that map to NBOI data are used to seed the Analysis Configuration \nBuilder (1). 2. The automated process, with inputs from step 1, determines which MEME Requirement the \nnode must satisfy. Based on the requirement, it selects the set of constraints that need to be evaluated to satisfy the requirement (2). 3. The constraints accessed model data by using calls to the Magicdraw API (3). The node can \neither Pass or Fail each constraint. The logic for each constraint was developed with the assistance of MITRE and Sponsor Army SMEs. In this manner, the constraint provides an explanation for what a Fail for a node means. 4. The results of each constraint are logically AND-ed in the Verdict constraint to determine \nthe overall requirement satisfaction (4).
5. The results are then saved into the derived properties of the node (5). Figure 6. The parametric diagram that is executed to perform the MEME Requirement analysis The analysis for every node can be executed individually or the entire architecture can be executed at once using the instance table that contains values that can be changed in the model. 2.3 Analysis Results Table 1 below shows a listing of Army nodes, their level in the node hierarchy, and the results of the analysis obtained after executing the model based on the requirements and constraints the nodes 9 Approved for Public Release Distribution Unlimited Case Number 16-4263 are expected to meet. A Fail indicates the node cannot communicate with the upper or lower level nodes given the radio equipment that they have been assigned, a PASS indicates they can. (Note: Not all nodes in the NBOI have a direct mapping to a MEME requirement, thus some nodes have N/A values.) The results of the Analysis can be exported directly from the instance table. Additionally, custom export files can be populated during execution using the Verdict constraint. Table 1. A notional export of an architecture instance table after analysis is executed 2.4 Mission Thread Analysis Description The sequence in which nodes must communicate to perform a MEDEVAC scenario was provided by the Army Sponsor SME. Using this data, an Internal Block Definition Diagram (IBD) was created (see Figure 7 below, name of blocks have been suppressed). An IBD reflects the hierarchy of the nodes defined in the BDD as nested nodes. In this diagram, the nodes that were required to communicate to complete the MEDEVAC thread were connected to define required communication lines (information exchange requirements). 10 Approved for Public Release Distribution Unlimited Case Number 16-4263 \nFigure 7. The notional Internal Block Diagram (IBD) of the architecture, wired together to complete a MEDEVAC thread The mission thread analysis was conducted by executing State Machines to send signals between nodes defined in the architecture (see Figure 8). Nodes can send signals over the connections created in the IBD. These signals were given 2 attributes: waveform and subnet. When a block sends a signal, its radio wave and subnet values are appended to the signal. For another block to receive the signal, the receiving block must have matching wave and subnet values. If the node successfully receives the signal (i.e., there is a match), it will relay the signal to the next node in the sequence after adding its own wave and subnet to the signal. This node will then stop listening. However, if the incoming signal does not match, the receiving node will continue listening and wait for a signal that will match its own wave and subnet. \nFigure 8. The State-Machine of a block waiting to receive and relay a message to the next block in the thread. 2.5 Mission Thread Analysis Results The mission thread can be recorded in a sequence diagram (auto generated based on the state machine execution sequence through the states) that captures the signals and the states of each node 11 Approved for Public Release Distribution Unlimited Case Number 16-4263 as it executes (see Figure 9). If a thread cannot complete based on the architecture configuration, then operationally relevant conditions are described such as the Field Surgeon never reaches the Responding to MEDEVAC state. In summary, by modeling the Army node hierarchy, relating the nodes to communications requirements, and using one illustrative mission thread (MEDEVAC), the MITRE team piloted an automated approach with a model using the requirements as constrains against which nodes must be able to communicate. Results are produced from the model execution using a variety of forms, one of which is the pass/fail table (Table 1). Other forms are more visual and show how the mission scenario comes stops after one node or another is unable to receive communication vital to successfully completing the mission because of a specific equipment configuration (e.g., sequence diagram generation halts). Based on such model execution and resulting analysis outputs, an acquisition team can explore architecture alternatives and make informed decisions on what equipment to purchase for which deployment configurations in order to ensure mission success. \nFigure 9. The Notional Recorded sequence diagram of the mission thread execution. Note: It completes when the Field Surgeon enters the Responding to MEDEVAC state 4. Conclusion and Future Work \nIn FY16 we engaged an Army sponsor using an MBSE approach for evaluating radio architecture suitability utilizing as-is Army deployment architecture, mission essential requirements and one mission specific MEDEVAC thread. The approach and prototype have been transitioned to an Army sponsor (ASA(ALT) SOSE Dalakas, V., Tsadimas, A. ; Nikolaidou, M. and Anagnostopoulos, D., 2014b. Model-based system engineering using SysML: Deriving executable simulation models with QVT, Systems Conference (SysCon), 8th Annual IEEE 531 538. MBSE Wiki, 2015. Accessed May 5. http://www.omgwiki.org/MBSE/doku.php McGinnis, L. Ustun, V., 2009. A Simple Example of SysML-Driven Simulation, Proceedings of the 2009 Winter Simulation Conference, 1703 1710. Mosterman, P. J., Vangheluwe, H., 2004. Computer automated multi-paradigm modeling: An introduction, Simulation, Volume: 80, 433 450. No Magic 2015. MagicDraw UML Modeling Tool, Accessed May 5. http://www.nomagic.com/products/magicdraw.html OMG 2015. UML Profiles: Accessed May 5. http://www.omg.org/mda/specs.htm R. Shaikh, H. Vangheluwe, Transforming UML2.0 Class Diagrams and Statecharts to Atomic DEVS, Proceedings of the 2015 Winter Simulation Conference, Dec. 2015 Sarjoughian, H., A. Alshareef, Y. Lei, BEHAVIORAL DEVS METAMODELING, Proceedings of the 2015 Winter Simulation Conference, Dec. 2015 SDRP 2007. PIM and PSM for Software Radio Components (SDRP), Accessed May 5. http://www.omg.org/spec/SDRP/ SysML 2014. Systems Modeling Language, Accessed May 5. http://omgsysml.org/index.htm Teran-Somohano, A., J. Ledet, A.E. Smith, L. Yilmaz, H. Oguztzn, A Model-Driven Engineering Approach To Simulation Experiment Design And Execution, Proceedings of the 2015 Winter Simulation Conference, Dec. 2015 Wang, R., Dagli, CH 2008. An executable system architecture approach to discrete events system modeling using SysML in conjunction with colored Petri Net, 2nd Annual IEEE Systems Conference, 2008, 1-8. http://www.omg.org/spec/FUML/1.1/\nhttp://ieeexplore.ieee.org/search/searchresult.jsp?searchWithin=p_Authors:.QT.Tsadimas,%20A..QT.&newsearch=true\nhttp://ieeexplore.ieee.org/search/searchresult.jsp?searchWithin=p_Authors:.QT.Nikolaidou,%20M..QT.&newsearch=true\nhttp://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6813884\nhttp://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6813884\nhttp://www.omgwiki.org/MBSE/doku.php\nhttp://mitre.summon.serialssolutions.com/search?s.dym=false&s.q=Author%3A%22Mosterman%2C+Pieter+J%22\nhttp://www.nomagic.com/products/magicdraw.html\nhttp://www.omg.org/mda/specs.htm\nhttp://www.omg.org/spec/SDRP/\nhttp://omgsysml.org/index.htm\nhttp://scholar.google.com/citations?user=s0RwJCoAAAAJ&hl=en&oi=sra 14 Approved for Public Release Distribution Unlimited Case Number 16-4263 Wang, W., Zhao, B., 2012. Research on construction method of DoDAF view based on DEVS and SysML, World Automation Congress (WAC), 1 4. Wang, Z., Hongyue, H. E., Wang, Q., 2014. Executable Architecture Modeling and Simulation Based on fUML, 19th ICCRTS, http://www.dodccrp-test.org/s/2014-091-yfn5.pdf XMI 2015. XML Metadata Interchange, Accessed May 5. http://www.omg.org/spec/XMI/ Zeigler, B.P., Praehofer, H., and Kim, T., 2000. Theory of Modeling and Simulation. Academic Press, 2nd edition. http://www.dodccrp-test.org/s/2014-091-yfn5.pdf\nhttp://www.omg.org/spec/XMI/ Executive Summary\n Acknowledgments\n Introduction\n Pilot Project\n Problem Description\n Stakeholder Needs and Current Army Approach Research Approach and Pilot Model\n Model-Based Solution\n Model Description\n Model Inputs from the Sponsor\n Model Structure Analysis and Results\n MEME Requirements Analysis Description\n Parametric Analysis Description\n Analysis Results\n Mission Thread Analysis Description\n Mission Thread Analysis Results Conclusion and Future Work ",
    "text": " Promoting SWIM through Open Source Software Promoting SWIM through Open Source Software Anuja Verma & Dan Greenbaum\nThis work was produced for the U.S. Government under Contract DTFAWA-10-C-00080 and is subject to Federal Aviation Administration Acquisition Management System Clause 3.5-13, Rights In Data-General, Alt. III and Alt. IV (Oct. 1996). The contents of this document reflect the views of the author and The MITRE Corporation and do not necessarily reflect the views of the Federal Aviation Administration (FAA) or the Department of Transportation (DOT). Neither the FAA nor the DOT makes any warranty or guarantee, expressed or implied, concerning the content or accuracy of these views. Brands and logos may be trademarked by their respective holder(s).\nUse of brands and logos is for identification purposes only and does not imply support or endorsement by the identified organization of the contents of this presentation.\nImage Sources: https://www.faa.gov/nextgen/programs/swim/overview/, https://opensource.org/ \nApproved for Public Release;Distribution Unlimited. Case Number 17-0645\n. | # | | # | \n \nTask Description: FAA Sponsored Independent R&D\nObjective:\nExamine the feasibility and best practices for developing and distributing SWIM-based applications via an open source software model. FAA Sponsor:\nFAA Mission-Oriented Investigation and Experimentation program.\nPaul Fontaine, Portfolio Management and Technology Development, Office of NextGen. Planned activities:\nExamine current uses for SWIM data in public and private sectors.\nExamine technologies and best practices to support open source development and implementation.\nImplement an initial open source SWIM site and develop user community. End product:\nRecommendations to the FAA SWIM Program office for standardizing data processing and associated analytic capabilities\nBest practices for accelerating development and technology transfer\nOpen source SWIM site and associated software capabilities | # | \n \nPresidential Memorandum Promoting Use of Open Source Software Establishes a pilot program directing agencies commissioning custom software to: Release at least 20 percent of new custom-developed code as Open Source Software (OSS) for three years Collect additional data concerning new custom software to inform metrics to gauge the performance of this pilot\nBrands and logos may be trademarked by their respective holder(s). | # | \n \nWhat is System Wide Information Management? SWIM Terminal Data Distribution Service (STDDS)\nWeather And Radar Processor (WARP)\nNOTAM Distribution Service (NDS)\nTime-Based Flow Management (TBFM)\nTraffic Flow Management (TFMData)\nSWIM Flight Data Publication (SFDPS)\nImage Source: https://www.faa.gov/nextgen/programs/swim/overview/ | # | \n 4 Who Uses SWIM? \nAirlines, Research organizations, ANSPs, FAA contractors, and more Image Source: https://www.faa.gov/nextgen/programs/swim/overview/\nBrands and logos may be trademarked by their respective holder(s).\nUse of brands and logos is for identification purposes only and does not imply support or endorsement by the identified organization of the contents of this presentation. | # | \n 5 Availability of the source code enables re-use\nNot a black-box\nClarity and trust\nAbility to debug\nUsers contribute improvements code is more reliable\nUsage, modification, and redistribution controlled by license\nDeveloper retains the copyright\nViolations of the license infringes copyright\nSuccessful Examples\nMozilla\nAndroid\nHDFS\nApache\nLinux Source: BigStockPhoto: mindscanner\nThe Open Source Software Model | # | \n 6 Expected Outcome\nPromote development and distribution of SWIM-based applications via an open source software model | # | \n 7 Standardize data processing and interpretation utilities Reduce development time and cost of application development Lower entrance barrier, enabling innovative end-user applications Promote tech transfer by reusing prototypes, lowering acquisition cost Develop a MITRE open source model / license (Apache)\nSurvey current SWIM data usages in public and private sectors\nIdentify the best open source practices\nDevelop licensing options\nIdentify best technologies to support implementation Implement the initial capabilities of SWIM Open Source site (e.g. GitHub, JIRA) Develop and distribute an initial Open Source SWIM software package\nBe modular, i.e., individual parts are useful without access to all feeds\nDevelop initial libraries\nConnect to feed\nAssociate data elements (e.g., TFMS + STDDS integrated flight object)\nCommon geometric, trigonometric, navigational\nCommon GUI / Visualization Components Outreach to internal/external SWIM data users Technical Approach | # | \n 8 Layered API Design\nObjectives of Component Design:\nProtect components from changes in SWIM feeds\nRe-use data structures\nRe-use algorithms\nMake components agnostic to real-time / replay\nEncourage use of single configuration process\nIntegrated status monitoring / logging\nMake components agnostic to file / stream input\nSupport archiving, live operation, replays, data pre-loading\nPromote code re-use / modularity | # | \n GUI Web Server Application Specific Processing Algorithmic Data Management SWIM Feed Processing Foundation Classes Examples of Reusable Components for SWIM Applications \nConnectivity:\nSWIM Client APIs\nSWIM Feed Services\nData Management:\nFlight Data API\nSurface Data API\nATC Facility API\nAlgorithmic Processing:\nHolding Detection Algorithm\nDiversion Detection Algorithm\nAirport Demand Prediction Algorithm\nAirport Departure and Arrival Monitor\nAirport Taxi Activity Monitor\nVisualization:\nAirport Taxi Status GUI\nAirport Status GUI\nWeather Display GUI Source: BigStockPhoto: landio Source: BigStockPhoto: tuulijumala Source: BigStockPhoto: ismagilov | # | \n 10 Intended Impact\nStandardize data processing and interpretation utilities for government and industry users Significantly reduce the cost and expedite the process of developing new automation\nLower entrance barriers\nFocus on innovative end-user applications Facilitate the development and tech transfer of software prototypes\nDevelopment of a common software foundation based on SWIM would enable ready conversion of prototypes to operational systems. | # | \n 11 FY17 Milestones\nReview current industry best practices for open source model Identify needs and user groups of SWIM-enabled applications Meet with FAA SWIM office, flight operators, and contractors to identify current and future SWIM program plans and planned uses of SWIM data Define requirements of the open source software platform Implement initial open source capabilities Conduct outreach SWIM user groups and build the community | # | \n 12 Promoting SWIM through Open Source Software Development\nObjective:\nCreate an Open Source Community of SWIM users (research organizations, airlines, \n commercial contractors, ANSPs) centered around software used to process FAA SWIM data\nExpected Results:\nImprove quality and interoperability of FAA software by standardizing data processing and interpretation\nReduce software development costs for FAA prototypes by enabling re-use\nEncourage SWIM usage by lowering barriers to entry for new participants\nLower FAA acquisition costs by facilitating direct tech transfer of research prototypes to operational systems\nActions:\nIdentify best practices for Open Source development:\nTechnologies: Github, JIRA, Atlassian toolkit, Java, JavaScript, JMS, Web Services\nEstablish rules for managing releases and contributions from multiple organizations\nIdentify Open Source license terms (e.g., Apache OS License)\nDevelop and release modular, object-oriented software to process SWIM data\nOutreach:\nFAA: Coordinate with FAA SWIM and open source software\nAirlines, research organizations and ANSPs: Determine current and planned uses for SWIM data and develop open source community\nDovetails with FAA Federal Source Policy by:\nChanneling new software development to produce re-usable, open source software so that the benefits of FAA policy and SWIM investment are fully realized\n2017 MITRE Open Source Research Project Brands and logos may be trademarked by their respective holder(s).\nUse of brands and logos is for identification purposes only and does not imply support or endorsement by the identified organization of the contents of this presentation.\nImage Sources: https://www.faa.gov/nextgen/programs/swim/overview/, https://opensource.org/ | # | \n ",
    "text": " Creating the Future of Aviation Technical and Professional Activities\n2016 The MITRE Corporation\nCenter for Advanced Aviation System Development www.mitre.org TABLE OF CONTENTS Introduction 1 Books, Journals, and Periodicals 3 Conference Participation 7 Honors, Awards, and Recognition 35 Professional Societies 47 Committee Participation 53 Academic and Special Appointments 69 Book and Journal Editors and Reviewers 73 Technology Transfer 77 Index of Contributors 81 1 INTRODUCTION I am pleased to introduce our seventeenth annual \ncompendium of technical and professional \naccomplishments from MITREs Center for Advanced \nAviation System Development (CAASD). This booklet \ndocuments the many signifi cant outreach and collaboration \nactions of MITRE staff in support of CAASDs mission: \nserving the public interest by advancing the safety, security, \neff ectiveness, and effi ciency of aviation in the United States \nand around the world. This continues to be an exciting time for the aviation \nand aerospace communities. Unmanned aircraft and \ncommercial space vehicles are inspiring innovative new \nbusiness opportunities, but bring new operational and \ntechnical challenges in preserving the high level of safety \nand effi ciency in todays system. New technologies, such \nas autonomy, mobile computing, data analytics, machine \nlearning, and advanced sensors, will play a part in this \nevolving landscape, but also present research challenges. \nAs the FAA deploys NextGen capabilities, which are \nnow being widely used in daily air traffi c management \noperations, new procedures and technologies off er airspace \nusers opportunities for signifi cant operational improvement \nand safety enhancement. This is a highly collaborative communityone which \nrelies on the free exchange of ideas and full consideration \nof all stakeholder viewpoints. In that spirit, CAASD \nstaff publish and present extensively in order to share \nour ideas, obtain community feedback, and understand \nnew perspectives. The papers, patents, awards, and other \ntechnical contributions documented here are testaments to \nthe collaborative spirit of our staff . We also thrive on intellectual challenges and opportunities to \ninnovate. Through analytic and human-in-the-loop simulation, \nour staff bring future concepts and capabilities to life in our \nlaboratories to explore the opportunities off ered by these \nadvancements, but also to understand their associated risks. \nSuch advancement requires signifi cant research, analysis, and \nunderstanding. Our staff s spirit of innovation and passion for \nadvancing system operations are evidenced here. In order to \nensure that our innovations have impact we actively manage \nthe transition of our research and technology to government, \nindustry, and other community stakeholders. Also refl ected in these pages is our diversity. Our work \nrequires a broad range of operational experience and technical \ndepth. Our staff include engineers, scientists, economists, \npilots, controllers, traffi c managers, former airline and military \npersonnel, and more. They provide operational expertise in air \ntraffi c control, traffi c fl ow management, and space operations, \nand technical expertise in systems engineering, computer \nscience, operations research, human factors, economics, \ncommunications, navigation, surveillance, and other essential \ndisciplines. We could not accomplish all that we do without \nthis rich diversity of experience and thought. Our staff inspire us by envisioning innovative ideas for \nfuture capabilities and by performing rigorous technical and \noperational analysis to ensure the viability of those ideas. The \ncontributions and achievements documented here highlight \nthe critical role CAASD and other MITRE staff are playing \nin making new ideas in aviation and aerospace operations a \nreality. Lillian Z. Ryals\nSenior Vice President, The MITRE Corporation\nGeneral Manager & Director, \nCenter for Advanced Aviation System Development 2 3 BOOKS, JOURNALS, AND PERIODICALS Airline Consolidation: Monopoly Power or Mature \nIndustry? Thomas P. Berry Jr., Katherine T. Harback, \nSimon Tsao, and Stephen K. Welman, TR News, No. 304, \npp. 4651, JulyAugust 2016, Transportation Research \nBoard. Big Strides in Air Control, John Reed, Uday Shankar, \nand Lesley A. Weitz, Aerospace America, Vol. 54, No. 11, \np. 20, December 2016, American Institute of Aeronautics \nand Astronautics. Can Aircraft and Space Traffi c Coexist? \nLillian Z. Ryals, Aviation Week & Space Technology, \nJuly 18, 2016, Aviation Week Network. End-to-End Time-Based Scheduling and Management: \nThe Vision, The Progress, Marlis McCollum, \nElida C. Smith, Managing the Skies, Vol. 14, No. 6, \npp. 20-25, November/December 2016, FAA Managers \nAssociation, Inc. MITRE/NASA Collaboration on Development of \nTerminal Sequencing and Spacing, \nKathleen A. McGarry Peterson, Marlis McCollum, and \nJohn E. Robinson III, Managing the Skies, Vol. 14, No. 4, \npp. 1621, July/August 2016, FAA Managers Association, \nInc. 4 Preparing for the Rise in Commercial Space Operations, \nDean E. Fulmer and Marlis McCollum, Managing the \nSkies, Vol. 14, No. 2, pp. 14-17, March/April 2016, FAA \nManagers Association, Inc. Safety on the Surface: A Low-Cost System for Runway \nAwareness, Marlis McCollum and Emily K. Stelzer, \nManaging the Skies, Vol. 14, No. 3, pp. 18-20, May/June \n2016, FAA Managers Association, Inc. Sense and Avoid for Unmanned Aircraft Systems, \nGiancarmine Fasano, Domenico Accardo, Antonio Moccia, \nand David R. Maroney, Aerospace and Electronic Systems \nMagazineTutorial X, Vol. 31, No. 11, Part II of II, \npp. 82110, November 2016, Institute of Electrical and \nElectronics Engineers. Special Issue on Sense and Avoid for Unmanned Aircraft \nSystems: Part I, David R. Maroney and Giancarmine \nFasano, Co-Editors, Aerospace and Electronic Systems \nMagazine, Vol. 31, No. 7, July 2016, Institute of Electrical \nand Electronics Engineers, Aerospace and Electronic \nSystems Society. Special Issue on Sense and Avoid for Unmanned Aircraft \nSystems: Part II, David R. Maroney and Giancarmine \nFasano, Co-Editors, Aerospace and Electronic Systems \nMagazine, Vol. 31, No. 9, September 2016, Institute \nof Electrical and Electronics Engineers, Aerospace and \nElectronic Systems Society. Books, Journals, and Periodicals 5 Books, Journals, and Periodicals Stochastic Optimal Control for Ground-Based Metering \nOperations, Travis L. Gaydos, Worth Kirkman, and \nLesley A. Weitz, Journal of Air Transportation, Vol. 24, \nNo. 2, (2016), pp. 2940, May 2016, American Institute of \nAeronautics and Astronautics. Streamlining the IFR Clearance and Release Process, \nPaul A. Diff enderfer, Kevin M. Long, and \nMarlis McCollum, Managing the Skies, Vol. 14, No. 1, pp. \n18-21, January/February 2016, FAA Managers Association, \nInc. The Solo Pilot Gets a Second Set of Eyes, \nMarlis McCollum, John R. Helleberg, Kevin M. Long, \nMatthew E. Pollack, and Jeff rey L. Stein, Managing the \nSkies, Vol. 14, No. 5, pp. 1419, September/October 2016, \nFAA Managers Association, Inc. Transforming Safety Decisions through Big Data \nAnalytics, Saam Ahmadi, TR News, No. 304, pp. 2223, \nJulyAugust 2016, Transportation Research Board. Verifying Required Communication Performance in Air \nTraffi c Management, John C. Gonda III and \nDongsong Zeng, Journal of Air Transportation, Vol. \n24, No. 1, pp. 917, January 2016, American Institute of \nAeronautics and Astronautics. Web Site Articles/Featured Opinion Applying Safety Science to Child Welfare, \nChristopher M. Teixeira, Mark D. Thomas, and \nEdward B. Walsh, The Chronicle of Social Change \nWebsite, November 28, 2016. 7 Conferences are an important part of CAASDs outreach \nto the global aviation community. CAASD staff participate \nin numerous ways: as presenters, moderators, panelists, \nchairs, and attendees in order to share their work, learn \nfrom other experts, make connections, and inform the \naviation community about our unique FFRDC role. CAASD has Conference Coordinators whose role is to \nchampion and manage staff participation where we will \nhave a signifi cant presence or exhibition. The conferences \nfor which CAASD has designated Conference Coordinators \nare listed below, along with the assigned Conference \nCoordinators. Conference Coordinator Air Line Pilots Association (ALPA) \nAir Safety Forum Wallace N. Feerrar Air Traffi c Control Association (ATCA) \nAnnual Conference and Exposition David G. Hamrick Air Traffi c Control Association (ATCA) \nAviation Cyber Security Day Joseph M. Veoni Air Transport and Operations \nSymposium (ATOS) David R. Maroney AirTOp User Conference John A. Kuchenbrod CONFERENCE PARTICIPATION 8 Conference Coordinator American Association of Airport \nExecutives (AAAE) \n Aviation Security Summit\n Conference and Exposition\n Issues Conference Douglas L. Molin American Institute of Aeronautics \nand Astronautics (AIAA) Aviation \nConference David R. Maroney American Institute of Aeronautics \nand Astronautics (AIAA) SciTech \nConference Lesley A. Weitz American Meteorological Society \n(AMS) Annual Meeting Matthew J. Fronzak Association for Unmanned Vehicle \nSystems International (AUVSI) \nXPONENTIAL Conference Andrew R. Lacher Avionics for NextGen Sean F. McCourt Civil Air Navigation Services \nOrganization (CANSO) \nAsia-Pacifi c Conference Miyoun L. (Mimi) Dobbs Civil Air Navigation Services \nOrganization (CANSO) \nWorld ATM Congress Miyoun L. (Mimi) Dobbs Congress of the International \nErgonomics Association Valerie Gawron Digital Avionics Systems Conference \n(DASC) Hilton Bateman Embry-Riddle Aeronautical \nUniversitys Space Traffi c \nManagement Conference Dean E. Fulmer FAA Commercial Space \nTransportation Conference Dean E. Fulmer Conference Participation 9 Conference Coordinator FAA/EUROCONTROL ATM R&D \nConference Craig R. Wanke FAA Managers Association (FAAMA) \nAnnual Gathering of Eagles \nConference Michael L. Klinker FAA UAS Symposium Hassan Shahidi Human Factors and Ergonomics \nSociety Annual Meeting Valerie Gawron Institute of Electrical and Electronics \nEngineers (IEEE) Conference on \nIntelligent Data Understanding Andrew R. Lacher Institute of Electrical and Electronics \nEngineers (IEEE) International \nSystems Conference Glenn F. Roberts Institute of Navigation (ION):\n GNSS+\n International Technical Meeting\n Joint Navigation Conference\n Pacifi c PNT Conference\n ION/IEEE Position, Location, and Navigation Symposium (PLANS) Christopher J. Hegarty Integrated Communications, \nNavigation, and Surveillance (ICNS) Amal Srivastava International Conference on Applied \nHuman Factors and Ergonomics Valerie Gawron International Symposium on Aviation \nPsychology Valerie Gawron MIT Lincoln Laboratory Air Traffi c \nControl Workshop David G.
Hamrick Munich Satellite Navigation Summit Christopher J. Hegarty Conference Participation 10 Conference Coordinator National Air Traffi c Controllers \nAssociation (NATCA) Communicating \nfor Safety Conference Douglas L. Molin National Business Aviation \nAssociation (NBAA) Friends and \nPartners of Aviation Weather Matthew J. Fronzak RTCA Annual Symposium Deborah A. Kirkman Space Foundations Space \nSymposium Dean E. Fulmer Transportation Research Board (TRB) \nAnnual Meeting Laurence F. Audenaerd University of New Mexicos UAS \nTechnical Analysis and Applications \nCenter (TAAC) Conference Andrew R. Lacher U.S. Chamber of Commerces Annual \nAviation Summit Cheryl A. Croft Women in Aviation International \n(WAI) Conference Elida C. Smith Worldwide TAAM User Group Meeting Jonathan H. Hoff man Conference Participation 11 2016 Federal Mobile Computing Summit Report, White \nPaper, R. Patrick Benito, MITREAdvanced Technology \nAcademic Research Center (MITREATARC) Mobile \nCollaboration Symposium, April 6, 2016, Washington, DC. ADS-B Surveillance in High Density SUAS Applications \nat Low Altitudes, R. Michael Guterres, \nStanley R. Jones, Sebastian V. Massimini, and \nRobert C. Strain, Proceedings of the International \nSymposium on Enhanced Solutions for Aircraft and Vehicle \nSurveillance Applications Conference, April 78, 2016, \nBerlin, Germany. Advancing the Trustworthiness of Automated Driving, \nAndrew R. Lacher, presented at the Transportation \nResearch Board 95th Annual Meeting, January 1014, \n2016, Washington, DC. AeroMACS Spectrum: Ready for Use, \nDean F. Lamiano, presented at the Avionics for NextGen \nConference, September 2829, 2016, Chantilly, VA. Agile Acquisition: FAA Incentives to Change their \nAcquisition Policies, Hugh G. Goodwin, \nMichael E. Liggan, Avinash Pinto, \nSiroos Sekhavat-Tafti, Amanda M. Staley, and \nNadya K. Subowo, presented at the Systems Engineering \nin DC (SEDC) 2016 Conference, March 31April 2, 2016, \nChantilly, VA. Conference Participation 12 Air Traffi c Controller Utilization of Voice and Data Link \nCommunications During Interval Management, \nRandall S. Bone and Kevin M. Long, Proceedings of \nthe 2016 Integrated Communications, Navigation, and \nSurveillance (ICNS) Conference, April 1921, 2016, \nHerndon, VA. Air Traffi c Management Simulation and Environmental \nModeling, Jonathan H. Hoff man, presented at the \nTransportation Research Board 95th Annual Meeting, \nJanuary 1014, Washington, DC. Analyses and Simulations for Aeronautical Mobile Airport \nCommunications System, Donald S. Arnstein, \nFrancis Box, Izabela L. Gheorghisor, Leonid Globus, \nand Vinay Lakshminarayan, Proceedings of the 2016 \nIntegrated Communications, Navigation, and Surveillance \n(ICNS) Conference, April 1921, 2016, Herndon, VA. Analyzing the Validity of Selective Mutation with \nDominator Mutants, Mariet S. Kurtz, Paul Ammann, \nMrcio E. Delamaro, Nida Gke, Bob Kurtz, and Jeff \nOff utt, Proceedings of the 2016 24th ACM SIGSOFT \nInternational Symposium on Foundations of Software \nEngineering, November 1318, 2016, Seattle, WA. Applicability of Lessons Learned from Aviation Safety \nManagement System for Automated Vehicles, \nAndrew R. Lacher, presented at the AUVSI Automated \nVehicles Symposium, July 1921, 2016, San Francisco, CA. Conference Participation 13 Are We There Yet? How Redundant and Equivalent \nMutants Aff ect Determination of Test Completeness, \nMariet S. Kurtz, Paul Ammann, Bob Kurtz, and Jeff \nOff utt, presented at The IEEE International Conference on \nSoftware Testing, Verifi cation and Validation (ICST) 11th \nInternational Workshop on Mutation Analysis, April 10, \n2016, Chicago, IL. Assessing Factors that Aff ect the Safety of Space Launch \nand Re-entry Operations in the National Airspace System, \nJonathan L. Schwartz, Jon L. Semanek, Zheng Tao, \n Ganghuai Wang, and Ashley G. Williams, presented at \nthe American Institute of Aeronautics and Astronautics \n(AIAA) Space 2016 Conference, September 1315, 2016, \nLong Beach, CA. Assessing Surveillance Performance Requirements \nfor Air Traffi c Control During Space Launch and Re-\nentry Operations, Zheng Tao and Ashley G. Williams, \npresented at National Space & Missile Materials \nSymposium / Commercial and Government Responsive \nAccess to Space Technology Exchange, June 2023, 2016, \nWestminster, CO. Assessment of Delivery Accuracy in an Operational Like \nEnvironment, Shivanjli Sharma and Mitchel Wynnyk, \nProceedings of the American Institute of Aeronautics and \nAstronautics (AIAA) Aviation 2016 Conference, \nJune 1317, 2016, Washington, DC. Conference Participation 14 ATM-Weather Integration (AWI) Gap Analysis of the \nNAS Segment Implementation Plan (NSIP), \nMatthew J. Fronzak and Claudia V. McKnight, \nProceedings of the 2016 Integrated Communications, \nNavigation, and Surveillance (ICNS) Conference, \nApril 1921, 2016, Herndon, VA. Capacity of Spectrum Available for Unmanned-Aircraft \nCommand and Control Links, Francis Box, \nLeonid Globus, and Richard E. Snow, Proceedings of \nthe 2016 Integrated Communications, Navigation, and \nSurveillance (ICNS) Conference, April 1921, 2016, \nHerndon, VA. Challenges in Developing an Aviation Operational \nPerformance Dashboard, Wayne W. Cooper Jr.,\nEhsan Esmaeilzadeh, Robert C. Flynn, and \nPhillip D. Schrader Proceedings of the 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 1921, 2016, Herndon, VA. Closing The Loop: Testing for IM Avionics Certifi cation, \n D. Stuart Bowman, David J. Elliott, Brenda Perez, and \nDon Walker, Proceedings of the American Institute of \nAeronautics and Astronautics Science and Technology \nForum and Exposition 2016, January 48, 2016, \nSan Diego, CA. Conference Participation 15 Collaborative Aviation Weather Statement (CAWS), \nSupporting Air Traffi c Management (ATM) with Aviation \nWeather Constraint Forecasts, John J. Huhn and Kevin \nJohnston, Proceedings of the American Meteorological \nSociety 96th Annual Meeting, January 1014, 2016, \nNew Orleans, LA. Concept Maturity Framework, Christopher T. DeSenti \nand Constance E. Morgan, presented at the FAA 11th \nAnnual Verifi cation and Validation Summit, September \n1415, 2016, Atlantic City, NJ. On Consumer-Driven Innovation, Engineering \nInnovation Panel: Creating Disruptive Interdisciplinary \nInnovation in Engineering, Glenn F. Roberts, Panelist, \n10th Annual School of Engineering and Applied Science \nStudent R&D Showcase, George Washington University, \nFebruary 22, 2016, Washington, DC. Continuous Mobile Integration, Jeff rey L. Stein, Session \nLead, Federal Mobile Computing Summit, The MITRE \nCorporation and the Advanced Technology Research \nCenter, April 6, 2016, Washington, DC. Counter Drone Technology: Counteracting UAS for \nSafetys Sake, Andrew R. Lacher, Panel Moderator, \nDrone World Expo, AUVSI XPONENTIAL, November \n1416, 2016, San Jose, CA. Conference Participation 16 Counter UAS Challenges & Technologies, \nAndrew R. Lacher, presented at the Technology Training \nCorporations Civil and Commercial Drone Systems and \nCounter Drone Technologies Symposium, June 2324, \n2016, Arlington, VA. Counter-UAS Concepts and Technologies, \nAndrew R. Lacher, Panelist, NASAs Unmanned Aircraft \nSystem Traffi c Management (UTM) Convention 2016, \nNovember 810, 2016, Syracuse, NY. A Cross-Generational Industry Perspective, \nLillian Z. Ryals, Panel Moderator, 61st Air Traffi c Control \nAssociation (ATCA) Conference and Exhibit 2016, \nOctober 1619, 2016, National Harbor, MD. Current Topics in Air Carrier Competition, \nKatherine T. Harback, Session Chair, Transportation \nResearch Board 95th Annual Meeting, January 1014, \n2016, Washington, DC. Cyber-Resiliency in Transportation, Andrew R. Lacher, \nProceedings of the 2016 Integrated Communications, \nNavigation, and Surveillance (ICNS) Conference, \nApril 1921, 2016, Herndon, VA. Conference Participation 17 Deep Learning for Extracting Word-level Meaning from \nSafety Report Narratives, David Chanen, Proceedings \nof the 2016 Integrated Communications, Navigation, \nand Surveillance (ICNS) Conference, April 1921, 2016, \nHerndon, VA. Defi ning an Error Budget for Required Interval \nManagement Performance, Lesley A. Weitz, Ian Levitt, \nand Johan Martensson, Proceedings of the American \nInstitute of Aeronautics and Astronautics Science and \nTechnology Forum and Exposition 2016, January 48, \n2016, San Diego, CA. Designing Stochastic Optimal Control Laws for Interval \nManagement, Travis L. Gaydos and Lesley A. Weitz, \nProceedings of the American Institute of Aeronautics \nand Astronautics Science and Technology Forum and \nExposition 2016, January 48, 2016, San Diego, CA. Developing a Real-Time Monitoring and Alerting \nCapability for Traffi c Flow Management, \n Hilton Bateman, James S. DeArmon, and \nShin-Lai Tien, Proceedings of the 35th Digital Avionics \nSystems Conference (DASC), September 2529, 2016, \nSacramento, CA. Digital Copilot, Matthew E. Pollack and \nJeff rey L. Stein, presented at the National Business \nAviation Association Business Aviation Convention and \nExhibition (NBAA-BACE), November 13, 2016, \nOrlando, FL. Conference Participation 18 Digital Copilot: Cognitive Assistance for Pilots, \nKevin J. Burns, Steven L. Estes, John R. Helleberg, \nKevin M. Long, Matthew E. Pollack, and \nJeff rey L. Stein, Proceedings of the Association for the \nAdvancement of Artifi cial Intelligence Fall Symposium, \nNovember 1719, 2016, Arlington, VA. Emerging Autonomy Operations: Defense and Security, \nAndrew R. Lacher, presented at the American Institute of \nAeronautics and Astronautics (AIAA) Intelligent Systems \nWorkshop, August 35, 2016, Hampton, VA. Enhancing GTAP with Tourism Flows and Domestic \nTransportation Margins, Shane L. Martin and Everett \nPeterson, presented at the Global Trade Analysis Projects \n19th Annual Conference on Global Economic Analysis, \nJune 1517, 2016, Washington, DC. Estimating Mode Choice for Freight Shipments Using the \nConfi dential Commodity Flow Survey, Daniel T. Brown \nand Shane L. Martin, presented at the Southern Economic \nAssociation 86th Annual Conference, November 1921, \n2016, Washington, DC. Estimating OverConservatism in Airspace Constraint \nManagement, Hilton Bateman, John Conroy, \nJames S. DeArmon, and Simon H. Heitin, Proceedings \nof the American Institute of Aeronautics and Astronautics \n(AIAA) Aviation 2016 Conference, June 1317, 2016, \nWashington, DC. Conference Participation 19 Evaluating the Impact of Estimated Time of Arrival \nAccuracy on Interval Management Performance, \nXiaoli Bai, Stephanie A. Priess, and Lesley A. Weitz, \nProceedings of the American Institute of Aeronautics and \nAstronautics (AIAA) SciTech 2016 Conference, \nJanuary 48, 2016, San Diego, CA. Evaluating the Safety of Launch and Reentry Operations \nin the National Airspace System, Jonathan L. Schwartz, \nJon L. Semanek, Zheng Tao, Ganghuai Wang, and \nAshley G. Williams, FAA Center of Excellence for \nCommercial Space Transportation Sixth Annual Technical \nMeeting, October 1114, 2016, Las Cruces, NM. Evaluation of Flight Deck Procedures Used in the \nDesignation of Traffi c for Tailored Collision
Avoidance \nLogic, Steven L. Estes, John R. Helleberg, and \nJennifer A. McLachlan, Proceedings of the Human \nFactors and Ergonomics Society Annual Meeting, \nSeptember 1923, 2016, Washington, DC. Examining the Eff ectiveness of a Traffi c Flow \nManagement Course for Air Traffi c Control Students, \nValerie Gawron, Roberta L. Zimmerman, Vernol \nBattiste, Jillian Keeler, Adriana Miramontes, Thomas \nZ. Strybel, and Kim-Phuong L. Vu, Proceedings of the \nHuman Factors and Ergonomics Society Annual Meeting, \nSeptember 1923, 2016, Washington, DC. Conference Participation 20 Examining Time to Evacuate Dynamically Activated \nAircraft Hazard Areas, Jonathan L. Schwartz, \nJon L. Semanek, Zheng Tao, Ganghuai Wang, and \nAshley G. Williams, Proceedings of the Embry-Riddle \nSpace Traffi c Management Conference 2016, November \n1618, 2016, Daytona Beach, FL. Exploring Necessary Altitude Awareness and Response \nTimes for Air Traffi c Control during Space Launch and \nReentry Vehicle Operations, Jonathan L. Schwartz, \nJon L. Semanek, Zheng Tao, Ganghuai Wang, \nPaul D. Wilde, and Ashley G. Williams, Proceedings of \nthe 8th International Association for the Advancement of \nSpace Safety (IAASS), May 1820, 2016, Melbourne, FL. FAA Air Traffi c Flow Management: Why, How, & the \nFuture, Marcus Smith, presented at the University of \nMassachusetts Transportation Center, April 28, 2016, \nAmherst, MA. GAJSC and GA ASIAS, Jeff rey P. Mittelman and \nCorey Stephens, presented at the Embraer Jet Operators \nAssociation Phenom Conference & Embraer Executive \nOperators Conference (EEOC2016), May 1821, 2016, \nSanta Fe, NM. Conference Participation 21 GPS Receiver Performance Degradation in the Presence \nof Faded Interference, Christopher J. Hegarty, Louis \nK. Dressel, Per K. Enge, Swen D. Ericson, Terence \nL. Johnson, Karl W. Shallberg, and Kyle D. Wesson, \nProceedings of the 2016 International Technical Meeting \nof The Institute of Navigation, January 2528, 2016, \nMonterey, CA. GPS/GNSS Antenna Characterization, \nChristopher J. Hegarty, presented at the Department \nof Transportation GPS Adjacent Band Compatibility \nWorkshop V, October 14, 2016, Washington, DC. How Low Cost Carriers Have Aff ected Air Fares Over \nthe Last Decade, Daniel T. Brown, presented at the \nTransportation Research Board 95th Annual Meeting, \nJanuary 1014, 2016, Washington, DC. Human Factors in the Design of Workplace Wellness \nPrograms, Valerie Gawron and Gregory M. Nelson, \nPanelists, SIM University Symposium on Human Factors in \nHealthcare, August 22, 2016, Singapore. Identifi cation, Quantifi cation and Mitigation of ATM-\nWeather Integration Gaps for NSIP Increments Dependent \non Weather Information, Matthew J. Fronzak and \nClaudia V. McKnight, Poster session: Aviations Usable \nRegions of Airspace, Hazards, and Mitigations at the \nAmerican Meteorological Society (AMS) 96th Annual \nMeeting, January 1014, 2016, New Orleans, LA. Conference Participation 22 Impact of Runway Closures on Arrival Flows at a Major \nMetropolitan Airport, John Conroy, James S. DeArmon, \nand Tudor Masek, Proceedings of the American Institute \nof Aeronautics and Astronautics (AIAA) Aviation 2016 \nConference, June 1317, 2016, Washington, DC. Impacts of Weather on the Nations Aviation System, \nMatthew J. Fronzak and Michael Robinson, Session \nCo-chairs, American Meteorological Society (AMS) 96th \nAnnual Meeting, January 1014, 2016, New Orleans, LA. Integrating ATM Applications Globally: Creating a \nHarmonized ATM System, Stephane L. Mondoloni, \nPanelist, 61st Air Traffi c Control Association (ATCA) \nConference and Exhibit 2016, October 1619, 2016, \nNational Harbor, MD. Integrating Avionics Standards with Ground ATM \nSystems to Meet 2025 Operational Needs, \nMahesh Balakrishna, Thomas A. Becher, \nRoland M. Sgorcea, and William L. Symionow, \nProceedings of the 35th Digital Avionics Systems \nConference (DASC), September 2529, 2016, \nSacramento, CA. Conference Participation 23 Interval Management: Development and Implementation \nof an Airborne Spacing Concept, Randall S. Bone, \nWilliam J. Penhallegon, and Lesley A. Weitz, \nProceedings of the American Institute of Aeronautics and \nAstronautics (AIAA) SciTech 2016 Conference, \nJanuary 48, 2016, San Diego, CA. Invited Session: Interval Management: Avionics \nAlgorithms and Performance Analysis, Lesley A. Weitz, \nSession Chair, The American Institute of Aeronautics and \nAstronautics (AIAA) SciTech 2016 Conference, \nJanuary 48, 2016, San Diego, CA. Invited Session: Interval Management: Operational \nConcept, Integration, and Benefi ts, \nWilliam J. Penhallegon, Session Chair, The American \nInstitute of Aeronautics and Astronautics (AIAA) SciTech \n2016 Conference, January 48, 2016, San Diego, CA. Introduction to Simple Workload Models Using \nCogulator, Steven L. Estes, Proceedings of the Human \nFactors and Ergonomics Society Annual Meeting, \nSeptember 1923, 2016, Washington, DC. Learning Automation for Traffi c Flow Management \nDecision Support, Christine P. Taylor, Erik P. Vargo, \nand Craig R. Wanke, Proceedings of the American \nInstitute of Aeronautics and Astronautics (AIAA) Aviation \n2016 Conference, June 1317, 2016, Washington, DC. Conference Participation 24 Leveraging Interval Management to Improve Air Traffi c \nOperations during Departure, Craig A. Guensch, \nBrock J. Lascara, Peter M. Moertl, and Lesley A. Weitz, \nProceedings of the American Institute of Aeronautics and \nAstronautics (AIAA) SciTech 2016 Conference, \nJanuary 48, 2016, San Diego, CA. Low Cost Surface Awareness Technology and \nDemonstration, Hilton Bateman, Shuo Chen, \nRonald S. Chong, Jacob Richkus, and \nEmily K. Stelzer, Proceedings of the 35th Digital Avionics \nSystems Conference (DASC), September 2529, 2016, \nSacramento, CA. Measuring Flight Effi ciency in the National Airspace \nSystem, Wayne W. Cooper Jr., James S. DeArmon, \nand Tudor Masek, Proceedings of the American Institute \nof Aeronautics and Astronautics (AIAA) Aviation 2016 \nConference, June 1317, 2016, Washington, DC. MITRE AirTOp Update, John A. Kuchenbrod, \npresented at the Air Traffi c Optimization (AirTOp) User \nWorkshop 2016, October 26, 2016, Singapore. The MITRE Corporation Countering Unauthorized UAS \nChallenge: A Case Study in Emerging Counter-Drone \nResearch, Andrew R. Lacher, presented at Defence IQ, \nCountering Drones Conference, December 68, 2016, \nLondon, United Kingdom. Conference Participation 25 Mobility Solutions to Enhance Citizen Engagement, \nMatthew E. Pollack, Session Lead, Federal Mobile \nComputing Summit, The MITRE Corporation and the \nAdvanced Technology Research Center, April 6, 2016, \nWashington, DC. Modeling Uncertainty in Inter-Aircraft Spacing Between \nthe Final Approach Fix and the Runway Threshold, \nStephanie A. Priess, Hans P. Stassen, and \nLesley A. Weitz, Proceedings of the American Institute \nof Aeronautics and Astronautics (AIAA) SciTech 2016 \nConference, January 48, 2016, San Diego, CA. A Monte Carlo Simulation Tool for Evaluating Space \nLaunch and Re-entry Operations, Tudor Masek, \nJonathan L. Schwartz, Ganghuai Wang, and \nZheng Tao, Proceedings of the 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 1921, 2016, Herndon, VA. A More Complete Characterization of Transportation \nMargins in the USAGE Model, Daniel T. Brown, \nKatherine T. Harback, Shane L. Martin, Peter Dixon, \nJames Lennox, and Maureen Rimmer, presented at the 19th \nAnnual Conference on Global Economic Analysis, \nJune 1517, 2016, Washington, DC. New Horizons in Aviation R&D: Balancing Innovation \nand Safety, Lillian Z. Ryals, presented at the R&D 100 \nConference, November 24, 2016, National Harbor, MD. Conference Participation 26 Operational Benefi ts of Parallel Off set Routes, \nJonathan H. Hoff man, Proceedings of the 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 1921, 2016, Herndon, VA. Operational Evolutions: Airport & Airspace Optimization/\nOperations (Track 6), Session B: Enabling Technologies, \nRalf H. Mayer, Session Chair, 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 19-21, 2016, Herndon, VA. Operational Evolutions: Airport & Airspace Optimization/\nOperations (Track 6), Session E: Operational Evolutions \nI, Thomas A. Becher, Session Chair, 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 19-21, 2016, Herndon, VA. Operational Evolutions: Airport & Airspace Optimization/\nOperations (Track 6), Session F: Operational Evolutions \nII, Thomas A. Becher, Session Chair, 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 19-21, 2016, Herndon, VA. Operational Evolutions: Commercial, Military, and \nConsumer UAS (Track 7), Session D: Data Communication \nII, Ralf H. Mayer, Session Chair, 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 19-21, 2016, Herndon, VA. Conference Participation 27 Operational Evolutions: Performance-Based CNS/ATM \n(Track 7), Session C: Data Communication I, \nRalf H. Mayer, Session Chair, 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 19-21, 2016, Herndon, VA. Overview of Speech Recognition Technology to Support \nAir Traffi c Management, Robert M. Tarakan, presented \nat SpeechTek 2016, May 2325, 2016, Washington, DC. Performance Based Network Concept for Advanced Air \nTraffi c Services, John C. Gonda III and Dongsong Zeng, \nProceedings of the 2016 Integrated Communications, \nNavigation, and Surveillance (ICNS) Conference, \nApril 1921, 2016, Herndon, VA. Performance-Based Navigation and Vertical Guidance, \nSebastian V. Massimini, presented at Eurasian Air \nTraffi c Control Conference, September 2830, 2016, \nSochi, Russia. Predictive Models of Departure and Arrival Runway \nOccupancy Time and Take-Off Distance, \nThomas L. Spencer, presented at the NEXTOR II 20th \nAnniversary Workshop, September 2930, 2016, \nCollege Park, MD. Conference Participation 28 Predictors of Unsuccessful Approaches, \nValerie Gawron and Frederick A. Niles, presented at the \nHuman Factors and Ergonomics Society Annual Meeting, \nSeptember 1923, 2016, Washington, DC. Projecting Air Traffi c Impact of Blocked Airspaces, \nAmal Srivastava, presented at the Embry-Riddle Space \nTraffi c Management Conference 2016, November 1618, \n2016, Daytona Beach, FL. Proposed sUAS Safety Performance Requirements for \nOperations over People, Jeff rey L. Breunig, \nEdward A. Lester, and Brian C. Patterson, presented \nat the Massachusetts Institute of Technology (MIT) \nLincoln Laboratory Air Traffi c Control Workshop, \nDecember 8, 2016, Washington, DC. Regulatory Perspective: The UAS Rulemaking and \nBeyond, David G. Hamrick, Panelist, K&L Gates \nAviations Next Frontier: UAS Outlook for 2016, \nFebruary 8, 2016, Washington, DC. Remote and Smart Tower Future 2016 and Beyond, \nKurt Rammelsberg, presented at the International Civil \nAviation Organization (ICAO) Remotely Piloted Aircraft \nSystems (RPAS)
and Remote Air Traffi c Services (ATS) \nSymposium, May 910, 2016, Stockholm, Sweden. Conference Participation 29 Remote and Smart Tower Future 2026 and Beyond, \nKurt Rammelsberg, presented at the CANSO Global \nATM Operations Conference, March 1011, 2016, \nMadrid, Spain. Research Panel: Through the NAS, Amal Srivastava \nand Zheng Tao, Panelists, Space Traffi c Management \nConference 2016, November 1618, 2016, Daytona \nBeach, FL. Results from a Field Evaluation of Interval Management \nduring an Optimized Profi le Descent Arrival and \nApproach, Randall S. Bone, William J. Penhallegon, \nand Hans P. Stassen, Proceedings of the American \nInstitute of Aeronautics and Astronautics (AIAA) SciTech \n2016 Conference, January 48, 2016, San Diego, CA. Risk-based Approach to Airworthiness, \nAndrew R. Lacher, Panel Moderator, Association for \nUnmanned Vehicle Systems International (AUVSI) \nXPONENTIAL, May 25, 2016, New Orleans, LA. Space Launch and Reentry Operations in the NAS \nInformation Integration, Catherine N. Bolczak, \nAmal Srivastava, Thomas J. St. Clair, and \nAmanda M. Staley, Proceedings of the 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 1921, 2016, Herndon, VA. Conference Participation 30 SWIM Consumer Implementation, Anuja Verma, \nProceedings of the 2016 Integrated Communications, \nNavigation, and Surveillance (ICNS) Conference, \nApril 1921, 2016, Herndon, VA. Terminal Controller Feedback on an Automated \nSequencing and Spacing Tool, Lynne Martin, \nKathleen A. McGarry Peterson, and Kevin Witzberger, \nProceedings of the Human Factors and Ergonomics Society \nAnnual Meeting, September 1923, 2016, Washington, DC. Trajectory Based Operations (TBO) SWIM needs \nfocused Stephane L. Mondoloni, presented at the FAA \nAir Transportation Information Exchange Conference, \nSeptember 2226, 2016, Silver Spring, MD. Trajectory-Based Operations Robust Planning under \nTrajectory Uncertainty, Stephane L. Mondoloni, \nProceedings of the 35th Digital Avionics Systems \nConference (DASC), September 2529, 2016, \nSacramento, CA. UAS EXCOM Science and Research Panel (SARP) 2016 \nTAAC Update, Dallas Brooks, Edward A. Lester, \nBrian C. Patterson, and Andrew Weiner, University of \nNew Mexicos Unmanned Aircraft Systems Technical \nAnalysis and Applications Center (UAS TAAC) 2016 \nConference, December 1215, 2016, Santa Fe, NM. Conference Participation 31 UAS WorkshopUAS Privacy & Security, \nAndrew R. Lacher, Panelist, Transportation Research \nBoard 95th Annual Meeting, January 1014, 2016, \nWashington, DC. Understanding Counter Drone Technology: Pros & \nCons of Diff erent Systems for Military, Government, \n& Industry, Andrew R. Lacher, Panel Moderator, \nCountering Drones Conference, December 68, 2016, \nLondon, UK. Unmanned and Autonomous Vehicles: A Cultural \nMismatch, Andrew R. Lacher, presented at George \nMason UniversityCenter for Air Transportation Systems \nResearch Seminar, April 27, 2016, Fairfax, VA. An Update from the NextGen Advisory Committee: \nUnique Venue for Public/Private Collaboration, \nLillian Z. Ryals, presented at the RTCA Global Aviation \nSymposium 2016, June 12, 2016, Washington, DC. Using Ensemble Weather Forecasts for Predicting \nAirport Runway Capacity, Shin-Lai Tien, \nChristine P. Taylor, and Craig R. Wanke, Proceedings \nof the American Institute of Aeronautics and Astronautics \n(AIAA) Aviation 2016 Conference, June 1317, 2016, \nWashington, DC. Conference Participation 32 Using Text Mining and Business Intelligence Tools in \nRegulatory Performance and Risk-Based Oversight, \nWallace N. Feerrar, presented at the FAA Flight \nStandards Asia Pacifi c Conference, July 1920, 2016, \nWashington, DC. VDL2 Power Control, John C. Gonda III and \nDongsong Zeng, Proceedings of the 35th Digital Avionics \nSystems Conference (DASC), September 2529, 2016, \nSacramento, CA. Vision of the Future: What is Our Biggest Challenge? \nAndrew R. Lacher, presented at the American Institute \nof Aeronautics and Astronautics (AIAA) Aviation 2016 \nConference, June 1317, 2016, Washington, DC. Technical Exchange Meetings Technical Exchange Meetings (TEM) are forums for \nexchanging ideas, starting new initiatives, learning about \nnew technologies, sharing resources, or collaborating \nacross programs and organizational boundaries. ACAS Xa and TCAS II NAS Operational Performance \nAssessment Update, Emily P. Bromberg, \nRyan W. Huleatt, Roland M. Sgorcea, and \nErik P. Vargo, ACAS Xa New Hampshire Technical \nExchange Meeting, August 2016. Conference Participation 33 ACAS Xa and TCAS II NAS Operational Performance \nAssessment Update, Emily P. Bromberg, \nRyan W. Huleatt, Roland M. Sgorcea, and \nErik P. Vargo, Data Science and Analytics mini-TEM \nSeries, August 2016, McLean, VA. ASIASThe Impact of Aviation Safety Analysis at \nMITRE, Michelle L. Harper and Jessica R. Lascara, \nGetting to WowExamples of Analytics Making an \nImpact Technical Exchange Meeting, Data Science and \nAnalytics mini-TEM Series, August 2016, McLean, VA. ASIAS Overview, Edward B. Walsh, Railroad Technical \nExchange Meeting, January 2016, Washington, DC. Talend Data Integration, Leigh T. Gathings, presented at \nthe Data Performance Technical Exchange Meeting, \nMay 2016, Colorado Springs, CO. Conference Participation 35 Special Honors and Recognition Aviation International News (AINonline) announced \nthat the Federal Aviation Administration (FAA) has \nnamed Lillian Z. Ryals as a member of the RTCA Drone \nAdvisory Committee (DAC), August 2016. The Commission on Accreditation of Medical Transport \nSystems (CAMTS) Board of Directors letter of appreciation \nfor the eff orts of Steven L. Estes, John R. Helleberg, \nKent V. Hollinger, and Mitchel Wynnyk on reviewing \ntheir Safety Culture Survey results as part of an FAA grant, \nSeptember 2016. The Department of Homeland Security Science and \nTechnology (DHS S&T) Directorate Ceremony, Under \nSecretarys Award for Outstanding Collaboration was \npresented to Kevin M. Long and Lisa A. Kerby for the \nNext Generation First Responder Apex Team: Honored for \nexecuting fi rst-of-its-kind test and evaluation approach and \ncommunication strategies, July 2016. The American Institute of Aeronautics and Astronautics \n(AIAA), elected Lesley A. Weitz to the grade of Associate \nFellow in October 2016. HONORS, AWARDS, AND RECOGNITION 36 The Federal Aviation Administration notifi ed the \nPARC Communications Working Groups that two \nsignifi cant ICAO manuals, The Global Operational Data \nLink Document (GOLD) and The Performance-Based \nCommunications and Surveillance (PBCS), have been \napproved by the ICAO Secretary General, August 2016. The R&D 100 Conference awarded the Massachusetts \nInstitute of Technology (MIT) Lincoln Laboratory for \ntheir Airborne Collision Avoidance System X (ACAS \nXu) project and recognized MITRE as a co-developer \nalong with the Federal Aviation Administration and \nJohns Hopkins University Applied Physics Laboratory, \nNovember 2016. The 2016 Institute of Electrical and Electronics Engineers \n(IEEE) and the American Institute of Aeronautics and \nAstronautics (AIAA) presented a certifi cate of appreciation \nto Dongsong Zeng for his outstanding contributions during \nthe 35th IEEE/AIAA Digital Avionics Systems Conference \n(DASC) conference, September 2016. RTCA 2016 Award for Global Harmonisation was \npresented to Randall S. Bone, John C. Gonda III, and \nDongsong Zeng during the EUROCAE/RTCA Annual \nSymposium, April 2016. Honors, Awards, and Recognition 37 The National Aeronautics and Space Administration \npresents the Group Achievement Award to the Operational \nIntegration Assessment (OIA) Team: \nPaul V. MacWilliams, Kathleen A. McGarry Peterson, \nAndrew S. Mendolia, David L. Toms, and \nMitchel Wynnyk, for designing, developing, and \nconducting a complex human-in-the-loop simulation to test \nNASAs Terminal Sequencing and Spacing technology in \nan operational environment, June 2016. RTCA presented its Outstanding Leadership Award \nto Lesley A. Weitz for her contributions on Special \nCommittee 186: Automatic Dependent Surveillance-\nBroadcast in producing DO-361: Minimum Operational \nPerformance Standards (MOPS) for the Flight-Deck \nInterval Management (FIM) at the 2016 Global Aviation \nSymposium, June 2016. RTCA presented its Signifi cant Contributor Award \nto David J. Elliott for his contributions on Special \nCommittee 186: Automatic Dependent Surveillance-\nBroadcast in producing DO-361: Minimum Operational \nPerformance Standards (MOPS) for the Flight-Deck \nInterval Management (FIM) at the 2016 Global Aviation \nSymposium, June 2016. Honors, Awards, and Recognition 38 RTCA presented its Signifi cant Contributor Award \nto Randall S. Bone for his contributions on Special \nCommittee 186: Automatic Dependent Surveillance-\nBroadcast in producing DO-328A: Safety, Performance \nand Interoperability Requirements Document for Airborne \nSpacingFlight Deck Interval Management (ASPA-FIM) \nat the 2016 Global Aviation Symposium, June 2016. RTCA presented its Signifi cant Contributor Award \nto Brock J. Lascara for his contributions on SC-206 \nAeronautical Information and Meteorological Data Link \nServices in producing DO-358: Minimum Operational \nPerformance Standards (MOPS) for Flight Information \nServicesBroadcast (FIS-B) with Universal Access \nTransceiver (UAT) at the 2016 Global Aviation \nSymposium, June 2016. RTCA presented its Signifi cant Contributor Award \npresented to J. William Carson for his contributions to \nthe SC-206 Aeronautical Information and Meteorological \nData Link Services in producing Supplement to DO-358: \nMinimum Operational Performance Standards (MOPS) \nfor Flight Information Services-Broadcast (FIS-B) with \nUniversal Access Transceiver (UAT), 2016 Global \nAviation Symposium, June 2016. Honors, Awards, and Recognition 39 RTCA presented its Signifi cant Contributor Award \npresented to Douglas Havens for his contributions to the \nSC-206 Aeronautical Information and Meteorological \nData Link Services in producing Supplement to DO-358: \nMinimum Operational Performance Standards (MOPS) \nfor Flight Information Services-Broadcast (FIS-B) with \nUniversal Access Transceiver (UAT), 2016 Global \nAviation Symposium, June 2016. Best Paper Awards Best of Session award presented to Hilton Bateman, \n Shuo Chen, Ronald S. Chong, Jacob Richkus, and \nEmily K. Stelzer, for their paper Low Cost Surface \nAwareness Technology and Field Demonstration, at \nthe 35th Digital Avionics Systems Conference (DASC), \nSeptember 2016, Sacramento, CA. Best Professional Paper award presented to David Chanen \nfor his paper Deep Learning for Extracting Word-Level \nMeaning from Safety Report Narratives at the 2016 \nIntegrated Communications, Navigation, and Surveillance \n(ICNS) Conference, April 2016. Honors, Awards, and Recognition 40 Best Paper of the Commercial Space Transportation Track \naward presented to Tudor Masek, Jonathan L. Schwartz, \nZheng Tao, and Ganghuai Wang for their paper A \nMonte Carlo Simulation Tool for Evaluating Space \nLaunch and Re-entry Operations at the
2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 2016. Best Paper of the Performance-Based CNS/ATM Track \naward presented to John C. Gonda III and \nDongsong Zeng for their paper Performance Based \nNetwork Concept for Air Traffi c Services at the 2016 \nIntegrated Communications, Navigation, and Surveillance \n(ICNS) Conference, April 2016. Best Paper of the Climate Change and Aviation Weather \nTrack award presented to Anuja Verma for her paper \nSWIM Consumer Implementation, at the 2016 Integrated \nCommunications, Navigation, and Surveillance (ICNS) \nConference, April 2016. Letters of Commendation From the Airports Authority of India in appreciation for \nMITREs generous hospitality and cooperation during \nour visit. We really appreciate the thorough planning and \ncoordinated presentation of valuable information during \nour interaction. It showed a really good appreciation of our \npresent day challenges and opportunities, February 2016. Honors, Awards, and Recognition 41 From the Colvin Run Elementary Schools Conservation \nRangers of Endangered Species team and coaches in \nappreciation of the amazing IDEA lab tour conducted by \nPaul V. MacWilliams, Jacob Richkus, and \nSamantha L. Tungul, October 2016. From the European Aviation Safety Agency in \nappreciation of the time and support of the valuable \nand instructive presentations given by Eric B. Chang, \n Heather L. Danner, Christopher J. Devlin, \nEugene A. Mwendwa, Prakash Subramanian, and \nEdward B. Walsh during their MITRE visit, \nOctober 2016. From the Federal Aviation Administration in appreciation \nfor the MITRE teams signifi cant contributions to the \ncollaborative eff ort in producing the PBN NAS Navigation \nStrategy 2016, which was endorsed by the NextGen \nAdvisory Committee (NAC), March 2016. From the Federal Aviation Administration in appreciation \nfor the MITRE teams support in developing and briefi ng \nthe Capability Package for the PBN Timing, Speed and \nSpacing Sequencing Tool NAC Tasking, March 2016. From the Federal Aviation Administration in appreciation \nfor Erin R. Catlett and Christopher G. Roberts \nfor facilitating eff ective training on a complex tool: \nrunwaySimulator, March 2016. Honors, Awards, and Recognition 42 From the Federal Aviation Administration in appreciation \nfor the MITRE Space Teams support and patience for a \nvery successful six months on the ATO Commercial Space \nIntegration Offi ce accomplishments, April 2016. From the Federal Aviation Administration in appreciation \nfor the MITRE teams support of the ATO Commercial \nSpace Integration document, April 2016. From the Federal Aviation Administration in appreciation \nof Michelle A. Duquettes tremendous assistance during \nthe UAS Symposium in conjunction with Embry-Riddle \nAeronautical University, April 2016. From the Federal Aviation Administration in appreciation \nfor the excellent job Elida C. Smith did in setting up \nand executing the demo day at MITRE. This event was \ninvaluable in educating the NAC PBN Tools Group on the \nvarious candidate capabilities, and in so doing, helped the \ncommunity move forward with this important tasking, \nMay 2016. From the Federal Aviation Administration in appreciation \nfor the support Justin R. Boesel, Michael L. Crane, \nJason A. Reinhart, and Stanley J. Roessner provided at \nthe SE 210 meeting, May 2016. Honors, Awards, and Recognition 43 From the Federal Aviation Administration, a letter of \nappreciation to Lillian Z. Ryals and the MITRE team \nfor their tremendous help developing the Performance \nBased Navigation (PBN) National Airspace System (NAS) \nNavigation Strategy, May 2016. From the Federal Aviation Administration in appreciation \nof Michael J. Fremberg, Grant Pan, John R. Polk, and \nAnuja Vermas great technical collaboration they provided \nto the FAA over the past year regarding the ASIAS work, \nJuly 2016. From the Federal Aviation Administration in appreciation \nof Michael J. Fremberg and Eugene A. Mwendwas \nsupport of the Digital Audio Legal Recorder Remote Audio \nAccess System (DRAAS), July 2016. Commendation from the Federal Aviation Administration \nregarding Cherlynn M. Jones methodical approach she \nused during her presentation on the Tuscon spaceport case \nstudy, August 2016. From the Federal Aviation Administration regarding \nreceiving approval from the JRC for the S1P2 Full Services \nportion of the program, in appreciation of MITREs \nexcellent systems engineering work and leadership in \nhelping the FAA achieve this milestone, August 2016. Honors, Awards, and Recognition 44 From the Federal Aviation Administration in appreciation \nof the MITRE team in completing the Human-in-the-\nLoop (HITL) Simulation Planning, Execution, and Reports \nIntegration of IDRP and ARSI, August 2016. From the Federal Aviation Administration in appreciation \nfor the eff orts of Monique Exum and Suzanne Porter \nthroughout the TRACON Evolution program, \nSeptember 2016. From the Federal Aviation Administration in appreciation \nfor the eff orts of Michelle J. Blucher and David Gouldey \nfor the work accomplished in compiling the TRACON \nEvolution Shortfalls Analysis document, September 2016. From the Federal Aviation Administration in appreciation \nfor the eff orts of Paul A. Diff enderfer throughout the \nTRACON Evolution program, September 2016. From the Federal Aviation Administration in appreciation \nfor the eff orts expended on the coagulator work by \nDevon B. Kelley and Raymond Stanley, September 2016. From the Federal Aviation Administration congratulating \nthe MITRE Team in completing the A-IM Capture \ndocument on time, September 2016. The FY16 Business Excellence recognition was awarded to \nthe VOR MON program team members during the Federal \nAviation Administrations PMO All Hands meeting, \nSeptember 2016. Honors, Awards, and Recognition 45 From the Federal Aviation Administration in appreciation \nfor the MITRE Teams support of the Operational Roles \nand Responsibilities for Space Vehicle Operations white \npaper, November 2016. From the Federal Aviation Administration in appreciation \nfor the MITRE Teams contribution for the AFST \n(renamed SFMA) 6th Mini-Evaluation 6 Summary Report, \nNovember 2016. From the Federal Aviation Administration in appreciation \nfor Thomas B. Hudak IIs participation at SASP1 in \nMontreal, November 2016. From the Federal Aviation Administration in appreciation \nfor Matthew J. Fronzak and John J. Huhns \ncontributions during the Weather Evaluation Team (WET) \nmeeting, November 2016. From the Federal Aviation Administration in \nappreciation for Robert M. Avjian, Matthew J. Fronzak, \nConstance E. Morgan, Kurt Rammelsberg, \n Michael Robinson, William J. Swedish, and \nShin-Lai Tiens assistance with the Aviation Weather \nDivisions weather integration initiatives, \nDecember 2016. From the Federal Aviation Administration in appreciation \nfor Amanda S. Matthews support on the 3T evaluation \ncoordination, October 2016. Honors, Awards, and Recognition 46 From RTCA in appreciation for Kelly R. Markins \nleadership on Phase 2 Terms of Reference updates for the \nSC-228 milestone, September 2016. From the University of Maryland in appreciation for \nCraig R. Wankes presentation at the NEXTOR 20th \nAnniversary Workshop, September 2016. Patents Awarded Air Traffi c Analysis Using a Linear Inequalities Solver, \nWilliam P. Niedringhaus, Paul T. R. Wang, and \nMatthew T. McMahon, U.S. Patent No. 9,251,710, \nFebruary 2, 2016. Patent Applications Filed Camera Surveillance Planning and Tracking System, \n Shuo Chen, Ronald S. Chong, Jacob Richkus, \nEmily K. Stelzer, David M. Tuomey, and Vilas Nene, \nJanuary 2016. Honors, Awards, and Recognition 47 Fellows Human Factors and Ergonomics Society Valerie Gawron The Institute of Electrical and Electronics \nEngineers Christopher J. Hegarty The Institute of Navigation Ronald Braff \nChristopher J. Hegarty International Ergonomics Association Valerie Gawron Royal Aeronautical Society Stephane L. Mondoloni Associate Fellows American Institute of Aeronautics and Astronautics Thomas A. Becher\nValerie Gawron\nJohn C. Gonda III\nChristopher J. Hegarty\nAndrew R. Lacher\nWesley B. Link\nDavid R. Maroney PROFESSIONAL SOCIETIES Sebastian V. Massimini\nRalf H. Mayer\nStephane L. Mondoloni\n Glenn F. Roberts\nCraig R. Wanke\nLesley A. Weitz\nAndrew D. Zeitlin 48 Memberships Advanced Computing Systems Association (System \nAdministration) (USENIX) Air Force Association (AFA) Air Line Pilots Association, International (ALPA) Air Traffi c Control Association (ATCA) Aircraft Owners and Pilots Association (AOPA) American Association of Airport Executives (AAAE) American Association of University Women (AAUW) American Economic Association (AEA) American Institute of Aeronautics and Astronautics \n(AIAA) American Mathematical Society (AMS) American Meteorological Society (AMS) American Physical Society (APS) American Planning Association (APA) The Association for Operations Management (APICS) American Society of Civil Engineers (ASCE) American Society for Quality (ASQ) American Society of Safety Engineers (ASSE) American Statistical Association (ASA) Armed Forces Communications and Electronics \nAssociation (AFCEA) Professional Societies 49 Association for Aviation Psychology (AAP) Association for Computing Machinery (ACM) Association for Enterprise Information (AFEI) Association for Unmanned Vehicle Systems International \n(AUVSI) Certifi ed Consulting Meteorologist (CCM) Certifi ed Information Systems Security Professional \n(CISSP) Experimental Aircraft Association (EAA) Federal Aviation Administration Managers Association \n(FAAMA) Guild of Air Traffi c Control Offi cers (GATCO) Human Factors and Ergonomics Society (HFES) Information Systems Audit and Control Association \n(ISACA) Institute for Operations Research and the Management \nSciences (INFORMS) Institute of Electrical and Electronics Engineers (IEEE) Communications Society (COMSOC) Computer Society (CS) Control Systems Society (CSS) Industrial Electronics Society (IES) Industry Applications Society (IAS) Women in Engineering (WIE) Professional Societies 50 Institute of Navigation (ION) International Air Transport Association (IATA) International Council on Systems Engineering (INCOSE) International Federation of Automatic Control (IFAC) International Institute of Forecasters (IIF) International Society of Air Safety Investigators (ISASI) International Union of Radio Science (URSI) Mathematical Association of America (MAA) National Air Traffi c Controllers Association (NATCA) National Association of Flight Instructors (NAFI) National Black MBA Association (NBMBAA) National Contract Management Association (NCMA) National Safety Council (NSC) National Society of Black Engineers (NSBE) Project Management Institute (PMI) Royal Aeronautical Society (RAeS) Royal Institute of Navigation (RIN) SAE International (SAE) Society for the Advancement of Material and Process \nEngineering
(SAMPE) Society for Industrial and Applied Mathematics (SIAM) Society of Women Engineers (SWE) Professional Societies 51 TBM Owners and Pilots Association, Inc. (TBMOPA) Threaded Track for Analysts by Analysts (TTAA) Transportation Research Board (TRB) Transportation Research Forum (TRF) Virginia Helicopter Association (VHA) Whirly GirlsInternational Women Helicopter Pilots Women in Aerospace (WIA) Women in Aviation, International (WAI) Women Military Aviators (WMA) Honor Societies Beta Gamma Sigma (Business) Eta Kappa Nu (Electrical and Computer Engineers) Omega Rho (International Operations Research) Phi Beta Kappa (Liberal Arts and Sciences) Sigma Pi Sigma (Physics) Tau Beta Pi (Engineering) Users Groups Airline Group of the International Federation of \nOperational Research Societies (AGIFORS) AirTOp User Group (AUG) Americas & Pacifi c Rim TAAM Users Group (APTUG) Professional Societies 52 BADA User Group (BUG) Large Installation System Administration Special Interest \nGroup (LISA) Special Interest Group on Computer-Human Interaction \n(SIGCHI)ACM / SIGCHI Worldwide TAAM Users Group (WWTUG) Professional Societies 53 American Institute of Aeronautics and \nAstronautics (AIAA) Aviation 2017 Executive Steering Committee Glenn F. Roberts Program Committees Transformational Flight\nDavid R. Maroney Unmanned Systems\nAndrew R. Lacher\nDavid R. Maroney Standing Committees Emerging Technologies Committee\nDavid R. Maroney Corporate Member Committee\nLillian Z. Ryals Technical Activities Committees Aircraft and Atmospheric Systems Group\nDavid R. Maroney, Deputy Director Air Transportation Systems\nStephane L. Mondoloni\nDavid R. Maroney, Emeritus Member TECHNICAL COMMITTEE MEMBERSHIPS 54 Guidance, Navigation, and Control\nLesley A. Weitz, Chair Intelligent Systems Technical Committee\nAndrew R. Lacher Modeling and Simulation\nChristine P. Taylor American Association of Airport Executives \n(AAAE) Operations, Safety, and Planning Committee Cheryl R. Andrews American Meteorological Society (AMS) Aviation, Range, and Aerospace Meteorology \n(ARAM) Matthew J. Fronzak Aviation, Range, and Aerospace Meteorology \n(ARAM) Conference Michael Robinson Civil Air Navigation Services Organisation \n(CANSO) Operations Standing Committee Bruce E. Killian, ASBU Chair EU-U.S. Cooperation on Satellite Navigation Working Group CARAIM Technical Subgroup Young C. Lee Committee Participation 55 Federal Aviation Administration (FAA) 1090 MHz Spectrum Risk Assessment Team Stanley R. Jones Advanced Interval Management and Dynamic \nRequired Navigation Focus Groups, FAA Data \nCommunication Segment 2 Subject Matter Expert John C. Gonda III Air Carrier Training Aviation Rulemaking \nCommittee (ACT ARC) Flight Path Management \nWorking Group William A. Miller Center of Excellence for Commercial Space \nTransportation, Executive Committee Zheng Tao Flight Standards: CNS Task Force (Joint with \nAirlines for America) Michael R. Cramer\nSean F. McCourt\nWilliam A. Miller General Aviation Issues Analysis Team (GA-IAT) Jeff rey P. Mittelman, Tri-chair Performance-Based Operations Aviation \nRulemaking Committee (PARC) Michael R. Cramer, WG ChairNavigation Communications Working Group\nDongsong Zeng Committee Participation 56 VNAV Action Team\nWilliam A. Miller, RNP Established Action Team \nChair Research, Engineering, and Development Advisory \nCommittee (REDAC) REDAC Human Factors Subcommittee\n Christopher T. DeSenti REDAC NAS Operations Subcommittee\nEmily K. Stelzer REDAC Subcommittee for Aircraft Safety\nAndrew R. Lacher Space-Based ADS-B Support Team Stanley R. Jones Unmanned Aircraft Safety Team (UAST) Deborah A. Kirkman\nPatricia Abel Massimini\nHassan Shahidi\nAnuja Verma Unmanned Aircraft System (UAS) Aviation \nRulemaking Committee (ARC) David G. Hamrick Unmanned Aircraft Systems Executive Committee \n(DHS, DoD, FAA, NASA) Science and Research Panel\nAndrew R. Lacher \nBrian C. Patterson USA/Europe ATM R&D Seminar\nCraig R. Wanke Committee Participation 57 Human Factors and Ergonomics Society A. R. Lauer Safety Award Committee Valerie Gawron, Chair Aerospace Systems Technical Group Valerie Gawron, Chair \n David A. Domino\nKathleen A. McGarry Peterson\nScott H. Mills\nEmily K. Stelzer Cognitive Engineering and Decision Making \nTechnical Group Emily K. Stelzer International Society of Air Safety Investigators \n(ISASI) Human Factors Working Group Mitchell L. Serber International Telecommunication Union\nRadiocommunication Sector (ITU-R) Effi cient Orbit/Spectrum Utilization for FSS and \nBSS (WP 4A) Michael Tran Effi cient Orbit/Spectrum Utilization for MSS and \nRDSS (WP 4C) Michael Tran MMS/GMDSS: Aeronautical Mobile Service and \nRadiodetermination (WP 5B) Michael Tran Committee Participation 58 Remote Sensing Systems (WP 7C) Michael Tran Space Radiocommunication Applications (WP 7B) Michael Tran National Aviation Authorities Joint Authorities for Rulemaking on Unmanned \nSystems (JARUS) Brian C. Patterson National Business Aviation Association (NBAA) NTSB Recommendation Project Team Jeff rey P. Mittelman Regional Airline Association Flight Technology Committee Sean F. McCourt RTCA, Inc. RTCA Annual Symposium Deborah A. Kirkman, CAASD Coordinator Drone Advisory Committee (DAC) Lillian Z. Ryals Integration and Coordination Committee (ICC) Robert A. Hekl NextGen Advisory Committee (NAC) Lillian Z. Ryals Committee Participation 59 NAC Advisory Subcommittee Dennis A. Sawyer NAC Policy Board Lillian Z. Ryals Program Management Committee (PMC) Christopher J. Hegarty, Chair Tactical Operations Committee (TOC) Douglas L. Molin GPS Adjacent Band Compatibility Task Group\nKelly R. Markin Wake Vortex Tiger Team Clark R. Lunsford (See also RTCA, Inc., Standards Committee Memberships.) SAE International Air Traffi c Management Steering Committee Christopher J. Hegarty Transportation Research Board (TRB ) Airfi eld and Airspace Capacity and Delay (AV060) Marcus Smith Aviation Economics and Forecasting (AV040) Katherine T. Harback Aviation System Planning (AV020) Ehsan Esmaeilzadeh\nMichael T. Wells Committee Participation 60 Committee on Intergovernmental Relations in \nAviation (AV010) Commercial Space Transportation Subcommittee\nCheryl R. Andrews\nMarcus Smith Common Performance Metrics for Airport \nInfrastructure and Operational Planning (ACRP \n03-41) Marcus Smith Environmental Impacts of Aviation (AV030) Anuja A. Mahashabde NextGenUnderstanding the Airports Role in \nPerformance-Based Navigation (ACRP 03-34) Laurence F. Audenaerd, Review Panel Member Standing Committee on Aircraft/Airport \nCompatibility (AV070) Neal Westlund Standing Committee on Airfi eld and Airspace \nCapacity and Delay (AV060) Neal Westlund Standing Committee on Light Commercial and \nGeneral Aviation (AV080) Neal Westlund Transportation Research Forum (TRF) Chicago Chapter Laurence F. Audenaerd Committee Participation 61 Women in Aerospace (WIA) Elida C. Smith, Board of Directors\nEmily K. Stelzer Committee Participation 63 STANDARDS COMMITTEE MEMBERSHIPS ARINC Engineering Services (AES), LLC \n(Rockwell Collins, Inc.) Airlines Electronic Engineering Committee \n(AEEC) ARINC 702A-5 Advanced Flight Management \nComputer System Standard Subcommittee\nJohn C. Gonda III Data Link (DLK) Systems Subcommittee\nDongsong Zeng Systems Architecture and Interfaces (SAI) \nSubcommittee\nJohn C. Gonda III\nWilliam A. Miller Flight Management Systems Subcommittee\nWilliam A. Miller ASTM International F38 Unmanned Aircraft Systems Francis Box\nMatthew T. DeGarmo\nR. Michael Guterres \nAndrew R. Lacher\nEdward A. Lester 64 Committee Participation European Organisation for Civil Aviation \nEquipment (EUROCAE) WG-62 GALILEO Christopher J. Hegarty International Civil Aviation Organization (ICAO) Aeronautical Communications Panel Working \nGroup I Dongsong Zeng Flight Operations Panel William A. Miller, Advisor Instrument Flight Procedures Panel (IFPP) \nIntegration Working Group William A. Miller, Advisor Navigation Systems Panel Roland O. Lejeune Leesburg Executive Airport Commission Caiolinn C. Ertel National Academy of Sciences Aviation Safety Assurance Committee Craig R. Wanke RTCA, Inc. RTCA/EUROCAE Forum on Aeronautical \nSoftware (FAS) John C. Angermayer 65 Committee Participation SC-147 Traffi c Alert & Collision Avoidance System \n(TCAS) Joseph M. Boyd\nDavid J. Elliott\nEdward A. Lester\nAndrew D. Zeitlin SC-159 Navigation Equipment Using the Global \nNavigation Satellite System (GNSS) Christopher J. Hegarty, Co-Chair\n Kevin W. Bean\nM. Bakry El-Arini \nJames P. Fernow\nRoland O. Lejeune\nMichael Tran SC-186 Automatic Dependent Surveillance-\nBroadcast (ADS-B) Randall S. Bone, WG-1 Co-Chair\n D. Stuart Bowman \n David A. Domino\nDavid J. Elliott\nStanley R. Jones\nRaphael D. Katkin\nDaniel B. Kirk\nBrock J. Lascara \nEdward A. Lester\nAnand D. Mundra\nWilliam J. Penhallegon\nStephanie A. Priess\nHans P. Stassen\nRobert C. Strain \nLesley A. Weitz 66 Committee Participation SC-206 Aeronautical Information Services and \nMeteorological Data Link Services Laurence F. Audenaerd\n J. William Carson\nIzabela L. Gheorghisor \nDouglas Havens\nBrock J. Lascara \nClark R. Lunsford\nRobert C. Strain\nDongsong Zeng SC-213 Enhanced Flight Vision Systems and \nSynthetic Vision Systems (EFVS/SVS) David A. Domino\nMitchell L. Serber SC-214 Standards for Air Traffi c Data \nCommunication Services Randall S. Bone, Tiger Team Co-Chair\nStephen L. Giles\nJohn C. Gonda III\nDaniel B. Kirk\nDongsong Zeng, Subgroup Chair SC-216 Aeronautical Systems Security John C. Angermayer SC-223 Internet Protocol Suite (IPS) and \nAeroMACS Francis Box\nIzabela L. Gheorghisor\nDongsong Zeng, Secretary 67 SC-227 Standards of Navigation Performance Michael R. Cramer\nWilliam A. Miller, WG-3 Chair SC-228 Minimum Operational Performance \nStandards for Unmanned Aircraft Systems Donald S. Arnstein\n Francis Box\n Joseph M. Boyd\nIzabela L. Gheorghisor\nLeonid Globus\nR. Michael Guterres\nEdward A. Lester\nKelly R. Markin\nKyle R. Noth\nBrian C. Patterson\nErin M. Sunshine SC-230 Airborne Weather Detection Systems Robert M. Avjian SC-233 Addressing Human Factors/Pilot Interface \nIssues for Avionics Valerie Gawron Committee Participation 69 Teaching Positions DePaul University Visiting Scholar Laurence F. Audenaerd Northwestern University Adjunct Faculty Laurence F. Audenaerd George Washington University School of \nEngineering and Applied Science National Advisory Council Andrew R. Lacher Queens University, Belfast, Northern Ireland Visiting Professor in Remotely Piloted Aircraft \nSystems David R. Maroney State University of New York at Buff alo Department of Mechanical and Aerospace \nEngineering, Faculty Advisory Board Lesley A. Weitz, Board Member ACADEMIC AND SPECIAL APPOINTMENTS 70 Courses Taught Through MITRE Aviation System Block Upgrades (ASBU) Implementation \nTraining, February 812, 2016, AEROTHAI, Bangkok, \nThailand. Decision Makers Methodology and Best Practices for \nAviation System Block Upgrades (ASBU) Implementation \nTraining, Scott L. Jacobs and Kent V. Hollinger, \nAugust 15, 2016, Singapore, Singapore Aviation \nAcademy. Safety Management Systems (SMS) Principles, \nMarch 711, 2016, July 1115, 2016, September 1216, \n2016, December 59, 2016, McLean, VA. SMS Audit, April 15, 2016, October 21, 2016, \nMcLean, VA. SMS II, April 1214, 2016, October 1820, 2016, \nMcLean, VA. SMS Principles, March 1418, 2016, ABX Air, Inc., \nWilmington, OH. SMS II, April 57, 2016, Skywest Airlines, Salt Lake \nCity, UT. SMS Audit, April 8, 2016, Skywest Airlines, Salt Lake \nCity, UT. Academic and Special Appointments 71 SMS Overview, April 1819, ASERTEC, Monterrey, \nMexico SMS Gap Analysis, June 1315, ASERTEC, Monterrey, \nMexico SMS Gap Analysis, June 17, ASERTEC, Toluca, Mexico SMS Principles,
October 1014, 2016, JetBlue, \nNew York, NY. Other Courses Taught DO-178C: Software Considerations in Airborne Systems \nand Equipment Certifi cation, John C. Angermayer and \nKent V. Hollinger, RTCA Training, March 2123, 2016, \nJune 2123, 2016, September 1921, 2016, and \nDecember 1214, 2016, RTCA, Washington, DC. runwaySimulator Training: Assembly and Execution, \nSeparations Component, Skills Evaluation, and Deep \nDive, Erin R. Catlett and Christopher G. Roberts, \nMarch and June 2016, The MITRE Corporation, \nMcLean, VA. Simulation Applications in Training, Valerie Gawron, \npresented for the Flight and Ground Vehicle Simulation \nUpdate, January 18, 2016, Binghamton University, \nBinghamton, NY. Academic and Special Appointments 72 Special Appointments Virginia Unmanned Systems Commission, \nDavid G. Hamrick, appointed by Governor Terry \nMcAuliff e. Laurence F. Audenaerd, Advisor Position: Niles West \nTownship High School, Illinois Jr Academy of Science \nFair. Awarded Best in Category for Project Designing \nWake Turbulence Avoidance Systems for Unmanned Aerial \nVehicles. Academic and Special Appointments 73 American Institute of Aeronautics & Astronautics, \nInc. Journal of Aerospace Information Systems\nCraig R. Wanke, Reviewer Journal of Air Transportation\nScott H. Mills \nGlenn F. Roberts, Associate Editor\nCraig R. Wanke, Associate Editor\nLesley A. Weitz, Reviewer Journal of Aircraft\nCraig R. Wanke, Reviewer Journal of Guidance, Control, and Dynamics\nShin-Lai Tien, Reviewer\nCraig R. Wanke, Reviewer\nLesley A. Weitz, Reviewer Air Traffi c Control Association: Air Traffi c Control \nQuarterly Glenn F. Roberts, Editorial Board\nCraig R. Wanke, Reviewer\nR. Michael Guterres, Reviewer Canadian Journal of Civil Engineering Panta Lucic, Reviewer BOOK & JOURNAL EDITORS & REVIEWERS 74 Ergonomics in Design: The Quarterly of Human \nFactors Applications Valerie Gawron, Editorial Board European Journal of Operational Research Panta Lucic, Reviewer\nCraig R. Wanke, Reviewer Global Navigation Satellite System: Technologies \nand Applications Series, Artech House Christopher J. Hegarty, Co-series Editor Institute of Electrical and Electronics Engineers Aerospace and Electronics Systems\nR. Michael Guterres, Reviewer Transactions on Aerospace and Electronic \nSystems\nYoung C. Lee, Associate Editor Transactions on Communications\n Donald S. Arnstein, Reviewer Transactions on Intelligent Transportation \nSystems\nCraig R. Wanke, Reviewer International Journal of Aviation Psychology Valerie Gawron, Domain Editor\nEmily K. Stelzer, Reviewer Journal of Aerospace Operations Shin-Lai Tien, Reviewer Journal of Navigation (Royal Institute of Navigation) Christopher J. Hegarty, Editorial Advisory Board Book and Journal Editors and Reviewers 75 Book and Journal Editors and Reviewers Journal of the Transportation Research Board Laurence F. Audenaerd, Reviewer Journal of the Transportation Research Forum Laurence F. Audenaerd, Reviewer NAVIGATION: Journal of the Institute of \nNavigation Christopher J. Hegarty, Associate Editor\nYoung C. Lee, Reviewer 77 MITREs Technology Transfer Offi ce works with staff \nmembers to ensure that the benefi ts of their innovations \nreach the largest possible user base. We share our \ninnovations with sponsoring as well as non-sponsoring \nagencies. In many situations, it benefi ts our sponsors \nto make our knowledge and intellectual property more \nreadily available to a broader audience. We do this through \npublications, open source contributions, and relationships \nwith industry and other research partners. We also transfer our technologies to commercial \norganizations when appropriate so that they can undertake \nthe technical, business, and manufacturing activities \nnecessary to bring products and services incorporating our \nintellectual property to market. As product development \nis not part of our mission, commercialization may be \nthe only viable transfer mechanism to bring commercial \nproducts that are accessible, aff ordable, and supported to \nour sponsors. Technology transfer provides government organizations \nwith new capabilities. It also helps MITRE achieve \nits mission to advance technology and return value to \nthe nations economy. Furthermore, it enhances U.S. \ncompetitiveness in the world market. TECHNOLOGY TRANSFER 78 Here is a list of recent technologies and capabilities \ndeveloped in CAASD that were transferred in 2015-2016 or \nare in the process of being transitioned currently. Technology Year Recipient AOV UAS Analyst Portal 2016 FAA eventAnalyzer 2016 FAA UAS COA Application and \nProcessing System 2016 FAA Speech Inputs to Surface \nLogic 2016 FAA En Route Controller Workload \nModel 2016 FAA Closed Runway Operation \nPrevention Device 2016 FAA Exhaust Plume Analyzer Ongoing Industry Safety Culture Survey Data \nVisualizer Ongoing Industry TARGETS Ongoing FAA and Industry Runway Simulator Ongoing FAA and Industry Threaded Track Data Fusion \nAlgorithms Ongoing FAA Concept Maturity Framework Ongoing FAA Technology Transfer 81 Index of Contributors Ahmadi, Saam 5 Andrews, Cheryl R. 54, 60 Angermayer, John C. 64, 66, 71 Arnstein, Donald S. 12, 67, 74 Audenaerd, Laurence F. 10, 60, 66, 69, 72, 75 Avjian, Robert M. 45, 67 Balakrishna, Mahesh 22 Bateman, Hilton 8, 17, 18, 24, 39 Bean, Kevin W. 65 Becher, Thomas A. 22, 26, 47 Benito, R. Patrick 11 Berry Jr., Thomas P. 3 Blucher, Michelle J. 44 Boesel, Justin R. 42 Bolczak, Catherine N. 29 Bone, Randall S. 12, 23, 29, 36, 38, 65, 66 Bowman, D. Stuart 14, 65 Box, Francis 12, 14, 63, 66, 67 Boyd, Joseph M. 65, 67 Braff , Ronald 47 Breunig, Jeff rey L. 28 Bromberg, Emily P. 32, 33 Brown, Daniel T. 18, 21, 25 Burns, Kevin J. 18 Carson, J. William 38, 66 Catlett, Erin R. 41, 71 Chanen, David 17, 39 Chang, Eric B. 41 Chen, Shuo 24, 39, 46 Chong, Ronald S. 24, 39, 46 Conroy, John 18, 22 82 Cooper Jr., Wayne W. 14, 24 Cramer, Michael R. 55, 67 Crane, Michael L. 42 Croft, Cheryl A. 10 Danner, Heather L. 41 DeArmon, James S. 17, 18, 22, 24 DeGarmo, Matthew T. 63 DeSenti, Christopher T. 15, 56 Devlin, Christopher J. 41 Diff enderfer, Paul A. 5, 44 Dobbs, Miyoun L. (Mimi) 8 Domino, David A. 57, 65, 66 Duquette, Michelle A. 42 El-Arini, M. Bakry 65 Elliott, David J. 14, 37, 65 Ertel, Caiolinn C. 64 Esmaeilzadeh, Ehsan 14, 59 Estes, Steven L. 18, 19, 23, 35 Exum, Monique 44 Feerrar, Wallace N. 7, 32 Fernow, James P. 65 Flynn, Robert C. 14 Fremberg, Michael J. 43 Fronzak, Matthew J. 8, 10, 14, 21, 22, 45, 54 Fulmer, Dean E. 4, 8, 10 Gathings, Leigh T. 33 Gawron, Valerie 8, 9, 19, 21, 28, 47, 57, 67, 71, 74 Gaydos, Travis L. 5, 17 Gheorghisor, Izabela L. 12, 66, 67 Giles, Stephen L. 66 Globus, Leonid 12, 14, 67 Gonda III, John C. 5, 27, 32, 36, 40, 47, 55, 63, 66 Goodwin, Hugh G. 11 Gouldey, David 44 83 Guensch, Craig A. 24 Guterres, R. Michael 11, 63, 67, 73, 74 Hamrick, David G. 7, 9, 28, 56, 72 Harback, Katherine T. 3, 16, 25, 59 Harper, Michelle L. 33 Havens, Douglas 39, 66 Hegarty, Christopher J. 9, 21, 47, 59, 64, 65, 74, 75 Heitin, Simon H. 18 Hekl, Robert A. 58 Helleberg, John R. 5, 18, 19, 35 Hoff man, Jonathan H. 10, 12, 26 Hollinger, Kent V. 35, 70, 71 Hudak, II, Thomas B. 45 Huhn, John J. 15, 45 Huleatt, Ryan W. 32, 33 Jacobs, Scott L. 70 Jones, Cherlynn M. 43 Jones, Stanley R. 11, 55, 56, 65 Katkin, Raphael D. 65 Kelley, Devon B. 44 Killian, Bruce E. 54 Kirk, Daniel B. 65, 66 Kirkman, Deborah A. 10, 56, 58 Klinker, Michael L. 9 Kuchenbrod, John A. 7, 24 Kurtz, Mariet S. 12, 13 Lacher, Andrew R. 8, 9, 10, 11, 12, 15, 16, 18, 24, 29, 31, 32, 47, 53, \n54, 56, 63, 69 Lakshminarayan, Vinay 12 Lamiano, Dean F. 11 Lascara, Brock J. 24, 38, 65, 66 Lascara, Jessica R. 33 Lee, Young C. 54, 74, 75 Lejeune, Roland O. 64, 65 84 Lester, Edward A. 28, 30, 63, 65, 67 Liggan, Michael E. 11 Link, Wesley B. 47 Long, Kevin M. 5, 12, 18, 35 Lucic, Panta 73, 74 Lunsford, Clark R. 59, 66 MacWilliams, Paul V. 37, 41 Mahashabde, Anuja A. 60 Markin, Kelly R. 46, 59, 67 Maroney, David R. 4, 7, 8, 47, 53, 69 Martin, Shane L. 18, 25 Masek, Tudor 22, 24, 25, 40 Massimini, Patricia Abel 56 Massimini, Sebastian V. 11, 27, 47 Matthews, Amanda S. 45 Mayer, Ralf H. 26, 27, 47 McCollum, Marlis 3, 4, 5 McCourt, Sean F. 8, 55, 58 McGarry Peterson, Kathleen A. 3, 30, 37, 57 McKnight, Claudia V. 14, 21 McLachlan, Jennifer A. 19 McMahon, Matthew T. 46 Mendolia, Andrew S. 37 Miller, William A. 55, 56, 63, 64, 67 Mills, Scott H. 57, 73 Mittelman, Jeff rey P. 20, 55, 58 Molin, Douglas L. 8, 10, 59 Mondoloni, Stephane L. 22, 30, 47, 53 Morgan, Constance E. 15, 45 Mundra, Anand D. 65 Mwendwa, Eugene A. 41, 43 Nelson, Gregory M. 21 Nene, Vilas 46 Niles, Frederick A. 28 85 Noth, Kyle R. 67 Pan, Grant 43 Patterson, Brian C. 28, 30, 56, 58, 67 Penhallegon, William J. 23, 29, 65 Pinto, Avinash 11 Polk, John R. 43 Pollack, Matthew E. 5, 17, 18, 25 Porter, Suzanne 44 Priess, Stephanie A. 19, 25, 65 Rammelsberg, Kurt 28, 29, 45 Reinhart, Jason A. 42 Richkus, Jacob 24, 39, 41, 46 Roberts, Christopher G. 41, 71 Roberts, Glenn F. 9, 15, 47, 53, 73 Robinson, Michael 22, 45, 54 Roessner, Stanley J. 42 Ryals, Lillian Z. 3, 16, 25, 31, 35, 43, 53, 58, 59 Sawyer, Dennis A. 59 Schrader, Phillip D. 14 Schwartz, Jonathan L.
13, 19, 20, 25, 40 Sekhavat-Tafti, Siroos 11 Semanek, Jon L. 13, 19, 20 Serber, Mitchell L. 57, 66 Sgorcea, Roland M. 22, 32, 33 Shahidi, Hassan 9, 56 Smith, Elida C. 3, 10, 42, 61 Smith, Marcus 20, 59, 60 Snow, Richard E. 14 Spencer, Thomas L. 27 Srivastava, Amal 9, 28, 29 Staley, Amanda M. 11, 29 Stanley, Raymond 44 Stassen, Hans P. 25, 29, 65 St. Clair, Thomas J. 29 86 Stein, Jeff rey L. 5, 15, 17, 18 Stelzer, Emily K. 4, 24, 39, 46, 56, 57, 61, 74 Strain, Robert C. 11, 65, 66 Subowo, Nadya K. 11 Subramanian, Prakash 41 Sunshine, Erin M. 67 Swedish, William J. 45 Symionow, William L. 22 Tao, Zheng 13, 19, 20, 25, 29, 40, 55 Tarakan, Robert M. 27 Taylor, Christine P. 23, 31, 54 Teixeira, Christopher M. 5 Thomas, Mark D. 5 Tien, Shin-Lai 17, 31, 45, 73, 74 Toms, David L. 37 Tran, Michael 57, 58, 65 Tsao, Simon 3 Tungul, Samantha L. 41 Tuomey, David M. 46 Vargo, Erik P. 23, 32, 33 Veoni, Joseph M. 7 Verma, Anuja 30, 40, 43, 56 Walsh, Edward B. 5, 33, 41 Wang, Ganghuai 13, 19, 20, 25, 40 Wanke, Craig R. 9, 23, 31, 46, 47, 56, 64, 73, 74 Weitz, Lesley A. 3, 5, 8, 17, 19, 23, 24, 25, 35, 37, 47, 54, 65, 69, 73 Wells, Michael T. 59 Welman, Stephen K. 3 Westlund, Neal 60 Williams, Ashley G. 13, 19, 20 Wynnyk, Mitchel 13, 35, 37 Zeitlin, Andrew D. 47, 65 Zeng, Dongsong 5, 27, 32, 36, 40, 55, 63, 64, 66 Zimmerman, Roberta L. 19 87 PHOTO LEGEND\nBack interior cover includes photos of CAASD staff \nparticipating in various conferences, meetings, \nshowcases, and industry events over the course of \n2016. front and inside front cover.pdf\n Slide Number 1\n Slide Number 2\n Slide Number 3\n Slide Number 4 back and inside back cover.pdf\n Slide Number 1\n Slide Number 2\n Slide Number 3\n Slide Number 4 ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-1598. Harnessing Data to Get Ahead of a Public Health Crisis (an interview with Jaya Tripathi) Routine visits to the pharmacy took on new meaningpersonally and professionallyfor MITRE's Jaya Tripathi in 2010. The analytics expert was helping a family member recover from a skiing accident and had to pick up the same pain medication every week for almost two months. \"The medication was a controlled substance, so the pharmacy was required to fill the prescription weekly instead of monthly,\" Tripathi says. \"This law was unfamiliar to me.\" The experience inspired Tripathi to pursue a new research focus: fraud and abuse of prescription painkillers. Specifically, she wanted to better connect the dots among prescribers, pharmacists, and patients. Tripathi was already familiar with the Prescription Drug Monitoring Program (PDMP), a system U.S. states use to track where, when, and in what dosages controlled substances are dispensed. She realized that PDMP data had untapped potential. \"Descriptive analytics were being employed on PDMP data already but I wanted to employ advanced techniques like predictive analytics to align with prevention and intervention,\" she says. \"When certain classes of drugs are combined with opioids, for example, it creates a very dangerous cocktail. Tracking the dispensing of this drug combination could help save lives.\" In 2014, 50,000 people died from a drug overdose of which more than half involved opioids, the class of euphoria-inducing drugs that includes heroin and a host of powerful, legal pain relievers. Tripathi, a data analytics scientist, knew there was a way to apply big data techniques to help stem this public-health crisis. Working with a MITRE team with expertise in areas such as health IT, geo-spatial analytics and graph analytics, Tripathi developed the Fraud Investigator's Analytic Tool, or FIAT. The web-based prototype is an actionable tool that identifies \"potentially bad\" prescribers. It's built around a core model that is designed to work with standard prescription data elements. It can generate graphs and a risk score, showing spikes in doses or red flags in prescription combinations, prescriptions filled in multiple locations, and more. \"We can create heat maps to show hot spots of prescription drug activity,\" Tripathi explains. \"These had not been used before to track dangerous drug combinations.\" She has presented her work at events such as Healthcare Information and Management Systems Society, the giant health IT conference. The state of Indiana is piloting FIAT while Tripathi and her colleagues continue to refine the tool. In researching prescription drug abuse, Tripathi noticed people buying and selling drugs anonymously using digital and virtual currencies. That led her to another area of study: the cryptocurrency economy. Tripathi has explored ways these currencies can facilitate criminal activity. Information Sharing for Solutions Opportunities to collaborate and explore different sets of challenges are two of the main factors keeping Tripathi at MITRE. \"I appreciate that you can reach out to colleagues with a vast array of expertise in many different domains,\" says Tripathi, who joined MITRE in 2004 on the recommendation of MITRE employee she met https://www.mitre.org/publications/project-stories/arming-doctors-and-pharmacists-with-data-the-us-takes-on-a-drug-epidemic\nhttps://www.mitre.org/centers/cms-alliances-to-modernize-healthcare/where-we-focus/health-it\nhttps://www.mitre.org/centers/homeland-security-systems-engineering-and-development-institute/where-we-focus/mature-the\nhttps://www.mitre.org/news/in-the-news/mitre-investigator-advanced-analytics-can-help-predict-fight-opioid-abuse\nhttps://www.mitre.org/news/in-the-news/mitre-investigator-advanced-analytics-can-help-predict-fight-opioid-abuse Approved for Public Release; Distribution Unlimited: 17-1598. in a leadership course. \"And I've never seen anything like our innovation program. It fosters creativity and originality,\" she says of the company's internal research and development program. Early on, Tripathi worked on the back-end processes of MITRE's internal infrastructure systems. She helped create the research and phonebook features of the company's award-winning intranet. When she wanted to turn to more sponsor-facing work, she moved to a different MITRE operating center and began working on new challenges, including telehealth, social media analysis, patient consent, and physician credentialing. A Thirst for Information A love of learning is a theme in Tripathi's life. \"As a student, I would take copious notes on things that interested me,\" says Tripathi, who grew up in Delhi, India. \"I'd go to the British Council Library and the American Library and study beyond my coursework. I researched things like photovoltaics, just for fun. I was an avid reader and represented my high school and college for quiz competitions.\" Tripathi's interest turned to quantum mechanics and then particle physics in graduate school at the University of Texas. She later worked for several multinational corporations, including the airline industry and a major telecommunications company. \"One interesting project was predicting customer churn,\" says Tripathi. \"Back then, processing two million records was a big deal. We needed expensive equipment and software to do analytics on the data. Now I can easily process 12 million records on my laptop.\" Enjoying the Balance \"I think the work-life balance at MITRE makes employees happier,\" Tripathi says. \"When you like your work, it's no longer a job. You do it because you love it.\" Tripathi has had several mentors along her career path, but she counts her mother and grandmother as significant role models. \"The women in my family have inspired me the most,\" she says. \"They faced challenges growing up in an India that was under British rule, and made many sacrifices. My mom had to end her career abruptly and was always happy that her daughters were able to continue their careers while raising their families.\" by Karina Wright https://www.mitre.org/research/overview\nhttps://www.mitre.org/publications/project-stories/mitre-intranet-still-making-history-20-years-later Harnessing Data to Get Ahead of a Public Health Crisis (an interview with Jaya Tripathi) ",
    "text": " Integrating Arriva Management with Procedure Design and Analysis American Institute of Aeronautics and Astronautics 1 Integrating Arrival Management with Procedure Design and \nAnalysis Roland Sgorcea, Michael Bush and Ryan Huleatt \nThe MITRE Corporation, McLean, VA, 22102, U.S.A Trajectory-Based Operations (TBO) is a fundamental component of the International Civil \nAviation Organization (ICAO) Global ATM Operational Concept and is envisioned to enable \nglobally consistent performance based 4D trajectory management. TBO will enhance \nplanning, execution and efficiency of flights, reducing potential conflicts and resolving \nupcoming network and system demand/capacity imbalances early. To achieve this, the \nimplementation of TBO will involve increased use of trajectory prediction, scheduling \nDecision Support Tools (DSTs) and improved methods for trajectory management to improve \nthe capacity and efficiency. This will in turn lead to increased utilization and dependence on \nautomation, which relies on a complex adaptation structure that defines how the DST should \nbe operated in a specific air traffic control facility airspace. At the same time, Performance \nBased Navigation (PBN) enabled arrival procedures that also have the objective to enable \nefficient arrival operations via the use of optimized routes are being developed and deployed. \nAlthough the arrival management DSTs are viewed as a key enabler for increased PBN usage, \nthe processes and tools that are associated with the arrival management DSTs adaptation \ndesign remains largely disjoint from the airspace and procedure design activities. The \nresearch presented here discusses the design, development and potential application of an \nintegrated procedure and arrival management DST adaptation design and evaluation tool that \nhas been under development by the MITRE Corporations Center for Advanced Aviation \nSystem Development (CAASD). It is envisioned that the research and the resulting capability \npresented here will enable combined airspace and arrival management design and will \nfacilitate more streamlined design and analysis of both airspace and arrival management \nconfiguration components. The utilization of these capabilities is expected to contribute to the \nTBO goal by enabling the creation of airspace designs that supports higher throughput and \nmore efficient flows for terminal and en-route operations. Nomenclature \n4D = Four Dimensional \nACM = Adjacent Center Metering \nADMT = Amount of Maximum Delay Time \nANSP = Air Navigation Service Provider \nARTCC = Air Route Traffic Control Center \nATC = Air Traffic Control \nATM = Air Traffic Management \nCAASD = Center for Advanced Aviation System Development \nCOTS = Commercial Off-the-Shelf \nCOMPAS = Computer Oriented Metering, Planning and Advisory System \nCSV = Comma Separated Variable \nCTAS = Center-TRACON Automation System \nDLR = German Aerospace Research Establishment \nDP = Dynamic Planner \nDST = Decision Support Tool \nEDC = En-route Departure Capability \nETA = Estimated Time of Arrival \nFAF = Final Approach Fix Approved for Public Release: 17-1704.\nCopyright has been transferred to another party. Reuse is restricted. Contact the Contracts department for guidance. American Institute of Aeronautics and Astronautics 2 GIM-S = Ground Interval Management-Spacing \nGUI = Graphical User Interface \nHITL = Human-in-the-loop \nIAP = Instrument Approach Procedure \nICD = Interface Control Document \nIFR = Instrument Flight Rules \nMAESTRO = Means to Aid Expedition and Sequencing of Traffic with Research of Optimization \nMIT = Miles-in-Trail \nMRP = Metering Reference Point \nNAS = National Airspace System \nNASA = National Aeronautics and Space Administration \nOPD = Optimized Profile Descent \nPAR = Preferred Arrival Route \nPBN = Performance Based Navigation \nPGUI = Plan-View Graphical User Interface \nPHX = Phoenix International Airport \nRA = Route Analyzer \nRNAV = Area Navigation \nRMD = Route Maximum Delay \nRNP = Required Navigation Performance \nSESAR = Single European Sky ATM Research \nSTA = Scheduled Time of Arrival \nSTAR = Standard Terminal Arrival Route \nTARGETS = Terminal Area Route Generation, Evaluation, and Traffic Simulation \nTBFM = Time-Based Flow Management \nTBO = Trajectory Based Operations \nTGUI = Timeline Graphical User Interface \nTRACON = Terminal Radar Approach Control Facility \nTMA = Traffic Management Advisor \nTMC = Traffic Management Coordinator \nTS = Trajectory Synthesizer \nTSAS = Terminal Sequencing and Spacing \nVFR = Visual Flight Rules I. Introduction\nir Navigation Service Providers (ANSPs), are making strategic investments to transform their operations in order \nto better meet the increased demand for Air Traffic Control (ATC) services and to also provide increased efficiencies for users and service providers. One of the major transformations in this domain, that is expected to occur \nover the next decade, is a shift from current flight plan based operations towards 4D Trajectory Based Operations \n(TBO). TBO is a fundamental part of the ICAO Global ATM Operational Concept and consists of several new \nprocesses and procedures which will enable ANSPs to safely accommodate significantly increased traffic, while still \nproviding world class safety, efficiency, and the ability to accommodate user preferences. It is envisioned that TBO \nwill be applied to all phases of flight: en-route, oceanic, and arrival/approach /departure airspace, as well as some \nsurface operations. In the United States, the NextGen program proposes TBO as one of the main mechanisms for \nmanaging traffic in highdensity or high-complexity airspace [1]. \n The implementation of the TBO concept and vision is dependent on several enabling technologies (ground and \nflight deck based capabilities), route infrastructure (i.e., Performance Based Navigation (PBN) procedures and routes) \nas well as changes to existing policy and procedures that are a key to this transition. At the foundational level, ANSPs \nhave deployed numerous PBN procedures and routes throughout their airspace, and aviation stakeholders have already \nstarted to realize benefits. However, full utilization of PBN will only be achieved after full integration between PBN \nand ground based air traffic management decision support tools (DSTs); achieving this tightly coupled integration is \nfoundational to ultimately achieving TBO. In the United States, arrival management is being provided by using the time-based scheduling and management \nDSTs which are enabled by the Time-Based Flow Management (TBFM) system. Use of time-based scheduling and \nmanagement in the arrival management domain has been demonstrated to be more effective than other traffic A American Institute of Aeronautics and Astronautics 3 management initiatives (e.g., miles-in-trail restrictions) and it has been demonstrated to provide increased \npredictability, smoother flows, and better use of airport capacity [12,13]. On one hand, time-based scheduling and management DSTs are becoming increasingly available to better manage \narrival flows and to meet the available airport capacity while minimizing controller interventions. On the other hand, \nPBN-enabled procedures that also have the objective to enable efficient arrival operations via the use of optimized \nroutes are being developed. However, the processes and tools that are associated with the development of the two \nremains largely disjoint. It would thus be desirable to be able to design PBN airspace and procedures while considering \nthe use of time-based scheduling and management, inclusive of DST use. More specifically, there are currently limited \ncapabilities and tools available that allow airspace and procedure designers to evaluate and account for the implications \nof using TBFM as part of an airspace redesign. Similarly, when defining the time-based metering operation design \nand supporting adaptation in the TBFM system, it is challenging to fully account for the effects of PBN, especially \nwhen new PBN airspace or procedures are anticipated; this may result in operational interoperability gaps not \nenvisioned by either effort. \n The current process of ensuring interoperability between PBN procedure design and time-based scheduling and \nmanagement entails an iterative process of performing the PBN/Airspace design, adapting that design into the TBFM \nsystem, making refinements to the TBFM adaptation and settings, and performing Human in the Loop (HITL) \nsimulations in a laboratory environment to validate the full operational design. While this approach has been \nsuccessfully used, it is time and resource intensive. This process requires multiple iterations before an operationally \nacceptable balance is achieved and can result in multiple changes to the design of airspace, procedures, and TBFM \nsystem adaptation and settings. Furthermore, any revisions to PBN procedures needed post-implementation (to update \nthem per the sites operational needs) have the potential to inadvertently introduce interoperability gaps since there \nare no field capabilities currently available to procedure design specialists to holistically evaluate TBFM adaptation \nand PBN design decisions to ensure they are harmonized. \n The paper begins by describing the evolution of arrival time based metering, procedure development, and their \nrelationship to the overall TBO goals. Next, the need along with a preliminary concept of operations for an integrated \nprocedure design and arrival management (i.e. TBFM) adaptation design and evaluation tool are discussed. This is \nfollowed by a detailed description of the architecture and functional components of the proposed capability. Finally, \na set of example applications intended to cover the types of analyses that can be performed are presented. II. Research Background \n The research presented in this paper has roots in both the arrival management as well as airspace and procedure \ndevelopment domains. Arrival management tools consist of ground-based planning tools with the purpose of assisting \nthe controller in guiding aircraft, ensuring the safe, efficient, and economic flow of inbound traffic into an Air Route \nTraffic Control Centers (ARTCC), Terminal Radar Approach Control Facilities (TRACON), and airport. The tools, \nhowever, depend on a complex set of static and dynamic site-adapted data containing site specific
parameters and \nlogic that can impact the arrival management tool (i.e., general airspace, routing, runways, or scheduling constraints). \nThe airspace and associated procedures (i.e. PBN enabled Standard Terminal Arrival Routes (STARs) or Instrument \nApproach Procedures (IAPs)) also play a key role in the adaptation and in turn the operational success of the arrival \nmanagement DST. This section provides an overview of the current and upcoming generation arrival management technologies along \nwith the associated processes that are currently in place for adapting the tools and for creating the published arrival \nprocedures. A. Arrival Management and Time Based Metering \nAs previously indicated, in the United States, arrival management is being provided through the use of arrival time-based scheduling and management DSTs, which are enabled by the TBFM system. Time-based scheduling (aka. \nmetering) of arrival flows is not a new concept in air traffic management. The original concept of metering goes \nback to at least the mid 1970s with the development of the En Route Metering (ERM) program. The ERM program \n(1970s-80s) was based on a simple concept of proactively spacing out the flights in en-route based on projected \ndemand to avoid excessive holding and vectoring near the destination airport and was deployed as part of the en-route \nautomation system. The second-generation metering tool was an evolution of the ERM system into the first national \nmetering program called Arrival Sequencing Program (ASP) (1980s-90s) which started to introduce low fidelity \naircraft trajectory prediction calculations as part of the scheduling. American Institute of Aeronautics and Astronautics 4 The current generation TBFM system, which is based on the National Aeronautics and Space Administration \n(NASA) Traffic Management Advisor (TMA) system, is the third generation of time-based metering tools. TMA was \na component of the CenterTRACON Automation System (CTAS), a suite of air traffic management tools developed \nat NASA Ames Research Center [6]. The system was technology transferred to the Federal Aviation Administration \n(FAA) and was first deployed in the early 2000s. The TMA system continued to expand and evolve. In 2003 the \nAdjacent Center Metering (ACM) capability was developed which allowed multiple en-route systems to provide input \nto TMA, effectively removing center boundaries for traffic management purposes. In 2006 the En-route departure \n(EDC) capability was added which extended the metering concept to managing departures. By August 2007, TMA \nwas deployed at all ARTCCs in the United States. TMA evolved into what is now called TBFM, which included a \ncomplete re-architecture and modernization of the technology. Recent enhancements to TBFM include the addition of \ncoupled and extended metering capabilities which increase the operational range of TBFM as well as meet time speed \nadvisories which controllers can utilize to achieve TBFM generated schedules. In addition to the current generation TBFM technologies, there are currently plans to implement an emerging \ntechnology that enhances TBFM, which is called the Terminal Sequencing and Spacing (TSAS) capability developed \nby NASA [15]. TSAS enhances TBFM to apply time-based metering operations in the terminal environment with the \nobjective of reducing tactical decision-making related to aircraft sequencing and spacing, and to enable mixed \nequipage use of both curved-path PBN procedures (i.e., procedures that contain Radius to Fix (RF) legs) as well as \nmore traditional PBN and RNAV procedures (i.e., procedures that only contain Track to Fix (TF) legs). TSAS achieves \nthese objectives by providing terminal airspace merging and spacing tools that are used for time-based metering \noperations. \nFigure 1. Evolution of Arrival Management Decision Support Tools. \n As indicated in Figure 1, with each evolution starting from the original ERM/ASP metering programs to current \ngeneration TMA/TBFM technologies and moving towards planned next generation technologies [14], theres a shift \nto more precise trajectory prediction and scheduling methodologies which in turn rely on increasing congruence \nbetween the arrival management DST adaptation and published procedure conformance. Although this paper focuses on arrival management tools in the U.S. (i.e. TBFM) and its evolution under the Next \nGeneration Air Transportation System (NextGen) program, prevalent use of arrival management technologies also \nexists in Europe as well as emerging use in Asia. Unlike in the U.S., Europe has a variety of arrival management tools \navailable with different levels of functionality [16]. However, some arrival management DSTs that are currently in \noperation, such as the Means to Aid Expedition and Sequencing of Traffic with Research of Optimization \n(MAESTRO) built by the French Centre d'Etudes de la Navigation Aerienne [8] and the Computer Oriented \nMetering, Planning and Advisory System (COMPAS) build by German Aerospace Research Establishment (DLR) \n[9], have a similar foundation and origin as the TMA/TBFM system first proposed by the NASA Ames Research \nCenter [7]. Given that they are undergoing a similar evolution as TBFM under the umbrella European Single European \nSky ATM Research (SESAR) [2] program, it is expected that many of the concepts and elements presented here could \nbe translated to those systems as well. B. PBN Procedure Development \nPerformance Based Navigation (PBN) comprises Area Navigation (RNAV) and Required Navigation Performance (RNP) and describes an aircrafts ability to navigate using performance standards. RNAV enables aircraft to fly on \nany desired flight path within the coverage of ground or space-based navigation aids. RNP is RNAV with the addition \nof an onboard performance monitoring and alerting capability. A defining characteristic of RNP operations is the \nability of the aircraft navigation system to monitor the navigation performance it achieves and inform the crew if the \nrequirement is not met during an operation. Based on the FAA PBN National Airspace System (NAS) Navigation \nStrategy, by 2030, PBN procedures and flexible routing will be the standard method of navigation throughout the NAS \nduring normal operating conditions. Utilization of PBN procedures is expected to be greatly enabled using advanced \nDSTs that will need to be tightly integrated [4]. American Institute of Aeronautics and Astronautics 5 The process for developing and implementing PBN procedures in the NAS is well-documented in the PBN \nDevelopment \nPreliminary Activities, Development Work, Operational Preparations, Implementation, and Post-Implementation \nMonitoring and Evaluation [3]. \nFigure 2. PBN Development & Implementation Process [3] The PBN Development & Implementation Process focuses on performing upfront work to determine whether the \nproject should be undertaken including achieving consensus from the Regional Airspace & Procedures Team (RAPT) \nprior to starting development. Following these preliminary activities, development and preparatory work is conducted \nprior to implementation. Lastly, post-implementation analysis is performed to capture any implementation issues that \narose and lessons learned for future projects. This process has been successfully applied to many PBN projects in \nrecent years throughout the NAS. When following the PBN Development and Implementation processes, various tools are employed to support the \nteams in executing their work. The primary tool for PBN procedure design is the FAAs capability called Terminal \nArea Route Generation, Evaluation, and Traffic Simulation (TARGETS). TARGETS provides a common platform \nthat enables procedure designers to leverage various navigation data sources to develop PBN procedures, evaluate \nthose procedures against the latest FAA design criteria, and to evaluate the flyability of a design utilizing aircraft \nperformance models. TARGETS also generates the required documentation required for operational preparations prior \nto implementing the new or modified procedure. Depending upon the extent of the change to a PBN procedure or if the procedure is part of a larger redesign effort, \nHuman-in-the-loop (HITL) simulations may be utilized to evaluate the procedures in various operational scenarios. \nThese operational scenarios are evaluated in real-time with air traffic controllers to elicit feedback on the suitability \nof the new operations. The HITL assessments lead to design refinements based on the perceived operational suitability, \nmaking HITL simulations a critically important tool for larger PBN redesign projects where the impact of the design \nchanges may not be well understood. C. TBFM Adaptation Process \nIntegration of PBN procedure design and TBFM adapted metering design is considered critical to the implementation of TBO. The current PBN/TBFM system design and adaptation process can take several months and \nthere are limited tools available to design teams to help with this process. Existing TBFM adaptation tools do not \neffectively support concurrent visualization/modification of procedures and TBFM adaptation elements, or enable \nassessment of the impact of proposed designs on flight operations. Compared to PBN, TBFM adaptation development and implementation processes are not as standardized or fully \ndocumented. The TBFM system requires that facility adaptation be developed and maintained to ensure desired \nperformance is achieved and that the adaptation is consistent with the local operations. The development and \nmaintenance activities are performed when new procedures are implemented, existing procedures are changed, or \nTBFM system performance changes are desired. The TBFM adaptation data consists of many hundreds of distinct \nfiles which use a complex syntax to specify the TBFM adaptation elements defined in the TBFM Interface Control \nDocument (ICD) [10]. Changes are made using careful configuration management practices and are applied on top of \na baseline representing the current TBFM adaptation at a facility. The adaptation is modified manually by editing the \nfile, or set of files, requiring a change to work with the operational TBFM system. Evaluation tools are used to analyze \nadaptation files for syntax
and logic errors following manual modification. Validation of the changes is performed by American Institute of Aeronautics and Astronautics 6 loading the newly updated adaptation into the Plan-View Graphical User Interface (PGUI) and the Timeline Graphical \nUser Interface (TGUI) and overlaying live traffic, which represents how the adaptation will be viewed by the TMCs \nwhen using the operational TBFM system. Following this validation, the changes are reviewed to ensure impacts to \nadjacent facilities and other potential operational issues are considered prior to implementation. When changing TBFM adaptation for a new or modified PBN procedure design, nominal interior routes are defined \nfor each runway configuration and aircraft type. These routes consist of a lateral path, as well as speed and altitude \nrestrictions based on published STARS, published approaches, and SOPs for the facility. The accurate definition of \nthese nominal interior routes is critical to enabling the TBFM system to produce Estimated Time of Arrival (ETAs) \nand Scheduled Time of Arrival (STAs) that are realistic and aligned with the anticipated traffic loads for the airport. \nWhile some upcoming capabilities (e.g., TSAS) will provide improved definitions of interior routes as well as PBN \nroutes, not all routes that are currently published will fully address all discontinuities that currently exist between \nSTARs and IAPs. This will require TBFM adaptation designers to address these discontinuities based on making \ninformed data driven decisions. III. Integrated Design Capability Needs Analysis \nFollowing the survey of current processes and tools for conducting PBN and TBFM adaptation design, the research consisted of a needs analysis to help derive the requirements for the envisioned integrated procedure design and arrival \nmanagement DST adaptation design and evaluation tool, referred to as the integrated design capability from here \non. Since the operational deployment of TBFM, many PBN projects have needed to consider TBFM adaptation \nparameters and configurations to ensure interoperability gaps are not present. However, the existing process for PBN \ndesign and implementation does not explicitly account for adapting the PBN designs in TBFM adaptation. \nAdditionally, TBFM can often be considered late in the procedure implementation process and result in rework to \nensure compatibility with the sites TBFM adaptation and that desired benefits are being realized. The groups \nexecuting this work today are not ignoring the interdependence of these two key concepts, but the lack of defined \nprocesses introduces the risk of inconsistent methods and inefficiency on the path to achieving the desired operational \nbenefits. This highlights a need for a standardized integrated PBN and TBFM design process (refer to Figure 3) to \nhelp ensure that the goals of NextGen and the PBN NAS strategy can be realized. \nFigure 3. Current and Desired PBN and DST Design Process In addition to the process shortfalls discussed above, the Needs Analysis focused on the current tools used to \nperform PBN and TBFM design. One identified tool shortfall is that limited capabilities exist for assessing PBN and \nTBFM performance during design activities. The primary method currently used to assess the performance of PBN \nand TBFM operations prior to implementation is conducting HITL simulations. HITL simulations help validate the \noperational acceptance of new procedures by including stakeholders, such as air traffic controllers and TMCs, in the \nevaluations while also helping validate the successful integration of these procedures into the TBFM site adaptation. \nHowever, conducting HITL simulations is a complex, resource intensive activity that may not be feasible for every \nintegrated design activity being conducted. When HITL simulations are not feasible, there is a gap in the existing \ncapabilities to assess the performance of PBN and TBFM operations. American Institute of Aeronautics and Astronautics 7 In design projects where HITL simulations are utilized, projects may still benefit from upfront PBN and TBFM \ndesign analyses to help identify a set of most promising candidate designs to model during HITL simulations. \nExamples of PBN and TBFM analyses that would benefit from integrated design include methods of quantifying delay \nand identifying problematic areas in TBFM site adaptation, iterative analysis where arrival rates and delay distribution \nparameters are adjusted to better achieve performance objectives, and assessing common PBN flight efficiency \nmeasures, such as optimized profile descent (OPD) compliance, level-offs, and fuel burn when TBFM is being used. \nPresently, these types of analyses are performed using data collected from HITL simulations or during post-\nimplementation analysis to evaluate the success of the development and implementation activities. Having greater \ninsight into how the new operations would perform earlier in the design process may help improve the final designs \nand save time and rework compared to the current processes being employed. Another shortfall observed is that the TBFM adaptation can be complex and cumbersome to work with. This \nchallenge is largely attributed to the structure of the adaptation and that many changes require the modification of \nmore than one file, increasing the likelihood for human error. Additionally, it can be difficult to interpret the contents \nof site adaptation as the PGUI and TGUI displays are the only methods of visualizing this data. Adaptation details \nregarding different site configurations and underlying scheduling parameters are not easily accessible using current \nmethods, requiring designers to retrieve this information from the adaptation files themselves. The combination of a \ncomplex structure and limited tools for visualization requires designers to employ an iterative process that can be error \nprone and resource intensive. IV. Concept for an Integrated Design Capability \nThe Integrated Design Capability is a software system intended for users supporting PBN and TBFM development and implementation activities for the FAA. A needs analysis has shown that current processes and tools are not \nsufficient to support integrated PBN and TBFM design. The intended user groups for the system are responsible for \nsuccessfully implementing operational changes to achieve desired performance benefits at sites throughout the NAS. \nThe concept of integrating PBN and TBFM design elements is emerging and, therefore; a new system is envisioned \nto satisfy the evolving needs and applications. The envisioned system will be capable of ingesting TBFM adaptation data and depicting geo-referenced adaptation \nelements and the underlying data parameters to the user. The system will also support access and visualization of \nnavigation data sources, as well as, PBN data elements sufficient to model operational scenarios throughout the NAS. \nThe combination of the TBFM adaptation and PBN navigation data within a single system will enable integrated \ndesign applications (refer to Figure 4). With PBN and TBFM data available to the system, scenario generation capabilities will support a variety of \nmodeling functions. Users will generate operational scenarios to help explore the performance of proposed PBN and \nTBFM designs. Given a scenario, TBFM scheduling algorithms will be used to provide insight into how the \noperational TBFM system will respond to the modeled traffic. A schedule will produce ETAs and STAs for each flight \nat key points within the TBFM adaptation and designed route structures. These times will enable the computation of \ndemand and delay-based metrics to provide insight into how TBFM may perform under the modeled configuration \nand traffic scenario. \nFigure 4. Integrated PBN & DST Design Concept The envisioned systems capabilities will support a broad set of applications for the users supporting PBN and \nTBFM development and implementation activities. The system may be used to perform pre-implementation analysis American Institute of Aeronautics and Astronautics 8 by analyzing the current TBFM and PBN infrastructure at a site and evaluating scenarios using historical traffic \ninformation to identify areas for improvement. Once a design project is undertaken, the system will support iterative \ndesign and analysis to help achieve desired performance measures. The result of iterative design activities will inform \nthe scenarios and configurations evaluated during HITL simulations, which will further refine the designs for review \nand potential buy-in from stakeholders. Lastly, the system will support post-implementation analysis where simulated \ntraffic along the newly implemented procedures and site adaptation are compared against the desired operational \noutcomes envisioned during the design phase. V. Integrated Time Based Metering Design Capability \nOptimization of aircraft arrival schedules has been the subject of numerous studies in the past, however, there is no comprehensive analysis tool that accounts for both the design of the airspace procedures as well as the arrival \nmanagement scheduling logic. The research and resulting capability presented as part of this work aims to provide a \nmeans for performing both airspace procedure design as well as account for the arrival management (i.e., TBFM) \ndesign as part of an integrated, lightweight design environment. To accomplish this goal, a set of initial design \nrequirements has been identified. These requirements were based on information collected during a study of current \nprocesses and tools used to conduct procedure development, TBFM adaptation development, and the results of the \nneeds analysis. The requirements are meant to address the shortfalls observed in that study and to help realize the \nenvisioned system described in the preliminary Concept of Operations (Section IV). The requirements were then used \nto inform the software design and were organized into the following areas: Adaptation Visualization & Modification \nThe adaptation visualization requirements focus on the key areas identified in the needs analysis related to
\nthe accessibility of adaptation data elements. These requirements include visualization and modification of \nTBFM adaptation elements as well as the underlying TBFM configuration parameters that are commonly \nmodified when adapting a TBFM site. Modeling & Simulation \nThe modeling and simulation requirements focus on the key areas identified in the needs analysis related to \nthe evaluation of candidate operational scenarios to gain insight into the operational performance of design \nchanges. These requirements focus on functional areas including scenario generation, scheduling, and \ntrajectory modeling. Analysis & Reporting \nThe analysis and reporting requirements focus on the key areas identified in the needs analysis related to the \nperformance evaluation of generated scenarios. Additionally, reporting requirements are included for \nsupporting the TBFM adaptation file modifications workflows needed to prepare adaptation for use in the \noperational TBFM system. A. Functional Components \nThe proposed capability consists of three main components adaptation data model with associated parsers, aircraft trajectory modeling (i.e., route analyzer / trajectory synthesizer), and the scheduler. These components \nenable the four main functions of the capability adaptation visualization and modification, scenario generation, \nscheduling, and metrics generation. Table 1 describes the mapping between the requirement categories, the \nprototype components, and the prototype functions. Table 1. Mapping between Requirements, Components, and Prototype Functions. Requirement Category Components Functions Adaptation Visualization & \nModification Data Model & Parsers Adaptation Visualization & \nModification Modeling & Simulation Route Analyzer & Trajectory \nSynthesizer Scenario Generation Scheduler Scheduler Analysis & Reporting Metrics Generation American Institute of Aeronautics and Astronautics 9 B. Software Architecture \nA modular software architecture was created to organize the capabilitys functionality into reusable blocks with clear responsibilities. The foundation of the prototype is a data model to describe the key logical elements of a \nTBFM adaptation. A separate module was developed to parse the text data files and create the objects described in \nthe data model informed by specific adaptation data. To simulate TBFM functions, separate modules were created \nfor the trajectory modeling and scheduling functions. Finally, user interfaces were built on top of these foundational \ncomponents to enable the functions which begin to satisfy the identified requirements. This modular approach enables future research to use some or all the components as needed, as well as \nfacilitating subsequent replacement or independent improvement of the individual capabilities. Figure 5 provides a \nhigh-level overview of the flow of information through the integrated design capability and the components which \nsupport the primary functions. \nFigure 5. Overview of Prototype Functions & Components. C. TBFM Adaptation Data Model \n A key function of the integrated TBFM design capability is the ability to view and evaluate an existing TBFM \nadaptation. The existing TBFM adaptation data consists of a set of text files organized in a complex structure with \nmany interdependencies between the different files. Because no existing tools were found that can extract the data \nfrom the TBFM adaptation file structure, the initial work focused on this area. A data model was implemented as a Java software library to describe the components of a TBFM adaptation. \nAlong with the data model, a set of parsers was created to build that data model from standard text files in a TBFM \nadaptation. The data model is the set of concepts and objects that are described by the data in the TBFM adaptation, \nand how those objects relate to each other. With a defined data model, other software that uses TBFM data can be \nmore easily be written. That data model can be populated with data read from disk or constructed on the fly. The \nelements of the data model can be altered by software to produce hypothetical changes to a TBFM adaptation without \nneeding to modify the adaptation files. The scope of the data model and parser components was, for initial efforts, limited to process only a subset of all \nTBFM adaptation parameters. The focus of the research thus far has been to support simulation and modeling of \nTBFM adapted routes, scheduling parameters (e.g., super stream and wake vortex separation requirements) and TBFM \nconfiguration data to best emulate the operational TBFM system as part of the design environment. Therefore, the \nrange of supported data elements and parsed files includes the set needed to support those capabilities. A sample subset \nof the resulting internal TBFM adaptation data model is shown in Figure 6. These elements are shown for illustration \npurposes only as well as to demonstrate how the TBFM adaptation text file structure was translated into a relational American Institute of Aeronautics and Astronautics 10 software data model. The actual model used contains significantly more elements, as such its entirety could not be \nincluded in this paper. \nFigure 6. Example TBFM Data Model Elements. (Subset) D. Visualization and Editing \nOnce the underlying TBFM adaptation data can parsed and made available as part of a software data model, the focus of the research shifted to adding functionality to visualize and modify the data. Since TARGETS is an existing \ncapability commonly used for procedure development (see Section II. B.), the decision was made to add a plugin to \nTARGETS to enable the visualization and evaluation of TBFM Adaptation in support of this research. TARGETS is \nan FAA Enterprise capability in use by FAA facilities and industry partners to perform a wide variety of design and \nanalysis activities. The software architecture of TARGETS provides a plugin model where additional capabilities can \nbe added to TARGETS dynamically. The software prototype, described herein, included the development of a \nTARGETS plugin which leverages the parsing, data modeling, and modeled TBFM scheduling functions. These \ncapabilities also exist on their own and could be integrated into tools other than TARGETS. However, TARGETS \nlarge user community and existing infrastructure makes it an appealing first integration goal for a research software \ncapability. Figure 7 depicts the TARGETS plan view after importing TBFM adaptation at Albuquerque ARTCC and \nPhoenix International Airport (PHX). Several of the key elements described in a TBFM adaptation can be \nrepresented in a map view. This enables users to quickly visualize the placement of TBFM adaptation elements such \nas arcs, freeze horizons, waypoints, and route segments which can highlight different issues with the underlying \nadaptation data. However, there are many additional critical properties, values, and relationships in the TBFM data \nthat are not easily visualized in a map view. An example is the weighting terms used to decide between runways, or \nthe separation matrix data associated with a flow. The applications we envision for the integrated design capability \noften require a user to iterate on, or at least interrogate, the data model to learn about some of these parameters \nduring an experiment. Therefore, the prototype also includes several graphical user interfaces (GUIs) to allow the \nuser to drill down into the TBFM data and examine, and in many cases change, the parameters of various elements \nand functions. American Institute of Aeronautics and Astronautics 11 \nFigure 7. TARGETS prototype with visualized TBFM adaptation E. Trajectory Modeling \nTBFM performs decision support functions using controlled airspace adaptation and the modeling of aircraft located in that volume. Two of the key functions in that modeling process are the Route Analyzer (RA) and Trajectory \nSynthesizer (TS) [5]. These components are required to be emulated because they enable scenario generation \ncapabilities to help evaluate how aircraft are expected to operate when flying along TBFM adapted routes. The RA is responsible for evaluating an aircrafts intended path and trajectory based on properties like the aircraft \ntype, the filed flight plan, the aircrafts current position, altitude, and speed. The evaluation results are an enumeration \nof the possible paths that the aircraft may be directed to take to an active runway at the arrival airport. Some airport \nconfigurations and route definitions can offer several options for an aircraft. These different route options are passed \nto the second module, the TS, which is used to execute a simulation of the aircrafts performance along each route. \nThis simulation produces ETAs at various key points along the route, including outer arc crossings, meter fix \ncrossings, final approach fix (FAF) crossings, and arrival at the runway threshold. In operational TBFM applications, RA and TS are functions are part of the TBFM architecture. The integrated \ndesign capability developed in this research is independent from any production TBFM source code or deployed \nfunctionality. Instead, simplified models of TBFMs functions were built using the data model discussed in previous \nsections. The simplified RA used data elements from the adaptation data model to inform several aspects of its operation. \nThis included the specification of various speed and altitude constraints along various routes. The starting point for \nthe modeled RA was an aircraft from a scenario (discussed in section V.G). An aircraft was specified by an en route \nprocedure segment, an aircraft identifier, an engine type, a wake vortex category, and a set of initial conditions. The \nprocedure segment that was associated with the aircraft was one that had been defined in the TBFM adaptation data \nand truncated at a meter fix. Any data along the procedure segment after the meter fix was discarded. Given
an airport \nconfiguration, the adaptation data defined one or more routes that could be taken from the meter fix down to a runway. \nThese segments will be referred to as TRACON routes. An aircraft in a scenario will have only one en route segment, \nbut can have many TRACON routes associated with it. The RA cannot yet know which TRACON route will be used, \nand therefore calculates and supplies information about each available option to the scheduler component, which \nmakes the final determination. The simplified model of TS is a simplified average behavior, fast time model of an aircraft, which has reasonable \nagreement with higher fidelity simulations under nominal operating conditions. The model assumes perfect lateral \nconformance and instantaneous turns. It propagates and calculates constraint data along the route, carrying forward \npreviously defined constraints until the route data defines new constraints. The constraints are used to generate vertical \nand speed profiles, which are then convolved to form a set of true speeds. The model also supports wind model data American Institute of Aeronautics and Astronautics 12 and produces average ground speeds over each segment of the route. Segment distances are used to calculate transit \ntimes over each segment, and transit times are aggregated to form ETAs at each point along the route. While simple, \nthe approach calculates values that are reasonably close to the results of more sophisticated models. Using a route \nwith a varied speed and vertical profile, the ground speed can be calculated along the route in both the simplified TS \nmodel and in a more sophisticated simulation model. This is shown for a sample route in Figure 8. The simplified TS \nmodel overestimates the speed during the final approach but otherwise has good agreement. Future iterations of this \ncapability will investigate a higher fidelity model for the TS component. \nFigure 8. Comparison of TS simplified model to a more sophisticated integrative model F. Scheduling \nOnce aircraft estimates are available from the Trajectory Modeling component, TBFM performs its core function: scheduling aircraft airport arrivals. The TBFM schedulers goal is to maximize airport landing and \nTRACON handling capacity without compromising safety or exceeding configuration constraints. The main functions that the TBFM scheduler performs consist of sequencing, scheduling and allocating runways \nfor arriving aircraft. As part of the scheduling process, Traffic Management Coordinators may input to the scheduler \na series of different scheduling constraints that reflect the operational and environmental conditions of the airspace. \nUnder these constraints, the scheduler uses the trajectory predictions data to derive individual aircraft schedules that \nhelp ensure an orderly, efficient, and conflict-free flow of traffic into the terminal area. The resulting schedules are \nin turn provided to controllers for implementation. Commonly used scheduling constraints are pre-stored as part of \npre-determined configurations that can be loaded as needed, however, TMCs may also make manual \nmodifications to those constraints. In the operational TBFM application, the Dynamic Planner (DP) function contains all the scheduling logic \nmentioned previously [11]. Like the RA and TS models (see previous section), we have implemented a simplified \nmodel of the TBFM scheduling function using the adaptation data model. This independent scheduling \nimplementation takes in ETA data (as provided by the RA and TS models) and produces STA data in a fashion \nsimilar to the actual TBFM scheduler, using as much as possible the data supplied by an actual, parsed, TBFM \nadaptation. The simplified Scheduler utilizes many of the same scheduling constructs that the TBFM DP does. The \nmain artifacts used by the simplified scheduler are summarized as follows: Meter Fix: A waypoint, which is at a distance from the destination airport, at which full scheduling \n(constraint application and deconfliction) is performed by the scheduler Meter Point: A waypoint at which the scheduler, in EDC mode will perform full scheduling (constraint \napplication and deconfliction). Gate: An arrival corridor, normally associated with the TRACON boundary, which may include one or \nmore arrival routes or meter fixes, primarily used for arrival traffic. American Institute of Aeronautics and Astronautics 13 Airport Configuration: Determines the airport arrival runways that are in use, flight landing rules \n(Instrument Flight Rules (IFR) or Visual Flight Rules (VFR)), internal TRACON routing and scheduling \nrules specific to this configuration Stream class: A group of aircraft sharing similar scheduling characteristics based on engine type (jet or \nturbo-prop/prop) and meter fix. A stream class can also be defined by aircraft category (heavy, large, etc.). Super stream classes: A grouping of stream classes. Every stream class will be included in one super \nstream class though several stream classes may be placed in the same super stream class. Freeze Horizon: The location at which an aircrafts STA becomes frozen. The aircraft is then transferred \nfrom the schedulable list to the frozen list. This is also the point that the last runway allocation is made and \nthe slot is assigned to this arrival. Scheduled Time of Arrival (STA): Refers to the desired time that an aircraft should cross a certain point \n(runway threshold or meter fix). It considers other arrival traffic and airspace configuration. It is calculated \nusing parameters like spacing, aircraft performance, and winds. Amount of Maximum Delay Time (AMDT): Represents the maximum amount of delay that can be \nabsorbed within an airspace (i.e. TRACON). Excess delay is fed back upstream. Route Maximum Delay (RMD): Represents the maximum amount of delay that a specific TRACON route \ncan absorb. In terms of the scheduling constraints that are supported by the simplified Scheduler, the core supported \nscheduling constraints consist of the Super Stream Class Miles-In-Trail (MIT), separation constraints that are \napplied at the meter fix, and the Wake Vortex Separation constraints that are applied at the runway or Final \nApproach Fix. These are by far the most commonly used scheduling features of TBFM. Acceptance rates are all \nassumed to be set to unrestricted as this feature is not commonly used operationally. The specific algorithm that the simplified Scheduler implements is depicted in Figure 9 and consists of \ndistributing delay between the upstream Meter Fix schedule and the downstream Runway schedule. First, a \ndeconflicted schedule at the meter fix is built by ensuring that the Center Scheduling restrictions (i.e., Super Stream \nClass MIT Separation) is not violated. Then based on that deconflicted meter fix schedule, a runway schedule is \nbuilt by ensuring that the TRACON Scheduling restrictions (i.e., Wake Vortex Separation) are not violated and that \nthe lower of the AMDT or RMD values is not exceeded. The process repeats until a solution that meets all \nconstraints is found. The algorithm is based on The Dynamic Planner: The Sequencer, Scheduler, and Runway \nAllocator for Air Traffic Control Automation (Wong, 2000) [11] and mirrors the main scheduling mode of TBFM, \nscheduling mode 8, which is executed every 6 seconds in the TBFM operational system. American Institute of Aeronautics and Astronautics 14 \nFigure 9. Core TBFM Simplified Scheduler Logic G. Scenario Generation \nTo evaluate an existing TBFM adaptation, a user first must specify a set of aircraft to occupy the adaptation airspace. That set of aircraft is referred to as a scenario. Each aircraft in the scenario is defined by an engine type, a \nwake vortex category (as defined in the adaptation data), an en route procedure segment, an initial time, altitude, and \nairspeed, and an aircraft identifier. For the purposes of this research, the aircraft are assumed to start at the beginning \nof a known en route procedure segment which can be selected from one of the imported TBFM Preferred Arrival \nRoutes (PARs) or STARs defined in the adaptation. The scenario follows the single airport, single TRACON concept, in that all aircraft in a scenario are assumed to \nbe arriving at the same airport, and only those PARs and STARs that are listed for that airport are eligible for the \nscenario. The scenario is not, however, tied to a particular airport configuration, as the configuration changes the American Institute of Aeronautics and Astronautics 15 interior TRACON routes that are utilized. When constructing a scenario, the user can filter the full set of PARs and \nSTARs down to a more manageable set by hiding unwanted routes in the integrated design capability. There are several options that the prototype offers for building a scenario. Scenarios can be imported in a \nsimplified comma separated variable (CSV) format, where each row in the import file describes a single aircraft in \nthe scenario and provides the name of a route that is available in the adaptation. A scenario can also be exported in \nthe same format. This can be used to generate a base scenario which can then be modified, manually or in other \ntools, before being reimported. Aircraft can also be added and deleted in the user interface manually, one at a time. \nAircraft in a scenario can also be edited manually in the table user interface for the scenario. As an alternative, scenario aircraft can also be generated from track data in the integrated design capability. \nAircraft trajectories, whether from recorded radar data or simulations, are projected against the set of selected PARs \nand
STARs to find the best matching route for the track. The aircraft identity, engine type, and wake vortex category \nare inferred from the aircraft type associated with the track data and the initial conditions for the aircraft are taken \nfrom the point that is closest to the starting point of the selected route. Finally, scenarios can be generated randomly using a set of parameters (refer to Figure 10). The primary drivers \nare the scenarios total duration, the desired demand in aircraft per hour, and a noise value. For each of the routes \navailable to the scenario, an estimated flight time is calculated. The reciprocal of the demand rate is used to specify \nan aircraft arrival interval. Random arrival times are calculated by generating a uniform random value in the range \nof plus or minus half the noise value, and adding that to the arrival interval time. The aircraft is assigned a route \nbased on a load balance specified by the user, and the estimated flight time is subtracted from the randomly \ngenerated arrival time to generate the aircrafts start time. \nFigure 10. Creating a Random TBFM Scenario. H. Metrics and Reporting \nOnce one or more scenarios are defined, the user evaluates a specific scenario by running it through the trajectory modeling and scheduling functions using a set of unmodified or modified TBFM adaptations. Normally, \nTBFM operates in a continuous process, where the information that is available to the scheduler changes over time, \nand the aircraft in the schedule are updating estimates based on operational constraints and decisions made by pilots \nand controllers, which means that TBFM is constantly producing updated schedules based on the most recent \ninformation it has. For speed and simplicity, the integrated design capability runs only once, given the initial state \nof the scenario, and produces a conflict-free schedule at all the scheduling Metering Reference Points (MRPs). American Institute of Aeronautics and Astronautics 16 The scheduled arrival of all the aircraft is then displayed to the user in a timeline view, which resembles the \nTGUI from the operational TBFM system (refer to Figure 11). The timeline view is zoom-able and pan-able \nallowing the user to explore the full range of times in the schedule. ETAs at a point of interest are shown to the left \nof the timeline, and STAs to the same point are shown to the right of the timeline. If the STA is later than the ETA, \nthe aircraft identifier and timestamp are rendered with a delay annotation. The timeline starts by displaying the \narrival runways, but the user can add additional timelines for other scheduled points of interest, eliminate timelines, \nand sort them. Several other scheduling delay metrics including various histogram views, waypoint delay, and \nsegment level delays are available. Visualizations are provided to allow the user to explore the schedule and delay \ndata set from these various perspectives, and examine both averages and histogram distributions of delay for \ndifferent areas of the adaptation. \nFigure 11. Example TBFM Scheduling Results Analysis VI. Use Cases and Applications \nAs part of the development of the integrated design capability, an agile development approach was utilized. This approach included the development team gathering several user stories from the domain subject matter experts that \nare familiar with the PBN and TBFM design space. These user stories consisted of short, simple descriptions of desired \nfeatures and applications of the prototype from the perspective of the users. This section discusses some example \napplications that were derived based on the user stories and they describe how the prototype can be used to support \nvarious analyses that are typically needed as part of PBN and TBFM design activities. The example applications \nreferenced here are not intended to cover all the types of analyses that could be performed as part of an integrated \ndesign activity. Given the functional nature by which the prototype has been designed, a wide variety of analyses can \nbe conducted ranging from adaptation visualization, parameter modifications, and scenarios based simulations. The following applications were explored in our research to demonstrate how the integrated design capability could \nsupport PBN and TBFM design activities: Adaptation Analysis: Application is focused on the analysis of an existing TBFM adaptation through the \nvisualization and exploration of the supported integrated design capability components. Nominal Interior Routes Analysis: Application is focused on analysis of the TBFM nominal interior \nTRACON routes through the supported integrated design capability components and existing TARGETS \nfeatures for radar track data analysis. Delay Distribution Analysis: Application is focused on the functionality available to inform questions \nregarding TBFM delay distribution, specifically to determine what settings should be used to provide a \nconsistent flow of aircraft into TRACON airspace without adversely impacting throughput. Adaptation Change Analysis: Application is focused on the functionality available to analyze \nmodifications to an adaptation. Specifically, focusing on analyzing a baseline TBFM adaptation that was \nmodified to support an new STAR procedure. American Institute of Aeronautics and Astronautics 17 Ground Interval Management-Spacing (GIM-S) Implementation Comparative Analysis: Application \nis focused on viewing and better understanding the comparative impact of adding GIM-S (e.g. extended \nmetering) to an arrival stream. GIM-S Design Optimization: Application is focused on comparing an existing GIM-S design against a \nmodified GIM-S design to determine the optimization impacts to delay allocation. Stream Class Setting Evaluation: Application is focused on evaluating stream class settings which enable \ndelivery of sufficient aircraft to the TRACON without causing excessive low-altitude vectoring. \nThe following describes one of the example applications of the integrated design capability, which involves determining the appropriate values for TBFM adaptation parameters that are frequently modified when adapting a \nsite, more specifically the parameters used for delay distribution. The explored parameters are the AMDT values in \nthe adaptation, which represent the maximum delay that can be absorbed within the performance characteristics of a \nlarge set of aircraft types on the trajectory between two assigned metering reference point segments. There are two \ntypes of delay distribution AMDT parameters that can be adjusted: Upstream AMDT parameters: Parameters used only to distribute delay between existing outer arcs as \nwell as between outer arcs and runways. These parameters do not affect the aircraft sequencing and spacing \nthat the TBFM simplified scheduler produces. Downstream AMDT parameters: Parameters used to specify how much delay can be absorbed within the \nTRACON (i.e. downstream from the meter fix). These can be specified based on the individual meter fix to \nrunway route via the RMD parameter and/or through a generic TRACON AMDT parameter. The example application analyzes the upstream AMDT parameters based on the same TBFM adaptation model \nthat was described previously. The analyst first generates scenario aircraft from track data that was obtained from a \nrecorded radar data source and the scenario is then selected for evaluation. In this case, the analyst selects the \nscenario based on representative PHX imported arrival tracks. Following the evaluation, the analyst is presented \nwith the timeline view and can add additional metering reference points of interest which, in this case, consist of the \nGEELA and SQUEZ meter fixes as well as PHX8 and PHX7R runway threshold metering points. The timeline \nallows the analyst to evaluate the specific aircraft sequencing and aircraft specific delay that has been allocated at \nthe points of interest. In addition to the aircraft-specific information available through the timeline view, the analyst \ncan analyze the results in more detail. In this case, the analyst examines first the aggregate delay by arrival gate and \ndetermines that the scheduler has allocated the SUNSS gate an average of 39 seconds of delay while the other gates \nhave been allocated an average delay of about 10 seconds. Finally, to better understand how delay impacts the specific meter fixes, the analyst can choose to view the non-\naggregate and aggregate average delay organized by arrival meter fix. In this case the non-aggregate delays which \naccount for the delay that was absorbed at upstream meter fixes is selected and the analyst determines that the \nscheduler has allocated the SQUEZ meter fix an average of 45 seconds of delay while the other meter fixes have \nbeen allocated a delay of under 10 seconds. Based on these results, the analyst determines that the sector that meters to the SQUEZ meter fix experiences \nhigher average delays then the sectors feeding BRUSR, HOMRR, and PAYNT; the other arrival gates. While these \nexact delay amounts occur because of the specific traffic scenario that was evaluated, it was discovered that the \nTBFM adaptation parameter pertaining to the distribution of delay between the SQUEZ meter fix and the associated \nouter arc was to set to 1 minute, compared to the other meter fixes that had a 0 minute AMDT parameter value on \nthe first outer arc segment. Due to this realization, the analyst decides to set the SUN/OA/J outer arc parameters to 0 \nminutes as well, thus pushing the delay assigned to Jet aircraft to upstream sectors, outer arcs, and meter points. The \nscenario was re-evaluated using the new adaptation parameter value and comparative results are shown in Figure 12. \nAs indicated, this adaptation
change reduced the average delay that needs to be absorbed at SQUEZ to under 5 \nseconds, while not affecting the other meter fixes. This change thus allowed for more equitable delay to be absorbed \nby the various arrival meter fix sectors. American Institute of Aeronautics and Astronautics 18 \nFigure 12. Scenario Scheduler Output Before (Top) and After (Bottom) \nWhile this application demonstrated one of the delay distribution analyses the integrated design capability can support, it was not meant to be exhaustive. The analyst together with operational experts are expected to work \ntogether to determine what changes can be made as well as to determine other aspects of adaptation development \nincluding operational suitability of the proposed changes. VII. Conclusion \n A description of the design, development and, potential application of an integrated procedure and arrival management (i.e. TBFM) design tool that has been under development by MITRE CAASD was presented. The \nresearch focused on identifying and understanding the current processes and tools used in designing and evaluating \nTBFM and PBN designs, identifying the shortfalls of these current processes and tools, defining requirements for a \ncapability to help address the identified shortfalls, and prototyping software capabilities based on these requirements. The resulting prototype provides TBFM adaptation visualization and modification, scenario generation, scheduling, \nand delay-based analysis functions. The prototype capabilities were described and potential applications were American Institute of Aeronautics and Astronautics 19 presented to demonstrate how the developed prototype could be used for PBN and TBFM design and analysis activities \nas well as how it could help enable the operational integration of TBFM into the NAS. It is envisioned that the research and the resulting capability presented here will enable combined airspace and \narrival management design and will facilitate more streamlined design and analysis of both airspace and arrival \nmanagement configuration components. The utilization of these capabilities is expected to contribute to the TBO goal \nby enabling the creation of airspace designs to enable higher throughput and more efficient flows for terminal and en-\nroute operations. Continuing research in this area will focus on enhancing this capability to support emerging arrival management \ncapabilities, such as TSAS, as well as improving the overall user workflow, associated processes, and usability of the \nproposed integrated design capability. References 1Joint Planning and Development Office: Concept of Operations for the Next Generation Air Transportation System, Version \n2.0, June 2007. 2Single European Sky ATM Research, European ATM Master Plan: The Roadmap for Delivering High Performing Aviation \nfor Europe. 2015 Edition. 3Federal Aviation Administration, Air Traffic Organization Policy Performance Based Navigation Implementation Process, \nOrder 7100.41, April 3, 2014. 4Federal Aviation Administration, Performance Based Navigation (PBN) NAS Navigation Strategy, 2016. \n5Slattery, Rhonda and Yipan Zhao, June 1995, En-Route Descent Trajectory Synthesis for Air Traffic Control Automation, Proceedings of the American Control Conference, NASA Ames Research Center, Moffett Field, CA. \n6Erzberger, Heinz and William Nedell, June 1989, Design of Automated System for Management of Arrival Traffic, National Aeronautics and Space Administration Ames Research Center Moffett Field, CA. \n7Nedell, William, Heinz Erzberger and Frank Neuman, April 1990, The Traffic Management Advisor, National Aeronautics and Space Administration Ames Research Center Moffett Field, CA. \n8Garcia, Jean-Louis, 1990, MAESTRO A Metering and Spacing Tool, Proceedings of the American Control Conference, Centre d'Etudes de la Navigation Aerienne, Orly France, \n9Volckers, U., 1990, Arrival Planning and Sequencing with COMPAS-OP at the Frankfurt ATC-Center, Proceedings of the American Control Conference, German Aerospace Research Establishment, Braunschweig, Germany. \n10Time Based Flow Management (TBFM) System Release t4.3.0 Adaptation Interface Control Document (ICD), Lockheed Martin Corporation, Rockville, MD, September 2014. \n11Wong, Gregory L., The Dynamic Planner: The Sequencer, Scheduler, and Runway Allocator for Air Traffic Control Automation, NASA Ames Research Center, Moffett Field, CA, April 2000. \n12Bush, Michael G., Juan Amezcua, and Thomas A. Becher, 2015, Demonstration Prototype for Designing Performance Based Navigation (PBN) Procedures with Time Based Flow Management (TBFM), F073-B15-015, The MITRE Corporation, McLean, \nVA. 13Bush, Michael G., Ryan Huleatt, and Roland Sgorcea, 2016, PBN Application Studies Applying Airport Active Flows and \nDevelopment of Capabilities to Support Design Optimization and Integration, The MITRE Corporation, McLean, VA. 14Marc Narkus-Kramer, \"(briefing) Concept of Operations for the Next Generation Air Transportation System,\" The MITRE \nCorporation, 2006. 15Swenson, Harry and Chen Liang \"Air Traffic Management Technology Demonstration 1 (ATD-1), NASAs ATM \nTechnology Demonstration #1 (ATD-1) Overview\" NASA Ames Research Center, Moffett Field, CA, 2013. 16Eurocontrol: AMAN Status Review, Edition 0.1, December 2010. Approved for Public Release: 17-1704. Distribution Unlimited. 2017 The MITRE Corporation. All Rights Reserved. Integrating Arrival Management with Procedure Design and Analysis\n Nomenclature\n I. Introduction\n II. Research Background\n A. Arrival Management and Time Based Metering\n B. PBN Procedure Development\n C. TBFM Adaptation Process III. Integrated Design Capability Needs Analysis\n IV. Concept for an Integrated Design Capability\n V. Integrated Time Based Metering Design Capability\n Adaptation Visualization & Modification\n A. Functional Components\n B. Software Architecture\n C. TBFM Adaptation Data Model\n D. Visualization and Editing\n E. Trajectory Modeling\n F. Scheduling\n G. Scenario Generation\n H. Metrics and Reporting VI. Use Cases and Applications\n VII. Conclusion\n References ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-1999. How to Spark Effective Conversations on Cybersecurity, Policy, and Mission May 24, 2017 Are we getting cybersecurity right? As a cybersecurity professional, I often wonder as we advise concerned agency executives on the many thousands or even millions of dollars they will need to invest in security measures to be secure. Many times, this advice is based on a short paragraph description of the mission or service, plucked from reams of documentation driven by organizational and government policy requirements such as cyber risk assessments or security plans. Some of these policy requirements have provided excuses for IT/security executives, mission executives, and even policy experts to avoid basic conversations; the process has stolen the conversation. As with other aspects of the policy and technology gap, we must look beyond what is required by policy and what can be achieved by technology to ground both in a comprehensive understanding of the organizations mission and balancing cost. Neither policy requirements nor security exists to hinder missions, yet both do when applied blindly. As such, the gaps between policy and technology can be felt most keenly when mission leaders and security professionals fail to come together in the spirit of getting something done with unity. We can increase the effectiveness of security measures with an effective conversation about the mission, policy implications, and security. After all, policy and security exist to assist in securing missions while ensuring that civil liberties and other legal and policy constraints are met. Do You Have the Right People in the Room? Having an effective conversation means first having the right people in the room. The people who need to be in this conversation are those who have the authority to make final decisions for the mission. And the more senior the participants, the better, ideally including mission executives such as program leads or mission directors. The security professionals involved in the conversation must be senior enough to approve or be responsible for the security for that service, such as a CISO or IT executive. These cybersecurity executives must understand the relevant national and local policies applicable to the mission or bring in the policy experts who can provide that insight; international missions may additionally require treaty and international agreement expertise. For those executives on all sides of the conversation who dont think they have the time for it, I ask, would you have the time if this 15-minute conversation could save you millions of dollars? Or possibly prevent an embarrassing cyber event? Or significantly increase the effectiveness of the mission? Having these conversations also builds trust and cooperation among IT executives, policy experts, and mission executives, which is necessary to truly secure missions. Approved for Public Release; Distribution Unlimited: 17-1999. Do You Understand the Mission First? Once the right participants are in the room, the person to provide information first is the mission executive. And, this is tough, but the role of the cybersecurity executive is to listen and seek understanding, without thinking about all the security to be recommended; trust me, I must even stop myself on this one. We need to ask ourselves questions, including what about the mission is valuable to you as a mission executive? The richer the picture the mission executive can paint, the better. For example, if my mission is to provide weather maps to military troops in combat, I would want accurate and rapidly available maps; Im picturing a soldier pulling out a smartphone, and the weather map is just there and ready. From a security perspective, its probably not going to be helpful if the military combatant must log in to the application to find out if its cold enough to sustain ice with bullets zinging; likewise, privacy is probably not a top concern. The point is that the security needs to be flexible and designed in context of a mission and environment. Are You Seeking to Be Understood? We all do it. We have our own languages or jargon specific to what we do for a living; we develop a short-hand way of communicating among our peers to convey complex ideas quickly, and we (usually) understand each other. We sometimes use language as a barrier, indirectly implying that what we do is too complex to be questioned, or we substitute buzzwords for deep thought. Cybersecurity jargon and its cousin, policy jargon, are infamous for their ability to bedazzle and overwhelm those not accustomed to this speak. The fastest way to clear a room at a party is to start talking about polymorphic encryption and its benefits as a security control for obfuscating personally identifiable information (two bits of jargon in the same sentence!). By the same token, we cannot underestimate the ability to befuddle others with mission-specific jargon. Even today I wonder what a competency-based approach to organizational efficacy means (if you know, please dont explain). As you enter these conversations, you need to be aware of our collective predilection for our own comfortable jargon and make a deliberate effort to speak in more universal terms, understandable to those in other disciplines. In the end, we all want the same thinga secure mission. Is the Proposed Security Reasonable? Also important is how much the mission is worth to protect. For example, if an application is developed for a mission that minimally impacts a few people, and costs a few hundred dollars and will be used by very few people for two weeks then discarded, it probably doesnt make sense to spend millions of dollars securing it. Discussing the worst-case scenario if the mission fails is very informative for understanding how much security is enough. For example, if human lives would be lost if the application is not available, you might spend extra money for redundancy. Likewise, if the temporary application used for two weeks Approved for Public Release; Distribution Unlimited: 17-1999. provides basic accounting that humans can do if the application is not available, maybe redundancy is not worth the expense. In addition, mission executives and cybersecurity executives may have differing perspectives, so you cannot make assumptions. For example, as a mission executive, maybe I plan to use a photo editor application that specializes in identifying edges of objects precisely to locate cancer cells of a patient remotely. If only the fact that this is a photo editor application specializing in edges is discussed, it may get lost that the lack of precision can be a matter of life or death. In this case, security measures may augment ensuring the accuracy. Extreme examples of consequences to make the point that mission worth and impact of mission loss are important to include in this conversation. The Shared Mindset Can Improve Security The goal of having these effective conversations is to develop a shared mindset among mission executives, cybersecurity executives, and policy experts. Successfully securing missions requires trust and cooperation among these decision makers. The more we cultivate a shared mindset, working together with transparency and common goals, the greater the likelihood we will spend the right amount of money and achieve the right level of security for the mission. About Kathryn Knerler Kathryn Knerler is a seasoned cybersecurity leader at the MITRE Corporation with 25 years of experience in cyber security network defense and threat intelligence. Her experience spans program management, leading organizational transitions and growth of cyber operations. She is currently advising senior executives in effective cybersecurity strategies, including authoring agency cyber security strategies and threat intelligence. How to Spark Effective Conversations on Cybersecurity, Policy, and Mission\n Do You Have the Right People in the Room?\n Do You Understand the Mission First?\n Are You Seeking to Be Understood?\n Is the Proposed Security Reasonable?\n The Shared Mindset Can Improve Security\n The Shared Mindset Can Improve Security ",
    "text": " () Project Story for www.mitre.org. Approved for Public Release; Distribution Unlimited: 17-1991. Technology that Spots What Humans Might Miss in a Crowd Security cameras in public places are commonplace, but they don't always prevent disturbances. MITRE researchers are exploring how a fusion of soft biometrics, audio, and other data from video feeds may help analysts detect and avert public threats. Whether you're shopping at the mall, cheering on the hometown team at a large sporting event, or in line at the airport, you know they're theresecurity cameras. \"Even in a location as benign as a parking garage, there are so many surveillance cameras capturing images at various angles that a person in a control room can only monitor so much before losing sensitivity,\" says Chongeun Lee, a MITRE engineer who specializes in biometrics. \"It's easy to miss something critical among all the information flowing in.\" Lee is the principal investigator on the \"LinkBioMan\" technology project, which is part of MITRE's internal research program. A team of researchers is contributing their expertise in video analytics, biometrics, machine learning, human language technology, and computational auditory perception to create sensors that can spot anomalies on video. By flagging unusual activities especially at large public gatheringsthe sensors can help humans act to prevent a crisis or respond promptly after the crisis. The key is to not just identify objects of interest or obvious concerns; but also, patterns of behavior that are both security and safety concerns and predict the most critical issues. Each response is costly and the balance with necessary privacy concerns is critical to this research. \"Our idea is when something abnormal happens, an alert is triggered so personnel on duty can act quickly,\" Lee says. [Blank page belowdelete.] https://www.mitre.org/publications/project-stories/new-advances-in-biometrics-research-move-beyond-the-csi-effect\nhttps://www.mitre.org/research/overview Project Story for www.mitre.org. Unusual Behaviors: Making the [Automated] Connection Surprisingly, most mainstream video security technology lacks sound, color, or both. Think of the grainy, silent, black-and-white images often replayed on television news reports. While today's video can solve small, specific problems, it doesn't effectively fuse visuals with audio and other sensor data. \"The color and audio technology found in social media video offers great clues,\" Lee says. \"The sounds of glass breaking, sirens, or gunshots might indicate civil disturbance.\" Therefore, the team makes use of selected cellphone videos of incidents, posted by individuals online, as data for training and testing. The LinkBioMan system is being designed with an ability to conduct fusion on real-time monitoring feeds and to apply the same algorithms for forensics purposes on pre-recorded video, regardless of the method of capturing. This type of \"smart video\" isn't normally available to security and law enforcement personnel until after an incident occurs. (MITRE conducts research in that area as well.) Sound is just one analytic in LinkBioMan, whose formal project title is \"Linking Soft Biometrics to Semantic Description of an Event.\" The MITRE team is going beyond audio. They're also applying machine learning to algorithms they developed that create a semantic linkage meaning a contextual understandingof the relationship between people, activities, objects, and environments. Training to Recognize a Link A good example of this type of technological understanding is a scenario where a group of children are playing on railroad tracks. Normally, children playing is a harmless activity, but the implication of their locationrailroad tracksis ominous. https://www.mitre.org/publications/project-stories/computer-vision-offers-new-tools-for-searching-the-video-explosion Project Story for www.mitre.org. Factor in the time-honored truth that most children aren't typically aware of their surroundings, and the situation dangerously elevates. Thus, the vision is that LinkBioMan technology would sound an alert to either the conductor or nearby personnel that the children are on the tracks and should get off. \"We're trying to elevate security to the next level, because presently there isn't much automation that can intelligently interpret activities and events within video,\" says Monica Carley-Spencer, the co-principal investigator on the project. \"We're applying computer vision and machine learning to multimedia (video frames, audio track, and potentially other data feeds), to essentially train a computer to recognize what is happening.\" The LinkBioMan algorithms also seek to catch unusual behavior that the human eye may not immediately detect. Think of someone carrying a large bag and walking in the opposite direction of thousands of standing people as they take in a parade. Maybe the person is just scanning the crowd for a friend. But, what if there's more going on? Safer in a Crowd A blend of open-source tools form the backbone of LinkBioMan technology. An additional element being developed by the team for this new fusion of tools is image captioning. Image captioning software examines a scene and provides a verbal description to analysts of what may be amiss. \"We're striving to connect object detection to the descriptions provided by the captioner,\" says Haluk Tokgozoglu, MITRE's technical lead of video analytics for LinkBioMan. \"We can create a contextual link between what the scene description says is happening, and what visual entities corresponding to the text are saying about the scene.\" https://www.mitre.org/publications/project-stories/dreaming-cgi-teaches-computers-to-see-better-than-humans Project Story for www.mitre.org. Within the LinkBioMan family of acoustic, video, and fusion algorithms, the team is currently working to increase accuracy and robustness. Their next step is to expand LinkBioMan to other use cases, such as natural disasters, environmental hazards, and construction safety. The work on LinkBioMan aligns with the needs of MITRE's sponsors, because \"the commercial sector is addressing the interests of their largest customer base, and these do not necessarily overlap with the problems that government and federal law enforcement agencies are most concerned with,\" Carley-Spencer points out. \"MITRE has significant in-house research expertise, so we can quickly leverage knowledge gained from other sponsor projects to generate prototypes on a low budget.\" \"Once we fully develop this system, we can re-tune it to address cases for a government organization's needs,\" Tokgozoglu adds. \"We already have an algorithm for riots, and we plan to tailor it to large public speaking gatherings, parades, and athletic events.\" Ultimately, the LinkBioMan research team is aiming for success via the technology's flexibility and customization. \"Our goal is to make the algorithm useful for all kinds of situations where security is difficult to maintain, because of the many elements in play,\" Lee concludes. --by Cheryl Scaparrotta Approved for Public Release; Distribution Unlimited: 17-1991. ",
    "text": " OGS Brian K. Schmidt\nMay 2017\nGeneralized Addition Tallying Operation (GATO)\nApproved for Public Release; Distribution Unlimited: 17-2162.\nNOTICE \nThis technical data was produced for the U. S. Government under contract No. DG-133E-12-CQ-0029, and is subject to the Rights in Data-General Clause 52.227-14 (DEC 2007). | # | \n \nPurpose of Briefing\nIn Decision Analysis studies, it is common to compute the overall benefit or mission performance of a system by means of a capability tree (or hierarchy)\nEach node in the tree has a score representing its degree of capability\nThe score of each node is computed from the scores of its children (the nodes immediately below it)\nOne hard part of the analysis is to develop a rollup function that expresses this relationship accurately\nThis briefing presents an advanced rollup function that can be used to express complex relationships based on data supplied by experts | # | \n Background | # | \n \nNOAAs Study of Observing Systems\nIn 2013-2015 the National Oceanic and Atmospheric Administration (NOAA) conducted an analysis to assess the impact of observing systems (e.g., satellites, ground radars, weather balloons). (See Ref 1.)\nThe analysis built a capability tree with more than 10,000 nodes\nAn especially complex part of the model dealt with the relationship between data sources (e.g., satellites) and NOAA products (e.g., tornado warnings) \nTo construct rollup functions for this part of the tree\nExperts supplied data in swing tables (see next slide)\nThe swing tables were translated into rollup functions using a method called Interval-Preserving Symmetric Extended Average (IPSEA) (see backup slides)\nThis briefing describes a new alternate rollup function (GATO) | # | \n \nSwing-to-Zero Swing Table\nOverall problem\nx1, \ny is the parent score\nThe xs and y lie in [0,1]\nOUR GOAL: Express y = f(x1, \nv1, \nu0 is the parent status quo (current) score\nu1, \nf( all status quo ) = u0\nf( xk = 0, others status quo ) = uk\nf( all 0 ) = 0 x1 x2 x3 y\n v1 v2 v3 u0\n 0 v2 v3 u1\n v1 0 v3 u2\n v1 v2 0 u3\n 0 0 0 0 | # | \n \nTerminology 1\ndeltak = percent drop from parent status quo score caused by kth\n child \n = (u0 uk) / u0 written as a percent total_delta = deltak x1 x2 x3 y drop delta \n 0.60 0.70 0.85 0.80 \n 0 0.70 0.85 0.20 0.60 75 % \n 0.60 0 0.85 0.20 0.60 75 % \n 0.60 0.70 0 0.40 0.40 50 % \n 0 0 0 0 0 \n 200 % total_delta | # | \n \nTerminology 2\nOnly if total_delta = 100% can we fit a weighted average to the swing table If total_delta < 100%, the table is called max-like because its properties are like those of a maximum function If total_delta > 100%, the table is called min-like, for a similar reason Extreme means total_delta is very large (say 300% or 1000%) | # | \n \nExtreme Swing Tables\nExtreme tables occur when there are deep drops in parent score (or a large number of children with moderate drops)\nHence the rollup function is far from being linear (which requires 100%)\nThese cases are hard to model. (See backup slides.)\nThis briefing presents a new rollup function that handles such tables well\n x1 x2 x3 x4 y drop delta \n 0.60 0.70 0.85 0.70 0.80 \n 0 0.70 0.85 0.70 0.20 0.60 75 % \n 0.60 0 0.85 0.70 0.20 0.60 75 % \n 0.60 0.70 0 0.70 0.10 0.70 87.5 % \n 0.60 0.70 0.85 0 0.10 0.70 87.5 % \n 0 0 0 0 0 \n 325 % total_delta | # | \n New Approach | # | \n \nGeneralized Sum\nIt feels natural to say that the parent score is in some sense the sum of the child scores\nBut a regular sum wont work\nWe need a non-linear function\nWith regular addition, scores could add up to more than 1\nThis would be bad because the node scores are on a [0,1] scale, with 1 interpreted as the best possible\nSo we need to use a new kind of addition operation that stays within [0,1]\nSome examples of such an operation are described in the following slides | # | \n 10 Example 1\nThe complementary product is used in statistical and risk analysis to express the probability that either Event A or Event B will occur x y = 1  (1-x)*(1-y)\n = x + y xy Where x = the probability that Event A will occur\n y = the probability that Event B will occur The value of the complementary product never exceeds 1 | # | \n \nExample 2\nThe velocity addition formula in the theory of special relativity (for collinear motion) is used to add the speeds of two moving bodies x y = (x + y) / (1 + xy/c2) \nFor example\n x = speed of an asteroid moving away from Earth\n y = speed of a rocket blasting off from the asteroid\n (going away from Earth), as seen by observers\n on the asteroid\n x y = speed of the rocket as seen from Earth The sum cannot exceed the speed of light (c) | # | \n \nContinuous Family\nMy research has shown that these two examples are part of a larger family \n x y = (x + y + (s-2)xy) / (1 + (s-1)xy) \ns = 2 Velocity addition formula (with speed of light = 1)\ns = 1 Complementary product The parameter s can take on any positive value\ns=0 can be used as a limiting case but is not technically part of family I call this family dsum (for diminishing sum, because the value is held below 1)\nIt is simple and natural | # | \n \nThis graph shows\ny = x x\nfor various values of the parameter s red curve is complementary product (s=1) green curve is limiting lower curve (s=0)\nGraph of dsum (Doubling) | # | \n \nFurther Information\nThere are many other generalized sum operations See backup slides for\nThe mathematical definition of a generalized sum\nMore information about dsum | # | \n \nHow to Use the Generalized Sum\nWe want to say that the parent score is the sum of the child scores\nBut each child could contribute a different amount\nCall these amounts c1, \nThese are the amounts contributed when xk = vk (status quo)\nSo it makes sense to say: f(x) = GENSUM( ck * (xk /vk) )\n = (c1 * (x1 /v1)) \n \nFitting a Swing Table\nTo fit a given swing table with GATO\nPick a family of addition operations\nIn these slides, we will use the dsum family\nMany other families can be used, giving different flavors of GATO\nSee backup slides\nSolve for c1, \nFor dsum, the parameter is s | # | \n \nApplying the GATO Function\nUsing the dsum family, GATO can fit many swing tables\nMax-like: It works for moderately max-like tables\nCases that dont work with GATO can be handled using IPSEA. (See backup slides.)\nMin-like: It works for all tables\nThe child status quo scores (v1, \n \nIssue Parameter Explosion\nAs tables get more extreme, the GATO parameter grows quickly\nThe table below is an example taken from particular swing tables total_delta s\n 238 % 3.4 E3\n 475 % 4.8 E6\n 713 % 6.6 E12 One might expect this to be a serious problem\nHowever, instead of getting into trouble, GATO converges (stabilizes) as s grows\nSee slide 50\nAs a result, there is no limit to how extreme a swing table can be; the dsum family of GATO still works | # | \n \nBringing In a New Child \nSuppose we:\nBuild a swing table\nConstruct a GATO rollup function that fits the table\nDecide we want to bring in a new child xn+1 Because we are using GATO, we can do this without changing the tradeoffs between the existing children\nThis property is hard to satisfy with other methods | # | \n \nConclusions\nGATO provides an alternate way of fitting a rollup function to a swing table\nGATO behaves well with extreme swing tables | # | \n \nNational Environmental Satellite, Data, and Information Service (NESDIS), U.S. Department of Commerce, December 2015, NOAA Observing System Integrated Analysis (NOSIA-II) Methodology Report, doi: 10.7289/V52V2D1H, Washington D.C.\nSchmidt, B.K., 2017, Multi-Swing Rollup Method, The MITRE Corporation, Bedford, MA. References | # | \n \nBackup\nSwing Table Details | # | \n \nSwing Table Assumptions\nIn both IPSEA and GATO analyses, we assume:\nAll of the us and vs lie strictly between 0 and 1\nuk < u0 for k = 1 to n | # | \n \nBackup\nInterval-Preserving Symmetric Extended Average (IPSEA) | # | \n \nSummary of IPSEA Rollup Function\nIPSEA is a generalization of a weighted average\nThe weights and other parameters are set from a swing table\nAdvantages\nProvides a rollup function that fits many swing tables occurring in practice\nIn good agreement with intuition/experience in many cases\nWorks well with those max-like tables that GATO cannot fit\nThe power family does this well (for definition, see slide after next)\nDisadvantage\nNOAA team found that IPSEA has difficulty fitting extreme swing tables\nTeam was able to work around the problem, because the extreme tables obtained from experts were judged to be exaggerated. (See Ref 1, p. 72.)\nNevertheless, the ability to fit extreme tables
may be required in future studies | # | \n \nIPSEA Formula\nIPSEA = Interval-Preserving Symmetric Extended Average\nAn extended average f(x1, \ng1 and g2 belong to the same family (symmetric) but may have different values of the parameter\nAll scaling functions in the family preserve the interval [0,1]\nI.e., they map the interval invertibly to itself\nTypically g(0) = 0 and g(1) = 1\nThis ensures that the f values stay in [0,1]\nIPSEA satisfies f(all 1) = 1 in addition to the swing table on slide 5 | # | \n \nFour Families of IPSEA\nBelow are four one-parameter families of functions. Each is interval preserving and hence can be used to build an IPSEA function by choosing g1(x) and g2(x) with different values of the parameter.\nUnit Hyperbolic\n g(s,x) = sx / ((s-1)x + 1) Unit Exponential\n g(a,x) = (ax 1) / (a 1) Power\n g(n,x) = xn Double Exponential\n g(a,x) = ue( ue(x) ), where ue(z) = (az 1) / (a 1) | # | \n \nIPSEA and Extreme Tables\nThe following slides show graphs of slice functions. These graphs show how the parent score changes when one child varies and the others are held fixed\nWe will show how IPSEA gets into trouble with extreme tables and what happens with GATO | # | \n \nIssue 1 Behavior Near x=0\nIPSEA: The curve rises too quickly near x=0\nThis happens only with the power family IPSEA power family The two dots are determined by the swing table. The curve must go through them.\nNOAA teams interpretation: The rapid rise near x=0 means that too much credit is given for a very small amount of child capability | # | \n \nIssue 1 IPSEA and GATO\nIPSEA: The curve rises too quickly near x=0\nThis happens only with the power family\nGATO: The curve looks more credible IPSEA power family\nGATO | # | \n \nIssue 2 Flattening with Extreme Tables\nIPSEA: For normal children (i.e., children that do not severely pull down the parents score), the curve is too flat\nThis happens with all families (hyperbolic is shown)\nIPSEA\nGATO The two dots are determined by the swing table. The curve must go through them.\nNOAA teams interpretation: The flattening of the curve means that too little credit is given for increasing the child score above about 0.2 | # | \n \nIssue 2 IPSEA and GATO\nIPSEA: For normal children (i.e., children that do not severely pull down the parents score), the curve is too flat\nThis happens with all families (hyperbolic is shown)\nGATO: The curve looks more credible\nIPSEA\nGATO | # | \n \nIssue 3 Parameter Explosion\nAs tables get more extreme, IPSEAs s1 parameter grows quickly\nOf the four IPSEA families, the exponential family has the most difficulty with this problem. It can also happen with the other families except the power family. IPSEA exponential\n total_delta s1\n 238 % 4.2 E6\n 475 % 1.0 E13\n 713 % > 1 E15 The large parameter makes IPSEA computations impossible without very high precision arithmetic\nThis is not a problem for GATO (see main slides) | # | \n \nBackup\nGeneralized Sums | # | \n \nDefinition of a Generalized Sum on [0,1]\nStays in [0,1]: 0 x y 1 ( for x,y in [0,1] )\nIdentity: x 0 = x\nCommutative: x y = y x\nAssociative: (x y) z = x (y z)\nAbsorbing: x 1 = 1\nContinuous\nIncreasing: x < x y ( for x,y in (0,1) )\nNon-saturating: x y < 1 ( for x,y in (0,1) ) | # | \n \n37\nTheorem\nAll generalized sum operations have the form x y = g-1( g(x) + g(y) ) where g: [0,1] [0, ] and g is\ncontinuous\nstrict order preserving\ng(0) = 0\ng(1) = | # | \n \n38\nExamples of Theorem\nComplementary product\n g(x) = - ln(1-x) Velocity addition formula in special relativity\n g(x) = tanh-1(x) g is called the generating map | # | \n \n39\nConverse of Theorem\nAny function g having the properties listed on slide 37 induces an addition operation\nHence we can construct lots of operations | # | \n \nGenerating Map for dsum Family 1\nThe generating map for dsum is\ng(x) = - ln( 1 hs(x) ) where hs (x) is given by hs: [0,1] [0,1]\n hs(x) = sx / ( (s-1)x + 1 ) This is the unit hyperbolic family used in IPSEA This graph shows hs(x) for various values of s | # | \n \nGenerating Map for dsum Family 2\nThe generating map may also be written:\ng(x) = ln( 1 + s*qn(x) )\n where qn(x) = x / (1-x) This explains why qn plays a big role in the behavior of GATO\nGATO converges to RPRM (see slide 48)\n f(x) = qn-1( q(u0) * { (1-rk) * (xk/vk) + rk } )\n where rk = qn(uk) / qn(u0) We can solve for GATO iff average(qn(uk) ) < ((n-1)/n)*qn(u0) | # | \n \nOther Flavors of GATO\nOn the previous slide, if we replace the mapping qn by a similar mapping m: [0,1] [0, ], we obtain a family of generating maps:\ng(x) = ln( 1 + s*m(x) ) Any such replacement gives rise to another flavor of GATO that converges to the corresponding flavor of RPRM Examples:\nm(x) = tanh-1(x)\nm(x) = tan( (/2) x )\nm(x) = spn( qn(x) ) \nwhere spn(x) = (1+x)n 1 is the shifted power function and n is a constant. More about this versatile family is given in Ref 2. | # | \n \nBackup\nGATO | # | \n \nDomain of Definition\nGATOs addition operation is defined only for numbers in [0,1]\nHence GATO is defined only when each ck * (xk /vk) is less than or equal to 1\nSo to cover all xk values (up to 1), we need ck vk for all k\nThere is no guarantee that GATO has this property\nHowever, it works in the natural cases we have examined\nTheoretical explanation\nWhen tables are extreme or nearly extreme, GATO is closely approximated by RPRM. And RPRM is defined for all values of the xs in [0,1]. | # | \n \nFitting a Swing Table: The Math 1\nIn these slides, we explain how to fit a GATO function to a given swing table. This derivation applies to all families of GATO, not just the dsum family. The equation we are trying to fit is: f(x) = GENSUM ( ci * (xi /vi) ) where GENSUM denotes the generalized sum.\nTo find the rollup function, we must solve for the ci constants and the function g that determines our addition operation.\nNote that f(all 0) = 0 is satisfied automatically.\nThe status quo row of the swing table gives: GENSUM( ci ) = u0 The kth swing row gives: GENSUM( skipping i=k )( ci ) = uk GENSUM( ci ) ck = uk where denotes generalized subtraction. | # | \n \nFitting a Swing Table: The Math 2\nThis becomes: u0 ck = uk So: ck = u0 uk This would tell us what the c's are if we knew what the operation was. But we still need to figure it out. Notice that if we have selected an operation and we define the c's by this formula, all of the swing rows will be true provided that the status quo row is true. So it is necessary and sufficient to find an operation satisfying: GENSUM( ck ) = u0 This becomes: GENSUM( u0 uk ) = u0 | # | \n \nFitting a Swing Table: The Math 3\nSwitching to ordinary arithmetic, we obtain: g-1( n*g(u0)  ( g(uk) ) ) = u0\nn*g(u0)  ( g(uk) ) = g(u0)\n(n-1)*g(u0) = ( g(uk) ) Solving for g boils down to solving the equation above. Recall that we are taking g from a one-parameter family of functions, so solving this equation boils down to finding the value of the parameter (s in the dsum case) which satisfies the equation. This can be done by numerical means. | # | \n \nBackup\nRescaled Proportion Retention Multiplier (RPRM) | # | \n \nDefinition of RPRM\nGiven a swing-to-zero table, the Rescaled Proportion Retention Multiplier (RPRM) is a rollup function given by f(x) = res-1( res(u0) * factork(xk) ) where \nres (the rescaling function) is an invertible mapping from [0,1] to [0,]\neach factork is a non-negative function on [0,1] satisfying\nfactork(vk) = 1\nfactork(0) = res(uk) / res(u0) Hence we can set\nfactork(xk) = (1-rk) * (xk/vk) + rk \n where rk = res(uk) / res(u0) | # | \n \nConvergence\nAs s goes to infinity, the dsum family of GATO converges to RPRM with rescaling function qn(x) = x / (1-x)\nqn is called the quintessential function This family of RPRM is given by\nf(x) = qn-1( qn(u0) * { (1-rk) * (xk/vk) + rk } )\nwhere\nrk = qn(uk) / qn(u0) When we use RPRM to approximate GATO, we dont have to solve an equation. (That is, we dont have to solve for s and the ck values.) The function can be computed directly from the swing table. | # | \n \nProperties of RPRM\nRPRM automatically satisfies the swing table on slide 5 except for f(all 0) = 0\nRPRM can give a fairly large value for f(all 0) when the table is max-like. However, for seriously min-like tables, f(all 0) is negligible.\nIt turns out that f(all 0) is
an estimate for 1/s in the dsum version of GATO. So when s is very large, f(all 0) is very small.\nNote also that f(all 1) < 1 is automatically satisfied by RPRM. So f(x) always lies in the required range [0,1].\nHence RPRM can handle extreme tables without numerical problems | # | \n \nMore General RPRM\nRPRM may also be used with more general swing tables than those discussed in these slides\nSpecifically, it can handle tables with multiple swings. (See Ref 2.) | # | \n \nGraph of Quintessential Function and Its Inverse\nqn-1(x) = x / (1 + x)\n = the inverse function qn(x) = x / (1 x) | # | \n 53 Backup\nExamples in These Slides | # | \n \nData Used in Examples 1\n k child (vk) parent (uk)\n 0 0.80\n 1 0.65 0.60\n 2 0.90 0.50\n 3 0.35 0.10\n 4 0.75 0.10 Slides 31-32, slice function for child 3\n k child (vk) parent (uk)\n 0 0.80\n 1 0.65 0.60\n 2 0.90 0.50\n 3 0.35 0.10\n 4 0.75 0.10\n 5 0.65 0.60\n 6 0.90 0.50\n 7 0.35 0.10\n 8 0.75 0.10\n 9 0.65 0.60\n 10 0.90 0.50\n 11 0.35 0.10\n 12 0.75 0.10 Slides 33-34, slice function for child 1.\nThis table is three copies of the smaller table | # | \n \nData Used in Examples 2\n k child (vk) parent (uk)\n 0 0.80\n 1 0.65 0.60\n 2 0.90 0.50\n 3 0.35 0.10\n 4 0.75 0.10\n 5 0.65 0.60\n 6 0.90 0.50\n 7 0.35 0.10\n 8 0.75 0.10\n 9 0.65 0.60\n 10 0.90 0.50\n 11 0.35 0.10\n 12 0.75 0.10 Slides 19 and 34\nThe three cases correspond to one, two, and three copies of the small table on the previous slide | # | \n \nSearch & Rescue\n42\nRecv Distress Call\n80\nLocate Vehicle\n20\nPlan Resources\n45\nReach Location\n70\n0.00.10.20.30.40.50.60.70.80.91.00.00.10.20.30.40.50.60.70.80.91.0sum(x,x)x\n0.00.10.20.30.40.50.60.70.80.91.00.00.10.20.30.40.50.60.70.80.91.0yxk\n0.00.10.20.30.40.50.60.70.80.91.00.00.10.20.30.40.50.60.70.80.91.0yxk\n0.00.10.20.30.40.50.60.70.80.91.00.00.10.20.30.40.50.60.70.80.91.0yxk\n0.00.10.20.30.40.50.60.70.80.91.00.00.10.20.30.40.50.60.70.80.91.0yxk\n0.00.20.40.60.81.00.00.20.40.60.81.0hs(x)x\n .20.40.60.81qn(x)x\n0.00.20.40.60.81. 617181920qn-1(x)x ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-2401. 1 Remote Tower Idea Gains Traction in Aviation Industry TEASER: \"Remote tower operations\" is a new concept in air traffic control that's begun to take off worldwide. MITRE is exploring its application to a variety of airport operations in both the United States and in Singapore. When we think about the air traffic controllers who manage flights arriving to or departing from airports, we typically picture them in a tower with windows offering a 360-degree view. But what if the controller could do the same work with real-time camera feeds that replicate or enhance that panoramic view? That ideaknown as the \"remote tower\" concepthas caught on in various parts of the world. It shows particular promise as an efficient and cost-effective way to support operations at smaller airports without airport traffic control towers. At MITRE, we're researching the remote tower concept for use both at home and abroad, and for large and small airports. Ground-breaking research we're conducting at our state-of-the-art air traffic management research facility in our MITRE Asia Pacific Singapore (MAPS) may result in the first-ever remote tower air traffic control (ATC) operation that can serve all the traffic demand at a high-traffic airport. How Do Remote Tower Operations Work? \"A remote tower is essentially an air traffic control facility that allows controllers to provide service to an airport without the need to build and maintain a physical tower. Controllers observe the airport's surface and the surrounding airspace using camera feeds and surveillance technology available today,\" explains Tony Colavito, who leads MITRE's work on the remote tower concept and its applications. \"The facility might not even be located at the airport. It could be hundreds of miles away.\" What makes this possible are video cameras mounted on poles erected on the airport surface. Multiple fixed-position cameras project feeds onto an array of connected video screensmimicking the panoramic, out-the-window view an air traffic controller would have from a physical tower. Approved for Public Release; Distribution Unlimited: 17-2401. 2 The system may also include video cameras that can pan, tilt, and zoom. \"Just as a controller in a tower might use binoculars to take a closer look at objects or areas of interest, controllers in a remote tower facility can use these cameras to do the same thing,\" Colavito says. Otherwise, it's business as usual. \"Controllers in a remote tower scenario have all the same weather and flight plan information they have in towers. They would have the same surveillance, and they would communicate with pilots in the same way,\" Colavito explains. \"The only thing that changes is the way they obtain their situation awareness of the airport surface and nearby airspace.\" The concept has already been employed at some of the world's smaller airports, and industry watchers predict that its use is likely to become more and more common in the coming years. An incentive for the concept's spread is cost savings. The construction of a new ATC tower for a small airport costs at least $56 million, on average. Remote tower operations at a small airport can be instituted at a much lower cost. MITRE Explores Multiple Uses for the Remote Tower Concept MITRE's research on remote towers for the Federal Aviation Administration (FAA) began more than a decade ago. As the concept gained popularity in the United States, MITRE conducted a study exploring the cost-effectiveness of remote tower operations and the development of a long-term strategy for providing remote tower ATC services in the United States. More recently, MITRE has investigated characteristics of airports best suited to remote tower operations and the various levels of service they could provide remotely. \"In the United States, airports that want tower-like services are starting to team up with vendors to come up with their own plans for remote tower operations,\" Colavito says. The FAA then has the responsibility of evaluating the proposal to ensure its safety and efficient interaction with other FAA services. \"To make that process more efficient, we're helping the FAA develop a standardized approval process they can use to evaluate a remote tower proposal.\" That work has included developing criteria the FAA can use to evaluate remote tower systems. \"We're looking at things like the operations the controllers need to see and how the controllers will use the system.\" How Will the Remote Tower Concept Work in Singapore? We're also researching the application of the remote tower concept in Singapore, but with a vastly different goal in mind than serving smaller airports. In Singapore, remote tower operations are being considered for Changi Airport, which currently uses two runways to handle as many as 72 flights an hour. MITRE is exploring the remote tower concept as a complement to the actual tower. \"We're researching whether it would be possible to use remote tower capabilities to handle all of the traffic at Changi Airport,\" Colavito explains. During the last two-and-a-half years, MITRE has developed a preliminary concept of operations to define how Changi Airport could operate in a remote tower scenario and conducted human-in-the-loop experiments to test the concept. Approved for Public Release; Distribution Unlimited: 17-2401. 3 \"In 2016, we engaged a production company to set up cameras on the Changi Control Tower at Changi Airport,\" Colavito says. \"We captured footage that would simulate what controllers see out the window. We then ran an experiment to see whether controllers could have the same level of situation awareness when they look at the video footage as they do when looking out the tower window. We found that they could.\" In another human-in-the-loop study, MITRE worked with controllers to evaluate the throughput that could be achieved at Changi Airport using remote tower operations. Overall, controller feedback was positive. MITRE has supported the Civil Aviation Authority of Singapore in bringing industry in to build a remote tower prototype system. \"MITRE doesn't compete with organizations that build these types of systems,\" Colavito notes. \"We're an objective party that works in the public interest. Our support will help to ensure that Singapore achieves its goal of incorporating advanced technologies and maximizing efficiency while maintaining safety.\" by Marlis McCollum Remote Tower Idea Gains Traction in Aviation Industry ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-2337. An Engineer Keeps Career Development on Her Radar How do you sustain and modernize early warning radar systems that have been in place for more than 50 years? That's the challenge that intrigues MITRE's Jenn Forsyth, an electrical engineer. Radars are a 20th century technology that provide an ongoing, valuable role in our nation's defense. \"That's what makes it such a cool challenge,\" she says. \"Our radar infrastructure needs to function while you make system improvements and upgrades. \"From a systems perspective, what you're worried about today is very different from what you worried about 40 years ago. Plus, you're trying to anticipate future needs and modernize the infrastructure in a way that will accommodate new technologies.\" This long-term perspective is an integral part of the partnership MITRE has with our sponsors and our mission to work in the public interest. \"My research focuses on technological improvements in radar and satellite communications for a range of different sponsorsnot just for the immediate future but for the next couple of decades,\" Forsyth says. Her work supports the National Security Engineering Center, a federally funded research and development center (FFRDC) MITRE operates for the Department of Defense. On-site Provides Insight into Arctic Communications Challenges Forsyth, who came to MITRE after graduating from Rensselaer Polytechnic Institute (RPI), started her career helping modernize early warning radar systems. \"A lot of my work can be applied to different projects,\" she says. \"But much of it looks at ionospheric impacts on radar and satellite communications, especially at high latitudes.\" It was her research and expertise in ionospheric physics and its effects that brought her to Thule, Greenland. She and two other MITRE staff spent a week on-site with a government sponsor running test scenarios, capturing data, and analyzing the performance of the systems. \"There are many communication challenges associated with the increases in accessibility of the multi- domain, multi-user activity in the Arctic. It's exciting because theres a lot of new activity, but it's also challenging because of the disturbed ionosphere there.\" The trip provided valuable insight as to how the operators use the system and how it performs in remote locations. \"Being able to look at the system through the lens of an operator or the site commander is completely different from seeing it in a development lab.\" (MITRE staff also research Arctic effects for U.S. Northern Command, with a focus on emergency response.) Now Forsyth is applying what shes learned to a MITRE Innovation Program (MIP) for modeling ionospheric impacts on arctic communications systems. Paying It Forward A college internship first brought Forsyth to MITRE. But it's the ongoing professional development and educational benefits that made her want to come backand stay. https://www.mitre.org/centers/national-security-and-engineering-center/who-we-are\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/publications/project-stories/testing-satellite-communications-links-on-top-of-the-world\nhttps://www.mitre.org/research/overview\nhttps://www.mitre.org/careers/student-programs/co-ops-interns\nhttps://www.mitre.org/careers/working-at-mitre/professional-development\nhttps://www.mitre.org/careers/working-at-mitre/professional-development Approved for Public Release; Distribution Unlimited: 17-2337. Over the last few years, she's completed her master's degree at Northeastern University with a concentration in electromagnetics and plasmas. She also earned a graduate certificate in Northeastern's Gordon Engineering Leadership program. \"Continuing my education was a priority,\" she says. Forsyth also participates in several professional development and volunteer activities. They include the Society of Women Engineers, Toastmasters, Young Women in Engineering, Networking for Professional Women, STEM Council, MITREs NextUp Executive Board, and recruiting events at RPI. But she is most proud of her work expanding MITREs Job Shadowing program. \"I'm very pleased with how it's grown in the last few years,\" she says. \"We have a lot of passionate staff here who apply to be mentors and mentees. When I got involved in the program in 2012, we had 11 pairs in one part of the company. Now we have 55 pairs across several different parts of the corporation. It's been very rewarding to see it grow.\" Looking back, Forsyth appreciates all the opportunities she's had at MITRE. She's also grateful to Michelle Getherall, the engineering teacher at Woburn [Massachusetts] High School, who inspired her to pursue engineering in college and as a career. \"Now I see her attend MITRE's annual Young Women in Engineering Day with some of her current students. She had a real impact on my career, so it's nice to be helping and encouraging other young women interested in engineering.\" by Kay M. Upham https://publish.mitre.org/kde/2017/04/21/casting-a-shadow-to-shine-a-light/\nhttps://www.mitre.org/about/corporate-social-responsibility/building-a-foundation-for-the-future/young-women-and-engineering An Engineer Keeps Career Development on Her Radar ",
    "text": " () A GAME ORIENTED APPROACH TO MINIMIZING CYBERSECURITY RISK SCOTT MUSMAN, & ANDREW J. TURNER The MITRE Corporation, McLean, Va, USA ABSTRACT Information and Communication Technology (ICT) systems are now ubiquitous in all aspects of our society. With an ability to create ICT incident effects via cyberspace, criminals can steal information or extort money, terrorists can disrupt society or cause loss of life, and the effectiveness of a military can be degraded. These threats have caused an imperative to maximize a systems cyber security resilience. Protecting systems that rely on ICT from cyber-attacks or reducing the impacts that cyber incidents cause is a topic of major importance. In this paper, we describe an approach to minimizing cybersecurity risks called Cyber Security Game (CSG), where CSG can be viewed as a form of model-based system security engineering. CSG is a method and supporting software that quantitatively identifies mission outcome focused cybersecurity risks and uses this metric to determine the optimal employment of security methods to use for any given investment level. CSG maximizes a systems ability to operate in todays contested cyber environment by minimizing its mission risk. The risk score is calculated by using a cyber mission impact assessment (CMIA) model to compute the consequences of cyber incidents, and by applying a threat model to a system topology model and defender model to estimate how likely attacks are to succeed. CSG takes into account the widespread interconnectedness of cyber systems, where defenders must defend all multi-step attack paths and an attacker only needs one to succeed. It employs a game theoretic solution using a game formulation that identifies defense strategies to minimize the maximum cyber risk (MiniMax), employing the defense methods defined in the defender model. This paper describes the approach and the models that CSG uses. Keywords: cybersecurity, risk assessment, risk management, return on investment, game theory 1 INTRODUCTION Information and communications technology (ICT) is now integral to almost every aspect of our daily activities. The detrimental aspect of introducing ICT dependencies, however, is that this makes us susceptible to impacts from cyber incidents. Criminals can steal and extort money or information, terrorists can disrupt society or cause loss of life, and the effectiveness of a military can be degraded, all because of an ability to create incident effects in cyberspace, and often without any requirement of physical proximity. Protecting ICT from cyber incident effects or reducing their impacts on operational activities has become of international importance. There is an escalating imperative to identify and minimize operational cyber risk. In almost all circumstances, we are interested in achieving operational resilience: the ability for mission systems to continue to acceptably achieve their function in the face of incidents, while also doing whats best to fulfill other security requirements. Achieving such resilience almost always must be pursued in the face of resource limitations. Often we need to justify the costs and resources needed, so a problem with trying to achieve resilience is that we need a way to measure it, including how to identify whether efforts to improve it are successful or not. If operational resilience is defined in a qualitative rather than quantitative way very little prescriptive advice can be offered to increase it. Many of todays risk management methods provide only generic guidance, or recommended best practices, and produce only risk rankings. As described by [1] risk rankings lack the information required to support optimal allocation of resources to manage those risks, and more importantly: ranking doesnt contain information of how an attacker will modify their behavior in the face of defender actions. The difficulty with trying to manage ones cyber risk is that it requires a holistic view of how a system fulfils its intended purpose. This requires a knowledge of the purpose, the entire range of hazards that are possible, and a need to consider all attack avenues. Due to the interconnectedness of cyber systems attackers can exploit seemingly-non-critical cyber components to bypass security controls and other defenses. Examples include Stuxnet [2] and the Target data breach [3], where non-critical systems were compromised to reach the important ones. In other words, effective cybersecurity does not just involve defending high impact resources, but all inter- connected resources that provide a pathway to those that are mission-critical. Some have proposed techniques where a defender considers only the resources that directly cause impacts [4] [5]. But without an explicit representation of how the ICT components interconnect this approach fails to defend the seemingly non-critical resources that act as stepping stones and consequently fails to defend indirect attack paths an attacker might use to bypass defenses. An attacker can choose any attack method, ranging from those with a high expected value (payoff), to speculative probes that might reveal a weakness not immediately apparent to a defender obsessed only with the crown jewels. To defend only against the most obvious attack paths simply allows an attacker to select the next most promising one, and so on, until some exploitable chink in the armor is discovered. Thus, without a holistic understanding of the system, one is likely to make the mistake of addressing only some of the hazards but not others, or to over-invest in addressing some hazards even though the risks from other hazards are higher. A comprehensive assessment is needed to be able to provide prescriptive advice to identify which defensive tools and methods are needed and where. Cyber attacks and the concomitant defensive actions can be viewed as game playing between two players [6]. One way this can be represented is as a zero-sum game (one where both attacker and defender assign the same value to gain or loss). In two player, finite, zero-sum games, the game theoretic solution concepts of Nash Equilibrium and Minimax produce the same solution where the defender tries to minimize the maximum payoff for the attacker. When implementing a technique to use to solve this type of game, we need to be concerned with our ability to define the game state (i.e. what game board looks like), how attacker and defender moves change the game state, and to be able to evaluate each game state. Since each mission system is going to be different, and since operational objectives are whatever they happen to be, for cyber, this means the game board must be built for each system, and we need to be able to evaluate how the modeled system can fulfil its purpose in the face of cyber incidents. This is made possible by reasoning about cyber incident effects, rather than the incident instances that cause the effects [7], and by leveraging our past work on Cyber Mission Impact Assessment (CMIA) [8] [9] as a way of assessing the goodness of a game state. Combining the mission impact measure with a system topology based [10] [11] threat likelihood model allows us to estimate mission risk. We describe a program that allows us to play a cybersecurity game with an objective to minimize a mission systems cyber risk. We call our software CSG, the Cyber Security Game. Our approach is theoretically grounded in game theory, yet focuses on being practically useful. We describe the specifics of how the game is formulated, and each of the models of the system needed to play the game. A cyber mission impact assessment (CMIA) model is used to identify the consequences of cyber incidents. A model is used to describe the ICT topology, connectivity, access relationships, and asset type information. Models define the defensive measures that can be employed, and a default attacker model is provided. Each of these models is algorithmically linked to aspects of the risk calculation so that changes to each can directly alter the mission risk metric. CSG is a model-based solution, meaning that user effort is focused on developing the models of the system and its usage scenario, and CSGs algorithms then operate on the models to compute mission risk and optimize the employment of security measures. The outcome of running CSG allows us to identify the optimal set of security tools and resilience techniques to reduce the mission systems cyber risk for any given defender cost. The next section describes our game, describes how we represent cyber mission systems, how we assess cyber threats, how we have implemented the game, and how we use it to perform a portfolio analysis of tools and methods that can reduce cyber risk. We then discuss aspects of our game program and how it solves the problem we have posed. 2 THE CYBER SECURITY GAME CSG is an algorithmic method that relies on models that describe the system, its purpose, the threat environment, and the defender capabilities. It runs algorithms on those models to produce results. CSG algorithms automate several expert level capabilities, such as the combinatorics of possible incidents, attack path discovery, and portfolio analysis, so that analysts do not have do them manually. When aspects of the system, defenses, or threats change (i.e., new vulnerabilities are discovered), a defender merely
updates the appropriate model and reruns CSG to assess the impact of the changes. An overview of CSG is provided here. CSGs game formulation searches through the combinatorics of cyber incidents, attack paths, impacts, and defender method employments using Minimax. CSG is formulated as a two-player zero-sum game. As such it implements rational decision making, where both players work to best counteract each others moves. CSG assumes that the attacker knows about the system they are attacking. This is reasonable because CSGs focus is on defense employment for the long term, assuming that attackers will be able to learn about and may pursue targets over the lifetime of a system. Methods for trying to deceive, delay, or deter an attacker over the short term would motivate a different game formulation. Examples of different formulations are shown in [6]. The system metric in CSG is a system risk score. This score comes from computing the different impacts that an attacker can cause combined conditioned on the how difficult the system architecture and defenses makes it to cause those impacts (described later in this paper). In the game, the defender tries to minimize this value. A state in the game represents a configuration of the system, either with no defenses employed, or some status quo version of the system that one wants to improve. To compute the risk score for that state, for the attacker player generates an attack tree that looks multiple attack steps ahead to identify possible impacts. The leaf nodes of the attack tree provide an expected value (EV) computed from the impacts and the probabilities (as shown in Figure 5). The defender then employs defenses to reduce expected value of the impacts the attacker can cause, and the game proceeds in typical game tree fashion. Starting from the initial state it employs MiniMax, to assess move pairs of a defender action (min), and the attackers revised attack tree given the defender changes (max). The resultant game tree assesses how each defender method can best reduce the risk score. Since the employment of each defender method incurs a cost, the game is over when either the game identifies the optimal set of defense methods to use when the defender has spent the amount of money they have allocated, or when a complete portfolio analysis is performed to compute the Pareto frontier for each price point. Figure 1 demonstrates the output of CSG, where the cost and performance of each portfolio option is plotted. The red dots show the Pareto optimal portfolios. In this example, 55,296 defense portfolio options were considered. With no defenses the risk score was 8492934. With all the security methods applied, the risk was reduced to 2038408, for a cost of $250k. However, spending ~$39k, the risk can be reduced to 2779440. This represents 89% of the risk reduction for only 16% of the cost. Figure 1: Security Portfolio Effectiveness vs. Cost CSG requires four system models. A CMIA process model computes impacts. A system topology model describes the component interconnectivity, type and trust relationships. It contains a built- in (default) attacker model. Lastly, models of the defender methods are needed. Each of these models is described below. 2.1 Modeling Incident Impacts CSG uses CMIA process models to determine the consequence (losses) incurred from cyber incidents, and the CMIA software is embedded in CSG. CMIA makes it possible to capture mission details as an executable simulation. It models mission activities, ICT activities, activity durations, activity dependencies, ICT resources, temporal constraints, data, and control flows. ICT resources in the process model can be affected by cyber incident effects represented by the DIMFUI cyber incident effect taxonomy described in [7] and relates the occurrence of an effect to mission outcomes in the form of mission impacts. Figure 2 shows the CMIA tool displaying a Business Process Modeling Notation (BPMN) diagram, and shows some of the underlying details that turn the model into an executable simulation. It is outside the scope of this paper to describe CMIA in detail but for more information on the CMIA method and tool see [12] [9]. Figure 2: Process Model Showing Mission Activity Order and Control Flow Dependencies CMIA process models can be probabilistic and stochastic, allowing one to bound the uncertainties associated with the model. Running combinatorics on the set of cyber incident effects allows the criticality of cyber resources to be estimated [12] or validated by mission subject matter experts. CMIA also supports the assessment of multiple (simultaneous) incidents, allowing CSG to run through combinations of the possible cyber incident effects that will be assessed using MiniMax. 2.2 Modeling the Attacker CSG, provides a default attacker model that defines the probability that attacks will succeed given the topological constraints that the system imparts on the attacker. For the attacker to affect ICT resources that can cause impacts, the attacker must find a pathway to access them. The attack model conditions the probability of an attack succeeding with the following characteristics: - Whether the attacker is trying to compromise a component they can directly connect to, or whether it requires crossing a network trust boundary to access - Whether that component is the same type as one of the components that the attacker has already demonstrated they can compromise - Whether a component is known to be vulnerable to known exploits - Whether the component is a server that contains one or more network services - Whether user roles, who have access to each resource, can leverage those roles to access other components in the network to create impact Figure 3: Default Attack Model Figure 3 shows the probabilities of attacker success given topology relationships. If they first try and attack host Win 7-2 before attacking something else, the diagram shows that is it possible to attack the host from the outside with probability of success |. It also shows there is a probability in becoming an inside user or subverting an insider account, where the number of accounts N, will affect the risk \n |. Once a host is compromised an attacker can compromise other resources on the devices with |. Once in, the attacker can try to attack other cyber resources of the same type as one of the components already compromised then the probability is P(S|STC). If its of a different type, then the attacker needs a new zero-day attack and has the probability |\n. Throughout, whether the host is a client or a server will affect the probabilities. The probability of successfully navigating the network to compromise a cyber resource is computed using the chain rule shown in Equation 1. This attack model captures the basic security properties of segmentation, diversity, and least privilege and can be composed across multiple networks, trust, and segmentation boundaries. It mathematically credits a defender reducing the amount of access to components that can cause significant impacts, for diversifying components that can cause significant impacts when attacked in combination, it credits a defender for making it harder to reach the components that cause significant impacts , , , . , |, , . , , |, . , . . , | Equation 1: General Form of the Chain Rule 2.3 Modeling System Topology and Applying the Attack Model CSG computes impacts and then uses the attacker model to estimate the probability that the impacts will occur given the constraints of the system topology. The topology model includes cyber components, applications, data, user account groups, and access controls that enforce trust relationships. Model elements include single ICT resources as well as ICT resource pools that represent functionally identical groupings of resources of the same type. The model also requires resource type information for each ICT resource. This makes it possible to know when the same attacker exploit from an earlier step might be reused, and when it cant. The existence of connections, firewall rules, and the access of user roles define connectivity capabilities and restrictions between ICT resources. An example of a topology model is shown in Figure 4 Infrastructure components are in blue, applications and services are shown in green, and data elements are in yellow. User group populations are also included in the model, but the diagram does not show the trust relationships of who can communicate with who, that are also captured in the model. Figure 4: A Simple Topology Model for a Point of Sale System 2.4 Computing the Risk Score The topology model makes it possible to compute attack trees. This process is illustrated in Figure 5. The figure illustrates the complexity of analyzing even a simple four host system. All the mission impacts in the figure would be computed from a CMIA model of the system. The impacts shown include impacts from when multiple components are compromised. Even though the model in the figure contains only two subnets, the model represents a trust relationship from S1 and S2 to S4. The attack tree is then generated, using the attacker model to estimate the probability of attack steps
succeeding. In Figure 5 only the attack steps from the internet are part of the final tree. This is possible for two reasons. First, rational attackers will always use the optimal path to compromise a component in the system. Second, we are evaluating risks in the context of MiniMax. This allows suboptimal paths to be pruned from the tree. Even so, this small four node example produces a more expansive attack tree than we can fully illustrate in the figure (only some pathways are shown). At the end of each path in the attack tree an expected value is computed (based on the worst-case the max in MiniMax). To do this it is necessary to consider different pathways to achieve the same impacts. This is necessary because trust relationships (i.e., as imposed by firewall rules) are not necessarily directionally symmetric, so each pathway has a different probability of success. The sum of EVs at the end of each branch in the attack tree represents the risk score for the system. An alternatively risk score for risk averse organizations (such as critical infrastructure components) could be the maximum EV that exists in the tree. In the next section we will discuss how defensive measures that reduce these EVs are modeled. Figure 5: Topological Attack Graph Calculation for Risk Scoring Because an attacker may have to compromise multiple ICT resources to cause significant impacts there is a need to look enough steps ahead to identify those cases. In CSG this number of attack steps to explore is a parameter than can be set. Usually, unless a system is composed of particularly layered defensive boundaries, looking 3-4 steps ahead should be sufficient. 2.5 Modeling Defender Methods To assess defender choices CSG requires models of the defensive measures. These are shown in Figure 6. Some of the defense measures reduce the likelihood that attacks will succeed. This is typically accomplished in one of two ways. One way applies protections to the cyber resources, and the other is to change access. Each defense measure requires an assessment of how well the method is expected to work. Measures that reduce the chance of attack success are shown in the table in Figure 6. The table lists: the measure name, cost estimates for employing the measure, and measure effectiveness assessment against each attack effect. This effectiveness assessment is defined as a score from 0 to 100. A score of 0 means that the measure is of no use to prevent the effect occurring, and a score of 100 means that the measure completely stops all the attacks that would cause that effect. An interpretation for this score is that a value of 40 should imply that 40% of the attacker exploits that we expect or anticipate as possible would no longer succeed. Other defender measures can be represented by changes to the CMIA process model. The bottom left of Figure 6 shows how a redundant server can be represented in the process model. Including a redundant path in the process illustrates the presence of a redundant server. If an incident only affects the original server then no impact occurs. However, since CSG looks multiple attacker steps ahead it will eventually identify the attack scenario that causes incidents on both servers. Figure 6: Modeling Defender Methods Other defensive measures can be represented in the topology model. This is accomplished by copying the topology model and modifying it to reflect any proposed changes. The likelihood that attacks will succeed can be reduced by changing the network topology or changing access controls. Risks can also be reduced by the principle of least privilege. This involves reducing the number of pooled resources (i.e., client workstations and/or users) with access. Lastly, the risks can be reduced by diversifying the components in the system, forcing the attacker to require multiple different attacks to create an impact[11]. 3 SUMMARY In this paper, we have described the Cyber Security Game (CSG). CSG is both a method and software that implements the method. CSG implements an approach that represents a quantitative, assessment of a mission systems cyber risk. CSG formalizes the information gathering activities that occur during a traditional risk assessment into computable models, artifacts that describe the system (i.e., a system topology model and impact model). CSG also algorithmically encapsulates expert capabilities in software that leverages these computable artifacts to implement a cyber risk assessment that is a consistent and comprehensive process. CSG artifacts also make it practical to keep risk assessments up to date as the system or missions change. A defender need only update the appropriate CSG model(s) to reflect changes, and rerun CSG to update the assessment. CSG explores the possible attack paths for as-is or as-may-be system topologies. It uses MiniMax search to investigate how attackers react to defender actions. Finally, it performs a portfolio analysis to identify optimal risk reduction portfolios. Such computations are challenging for non- experts to perform consistently, especially without assisting tools. Implementing these in a tool form can help level the playing field for organizations that perform risk assessments, by reducing the need for risk assessment specialists and by producing artifacts that clearly capture the system, mission, threat and defense and assumptions that the assessment used. When remediating risks it is easy to over invest in defending one portion of the system at the expense of underinvesting in defending others. CSG combats this by looking across the entire set of incidents, and outcomes. It apportions defenses to reduce the risks systematically. Each step in the game attempts to mitigate the largest risks existing at that point in the game. At the same time, it looks some steps ahead to avoid making a locally greedy decision. Each defender move may cause attacking some other component(s) to have the largest payoff for an attacker. Therefore, CSG can answer important cybersecurity questions like, how much diversity is enough? CSG answers this by being able to diversify components until the best attacker move becomes one that attacks other components not being protected by diversity. At that point, in a game theoretic sense, additional diversity is wasted given that the attacker already has a higher payoff elsewhere. By exploring the game-tree, CSG portfolios are always balanced to reduce overall risk. When used with a decision target (i.e., reduce the risk by 70%) or a cost threshold (i.e., how much money one wants to spend), CSG can be used to determine whether the available set of defense methods can achieve some risk reduction target and identify the optimal set of defense methods needed to reach that target. If there is no a priori decision target, CSG can also be used to perform an entire portfolio analysis. This makes it possible to identify the Pareto frontier allowing the user to identify the optimal set of defense methods to use at each given price point, and to understand if and when there is a diminishing return on their investment. THIS PAPER HAS BEEN APPROVED FOR PUBLIC RELEASE; DISTRIBUTION UNLIMITED: 17-2021. The author's affiliation with The MITRE Corporation is provided for identification purposes only, and is not intended to convey or imply MITRE's concurrence with, or support for, the positions, opinions or viewpoints expressed by the author. REFERENCES [1] A. Cox, \"Some limitations of risk = threat vulnerability consequence for risk analysis of terrorist attacks.,\" vol. Vol 28, 2008. [2] R. Lagner, \"To Kill a Centrifuge,\" The Langner Group, 2013. [3] United States Senate Committee on Commerce, Science, and Transportation, \"A Kill Chain Analysis of the 2013 Target Data Breach,\" United States Senate , Washington, D.C., USA, 2014. [4] P. R. Garvey and S. H. Patel, \"Analytical Frameworks to Assess the Effectiveness and Economic- Returns of Cybersecurity Investments,\" in Military Communications Conference (MILCOM), 2014 IEEE, Baltimore, MD, USA, 2014. [5] L. Carin, G. Cybenko and J. Hughes, \"Cybersecurity Strategies: The QuERIES Methodology,\" Computer, vol. 41, no. 8, pp. 20 26, 2008. [6] S. Roy, C. Ellis, S. Shiva, D. Dasgupta, V. Shandilya and Q. Wu, \"A Survey of Game Theory as Applied to Network Security,\" in 43rd Hawaii International Conference on System Sciences (HICSS), Koloa, HI, USA, 2010. [7] A. Temin and S. Musman, \"A Language for Capturing Cyber Impact Effects. MITRE Technical Report MTR-10344,\" MITRE Corporation, Washington D.C., 2010. [8] S. Musman, A. Temin, M. Tanner, T. Fox and B. Pridemore, \"Evaluating the Impact of Cyber Attacks on Complex Missions,\" in 5th International Conference on Information Warfare and Security, Dayton, OH, USA, 2010. [9] S. T. A. Musman, \"A Cyber Mission Impact Assessment Tool,\" in Homeland Security Technologies Conference, Boston, 2015. [10] N. S. Jajodia S., \"Topological Vulnerability Analysis,\" Cyber Situational Awareness, Advances in Information Security, 2010. [11] L. Wang, S. Jajodia, S. A and S. Noel, \"k-zero day safety: Measuring the security risk of networks against unknown attacks,\" in European Symposium on Research in Computer Security, Athens, Greece, 2010. [12] S. Musman, M. Tanner, E. Elsaesser and L. Lewis, \"A Systems Engineering Approach to Crown Jewels Estimation and Mission Assurance Decision Making,\" in
Proceedings of the IEEE Symposium on Computational Intelligence in Cyber Security, Paris, France, 2011. [13] S. Musman, M. Tanner, A. Temin and E. Elsaesser, \"Computing the Impact of Cyber Attacks on Missions,\" in 2011 IEEE International Systems Conference (SysCon), Montreal, QC, 2011. [14] S. Musman and S. Agbolosu-Amison, \"A Measurable Definition of Resiliency Using \"Mission Risk\" as a Metric,\" MITRE Corp, McLean, VA, USA, 2014. [15] N. Dhanjani, B. Rios and B. Hardin, Hacking: The Next Generation, Sebastopol, CA: O'Reiley Media Inc., 2009. [16] S. Noel, J. Ludwig, P. Jain, D. Jhonson, R. Thomas, J. McFarland, B. King, S. Webster and B. Tello, \"Analyzing Mission Impacts of Cyber Actions (AMICA),\" in ATO IST-128 Workshop on Cyber Attack Detection, Forensics and Attribution for Assessment of Mission Impact, Istanbul, Turkey, 2015. [17] K. Nguyen, T. Alpcan and T. Basar, \"Stochastic games for security in networks with interdependent nodes,\" in International Conference on Game Theory for Networks, Istanbul, Turkey, 2009. [18] J. Jormakka and J. Jolsa, \"Modelling Information Warfare as a Game,\" Journal of information warfare, vol. 4, no. 2, pp. 12 25, 2005. [19] K. Sallhammar and S. Knapskog, \"Using Game Theory in Stochastic Models for Quantifying Security,\" in Proceedings of the 9th Nordic Workshop on Secure IT-systems , Espoo, Finland, 2004. [20] MSM, \"Making Security Measurable,\" 8 July 2013. [Online]. Available: https://makingsecuritymeasurable.mitre.org/. [21] T. Alpcan and T. Basar, \"A game theoretic analysis of intrusion detection in access control systems,\" in 43rd IEEE Conference on Decision and Control, Nassau, Bahamas, 2004. [22] J. Watters, S. Morrissey, D. Bodeau and S. Powers, \"The Risk-to-Mission Assessment Process (RiskMAP): A Sensitivity Analysis and an Extension to Treat Confidentiality Issues,\" MITRE, McLean, VA, USA, 2009. [23] S. Noel, J. S, O. B. and J. M. , \"Efficient minimum-cost network hardening via exploit dependency graphs,\" in Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC03), 2003. ABSTRACT\n INTRODUCTION\n THE CYBER SECURITY GAME\n Modeling Incident Impacts\n Modeling the Attacker\n Modeling System Topology and Applying the Attack Model\n Computing the Risk Score\n Modeling Defender Methods SUMMARY\n REFERENCES ",
    "text": " () Approved for Public Release; Distribution Unlimited: 16-4644. Interns Develop Aerial Refueling Planner (a Student Voices article) The Air Force's process for planning aerial refueling missions is one that requires planners to manually connect requests for fuel with available tankers. And once they've established the route, they need to input the refueling plans into a computer, which often takes many hours. Contractors have offered new desktop applications, but none have satisfied all the needs of the planners and become their primary tool for aerial refueling missions. During the summer of 2016, eight MITRE interns, along with one Air Force intern, developed a prototype electronic whiteboard solution. The Tanker Planner can enable the Air Force to take advantage of new technology while retaining the benefits of manually drawing out the routes, said project leader Chris Partridge. A Prototype for Developing \"What Ifs?\" With the new prototype, planners don't need to spend time writing requested routes on an actual whiteboard. That information goes straight from the requester into the Air Tasking Order Management System. This eliminates the need for data entry at the end of the planning process, said intern Ryan Aikman, a senior at the University of Denver. The interns also developed an \"easy button\" that enables the system to make an automated recommendation for the refueling plans, Partridge said. The recommendation takes into account fuel needs, optimal routes for planes to meet tankers, and air traffic concerns. The recommendation will likely make the process more efficient, even if planners opt to make adjustments based on weather reports or other information about the local environments, said Zack Schiller, a software applications engineer who mentored the interns. Even a small improvement to the refueling plans could save the Air Force millions of dollars each year, said Derek Lax, a software systems engineer who also mentored the interns. Tankers can take off at a higher weight than they can safely land. When they're left with excess fuel at the end of an operation, they either need to fly longer to burn it off or dump it. The feedback from the sponsor has been very positive, Partridge said. \"We're finding that it jars people out of that desktop mode. It's an interesting and new way to look at https://www.mitre.org/careers/student-programs/student-voices this type of data. It's fascinating when you see people use it. They'll crowd around it, and start doing \"what ifs?'\" In addition to demonstrating the planning application, this work gave MITRE interns experience building a solution that plugs into existing Air Force Command and Control (C2) systems to remove the need for time-consuming manual entry. The interns' work also helped MITRE identify interface gaps in these C2 systems for future improvements. by Jeremy D. Singer Approved for Public Release; Distribution Unlimited: 16-4644. ",
    "text": " () ALTERNATIVE PAYMENT ALTERNATIVE PAYMENT ALTERNATIVE PAYMENT ALTERNATIVE PAYMENT MODEL MODEL MODEL MODEL (APM) FRAMEWORK(APM) FRAMEWORK(APM) FRAMEWORK(APM) FRAMEWORK Final White Paper Written by:Written by:Written by:Written by: Alternative Payment ModelAlternative Payment ModelAlternative Payment ModelAlternative Payment Model Framework Framework Framework Framework and and and and Progress Tracking (APM FPT) Work GroupProgress Tracking (APM FPT) Work GroupProgress Tracking (APM FPT) Work GroupProgress Tracking (APM FPT) Work Group Final VersionFinal VersionFinal VersionFinal Version Version Date: [TBD]Version Date: [TBD]Version Date: [TBD]Version Date: [TBD] Approved for Public Release; Distribution Unlimited: 17-2546. 2 Table of Contents Executive Summary \n1 Please note that opinions expressed within the White Paper are those of the Work Group Members, not of the organizations with which they are affiliated. \n2 Please note that opinions expressed within the White Paper are those of the Advisory Group Members, not of the organizations with which they are affiliated. Approved for Public Release; Distribution Unlimited: 17-2546. 7 Clarify relationships between Advanced APMs under MACRA and categories in the LAN APM \nFramework (see discussion of Category 3 and Appendix A); Identify opportunities for small, rural, and safety net providers to increase APM adoption (see \nPrinciples 3 and 6); Consider a new framework category for the growing sector of integrated finance and delivery \norganizations (see discussion of Category 4); and Identify opportunities to modify the APM Framework in ways that expedite and simplify the \nprogress-tracking effort (see discussion of Category 2). Overview of Changes to the APM Framework and Its Supporting Principles The Advisory Groups deliberations tackled both foundational principles and APM classification conventions. With respect to foundational principles, the Advisory Group focused on the importance of viewing payment as a vehicle for driving delivery system transformation, and it closely reviewed key statements in the original White Paper to be sure they did not imply that payment reform was a goal unto itself. These discussions culminated in a new Principle 2, which articulates that payment reforms are only as successful as the delivery transformations they support. Advisory Group discussions also resulted in changes to the original Principles 2 and 5. First, they clarified that Category 2 APMs can be an endpoint for certain types of providers in specific markets. They also clarified that the strength of incentives should balance the potential for delivery system transformation against the risk of physicians taking on greater financial and insurance risk than they can manage. Figure 3, which illustrates the LANs national goals for payment reform, has been updated to reflect greater parity in clinical outcomes and cost management in Category 3 and Category 4 APMs. The Advisory Group believes that these changes address challenges that many small, rural, and safety net providers face when participating in APMs. The Advisory Group also carefully considered classification conventions used in the original APM Framework. Some of these discussions involved relatively minor modifications that would simplify and improve the LANs Progress Tracking efforts, such as the decision to consolidate Categories 2C and 2D into a single Category 2C for Pay-for-Performance. Other considerations included the need for additional patient protections in APMs with cost accountability. Accordingly, the Advisory Group decided to make appropriate care measures a requirement for Categories 3 and 4 APMs in order to give providers strong incentives to focus on eliminating care that does not help (and may harm) patients.3 The past several years have witnessed a considerable expansion of integrated finance and delivery systems i.e., joint ventures between insurance companies and health systems, insurance companies that own provider groups, and provider organizations that offer insurance products. Notable examples include not only Kaiser Permanente and Geisinger Health System, but also Vivity (a joint venture between Anthem and seven provider groups), the Allegheny Health Network (a joint venture between Highmark Blue Cross Blue Shield and the West Pennsylvania Allegheny Health System), the University of Pittsburgh Medical Center, Intermountain Healthcare, and the Henry Ford Health System. Integrated finance and delivery systems are also expanding rapidly in the Medicare Advantage (MA) market, where \n3 In this context, appropriate care measures cover topics such as unnecessary imaging, preventable hospitalizations, and adherence to clinical guidelines. Approved for Public Release; Distribution Unlimited: 17-2546. 8 roughly 60% of new MA plans are provider-sponsored.4 In light of this growth and the potential for these arrangements to better coordinate care, the Advisory Group thought it important to consider a new Category to track payments in these systems. Upon consulting with organizations that are making investments in these areas, the Advisory Group determined that integrated finance and delivery systems have the potential to help build organizational culture and investment strategies around population health management; support investments in key delivery infrastructure, such as care management, and health information technology; advance linkages to community organizations/community health; and promote alignment of value-based financial incentives among plans and providers. The Advisory Group therefore created a new Category 4C, which will enable further assessment of the effectiveness of these organizations in increasing the value of care through these more highly integrated arrangements. The APM Framework and MACRA are aligned in the goal of moving payments away from FFS and into APMs that reduce the total cost of care (TCOC) and improve the quality of care. Both MACRA and the APM Framework establish designations for APMs that consider the extent to which payments are based on value (as opposed to volume). For MACRA, Advanced APMs receive special consideration, and for the APM Framework, Categories 3 and 4 mark the goal for national payment reform. MACRA and the APM Framework also both aspire to take provider variability into account when making these designations, to ensure they are responsive to the manifold settings in which health care is delivered nationwide. Therefore, comparisons between the two systems for designating level of APM advancement, and the identification of potential incongruities, offer an opportunity to properly designate payment arrangements for particular providers that are specially designed to reward high-value care. With one exception, all Advanced APMs under MACRA were classified in Categories 3 and 4, according to the original APM Framework. However, the two designation systems inconsistently classified the flagship CMS CPC+ Track 1 program, which fell into Category 2 in the original APM Framework. The Advisory Group therefore considered new conventions for Category 3, which highlighted opportunities for the LAN to adopt more nuanced criteria that better reflect the lessons CMS learned about implementing primary care APMs for the Medicare population. Specifically, CPC+ Track 1 showed that utilization measures can be expected to establish shared-savings arrangements without a formal financial benchmark when smaller primary care providers are unable to bear much financial risk. This type of arrangement may not be appropriate in all settings or market segments, and it will be important to evaluate whether it achieves its intended results for smaller primary care practices. However, the Advisory Group decided that CPC+ Track 1s utility for introducing cost accountability to primary care physicians taking care of the Medicare population warranted its inclusion in Category 3. Although there will be differences in the specific criteria that MACRA and the APM Framework use to categorize APMs,5 this modification will achieve complete alignment between designations made by MACRA and the LAN \n4 Avalere. Provider-Sponsored Health Plans: Enrollment, Quality, and Future Impact. Available at: http://go.avalere.com/acton/attachment/12909/f-0290/1/-/-/-/-/20160119_Aetna%20PSP%20Paper.pdf. \n5 Whereas both the APM Framework and MACRA focus on the structural elements of APM design, MACRA focuses more on specific technical requirements. For instance, MACRA highlights the intensity of risk as a distinguishing factor between APMs and Advanced APMs by quantifying a more than nominal amount of financial risk. Under the APM Framework, risk differentiates APMs (i.e., between a 3A and 3B classification), but the precise magnitude of risk is not specified. Approved for Public Release; Distribution Unlimited: 17-2546. 9 Framework, such that all Advanced APMs under MACRA fall into Categories 3 and 4 in the updated Framework. Taken together, these changes to the original APM Framework reflect experiences and developments that have occurred since the original White Paper was initially released. The updates will help ensure that the APM Framework remains fundamental for payment and delivery reform. Changes are embedded in this refreshed White Paper in order to maintain a single source for the LANs perspectives on APM classification and goals for payment reform. The Advisory Group has incorporated public comments that it received, and it thanks all commenters for taking the opportunity to provide input on this work. The Case for Reforming the Health Care Payment System Like many health care stakeholders, the LAN is committed to driving payment approaches that improve the quality and safety of care, and the overall performance and sustainability of the U.S. health system. Collectively, we believe that making a positive impact on patient care and health should be the ultimate goal of payment reform, and we envision a health care system that provides person-centered care. For the purposes of this paper, and recognizing that the term may encompass additional characteristics that are not captured below, person-centered care means patients and their care teams form partnerships around high-quality,
accessible care, which is both evidence-based and delivered in an efficient manner, and in which patients and caregivers individual preferences, needs, and values are paramount. Person- centered care, so defined, rests upon three pillars: Quality: This term indicates that patients receive appropriate and timely care that is consistent \nwith evidence-based guidelines and patient goals, and that results in optimal patient outcomes and patient experience. Measures of performance and impact should be meaningful, actionable, and transparent to consumers, patients, family caregivers, and other stakeholders. Ideally, quality should be evaluated using a harmonized set of appropriately adjusted process measures, outcome measures, patient-reported outcome measures, and patient experience measures that together provide an accurate and comprehensive assessment of clinical and behavioral health. Measure scores should also be meaningfully accessed, understood, and used by patients and consumers. Efficiency: Eliminating waste and delivering affordable, appropriate health care services, are vital \nfor ensuring that the nation can support investments in education, housing, and other social determinants that can independently improve population health. This term indicates the degree to which services, care delivery models, and payment arrangements achieve the core outcome goals of patients, providers, payers, and purchasers in relation to their costs. Care that is less expensive than expected but that results in poor clinical outcomes is not considered efficient. Conversely, care that is unavoidably costly but results in dramatic improvements in patient outcomes is considered efficient. For purchasers, efficiency (and, therefore, value) might mean comprehensive care services that support the health and productivity of their workforces. For payers, efficiency might mean adjusting reimbursements to incentivize the delivery of care that achieves outcomes that matter to patients, thereby improving adherence to care plans, decreasing acute episodes that require emergency room visits or hospitalization, and lowering overall costs by reducing utilization of services that do not achieve desired outcomes. For providers, efficiency might mean aligning payment rates and incentives to reinforce best practices and remove undesirable incentives for Approved for Public Release; Distribution Unlimited: 17-2546. 10 low-value care that does little to achieve patients goals. And lastly, for patients, efficiency is about achieving the outcomes that matter to them in a manner that is affordable and accessible. Collaborative Patient Engagement: This term encompasses the important aspects of care that \nimprove patient experience, enhance shared decision making, and ensure that patients and consumers achieve their health goals. Patient engagement should occur at all levels of care delivery: with patients and caregivers serving as partners when setting treatment plans and goals at the point of care; when designing and redesigning delivery and payment models; on governance boards and decision making bodies; and when identifying and establishing connections to social support services. Collaborative engagement involves partnering with patients and consumers so they can be informed of their health status and share in their own care; easily access appointments and clinical opinions; seek care at the appropriate site; possess the information they need to identify high-value providers and to tailor treatment plans to individual health goals; provide ongoing feedback that providers can use to improve patient experience; obtain transparent price information from their health plan about services and evidence of their value for patients and consumers based on individualized characteristics and goals; and move seamlessly among providers that are engaged in different aspects of their care. Routine communication with family caregivers and other support members is also a critical part of comprehensive, person-centered care. As evidenced by the LAN itself, there is an emerging consensus among providers, payers, patients and consumers, purchasers, and other stakeholders that efforts to deliver person-centered care have been stymied, to a large degree, by a payment system that is oriented toward paying for volume, as opposed to value for patients and caregivers. These stakeholders agree that reconfiguring payments to incentivize value, and ensuring that valuable activities (e.g., care coordination) are compensated appropriately, will better enable providers to invest in care delivery systems that are more focused on patient needs and goals. In other words, changes in payment are necessary (though insufficient on their own) to drive delivery system transformations, which ensure that health care costs reflect appropriate and necessary spending for individuals, government, employers, and other payers. Shifting from traditional FFS payments (i.e., claims-based payments that are not linked to quality or value) to population-based payments (in which all or much of a persons overall care or care for related conditions is encompassed within a single payment), is a particularly promising approach to creating and sustaining delivery systems that value quality, cost effectiveness, and patient engagement. Such payments should therefore include accountability for the quality of care delivered to patients, rather than incentivizing providers to increase the volume of services they provide. Although it is not yet possible to reach a definitive, evidence-based conclusion about the impact of population-based payments on patient care, there is a widespread belief that these types of payment models hold substantial promise. This is because population-based payments give providers more flexibility to coordinate and optimally manage care for individuals and populations. In combination with substantially reduced incentives to increase volume, and stronger incentives to provide services that are currently undervalued in traditional FFS, there is a consensus that this flexibility will expedite fruitful innovations in care delivery, particularly for individuals with chronic, complex, or costly illnesses. At present, traditional FFS payments are ill suited for initiating investments and sustaining population health management innovations, such as information technology, clinical decision support tools, patient engagement and care coordination functions, and additional opportunities to increase access to care Approved for Public Release; Distribution Unlimited: 17-2546. 11 (e.g., payments for telehealth, home visits, group visits, and additional office hours). This is because traditional FFSs price per unit of service system incentivizes providers to produce revenue by increasing volume, which can encourage unnecessary and harmful care. Population-based payments may enable providers to develop more innovative approaches to person-centered health care delivery, because they reward providers that successfully manage all or much of an individuals care. Innovative approaches to health care delivery stand to benefit patients and society alike, with patients coming to expect a more coordinated, more accessible, and more effective health care system, and the nation benefiting from reductions in national health care expenditures thanks to a healthier, more productive population. New payment models require providers to make fundamental changes in the way they provide care, and the transition away from FFS may be costly and administratively difficult, even though new payment models will be more efficient over the long term. Participation in shared-risk and population-based payment models involves financial risk for providers, and not all provider organizations currently possess the capacity to successfully operate in these payment models. Such providers will need assistance to develop additional capabilities. To smooth and accelerate this transition, a critical mass of public and private payers must adopt aligned approaches and send a clear and consistent message that payers are committed to a person-centered health system that delivers the best health care possible. If providers were able to participate in APMs that were consistently deployed across multiple payer networks, the administrative burden of making the transition would be reduced and investments could be applied to all patient populations, independent of payer. Aligned payment approaches and performance metrics from a critical mass of payers would enable providers to establish an infrastructure that would increase the likelihood of success for innovative delivery systems over the long term. The adoption and diffusion of these innovative delivery systems should ultimately improve the quality, efficiency, safety, and experience of patient care, while becoming sustainable business models for providers that are eager to take a more comprehensive and coordinated approach to health care delivery. Safeguards will be needed to ensure that quality and patient engagement are not sacrificed to reduce costs, and that the care delivered is state of the art and takes advantage of valuable advances in science and technology. It will also be important to take into account the time physicians spend on administrative tasks. Physicians already spend as much time doing desktop medicine as they do interacting face-to-face with patients.6 Given the weight of the current administrative burden, particularly in primary care, it will be important to design APMs in a way that minimizes the time providers spend on administrative tasks, and restores this to time spent interacting with patients. In order to mitigate the possibility of these and other unintended consequences, it will be essential to monitor the impact of population-based payment systems on patient outcomes, affordability, and other indicators of significance to patients and other stakeholders in the health care system. This shift to person-centered, population-based payment should properly be viewed as a course correcting feedback loop between innovation, implementation, and evaluation. However, the LAN firmly believes that a shift to person-centered, population-based payments will, in concert with significant delivery system reforms, result in an acceleration of high-value care in the United States. As discussed in the next section, the APM Framework will provide a valuable tool in accelerating this process. \n6 Ming T.S. et al. (2017). Electronic Health Record
Logs Indicate That Physicians Split Time Evenly Between Seeing Patients And Desktop Medicine. Health Affairs, 36(4), 655-662. Approved for Public Release; Distribution Unlimited: 17-2546. 12 Purpose of the White Paper To accelerate the transformations described above, the LAN created an APM Framework through which to describe and measure progress toward payment reform. In addition to providing a roadmap to measure progress, the APM Framework helps establish a common nomenclature and a shared set of conventions that can facilitate discussions among stakeholders and expedite the generation of an evidence base for evaluating the capabilities and results of APMs. This White Paper begins by describing the approach used to develop the APM Framework, followed by the principles upon which the APM Framework is based. With these principles in mind, the White Paper differentiates categories within the APM Framework by explaining how they are defined and where their boundaries lie. The White Paper concludes with a summary of key findings and recommendations, as well as recommendations for how various stakeholders can use the APM Framework to accelerate payment reform. To further clarify the classification of individual APMs, the Work Group has separately released a collection of APMs that are currently in use as of January 2016. Approach When developing the APM Framework, the Work Group began with the payment model classification scheme that CMS originally advanced,7 and expanded it by introducing refinements that are described in more detail below. As illustrated in Figure 2, the CMS Framework assigns payments from payers to health care providers to four Categories, such that movement from Category 1 to Category 4 involves increasing provider accountability for both quality and TCOC, with a greater focus on population health management (as opposed to payment for specific services). \n7 Rajkumar R., Conway P.H., and Tavenner M. (2014). CMS: Engaging multiple payers in payment reform. JAMA, 311(19), 1967-8. http://hcp-lan.org/workproducts/apm-whitepaper-addendum.pdf Approved for Public Release; Distribution Unlimited: 17-2546. 13 Figure 2: CMSs Original Payment Model \nThe Work Group added to and refined the CMS model by: 1) articulating key principles to explain what the APM Framework does and does not mean to convey; 2) introducing four new Categories to account for payment models that are not considered progress toward payment reform; 3) introducing eight subcategories to account for nuanced but important distinctions between APMs within a single Category; 4) delineating explicit decision rules that can be used to place a specific APM within a specific subcategory; and 5) compiling, with the help of the LAN, examples of APMs that illustrate key characteristics of each of the subcategories. Key Principles for the APM Framework The APM Framework is predicated on several key principles. To provide context for understanding the Framework and recommendations, these principles are delineated and explained below. Approved for Public Release; Distribution Unlimited: 17-2546. 14 Principle 1: Changing payment to providers is only one way to stimulate and sustain innovative approaches to the delivery of person-centered care. In the future, it will be important to engage patient representatives in aspects of model design, and monitor progress in initiatives that empower patients to seek care from high-value providers (via performance metrics, financial incentives, and other means) and to encourage patients to become more active participants in shared decision-making. Although it was necessary to focus on financial incentives for providers as a critical first step, additional efforts to engage patients and consumers will be needed to achieve a high-value, coordinated health care system. As more providers begin to participate in payment models that are divorced from traditional FFS, all stakeholders will need to collaborate on approaches to empower patients to become active partners as they strive to achieve their health goals. This includes engaging patients in ways that match their needs, capacities, and preferences. Such approaches may include strategies to clearly and meaningfully communicate, to patients and consumers, information about provider and health plan performance on clinical and patient experience measures; provide financial rewards for patients and consumers who select high-value providers and chronic disease management with interventions that achieve outcomes that matter to patients; and enlist patients and caregivers as partners in setting health goals and developing treatment plans. This includes giving patients direct access to evidence- based tools that allow them to better understand their condition, preferences, and treatment options, as well as the benefits, risks, and out-of-pocket costs for each. Consumers, patients, families, and their advocates should be collaboratively engaged in aspects of design, implementation, and evaluation of payment and care models, and they should be engaged as partners in their own care. As models become more advanced in value-based payment, the corresponding care models should more comprehensively reflect the delivery of true person-centered care and meaningful partnership with patients and families. To avoid unintended consequences associated with APMs, it is essential for payment models to include safeguards to prevent selection against individuals with more complex illnesses or greater need for social support, and patients and consumers should be informed of providers financial incentives in APMs. Additional activities and monitoring will also be needed to ensure that the expansion of population-based payments does not lead to inequities in health outcomes or to a decline in access to care. APMs should therefore collect data that allows for assessment of differential impacts on, and the identification and redress of, disparities in health, health outcomes, care experience, access, and affordability. Principle 2: Reformed payment mechanisms will only be as successful as the delivery system capabilities and innovations they support. APMs therefore need to be predicated on knowledge about how specific payment mechanisms drive new models and improvements in care delivery. Approved for Public Release; Distribution Unlimited: 17-2546. 15 Payment reform is necessary, but not sufficient on its own, for transforming the current volume-based health care system into a system that rewards providers for delivering value-based, person-centered care. This is because the relationship between APMs and the value they are intended to generate is neither deterministic nor universally applicable across provider types and patient populations. For example, payment mechanisms that are appropriate for advanced, highly integrated health systems may have different outcomes in safety-net hospitals or small primary care practices serving rural communities. The characteristics of the patient population can also be an important factor in the success of a given payment model. For example, social determinants and social needs have a much higher impact on some populations, so payments that often effectively address these needs may not work as well in different populations. For these and other reasons, it is important to base APM design on the best available evidence and information about how to optimize care delivery, and to identify payment mechanisms that are capable of stimulating infrastructure investments that maximize value (i.e., deliver the best possible quality and experience of care within the constraints of available resources) in specific clinical settings. Ultimately, positive impact on patient care and health should be paramount. Because delivery system improvements drive the production of value in the health care system, it is important to identify evidence-based best practices for delivery components that have been demonstrated to improve care. Empirical evidence on the effectiveness of particular delivery components and competencies is still emerging, but several compendiums of best practices and essential components are beginning to be understood. For example, the Peterson Center on Healthcare and Stanford Universitys Clinical Excellence Research Center identified 10 characteristics of high-value primary care providers, based on their analysis of 11 practices that provide exceptionally high-value care. Among other activities, these practices increase accessibility through after-hours calls and same- day appointments, provide the most support to patients who need it, refer patients to a selective list of specialists who share their commitment to value, and employ multidisciplinary care teams that work at the top of their licenses.8 Similarly, the Accountable Care Learning Collaborative (ACLC) identified competencies that are essential for the success of accountable care organizations (ACOs), based on their review of the evaluation literature.9 Broken into seven categories (i.e., governance and culture, financial readiness, health IT, patient risk assessment, care coordination, quality, and patient-centeredness), ACLCs proposed list of competencies include: Align quality improvement initiatives with ethical obligations; \n Measure shared savings and cost sharing between providers and payers; \n Present useful and usable decision support at the point of care; \n Offer access to and integrate with behavioral health services; and \n Invest in health IT that optimizes your quality improvement and safety efforts.10 \n8 Peterson Center on Healthcare. Identification: Uncovering Americas Most Valuable Care. Retrieved from http://petersonhealthcare.org/identification-uncovering-americas-most-valuable-care \n9 Accountable Care Learning Collaborative. ACLC Competencies. Retrieved from https://www.accountablecarelc.org/aclc-competencies \n10Accountable Care Learning Collaborative. Inaugural List of Competencies Spreadsheet. Available at https://www.accountablecarelc.org/sites/default/files/ACLC%20Competencies%20for%20Public%20Comment%20 FINAL_0%20%284%29%20-%202.16.17.xlsx Approved for Public Release; Distribution Unlimited: 17-2546. 16 Payment mechanisms should be selected based on assumptions of how APMs will catalyze the development of essential delivery components and competencies for specific patient populations and provider organizations. Given the relative lack of national experience with APMs, and the time it takes to obtain results from rigorous evaluation studies, there is not at present a large volume of evidence on the relationship between
specific payment mechanisms and their impact on delivery system design. However, CMMI has published a helpful list of factors that model designers should take into account (such as alignment with goals for delivery-system reform and extent of clinical transformation in model design) when selecting payment mechanisms.11 Additionally, typologies of payment mechanisms can provide useful insights into the economic incentives inherent in particular payment approaches.12 In addition to obtaining information about others experience implementing APMs, such as through the LANs Action Collaboratives and other multi-stakeholder networks, model designers can draw on these conceptual resources as results from program evaluations emerge. Principle 3: The goal is to effectively transition health care payments from fee for service toward payment mechanisms that are better designed to promote the triple aim of healthier people, better care, and smarter spending, and this can include Category 2C APMs in certain cases. However, in order to achieve improvements in care coordination and support high-quality, evidence-based care, the majority of national spending should continue moving into Category 3 and 4 shared-risk and population- based payment models. The overarching objective of the LAN is to encourage multi-payer alignment between and within the public and private sectors, as the health care system moves away from traditional FFS payment and into payment and delivery approaches that are better suited for promoting high-quality, effective care. It is useful to view this transition as a journey with origins, way stations, and destinations, both for individual providers and for national spending as a whole. Providers at the early stages of the journey may benefit from infrastructure payments to support investments in delivery components that are needed to successfully manage population health and spending. For example, primary care practices may need dedicated care managers, care coordinators, community liaisons, and practice managers, while improving health information technology and data analytic capabilities and offering additional ways to access care around the clock. Although infrastructure investments to support these sorts of activities can be considerable, providers can obtain \n11 The Centers for Medicare & Medicaid Services. Alternative Payment Model Design Toolkit. Available at https://aspe.hhs.gov/system/files/pdf/234386/CMMIAPMToolkit.pdf \n12 See, for example: Berenson R.A., Upadhyay D.K., Delbanco S.F., and Murray R. (2016). A Typology of Payment Methods. Retrieved from Urban Institute website at http://www.urban.org/sites/default/files/publication/80 -A-Typology-of-Payment-Methods.pdf; and Spector J.M., Studebaker B., and Menges E.J. (2015) Provider Payment Arrangements, Provider Risk, and Their Relationship with the Cost of Health Care. Retrieved from the Society of Actuaries website at https://www.soa.org/research-reports/2015/2015-provider-payments-arrangements-risk/. Approved for Public Release; Distribution Unlimited: 17-2546. 17 funding from a variety of sources, including per-member-per-month payments from insurers, their own cash reserves, capital markets, and investment funding from companies that give providers tools and resources to engage in population health management. Irrespective of their source, these initial infrastructure payments should be designed to enable early-stage providers to move into and succeed in Category 2C arrangements (pay-for-performance) by providing high quality health care for their patients. For example, CMS Multi-Payer Advanced Primary Care Practice model provides Category 2A infrastructure payments for primary care practices to transform into patient-centered medical homes (PCMHs). Similarly, Aetnas PCMH Recognition Program provides a per-member-per-month fee to support investments in care coordination and quality of care.13 Certain types of providers face structural constraints and will require extensive technical and financial support to move into and beyond Category 2C arrangements. For example, some providers have difficulty accessing debt markets, cash reserves, and other sources of infrastructure funding needed to initiate the transition to APMs. Other providers lack experience with population health management, face geographic barriers to care integration and coordination, or do not care for enough patients to adequately manage clinical risk. In general, providers who face structural constraints tend to be physicians in solo and small group practices, small and medium-sized primary care practices, rural providers, and safety net providers. Some providers facing structural constraints will be able to undergo this transformation on their own, in a way that meets their needs and the needs of their patients. New organizations are emerging which provide management services capabilities to some of these clinical practices. There are many options for practices to come together and form partnerships that support shared infrastructural investment and financial risk, which will improve care and enable success in Category 2C and more advanced payment arrangements. For example, providers can form regional collaboratives to share delivery infrastructure and launch joint care coordination and quality improvement initiatives. Providers can also enter into gain-sharing arrangements with companies that specialize and invest in population health management. In addition to providing practices with investment capital for infrastructure development, these types of companies provide practice management support, in the form of data analytics, assistance with practice transformation, and resources to improve care integration and coordination. In return for investments and technical assistance, these companies share in the financial gains the practices produce, which further aligns payers and purchasers around value-based (as opposed to volume-based) incentives for care delivery. Furthermore, smaller provider organizations can join together to achieve panel sizes large enough to allow providers to assume clinical risk they are able to manage. This can be accomplished by entering into contracts with population health management organizations, and in the future it could be accomplished through the formation of virtual groups, such as those that will be available in CMS Merit-Based Payment System and CareFirsts PCMH program. Both of these options provide a pathway for small groups to aggregate and receive collective score accountability (even though they may not share in the management of a common group of patients). Irrespective of how it is accomplished, moving structurally constrained providers (especially safety net providers) into Category 3 and 4 APMs \n13 ASPE. (2016). Examples of Health Care Payment Models Being Used in the Public and Private Sectors. pp. 60-63. Available at https://aspe.hhs.gov/system/files/pdf/208761/ExamplesHealthCarePaymentModels.pdf. Approved for Public Release; Distribution Unlimited: 17-2546. 18 will be critical for achieving the transformations necessary to bend the cost curve and meet the triple aim. Therefore, it will be important to address barriers that today may seem insurmountable. In addition to steps providers can take on their own, impactful reforms to the fee schedule would go a long way toward accelerating the pace of payment and delivery reform. Assigning values to services (particularly primary care services) that are based on a true indication of their impact over the long term would considerably benefit structurally constrained providers. In particular, primary care plays a critical role in achieving efficiencies for the health care system as a whole, but is undervalued in current FFS; this problem will not be solved by simply adding more codes for services such as chronic care management or behavioral health. Reforming fee schedules is important because FFS is a vital component of many APMs, which would also benefit from a reformed fee schedule. For some structurally constrained providers (i.e., providers facing the structural constraints described above), Category 2C arrangements may support continuous delivery system improvement and therefore constitute an ultimate payment reform destination. For example, Category 2C payments may be ideally suited for driving increases in underutilized preventive services. However, for providers who do not face structural constraints, Category 2C should be a way station on the pathway to Category 3 and 4 arrangements, which offer additional opportunities to improve the management of population health and target spending on care that patients value. The Work Group believes these structural constraints are not pervasive and therefore will not constitute a barrier for the majority of providers to eventually move into Categories 3 and 4, as illustrated below in Figure 3. Approved for Public Release; Distribution Unlimited: 17-2546. 19 Figure 3: Payment Reform Goals * Note: The values presented in the above current state graphic are based on available data on private plans from Catalyst for Payment Reform and Medicare FFS allocations. This graphic is meant to represent recommendations for how the health care system should change, and it accounts for the likely impact of Medicares Quality Payment Program and private initiatives. Values displayed in the graphic are not precise, and will depend on delivery capabilities, as described elsewhere in this document. The size of the various circles represents spending across various types of payment models. Payments are expected to shift over time from Categories 1 and 2 into Categories 3 and 4. Additionally and over time, APMs within a particular category will increase the extent to which payments are linked to provider accountability, enable more innovation in care, make a greater impact on quality and cost performance, increase coordination in delivery systems, and result in more value-based care. Moving national spending into Categories 3 and 4 is critical for several reasons. First, given the already negative impact ineffective health care spending is having on businesses and the national economy, purchasers cannot be expected to indefinitely subsidize infrastructure without a return on investment in the form of improved cost and quality performance. Second, absent accountability for cost, utilization, and appropriate care, FFS is incompatible with person-centered care delivery, because Category 2C payments do not incentivize providers to efficiently distribute resources to the patients for
whom improved care can lead to significant cost savings, or to adopt measures to reduce the use of low-value care. Third, FFS is not conducive to the pursuit of care delivery innovations that are capable of better addressing complex issues, such as social determinants of health and care management for patients with multiple chronic conditions. This is because solutions to these types of issues require considerable coordination beyond the walls of the clinic or hospital, which cannot realistically be itemized on a fee schedule. By supporting successful initiatives to address social determinants and chronic comorbidities, value-based payments can improve, but not completely remediate, outcomes related to patients complexities. Approved for Public Release; Distribution Unlimited: 17-2546. 20 As illustrated in Figure 3, Category 4 APMs have the potential to give providers additional opportunities and flexibility when establishing and maintaining delivery system components that improve the value of care (compared to Category 3 APMs). This is because Category 4 APMs provide stronger incentives to decrease costs while using quality and appropriateness-of-care measures to hold providers accountable for maintaining or improving quality standards. Category 4 APMs can also be more administratively efficient to pay providers prospectively, instead of reimbursing each individual claim and undergoing an extensive retrospective reconciliation at the end of the performance period. However, individual providers should not feel compelled to enter Category 4 arrangements if they believe doing so could adversely impact practices and patients. As discussed in Principle 6, providers should only assume as much risk as needed to maximize the value of care delivered, which means Category 3 will serve as an ultimate destination for some providers. Above all, the systemic imperative to move payments into Categories 3 and 4 will need to be balanced against individual providers readiness to change payment and delivery models. Striking the proper balance between these potentially conflicting priorities will require considerable trust amongst all stakeholder groups, in order to move at the best pace for patients and consumers. Principle 4: To the greatest extent possible, value-based incentives should reach providers across the care team that directly delivers care. Payment reforms for quality improvement and cost reduction are most effective when they directly impact payments for clinicians who are principally responsible for providing care to patients. These incentives are effective because providers delivering patient care are best positioned to develop processes and practices, which drive well-coordinated, and high-value care that ultimately lead to better outcomes. For example, an ACO that is at risk for cost and quality would ideally design financial incentives for physicians and their care teams and hospitals that achieve outcomes that matter to patients. It may not always be possible to measure accurately the degree to which incentive payments reach front-line providers. Nevertheless, this should become a best practice, because making population-based payments to provider organizations that, in turn, pay care teams on an FFS basis will not harness the full potential of the incentives in the APM. This is particularly important in light of the recent growth in physician employment, because employed physicians often do not receive performance feedback directly.14 The question of how far incentive payments should reach, and whether it is appropriate for individual clinicians to receive incentive payments, raises difficult and complicated issues. On the one hand, it is essential to reward clinicians who deliver high-value, person-centered care, because they are the ones who work directly with patients to achieve positive outcomes. On the other hand, risk-adjustment methodologies and illness severity scales do not always sufficiently account for patient complexity, so rewarding individual providers could unintentionally encourage adverse selection against patients with complex medical needs. Additionally, when compared to financial incentives for practices or physician \n14 See, for example: Farmer S., Darling M.A., George M., Casale P.N., Hagan E., and McClellan M.B. (2017). Existing and Emerging Payment and Delivery Reforms in Cardiology. JAMA Cardiology, 2(2), 210-217. Approved for Public Release; Distribution Unlimited: 17-2546. 21 groups, financial incentives for individuals may not be reinvested as much in improvements to care delivery. Therefore, APMs need to carefully evaluate incentive structures for provider groups and individual clinicians, to ensure that there are sufficient protections for complex patients, that individual clinicians are fairly compensated for delivering exemplary care, and that incentive payments are used to sustain delivery system transformations. Additional patient protections such as independent oversight and robust venues for voicing patient concerns may also be needed during the transition from FFS to population-based payment. Principle 5: Payment models that do not take quality and value into account will not be designated as value-based. They will not be considered APMs for the purposes of tracking progress toward payment reform. As illustrated in Figure 4, the APM Framework represents a continuum of payment approaches across four Categories. Category 1 represents FFS payment not linked to quality incentives. Categories 2 through 4 advance successively beyond traditional FFS payment. There is limited merit in moving toward population-based payments if the resulting payment models do not include incentives to deliver quality care based on current clinical evidence on how to achieve outcomes that matter to patients. Although specific recommendations about what constitutes meaningful quality measurement is beyond the scope of this paper, several general elements are critical. APMs should use harmonized measure sets that include measures of process, clinical outcomes, patient-reported outcomes, and patient experience of care. Quality measures should be appropriately adjusted for patient mix, and whenever possible the measures used should be nationally vetted and endorsed by professional organizations, the National Quality Forum, the Core Quality Measures Collaborative, and others involved in developing consensus on measure specifications and core sets. Measure sets should also be robust enough to provide a comprehensive portrait of a populations clinical and behavioral health. Measure sets should address the full spectrum of care, care continuity, and overall performance of specific models, but individual measures should be granular enough to enable patients to make informed decisions about providers and treatments. Payment models that represent some movement away from traditional FFS, but do not take quality and appropriateness into account, will be placed under the corresponding payment category and marked with an N to indicate No Quality considerations (e.g., population-based payments not linked to value will fall into Category 4N). Accordingly, such models will not be considered to represent progress toward true payment reform, and are not tracked as part of measuring the achievement of the LANs goals. Approved for Public Release; Distribution Unlimited: 17-2546. 22 Principle 6: In order to maximize the value of care that providers deliver and to reach the LANs goals for payment reform, value-based incentives should be sufficiently meaningful for providers to invest in and implement delivery reforms, without subjecting providers to risk that is beyond their financial means and/or clinical scope of care. When considering approaches to making value-based incentives meaningful for providers, it is useful to distinguish between two kinds of risk even though they are difficult to separate in practice (for further discussion, please see the description of Category 4 APMs below): management risk, and insurance risk. There is widespread agreement on three different principles about how risk should be deployed in APMs. First, individual providers should not be placed in the position of assuming insurance risk, because payers and large health systems are specifically designed to perform this function. Second, APMs can be effective stimuli for delivery system change because providers will develop and sustain innovative approaches to care delivery when they are subjected to certain levels of management risk. Third, excessive levels of management risk can lead to perverse consequences, such as the delivery of inappropriately intensive care (either too much or too little), and potential access problems if critical provider groups are forced out of business. Therefore, value-based incentives should avoid imposing insurance risk on providers, while seeking to find the optimal degree of management risk to maximize beneficial drivers of health care transformation and simultaneously minimizing counterproductive drawbacks. When striking this balance, the overarching objective should be to maximize the value of care for patients and consumers: levels of management risk should not be based on goals for payment reform that are dissociated from goals for improving care delivery. When considering levels of management risk, it is important to consider attributes of the providers who will assume that risk. For example, compared to small providers, large providers are better equipped to manage financial risk by making service adjustments. Therefore, management risk will need to be higher for large providers to make meaningful transitions to value-based care delivery. Similarly, factors such as practice size, availability of cash reserves, provider readiness, scope of practice, and geography can all impact the amount of financial risk that providers are able to bear. Safety-net providers experience considerable volatility in their financial margins and typically have to operate without substantial cash reserves; these factors make it difficult and potentially counterproductive for them to take on significant amounts of performance and financial risk. Practices with a large scope and diversity of care will have greater influence over the total costs of care for its
population, which means they are able to assume Types of risk for providers in APMs Management or clinical risk: Potential monetary losses or gains for providers, based on quality and cost performance that providers can reasonably manage with the proper safeguards in place (e.g., risk adjustment, stop loss and other mechanisms). Insurance or actuarial risk: Unpredictable outcomes or losses, which result from outlier patients in a providers panel who have unusual and expensive conditions. Approved for Public Release; Distribution Unlimited: 17-2546. 23 more financial risk than practices that provide a narrower scope of care. Small and rural practices face similar constraints, in addition to the challenges associated with establishing coordinated networks of care over large geographical regions, which means they also may only be able to assume limited amounts of financial risk.15 As discussed above in the context of Principle 3, these types of providers may be able to contract with population health management companies and take other steps to increase the amount of performance and financial risk they are able to assume. Irrespective of which mechanism is used, it is essential for providers to have as much flexibility as possible to determine the amount of financial risk they can assume. Contract negotiation between providers and private payers offers a suitable mechanism for flexibly selecting appropriate levels of risk for specific provider organizations. For public payers, the statutorily mandated use of rulemaking to select risk levels for all providers participating in a given payment model somewhat reduces this flexibility. However, this standardized approach is offset considerably by the wide variety of Medicare APMs that are available for providers, which allows providers to select APMs with risk levels that are appropriate for them. In both the public and private markets, model transparency is critical, because providers cannot tailor financial risk without knowing the financial characteristics of the models in which they participate. As providers obtain greater experience in advancing quality while managing costs, and as infrastructure investments begin to generate cost savings, it may be desirable to increase performance and financial risk. However, decisions to do so should be based on the performance and stability of health care delivery systems, and not dictated solely by economic imperatives to decrease costs. Categories in the APM Framework are drawn around qualitatively different approaches to risk, and provider risk increases from one category to the next. Nevertheless, the Framework does not consider the precise, quantitative level of risk within each qualitative approach, because there is not a right level of risk or reward that will maximize value for all providers. For example, a 10% shared-savings arrangement is classified the same as a 2% shared-savings arrangement. Principle 7: For tracking purposes, when health plans adopt hybrid payment models that incorporate multiple APMs, the payment dollars will count toward the category of the most dominant APM. This will avoid double counting payments through APMs. A particular payment model may utilize several APMs concurrently, especially as the model is evolving. For example, an ACO may utilize a shared-savings model in years one and two along with nominal pay for performance incentives, and then transition to a shared-risk model in year three. To track progress in such hybrid cases, the entire payment model will be placed in the category that best captures the \n15 Certain approaches to operationalizing financial risk may also impede providers ability to assume it, irrespective of particular provider characteristics. For example, recouping savings from efficient providers too quickly can disincentivize efforts to generate such savings. Similarly, short contract cycles can have the effect of disincentivizing long term investments in preventative care, which can yield significant improvements in health outcomes and cost savings over the course of decades. Approved for Public Release; Distribution Unlimited: 17-2546. 24 dominant APM (in this case, shared savings for years one and two, and shared risk in year three). It is also possible that bundled payments may be used within upside/downside risk, and population-based payment models, and that a PCMH may be supported by FFS-based care coordination fees, pay for performance, and shared savings. In these and other scenarios, payment dollars will count toward the most dominant APM in use, meaning the APM to which the greatest amount of incentive payments are directed. In classifying APMs on the basis of their constituent payments, it is important to note that when incentive payments are linked to a FFS architecture (e.g., bonuses of quality in Category 2C or shared savings payments in Category 3A), the most advanced incentive payment and FFS payment are considered together to determine which payment is dominant. For example, if 40% of payments in an APM entail FFS with a link to quality, and 60% of the payments are population-based, then the APM would be classified in Category 4. Similarly, an APM that includes a shared-savings component will be considered 3A, even if the shared-savings payment is less than the payment for quality. Principle 8: Centers of excellence, patient-centered medical homes, and accountable care organizations are delivery models, not payment models. In many instances, these delivery models have an infrastructure to support care coordination and have succeeded in advancing quality. They enable APMs and need the support of APMs, but none of them are synonymous with a specific APM. Accordingly, they appear in multiple categories of the APM Framework, depending on the underlying payment model that supports them. Consistent with the mission of the LAN, the scope the APM Framework is limited to payment models, as opposed to delivery models. Because centers of excellence (COEs), PCMHs, and ACOs are delivery models that can accommodate a wide variety of payment arrangements, they are listed according to their underlying payment arrangement when they appear in the APM Framework. For example, a PCMH that participates in a shared-savings/risk model will be classified in Category 3, but a PCMH that receives population-based payments linked to value will be classified in Category 4. Although PCMHs and ACOs are commonly understood to be associated with risk-sharing payment models, clear distinctions should be maintained between concepts that describe payment models and those that describe delivery models. At the same time, these delivery models have been developed with the goal of driving care coordination and delivery improvements, and will enable more advanced payment models while at the same time requiring more advanced payment models to succeed. The APM Framework The APM Framework is depicted in Figure 4. The Framework represents payments from public and private payers to provider organizations (including payments between the payment and delivery arms of highly integrated health systems). It is designed to accommodate payments in multiple categories that are made by a single payer, as well as single provider organizations that receive payments in different categoriespotentially from the same payer. Although payments will be classified in discrete categories, the Framework captures a continuum of clinical and financial risk for provider organizations. The Approved for Public Release; Distribution Unlimited: 17-2546. 25 following discussion identifies the organizing principles that serve as the foundation for each Category, explains how the Categories are differentiated, and highlights examples of APMs in each Category. Figure 4: The Updated APM Framework Approved for Public Release; Distribution Unlimited: 17-2546. 26 Fee for Service with No Link to Quality & Value (Category 1): Payment models classified in Category 1 utilize traditional FFS payments (i.e., payments made for units of service) that are adjusted to account for neither infrastructure investments, nor provider reporting of quality data, nor provider performance on cost and quality metrics. Additionally, it is important to note that diagnosis related groups (DRGs) that are not linked to quality and value are classified in Category 1. This is because DRGs are used to reimburse a group of services delivered within a hospitalization, and while DRGs drive efficiencies in inpatient care, hospitals typically bill DRGs in much the same way physicians bill services that are paid on a fee schedule. In both instances, the provider's incentive may be to bill for additional services because they are paid more for more volume. Payments in Category 1 are distinguished from those in Category 2 in that the latter incentivizes infrastructure investments and/or involves some method of reporting or assessing the quality of the care delivered. Unlike payments made in Category 1, payments made in Category 2 are influenced by whether a provider invests in infrastructure, reports quality data, or achieves quality targets. Fee for Service Linked to Quality & Value (Category 2): Payment models classified in Category 2 utilize traditional FFS payments (i.e., payments made for units of service), but these payments are subsequently adjusted based on infrastructure investments to improve care or clinical services, whether providers report quality data, or how well providers perform on cost and quality metrics. In addition to their capacity to stimulate and focus quality improvement initiatives, investments in quality performance assessment are also valuable because they can drive the development and expansion of health information technology (HIT).16 In certain cases, such as vaccinations and colonoscopies, FFS appropriately incentivizes increased utilization of important services. In these cases, linking
FFS payments to quality indicators (e.g., measures that reinforce the right care at the right time) can be an ideal arrangement. However, for the majority of services, Category 2 should be used to smooth the transition into Category 3 and 4 APMs, and spur the delivery system improvements these payments enable. The Work Group has split Category 2 into subcategories A, B, and C, as outlined below: Payments placed into Category 2A involve payments for infrastructure investments that can \nimprove the quality of patient care, even though payment rates are not adjusted in accordance with performance on quality metrics. For example, payments designated for staffing a care coordination nurse or upgrading to electronic health records would fall under Category 2A. Because investments in these and similar delivery enhancements will likely improve patient experience and quality of care, these types of FFS or per-member-per-month (PMPM) payments are considered an importantthough preliminarystep toward payment reform. \n16 Although the Work Group was not tasked with developing specific recommendations on HIT or data sharing, it believes that providers should invest in interoperable systems; that administrative reporting requirements should be minimized as much as possible; that patients and caregivers should have free and ready access to patient records; and that HIT should be used to maintain patient registries and contribute to the development of clinical measures and guidelines. For additional guidance on how to approach data sharing in population-based payment models, see: LAN (2016). Accelerating and Aligning Population-Based Payment Models: Data Sharing. Available at https://hcp-lan.org/groups/pbp/ds-final-whitepaper/. Approved for Public Release; Distribution Unlimited: 17-2546. 27 Payments placed into Category 2B provide positive or negative incentives to report quality data to \nthe health plan andpreferablyto the public. Providers may have initial difficulties reporting clinical data accurately. Participation in a pay-for-reporting program therefore gives providers an opportunity to familiarize themselves with performance metrics, build internal resources to collect data, and better navigate a health plans reporting system. Because pay-for-reporting does not link payment to quality performance, participation in Category 2B payment models should be time limited, and participation in Category 2B payment models will typically evolve into subsequent categories. Payments are placed into Category 2C if they reward providers that perform well on quality metrics \nand/or penalize providers that do not perform well, thus providing a significant linkage between payment and quality. For example, providers may receive higher or lower updates to their FFS baseline, or they may receive a percent reduction or increase on all claims paid, depending on whether they meet quality goals. In some instances, these programs have an extensive set of performance measures that assess clinical outcomes, such as a reduction in emergency room visits for individuals with chronic illnesses or a reduction in hospital-acquired infections. Payments in this subcategory are not subject to rewards or penalties for provider performance against aggregate cost targets, but may account for performance on a more limited set of utilization measures. As the evaluation literature demonstrates, Category 2A and 2B payments, for HIT and other infrastructure needed to assess and improve quality performance, are often insufficient on their own to catalyze significant delivery transformations.17 Providers should therefore use Category 2A and 2B payments as an on ramp to participation in subsequent categories. Providers will transition into Category 2C in different ways. In the private sector, few payment plans support pay-for-reporting arrangements, and providers often move directly into pay-for-performance models. By contrast, Medicare pay-for-reporting programs typically precede and serve as the foundation for pay-for- performance programs in the same facility setting. Irrespective of how the transition occurs, it is important for providers to move quickly into Category 2C arrangements. Payments that fall under Category 2 are distinguished from those that fall under Category 3 in two respects. First, Category 2 payments do not involve arrangements in which providers are rewarded for providing appropriate care or penalized for insufficiently reducing low-value care (e.g., shared savings or shared losses based on established cost targets). Second, FFS-based payments in Category 3 reflect, to a greater degree, care provided longitudinally, such that multiple providers are responsible for the cost and quality associated with a particular set of procedures or services. By contrast, Category 2 payments are typically limited to specific providers. APMs Built on Fee for Service Architecture (Category 3): Payment models classified in Category 3 are based on an FFS architecture, while providing mechanisms for the effective management of a set of procedures, an episode of care, or all health services provided for individuals. To accomplish this, Category 3 payments are based on cost (and occasionally utilization) performance against a target, irrespective of how the financial or utilization benchmark is established, updated, or adjusted. Additionally, payments in Category 3 are structured to encourage providers to deliver effective and efficient care. Episode-based and other types of bundled payments encourage care coordination because they cover a complete set of related services for a procedure that may be \n17 See, for example: Mendelson A., et al. (2017). The Effects of Pay-for-Performance Programs on Health, Health Care Use, and Processes of Care: A Systematic Review. Annals of Internal Medicine, 166: 341-354. Approved for Public Release; Distribution Unlimited: 17-2546. 28 delivered by multiple providers. Clinical episode payments fall into Category 3 if they are tied to specific procedures, such as hip replacement or back surgery. Due to the potential that providers may curtail necessary care to meet explicit cost and/or utilization targets in Category 3 APMs, it is essential for these APMs to include safeguards that go beyond the standard types of quality measures used in Category 2 APMs. Accordingly, Category 3 APMs must hold providers financially accountable for performance on available measures of appropriate care. In this context, appropriate care is delivered when patients receive the right care at the right time, in the right place, and at the right intensity. Appropriate care adheres to evidence-based guidelines and comparative effectiveness research; it avoids unnecessarily costly, harmful, and unnecessary procedures; its intensity is commensurate with patients goals, prognoses, and needs; and it reflects the outcome of shared decision-making among patients, their caregivers, and their clinicians. Several organizations and initiatives, including the Agency for Healthcare Research and Quality (AHRQ), the Choosing Wisely campaign, the National Academy of Medicine, and AcademyHealth working with the American Board of Internal Medicine, have further developed this concept of appropriate care by compiling lists of low-value procedures and never events, by investigating the root causes of low-value care, by designing decision-support tools to promote appropriate care, and by designing measures to assess rates of low- and no-value care. Some of the many topics used to measure appropriate care include preventable hospital admissions, unnecessary imaging, documentation of shared-decision-making and patient goals for end of life care, adherence to clinical guidelines for pre-term labor and delivery, appropriate use of medications, and rates of never events. Although cost (and/or occasionally utilization) performance is the distinguishing component of Category 3 APMs, Category 3 payments hold providers accountable for this wider range of activities and outcomes. This is consistent with the notion that cost saving on its own is not an appropriate goal for healthcare reform; rather, the goal is to generate cost savings by reducing the utilization of care that provides little to no value for patients. All Category 3 payments evaluate providers against financial benchmarks and, occasionally, utilization targets. The Category is further subdivided as follows:18 In Category 3A, providers have the opportunity to share in a portion of the savings they generate \nagainst a cost target or by meeting utilization targets, if quality targets are met. However, providers \n18 Please note that this definition of a Category 3 APM has been revised in the 2017 APM Framework Refresh. Please see Appendix A for additional details. Measures of Appropriate Care Appropriate care avoids wasteful tests and procedures that provide no benefit to patients, involves a high degree of care coordination to ensure efficient delivery, and encompasses everything patients need to achieve their personal health-related goals. Measures of appropriate care are essential for Category 3 and 4 APMs, to ensure that providers are incentivized to reduce/eliminate only care that is wasteful and potentially harmful for patients. http://www.choosingwisely.org/ Approved for Public Release; Distribution Unlimited: 17-2546. 29 do not need to compensate payers for a portion of the losses that result when cost or utilization targets are not met. In Category 3B, providers have the opportunity to share in a portion of the savings they generate \nagainst a cost target or by meeting utilization targets, if quality targets are met. Additionally, payers recoup from providers a portion of the losses that result when cost or utilization targets are not met. Most ACO arrangements today can be placed into either Category 3A (most often) or Category 3B, depending on whether the underlying risk arrangement includes only upside shared savings or both upside shared savings and downside risk for providers. These and other Category 3 arrangements will advance clinical integration and affordability to a greater extent than payments in Category 2, because accountability for reductions in low value care provides stronger incentives
to manage health care costs and improve care coordination across the span of care. The most important distinction between Category 3 and Category 4 payments is that the latter involve a single, predominantly prospective payment that encompasses a broad array of services, whereas providers participating in Category 3 models continue to be paid on a FFS basis with retrospective reconciliation after the period of performance. Additional conditions must be met before a payment model can be placed into Category 4. Specifically, Category 4 payments reflect the (TCOC) for treating a primary (typically chronic) condition (e.g., diabetes or cancer), a more limited set of specialty services (e.g., primary care or behavioral health), or comprehensive care for an entire population. By contrast, payments for a more limited set of services or procedures (e.g., knee and hip replacement) are classified as Category 3, even if they are population-based and patient-centered (e.g., paid for prospectively and include accountability for patient-reported outcomes). For example, a prospective, population-based primary care model would be classified in Category 4A, but a population-based bundled payment for maternity care would be classified as a Category 3B because it only addresses one aspect of a persons care and health. Similarly, population-based clinical episode and bundled payments that are tied to conditions (e.g., diabetes or cancer) fall under Category 4, whereas clinical episode payments tied to procedures (e.g., hip replacement or back surgery) fall under Category 3, even if they are paid prospectively. As such, Category 4 payments are more person-focused, insofar as they include stronger incentives to promote health and wellness throughout the care continuum. Population-Based Payment (Category 4): Payment models classified as Category 4 involve prospective, population-based payments, structured in a manner that encourages providers to deliver well-coordinated, high-quality, person-centered care within either a defined scope of practice (4A), or a comprehensive collection of care (4B), or a highly integrated finance and delivery system (4C). For the same reasons as Category 3, Category 4 APMs require accountability for measures of appropriate care, to provide additional safeguards against incentives to limit necessary care. Absent this accountability, APMs that use prospective, population- based payments will be classified in Category 4N. Payments within Category 4 can be used to cover a wide range of preventive health, care coordination, and wellness services, in addition to standard medical procedures typically paid through claims, and this flexibility makes it easier for providers to invest in foundational and innovative delivery system components. Additionally, replacing the volume-based incentives of FFS with prospective, population- based payments creates stronger incentives for providers to maximize quality within a budget. Taken Approved for Public Release; Distribution Unlimited: 17-2546. 30 together, these mutually reinforcing characteristics of Category 4 payments both the freedom to practice medicine without having to rearrange care delivery to meet strict reimbursement requirements, and the incentives to maximize the quality and efficiency of care delivery hold special promise for providers and patients who are able and willing to participate in them. Despite the promise of Category 4 APMs, it is important to recognize that it is very difficult to limit providers exposure to insurance risk in these payment arrangements. When designing Category 4 APMs, it is therefore essential to recognize that providers outside of integrated finance and delivery systems are unlikely to have the administrative capabilities or risk-based capital to assume insurance risk. Certain safeguards can be taken to minimize the introduction of insurance risk into population- based payment models. First, these models will need to be carefully risk-adjusted to account for patient case-mix. Second, the models will need to carve out payments for essential yet extraordinarily expensive or random events, which should not be attributed to the accountable provider (e.g., in the case of patients needing a heart transplant soon after they are attributed to a provider organization). Third, stop-loss mechanisms should be put into place, in order to protect providers against unexpected cost increases for warranted care (e.g., the recent entry of expensive but effective pharmaceuticals), as well as other catastrophic, unpredictable events (e.g., epidemics of infectious disease). Category 4 is subdivided into subcategories A, B, and C, as outlined below: Category 4A includes bundled payments for the comprehensive treatment of specific conditions. \nFor example, bundled payments for cancer care fall under Category 4A if providers are responsible for the total cost and quality of care for a patient, rather than covering, for example, only chemotherapy payments. Additionally, prospective payments are classified in Category 4A if they are prospective and population-based, and also cover all care delivered by particular types of clinicians (e.g., primary care and orthopedics). Payments in Category 4B are prospective and population-based, and they cover all an individuals \nhealth care needs. Category 4B encompasses a broad range of financing and delivery system arrangements, in which payers and providers are organizationally distinct. Payments in Category 4C also cover comprehensive care, but unlike Category 4B payments, they \nmove from the financing arm to the delivery arm of the same, highly integrated finance and delivery organization. In some cases, these integrated arrangements consist of insurance companies that own provider networks, while in other cases they consist of delivery systems that offer their own insurance products. To be effective, the finance and delivery arms will need to work in tandem, to ensure that effective delivery investments are being made, and that incentives and strategies within the organization are properly aligned. Additionally, it is important to note that when integrated lines of business comprise a portion of a companys portfolio, only the integrated payments count toward Category 4C. Integrated Finance and Delivery Systems Integrated finance and delivery systems bring together insurance plans and delivery systems within the same organization. These systems may include joint ventures between insurance companies and provider groups, insurance companies that own provider groups, or provider groups that offer insurance products. Approved for Public Release; Distribution Unlimited: 17-2546. 31 Category 4A may be an appropriate endpoint when smaller provider organizations with targeted skill sets deliver patient care that revolves around the management of chronic conditions, such as cancer or heart disease. Nevertheless, in many instances it is preferable to compensate providers for maintaining health and managing illness for an entire population, rather than compartmentalizing and subdividing payments into distinct conditions. Additionally, condition-specific payments should, in time, become part of a comprehensive approach to improving health and reducing costs for an entire population, such that Category 4A arrangements evolve into Category 4B arrangements. Based on interviews with companies involved in integrated finance and delivery arrangements, it appears that Category 4C payments have the potential to carry significant advantages. For example, these arrangements can expedite investments in crucial care delivery infrastructure, such as population health management support, programs to improve care coordination and care transitions, HIT, and community health initiatives. Additionally, highly integrated arrangements can provide important foundations for organizational cultures and strategies directed toward population health management, and they can create stronger alignments between physician groups and hospitals. On the other hand, widespread growth of integrated finance and delivery systems could potentially result in market consolidation, which could in turn lead to decreased choices and lack of access for patients, as well as increased costs. Evidence on the effectiveness of highly integrated systems is still in its early stages, and preliminary results are inconclusive. Therefore, Category 4B and 4C APMs should be considered equally effective vehicles for increasing the value of care through delivery system improvements. Taken together, Categories 4A, 4B, and 4C represent the furthest departure from traditional FFS payments, while simultaneously ensuring that providers possess the strongest possible incentives to deliver high-quality and efficient care. Nevertheless, as discussed above, Category 4 payments are not necessarily appropriate for all providers and markets. To be successful, providers will necessarily travel at different paces and along different trajectories in the collective journey of health payment and delivery reform. But over time, Category 4 APMs will offer an appealing destination for more and more providers and other stakeholders in the health care system. Approved for Public Release; Distribution Unlimited: 17-2546. 32 Conclusion As set forth in this document, transitioning from FFS to population-based payments is critical for health care transformation. Keeping in mind the underlying principles, the APM Framework provides a high-level mapping of payment approaches, as well as a pathway for payment reform and a foundation for measuring progress. These tools should be useful for all stakeholders and prove enduring as they navigate the health care ecosystem. Although the Framework identifies and encompasses all models of payment reform, new developments in the health care sector may result in a need for further refinement in future years. Nevertheless, the Framework should be robust enough to accommodate foreseeable changes and become the overarching framework for discussing and evaluating payments in the U.S. health care system. The LAN intends to continue compiling and periodically releasing case studies of payment models. (See APM Framework White Paper Addendum.) This is important because it will disseminate lessons learned and provide the nation with models to consider as public and private plans align around common payment
approaches. Stakeholders and the APM Framework Patient Advocacy Groups can use the APM Framework to understand the context behind plan and benefit design so they can identify and communicate desirable elements and participate in decisions about how to design payment plans and delivery systems. Providers can use the APM Framework to appreciate the types of payment reforms underway, to achieve a better understanding of where they are situated, to begin to conceive of where they might like to end up, andmost importantlyto plan for the future. Plans can use the APM Framework to drive payment and contracting models and as an financial tool to track spending and the distribution of members/beneficiaries and providers. This is crucially important, because adopting a common classification scheme represents a first step toward the alignment of payment approaches. Purchasers can use the APM Framework to engage and educate their employees about the health insurance landscape and to share information for population-based plans, along with the safeguards and benefits that would motivate them toward enrolling in such plans. http://hcp-lan.org/workproducts/apm-whitepaper-addendum.pdf\nhttp://hcp-lan.org/workproducts/apm-whitepaper-addendum.pdf Approved for Public Release; Distribution Unlimited: 17-2546. 33 Appendix A: Category 3 Incentive-at-Risk APMs Because MACRA and the LAN APM Framework share the goal of transitioning away from FFS and into APMs that achieve better outcomes at lower costs, comparisons between the two systems for designating APM advancement can illuminate alternative ways to effectively tether payment to value, and take better account of variation among providers. Given that CPC+ Track 1 was the only Advanced APM (by MACRA standards) that was not classified as a Category 3 or 4 in the original framework, the Advisory Group closely examined how it used payment to hold providers accountable for quality and cost. As a result of these discussions, the Advisory Group determined that payments in CPC+ Track 1 drive value in a manner that is functionally equivalent to shared-savings arrangements in Category 3A. The Advisory Group therefore decided to classify CPC+ Track 1 and other incentive-at-risk APMs in Category 3A. Incentive-at-risk APMs give providers the opportunity to share in a portion of the savings they generate as a direct result of meeting utilization targets. These APMs possess two important characteristics. First, utilization measures that provide very strong proxies for TCOC take the place of formal financial benchmarks. Second, incentive payments for performance on utilization measures are used to reallocate derived savings (if any) between payers and providers. Because incentive payments (as opposed to payments made through the FFS architecture) are at risk for utilization performance, incentive-at-risk APMs are classified in Category 3A (as opposed to Category 3B). These incentive-at-risk APMs are particularly appropriate for smaller practices and other situations in which upfront investment might be necessary to provide adequate resources for providers to undertake care transformation, and in which it is not ideal to hold providers directly accountable for meeting benchmarks based on TCOC. Primary care in the Medicare population involves a unique set of circumstances that make incentive-at- risk APMs effective vehicles for improving quality while decreasing costs. First, a greater proportion of TCOC for the Medicare population is driven by fewer categories of health care utilization. Emergency department usage and inpatient stays account for roughly 40% of TCOC in the Medicare population, while these categories account for only about 20-25% of TCOC in the population covered by commercial insurance. This means that inpatient utilization measures provide more robust proxies for TCOC with fewer utilization targets for practices to track and work to achieve. Primary care practices also have the capability to focus on and influence these measures to a much greater degree than some other cost drivers under an expansive TCOC benchmark. CPC+ practices may also improve utilization performance by partnering with value-oriented specialty providers who appropriately use tests and interventions. Primary care providers also tend to practice in small groups, and their patient panels are typically too small to manage the financial risk of outlier patients disproportionate impact on TCOC. Additionally, Medicares previous experience with its Comprehensive Primary Care Classic model suggested that although the formation of virtual groups achieved panel sizes large enough to mitigate this risk and allowed for cost accountability, pooling patients across providers in a region appeared to dampen the driving force for cost savings. This may have been attributable to the diffusion of responsibility among multiple practices within a virtual group. Additionally, behavioral economics research strongly supports the notion that receiving an uncertain amount of incentive payments after a period of performance Approved for Public Release; Distribution Unlimited: 17-2546. 34 would be less motivational than providing defined payments up front and reconciling them after the fact, because providers are more likely to be motivated by potential losses than potential gains.19 Track 1 of Medicares CPC+ model takes these unique factors into consideration in the design of a Category 3A arrangement that generates cost savings by tying incentive payments to reductions in utilization. In addition to payments made through Medicares standard fee schedule, primary care practices receive prospective care management fees (Category 2A), as well as prospective performance- based incentive payments (Category 2C). Fifty percent of the incentive payment is based on providers performance on two utilization measures inpatient hospitalization utilization per 1,000 attributed beneficiaries and emergency department utilization per 1,000 attributed beneficiaries which means providers are able to share in a significant proportion of Medicares savings from reduced hospital utilization as a result of improved care coordination or greater availability of office visits, telephone, or telemedicine consultation. Conversely, providers who perform poorly on these two utilization measures risk paying back Medicare some or all of the utilization portion of the incentive payment. Cumulatively, these payments and risk place CPC+ Track 1 in Category 3A. Figure 5 illustrates the expected payment implications in CPC+ Track 1, when a provider maintains utilization at average levels, reduces utilization significantly more than average, or increases utilization slightly more than average. \n19 Please note: So long as incentive payments for performance on key utilization measures effectively create a shared-savings arrangement they will be classified in Category 3A, irrespective of whether they are made prospectively or retrospectively. Approved for Public Release; Distribution Unlimited: 17-2546. 35 Figure 5: Impacts of Utilization on Payments in CPC+ Track 1 It is important to note that reducing utilization (especially hospital utilization) is not intrinsically indicative of increased value, as this could theoretically be achieved through reductions in necessary care. To avoid the unintended consequences of rewarding reductions in utilization alone in CPC+, CMS 1) requires practices to meet quality benchmarks applicable to their entire practice population (not limited to Medicare beneficiaries) before they can keep a utilization incentive payment; 2) actively monitors claims activity to detect potentially unwarranted reductions in utilization; and 3) employs contractual agreements with providers that include additional patient protections. Approved for Public Release; Distribution Unlimited: 17-2546. 36 Just as with TCOC reduction incentives, these and other safeguards are essential for incentive-at-risk APMs that use utilization as a proxy for cost, in order to ensure providers either are incentivized to only reduce unnecessary care or achieve efficiencies and prevent avoidable hospitalization and emergency room visits through care coordination and access. Approved for Public Release; Distribution Unlimited: 17-2546. 37 Appendix B: APM Framework Refresh Advisory Group Members and Staff Advisory Group Chair Samuel R. Nussbaum, MD Senior Fellow, USC Schaeffer Center for Health Policy and Economics Advisory Group Members Alexander Billioux, MD, DPhil Center for Medicare Distribution Unlimited: 17-2546. 38 Anne Gauthier, MS LAN Project Leader Amy Aukema, MPP LAN Deputy Project Leader Suzanne F. Delbanco, PhD Executive Director, Catalyst for Payment Reform Approved for Public Release; Distribution Unlimited: 17-2546. 39 Appendix C: Original APM Framework Work Group Members and Staff Work Group Chair Samuel R. Nussbaum, MD Former Executive Vice President, Clinical Health Policy and Chief Medical Officer, Anthem, Inc. Work Group Members Shari M. Erickson, MPH Vice President, Governmental Affairs and Medical Practice, American College of Physicians Andrea Gelzer, MD, MS, FACP Senior Vice President and Corporate Chief Medical Officer, AmeriHealth Caritas James Guest, JD Former President and CEO of Consumer Reports Paul Harkaway, MD Senior Vice President, Clinical Integration and Accountable Care, Trinity Health, Inc. Scott Hewitt, MPH Vice President, Value Based Contracting Strategy, UnitedHealthcare Susan Nedza, MD, MBA, FACEP CMIO and Senior Vice President of Clinical Outcomes Management, MPA Healthcare Solutions Steve Phillips Senior Director, Global Health Policy, Government Affairs and Policy, Johnson and Johnson Richard Popiel, MD, MBA Executive Vice President, Health Care Services and Chief Medical Officer, Cambia Health Solutions and Regence Health Insurance Company Rahul Rajkumar, MD, JD Deputy Director, Center for Medicare Distribution Unlimited: 17-2546. 40 Lisa Woods Senior Director Health Care Benefits, Wal-Mart Stores, Inc. Approved for Public Release; Distribution Unlimited: 17-2546. 41 Appendix D: Other LAN Content The LAN has written a suite of papers to help align payment reform efforts. The papers referred to in this appendix include recommendations on the design of population-based payments and clinical episode payments, as well as a toolkit on data sharing for alternative payment models. These recommendations are the result of input
from a wide variety of persons and organizations with either direct experience with implementing payment reform or deep experience in the health care field. CAMH convened two Work Groups, the Population-Based Payment (PBP) Work Group and the Clinical Episode Payment (CEP) Work Group, to develop recommendations for the implementation of these types of payment models. Their recommendations focus on specific design elements, many of which overlap and upon which there was much common agreement even as the Work Groups deliberated separately. Each of the four PBP White Papers described below focuses on a separate design element (financial benchmarking, patient attribution, performance measurement, and data sharing) in a PBP context. In a PBP arrangement, an accountable entity takes responsibility for the care for a defined population over a specified period of time (typically a year) for the full continuum of care. These design elements should be considered as a whole for effective PBP implementation as they interact considerably. The CEP Work Group also divided their recommendations into design elements, but included several operational considerations along with 10 design elements. The recommendations were organized in chapters in the comprehensive White Paper and applied to three clinical areas where clinical episode payment models would be most effective: elective joint replacement, maternity care, and coronary artery disease (CAD). While the clinical focus is more targeted here, the underlying concepts for setting the episode price (including the level and type of risk), defining the population and services included in the episode, patient engagement and quality metrics, and the data infrastructure are similar to those of the four PBP White Papers. The LAN convened the Data Sharing Requirements Initiative (DSRI) to gather information on recent approaches and experiences building data-sharing capacity. The DSRI leadership team incorporated input from interviews with organizations engaged in data sharing in support of APMs, and reviewed material on critical developments in technology and policy. The resulting toolkit is meant to be of practical value for those planning and developing future data sharing activities. The following provides links and a brief overview of each of the papers written by the LAN Work Groups. By reading the full suite of products, readers of this paper will be better able to make decisions about the most effective payment model(s) to implement and the key issues to consider when designing those models. Visit our website (https://www.hcp-lan.org) for an up-to-date list of LAN work products. Population-Based Payment (PBP) Models: Accelerating and Aligning Population-Based Payment (PBP): Patient Attribution The Patient Attribution White Paper describes the method by which patient populations are assigned to providers who are accountable for total cost of care and quality outcomes for their designated populations in a PBP model. The paper recommends that active, intentional identification, or self- reporting by patients, should be considered first. The paper also outlines nine additional https://www.hcp-lan.org/\nhttps://hcp-lan.org/groups/work-group-products/\nhttps://hcp-lan.org/groups/pbp/pa-final-whitepaper/ Approved for Public Release; Distribution Unlimited: 17-2546. 42 recommendations that payers and providers can use when making decisions on attribution in their PBP models. Accelerating and Aligning Population-Based Payment (PBP): Financial Benchmarking The Financial Benchmarking White Paper describes approaches for setting an initial benchmark and updates over time, as well as addresses risk-adjustment considerations. The White Paper discusses the need to balance voluntary participation with the movement toward convergence in a market with providers at different starting points. Accelerating and Aligning Population-Based Payment (PBP): Data Sharing The Data Sharing White Paper offers several guiding principles and recommendations that highlight the future development of data sharing arrangements in PBP models. The paper also outlines use cases for data sharing which describe particular types of data sharing arrangements, in both their current and aspirational states. The goal is to create an environment where data follows the patient and is available to stakeholders (patients, providers, purchasers, and payers) in a timely manner. Accelerating and Aligning Population-Based Payment (PBP): Performance Measurement The Performance Measurement White Paper offers both short-term action recommendations and a long-term vision for accelerating alignment around APMs. The paper offers a way forward that could lead to radical change in how performance is measured across the board in order to enable the implementation of effective population-based payments. The White Paper describes how to evolve from granular measurement systems of the full continuum of care, which focus on narrow and specific care processes, to more macro-level measurement systems oriented on outcomes. The paper also makes strong recommendations for immediate action steps by describing four key performance measurement principles and seven recommendations for building and sustaining a performance measurement system that supports and encourages collaboration among stakeholders. Clinical Episode Payment (CEP) Models: Accelerating and Aligning Selected Clinical Episode Payment (CEP) Models This paper provides high-level recommendations for designing clinical episode payment models. A clinical episode payment is a bundled payment for a set of services that occur over time and across settings. The paper outlines design elements and operational considerations for three selected clinical areas: elective joint replacement, maternity care, and coronary artery disease. Recommendations are organized according to design elements and operational considerations. Design elements address questions stakeholders must consider when designing an episode payment model, including the definition, the duration of the episode, what services are to be included, and others. Operational considerations relate to implementing an episode payment model, including the roles and perspectives of stakeholders, data infrastructure issues, and the regulatory environment in which APMs must operate. https://hcp-lan.org/groups/pbp/fb-final-whitepaper/\nhttps://hcp-lan.org/groups/pbp/fb-final-whitepaper/\nhttps://hcp-lan.org/groups/pbp/ds-final-whitepaper/\nhttps://hcp-lan.org/groups/pbp/pm-final-whitepaper/\nhttps://hcp-lan.org/groups/pbp/pm-final-whitepaper/\nhttps://hcp-lan.org/groups/cep/clinical-episode-payment/ Approved for Public Release; Distribution Unlimited: 17-2546. 43 Several key principles drove the development of the recommendations across all three episodes: 1) incentivizing person-centered care; 2) improving patient outcomes through effective care coordination; 3) rewarding high value care by incentivizing providers and patients, together with their family caregivers, to discuss the appropriateness of procedures; and 4) reducing unnecessary costs to the patient and the health care system. The recommendations are designed to speak to a multi-stakeholder audience with the goal of supporting broad clinical episode payment adoption. Elective Joint Replacement The elective joint replacement recommendations emphasize using functional status assessments (both pre- and post-procedure) and shared decision-making tools to determine whether a joint replacement is the appropriate treatment for a given patient. Maternity Care The maternity care recommendations emphasize the need for patient engagement, education, and parenting support services (in addition to clinical maternity care), to achieve a number of critical goals. These include increasing the percentage of full-term births and the percentage of vaginal births, while decreasing the percentage of pre-term and early elective births, complications, and mortality. Coronary Artery Disease The coronary artery disease (CAD) recommendations are based on a CAD condition-level episode, which includes a nested bundle for procedures like percutaneous coronary intervention (PCI) and coronary artery bypass graft (CABG). The recommendations emphasize overall condition management designed to reduce the need for procedures, and strong coordination and communication between the surgeons who perform cardiac procedures and the providers who deliver follow-up and long-term cardiac care. Primary Care Payment Models (PCPM): Accelerating and Aligning Primary Care Payment Models Primary care is a critical link in health care delivery. Often patients first point of contact with the health care system, primary care practitioners make decisions that broadly impact both patient health and total health care spending. The Primary Care Payment Model (PCPM) White Paper views primary care teams as uniquely positioned to serve as catalysts for innovative care as well as effective stewards of health care resources. The paper offers principles and recommendations for implementing PCPMs that can help overcome the barriers to effective primary care tied to traditional fee-for-service payments based on the volume of services provided rather than the quality and value of care. Data Sharing Requirements Initiative (DSRI): Collaborative Approaches to Advance Data Sharing One of the key insights from the DSRI findings is the essential role, in developing data sharing capacity, of collaboration, shared goals, and shared solutions to enable sustainable APM success. Unlike fee-for- https://hcp-lan.org/groups/cep/ejr-final/\nhttps://hcp-lan.org/groups/cep/maternity-final/\nhttps://hcp-lan.org/groups/cep/cad-final/\nhttps://hcp-lan.org/groups/pcpm/pcpm-final-whitepaper/\nhttps://hcp-lan.org/groups/dsri-report/ Approved for Public Release; Distribution Unlimited: 17-2546. 44 service payment models that largely limit accountability to a single setting (such as hospital or physicians office), APMs require providers to understand and/or be accountable for patients across the medical neighborhood and over time. While the toolkit is not a how to guide, as the specifics for each organization and region differ, it will be helpful in the strategic planning process to identify the APM functions that require data sharing, to assess current capacity and barriers, and to consider strategies within and across organizations to fill gaps in necessary data sharing functionality. Approved for Public Release; Distribution Unlimited: 17-2546. 45 Appendix E: Principles for Patient- and Family-Centered Payment The following principles, produced by the LANs Consumer and Patient Affinity Group, are intended to help guide the development of new payment strategies. They provide guidance and aspirational direction to ensure that we address the needs and priorities of patients and families as we transition to value-based payment. The principles rest on the conviction that consumers, patients, and families are essential partners in every aspect of transforming health care and improving health. Consumers, patients, families, and their advocates should be collaboratively engaged in all aspects
of design, implementation, and evaluation of payment and care models, and they should be engaged as partners in their own care. The collaboration in design of payment and care models should include oversight, governance, and interface with the communities where care is delivered. At the point of care, patients and families should be engaged in ways that match their needs, capacities, and preferences. Collaborative care should be aligned with patient goals, values, and preferences (including language), and should reflect shared care planning and decision-making throughout the care continuum. Positive impact on patient care and health should be paramount. The central consideration in all payment design should be improving patient health outcomes, experience of care, and health equity, while also ensuring the most effective use of health care resources. Measures of performance and impact should be meaningful, actionable, and transparent to consumers, patients, and family caregivers. New payment models should be assessed using measures that are meaningful to patients and families. They should prioritize the use of measures derived from patient-generated data that address both care experience and outcomes. Measures should also address the full spectrum of care, care continuity, and overall performance of specific models. Measures should be granular enough to enable patients to make informed decisions about providers and treatments. Primary care services are foundational and must be effectively coordinated with all other aspects of care. Payment models should foster this coordination, particularly between primary and specialty care, in order to promote: optimal coordination, communication, and continuity of care; trusted relationships between clinicians and patients/families; concordance with patient goals, values, and preferences; integration of non-clinical factors and community supports; and coordination of services delivered through non-traditional settings and modalities that meet patient needs. Effective delivery and coordination of primary care services should promote better care experience, optimal patient engagement, better health outcomes, and increased health equity. Health equity and care for high-need populations must be improved. New payment models should foster health equity, including access to innovative approaches to care and preventing any discrimination in care. They should collect data that allow for assessment of differential Approved for Public Release; Distribution Unlimited: 17-2546. 46 impacts and the identification and redress of disparities in health, health outcomes, care experience, access, and affordability. Patient and family engagement and activation should be supported by technology. New payment models should promote use of information technology that enables patients and their designated caregivers to easily access their health information in a meaningful format that enables them to use the information to better manage and coordinate their care. The technology should also enable patients to contribute information and communicate with their providers, and it should foster the patient-clinician partnership in ongoing monitoring and management of health and care. Financial incentives used in all models should be transparent and promote better quality as well as lower costs. Financial incentives for providers and patients should be fully disclosed so that patients and consumers understand how new payment approaches differ from traditional fee-for-service models, and how certain incentives may impact the care providers recommend or provide. Financial incentives should be developed in partnership with patients and consumers in order to reflect how patients define value, and to reduce financial barriers to needed care and ensure that patients are not steered to lower-cost care without regard for quality. Approved for Public Release; Distribution Unlimited: 17-2546. 47 Appendix G: About the CMS Alliance to Modernize Healthcare The Centers for Medicare & Medicaid Services (CMS) sponsors the CMS Alliance to Modernize Healthcare (CAMH), the first federally funded research and development center (FFRDC) dedicated to strengthening our nations health care system. CAMH is the convener of the LAN. The CAMH FFRDC enables CMS, the Department of Health and Human Services (HHS), and other government entities to access unbiased research, advice, guidance, and analysis to solve complex business, policy, technology, and operational challenges in health mission areas. The FFRDC objectively analyzes long-term health system problems, addresses complex technical questions, and generates creative and cost-effective solutions in strategic areas such as quality of care, new payment models, and business transformation. Formally established under Federal Acquisition Regulation (FAR) Part 35.017, FFRDCs meet special, long- term research and development needs integral to the mission of the sponsoring agencywork that existing in-house or commercial contractor resources cannot fulfill as effectively. FFRDCs operate in the public interest, free from conflicts of interest, and are managed and/or administered by not-for-profit organizations, universities, or industrial firms as separate operating units. The CAMH FFRDC applies a combination of large-scale enterprise systems engineering and specialized health subject matter expertise to achieve the strategic objectives of CMS, HHS, and other government organizations charged with health-related missions. As a trusted, not-for-profit adviser, the CAMH FFRDC has access (beyond what is allowed in normal contractual relationships) to government and supplier data, including sensitive and proprietary data, and to employees and government facilities and equipment that support health missions. CMS conducted a competitive acquisition in 2012 and awarded the CAMH FFRDC contract to The MITRE Corporation (MITRE). MITRE operates the CAMH FFRDC in partnership with CMS and HHS, and maintains a collaborative alliance of partners from nonprofits, academia, and industry. This alliance provides specialized expertise, health capabilities, and innovative solutions to transform delivery of the nations health care services. Government organizations and other entities have ready access to this network of partners. This includes select qualified small and disadvantaged businesses. The FFRDC is open to all CMS and HHS Operating Divisions and Staff Divisions. In addition, government entities outside of CMS and HHS can use the FFRDC with the permission of CMS, CAMHs primary sponsor. Executive Summary\n Overview and Introduction to the 2017 APM Framework Refresh\n Overview of Changes to the APM Framework and Its Supporting Principles The Case for Reforming the Health Care Payment System\n Purpose of the White Paper\n Approach Key Principles for the APM Framework\n The APM Framework\n ( Fee for Service with No Link to Quality & Value (Category 1): \\)\n ( Fee for Service Linked to Quality & Value (Category 2): \\)\n ( APMs Built on Fee for Service Architecture (Category 3): \\)\n ( Population-Based Payment (Category 4): \\) Conclusion\n Appendix A: Category 3 \"Incentive-at-Risk\" APMs\n Appendix B: APM Framework Refresh Advisory Group Members and Staff\n Advisory Group Chair\n Advisory Group Members\n CMS Alliance to Modernize Healthcare (CAMH) Staff Appendix C: Original APM Framework Work Group Members and Staff\n Work Group Chair\n Work Group Members Appendix D: Other LAN Content\n Data Sharing Requirements Initiative (DSRI):\n Appendix E: Principles for Patient- and Family-Centered Payment\n Appendix G: About the CMS Alliance to Modernize Healthcare ",
    "text": " () Approved for Public Release: 17-0213. Copyright has been transferred to another party. Reuse is restricted. Contact the Contracts department for guidance. Twelfth USA/Europe Air Traffic Management Research and Development Seminar (ATM 2017) Building an Integrated Simulation Environment for Modeling Traffic Management Interactions Shin-Lai (Alex) Tien, David Bodoh, Huina Gao, James DeArmon Center for Advanced Aviation System Development (CAASD) The MITRE Corporation McLean, Virginia, U.S.A. \nAbstract The Federal Aviation Administration (FAA) is funding and encouraging new concepts for improving air traffic flow management (TFM) decision-making. The resulting automation capabilities will need to be operationally integrated into the existing air traffic management (ATM) system. Understanding how a new capability will interact with existing system components is challenging because of the range of possible real-world situations which must be handled by the ATM system. Although there are fast-time traffic simulation tools available for modeling the impact of TFM actions, they are not flexible nor scalable to work in concert with various advanced TFM capabilities for conducting integration studies or quantifying benefits. To address this gap, we have built a distributed simulation platform that integrates state-of-the-art traffic simulator and allows the plug-in of advanced TFM prototypes or other experimental capabilities that already exist so that their interactions can be studied. In this paper, we discuss the requirements and the necessary components for building this platform, which requires an archi tecture that is flexible enough to support many different configurations of modeling tools and applications. We then use a TFM integration case study to demonstrate the utility of the platform. We show that, with only minor effort, a proposed TFM prototype can be plugged into the platform, and its benefits can be evaluated. Keywords- traffic flow management; modeling and simulation; distributed simulation; airborne reroute; metering I. INTRODUCTION As part of continuing improvement to the National Airspace \nSystem (NAS) automation, new concepts and capabilities for \nenhancing traffic flow management (TFM) decision-making are \nbeing proposed or developed for future operating environments \n[1]. Integrating these capabilities in the current ATM system and \nunderstanding optimal strategies for using them effectively are \ncritical to achieve associated benefits. Due to the scale of \ninvestment and complexity of systems integration, thoroughly \nanalyzing operational integration issues is necessary. Fast-time simulation modeling is commonly used to analyze \nthe interactions between new and existing capabilities due to \nfavorable low cost and ease of setup, compared with Human-in-\nthe-loop (HITL) experiments. However, existing air traffic simulation tools do not provide the flexibility of using advanced \nTFM prototypes for conducting integration studies, comparing \nalternatives, or quantifying benefits. As a result, most studies \nhave to use a surrogate or oversimplified capability to mimic the \nimpact of a future TFM concept, which already has a working \nprototype. We propose to build a flexible, distributed simulation \nplatform for facilitating TFM integration studies which allows \nrealistic prototype or fielded TFM capabilities to engage and \ninfluence simulated air traffic. On the proposed platform, a \ndedicated air traffic simulator is employed not only for \nsimulating air traffic movement but also for executing the \ndirectives from individual TFM capabilities. It is expected that \nintegrating a traffic simulator with the TFM capabilities in this \nway will enable a better understanding of overall system \ndynamics, failure modes, and strategies for using new TFM \ncapabilities effectively. Moreover, it will encourage the \ninteroperability and reusability of the simulation modeling \nelements, since the plug-and-play nature of the platform \neliminates the need for ad hoc design of each new TFM \ninteraction study. To build this simulation platform, the traffic simulator and \nthe TFM capabilities should each satisfy the requirements of \nexposing a run-time application interface, maintaining a logical \nsimulation clock, having access to a shared communications \nnetwork, and automating the human decision components. There \nexists a variety of available distributed simulation modeling \nsystems which provide the necessary services of time \nmanagement, data exchange, and subscription management, and \nthey can expedite the development of the proposed platform [2]. This paper describes our approach to build the proposed \nplatform, summarizes our implementation experience, and then \ndocuments how the platform is applied to addressing a TFM \nintegration research need. One of the objectives of this paper is \nto aid other research institutions by describing the requirements \nand architecture for the simulation integration platform for them \nto build similar capabilities for conducting TFM integration \nstudies. Section II of this paper specifies the requirements and \nthe architecture design of the simulation platform. Section III discusses the background of a TFM integration study and the \ninteractions of two capabilities to be modeled in the simulation. \nOur approach to building the simulation platform for facilitating \nthe integration study is summarized in Section IV, and the initial \nstudy results are summarized in Section V. II. SIMULATION ARCHITECURE DESIGN The proposed simulation platform requires an architecture \nthat can support a variety of air traffic management experiments, \nexercising a variety of configurations of modeling tools and \napplications. Generally, many usable applications already exist \nin some form but with varying degrees of fidelity and \nfunctionality. Without targeting specific applications, the \narchitecture needs to be flexible and scalable to meet the current \nand anticipated analysis needs. In most cases, different \ncombinations of diverse capabilities must be configured so that \nthe researchers can exercise them in concert to address specific \nconcerns about current and future TFM policies and technology. \nThis section describes the technical simulation-level \nrequirements that would be used to build the proposed platform. A. Requirement Overview The architecture design is inspired by the High-Level \nArchitecture (HLA), which is a federated simulation standard \nwidely used in the defense industry [3] and applied in other \ndomains as well [4, 5]. The research described in this paper \napplied the HLA concept for building a distributed simulation \nexperiment using disparate capabilities. As a first consideration, \nall modeling components must be capable of either time-\nstepped fixed-interval time advancement or next event time \nadvancement. Time-stepped advancement, which nominally \nadvances time much faster than wall-clock time, precludes the \nuse of HITL experiments. Any decision points that would \nnormally pause and defer to an external operator must instead be \nconfigured using some heuristic to auto-select an action from a \nset of options. Alternate policies for selection criteria can be \ntreated as one of the experimental effects, and analyzed via a \nMonte Carlo (randomized sampling) approach. All components must have access to a common network. The \narchitecture must be flexible enough to engage installations that \nonly run on specific operating systems (e.g., Linux or Windows) \nor in specific locations. For timely data exchange among these \napplications, there must some shared protocol that allows \nexpedient conveyance of events and messages. The architecture must support the ability to interchange \ncomponents, so that as tools with different fidelity or capabilities \nbecome available, they can be readily plugged-in this offers \nanalysts a selection of options best suited to their research. A \nloosely-coupled 1 functional interface to implemented \ncapabilities helps shield other applications from lower-level \ndetails. All involved components must expose a data layer runtime \nApplication Program Interface (API) for reporting current flight \n1 In computing systems design, a loosely-coupled system is one in which the components make little or no use of the definitions of other components. positions, issuing Traffic Management Initiatives (TMIs), \nsignaling acceptance of reroutes, and exchanging other \nmessages. Any local event that is of relevance to another \ncomponent must be exposed and reflected so that both \napplications have a common perspective of the system state. Finally, the system must be deterministic, and therefore each \ninvolved component must be deterministic as well. Repeated \nruns using the same configuration must yield the same results. \nThis is important for simulation repeatability and \ntroubleshooting. Any stochastic elements must be controlled via \nrandom number seed variables. B. Necessay Services and Modeling Components To satisfy the requirements, the necessary services and \nmodeling components are discussed below: 1) Run-Time Infrastructure \nThis is the software protocol which all the simulation modeling components on this platform need to follow for \ndesigning their APIs, so that they can coordinate their logical \nprocesses, synchronize simulation time advancement, and \nexchange data during runtime. 2) Time Management Function \nThis controls the advance of logical time in the simulation run at a fixed step size (e.g., 1 second). All the simulation \nmodeling components need to finish processing their events at \nthe current time step before the time management function \nmoves the simulation clock. 3) Data Distribution Service \nThis governs how data is communicated among the simulation modeling components during runtime. For the \nefficiency of data exchange, publication/subscription type \nservices can be used each application publishes the data that \nare meaningful to others and subscribes to the data that it needs \nas input. 4) Simulation Management Function \nThis is the function that controls the state of each simulation modeling component. It starts, pauses, continues, and ends the \nsimulation model execution. 5) TFM Modeling Component \nThese are the modules which are plugged-in to the platform for integration study. Regardless of their TFM purposes, they \neach need to have an API which allows the Simulation \nManagement Function to control the state of
the simulation. \nAlso, they should have the data distribution interfaces that can \nexchange data and comply with the protocol defined in the Real-\nTime Infrastructure (RTI). They receive system status (e.g., \nflight positions, trajectories, airspace constraints) and output \nTFM actions (e.g., reroutes, departure delays) 6) TFM Integration Policy Module \nThis governs how TFM actions from multiple simulation modeling components should interact. For example, if an airborne flight has already taken an action from Component A, \nthe Integration Policy Module may dictate that it cannot take \nanother action from Component B in the next 15 minutes due to \nprocedural or operational considerations. Such treatment of the \nprecedence relations of TFM actions is typical in a TFM \nintegration study, either from the functional or procedural \nperspective. The settings in the Integration Policy Module are specific to \nan integration scenario, and could be parameterized pursuant to \na Monte Carlo analysis. 7) Traffic Simulator \nOur idea is to employ a dedicated air traffic simulator to evaluate the actions generated by individual TFM components, \ne.g., revised departure times, flight reroutes, and requested times \nof arrival (RTAs) at fixes. This traffic simulator will perform the \nfollowing functions: Advance flights through airspace from origin to \ndestination airports; Provide the current status of system state (e.g., flight \npositions, flight trajectories, sector traffic counts); Ingest and execute the actions levied by the TFM \nIntegration Policy Module; Implement fundamental air traffic control (ATC) rules \nand constraints (e.g., aircraft separation, \ndeparture/arrival procedures, facility letter of agreement \n(LOA) restrictions, sector capacities, and special use \nairspace (SUA) transits). Figure 1 illustrates the proposed architecture of the RTI. To \ninitialize a run, all the simulation modeling components, the \nIntegration Policy Module, and the traffic simulator need to \nregister with the RTI and start their publication/subscription \nservices. During a simulation run, the simulation clock only \nmoves from one time step to the next when all the components \nhave finished their processes from the prior step. At each step, \nthe TFM modeling components receive data of interest provided \nby the traffic simulator and then publish the TFM actions when \nsome triggering events are activated. Subsequently, the \nIntegration Policy Module, which subscribes to TFM actions, \ndetermines whether to publish those actions to the traffic \nsimulator based on the current operative integration policies. \nThe traffic simulator applies TFM actions, if any, and then \nupdates system status. At the end of the simulation time, all the \nmodeling components are halted. Figure 1. Architecture of the Proposed TFM Integrated Simulation Platform III. CASE STUDY: ENABLING ARRIVAL METERING DURING \nEN ROUTE WEATHER VIA AN ADVANCED REROUTE CAPABILITY This section describes the background of an operational \nproblem and how a new TFM capability is expected to mitigate \nthat problem. This problem illustrates the need for the proposed \nplatform championed in this paper. A. Arrival Metering during En route Weather The Time-Based Flow Management (TBFM) system is a \nmeans of modulating (metering) air traffic flows using time \nsequencing. In the case of arrival flows, as flights progress \ntoward a destination airport, the TBFM system constructs a \ntrajectory which includes predictions of future crossing times at \nspecific meter reference points calculated using winds, aircraft \nperformance characteristics, flight plan information, etc. When \na flight crosses the Freeze Horizon (FH: a specified distance \nfrom the meter reference point where assigned times are \nfrozen,), a scheduled time of arrival (STA) at the meter reference point is assigned for the flight, based on competing \ndemand and scheduling constraints. One type of meter reference \npoint is a meter fix (MF) which is typically on or near the \nTerminal Radar Approach Control (TRACON) boundary, about \n40 to 60 nautical miles (NMs) from the destination airport. A \nsimplified diagram of a typical metering design is shown in \nFigure 2. Delivering the flights per their STAs to the MFs will ensure \nsteady, manageable traffic flows into the TRACON airspace, \nconsistent with the runway arrival capacity. During periods of \nhigh demand, controller and pilot actions such as speed \nadjustments or vectoring may be necessary to meet the \nscheduled times [6]. However, a serious challenge for arrival \nTBFM is maintaining time-based schedules in conditions of \nsevere en route weather. Severe weather affects routing \npredictability: route changes or vectors implemented inside the \nFH alter trajectories from the flights plan, making flying time to \nthe meter fix less predictable, and STAs difficult to achieve. \nOften, TBFM is turned-off in these cases, and a less efficient \nflow management technique is employed, namely, miles-in-trail \n(MIT) spacing at the MF and further upstream. MIT spacing is \nless efficient because each flow is managed independently, \nwithout consideration for the relative demand on each flow and \nthe merging of flows as they approach the airport. In sum, lacking a dynamic reroute capability, flights passing \nthrough severe en route weather inside the FH will likely cause \na path modification which alters flying time, making trajectory \npredictions unstable and STAs potentially unachievable. Figure 2. Notional flight path, TBFM FH, and MF B. Benefit of Integrating A Reroute Capability One of the promising solutions to the challenge of metering \nflights during weather impact is to incorporate a dynamic route \nplanning capability for the flights, to identify reroute \nopportunities before their crossing the FH and making the \nrevised trajectory available to TBFM [7]. In the current traffic management tool set, automated \nidentification of airborne flights affected by severe weather is \nnot available. In light of this need, MITRE CAASD and NASA, \nin partnership with the FAA, have developed a concept and \nprototype capability to identify such problems and help to \nresolve them. This capability is referred to as Advanced Flight-\nSpecific Trajectories (AFST). (See [8], wherein the capability \nwas called En route Flow Planning Tool.) The AFST concept is based on the premise that as planning \nhorizons decrease (shorter look-ahead times), predictions \nabout constraints and about affected flight trajectories become more certain. With this increased certainty, flow management \ndecisions can become less conservative, i.e., more precise. \nAFST will provide more efficient and flexible flight trajectory \noptions which are consistent with prevailing en route \nconstraints, e.g., weather blockage, sector congestion, or special \nuse airspace activation. For the problem of TBFM use during severe weather, AFST \nwill formulate, prior to a flights crossing of the FH, reroutes, \ni.e., deviations around or through weather. The adjusted route \ncan then be provided to TBFM and because it has been de-\nconflicted with the weather, the new path can be maintained \nwithout minor or no further modification. This means that \ndependable schedule times can be assigned and achieved \nTBFM can remain active, thereby enabling greater efficiencies \nas compared to turning it off and reverting to MIT restrictions. IV. BUILDING THE SIMULATION PLATFORM This section describes the setup for the AFST/TBFM \nintegration study. A. RTI, Data Distribution, Time Management, and Simulation \nManagement As described in Section II, the proposed platform is similar \nto the HLA in that there is a runtime architecture which manages \nseveral distributed simulation services. To meet the \nrequirements, MITREs Center for Advanced Aviation System \nDevelopment (CAASD) developed the Simulation Data \nDistribution Framework (SDDF), a cross-platform architecture \nwhich supports several types of simulation experiments, \nconnecting a variety of applications. Additionally, SimBuilder, \ndeveloped by MITRE CAASD, is a deployment utility with a \nuser interface for managing a set of applications which operate \non a simulation platform. These two technologies work in unison \nto satisfy the requirements in the following ways. SDDF/SimBuilder allows applications to share a service host \nand communications port for joining a common simulation \nmodeling experiment. This distinguishes the applications from \nthose joining to other concurrent simulations, avoiding \ninterference. It also allows independent applications to join a \nsimulation ad-hoc, even after the simulation clock has started. \nApplications that subscribe to services via SDDF must provide \nhandling routines for events received from publishing \napplications. SDDF will buffer those events until the subscriber \nposts a READY status, which triggers those routines such \ntransactions happen regularly within the main processing cycle. The SDDF/SimBuilder centrally scripts the execution \nparameters of all applications, including the hosts, displays, and \ncommand-line parameters used for each one. This feature is \nconvenient for simulation repeatability, start-up, and shut-down. SDDF/SimBuilder serve the role of time management by \noffering multiple modes of fixed-interval time advancement. An \nHITL experiment typically runs on par with wall-clock time, i.e., \none second of simulation time takes one second. SDDF also \nsupports a time-stepped protocol in which the simulation is \nrunning as fast as it can, without any applications lagging. (The \nother major time-advance mechanism, next event time \nadvance, is not available in SDDF.) Under SDDF, applications have a means to advertise the \nevent contents that they publish, and they can discover the \nservices advertised by other applications in the simulation. Note that SDDF/SimBuilder is one of several MITRE \nCAASD implementations for distributed simulation \ntechnologies based on published standards, such as HLA and \nDistributed Interactive Simulation (DIS) [2, 3]. Other research \ninstitutions may follow similar standards and build this \narchitecture for individual simulation needs. B. A Dedicated Traffic Simulator The requirements of a traffic simulator for the proposed \nplatform were discussed in Section II.B. While there
are many \ntraffic simulator options, the Total Airport and Airspace Model \n(TAAM), a highly reputable air traffic simulation package \nowned by Jeppesen [9], was selected for this case study for its \nmodeling capabilities in terminal airspace and its well-\ndocumented API. Through its APIs, TAAM allows external programs during \nruntime to control simulation progress (start, pause, end), to \nobtain traffic status, and to input TFM actions (add/delete \nflights, amend flight plan, implement RTAs for flights at fixes) \n[10]. An SDDF-compatible interface software module called \nTAAM SDDF Gateway was developed so that the runtime \ncommunication with TAAM can be effected. C. Advanced Flight-Specific Trajectories (AFST) MITRE CAASD has developed a working prototype of \nAFST, and it has been evaluated in several HITL experiments. \nIt has sophisticated route evaluation/generation algorithms. \nWith only minimal changes to the software, the AFST prototype \nwas configured to plug into our TFM integration platform. In operational use, AFST will require user interactions and \nfacilitates decision-making. A user would follow these steps: Identify constraints (e.g., severe weather): use AFSTs \ntrajectory evaluation algorithms to search for \nopportunities for rerouting affected flights Consider alternatives: construct and rank, via \nquantitative measures, various feasible routes. Collaborate on proposed route revisions: negotiate and \nseek consensus with dispatchers and controllers using \nAFSTs computer-human interface. Execute revisions: once a new route is determined, \ndistribute route update to air traffic control personnel for \nreview and issuance to pilots via AFSTs interface. Since this case study is focused on integration policy, and \nnot on human factors, the human decisions to be made with \nAFST can be simulated with are parameterization. For example, \nthe route selection process is simulated by selecting the top-\nranked route from the feasible ones generated by AFSTs \nalgorithms. Parameterizing human decisions this way allows \nAFST to run in a fast-time simulation mode. The AFST prototype software is compatible with \nSDDF/SimBuilder, so there was no additional interface to be developed. The only change required was to subscribe to flight \ntrack data from TAAM. During runtime, AFST automates the \nreroute decisions and publishes its reroute messages. D. TBFM Scheduler The functionality of TBFM in this case study is to provide \nthe STAs at the MFs. To simulate this functionality without \naccess to the actual (proprietary) TBFM software, a scheduling \nsoftware to mimic TBFM functionality was developed. This \nsoftware application takes into account site adaptation data (e.g., \nairways, fixes, and airport runways), aircraft separation matrix, \nand flying time estimates to generate a schedule and assign \nflights STAs. During simulation runtime, the scheduler subscribes to the \nTAAM-published estimated times of arrival (ETA) at the MFs, \nthen calculates and publishes the schedule of STAs. E. Integration Policy Module The Integration Policy Module governs how the AFST \nprototype, TBFM scheduler, and TAAM communicate, and the \nmodule implements a set of policies/rules to model the \ninteractions between simulation components. The following \ndefines how AFST and TBFM should interact: AFST sends flight reroutes which avoid en route \nweather. TAAM implements AFST reroutes, and updates the \nETAs to MFs. The TBFM scheduler receives the updated ETAs, and \nrevises the metering schedule when needed. TAAM receives the updated metering schedule and \ndelivers the flights pursuant to STAs at the MFs, \nmeeting the schedule times to the extent possible: with \nspeed changes (subject to the airframe performance \ncharacteristics), or by executing vectors or holding. No change in STA is allowed after flights cross the FH. F. Summary Figure 3 is a screenshot of SimBuilders user interface, \nillustrating the models/services in the proposed platform running \nin the Linux environment. Not shown on the screenshot is the \nTAAM application, which is running on an external Windows \nmachine and connecting to the simulation platform via the \nTAAM SDDF Gateway. In Fig. 3, in the center is the Integration Policy Module. \nDuring the execution of a simulation, it passes flight positions to \nAFST, and MF ETAs to the TBFM modeling component. For \nexample, a pre-specified condition might be that once a flight \ncrosses the FH, its ETA update will not be sent to TBFM (since \nwe want the original STA to be achieved). Likewise, the \nIntegration Policy Module passes STAs and reroute messages to \nTAAM. TAAM will model the reroutes and apply these to the \nappropriate flights (as flight plan amendments). TAAM will \nthen execute the STAs as RTAs to deliver the flights to MFs as \nclose to the STAs as possible. Figure 3. Connecting Simulation Modeling Components in a Time-Synchronized, Discrete Event Simulation Platform for TBFM/AFST Integration Study V. SIMULATION EXPERIMENT A. Scenario Setup An experiment was designed to simulate an operational \nscenario with arrivals flows in severe weather, using the AFST \nprototype and TBFM scheduler components for TFM \nfunctionality. The terminal airspace of George Bush Intercontinental \nAirport (IAH) at Houston, Texas was selected for the study area. \nThe weather data were taken from July 25, 2016, wherein \nconvective activity and thunderstorms were present near IAH \nfrom 18:00Z to 22:00Z. The weather did not block the MF \ncompletely and neither did it significantly impact arrival runway \ncapacity, meaning that TBFM could potentially still operate. The traffic data were taken from December 2, 2015, which \nwas a clear weather day for IAH. There were 198 arrivals and \n200 departures scheduled for the period of 18:00Z to 22:00Z. By \nusing clear-weather traffic, the simulation modeling elements \nare able to modify flight paths for weather when needed. The scenario assumes that TBFM arrival metering will \nremain active, and AFST will generate weather-avoidance \nreroutes for individual flights based on forecast weather before \nthe flight crosses the FH. Figure 4 shows the seven MFs (in \ngreen) used in this scenario, (i.e., RIICE, ZEEKK, MPORT, \nGMANN, LINKK, DOOBI, and SUUNR). The FHs for jet \naircraft are about 190 to 250 NM away from the MFs. The \nmovement of the weather was from southeast to northwest. Figure 4. IAH Airspace, Meter Fixes, and Weather at 19:00Z on July 25, 2016 B. Experiment Results The simulation experiment started by launching all the \nmodeling components (i.e., SimBuilder, TAAM, AFST, TBFM, \nand the Integration Policy Module). Once SimBuilder confirmed \npositive connection statuses, it advanced the simulation clock in the step size of one second. When all the modeling components \nfinished their respective computations for this time, SimBuilder \nadvanced another one-second step. This process was repeated \nuntil the end of the simulation time. SDDF provided the publish \nand subscribe services so that each modeling component could \ndisseminate and receive data during runtime execution. The speed of this simulation was 1.2 to 4 times faster than \nwall-clock time, depending on the number of active flights in the \nsimulation, i.e. the more the active flights, the more the weather \navoidance problems the AFST prototype solves simultaneously. \nAfter the end of the simulation, the results were compiled from \nthe log files of the modeling components. As the simulation progressed, there were 22 weather-\navoidance reroutes identified and published by AFST, and \nTAAM applied these to the affected flights. The total extra \ndistance due to AFST reroutes was 361 NM, an average of about \n16 NM per flight. Regarding meter time conformance, the total \ndeviation between the STAs and the actual arrival times at the MFs was 586 seconds for the 198 arrivals, an average of 3 \nseconds per flight. The source of the deviation is mainly from \nthe flight merging and maneuvering activities in TAAM. Table I illustrates for a particular flight (UAL21) the event \nmessages exchanged among simulation components in the \nruntime execution. This flight departed per TAAM at 17:22:00 \nand was scheduled to cross MF DOOBI at 19:42:28. Its original \nplanned route is shown (in light blue) in Figure 5(a). Before its \npath reached the FH, AFST detected a weather blockage risk, so \nAFST issued a new route at 18:24:03. This new route, shown in Figure 5(b), avoided the weather \nand was routed to an alternate MF, MPORT. The ETA to the MF \nthen became 19:58:41, which was estimated by TAAM using the \nnew route. TBFM used this ETA to calculate an STA with the \nsame time (indicating no additional delay was needed for this \nflight). At time 19:35:08, TBFM froze the STA of UAL21. At \n19:58:42, TAAM delivered the flight to the MF. TABLE I. TIMELINE OF SIGNIFICANT EVENTS FOR FLIGHT UAL21 Sim Time (hh:mm:ss) Acting Module Event or Action 00:00:00 TAAM Creates a new flight UAL21, scheduled to depart 17:22 on a flight plan [KBUF..EWC..FLM..BWG..SQS..AEX..JERNY..BEATL..DOOBI..SKNRD..KIAH] 17:21:59 TAAM Creates a route event of UAL21 17:22:00 TAAM Departs UAL21 from the origin airport 18:13:58 TAAM Publishes the ETA to MF (DOOBI) of UAL21 as 19:41:35 18:14:00 TBFM Schedules UAL21 to MF (DOOBI) at 19:42:28 18:14:00 TAAM Accepts the request to deliver UAL21 to MF (DOOBI) at 19:42:28 18:24:03 AFST Publishes a reroute event of UAL21 18:25:11 TAAM Accepts and amends the flight plan of UAL21 [BWG.SQS.EIC.LFK.LOA..MPORT..KIAH] 18:23:58 TAAM Publishes the ETA to MF (MPORT) of UAL21 as 19:58:41 18:25:01 TBFM Schedules UAL21 to MF (MPORT) at 19:58:41 18:25:01 TAAM Accepts the request to deliver UAL21 to MF (MPORT) at 19:58:41 19:35:08 TBFM Freezes the STA of UAL21 to MF (MPORT) 19:58:42 TAAM
Delivers UAL21 to MF (MPORT) at 19:58:42 (a) Original Route (b) Weather-Free Route by AFST Figure 5. UAL21 Original Route vs Weather-Free Route by AFST C. Summary In this experiment, we simulated an integrated operation of \nTBFM and AFST using the proposed platform. The operational \nscenario demonstrated that following the AFST rerouting of \nflights meant that weather had little impact on the stability of the \nmetering schedule, i.e., most STAs to the MFs could be met \nwithin an acceptable level of conformance. In follow-on research we plan to use this simulation platform \nand expand the analysis to additional operational scenarios to \nbetter understand the ability and also the limitation of AFST \nfinding usable reroutes around/through weather. If too few \nreroutes are found, then flights may make unplanned deviations \naround weather, TBFM and TAAM ETAs will be out of sync, \nassigned STAs will not be unachievable, and metering will be \nineffective and turned off. On the other hand, if a sufficient \nproportion, say 90% of weather-blocked flights2 receive viable \nreroutes, then benefits of keeping TBFM active can be achieved. \nOf course, in real-world application, a traffic manager may see \nreroute opportunities which the AFST algorithm does not \nidentify. In the posited scenario, positive benefits will accrue via the \nimproved efficiency of metering, compared to MITs. Also of \npositive benefit, reroutes may likely reduce tactical ATC \nmaneuvers, implying reduced controller workload in the adverse \nconditions of severe en route weather. VI. CONCLUDING REMARKS We have built a flexible, distributed simulation platform for \nfacilitating TFM integration studies. The platform allows \nrealistic prototypes of proposed or fielded TFM capabilities to \ninteract with each other and influence simulated air traffic. A \ndedicated air traffic simulator played the role of advancing \nflights in time and space and of evaluating the actions derived \nfrom the TFM capabilities. This addressed the need of using \nadvanced TFM capabilities for conducting integration studies or \nquantifying benefits. Such a simulation platform can not only support simulating \nTFM interactions but also promote the reuse and interoperability \nof the existing prototypes or modeling capabilities the plug-\nand-play facility of the platform eliminates the need for the ad \nhoc design of each new study. An initial experiment simulated AFST and TBFM under \nconditions of severe en route weather. AFST demonstrated an \nability to construct viable weather-avoidance reroutes. When \nthese reroutes were implemented prior to the FH, metering \ngenerated achievable STAs. Future work will investigate the \nsuccess rate of AFST constructing reroutes. \n2 Subject Matter Experts at MITRE CAASD have suggested that if more than about 10% of the metered flights cant meet their STAs, then metering would be deactivated. ACKNOWLEDGMENT The authors would like to acknowledge Lixia Song, John \nKuchenbrod, and Steve Zobell of MITRE CAASD for their \nsignificant contribution to this research. In addition, the authors \nwould like to thank for the guidance and support of David \nChaloux, Tim Stewart, Mary Hokit, Elizabeth Lacher, Emily \nStelzer, Craig Wanke, Glenn Roberts, and Joe Hoffman of \nMITRE CAASD. NOTICE This work was produced for the U.S. Government under \nContract DTFAWA-10-C-00080 and is subject to Federal \nAviation Administration Acquisition Management System \nClause 3.5-13, Rights In Data-General, Alt. III and Alt. IV (Oct. \n1996). The contents of this material reflect the views of the \nauthors and The MITRE Corporation and do not necessarily \nreflect the views of the FAA or the Department of \nTransportation (DOT). Neither the FAA nor the DOT makes any \nwarranty or guarantee, or promise, expressed or implied, \nconcerning the content or accuracy of these views. REFERENCES [1] FAA, Decision Support Systems (DSS) Status, CDM Spring 2016 \nGeneral Meeting, Retrieved January 1, 2017, from \nhttps://cdm.fly.faa.gov/wp-content/uploads/7.-DSS-CDM-DFW-3T-\nStatus_041320016.pdf. [2] Fujimoto, R., Parallel and distributed simulation, In Proceedings of the \n2015 Winter Simulation Conference, December 2015. [3] IEEE Standard for Modeling and Simulation (M&S) High Level \nArchitecture (HLA)-- Framework and Rules,\" in IEEE Std 1516-2010 \n(Revision of IEEE Std 1516-2000) , vol., no., pp.1-38, August 18 2010. [4] Bodoh, D, Wieland, F., Performance Experiments with the High Level \nArchitecture and the Total Airport and Airspace Model (TAAM), \nProceedings of the Seventeenth Workshop on Parallel and Distributed \nSimulation, 2003. [5] Wall, T., Rodgers, M., Fujimoto, R., Hunter, M., A Federated Simulation \nMethod for Multi-modal Transportation Systems: Combining a Discrete \nEvent-based Logistics Simulator and a Discrete Time-step-based Traffic Microsimulator, Simulation: Transactions of the Society for Modeling \nand Simulation International, Vol. 91(2) 148163, 2015. [6] Shresta, S. et al., Comparison of Strategies for Continuing Time-based \nMetering during Inclement Weather, ATC Quarterly, Vol. 22, No. 1, Air \nTraffic Control Association Institute (publisher), 2014. [7] Gong, C., McNally, D., Lee, C., Dynamic Arrival Routes: A Trajectory-\nBased Weather Avoidance System for Merging Arrivals and Metering, 15th AIAA Aviation Technology, Integration, and Operations \nConference, , Dallas, TX, 22-26 June 2015. [8] Stewart, T., Askey, L., Hokit, M., A Concept for Tactical Reroute \nGeneration, Evaluation and Coordination, The MITRE Corporation Center for Advanced Aviation System Development, DOI: 10.2514/6.2012-5586, 12th American Institute of Aeronautics and Astronautics (AIAA) Aviation Technology, Integration, and Operations \n(ATIO) Conference, Indianapolis, IN, 17-19 September 2012. [9] Jeppesen webpage describing TAAM: http://ww1.jeppesen.com/industry-\nsolutions/aviation/government/total-airspace-airport-modeler.jsp, \naccessed October 2016. [10] Jeppessen, TAAM Reference Manual and Model Changes Summary, \nDecember 2016. AUTHOR BIOGRAPHY Dr. Alex Tien is a Lead Analyst at The MIRE Corporation. \nHis research interest includes air traffic flow management, \naviation system performance analysis, and weather impact \nmodeling. In recent years, he has been involved in developing \nconcepts and decision support capabilities to improve TFM \nstrategic planning process and operational awareness. He \nreceived his doctorate in Civil Engineering from University of \nMaryland, College Park. David Bodoh is a Lead Systems Engineer at The MITRE \nCorporation. He has been designing and building air traffic \nmanagement simulation models for over twenty years. He is \nexperienced in developing real-time and fast-time models, \nespecially those using distributed systems. Dr. Huina Gao is a Lead Simulation Engineer at The \nMITRE Corporation. She has worked in modeling and \nsimulation of air traffic management for over 10 years. She holds \na Ph.D. degree in Decision Science and a master degree in \nApplied Statistics from University of Maryland, College Park. James DeArmon is a Principal Engineer with The MITRE \nCorporation. He has worked for the last several years in research \nand modeling of air traffic flow dynamics. He holds a Masters \ndegree in Operations Research, and has written numerous papers \nin aviation and applied math. Introduction\n Simulation Architecure Design\n Requirement Overview\n Necessay Services and Modeling Components\n Run-Time Infrastructure\n Time Management Function\n Data Distribution Service\n Simulation Management Function\n TFM Modeling Component\n TFM Integration Policy Module\n Traffic Simulator Arrival Metering during En route Weather\n Benefit of Integrating A Reroute Capability\n RTI, Data Distribution, Time Management, and Simulation Management\n A Dedicated Traffic Simulator\n Advanced Flight-Specific Trajectories (AFST)\n TBFM Scheduler\n Integration Policy Module\n Summary Simulation Experiment\n Scenario Setup\n Experiment Results\n Summary Concluding Remarks\n Acknowledgment\n Notice\n References\n Author Biography\n Author Biography ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-0436. Version 9, 7/13/17 Title: Cloud Computing Expert Advances Government Missions Justin Brunelle clearly relishes working for MITRE, helping the government accelerate its use of the technology that's changing how the world operates. It's an exciting time for someone who has made web sciences his career. After all, technologiesfrom mobile systems and cloud computing to big data analytics and the Internet of Thingschange almost daily. Brunelle's specialty is cloud computing. He recently completed his doctorate in computer science from Old Dominion University and frequently publishes papers about the government's use of the cloud and provides expertise to the public and industry. \"We deliver concrete recommendations that accelerate their cloud adoption,\" he says. \"This head start enables agencies to do in days what they frequently were struggling to accomplish for months.\" Agencies call on MITRE to help them navigate challenges unique to the governmentones that commercial companies may not face. Depending on the agency, these challenges might include specific regulations, network security policies, data privacy, and other factors that constrain them from diving right into the latest technology. Brunelle has applied his cloud computing know-how to several of our sponsors. For example, last year he advised the Department of Veterans Affairs on best practices for migrating its services from legacy environments to those in a cloud. \"We helped the VA understand the processes other agencies used to migrate their services to the cloud. We outlined potential pitfalls and challenges, and helped them interface with commercial cloud providers. This ensured the solutions they were procuring would be as impactful as possible for the VAs customers.\" Brunelle has also supported the Armys efforts to adopt emerging cloud architectures. \"For the military, the challenge is that traditional cloud services rely on robust network connections and communications. But in a tactical environment in the field thats not always the case.\" His team focused on mitigating the challenge of being disconnected but still taking advantage of the benefits of cloud services. \"We performed research on algorithms, processes, and architectures that would allow computation in tactical environments to be performed even when you dont have a reliable network connection.\" Linking Knowledge Across Domains Even if the details vary, many of MITRE's sponsors have the same underlying issues when it comes to integrating or adopting new technologies. \"Cybersecurity is a big priority for everyone,\" Brunelle says. \"There's definitely a lot of cross-pollination of ideas here and a wealth of MITRE knowledge to draw from.\" https://www.mitre.org/publications/technical-papers/july-2016-federal-cloud-computing-summit-report\nhttps://www.mitre.org/news/in-the-news/mitre%E2%80%99s-justin-brunelle-offers-insight-into-government-cloud-computing\nhttps://www.mitre.org/capabilities/cybersecurity/overview?category=all Approved for Public Release; Distribution Unlimited: 17-0436. That's where Brunelle's other specialtythe ability to apply knowledge from one area for the benefit of anothercomes in. He's become crucial to an ongoing public-private collaboration that's helping government adopt emerging technologies. In this role, Brunelle coordinates MITRE's work with the Advanced Technology Academic Research Center (ATARC). ATARC is a forum for industry and academia to collaborate with the federal government to solve technology challenges. MITRE staff have been involved with ATARC since a 2013 summit that addressed mobile computing. Following the summits, MITRE develops reports on such topics as big data and the Internet of Things, which are available both on our website and ATARC's. Brunelle got involved when ATARC added a cloud computing summit. The summits first cloud computing white paper identified specific challenges facing the government adoption of cloud computing technologies and cited best practices that have been adopted by government cloud practitioners. It also included recommendations for government, industry, academia, and FFRDCs to pursue to ease and advance the adoption of cloud computing within the federal government. Since that first paper, the publications have become a series. Brunelle's collaborations with ATARC participants have also expanded his knowledge well beyond cloud computing. \"I now work with any kind of emerging technologyInternet of Things, mobile, big data, and web science,\" he says. \"As the operator of several federally funded research and development centers, MITRE has the opportunity to influence those domains and apply lessons learned to the next emerging technology challenge. At Work or at PlayNothing but Net As a newly minted Ph.D., Brunelle also embraces the opportunities he gets to give back to the research community. He serves on the programming committees for conferences, speaks at events, and publishes in journals on topics such as web content archiving and ways to improve it with new technology, as well as advances in digital library sciences. He also was the committee co-chair for posters and demonstrations at the recent 17th ACM/IEEE Joint Conference on Digital Libraries. \"We often take principles that worked in addressing an issue with cloud computing, for instance, and apply them to web science or information retrieval.\" Even when he's relaxing, Brunelle extends his influence in the research community. He plays basketball in an engineers' league at NASA's Langley Research Center (recently in the public eye as the setting of the hit movie Hidden Figures). It's located just a few minutes away from his Hampton office. \"Every day is differentand that's a good thing. It's one of the benefits of working here. It keeps my job fun and interesting.\" by Jeremy D. Singer BOX ON CLOUD COMPUTING https://www.mitre.org/publications/project-stories/mitre-fosters-agency-collaboration-in-the-brave-new-world-of-technology\nhttps://www.mitre.org/publications/project-stories/mitre-fosters-agency-collaboration-in-the-brave-new-world-of-technology\nhttp://www.atarc.org/\nhttps://www.mitre.org/publications/technical-papers/federal-big-data-summit-report-june-2016\nhttps://www.mitre.org/publications/technical-papers/november-2015-federal-internet-of-everything-summit-report\nhttps://www.mitre.org/news/in-the-news/mitre-and-atarc-guide-government-agencies-migration-to-the-cloud\nhttps://www.mitre.org/news/in-the-news/mitre-and-atarc-guide-government-agencies-migration-to-the-cloud\nhttps://www.mitre.org/publications/technical-papers/july-2016-federal-cloud-computing-summit-report\nhttps://www.mitre.org/publications/project-stories/are-you-ready-to-be-part-of-the-internet-of-things\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://arxiv.org/abs/1601.05142\nhttps://arxiv.org/abs/1508.02315\nhttp://dlib.org/dlib/january16/brunelle/01brunelle.html\nhttps://itnews.iu.edu/events/17th-acmieee-joint-conference-on-digital-libraries.php Approved for Public Release; Distribution Unlimited: 17-0436. MITRE and Cloud Computing For more than a decade, MITRE has been at the forefront of helping the government weigh the pros and cons when it comes to moving to the cloud. By working across FFRDCs, government agencies, and even within agencies and organizations, MITRE makes connections between government, industry, and academic partners that would not be readily available in normal circumstances. In addition, our robust internal research program benefits multiple sponsors by preparing to solve future challenges. Cloud computing holds the promise for using IT resources more efficiently across the government enterprise, yielding significant cost and capability advantages in the process. Compared to industry, however, government agencies face unique constraints, including risk management and network security concerns faced by organizations such as the Department of Defense. MITRE is helping them address the evolving acquisition, management, and security considerations of adopting cloud technologies. Learn more about MITRE's work in cloud computing. https://www.mitre.org/publications/technical-papers/resiliency-mitigations-in-virtualized-and-cloud-environmentshttps:/www.mitre.org/publications/technical-papers/resiliency-mitigations-in-virtualized-and-cloud-environments\nhttps://www.mitre.org/publications/technical-papers/resiliency-mitigations-in-virtualized-and-cloud-environmentshttps:/www.mitre.org/publications/technical-papers/resiliency-mitigations-in-virtualized-and-cloud-environments\nhttps://www.mitre.org/publications/technical-papers/cloud-sla-considerations-for-the-government-consumer-0\nhttps://www.mitre.org/publications/technical-papers/critical-decision-factors-for-agile-on-federal-it-projects\nhttps://www.mitre.org/publications/technical-papers/federal-cloud-security\nhttps://www.mitre.org/capabilities/advanced-technologies/information-systems/cloud-computing Version 9, 7/13/17 ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-2850. Integrated Master Schedule (IMS)/Integrated Master Plan (IMP) Application Definition: The IMP comprises a hierarchy of program events in which each event is supported by specific accomplishments, and each accomplishment is based on satisfying specific criteria to be considered complete. The IMS is an integrated, networked schedule of all the detailed, discrete work packages and planning packages (or lower level tasks of activities) necessary to support the IMP's events, accomplishments, and criteria. Keywords: earned value management, EVMS, integrated master plan, integrated master schedule, program plan, work breakdown structure, WBS MITRE SE Roles and Expectations: The IMS and IMP form a critical part of effectively providing acquisition support. MITRE systems engineers (SEs) should understand the use and implementation of these tools and how they can be used to effectively monitor program execution. What We Know About the IMS and IMP An Integrated Master Plan (IMP) and an Integrated Master Schedule (IMS) are not equivalent. An IMP is an event-driven plan that documents the significant accomplishments necessary to complete the work and ties each accomplishment to a key program event. It defines how the project will be organized, structured, and conducted and how the total process will be controlled to provide a product that satisfies stakeholder requirements. An IMS is an integrated and networked multilayered schedule of program tasks required to complete the work effort captured in a related IMP. It is linked to both the IMP and the work breakdown structure (WBS) and is an essential companion to the IMP. The term \"integrated master plan\" is a DoD term and has no standard definition in the civil agency environment. If used in a civil agency environment, the term \"IMP\" must be a mutually agreed definition. In the DoD environment, the IMP normally is a bilateral agreement between the government and a contractor on what defines the event-driven program. Approved for Public Release; Distribution Unlimited: 17-2850. The IMS constitutes a program schedule of the entire required scope of effort, including the effort necessary from all government, contractor, and other key parties for a programs successful execution from start to finish (the period of performance). The IMS is developed from the IMP, major contractor events, accomplishments, entrance criteria, exit criteria, and the WBS, which defines the program work structure and work packages. Like the IMP, the IMS is maintained, under configuration control, through disposal or program termination. An IMS may be made up of several individual schedules that represent portions of effort within a program. Different organizations may use the term integrated master schedule differently; for example, an IMS is often used to refer solely to the prime contractor schedule. In actual practice, the government IMS usually incorporates the summary level elements of the contractors IMS, whereas the contractors IMS, as its lowest tier, includes the individual activities necessary to complete each work package. The use of integrated here implies the schedules incorporation of all activitiesthose of the contractor and their subcontractors major eventnecessary to complete a program. Together, the IMP and IMS should clearly demonstrate that the program is adequately structured, realistic, and executable and that the planned tasks are achievable within schedule and cost constraints with an acceptable level of risk. During the proposal evaluation and source selection phases, the IMP and IMS are critical components of the offeror's proposal; they identify the offeror's ability to partition a program into tasks and phases that can be successfully executed to deliver the proposed capability. After contract award, the contractor and/or the government use the IMP and IMS as the day-to-day tools for executing the program and tracking program milestone status. The IMP and IMS are business tools to manage and provide oversight of acquisition, modification, and sustainment programs. They provide a systematic approach to program planning, scheduling, and execution. They are equally applicable to competitive and sole source procurements with industry, as well as to government-only, in-house efforts. They help develop and support program/project budgeting and can be used to perform \"what- if\" exercises and to identify and assess candidate problem workarounds. Finally, use of the IMP/IMS focuses and strengthens the interaction between the government and contractor teams with respect to program execution. Best Practices and Lessons Learned Understand how the IMP and IMS differ. In general, think of the IMP as a planning tool and the IMS as the execution tool following the WBS from individual activities Approved for Public Release; Distribution Unlimited: 17-2850. through work tasks to the final product. Note that the IMS is a scheduling tool for management control of program progression, not primarily for cost collection purposes. The IMP is an event-driven plan in which the events are not tied to calendar dates; \nthey are tied to the accomplishment of a task or work package as evidenced by the satisfaction of the specified criteria for that accomplishment. Accomplishments in the IMP should have criteria for determining completion with clear evidence so that the entire program team can understand the progress. The IMS is time driven, tied to calendar dates, and should be defined to the level of detail necessary for program execution. The IMS is a hierarchical, tiered structure capable of rolling up to high-level \nsummary representations of activities as well as breaking down to the lowest level of task details showing dependencies, resources, durations, and constraints. Consider interrelationships. To build a reasonable IMP and IMS, you need to estimate the attributes of work products and work packages, determine the resources needed, estimate schedule durations, and identify and analyze program risks. The IMS should be traceable to the IMP events and accomplishments, be traceable to the WBS, be linked to the statement of work, and support the earned value management system (EVMS). The WBS specifies the work structure on which the IMS should be built and on which the EVMS should report. A good WBS includes key work efforts partitioned into discrete elements that either result in a product (i.e., document, software item, test completion, integrated product) or whose progress can be quantified (e.g., percent of software development completed, test procedures successfully run, or training material developed). The IMP is placed on contract and becomes the baseline execution plan for the program/project. The IMS should not be placed on contract; it is often a contract deliverable. Evaluate a contractor's IMS carefully. For evaluating a contractors proposed IMS, the evaluator must be knowledgeable in and familiar with the contractors technical proposal in the area of evaluation. The evaluator should focus on realistic task durations, predecessor/successor relationships, and identification of critical path tasks, viable resource loading at the task level and viable risk mitigation and contingency plans. A contractors IMS should also include, at the appropriate fidelity level, key external dependencies, subcontractor tasks and deliverables, and government GFE/GFP/GFI deliverables. An IMS without lower tier detailed information may often result in obscuring critical execution elements and contributing to failure of the EVMS to accurately report progress (for more details on EVMS, see the SEG article Acquisition Management Metrics). An unsupported high-level IMS may also fail to show related risk http://www.mitre.org/publications/systems-engineering-guide/acquisition-systems-engineering/acquisition-program-planning/acquisition-management-metrics\nhttp://www.mitre.org/publications/systems-engineering-guide/acquisition-systems-engineering/acquisition-program-planning/acquisition-management-metrics Approved for Public Release; Distribution Unlimited: 17-2850. management approaches being used, which often results in long duration tasks and artificial linkages masking the true critical path. Establish measurable criteria. Criteria established for IMP accomplishments should be measurable (i.e., satisfactory completion of a test event, approval of a study report, or verification of an activity or test). Consider including critical performance requirements (key performance parameters or technical performance metrics) as accomplishment entrance or exit criteria. Include relationships for multiple delivery/increment programs. On programs with multiple deliveries and/or multiple increments, ensure that the IMS includes cross- delivery order and cross-increment relationships. This is valuable when conducting critical path analyses on the IMS. These relationships sometimes drive \"ripple effects\" across the delivery orders and work packages. Insight into these relationships can be an extremely valuable factor when analyzing a critical path or estimating a \"what if\" or total cost for a modification. Involve stakeholders. Relevant stakeholders (including user organizations, financial managers, and sustainment organizations) should be involved in the planning process from all life-cycle phases to ensure that all technical and support activities are adequately addressed in program management products. Communicate via IMS. The IMS can be used to communicate with stakeholders on a regular basis. For enterprise systems with large numbers of external interfaces and programs, the IMS can be used as the integration tool to indicate and track milestones relevant to the other programs. References and Resources Acquisition Community Connection, Integrated Master Plan (IMP)/Integrated Master Schedule (IMS), accessed June 7, 2016. DAU, Defense Acquisition Guidebook, Chapter 11.3.1.4.2. Integrated Master Schedule (IMS), accessed June 7, 2016. Department of Defense, October 21, 2005, Integrated Master Plan and Integrated Master Schedule: Preparation and Use Guide, Ver. 0.9. https://www.dau.mil/cop/risk/Pages/Topics/Integrated Master Plan IMP and Integrated Master Schedule IMS.aspx\nhttps://www.dau.mil/cop/risk/Pages/Topics/Integrated Master Plan IMP and Integrated Master Schedule IMS.aspx\nhttp://www.acq.osd.mil/se/docs/IMP_IMS_Guide_v9.pdf\nhttp://www.acq.osd.mil/se/docs/IMP_IMS_Guide_v9.pdf Approved for Public Release; Distribution Unlimited: 17-2850. INCOSE, 2015, Systems Engineering Handbook, A guide for system life-cycle
processes and activities, Fourth Ed., INCOSETP200300204. Project Management Institute (PMI), 2013, Standard for Program Management, Third Ed. U.S. Government Accountability Office, December 22, 2015, GAO Schedule Assessment Guide: Best Practices for Project Schedules, GAO-16-89G. http://www.gao.gov/products/GAO-16-89G\nhttp://www.gao.gov/products/GAO-16-89G Integrated Master Schedule (IMS)/Integrated Master Plan (IMP) Application ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-2852. Agile Acquisition Strategy Definition: Agile acquisition is the strategy, structure, and process to effectively adopt and apply agile software development methodologies. Agile acquisition integrates planning, design, development, and testing into an iterative life cycle to deliver small, frequent, incremental capabilities to an end user. Agile acquisition in government programs requires integrated government and contractor processes and partnerships. It embraces the agile development principles of self-organizing cross-functional teams, frequent capability deliveries, continuous user participation and feedback, and evolving requirements. Keywords: acquisition strategy, agile, agile acquisition, agile development, incremental, uncertainty, rapid MITRE SE Roles and Expectations: MITRE systems engineers (SEs) are expected to understand the fundamentals of agile acquisition, identify when it is appropriate to adopt an agile strategy, and understand how to successfully adopt and implement agile practices for a program. They should understand how systems engineering processes may change within an agile environment and how to tailor them to program constraints and objectives. SEs must understand that the challenges of dynamic development, requirements, and related processes require significant rigor, coordination, and integration. Background Agile development is built around a culture of small, dynamic, empowered teams actively collaborating with stakeholders throughout product development. Agile development requires team members to follow disciplined processes that require training, guidance, and culture change. The agile method does not follow a set of standard waterfall-based prescribed formal processes. Agile methods demand processes specifically tailored for a rapid, iterative, dynamic development approach, especially in the areas of requirements, test, and systems engineering. Agile acquisition can be distilled into four core elements: 1. Structuring the program via small, frequent capability releases \n2. Valuing working software over comprehensive documentation \n3. Responding to changes in operations, technology, and budgets \n4. Actively involving users throughout development to ensure high operational value The foundational structure of an agile program, as depicted in Figure 1, is: Release: Capability delivered to users, composed of multiple sprints \n Sprint: Priority capabilities developed, integrated, tested, and demonstrated (aka iteration) Approved for Public Release; Distribution Unlimited: 17-2852. Daily scrum: Team synchronization meeting to plan activities and assess progress and \nimpediments \nFigure 1. Basic Agile Structure Enabling an agile acquisition strategy demands some degree of upfront planning and design, but it places importance on beginning development quickly. The fundamental assumption is that requirements, designs, and capabilities will evolve as team members gain information during the development process [1]. When to Use Agile In determining whether an agile acquisition strategy is appropriate for the program, it is critical to evaluate the operational, acquisition, and developer conditions. Agile acquisition strategies should be considered when: The full set of requirements cannot be defined up front, but an initial set can be \ndetermined, at least for a first release. Requirements can be decomposed into small tasks to support iterative development. \n Users want smaller, more frequent, iterative deliveries. \n Users are able to actively engage throughout development. \n User feedback is used to shape the requirements for future releases. \n Acquisition processes can be tailored to support smaller, frequent releases. \n Leadership and stakeholders support an agile acquisition strategy and processes. \n The government program office has agile trained or experienced individuals, tailored processes, and access to coaches, and developers have agile experience. Users, program office staff, and developers can establish a collaborative environment \nand are able to collocate or establish an effective virtual working environment. The program can leverage enterprise platforms, processes, and documents for \ncontracting, development, and test to enable rapid execution. Agile acquisition works best with smaller scoped developments, such as a self-contained application or incremental upgrade to an operational system. Agile can scale to apply to larger development efforts, but this requires additional rigor in technical architecture, coordination across development teams, and integration. It is difficult to develop a large infrastructure system from the start using agile development. The more agile development can leverage an established infrastructure platform, the more autonomy the team will have for their iterative development. A program can use a traditional approach to build an initial increment that meets the baseline Approved for Public Release; Distribution Unlimited: 17-2852. architecture requirements. Once the program has established a baseline and framed the overall conceptual design, program managers can consider shifting to an agile approach for subsequent releases that build additional functionality into the operational baseline. Best Practices and Lessons Learned Setting up an agile environment. An agile acquisition strategy represents a change in the way the government traditionally conducts business. Programs must rethink how they are staffed, organized, and managed, and they must structure the business processes, governance reviews, and funding models to support agile methods. Agile requires dedicated government involvement throughout the entire process in order to plan and integrate multiple releases, oversee development cycles, manage evolving requirements, facilitate collaboration, and obtain committed, active, and consistent user engagement. The optimal structure to foster a collaborative environment features physical collocation of the acquisition support team, which consists of the program staff, contractor, and supporting functional areas. Constant communication across the team is essential. Most agile methodologies require daily meetings for status, direction, feedback, and assignments. A culture of trust that spans the decision authority, developers, testing organization, acquirers, program management, and users is critical to successful agile delivery. Structuring an agile program. The way a program is structured into releases and sprints from the start can play a key role in its success over the life cycle. Government program managers in consultation with operators and developers must determine the optimal timelines for releases and sprints on the basis of various constraints, risks, and other factors. The primary drivers include how frequently the operational community wants and can integrate new releases, and the ability of the development environment to regularly build, integrate, test, quality assess, and deploy capabilities. Traditional acquisition, contracting, budget, test, and related processes constrain development, but the program should tailor these processes to support smaller, more frequent releases. Active stakeholder engagement and contributions can aid the program in designing the acquisition and development processes to fit the planned structure. Requirements management. The agile methodology embraces requirements change throughout development. Because it is often difficult to define the full set of requirements for systems up front, they can be iteratively identified and shaped along the way. Given the rapid pace of changes in technologies and operational environments, requirements can evolve over time. Active user involvement is needed to inform the development process and provide feedback based on early releases. This gives users the opportunity to add, edit, and delete requirements with sufficient management controls. Requirements are managed via a prioritized product backlog that is typically in a database format, instead of a single document. A product owner from the user community traditionally controls the requirements backlog. The highest priority requirements that can be developed within the set timeframe define the scope of the next release. Approved for Public Release; Distribution Unlimited: 17-2852. Release requirements can be changed during development. Sprint requirements are an agreed-to subset of a release between the users and developers and are locked, preventing changes for this short interim build. See Figure 2. \nFigure 2. Program, Release, and Sprint Backlogs Systems engineering. In an agile environment, systems engineering requires tailored methods and processes to incrementally deliver capabilities. SEs play a critical role in technical and programmatic integration via disciplined engineering processes. To enable faster, smaller deliveries, enterprise architectures are required to guide system design. Agile systems engineering practices, such as design reviews, are not one time events for the entire system, but rather an iterative process with smaller, more frequent reviews built into each release. It is critical to keep all key stakeholders informed on a regular basis, given the rapid and dynamic nature of the agile environment. Conducting a demonstration of capabilities at the end of each sprint and release is an opportunity to bring users, developers, and other stakeholders together to drive collaboration and decision making. It is important to put in place a clear architecture that is refined over time as sprints and releases are developed. The architecture should be government managed and should involve active collaboration with the contractors developing capabilities governed by it. SEs should periodically hold technical reviews for large elements of the system (broader than any release) to assess designs, performance, and alternatives. SEs should actively partner with testers to ensure active and early involvement in the process and to establish a common set of expectations for outcomes. Architecture. The architecture of the system should have enough flexibility so that capabilities can be designed, added, or modified with functional independence. In other words, the system is architected and designed so that capabilities scheduled for delivery can interoperate with the components that have been delivered and do not have critical operational dependencies on capabilities that have not yet been delivered. Layered architectures lend themselves to this application. Components may be developed for different layers; concentrating on the most commonly used/reused components first. An initial capability for delivery could be a component that
crosses layers and provides utility to the user (\"user-facing\"). Approved for Public Release; Distribution Unlimited: 17-2852. Lessons Learned: Apply agile acquisition practices where they work best: on smaller programs and ones \nthat can be sub-divided into smaller elements. Attempting to develop very large systems via agile methods will be a challenge and requires a higher level of expertise to scale effectively. Ensure that stakeholders in the operational and acquisition community agree on the \nsize/frequency of releases and sprints (or related terms). Releasing capabilities to the users every 612 months and the developers demonstrating interim capabilities monthly is an approach used by many government agile programs today. Arrange for close, physical proximity of the program, developers, and users to enable \nfrequent communication that is characteristic of agile developments. Use small, empowered cross-functional teams to enable program agility and meet \naggressive program schedules. Use a portfolio-based approach to allow programs to take advantage of efficiencies \ngained across several agile development efforts (e.g., portfolio-level agile development contract, portfolio-level testing and certification processes). Establish team criteria to define when a user story is considered done. \n Use a Change Control Board for larger programs to manage product backlog grooming decisions. Obtain agreement from the operational user community to provide users who can \nparticipate in the development, testing, and feedback process. Hold user forums to enhance collaboration and ensure that all stakeholders understand \nand agree on the program's priorities and objectives. Provide systems engineering information to all key stakeholders on a consistent, regularly \nscheduled basis, either through design reviews or program reviews. Use the release planning and sprint demonstrations as opportunities to bring users, \ndevelopers, and stakeholders together in face-to-face sessions to drive collaboration and strengthen teaming arrangements. Ensure that once a clear architecture is in place, SEs continue to refine it as they learn \nmore from the development sprints and releases. Independent of releases, hold periodic technical reviews for larger epics, strategic \nplanning, grooming the program backlog, managing resources, and shaping the programs direction. Capture systems engineering processes and related content in portfolio-level systems \nengineering plans for broad use. Individual releases can capture the scope details in small appendices approved at a low level. Per the recommendation of experts in agile methods, use common (ideally open sourced) \nplatforms, standards, interfaces, and application program interfaces (APIs) over costly point-to-point interfaces. Institute rapid prototyping that allows developers and government organizations to \nquickly demonstrate potential solutions that meet urgent requirements, mature and Approved for Public Release; Distribution Unlimited: 17-2852. integrate technologies for the particular solution space, and highlight advantages over alternative options. Establish an environment that includes processes and properly configured test platforms \nto rapidly prototype capabilities that extend beyond the next increment or project. This opens up opportunities for innovative and dynamic solutions. Use automated tools to enable continuous integration, reduce delays in integration and \ntesting, and provide configuration management functionality. References and Resources 1. Modigliani, P., and S. Chang, March 2014, Defense Agile Acquisition Guide: Tailoring DoD IT \nAcquisition Program Structures and Processes to Rapidly Deliver Capabilities, The MITRE Corporation. Additional References and Resources Balter, B., 2011, Towards a More Agile Govt: The Case for Rebooting Federal IT Procurement, Public Contract Law Journal, Vol. 41, No. 1. Government Accountability Office, July 27, 2012, Effective Practices and Federal Challenges in Applying Agile Methods, GAO Report 12-681. Lapham, M. A., S. Garcia-Miller, L. Adams, N. Brown, B. Hackemack, C.Hammons, L. Levine, and A. Schenker, October 2011, Agile Methods: Selected DoD Management and Acquisition Concerns. Software Engineering Institute. Lapham, M. A., R. Williams, C. Hammons, D. Burton, and A. Schenker, April 2010, Considerations for Using Agile in DoD Acquisitions, Software Engineering Institute. Manifesto for Agile Software Development (i.e., the Agile Manifesto), accessed June 7, 2016. Northern, C. et al., December 15, 2010, Handbook for Implementing Agile in Department of Defense Information Technology Acquisition, MITRE Technical Report MTR 100489. http://www.mitre.org/publications/technical-papers/defense-agile-acquisition-guide-tailoring-dod-it-acquisition-program\nhttp://www.mitre.org/publications/technical-papers/defense-agile-acquisition-guide-tailoring-dod-it-acquisition-program\nhttp://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1966241_code1753579.pdf?abstractid=1966241&mirid=1\nhttp://www.gao.gov/products/GAO-12-681\nhttp://www.gao.gov/products/GAO-12-681\nhttp://www.sei.cmu.edu/reports/11tn002.pdf\nhttp://www.sei.cmu.edu/reports/10tn002.pdf\nhttp://www.sei.cmu.edu/reports/10tn002.pdf\nhttp://agilemanifesto.org/\nhttp://www.mitre.org/publications/technical-papers/handbook-for-implementing-agile-in-department-of-defense-information-technology-acquisition\nhttp://www.mitre.org/publications/technical-papers/handbook-for-implementing-agile-in-department-of-defense-information-technology-acquisition Agile Acquisition Strategy ",
    "text": " () Simulated Patient Data Fuels a New Tool for Healthcare Innovators Keywords: Healthcare, open source software, health IT, health data, de-identified data, innovation, healthcare data, Standard Health Record Collaborative (SHRC), Synthea Lack of useable patient data can stifle innovation in healthcare. So, MITRE employees designed Synthea, a tool that creates simulated patient records. We offer it as open source software without chargeand the health IT community has embraced it. One of the biggest changes in healthcare isn't taking place in the operating room. It's coming in bits and bytes of data. Digital data can open many doors in the advancement of the quality of healthcare. Such as the ability for researchers to use computer-based patient health records to develop analytical measures and clinical decision-support tools. To get a complete picture of the patient, providers must merge electronic health record (EHR) system information from multiple sources; health data interoperability is key to this integration of patient information. And it is key to the promise of establishing a \"learning\" health system in which science, informatics, incentives, and culture are aligned for continuous improvement and innovation. However, all these advances require access to vast amounts of information about people, their health conditions, their lifestyles, their health outcomes, and a host of other factors. But due to privacy regulations, that data is extremely hard to come by even for highly justified causes. But now, MITRE researchers have found a way to create mock patients with realistic health issues to generate the data that's needed. Our solution is an open source software tool called \"Synthea,\" a contraction of \"synthetic\" and \"health.\" Synthea generates synthetic patients and their medical histories based on simulated incidences. Their ailments and conditions range from allergies and asthma, to lung cancer and lupus, to total joint replacements and urinary tract infections. https://synthetichealth.github.io/synthea/#home All this information about synthetic patients creates a synthetic \"world\" that can be fed into EHR systems and services under development. By simulating the health of these patients, from onset of conditions through treatment for some of the most frequent and chronic ailments in the United States, developers have a set of usable, realistic data to work from with no restrictions whatsoever. Researchers from around the world now use Synthea to move healthcare forward. Innovators Stopped \"Dead in Our Tracks\" The Synthea saga has its origins in MITRE's work in support of the healthcare IT community. \"We needed patient datasets we could use to test software we were developing, such as clinical quality measures,\" MITRE's Jason Walonoski explains. However, researchers can't use actual patient data except under rare circumstances. That meant the MITRE team and other innovators needed to turn to patient data that has been \"de-identified\" and can't be linked to an actual patient. De-identified data is available but can be very expensive to purchase. In addition, even its use is often restricted and, in some cases, the quality of the data is marginal at best. Another problem, Walonoski says, is that \"it's relatively easy to re-identify the data with a real person, and then you could be in violation of the Health Insurance Portability and Accountability Act [HIPAA] and other laws.\" According to group leader Dr. Mark Kramer, who focuses on health IT interoperability, \"The lack of useful patient data was stifling innovation in healthcare. We were being stopped dead in our tracks.\" So, five years ago, Kramer and his colleague Dr. Marc Hadley began investigating the possibility of building a solution that could generate synthetic data for healthcare research and analytics. Kramer dubbed it Synthea. The team built Synthea with factual human disease models that create synthetic patients and their related health conditions and behaviors to reflect real U.S. populations. MITRE researchers culled clinical care data and academic research to build the Synthea disease models. The team then combined that data with disease incidence and prevalence statistics from the U.S. Centers for Disease Control and Prevention, the National Institutes of Health, and other government sources to create clinical disease \"modules\" that simulate health events that could occur in a real patient's life. Finally, they added demographic data provided by the United States Census Bureau and other sources. https://www.mitre.org/centers/cms-alliances-to-modernize-healthcare/where-we-focus/health-it They tested their work through a demonstration project, SyntheticMass, which models the health information of more than one million Massachusetts residents. (Read \"A World of Bay Staters Changing Electronic Health Records\" below.) An Open Source Solution Bridges the Gap The team knew there would be high demand for Synthea data in the healthcare IT community. There was little doubt in their minds that the solution would have broad impact when implemented as a publicly accessible, open source project. \"Open source is a way to innovate and attract collaborative user communities,\" Kramer notes. \"You can obtain an even higher rate of progress by engaging external communities in the system's development. As Sun Microsystems co-founder Bill Joy once said, 'No matter who you are, most of the smartest people work for someone else.' Open source helps bring in the smartest people.\" Researchers can use Synthea's Generic Module Framework (GMF) to create their own illness and disease modules and describe a progression of health states and the transitions between them. The GMF is available to the entire community via the GitHub repository, and the simulated patient health records can be exported in several different standard health data formats to provide researchers additional flexibility. \"People around the world are using the data from Synthea, and folks from as far away as Australia and New Zealand are collaborating with us on improvements,\" Walonoski says. \"It truly is a global project, which we are developing and offering as open source code, in the public interest.\" The Increasing Role of Data in Healthcare \"More and more, the healthcare field is about digital patient data,\" Kramer adds. \"We're helping the next generation of healthcare workers in the broadest sensefrom a new class of doctors to nursing informatics specialiststo understand and work with realistic patient data.\" \"We're also enabling innovators to get into health IT because they now have access to realistic health data free of legal, privacy, security, and intellectual restrictions,\" Walonoski says. \"They're using Synthea data to develop software applications, advance health data sharing, and to perform preliminary testing on their new, innovative digital healthcare services.\" https://github.com/synthetichealth/synthea Synthea is also part of the Standard Health Record Collaborative, an open source, health data interoperability effort started by MITRE. The collaborative's focus is to develop a Standard Health Record (SHR) and the technological infrastructure that will make it easier to deliver patient-centric services. \"The type of information provided by Synthea is critical to developing health record standardization,\" says SHR team leader Andre Quina of MITRE. \"We're aiming for a single, high-quality SHR that takes a 'one human, one health record' approach to digital healthcare.\" Additionally, the data standards organization Health Level Seven International singled out Synthea and SyntheticMass this past spring for its contributions to health IT research following Walonoski's presentation at the HL7-AMIA Datathon. Synthea holds other promises as well. \"Synthea also simulates the behaviors of patients, not only their healthy and non-healthy behaviors, but also their care-seeking behaviors,\" Kramer says. \"In the future, we might be able to capture the impact of accessibility to health services and the costs of health services on the health outcomes of a population. And, intriguingly, maybe we can even make predictions about the impact of specific health policies on the overall health of a community.\" --by Jim Chido ENDBAR A World of Bay Staters Changing Electronic Health Records SyntheticMass supplies simulated health data for more than one million synthetic patients in Massachusetts that provides a snapshot of the health of a community at the county and city levels, as well as representative synthetic individuals. The synthetic data align with actual clinical, standard of care, and demographic statistics. Our researchers then folded in the top 10 reasons why patients visit their primary care physicians and the top 10 diseases and chronic conditions that result in shorter lifespans. So, for example, if 10 percent of the population in Fall River have diabetes, 10 percent of the patients in synthetic Fall River have diabetes. http://standardhealthrecord.org/\nhttp://blog.hl7.org/3fhirapproaches\nhttp://blog.hl7.org/3fhirapproaches\nhttps://www.amia.org/jointsummits2017/datathon\nhttps://syntheticmass.mitre.org/about.html The long-term vision? To create \"SyntheticUSA,\" with a population of 330 million simulated or synthesized patients reflecting the health statistics of the U.S. Each \"patient\" would include a longitudinal or comprehensive summary of their clinical experiencesbut without the privacy concerns of using actual patients' health information. Those realistic-but-not-real health records would be available free of charge for researchers, clinicians, policymakers, and software developers who are creating the next generation of health information technology. Approved for Public Release; Distribution Unlimited: 17-2799. Simulated Patient Data Fuels a New Tool for Healthcare Innovators ",
    "text": " () Performance Management Service Level and Activities Calculator 1 Ellen Wingrove, Principal Information Systems Engineer, ebirch@mitre.org2 This paper describes the development of a \"calculator\" that can be used to provide an initial view of the optimum set of activities to manage the performance of an application. The calculator shows Performance Management service levels, activities, and roles for the full software development lifecycle (SDLC). Table of Contents 1. INTRODUCTION \n Characterizations of three Performance Management areas: Performance Engineering (PE), Capacity Planning (CP), and Performance Operations (PO) Development of the following for the three Performance Management areas across the SDLC: \n Service levels Activities Organizational roles and responsibilities Integration points 1 2 The authors affiliation with The MITRE Corporation is provided for identification purposes only, and is not intended to convey or imply MITRE's concurrence with, or support for, the positions, opinions or viewpoints expressed by the author. In testing, it was found that recommended activities were being done in the later life cycle stages, but there was a lack of emphasis on planning and budgeting and on requirements gathering for performance and capacity. This confirmed a lack of Performance Management activities early in the SDLC. 2. Performance Management Definition Performance Management can be considered as a set of activities within Capacity Management, one of the processes found in the Service Design phase of the Information Technology Infrastructure Library (ITIL) V3 service delivery lifecycle. Capacity Managements goal is to ensure that cost-justifiable capacity in all areas of IT always exists and is matched to the current and future agreed needs of the business, in a timely manner. Capacity Management is not a one-time design activity, but an ongoing process that looks at the entire IT environment throughout the service delivery lifecycle and has both proactive and reactive elements. Capacity Management also works with the ITIL V3 Service Level Management process to ensure that service level targets for new services are reasonable considering capacity constraints. Performance Management begins in the design of a new or changed service and includes planning of hardware, software, staffing, and processes to ensure successful deployment. Performance Management fits within the proactive element of Capacity Management by predicting future needs, developing capacity solutions, and engaging with service level management to ensure achievable performance targets. Reactive elements of Performance Management occur post-deployment. They include monitoring and responding to threshold alerts, assisting the service desk in resolving incidents, and conducting capacity-related root cause analyses. Performance Management begins with an understanding of business demands and performance targets, as well as current capacity, performance, and technology limitations. Only after methodical performance and capacity modeling has yielded capacity requirements should procurement of resources begin. This ensures that acquisitions are defendable, and it increases the likelihood of selecting the best solution considering total cost of ownership and scalability. 2.1 Performance Management Areas The three Performance Management areas have the same concerns, but each has a different focus, so each has different activities. Together, the Performance Management areas focus on continuous evolution and improvement of systems. Each area informs the others, as shown in Figure 1. Figure 1: Performance Management Lifecycle The three Performance Management areas are: Performance Engineering (PE) The focus of Performance Engineering is to maximize performance in the design \nof an application, given defined service levels (e.g., availability, response time), system capacity (e.g., processor, Capacity Planning (CP) Focus: Resources \n Given Design \n Given Service Levels \n Given Workload Performance Operations (PO) Focus: Service Levels \n Given Design \n Given Resources \n Given Workload Performance Engineering (PE) Focus: Design \n Given Service Levels \n Given Resources \n Given Workload memory, storage, network bandwidth), and workload size (e.g., transactions, users). Performance Engineering occurs in the early part of the lifecycle, concluding with the testing phase. Capacity Planning (CP) The focus of Capacity Planning is to optimize system capacity (e.g., processor, memory, \nstorage, network bandwidth), given the design of the application, defined service levels (e.g., availability, response time), and workload size (e.g., transactions, users). Capacity Planning efforts occur primarily in the middle part of the lifecycle, based on testing phase results. Performance Operations (PO) The focus of Performance Operations is to manage the operational system \n(hardware, operating system, system software, application) to defined service levels (e.g., availability, response time), given the implemented system capacity (e.g., processor, memory, storage, network bandwidth), the design of the application, and workload size (e.g., transactions, users). Performance Operations efforts occur primarily in the latter part of the lifecycle, after application deployment. 3. Development of Performance Management Program To support rapid decision making on which Performance Management activities should be conducted for applications, a standard program has been developed based on standard SDLC activities, lead organizations, scenarios for different categories of applications, service levels, and service level criteria. 3.1 Activities and Service Levels The following steps can be used in developing a Performance Management program for an application: Assign appropriate organizational SDLC activities to each of the Performance Management areas. \n Assign a lead organization for each activity. \n Using the following definitions of major service levels, determine whether each activity should be performed based on the service level: Gold (G) top level of service Silver (S) average level of service Bronze (B) lowest level of service Table 1 shows example activities, SDLC phases, minimum service levels, and lead organizations. SDLC Phases are defined as: Phase 0 Vision \n Phase 1 Planning \n Phase 2 Requirements \n Phase 3 Design \n Phase 4 Develop / Test \n Phase 5 Deploy / O&M (Operations and Maintenance) As examples: PE activity 3 should be done for all service levels (gold, silver, and bronze), because it is defined for the bronze \n(B) level PE activity 6 is only required for the gold (G) level \n CP activity 1 should be done for the silver and gold levels (S) Table 1: Example Performance Management Activities, Service Levels, and Organizations 3.2 Scenarios Scenarios of different applications have been developed to show activities across the SDLC lifecycle for each Performance Management area. Table 2 shows sample scenario definitions, including initial evaluations of service levels. Table 2: Scenario Definitions 4. Service Level and Activities Calculator A spreadsheet has been developed (available on request) that implements the above defined Performance Management program. The following sections show the data entry and calculations in the calculator (specific instructions are in the spreadsheet). The overall process is shown in Figure 2. Figure 2: Performance Management Calculator Process The calculator uses entered application information and ratings against defined criteria to determine Performance Management service levels and activities for the application. Calculated activities can then be compared to the applications project plan to ensure the appropriate Performance Management activities are in the plan to cost effectively minimize risk of performance or capacity issues. 4.1 Criteria, Metrics, System Information, and Service Rating Criteria to be used to determine service levels are defined for each of the Performance Management areas, along with service metrics for high (5), medium (3), or low (1) values. The spreadsheet criteria and activities can be customized for each organizations priorities. System information is entered and ratings are entered based on the service metrics definitions. Table 3 shows example criteria for the three Performance Management area, along with entered system information and rating. Table 3: Service Level Criteria and Metrics Performance Engineering Criteria and Metrics Definitions Service Metrics App Info Rating # Criteria Name Criteria Definition Criteria Justification High (5) Medium (3) Low (1) 1\nMany/Complex Interfaces Many or complex interfaces Many and/or complex interfaces may need capacity planned more carefully >4 interfaces and/or 1 complex interface\n>=2-4 interfaces <2 interfaces 1 complex interface\n5 2 High WAN Use\nSignificant amount of WAN transmission Extensive use of WAN to transmit data may need to be engineered and tested more extensively\n>155 Mb/sec (OC3) >=52-155 Mb/sec (OC1+)\n<52 Mb/sec OC1 3 3 Many Lines of Code Multiple hardware platforms and/or locations Multiple hardware platforms and/or locations may be more complex to manage\n>500K SLOC >=100-500K SLOC <100K SLOC 200 SLOC 3 4\nMany Performance Reqs\nShared infrastructure Shared infrastructure may need capacity planned more carefully\n>100 requirements 50-100 requirements <50 requirements 120 requirements 5 5 Code Not Stable\nExtensive disaster recovery Extensive disaster recovery (DR) capabilities may need capacity planned more carefully\n>25% changed >=10-25% changed <10% changed 11% code change 3 6\nPrior Problem Tickets\nMany users Many users may need capacity planned more carefully >50 unique errors / past year >=25-50 unique errors past year <25 unique errors / past year\n70 app errors 5 7 New System\nSignificant workload change Significant workload change may need capacity planned more carefully\nyes no existing app 5 8 Mainframe\nMonitoring in place/planned Monitoring capabilities implemented/planned, may have stringent performance requirements\nmainframe Linux PC Tier 2 3 4.2 Service Level Calculation The spreadsheet calculates service levels for each Performance Management area, based on the ratings shown in Table 3. Figure 3 shows the service level calculator results using the Table 3 ratings. Figure 3: Service Level Calculator Results Capacity Planning Criteria and Metrics Definitions Service Metrics System Info Rating # Criteria Name Criteria Definition Criteria Justification High
(5) Medium (3) Low (1) 1\nMany/Complex Interfaces Many or complex interfaces Many and/or complex interfaces may need capacity planned more carefully >4 interfaces and/or 1 complex interface >=2-4 system interfaces\n<2 system interfaces 1 complex interface\n5 2 High WAN Use\nSignificant amount of WAN transmission Extensive use of WAN to transmit data may need to be engineered and tested more extensively\n>155 Mb/sec (OC3) >=52-155 Mb/sec (OC1+)\n<52 Mb/sec OC1 3 3 Multiple HW Platforms/ Locations Multiple hardware platforms and/or locations Multiple hardware platforms and/or locations may be more complex to manage >2 HW platforms/locations 2 HW platforms/locations 1 HW platform/location\n2 HW locations 3 4\nShared Infrastructure\nShared infrastructure Shared infrastructure may need capacity planned more carefully All components on shared infrastructure Some components on shared infrastructure No components on shared infrastructure\nnot shared 1 5 Disaster Recovery\nExtensive disaster recovery Extensive disaster recovery (DR) capabilities may need capacity planned more carefully\n>=50 GB replicated >=50 GB backed up <50 GB replicated or backed up\n70 GB backup 3 6 Large User Base Many users Many users may need capacity planned more carefully >200 users >=50-200 users <50 users 20 users 1 7 Workload Stability\nSignificant workload change Significant workload change may need capacity planned more carefully\n>25% workload change >=10-25% workload change\n<10% workload change 5% workload change\n1 8 Monitoring\nMonitoring in place/planned Monitoring capabilities implemented/planned, may have stringent performance requirements Performance and error monitoring\nOnly error monitoring No monitoring no monitoring 1 Performance Operations Criteria and Metrics Definitions Service Metrics System Info Rating # Criteria Name Criteria Definition Criteria Justification High (5) Medium (3) Low (1) 1\nMany/Complex Interfaces Many or complex interfaces Many and/or complex interfaces may need capacity planned more carefully >4 interfaces and/or 1 complex interface >=2-4 system interfaces\n<2 system interfaces 1 complex interface\n5 2 High WAN Use\nSignificant amount of WAN transmission Extensive use of WAN to transmit data may need to be engineered and tested more extensively\n>155 Mb/sec (OC3) >=52-155 Mb/sec (OC1+)\n<52 Mb/sec OC1 3 3 Multiple HW Platforms/ Locations Multiple hardware platforms and/or locations Multiple hardware platforms and/or locations may be more complex to manage >2 HW platforms/locations 2 HW platforms/locations 1 HW platform/location\n2 HW locations 3 4\nShared Infrastructure\nShared infrastructure Shared infrastructure may need capacity planned more carefully All components on shared infrastructure Some components on shared infrastructure No components on shared infrastructure\nnot shared 1 5 Disaster Recovery\nExtensive disaster recovery Extensive disaster recovery (DR) capabilities may need capacity planned more carefully\n>=50 GB replicated >=50 GB backed up <50 GB replicated or backed up\n70 GB backup 3 6 Customer Facing Many users Many users may need capacity planned more carefully Customer facing Not customer facing\nnot customer facing\n1 7 Workload Stability\nSignificant workload change Significant workload change may need capacity planned more carefully\n>25% workload change >=10-25% workload change\n<10% workload change 5% workload change\n1 8 Monitoring\nMonitoring in place/planned Monitoring capabilities implemented/planned, may have stringent performance requirements Performance and error monitoring\nOnly error monitoring No monitoring no monitoring 1 Criteria # Cross-Reference 1 2 3 4 5 6 7 8 System PE Service Many/Complex \nInterfaces High WAN Use Many Lines of Code Many Performance Reqs Code Not Stable Prior Problem Tickets New System Mainframe Sample System 32 5 3 3 5 3 5 5 3 Criteria # Cross-Reference 1 2 3 4 5 6 7 System CP Service Many/Complex \nInterfaces High WAN Use Multiple HW Platforms/ Locations Shared Infrastructure Disaster Recovery Large User Base Workload Stability Sample System 17 5 3 3 1 3 1 1 Criteria # Cross-Reference 1 2 3 4 5 6 7 8 System PO Service Many/Complex \nInterfaces High WAN Use Multiple OS Platforms/ Locations Shared Infrastructure Disaster Recovery Customer Facing Business Critical Monitoring Sample System 13 1 3 2 1 3 1 1 1 Gold Service > 21 Silver Service > 14 Bronze Service > 0 System PE Service CP Service PO Service Sample System 32 17 13 4.3 Activities for Service Levels Detailed activities for each Performance Management area are defined by the spreadsheet based on calculated service levels. Table 4 shows some color-coded activities for PE, along with lead organizations, and associated SDLC artifacts. For the top service level (Gold), all activities are done (color-coded in gold, silver, and bronze). The Silver service level activities are color- coded in silver and bronze. The Bronze service level activities are in bronze. Only the first three SDLC phases are shown. Table 4: Performance Engineering Activities 5. Summary The Performance Management Service Level and Activities Calculator is intended to be used as a first cut at service level definitions and used during the requirements definition process. The spreadsheet criteria and activities can be customized for each organizations priorities. It can also be used as a first step towards an enterprise-wide standard Performance Management program. Since it is often difficult to make this first step, the Service Level and Activities Calculator can provide a simple tool for developing service levels and defining activities to manage to these service levels. Performance Engineering Activities Phase Lead Organization SDLC Artifacts 1 Define Business Need 0 Project Office End-to-End Costing Spreadsheet (E2E) Develop a business case for the system understand the business problem being addressed by the system, identify and meet with stakeholders, define a high level solution E300 Capital Asset Plan and Business Case Summary Coordinate with CP steps 1-2 (convert business needs into initial system capacity estimates for costing and capital asset plan) and PM steps 1-2 (convert business needs into performance management needs) Solution Concept 2 Convert Business Needs to Performance Needs/Standards Engineering Define high level performance metrics for throughput, response time, processing time, and utilization (CPU, memory, storage, network) Incorporate performance metrics into high level solution Coordinate with CP step 1-2 (convert business needs into initial system capacity estimates for the solution concept) 3 Tailor PE Activities for Project Plan 1 Engineering E300 Capital Asset Plan and Business Case \nSummary (updated) Determine system service type (bronze, silver, gold) via criteria Acquisition Management Plan Define specific PE activities for system based on service type 4 Incorporate PE Activities into Project Plan Project Office Approve PE activities and incorporate into project plan, acquisition plan, and business case Determine PE activities' schedule, including coordination with other Performance Management activities 5 Decompose Requirements into Detailed Performance Requirements 2 Engineering Business System Architecture Report \n(BSAR) Translate business requirements into performance and capacity requirements, including use cases and assumptions Business System Requirements Report (BSRR) Develop performance & capacity sections of Business System Reports Business System Concept Report (BSCR) Introduction\n Performance Management Definition\n Performance Management Areas Development of Performance Management Program\n Activities and Service Levels\n Scenarios Service Level and Activities Calculator\n Criteria, Metrics, System Information, and Service Rating\n Service Level Calculation\n Activities for Service Levels Summary ",
    "text": " () Approved for Public Release; Distribution Unlimited: 17-3083. Intern Project Amplifies Benefits for Hard of Hearing Community We've all experienced video calls with annoying technical issues, from poor audio to blurry video. Now imagine you are deaf or hard of hearing (HOH) and you try to interpret sign language on incompatible video phone devices and software made by multiple vendors. It's not only annoying, it's unacceptable. MITRE is doing something about that, with the help of four deaf and HoH interns from Gallaudet University and Rochester Institute of Technology. The students add a unique perspective to the company's work developing Video Relay Service (VRS) prototypes for the Federal Communications Commission (FCC) National Test Lab. (VRS services allow deaf and HoH people to communicate with others through a third person using sign language.) The students test various devices and software to ensure interoperability and compatibility of these systems. They provide critical insight into the communications preferences of deaf and HoH people. The overall goal is to help ensure top video quality, latency delay, and consistent connections through the entire call. \"I've had video calls where the video input from the other side is blurry or pixelated,\" says intern Michael Tota, a junior information technology major at Gallaudet University. \"That makes it hard for me to understand what the other person is saying using sign language. Other times, the other side has difficulty understanding me. It's important for all video phone providers to be compatible so that the deaf and HoH community has 100 percent access to communications.\" \"Since I use VRS outside of this project, being able to apply my experience to real3life situations and seeing how the results come out is great,\" adds Grace Yukawa a senior mechanical engineering student at Rochester. \"This is crucial in the deaf community since VRS is one of our primary modes of communicating.\" Research Team Energized by Interns MITRE has been working on this project for a while. \"Our project started two3and3a3half years ago as a research3based approach to solving problems and guiding data3driven decisions for the FCC,\" says MITRE's Jeff Rogers, who came up with the idea of using the interns this summer. \"MITRE's research represents a fundamental shift in how the FCC proposes, makes, and sets policies and rates for the Telecommunication Relay Service [TRS].\" The students are working on two FCC3funded community service products: https://www.mitre.org/publications/project-stories/better-telecom-technology-helps-an-underserved-community-reach-out\nhttps://www.mitre.org/publications/project-stories/better-telecom-technology-helps-an-underserved-community-reach-out Approved for Public Release; Distribution Unlimited: 17-3083. Video Relay Service (VRS), which is a video telecommunication service that allows deaf, HoH, and speech3impaired people to communicate over video telephones and similar technologies with hearing people in real time, via sign language. Internet Protocol Captioned Telephone Service (IP CTS), which allows people to speak directly to the called party and then listen, to the extent possible, to the other party and simultaneously read captions of what the person is saying. \"Having these students here at MITRE is refreshing and energizing,\" Rogers adds. \"We want to gain experience with the deaf and HoH community as part of our prototype and pilot development so we can advance the technology to support this community. The students give us that, while gaining some great experience working on the VRS.\" Developing Connections for Careers and Communications \"This program benefits both MITRE and the students,\" MITRE's Reeta Singh says. \"We get new, diverse viewpoints from people who are dealing with hearing issues every day. And the students get access to equipment and MITRE people to develop some real experience they can use in their careers.\" The students agree. \"It's such a fantastic experience for me to work on ways to improve VRS interoperability,\" Tota says. \"Not all deaf people have the same devices and software. It's all based on personal preferences, so it's important that all the devices and software work together without problems. The coolest thing about this project are the tests on devices and software that I've never used before.\" \"My experience has been very beneficial,\" adds Minnie Buenventura, a senior at Gallaudet pursuing an information technology degree. \"I'm part of the deaf and HoH community and I want that community to have good3quality communications access and better services.\" \"Working on this project has been a lot of fun,\" says Andre Webster, a fifth3year electrical engineering student at Rochester. \"It's cool to see the different engineering aspects that go into a VRS service and to work with a fantastic team. The scope of this project is very important because many deaf and hard of hearing people use VRS services not just for social purposes but also professionally.\" 33by Andy Porter Approved for Public Release; Distribution Unlimited: 17-3083. MITRE interns (left to right) Michael Tota, Minnie Buenaventura, Grace Yukawa and Andre Webster, are testing various devices and software to ensure interoperability and compatibility of Video Relay Service prototypes for the Federal Communications Commission. [Endbar] About the National Test Lab The MITRE FCC National Test Lab has been established to support the FCC mission to promote efforts in improving routine communications and the quality of life for members of the deaf and HoH community. The lab's focus is on repeated and rigorous baseline testing of two of the most fundamental FCC3funded community services today. With independent verification and validation efforts, the lab will capture unbiased \"snapshots\" of overall system interoperability and performance observations and measurements across both current end3user equipment and services as well as legacy devices with large end3user populations. Intern Project Amplifies Benefits for Hard of Hearing Community ",
    "text": " () Authors: Gary L. Ingber \n Dr. Shelley A. Kirkpatrick \n Gordon C. Milbourn III W. Bruce Shirk \n Jonathan R. Stehle \nSeptember 2017 PAYMENT INTEGRITY What Motivates Entities Making Payments and Claimants to Optimize Ongoing Payment Integrity Efforts? \nThe views, opinions and/or findings contained in \nthis report are those of The MITRE Corporation \nand should not be construed as an official \ngovernment position, policy, or decision, unless \ndesignated by other documentation. Approved for Public Release: 17-3400. \nDistribution Unlimited. \nreserved. McLean, VA McLean, VA McLean, VA McLean, VA ii iii Acknowledgments The MITRE Corporationa private, not-for-profit organizationoperates federally funded \nresearch and development centers (FFRDCs), unique organizations sponsored by \ngovernment agencies under the Federal Acquisition Regulation to assist with research and \ndevelopment, study and analysis, and / or systems engineering and integration. MITRE \noperates seven FFRDCs sponsored by the federal government. These are: National Security Engineering Center sponsored by the Department of Defense, Center for Advanced Aviation System Development sponsored by the Federal \nAviation Administration, Center for Enterprise Modernization sponsored by the Department of the Treasury \nand co-sponsored by the Department of Veterans Affairs, CMS Alliance to Modernize Healthcare sponsored by the Centers for Medicare & \nMedicaid Services, The Homeland Security Systems Engineering and Development Institute sponsored \nby the Department of Homeland Security, Judiciary Engineering and Modernization Center sponsored by the Administrative \nOffice of the U.S. Courts, and National Cybersecurity Federally Funded Research and Development Center \nsponsored by the National Institute of Standards and Technology. MITRE also maintains a broad, independent research program, designed to explore \nemerging issues and potential solutions to benefit our government sponsors, industry and \nthe public. In conducting this independent study, MITRE interviewed representatives of a number of \nfederal agencies and federal oversight and accountability organizations. A complete list is \nshown in Appendix A of the report. MITRE wishes to thank all of these organizations for \ntheir time and contributions to the study. MITRE Study Team Gary Ingber Dr. Shelley Kirkpatrick Gordon Milbourn Bruce Shirk Jon Stehle iv Abstract According to the Office of Management and Budget, the federal government annually makes \nmore than $3 trillion in payments of all kinds, the great majority of which are proper. \nHowever, in fiscal year 2016, federal agencies estimated that they made more than $144 \nbillion in improper payments (nearly 4.7 percent of all payments), representing the \nequivalent of the fifth largest federal agency. The amount of reported improper payments \nnearly tripled over the last decade, and these estimates do not include all programs. The MITRE Corporation, a not-for-profit corporation that operates federally funded \nresearch and development centers on behalf of federal government sponsors, conducted \nthis independent study of the motivators of federal Payment Integrity1 in conjunction with \nits charter to help address significant government-wide problems. The study addresses the \nfollowing issues. What motivates and enables federal agenciesthe organizations as a whole and \ntheir individual employeesand entities acting on their behalf (for example, states, \ngrantees) to optimize their ongoing Payment Integrity efforts? What motivates claimantsindividuals and organizations filing benefits claims, tax \nreturns, commercial invoices, etc.to be accurate and not make errors or commit \nfraud? This study describes the impact of these issues and recommends 11 actions for broader, \nmore cross-government approaches to motivating federal agencies, entities acting on their \nbehalf, and claimants to ensure Payment Integrity. \n1 Payment Integrity refers to improper payments and the people, processes, and technology that are meant to ensure that \nthe payments are actually proper. v Executive Summary According to the Office of Management and Budget (OMB), the federal government \nannually makes more than $3 trillion in payments of all kinds, the great majority of which \nare propermade to the right person or entity, for the right reason, at the right time, in the \nright amount. However, in fiscal year 2016, federal agencies estimated that they made \nmore than $144 billion in improper payments (nearly 4.7 percent of all payments)an \namount that has nearly tripled over the last decade, represents the equivalent of the net \ncost of the fifth largest agency, and is only for about 115 of the hundreds of federal \nprograms. This level of improper payments is unaffordable and contributes to public \nconcerns about the stewardship over taxpayer dollars. Numerous requirements call on \nagencies to estimate, report on and mitigate improper payments, and we acknowledge the \nconsiderable efforts ongoing at OMB and across federal agencies to address the challenge. The MITRE Corporation (MITRE), a not-for-profit organization that operates federally \nfunded research and development centers on behalf of federal government sponsors, \nrecognizes the impact of the overall Payment Integrity2 situation. Given the public interest \nnature of the challenge, MITRE conducted this independent study as a follow-on to its \nFebruary 2016 report.3 MITRE interviewed officials at 9 agencies and 4 oversight and \naccountability organizations; reviewed extensive academic literature and domestic and \ninternational applied literature and research; and assessed this information in the context \nof motivators specific to Payment Integrity. Agencies are often faced with complex legal and regulatory environments, insufficient \nresources, limited data, and tight timeframes in which to make decisions about payment \nvalidity and accuracy. Frequently, agencies have competing priorities to issue payments \ntimely to those who deserve them vs. applying the time and resources to ensure their \naccuracy. As a result, agencies are often forced to make trade-offs between their \nresponsibilities to serve the public and to assure the integrity of the payment process. This \nstudy focuses on a key issue impacting ongoing efforts and the implementation of \nrecommendations made in MITREs 2016 reportwhat motivates federal agencies, those \nacting on their behalf (for example, states), and claimants to optimize their ongoing \nPayment Integrity efforts? Motivating Agencies and Those Acting on Their Behalf \nMotivating agencies, their employees, and entities acting on their behalf is one important \nfactor that contributes to program performance in general. In the case of Payment \nIntegrity, applied literature and research regarding the systems view of organizations \nindicated that all components of an organizational system should be aligned and \nfunctioning properly to create the conditions needed for reducing improper payments. \n2 Payment Integrity refers to improper payments and the people, processes, and technology that are meant to ensure that \nthe payments are actually proper. \n3 GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND SOLUTIONS NEEDED (MTR160040, February \n2016) vi Based on interviews with officials from agencies and accountability organizations, we \nfound that visibility and accountability are motivating, especially external visibility from \nthe public release of improper payments information; oversight by Congress and other \nstakeholders; and techniques as naming and shaming. Statutes that mandate certain \ntypes of program design, that place restrictions on Payment Integrity defenses such as data \nmatching, or that restrict how states can spend funds on Payment Integrity activities, can \nadversely impact motivation levels, as can limits on funds for Payment Integrity activities. Some agency officials stated that publishing goals addressing improper payments, coupled \nwith the required reduction targets, is motivating; a Cross-Agency Priority Goal would \nquite likely be of help, as well. MITREs February 2016 study report, as well as applied \nliterature and research, pointed out that agencies need to more closely balance the priority \non mission (for example, maximizing participation in benefits programs) with \nmanagement (for example, making accurate payments) in order to emphasize proper \nstewardship over federal funds. Further, benefits paying programs can be motivated to \nimprove delivery quality if performance metrics include accuracy of the original payments \nand if managers are rewarded for quality. Accountability officials and applied literature and research discussed the importance of \nsenior leaders having the will to address improper payments, regularly communicating the \nimportance of addressing them throughout government, and holding themselves and \nothers accountableestablishing a tone at the top to put attention on the issue and keep \nit there. Agency officials further observed that it is important to address Payment Integrity \nacross the entire organization, share accountability, and adopt an acting as one approach \nacross the organization to enhance coordination and decision-making for results. Agency and accountability officials believed that the degree of concern about Payment \nIntegrity varies across government, with some officials saying that most leaders and staff \ncare genuinely and others believing these pockets of caring need to be a government-\nwide culture that starts at the very top and extends through the agencies to states, \ngrantees, and others. Leaders must set the expectation of and norms for a workplace where \nall employees work together constructively to ensure Payment Integrity. Various officials, along with applied literature and research, emphasized that managers and \nstaff also need to be accountable. Some agencies include Payment Integrity in performance \nstandards at all levels, while others have indirect linkages between the standards and \norganizational improper payment goals. These goals need to be balanced with, not in \nconflict with, program goals. For some issues, cross-government approaches might \nmotivate agencies towards better solutions; decentralized approaches can generate ad hoc, \nagency-specific solutions for what are actually common issues such as identity. Based on interviews with agency officials and review of academic research, applied \nliterature and research, we concluded that effectively motivating individual employees
\ninvolves setting agency, group, and individual goals that align with each other and gaining \nemployees commitment to them; providing feedback on progress towards goal \nachievement; and providing incentives and rewards aligned with desired performance. \nThese elements can be interrelated. For example, goal commitment can be low when the vii wrong behavior is unintentionally rewarded. Finally, some employees are motivated by \nthings other than rewards, in particular a belief in public service; employees may want to \n\"get the biggest bang for the buck\" for the intended beneficiaries of their programs, and \nthat bang depends, in part, on Payment Integrity. Motivating Recipients of Federal Payments \nApplied literature and research indicated that motivators to be accurate and not make \nerrors or commit fraud when submitting claims to the government can arise from sources \nboth extrinsic and intrinsic to the individual. Extrinsic motivation usually focuses on \nelements of the economics-of-crime model. The model is most frequently applied to tax \nevasion, wherein many believe the probability of being examined and the magnitude of the \npossible penalty correlate with the overall level of compliance. In reality, while the \npossibility of examination and penalty appears to have a predictive relationship with \nindividual behavior, taxpayers as a whole do not appear to make their compliance \ndecisions solely based on the likelihood of being examined. Extrinsic motivation can also derive from the characteristics of the environment. For \nexample, the ability to obtain all necessary information and have it presented in clear and \nstraightforward ways better motivates individuals and organizations to make good \ncompliance decisions. However, this is not always the case with government programs. Multiple intrinsic factors can affect tax compliance, such as perceived fairness of the tax \nsystem and the authorities, and acceptance of tax evasion among a reference group such as \nan individuals friends. Other nonpecuniary motivators for tax compliance include concepts \nlike reciprocal motivationthe willingness to pay taxes in exchange for benefits that \ngovernment provides even though the actual payoff would be higher by not paying. Based on interviews with agency and accountability officials, as well as review of applied \nliterature and research, we concluded that just as with motivating agencies and entities \nthat act on their behalf, visibility and accountability can motivate claimants. Organizations \ncan take numerous actions to promote visibility and accountability in hopes of motivating \nclaimants to be accurate and not make errors or commit fraud, such as using compliance \nactions to increase levels of claimant responsibility, informing claimants that their \ninformation will be shared with other agencies for matching as a deterrent, and publicizing \npenalties for noncompliance. Finally, applied literature and researched showed that how claimants view agencies plays a \nrole, especially the reputation of an agency, which is key to the level of claimants trust. \nBoosting the level of trust in and / or the perception of power of agency authorities leads to \ngreater compliance. viii Recommendations \nOMB and agencies can fundamentally transform the entire system by implementing the \nfollowing recommendations in order to create the conditions for optimal Payment \nIntegrity. Table ES-1. Study Recommendations Motivating Agencies Motivating Recipients 1. Set clear organizational goals for Payment \nIntegrity with accountability for results 8. Ensure claimants have easy, optimal means to \ninteract with agencies 2. Establish a culture of Payment Integrity 9. Strive for proactive, timely communications \nwith claimants 3. More closely balance the priorities of mission \nand management 10. Broaden use of compliance-oriented motivators \nsuch as data mining 4. Emphasize coordinated, cross-government \napproaches to Payment Integrity challenges 11. Consider additional compliance motivators, as \nwarranted 5. Address statutory barriers 6. Explore funding options to strengthen Payment \nIntegrity 7. Consider Payment Integrity when modernizing \ninformation technology systems and \ndeveloping shared services ix Table of Contents Acknowledgments \nTheir Ongoing Payment Integrity Efforts? \nTax Returns, Commercial Invoices, Etc.to Be Accurate and Not Make Errors or \nCommit Fraud? \nFigure 2. Overall Tax Compliance as a Function of Trust and Power \nTable 2. Study Interviews \n(OMB), the federal government annually makes more \nthan $3 trillion in payments of all kindsdirect \nentitlement payments, grants, loans, acquisitions, and \nmore. The great majority of payments are proper\nmade to the correct person or organization, for the right \nreason, at the right time, in the correct amount. However, in fiscal year (FY) 2016 federal agencies, using their own methods and available \ndata, estimated that there were more than $144 billion in improper payments (nearly 4.7 \npercent of all payments) for about 115 of the hundreds of federal programs, representing \nthe equivalent of the net cost of the fifth largest federal agency. Given the limited number of \nprograms for which estimates are calculated, the complexity of the estimates, and the \ndifficulty of estimating fraud, this may very well be a lower bound to the actual improper \npayments that year. Considerable efforts are already in place at OMB and across federal agencies to identify, \nreport and mitigate improper payments. However, the level of improper payments has \nnearly tripled over the last decade, is unaffordable, adds to the current difficult economic \npicture, and contributes to public concerns about the effectiveness of the governments \nstewardship over taxpayer dollars. The MITRE Corporation (MITRE), a not-for-profit organization that operates federally \nfunded research and development centers (FFRDC) on behalf of federal government \nsponsors, recognizes the impact that the overall federal Payment Integrity4 situation has on \ngovernment effectiveness and public confidence. Given the public interest nature of this \nchallenge, MITRE conducted this independent study as a follow-on to its February 2016 \nreport5 that assessed the underlying systemic factors that enable fraud and other improper \npayments and explored government-wide solutions to improve Payment Integrity. This \nstudy focuses on a key issue that impacts the implementation of many of the \nrecommendations made in the February 2016 reportwhat motivates federal agencies, \nthose acting on their behalf (for example, states, grantees), and claimants to optimize their \nongoing Payment Integrity efforts? In conducting this qualitative study, MITRE interviewed officials at 9 agencies and 4 \noversight and accountability organizations. MITRE also reviewed extensive academic \nliterature, domestic and international applied literature, and research. MITRE then \nassessed this information in the context of motivators specific to Payment Integrity. See \nAppendix A for a complete description of the study methodology. \n4 Payment Integrity refers to improper payments and the people, processes, and technology that are meant to ensure that \nthe payments are actually proper. \n5 GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND SOLUTIONS NEEDED (MTR160040, February \n2016) 2 1.1 Federal Requirements Regarding Payment Integrity Congressional concerns over government-wide Payment Integrity \nhave, in recent years, prompted passage of a number of important pieces of legislation \naimed at helping the federal government address the problem. These statutes include the \nfollowing. The Improper Payments Information Act of 2002 (P.L. 107-300), the Improper \nPayments Elimination and Recovery Act (IPERA) of 2010 (P.L. 111-204), and the \nImproper Payments Elimination and Recovery Improvement Act (IPERIA) of 2012 \n(P.L. 112-248), which collectively: o Require federal agencies to annually review all programs and activities and \nidentify those that may be susceptible to significant improper payments. o Require federal agencies, for those programs and activities identified, to \nestimate the annual amount of improper payments. o Establish in statute the Do Not Pay (DNP) Initiative and require federal agencies \nto ensure that a thorough review of available databases with relevant \ninformation on eligibility occurs to determine program or award eligibility. The Digital Accountability and Transparency Act of 2014 (P.L. 113-101), which \nauthorized the Secretary of the Treasury to establish a data analysis center or \nexpand an existing service to provide data, analytic tools, and data management \ntechniques to support, among other things, the prevention and reduction of \nimproper payments.6 The Fraud Reduction and Data Analytics Act of 2015 (P.L. 114-186), which focuses \nagencies attention on identifying, assessing, and mitigating fraud risks, including \nthe use of data analytics. The Executive Branch has also taken a number of steps aimed at improving Payment \nIntegrity government-wide. These include: Issuing Executive Order 13520, Reducing Improper Payments and Eliminating Waste \nin Federal Programs (November 20, 2009), which established a strategic outcome, \ngoals and strategies for reducing improper payments. Issuing a Presidential Memorandum (Enhancing Payment Accuracy Through a Do \nNot Pay List [June 18, 2010]) and OMB memoranda (M-12-11, Reducing Improper \nPayments through the \"Do Not Pay List [April 12, 2012] and M-13-20, Protecting \nPrivacy while Reducing Improper Payments with the Do Not Pay Initiative [August 16, \n2013]), which established the Treasury DNP solution and provided guidance to \nagencies on its use, prior to passage of IPERIA. \n6 Treasury officials evaluated the provision, concluded that a Bureau of the Fiscal Service post-payment center in \nPhiladelphia fulfills the intent of this provision, and decided not to invoke the authority provided. 3 Issuing OMB memorandum M-15-02, Appendix C to Circular No. A-123, \nRequirements for Effective Estimation and Remediation of Improper Payments \n(October 20, 2014), which, among other things, established new categories for \nreporting improper payments and introduced a new internal control framework. Establishing a goal of a government-wide improper payments rate of no more than \n3.0 percent by the end of FY 2016. The Government Accountability Office (GAO) has
also made important contributions to the \nongoing efforts to reduce federal improper payments. Beyond findings discussed and \nrecommendations made in numerous audit reports, in July 2015 GAO issued A Framework \nfor Managing Fraud Risks in Federal Programs. In this document, GAO identified leading \npractices for managing fraud risks and organized them into a conceptual framework [t]o \nhelp managers combat fraud and preserve integrity in government agencies and \nprograms.7 Further, to assist the new Administration and Congress, in January 2017 GAO provided \nextensive information on the critical management challenges facing the federal government \nand actions needed to address those challenges. Of specific relevance to this study are: Manage Finances to Improve the Nations Fiscal ConditionChallenge: Improper \nUse or Payment of Federal Funds. GAO noted the size of the problem and provided \nseveral key actions needed that include implement[ing] effective corrective actions \nto prevent or minimize improper payments. Strengthen Human Capital Capabilities to Enhance PerformanceChallenge: Create \nAccountable and Inclusive Organizations. GAO highlighted the need for effective \nperformance management that includes key actions such as [e]nsur[ing] \nperformance management systems have a line of sight showing how individual and \nunit performance contribute to overall organizational goals. Promote Transparency and Open Government to Enhance Civic Engagement and \nFoster InnovationChallenge: Insufficient Focus on Addressing Customer Needs. \nGAO drew attention to the current federal Cross-Agency Priority (CAP) Goal8 for \nCustomer Service: Increase citizen satisfaction and promote positive experiences with \nthe federal government by making it faster and easier for individuals and businesses to complete transactions and receive quality services. One aspect of a complete \ntransaction and a quality service would be receiving a proper payment when it is \nwarrantedaccurate, on time, for the right reason, etc. Finally, in February 2017 GAO issued its updated list of 34 high-risk areas.9 Among these \nare Medicare and Medicaid, both of which are susceptible to very significant improper \n7 A Framework for Managing Fraud Risks in Federal Programs (GAO-15-593SP, July 2015) \n8 According to the Government Performance and Results Act Modernization Act of 2010 (P.L. 111-352), CAP Goals are \nlong-term goals designed to address a limited number of crosscutting policy areas and management improvements \nneeded. \n9 HIGH-RISK SERIES Progress on Many High-Risk Areas, While Substantial Efforts Needed on Others (GAO-17-317, \nFebruary 2017) 4 payments. In 1990, GAO designated Medicare as one of its original high-risk areas due, in \npart, to its susceptibility to improper payments. GAO then designated Medicaid as a high-\nrisk area in 2003; similarly, this was due, in part, to concerns about the adequacy of \noversight needed to prevent inappropriate Medicaid spending. For FY 2016, the \nDepartment of Health and Human Services (HHS) estimated that Medicare made nearly $60 \nbillion in improper payments and Medicaid more than $36 billion, making them the two \nfederal programs with the highest dollar levels of improper payments. 1.2 The Current State of Federal Payment Integrity The government-wide goal for the end of FY 2016 provided a \ntarget for agencies, and the numerous statutes and Executive \nBranch documents provided policy and guidance information to help agencies hit the \ntarget. However, by the agencies own calculations, the situation has been getting worse. \nFrom FY 2013 to 2016, the reported dollars climbed from approximately $106 billion to \nmore than $144 billion, and the rates increased from 3.5 percent to nearly 4.7 percent. At \nthe end of FY 2016, the rate was nearly 56 percent higher than the end-of-FY 2016 goal of \n3.0 percent. Each year the Inspectors General of the 24 Chief Financial Officers (CFO) Act agencies \ndetermine whether their agencies complied with six key criteria in IPERA related to the \nestimation of improper payments. In a report summarizing the results of these audits for \nFY 2014,10 GAO indicated that 15 of these agencies did not comply with the IPERA criteria, \nan increase from each of the prior 3 years. Agency noncompliance for FY 2014 was largely \ndue to agencies not meeting their improper payment reduction targets or not reporting \nimproper payment rates of less than 10 percent for all programs. At the same time, \nvirtually all of the agencies published corrective action plans, so it would appear that the \ncorrective actions are not, in fact, resolving the problems. One reason that corrective actions may not be resolving the problems could be that \nagencies do not necessarily always identify the true root causes of their improper \npayments. For challenging problems like improper payments, it is especially critical to \nunderstand the true root causes in order to formulate effective corrective actions. \nIdentifying these true root causes can be difficult, and as MITRE discussed in its February \n2016 study report, agencies do not always appear to dig deep to find these true root causes, \noften settling for apparent root causes (also called causal factors). An important true root cause can be the dynamics of the motivators in the environment, \nspecifically the following, which are the subject of this study report: What motivates and enables federal agenciesthe organizations as a whole and \ntheir individual employeesand entities acting on their behalf (for example, states, \ngrantees) to optimize their ongoing Payment Integrity efforts? \n10 IMPROPER PAYMENTS CFO Act Agencies Need to Improve Efforts to Address Compliance Issues (GAO-16-554, June \n2016) 5 What motivates claimantsindividuals and organizations filing benefits claims, tax \nreturns, commercial invoices, etc.to be accurate and not make errors or commit \nfraud? 6 2 What Motivates and Enables Agencies and Those Acting on Their Behalf to Optimize Their Ongoing Payment Integrity Efforts? The systems view of organizations holds that there are a number of components of an \norganization, and that in order to create the conditions needed for high performance, these \ncomponents need to be aligned and functioning properly. One of these components\nmotivating individual employees towards high performanceis critical to organizational \nsuccess, but it alone is not sufficient for optimal organizational performance. Agency \nleaders must be at the forefront of promoting optimal performance of their organizations \nas a whole, their employees, and entities that are acting on behalf of the agencies, such as \nstates and grantees. This is true for Payment Integrity, as it is for other critical goals and \nactivities. Certain aspects of these organizational components, however, often challenge agencies in \ntheir ability to ensure Payment Integrity. Agencies are often faced with complex legal and \nregulatory environments, insufficient resources, limited data, and tight timeframes in \nwhich to make decisions about payment validity and accuracy. Frequently, agencies have \ncompeting priorities to issue payments timely to those who deserve them (and often \ncritically need them) vs. applying the time and resources needed to ensure the payments \nvalidity and accuracy. As a result, agencies are often forced to make trade-offs between \ntheir responsibilities to serve the public and to protect the integrity of the payment \nprocess. 2.1 Organizational Motivation The Burke-Litwin Model of organizational performance \nand change describes both the factors that impact \norganizational performance and the relationship among \nthose factors. Understanding the factors and how they \nrelate to and impact each other improves our \nunderstanding of how organizations function. The model identifies the following components of an organizational system that must be \naligned and functioning properly to promote optimal performance. Individual motivation is \nalso a model component that is addressed separately in section 2.2. External Environment. The external environment is comprised of laws and \nregulations, resources that have been budgeted to ensure Payment Integrity and \nmonitor improper payments, and stakeholders who see value in reducing improper \npayments. Mission and Strategy. Reducing improper payments will be influenced by the \ndegree to which Payment Integrity is reflected in the agencys mission and strategy \nas well as communicated by agency top management to its workforce. 7 Leadership. Leadersranging from an employees immediate supervisor to top \nagency executivesmotivate employees to take necessary steps to reduce improper \npayments. Both formal and informal leaders serve as role models. In particular, top \nmanagement support and commitment to Payment Integrity can influence employee \ngoal commitment. Organizational Culture. A constructive culture sets norms and expectations that \nencourage the reduction of improper payments. In such a culture, employees share \ninformation and focus on achievement while working collaboratively to share \ninformation and support high performance. Structure. The agency structure must align with the goal of reducing improper \npayments to allow access to resources and decisions when needed. Management Practices. Managers should effectively allocate resources to \nimplement the strategy and engage in effective supervision in order for their \nemployees to pursue goals related to Payment Integrity. Systems (Policies and Procedures). Policies and mechanisms must be \nstandardized yet flexible enough to facilitate, not inhibit, employees ability to \nreduce improper payments, and striving for such reductions should be budgeted for, \nstaffed, reflected in performance appraisals, and rewarded. Work Unit Climate. Teams and units must work well together, collaborate with \nother teams / units inside their component of the agency, and work effectively with \nother teams / units across the agency. Task and Individual Skills. Employees must have the specific knowledge and skills \nfor effective job performance. Further, jobs must be designed to allow for improper \npayments to be addressed, such as providing employees sufficient time
during \nprocessing to correct errors or develop fraud leads when appropriate. Individual Needs and Values. Employees values should be consistent with the \norganizations observed and stated values, and their work-related needs should be \nsatisfied through the job. Job-person fit must exist in terms of needs and values as \nwell as skills. Employees should understand how their jobs contribute to the agency \nmission and goals. The following sections summarize the results of MITREs interviews and literature \nresearch, organized according to relevant components of the Burke-Litwin model. 2.1.1 External Environment 2.1.1.1 Visibility and Accountability Certain aspects of the External Environment have major impacts \non agencies motivation to reduce improper payments. First, \nofficials from agencies and accountability organizations indicated that both external and \ninternal visibility and accountability serve as motivators. External visibility is especially 8 motivating, via mechanisms such as the public release of improper payments information \nin the annual Agency Financial Reports (AFR) and oversight by Congress, OMB, audit \norganizations, and other stakeholders such as the media. The public has access to a great \ndeal of information in the AFRs and on paymentaccuracy.gov, and as one agency official \nnoted, millions of Americans are touched by their benefits programs, so they want to \nmaximize public confidence in the programs. Another agency pointed out that external \nvisibility increases reputational risk thereby providing motivation, while on the other hand, \nan accountability organization pointed out that there are really no consequences (for \nexample, reductions in funding) to agencies for not complying with IPERA and OMB \nguidance, which decreases their motivation.11 Internally, some agency and accountability \nofficials stated that peer pressure and formal internal reporting can be motivators; for \nexample, internal improper payments boards that require periodic reporting help officials \nkeep focused on the issue. Many programs are totally or partially funded by the federal government, administered by \nstates, and carried out by grantees and contractors. Agency officials recognized that just as \nwith their agencies, External Environment visibility and accountability need to motivate \nstates, grantees, and others to reduce improper payments. One agency, for example, uses a \nname and shame technique in a key programpublishing the five states with the highest \nimproper payment rates in order to motivate them to reduce their rates. The agency also \ntakes actions such as increasing the level of monitoring and sending letters to the \ngovernors of these states requiring remediation plans. 2.1.1.2 Legislation Another key aspect of the External Environment is legislation.12 Various mandates play a \nrole in how agencies are motivated to reduce their improper payments. In particular, \nagencies motivation can be impacted by legislatively driven program design issues. For \nexample, some programs must rely heavily on timely beneficiary self-reporting of life \nchanges. This happens in the Supplemental Security Income (SSI) program, where benefits \nare paid on the first of the month for the upcoming month, but beneficiaries do not always \nreport income changes that could affect their eligibility to the Social Security \nAdministration (SSA). While working to reduce improper payments, including taking steps \nto enhance data matching to address this issue, agency officials nonetheless recognize the \nissue that this mandate creates. At the same time, legislative restrictions can constrain federal agencies ability to address \nPayment Integrity problems, de-motivating them in their efforts. The most notable statute \nin this regard is the Computer Matching and Privacy Protection Act (CMA) of 1988 (P.L. \n100-53), which restricts the computerized matching of data sets within an agency or \nbetween agencies. Both what CMA requires (such as computer matching agreements that \nare limited to terms of 18 months) and what it does not say (for example, there is no \n11 For more information on reputational risk and its relationship to Payment Integrity, see section 3.2.4. \n12 For a more complete discussion of this issue, see MITREs study report, GOVERNMENT-WIDE PAYMENT INTEGRITY: \nNEW APPROACHES AND SOLUTIONS NEEDED (MTR160040, February 2016) https://paymentaccuracy.gov/ 9 blanket authority to match agency data with external data sources) create problems. Some \nagency officials suggested that even limited changes like lengthening the term of the \ncomputer matching agreements from 18 months to 5 years, for example, would be very \nhelpful. Federal statutes also play a role in addressing states Payment Integrity problems. In \nparticular, agency officials indicated that some statutes restrict how states can spend funds \non Payment Integrity activities, and that statutes are increasingly limiting the percentage of \nfederal funding received that the states can use for oversight that would help improve \nPayment Integrity. Some programs would need legislative authorization to allow the states \nto use some of the funds they recover for additional Payment Integrity activities. Finally, \nsome agency officials said they would like to compel the states to use their administrative \nfunds to do more Payment Integrity-related data analytics and matching but would need \nlegislation to do this. One agency cited a positive example where they had done this within \nexisting legislative parameters, mandating that states in one program use the National \nDirectory of New Hires in order to detect individuals still receiving benefits after \nreemployment. In another example, the Medicare Access and CHIP13 Reauthorization Act of \n2015 (P.L. 114-10) requires the Centers for Medicare and Medicaid Services (CMS) to \nspecify incentives that would encourage states to participate in a Medicaid data matching \nand mining program. 2.1.1.3 Resources The lack of resources devoted to Payment Integrity challenges agencies motivation. Both \nagency and accountability officials acknowledged that the governments difficult fiscal \nenvironment makes the likelihood of obtaining resources specifically to fight improper \npayments very low. While there are some notable returns on investment for such dollars\nsuch as SSI redeterminations ($8 returned for every $1 invested), Continuing Disability \nReviews (9:1), and work reviews (11:1)even when such investments are authorized and \nmade in one year they are subject to budget cuts the next. Some officials believed that agencies, in general, cannot keep any of the funds recovered \nfrom activities like those above, or from recovery audits, for use in additional Payment \nIntegrity or program activities. Instead, they believed that some of the funds could be kept \nfor the purpose of helping to cover the administrative costs incurred in conducting the \nactivities, while the balance of the funds must be turned over to the U.S. Treasury. \nHowever, recovered funds are, in fact, available for other purposes. OMB Circular A-123, \nAppendix C, Part I.D.14, provides implementing guidance for IPERA on the proper \ndisposition of recaptured funds. The Circular provides that overpayments from expired \ndiscretionary fund accounts14 that are not used to reimburse agency expenses or pay \nRecovery Audit Contractors are to be used for a financial management improvement \nprogram, for the original purpose of the funds, or for Inspector General activities, or they \n13 Childrens Health Insurance Program \n14 The guidance contains different requirements for overpayments from unexpired discretionary fund accounts, \nmandatory fund accounts, and closed accounts. 10 should be returned to the Treasury as miscellaneous receipts or to trust or special fund \naccounts. In particular, up to 25 percent of these recaptured funds may be used for an \nagencys financial management improvement program to ensure that actions are taken to \nimprove internal controls to address problems that directly contribute to improper \npayments. IPERA characterizes this as the first priority of this program. Finally, applied literature and research stressed that agencies should be required to meet \npolicy goals and evaluated periodically to measure progress. However, the research \nindicates that cutting their budgets as a way to motivate them to better mitigate improper \npayments only exacerbates the problem. Some agency officials also believed that incentives for \nstates to invest funds in Payment Integrity activities are \ninadequate. These officials offered the following thoughts. When the states are the flow-through vehicle for \nfederal funds on the way to the ultimate recipients, \nhaving the states dedicate some of their own \nresources to reducing improper payments is a cost \nto them without an apparent benefit. Consequently, \nsome states have suggested changing financial \nincentive structures (for example, in the \nSupplemental Nutrition Assistance Program \n[SNAP]) to promote conducting fraud investigations. In some jointly funded programs, the states have \nhistorically had little incentive to recover improper \npayments because for each dollar recovered they \nmay only keep their share of the funding (which is \nalways less than half). States need resources to use for Payment Integrity activities, but federal funds \nappropriated for this purpose have been decreasing. 2.1.2 Mission and Strategy Clear, publicly stated Payment Integrity goals also serve as \nmotivators. Agency officials said that publishing goals externally \naddressing key aspects of improper payments is helpful, coupled \nwith the reduction targets required by IPERA for programs with \nreported improper payments. Some agencies publish such goals in their strategic plans or \nAFRs. A number of officials believed that a government-wide CAP Goal would quite likely \nbe of help in motivating agencies. Internal goals can also be used as part of an overall \nstrategy to reduce improper payments, especially if this is combined with employee \ninvolvement such as soliciting their input to identifying root causes and corrective actions. In one program, agency \nofficials indicated that in \nrecent years, federal funding \nhas been provided to \nindividual
states for internal \ntask forces to examine their \nimproper payments and \ndevelop solutions. The \nagency has seen improve-\nments in those states since \nthis began, so they believe \nthere is a cause-and-effect \nrelationship. SUCCESS STORY 11 From the perspective of policy and priority drivers of motivation, MITREs February 2016 \nstudy report,15 applied literature and research found that benefit paying organizations are \noften focused on the number of payments processed rather than their accuracy. Agencies \nneed to adopt an approach of more closely balancing mission (for example, timeliness of \npayment, maximizing participation in benefits programs) with management (for example, \naccuracy of payment) in order to emphasize proper stewardship over federal funds. One \nagency indicated that while employees should understand the need for balance between \nservice to claimants and stewardship of funds, finding the right balance can be difficult. It is helpful for agencies to reinforce improper payment reduction policies by establishing \nquantifiable objectives and metrics focused on quality control and accuracy. Benefits \npaying programs can be motivated to improve delivery quality if employee performance \nmetrics include accuracy of the original payments (not just corrections when those \npayments are identified as incorrect) and if managers are rewarded for overall quality \ncontrol. Applied literature and research also indicated that preventive and deterrent \nactions are more difficult to measure in the near-term, so the focus of measurement should \nbe on long-term trends. 2.1.3 Leadership Although effective leadership entails a wide range of actions, one \nleadership factor that emerged is the focus and emphasis that \nleaders place on Payment Integrity. Accountability officials, \napplied literature and research indicated that a critical success \nfactor in Payment Integrity is political and senior agency leaders having the will to address \nthe issue, communicating that throughout their organizations, and holding themselves and \nothers accountable. Numerous agency officials cited the importance of regular statements \non Payment Integrity from top leaders and accountability among senior staff, with some \nadding that tone at the top is essential for getting the organizations attention on the issue \nand keeping it there. A number of agency officials stated that they believed it is important to work across the \norganization on improper payments issuesboth in general and with respect to specific \nissues. In this regard, multiple agencies described their senior level boards that promote \nshared accountability and an acting as one approach across the organization in order to \nenhance coordination, collaboration, and decision-making. One agency has designated a \nSenior Accountable Official in each component to be responsible for developing improper \npayment remediation plans. In all cases, it is critical for senior leaders to follow through on \ntheir words with actions that produce resultsreductions in improper payments. \n15 GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND SOLUTIONS NEEDED (MTR 160040, February \n2016) 12 2.1.4 Organizational Culture The degree of concern about Payment Integrity appears to vary \nacross government. Some agency and accountability officials said \nthat fraud, in particular, angers leaders and staff, and that most of \nthem genuinely care about the improper payments issue, taking \npride in their organizational mission and their efforts to prevent, identify, and recover \nimproper payments. Other officials believed that these pockets of caring need to be \nbroadened to a government-wide culture that starts at the very top levels, stating that \nPayment Integrity needs to be a political imperative and that agency heads need to be held \nresponsible for meeting goals. Further, just as at the federal level, some agency officials \nindicated that it is important to establish accountability by emphasizing overall integrity to \nthe states and by creating a culture of Payment Integrity among all entities making \npayments. Some agency officials also indicated that it is difficult to keep leaders and staff focused on \nPayment Integrity because of all their competing priorities. Others indicated that many \nleaders and staff in their organization recognize that resources are scarce, so they simply \ncannot afford to have improper payments that divert resources from deserving recipients; \nhowever, this perspective took time to develop and integrate into the culture of the \norganization. 2.1.5 Systems (Policies and Procedures) Managers and staff, like senior leaders, need to be accountable for \nPayment Integrity. Some agencies include Payment Integrity in \nsenior leaders, managers, and staff performance standards, while \nothers have indirect linkages between the standards and agency / \ncomponent goals to reduce improper payments. Applied literature and research echo this \napproach, indicating that organizations should assign roles and responsibilities for meeting \nPayment Integrity goals and ensure accountability through a reward system at both the \norganizational and individual levels. These Payment Integrity goals and metrics need to be \nbalanced with, not in conflict with, program goals and metrics. As GAO noted in its July \n2015 document, A Framework for Managing Fraud Risks in Federal Programs, performance metrics for employees can perpetuate this conflict [between timeliness and accuracy] and create disincentives to combat fraud. For instance, we reported in November 2014 that one programs performance measures for its frontline employees responsible for processing applications for benefits focused on prompt processing, resulting in a disincentive for employees to report potential fraud because of the time it requires to develop a fraud referral. Effective performance metrics reinforce the objectives of fraud risk management activities and strike a balance with other activities that serve the programs mission.16 Applied literature and research suggest that cross-government policies on Payment \nIntegrity might improve solutions and accountability. A completely decentralized approach \n16 A Framework for Managing Fraud Risks in Federal Programs (GAO-15-593SP, July 2015) 13 to addressing improper payments can generate ad hoc, niche, agency-specific solutions to \nwhat are actually cross-government issues like identity and eligibility. On the other hand, \nfor some challenges a coordinated, systematic approach can motivate agencies to work \nmore effectively together to solve government-wide problems. The solution is not either-\nor; instead, it is finding the right balance between doing both. Some processes need to be \nstandardized, while at the same time, agencies need to be able to adapt those processes \nwhen it makes them more effective. Agency officials indicated that it is important for the states, not just federal agencies, to hold grantees, contractors, program beneficiaries, and others accountable. Examples of this include states: Charging contractors damages for improperly invoicing the government. Prosecuting benefits fraud, and if a person is found guilty, taking away their \neligibility for the program. Using data matching programs. For example, a GAO report about SNAP stated that \n\"in 2014, GAO found that selected states employed a range of tools to detect \npotential program recipient fraud, though they faced some challengesAll 11 \nselected states that GAO reviewed matched information provided by SNAP \napplicants and recipients against various data sources to check for accuracy, but \nefforts varied widely among these states.\"17 One agencys officials also advised that if the states do not conduct the activities and \nachieve the results outlined in their improper payments corrective action plans, then the \nagency provides more monitoring, requires more reporting, and gives more technical \nassistance. Related to this, some agency officials offered the opinion that communicating \nproactively with the states can help them prevent improper payments. One program, for \nexample, is increasing its efforts to provide advance notification to states of upcoming \nguidance changes and increasing technical assistance to states, including identifying and \naddressing potential drivers of improper payment rate changes. 2.1.6 Work Unit Climate Work unit climate directly impacts employee motivation, \nenhancing it when employees have clear goals, roles, and \nresponsibilities; when they trust and respect each other; and when \nthey cooperate and work together as a team. In particular, an optimal work unit climate \nemphasizes teams and units collaborating internally and working effectively with other \nteams and units across the organization. Some officials indicated their agency has \nimplemented this concept, describing their working groups at the manager and staff level \nthat assist senior leaders with coordination, collaboration, decision-making, and visibility / \naccountability in addressing improper payments. \n17 SUPPLEMENTAL NUTRITION ASSISTANCE PROGRAM Policy Changes and Calculation Methods Likely Affect Improper \nPayment Rates, and USDA Is Taking Steps to Help Address Recipient Fraud (GAO-16-708T, July 8, 2016) 14 2.1.7 Task and Individual Skills Applied literature and research identified the importance of staff \nskillsets in increasing accuracy and preventing improper \npayments. These skills must be sustained and improved over time, \nwhich costs money. Further, using humans to conduct analytical tasks to help prevent \nimproper payments may be more rewarding, and thereby more motivating, than merely \nprocessing claims, which in many agencies could be more substantially automated. 2.2 Individual Employee Motivation Academic research on individual employee motivation has produced a \nmodel called the high-performance cycle, which highlights key \naspects of three elements relating to goals, feedback and rewards that \nmust be present for individual employee motivation efforts to be \neffective. The model emphasizes establishing appropriate goals in \norder to drive performance, along with rewards to recognize high performance. The impact \nof goals on performance can be enhanced when employees commit to goals, see the goals \nas important, feel confident in their ability to reach the goals, and receive feedback on \nprogress toward the goals. As shown in Figure 1, all three elementsgoals, performance,
\nand rewardsmake key contributions to motivating employees towards high \nperformance. \nFigure 1. The High-Performance Cycle Source: Locke & Latham, 2002 15 Research has also identified the following best practices to achieve high performance: Set agency, group, and individual goals that align with each other. Assign goals that are viewed by employees as challenging, specific, actionable, \nmeasurable, and time-bound. Ensure that employees are committed to the goals and perceive that they have the \ncapability (such as resources and skills) to achieve the goals. Provide feedback regarding progress towards goal achievement. Provide incentives and rewards that align with desired performance. Table 1 expands on these best practices and gives examples of their application to Payment \nIntegrity. Table 1. Summary of Key Motivational Factors for Individuals An Individuals Motivation to Perform a Task is Enhanced When: Application to Payment Integrity A challenging, specific, actionable, measurable, time-bound goal is set; the goal can be an individual goal, group goal, or both Set challenging yet achievable goals for specific types of improper \npayments to break down the problem into manageable units. Set a combination of group and individual goals to encourage teamwork \nand sharing of lessons learned while retaining individual accountability. The individual is committed to the goal \n Goals can be set with employees participation or can be assigned by management; both methods are effective as long as employees are \ncommitted to the goal. Set achievable goals and ensure transparency about the goals in order \nto increase goal commitment. Set both group and individual goals to increase goal commitment. \nThe individual has high self-efficacy (confidence that the task can be carried out) Ensure that employees: Understand how to perform their job and minimize improper payments. \n Possess the necessary skills and resources. \n Are encouraged and rewarded when achieving high performance. Feedback regarding goal progress is provided \n Provide regular, transparent, clear updates about individual employees or work units goal progress; regular feedback oriented towards the \nprocess permits employees to make timely adjustments to their \nstrategies rather than waiting until the end of the task or period to do so \nbased on outcome feedback. Celebrate milestones and other significant successes. \n Relate / link individual success to program level goals. \n Show employees the positive impact of reaching their goals, such as more program dollars to help those who need help as opposed to \ntaking money away from someone. Incentives or rewards for performance (not organizational goal achievement) are given Seek employee input on non-monetary incentives / rewards they prefer. \n Ensure linkage between performance and performance rating. \n Ensure that rewards are given for tasks / goals that are under the employees control; use group performance rewards for inter-\ndependent tasks / organization-wide goal achievement. 16 An Individuals Motivation to Perform a Task is Enhanced When: Application to Payment Integrity The goal is seen as important by the individual Communicate how improper payments impact the agencys budget and \nthus the agencys ability to accomplish its mission. Make the need to reduce / minimize improper payments part of the \nagencys mission statement. Ensure that supervisors reinforce the linkage between the individuals / \nteams work and the agency mission. Show how ensuring Payment Integrity has benefited the agencys \ncustomers by sharing anecdotes or specific cases. Appropriate task strategies are discovered for completing complex tasks Set aside time for designated employees to pursue new strategies, share \nsuccesses, and maintain awareness of new strategies (such as through \nattending conferences or assessing improper payment reduction actions \nby other agencies). Reward them for trying new strategies; ask them what they learned. \n Encourage risk taking via setting learning goals, rather than performance goals, when employees are trying new strategies. Source: MITRE Analysis Research supports the view that, compared to the private sector, the ability to motivate \npublic sector employees is constrained. One researcher put it this way: the public-sector \nwork context may find it easier to constrain employees from doing anything wrong than to \nmotivate them to do something right. [emphasis added] Constraints often impact public \nsector motivation in the following ways. Public sector managers are constrained in their ability to provide rewards that are \ncontingent on performance. Managers are also constrained in their ability to \nincrease compensation as an employees skills and experience increase. As a result, \npublic sector employees perceive a weaker relationship between extrinsic rewards \n(pay, job security) and performance than do private-sector employees. Goals are often more ambiguous, vague, and conflicting than in the private sector. As \na result, employees receive less feedback and are less certain that they have \nachieved their job-level goals, as compared to the private sector. It also is difficult \nfor employees to understand what contributions they have made and to make their \ncontributions known. The existence of extensive rules and bureaucracyred tapecan hinder goal \nachievement. Further, goal commitmenta critical foundation block of goal achievementcan be low \nwhen the wrong behavior is unintentionally rewarded. Numerous public sector examples \nexist of organizations that reward A while hoping for B. For example, agencies often \nreward spending all of the money budgeted for a particular program, while at the same \ntime hoping for prudent spending. Instead, rewards and recognition should overtly \nreinforce all types of desired behavior. 17 Although the private sectors ability to provide large salary increases, bonuses, or stock \noptions does not exist in the public sector, agencies can still effectively recognize and \nreward employees. Agencies have the authority to design extensive incentive and \nrecognition programs that include providing awards to federal employees to recognize \nspecific individual and group performance. Office of Personnel Management (OPM) \nguidance provides for a wide range of types of incentives and recognition, including the \nfollowing which could be used in conjunction with reducing improper payments. Formal rewards o Cash incentive and recognition awards programs o Quality step increases o Time off Informal recognition o A sincere Thank you! given to the employee at agency events or meetings, or \nindividually via personal visits or notes posted on the employees door or cubicle o Recognition in agency blogs or tweets, in newsletters, or with certificates of \nappreciation Outside groups can also recognize outstanding work. For example, the Baltimore Federal \nExecutive Board has recognized outstanding regional employees for more than 40 years. \nEmployees are honored in an annual award ceremony and luncheon attended by over \n1,000 federal officials, employees, and guests. Further, the Merit Systems Protection Board (MSPB) recommends providing regular \nfeedback and recognition and closely linking recognition and rewards to performance. \nMSPB reinforces the point that no single factor or action will result in dramatic, sustainable \nimprovements in an agencys performance; instead, a comprehensive, multi-faceted effort \nmust be undertaken. Agency officials offered various views on motivating employees in relation to Payment \nIntegrity. Officials at one agency believe their employees are motivated by an attitude of \npublic service, in particular \"getting the biggest bang for the buck\" for the intended \nbeneficiaries of their programs. That bang is dependent on spending the budgeted funds \non the right beneficiaries. While employees may not necessarily think overtly of \npreventing improper payments, officials acknowledged the need to prevent over-\npayments or payments to ineligible recipients in order to maximize the funds available for \nintended beneficiaries. Conversely, underpayments mean people or entities that are \nentitled to benefits are not receiving all of the benefits allowed. Officials at another agency suggested that the nature of the work at some agencies makes it \neasier for them to motivate their employees than for other agencies to do so. For example, \nthey believed it is easier to motivate employees when they process transactions like \"case \nworkers\"personally handling the details of each transaction. On the other hand, if \nautomated systems largely process the transactions, then these officials believed it is 18 harder to motivate individual employees by appealing to the spirit of public service \nbecause the employees feel more distant from the recipient of the payment or benefit. 2.3 Recommendations OMB and agencies can fundamentally transform the entire system by implementing the \nfollowing recommendations in order to create the conditions for optimal Payment \nIntegrity. 1. Affirm a Culture of Payment Integrity. Senior Executive Branch leadership needs \nto demonstrate a government-wide focus on the importance of Payment Integrity\na tone at the top that is emphasized on a regular basis,18 is enhanced in peer-to-\npeer relationships within agencies, and permeates throughout the agencies. \nPayment Integrity needs to be important to everyone. a. Consider a government-wide CAP Goal for Payment Integrity. b. Ensure there is a line of sight from agency improper payments goals through \ncomponent goals, to the performance standards of executives, managers, and \nfront line employees. Ensure employees understand the relationships between \nagency improper payment goals and their own job goalshow their job impacts \nagency-level goals. c. Include Payment Integrity as a factor in ratings and awards. Providing \nemployees with regular feedback and recognition regarding improper payments \nprevention and reduction, along with closely linking recognition and rewards to \nperformance, can motivate them towards success in this area. d. Recognizeformally and informallyindividuals at both agency- and \ngovernment-wide levels for superior achievement in meeting improper payment
\nreduction goals. e. Maintain employees self-efficacy when environmental conditions change (for \nexample, new legislation or new threats impacting Payment Integrity) by \nensuring they have the necessary skills through organizational training and \nmentoring programs and ensuring that their effort and focus do, in fact, result in \nhigher performance. f. Work with employees to enhance existing and identify new strategies that will \nhelp them achieve their individual, as well as their organizations, Payment \nIntegrity goals. For example, solicit their ideas for responding to changing \nconditions instead of imposing solutions on them. \n18 See recommendation 1 in MITREs report, GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND \nSOLUTIONS NEEDED (MTR 160040, February 2016), regarding establishing a government-wide Payment Integrity \nleadership group. 19 g. Emphasize the importance of Payment Integrity to states, grantees, and others \nacting on behalf of agencies at every opportunity, to help ensure the federal-level \ntone at the top is clearly understood. 2. Set Clear Agency Goals for Payment Integrity with Accountability for Achieving \nThem. Agencies should focus on achievable, concrete, measurable, long-term goals \nfor reducing improper payments, and ensure these goals are appropriately related \nto customer service and programmatic results (see Table 1 above). Aggressive near-\nterm reduction goals, especially if they are isolated from customer service and \nprogrammatic goals, tend to motivate agencies to choose ineffective stop-gap \nsolutions which focus primarily on treating the symptoms rather than rectifying the \ntrue root causes of improper payments. Instead, agencies need to be accountable for \nreducing their improper payments over the long term, and need to be rewarded for \nachieving appropriate reduction goals. Actions needed include: a. Providing recognition for agencies for achieving these goalsfor example, \nformal government-wide awards, or a Better Business Bureau style seal of \napproval. b. Identifying and resolving any ambiguity in and conflict between organizational \nlevel goals by examining and, as needed, modifying these goals to ensure desired \nPayment Integrity outcomes are overtly addressed. c. Identifying rewards pertaining to compliance with IPERA requirements, such as \nallowing agencies to retain a percentage of improper payment dollars prevented \nor recovered (beyond what IPERA currently allows) for future investment in \nPayment Integrity activities. d. Identifying consequences pertaining to compliance with IPERA requirements, \nsuch as leveraging funding cuts for agencies as a long-term consequence for \nfailure to achieve their improper payment reduction goals. 3. More Closely Balance the Priorities of Mission and Management. Agency \nofficials have described their dilemma in key programs between making benefits \npayments at a certain time (mission), and making sure the payments are proper \n(management). a. Executive Branch leadership needs to clarify government-wide expectations \nregarding Payment Integrity to encourage agencies to more closely balance \nmission and management. b. Agencies need to ensure their programmatic goals and process objectives \nestablish an appropriate balance between mission and management. 4. Emphasize Coordinated, Cross-Government Approaches to Payment Integrity \nChallenges. To facilitate systemic solutions, a centralized organization with \ndecision making, enforcement and political power should facilitate the effective \ncoordination of agencies, pooling of resources, achieving of synergies, and \npromotion of accountability in tackling cross-government Payment Integrity 20 challenges. Under OMBs leadership, a government-wide Payment Integrity \nleadership group, such as the working group mandated by the Fraud Reduction and \nData Analytics Act of 2015, could form such a strong, centralized decision making \nbody to develop goals and strategies and to promote accountability for Payment \nIntegrity among the heads of agencies.19 Further, as the Comptroller General of GAO \nnoted in his February 15, 2017, testimony before the Committee on Oversight and \nGovernment Reform, House of Representatives, This working groupshould help \nagencies to coordinate their fraud detection efforts20 5. Address Statutory Barriers. Legislative barriers can be de-motivators. a. As previously recommended, address statutes that appear to create or \ncontribute to improper payments in selected major programs.21 b. Include an examination of statutory requirements and restrictions, and their \nimpacts, regarding how states can spend funds on Payment Integrity activities. 6. Explore Funding Options to Strengthen Payment Integrity. Develop approaches \nto provide agencies and states with Payment Integrity funding that would not \nincrease budgets, such as: a. Ensuring agencies are taking full advantage of the provisions of IPERA and OMB \nCircular A-123, Appendix C, for identifying and using recovered overpayments to \nhelp fund financial management improvement programs to address problems \nthat directly contribute to improper payments. b. Considering Public-Private Partnerships that can provide a way for government, \ncommercial, academic, and non-profit entities to collaborate on issues of mutual \ninterest and share the burden of time, labor, and investment.22 \n19 See recommendation 1 in MITREs report, GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND \nSOLUTIONS NEEDED (MTR 160040, February 2016), regarding establishing a government-wide Payment Integrity \nleadership group. \n20 HIGH-RISK SERIES Progress on Many High-Risk Areas, While Substantial Efforts Needed on Others (GAO-17-375T, \nFebruary 15, 2017) \n21 See recommendation 13 in MITREs report, GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND \nSOLUTIONS NEEDED (MTR 160040, February 2016), regarding addressing statutes that appear to create or contribute\nvia program design, definitions, etc.to improper payments in selected major programs. \n22 See recommendation 15 in MITREs report, GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND \nSOLUTIONS NEEDED (MTR 160040, February 2016), regarding establishing Public-Private Partnerships to address \nPayment Integrity challenges. 21 c. Establishing a revolving fund for multi-agency \npilot projects to enhance collaboration for, and \ndevelop innovative approaches to, solving cross-\ngovernment problems (for example, common \nissues involving identity or eligibility). i. Agencies could borrow from the fund and \nrepay it when the projects are completed. ii. The fund could be used to implement the \nFebruary 2016 MITRE recommendation to \nassess existing metrics to determine \nwhether there are better ways to measure \nthe return on investment for pre-pay \nanalytics in order to better justify such \ninvestments.23 d. Evaluating the potential for a similar revolving \nfund at the state level, once pilot projects prove \nthe viability of a federal-level fund. 7. Consider Payment Integrity When Modernizing \nInformation Technology Systems and Developing Shared Services. When modernizing information \ntechnology systems and developing shared services, include consideration of \nprocess redesign that will enable human resources to be shifted toward higher \nvalue, greater engagement work (for example, analytics of improper payments true \nroot causes) that will increase employee investment and morale. \n23 See recommendations 3 and 12 in MITREs report, GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES \nAND SOLUTIONS NEEDED (MTR 160040, February 2016), regarding preventing errors and deterring fraud, and pre-pay \nanalytics, respectively. White House Chief \nInformation Officer Tony \nScott's proposal for a $3.1 \nbillion revolving fund \ndesigned to pay for \n[information technology] \nmodernizationa variation \nof which passed in the \nHousecould be one of \nthose solutions to the future \n \nit's one of the solutions, \n[U.S. Controller David] \nMader said. \nGovernment Shared Services Meet Challenges in People, Capital (NextGov, \nDecember 7, 2016) REVOLVING FUNDS 22 3 What Motivates ClaimantsIndividuals and Organizations Filing Benefits Claims, Tax Returns, Commercial Invoices, Etc.to Be Accurate and Not Make Errors or Commit Fraud? The motivation to be accurate and not make errors or commit fraud when submitting \nclaims of various types to the government can arise from sources both extrinsic and \nintrinsic to the individual. How agencies are viewedin terms of trust and poweralso \nplays an important role. While no single model takes into account all the relevant factors \nthat affect such motivation, agencies can nevertheless take advantage of all these \npossibilities to motivate claimants to be accurate and not make errors, and to deter them \nfrom committing fraud. In conducting this portion of the study, the great majority of the research MITRE identified \nand reviewed pertained to individual motivation vis--vis tax compliance. Some of that \nresearch mentioned organizations, but there was no discussion of the behavior specifically \nof large organizations. For the purposes of the analysis that follows, MITRE assumes that \nthe behavior of individuals when interacting with non-tax agencies is generally the same as \nwhen interacting with the Internal Revenue Service (IRS). However, people do not \nnecessarily view other federal agencies with the same degree of trust, power or \ncompetence as they view IRS. So it is possible that some individuals may not respond to \nthese other agencies in the same way that they respond to IRS motivating actions. 3.1 Extrinsic Motivation Extrinsic motivation is a reward or incentive from a person or \nentity intended to induce another person to take an action. An \nextrinsic motivator may be necessary when a person is not \nsufficiently motivated intrinsically, such as by a personal desire \nto achieve a goal or complete a task. Examples of extrinsic \nmotivators include the following. In education, grades are an extrinsic motivator for learning and achievement. In organizations, compensation, public praise, and employee awards are extrinsic \nmotivators to inspire employees towards high performance. 3.1.1 The Traditional or Classical Economic Deterrence Model Extrinsic motivation in Payment Integrity usually focuses on \ntraditional deterrence theory, which is based on the economics-\nof-crime model. The model is most frequently applied to tax evasion, where it is believed \nthat the probability of being examined and the magnitude of the possible penalty are 23 correlated with the level of voluntary tax compliance. This represents essentially a risk-\nbased approach, where the probability of being examined equates to
the likelihood of the \nevent occurring, the magnitude of the possible penalty equates to the consequence / impact \nif the event does occur, and the two taken together equate to the level of risk. Voluntary tax \ncompliance, then, becomes a form of risk mitigation. In reality, however, taxpayers as a whole do not appear to make their compliance decisions \nsolely based on the likelihood of being examined. While the perceived probability of \nexamination does seem to impact individual compliance decisions, changes to the overall \nexamination rate appear to have little or no effect on voluntary compliance overall. \nIndividual behavior is often consistent with the classical theory, but it is sporadic and does \nnot appear at the macro or systemic level. In effect, people simply do not break the rules \nas often as the classical economic deterrence model would predict, even where the risk of \npunishment is relatively low. So it seems that IRS examination risk (or perhaps \ncompliance reviews by other agencies) is not the entire motivation in framing an \nindividuals decision whether to comply. The focus of the classical economic deterrence model is strictly on extrinsic motivation. The \nmodel implicitly excludes as irrelevant any considerations of justice, fairness and other \nnonpecuniary (intrinsic) motivators for complianceas well as peer behavior, guilt, \nshame, and other psychological factors. The model appears to have little or no utility in \ndefinitively predicting overall taxpayer compliance, but the constituent elements of the \nmodelthe related threats of examination and fines / penaltiesdo appear to have a \npredictive relationship with individual compliance behavior. Therefore, these types of \nactivities should be taken into account in any analysis of taxpayer behavior and considered \nfor inclusion in any program aimed at motivating taxpayers to comply. 3.1.2 Impacts of the Environment Extrinsic motivation can also derive from the characteristics of the \nenvironment. For example, the ability to obtain all necessary \ninformation, and have it presented in clear and straightforward \nways, better motivates individuals to make good compliance decisions. However, this is not \nalways the case with government programs. Two examples pertaining to significant \nprograms with billions of dollars of improper payments each year follow. Accountability officials indicated that the complexity of the Earned Income Tax \nCredit creates difficulties for IRS in educating the population that claims the credit, \ndecreasing the motivational benefits of education. In June 2015, GAO testified24 before the House Subcommittee on Social Security, \nCommittee on Ways and Means, that the Disability Insurance programs work \nincentive rules are confusing. GAO officials stated that SSA staff interviewed had \nvarying interpretations of the rules and gave beneficiaries differing instructions. \n24 DISABILITY INSURANCE Preliminary Observations on Overpayments and Beneficiary Work Reporting (GAO-15-673T, \nJune 16, 2015) 24 This can lead to variations in the level of compliance motivation among \nbeneficiaries. Another environmental characteristic that impacts individuals motivation to comply with \nrequirements is the way a program is structured. In particular, programs that have to \nwholly or partially rely on beneficiaries self-reporting of life changes, such as a change in \nincome level or number of dependents, for determination of compliance are at a distinct \ndisadvantage. Agency officials stated: Many beneficiaries who must self-report life changes are not focused on self-\nreporting, which complicates agency reliance on it. Frequently reminding \nbeneficiaries of their self-reporting responsibilities may simply not work. It needs to be easy for individuals to self-report and interact with agencies. For \nexample, interaction mechanisms need to be tailored to the specific groups with \nwhich each agency interacts, and potential unintended consequences need to be \nidentified and considered before making any changes to reporting methodologies. Self-reporting needs to be individual-focused, not agency-focused or program-\nfocused; for example, it might be advantageous to self-report information to a \nsingle government point-of-entry, instead of having to report the same information \nmultiple times across programs or agencies. Another major factor with program structure is how a system such as health care \nreimburses for items and services. Agency officials indicated this can dictate how unethical \nand dishonest individuals will exploit the system. The specific anti-fraud measures and \nprogram safeguards that must be integrated into programs depend on the way that system \nand its payments are structured. 3.2 Intrinsic Motivation Intrinsic motivation is a person's natural, innate \nmotivation. Anything that moves a person to do \nsomething out of pure interest, such as learning to play a \nsport or creating artwork without being compelled to do \nso, is an intrinsic motivator. It is the most effective \npersonal motivator, and because of that, positive long-\nrange results are more likely from intrinsic motivators \nthan from extrinsic ones. Finally, extrinsic and intrinsic \nmotivation can coexist; for example, a person may be extrinsically motivated by high pay in \nthe workplace but at the same time be more highly motivated by their true enjoyment of \nthe work. 25 3.2.1 Social Psychology and Tax Morale Social psychology has established that along with extrinsic factors, \nthere are multiple intrinsic (psychological) factors that can affect \ntax compliance. Intrinsic or psychological motivators include: Perceived fairness with regard to the tax system and the \nauthorities administering the system Acceptance of tax evasion among a relevant reference group Perceived tax evasion among friends Sense of self-esteem / self-image Perceived procedural, distributive, or retributive justice25 Building on these motivators, tax morale is a concept developed by social psychology to \nencompass nonpecuniary motivators for tax compliance as well as factors that fall outside \nthe standard, expected utility framework (the classical economic deterrence model). \nSpecific factors in the tax morale concept include: Intrinsic motivation o Paying taxes or feeling guilt or shame for not doing so o Being influenced by peer behavior, including the possibility of social \nrecognitionor sanctionsfrom peers, in which the willingness to pay taxes \ndepends on the views or behaviors of other individuals, such as a reluctance to \ndo something wrong in the eyes of others Reciprocal motivationwillingness to pay taxes in exchange for benefits that \ngovernment provides even though the pecuniary payoff would be higher by not \npaying the taxes; it should be noted that behavioral economics suggests that any \nperceived remoteness of a compulsory payment from its benefit is critical to \ncompliance considerations Cultural factors, such as corruption, that may affect the willingness to pay taxes Information imperfections and deviations from utility maximization; for example, \nindividuals may misperceive the probability of being detected when they evade \ntaxes or may exhibit a systematic bias in their decision-making process such as loss \naversion Tax authorities often pursue policies that reflect the belief that nonpecuniary factors are \nimportant in tax compliance decisions. For example, publicity and visibility are often used \nin both positive and negative ways. Some tax authorities have publicly recognized \ncompliant or high-payment taxpayers. Alternatively, more than half of U.S. states have or \n25 Procedural justice concerns fairness of the processes by which decisions are made. Distributive justice refers to fairness \nin the distribution of rights or resources, while retributive justice refers to fairness in the punishment of wrongs. 26 have had name and shame programs in which the names of top tax debtors are revealed \npublicly on state websites. Related to these factors, behavioral economics offers additional intrinsic motivators that \ncan impact an individuals tax compliance decisions. These include: Cost-benefit analysisbalancing the cost of being detected with the benefits of \nsuccessfully evading payment A libertarian approachThis money belongs to me Alienationpeople may not feel part of a society Resentment of coercionpeople simply do not like to be forced to pay their money \nin taxes Perception of unfairness vis--vis the obligation to pay taxes, such as the belief that \nrich individuals do not pay enough taxes Reciprocity / social acceptability of noncompliancein some societies tax evasion is \nnot considered an intolerable act Perception that Others are not payingwhy should I? Outcome remotenessthe inability to see the effect of noncompliance 3.2.2 Visibility and Accountability Just as with motivating agencies and those that act on their behalf, \nvisibility and accountability can motivate claimants. In particular, \nofficials at one agency offered the view that visibility generally \nimpacts organizations that receive federal funding more so than \nindividuals; in other words, reputational risk is a more significant issue for organizations. 27 Agency and accountability officials, as well as applied \nliterature and research, offered a number of actions \nthat organizations take to promote visibility and \naccountability in hopes of motivating claimants to be \naccurate and not make errors or commit fraud. Using compliance activities (such as identity \nvalidation, penalties, loss of benefit eligibility) to \nmotivate, balanced with help for claimants when \nappropriate; leveraging enforcement to increase \nlevels of claimant responsibility. Informing claimants that their information will \nbe shared with other agencies for matching. Incorporating accountability clauses in grants to \nensure grantees awareness of responsibilities. Raising public awareness and providing \neducation regarding noncompliance penalties\nensuring these penalties are well known. Naming and shamingbut an agency must \nhave credible power for this to be of value. Recognizing compliant or high-paying taxpayers \npublicly as an alternative to shaming tax \nevaders, a strategy adopted by an increasing \nnumber of developing countries. Conducting public campaigns to change attitudes towards tax evasion; for example, \ntelevision and
print advertising campaigns were used in Italy to highlight the need \nto reduce widespread tax evasion in order to better cope with the European debt \ncrisis. 3.2.3 Trust in Authorities and Perception of Power as Motivators How claimants view agenciesin terms of the level of trust of \nthose agencies and the power they are perceived to haveplays a \nrole in both voluntary and enforced compliance. Research in, \nagain, taxation has shown that when both the level of trust and the perception of power are \nlow, more taxpayers aim at maximizing individual payoffs by evading taxes. Boosting the \nlevel of trust enhances voluntary compliance, whereas increasing the power of authorities \nleads to enforced compliance. So while increasing both trust and power can improve \ncompliance, the quality of the taxpayers cooperation differs. Mark Branson, the head of \nSwitzerlands financial regulatory \nbody, the Swiss Financial Market \nSupervisory Authority (Finma), \nstated in an interview that levying \nlarge penalties on banks for \nfinancial crime compliance \nfailures will not lead to better \nadherence to regulations across \nthe financial services sector. \nBranson noted that Finma does \nnot have the power to impose \nmassive fines on recalcitrant \nbanks, and that the hefty penalties \npaid in countries like the U.S. and \nUK have not stopped bank \ncompliance failures or money \nlaundering and are, in actuality, \nborne by the shareholders. Finma \nhas the power to pull the profits \nbanks get on illicit funds and can \nlimit activities, which can be an \neffective motivator for change. DO BIG FINES INCREASE COMPLIANCE? 28 The mediating effects of trust and power on compliance have been depicted as shown in \nFigure 2. Compliance is highest when the level of trust is high. Conversely, when both the \nlevel of trust and perceived power are low, compliance is at its lowest. \nFigure 2. Overall Tax Compliance as a Function of Trust and Power Source: Kogler, Muehlbacher, Kirchler, 2013 If compliancewhether voluntary or enforcedis to be enhanced by claimant perceptions \nthat the authority is trustworthy or powerful or both, then it is critical that the claimant \nalso perceive the authority as competent. There can be neither a belief in agency \ntrustworthiness nor respect for agency power if the agency is perceived as ineptwithout \nregard to whether the agency is, in fact, inept. Perception is the driver. 3.2.4 Enterprise Risk Management and Relation to Trust Enterprise Risk Management (ERM) is a discipline that addresses \nthe full spectrum of an agencys risks and issues, including \nchallenges and prospects, integrating them into an enterprise-\nwide, strategically aligned portfolio view. It is a component of an \noverall governance framework and encompasses areas of enterprise-wide exposure to risk, \nsuch as financial, compliance, and reputational risks. Reputational risk is particularly relevant to the issue of compliance motivators. As OMB \nCircular A-123 notes, this risk damages the reputation of an Agency to the point of having When level of trust, perceived power, or both are high, compliance is high. When level of trust and perceived power are low, compliance is low. 29 a detrimental effect[on its] ability to carry out mission objectives. The Circular goes on \nto state that an example of reputational risk would be the loss of trust and confidence that \nstakeholders have in the agency to deliver operational services, and adds that reputational \nrisk of fraud, in particular, can damage the perception of an agency and create public \ndistrust. The requirements in the Circular for agencies to assess and mitigate their risks, \nincluding reputational risk, can help with the level of trust that stakeholders and claimants \nhave for agencies. 3.2.5 Interactions Between Agencies and Claimants Research has shown that interactions between agencies and \nclaimants contribute to the claimants perception of agencies \ntrustworthiness and competence. Something as simple as the \nclarity of claim forms can enhance, or damage, that perception. \nFurther, claim forms and online filing processes can elicit more truthful responses from \nclaimants by techniques such as using more direct questions and placing the commitment \nnot to cheat at the beginning of forms rather than at the end. Such techniques put the \nburden on claimants to give explicit answers and increase the psychological cost of lying. Other types of interactions can contribute to claimants perception of agencies power and \ncompetence. For example, an agency being able to quickly identify misstatements on claim \nforms, and communicating to claimants in advance that this will occur, can enhance this \nperception. The certainty of detection of misstatementsbased, as one alternative, on an \nagencys ability to quickly and effectively compare representations on claim forms with \nindependent, reliable datais a powerful motive for compliance. Even a small increase in \nan agencys ability to do this, conveyed to claimants, can enhance the perception of power \nand competence, thereby increasing the motivation to comply. Effective, helpful communications between agencies and claimants can enhance trust and \nthe perception of competence. Agency officials indicated they take a number of actions to \nstrengthen communications with claimants, such as: Providing both general information to all claimants and targeted communications / \noutreach to specific claimants. Proactively communicating, esp. when changes are occurring in a program. Using real-time / near real-time communications; one major program, for example, \nthat issues benefits via electronic benefit transfer cards has a vision to be able to \nsend a card user an immediate text message when the system sees a questionable \ntransaction, asking them if they understand the rules. Emphasizing clarity in communications. Using multiple communications mediapamphlets, website, webinars, social media. Incorporating clauses in contracts re: reducing / recovering improper payments to \nserve notice to contractors of the importance of the issue. Talking openly about fraud with grantees, contractors and other claimants. 30 3.3 Recommendations OMB and agencies can fundamentally transform the entire system by implementing the \nfollowing recommendations in order to create the conditions for optimal Payment \nIntegrity. 8. Ensure Claimants Have Easy, Optimal Means to Interact with Agencies. \nGovernment forms, instructions, payment methods, etc., need to be clear and simple \nto use so it will be easy for claimants to comply and will enhance their perceptions \nof agency trustworthiness and competence. Without this, people sometimes default \nto errors and noncompliance. This also supports achievement of the CAP Goal for \nCustomer Service (mak[e] it faster and easier for individuals and businesses to \ncomplete transactions). Specific actions agencies can take include: a. Eliminating ambiguities in claim forms. b. Revising forms to use only direct wording and plain language. c. Redesigning forms and online filing processes to elicit more truthful responses \nfrom claimants. d. Making it as easy as possible for people to self-report. The process should be \napplicant-focused vs. agency / government-focused, such as easier, one-time \nreporting of the same information instead of multiple times across programs and \nagencies.26 9. Strive for Proactive, Timely Communications with Claimants. Agencies should \nensure that communications with claimants are proactive and near real-time to key \nevents, such as the filing of a benefits claim, in order to maximize their value and \nenhance perceptions of competence and trustworthiness. 10. Broaden Use of Compliance-oriented Motivators Like Data Matching. There is \nmotivational value in securing and matching / analyzing / mining data from various \nsourcessuch as other agencies, the private sector, or open sourcesand then \nusing it for compliance and outreach. The fact that the agency is doing this should be \ncommunicated to claimants, which will enhance the perception of power. For \nexample, advise claimants that their data will be validated and verified during the \nclaims process. 11. Consider Additional Compliance Motivators, as Warranted. Agencies should \nconsider the following additional compliance motivators for individuals and \norganizations to which they make payments, to enhance perceptions of power. \n26 See recommendations 8 and 9 in MITREs report, GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES \nAND SOLUTIONS NEEDED (MTR 160040, February 2016), regarding reducing reliance on self-reporting by benefits \nrecipients where it causes the most risks and identifying and pilot testing agency-specific and government-wide \nalternatives for making identity and eligibility determination processes more rigorous, data driven, and cost-effective, \nrespectively. 31 a. Employ swift and effective consequences for claimants balanced with providing \nhelp when appropriate, such as a designated team to address \"suspended\" \npayments rapidly. b. Use publicity, such as naming and shaming, to increase the visibility of the \nconsequences of noncompliance. c. Signpost potential penalties to increase the motivation for people to take \nresponsibility. d. Require proactive confirmation of claimant life changes to increase the \nmotivation for people to take responsibility. e. Include clauses in contracts for the recovery of improper payments. f. Include accountability clauses in grants. 32 Appendix A Study Purpose and Methodology The MITRE Corporation, a not-for-profit organization that operates FFRDCs on behalf of \nfederal government sponsors, recognizes the impact that the overall federal Payment \nIntegrity situation has on government effectiveness and public confidence. Given the public \ninterest nature of this challenge, MITRE conducted this independent study as a follow-on to \nits February 2016 report27 that assessed the underlying systemic factors that enable fraud \nand other improper payments and explored government-wide solutions to improve \nPayment Integrity. We acknowledge the considerable efforts already in place at OMB and across federal \nagencies
focused on identifying, reporting and mitigating improper payments. With that in \nmind, this study focuses on a key issue that impacts those efforts along with the \nimplementation of many of the recommendations made in the February 2016 report\nwhat motivates federal agencies, those acting on their behalf (for example, states, \ngrantees), and recipients of federal payments of all kinds to optimize their ongoing \nPayment Integrity efforts? In conducting this qualitative study, MITRE interviewed officials at 9 agencies and 4 \noversight and accountability organizations and reviewed extensive academic literature and \ndomestic and international applied literature and research. MITRE then assessed this \ninformation in the context of motivators specific to Payment Integrity. Table 2 presents a complete listing of interviews, while documents reviewed are shown \nafter the table. Table 2. Study Interviews Agencies Department of Defense Department of Education HHSCMS Department of Homeland Security Department of Labor (DOL) IRS OPM SSA Department of Veterans Affairs (VA) Oversight and Accountability Organizations OMB Resource Management Offices for DOL, IRS, \nand SSA GAO SSA Office of Inspector General (OIG) Treasury IG for Tax Administration \n27 GOVERNMENT-WIDE PAYMENT INTEGRITY: NEW APPROACHES AND SOLUTIONS NEEDED (MTR160040, February \n2016) 33 \nWe researched relevant statutes and guidance, particularly IPERA and OMB Circular A-123 \nAppendix C; prior MITRE work products on improper payments; and the following \ndocuments to assemble a wide array of key information for use in the assessment. Agency documents o DOL. FY 2015 Annual Performance Report. o DOL. FY 2012 Annual Report on Improper Payment Recapture Activities. \nNovember 2012. o Federal Reserve Bank of Kansas City. Controlling Security Risk and Fraud in \nPayment Systems. o HHS. Fiscal Year 2015 Agency Financial Report. o HHS. HHS Strategic Plan, FY 2014-2017. o HHS. Testimony: Statement by Shantanu Agrawal, M.D., Deputy Administrator \nand Director, Center for Program Integrity, Centers for Medicare & Medicaid \nServices, U.S. Department of Health and Human Services, on CMS Efforts To \nReduce Improper Payments In The Medicare Program, before the Committee on \nOversight & Government Reform, Subcommittee on Energy Policy, Health Care & \nEntitlements, United States House of Representatives. (May 20, 2014) o SSA. Social Security Administration Agency Strategic Plan: FISCAL YEARS 2014 \n2018. o SSA. Annual Performance Report, FY 2015 2017. o Treasury. Agency Financial Report: Fiscal Year 2015. o Treasury. Department of the Treasury FY 2014-2017 Strategic Plan. o U.S. Department of Agriculture. Agency Financial Report FY 2015. o VA. Financial Policies and Procedures, Volume VII, Chapter 9, Financial \nReporting Erroneous and Improper Payment Reporting under OMB Circular A-\n123, Appendix C. January 2016. Congress o United States House of Representatives Subcommittee on Human Resources of \nthe Committee on Ways and Means. TranscriptHearing on the Use of Data \nMatching to Improve Customer Service, Program Integrity, and Taxpayer \nSavings. March 2011. o United States Senate Special Committee on Aging. Committee Staff Report, \nImproving Audits: How We Can Strengthen the Medicare Program for Future \nGenerations. 2014. 34 GAO reports o A Framework for Managing Fraud Risks in Federal Programs (GAO-15-593SP, \nJuly 2015) o DISABILITY INSURANCE Preliminary Observations on Overpayments and \nBeneficiary Work Reporting (GAO-15-673T, January 16, 2015) o ELECTRONIC HEALTH RECORDS First Year of CMSs Incentive Programs Shows \nOpportunities to Improve Processes to Verify Providers Met Requirements \n(GAO-12-481, April 1, 2012) o FISCAL OUTLOOK Addressing Improper Payments and the Tax Gap Would \nImprove the Government's Fiscal Position (GAO-16-92T, October 1, 2015) o FOSTER CARE PROGRAM Improved Processes Needed to Estimate Improper \nPayments and Evaluate Related Corrective Actions (GAO-12-312, March 2012) o IMPROPER PAYMENTS Government-Wide Estimates and Reduction Strategies \n(GAO-14-737T, July 19, 2014) o IMPROPER PAYMENTS Moving Forward with Government-wide Reduction \nStrategies (GAO-12-405T, February 7, 2012) o MEDICARE Claim Review Programs Could Be Improved with Additional \nPrepayment Reviews and Better Data (GAO-16-394, May 2016) o MEDICARE PROGRAM INTEGRITY Greater Prepayment Control Efforts Could \nIncrease Savings and Better Ensure Proper Payment (GAO-13-102, November \n2012) o MEDICARE RECOVERY AUDIT CONTRACTING Lessons Learned to Address \nImproper Payments and Improve Contractor Coordination and Oversight (GAO-\n10-864T, July 15, 2010) o STRATEGIES TO MANAGE IMPROPER PAYMENTS Learning From Public and \nPrivate Sector Organizations (GAO-02-69G, October 2001) o SUPPLEMENTAL NUTRITION ASSISTANCE PROGRAM Policy Changes and \nCalculation Methods Likely Affect Improper Payment Rates, and USDA Is Taking \nSteps to Help Address Recipient Fraud (GAO-16-708T, Reissued July 8, 2016) International sources o Asian Organization of Supreme Audit Institutions. Evaluation and Improvement \nof Internal Audit Systems and the Relationship Between the Internal Audit Units \nand [Supreme Audit Institutions]. 2012. o Australian Institute of Criminology Fraud Against the Commonwealth. July 2015. Responding to Welfare Fraud: The Australian Experience. December 2012. 35 Trends & Issues in Crime and Criminal Justice no. 418. 2011. o Australian National Audit Office (ANAO) Administration of the Fair Entitlements Guarantee. April 2015. Annual Compliance Arrangements with Large Corporate Taxpayers. \nNovember 2014. Centrelink Fraud Investigations. September 2010. Fraud Control Arrangements. October 2014. Fraud Control in Australian Government Agencies. May 2010. Implementation of ANAO Performance Audit Recommendations. May 2014. Medicare Compliance Audits. April 2014. o New Zealand Associate Minister for Social Development. Combatting Welfare \nFraudMain Initiatives. February 20, 2013. o Organization of Economic Cooperation and Development Corporate Governance and Business IntegrityA Stocktaking of Corporate \nPractices. 2015. Integrity in Public ProcurementGood Practice [sic] from A to Z. 2007. o United Kingdom BDO LLP and the Center for Counter Fraud Studies at the University of \nPortsmouthTHE FINANCIAL COST OF HEALTHCARE FRAUD 2014. March \n2014. Fraud, Error and Debt TaskforceTackling fraud and error in government. \nFebruary 2012. Her Majestys Revenue & Customs, Department for Work and Pensions Estimated Fraud and Error Savings 2011/12 to 2014/15. July 2015. Fraud and error in financial, welfare and revenue services: A Systematic \nMap of the empirical research evidence (WP97). April 2013. Fraud and Error in the Social Protection SystemThe UKs Approach. \n2014 / 2015. Fraud and Error Service. June 2014. Penalties Policy: In respect of social security fraud and error. January \n2015. Tackling fraud and error in the benefit and tax credits systems. October \n2010. 36 Home Office. Fighting Fraud Together: The strategic plan to reduce fraud. \nUndated. Howard Journal of Crime and Justice. COUNTERBLAST: Another Case of Old \nWine in New Bottles? The Coalitions Misguided Strategy to Reduce Benefit \nFraud. May 2011. National Audit Office Department for Work and Pensions 2015-16 accounts. July 2016. Department for Work and Pensions: Management of benefit overpayment \nof debt. May 2009. Fraud landscape review. February 2016. Her Majestys Revenue & Customs [HMRC] 2013-14 accounts. July 2014. Her Majestys Revenue & Customs Annual Report and Accounts 2015-16. \nJuly 2016. Housing Benefit fraud and error. October 2014. Reducing losses in the benefits system caused by customers mistakes. \nJanuary 2011. Tackling tax credits error and fraud. February 2013. Tackling tax fraud: how HMRC responds to tax evasion, the hidden \neconomy and criminal attacks. December 2015. News media HMRC asked tax avoider to sign pledge not to engage in practice again. \nThe Guardian. November 27, 2015. Round table: improving debt recovery. Civil Service World. June 17, \n2014. Parliament Committee on Public Accounts. Fraud and Error Stocktake. October 19, \n2015. Communities and Local Government Committee. Implementation of \nwelfare reform by local authorities. April 3, 2013. Treasury Subcommittee. ADMINISTRATION AND EFFECTIVENESS OF \nHMRCOral Evidence before the Treasury Subcommittee. October 31, \n2012. Work and Pensions Committee Benefit delivery: Committees Fourth Report of Session 201516. \nDecember 18, 2015. 37 Benefit delivery: Government Response to the Committees Fourth \nReport of Session 201516. July 11, 2016. Fraud and error in the benefits system: Government Response to the \nCommittee's Sixth Report of Session 2013-14. September 5, 2014. Sixth Report: Fraud and error in the benefits system. May 15, 2014. OMB document: Reducing Improper Payments: [Unemployment Insurance] \nIntegrity Conference. April 10, 2010. OIG reports o U.S. Department of Education Office of Inspector General, FY 2015 Management \nChallenges; and FY2106 Management Challenges. o HHS OIG. MEDICARE CLAIMS ADMINISTRATION CONTRACTORS ERROR RATE \nREDUCTION PLANS. January 2014. o HHS OIG. Statement of Lewis Morris, Chief Counsel, Office of Inspector General, \nDepartment of Health and Human Services, before the Healthcare Compliance \nAssociation. Undated. Professional and Research sources o American Action Forum. Curbing Waste, Fraud, and Abuse in Medicaid. March \n9, 2016. o American Physical Therapy Association. CMS Criticized Over Rate of Improper \nPayments. July 15, 2014. o Brookings. Should the US follow the UK to a Universal Credit? July 10, 2014. o Cato Institute. Reducing Wasteful Spending. Testimony of Chris Edwards \nbefore the Committee on Homeland Security and Governmental Affairs, United \nStates Senate. June 10, 2015. o Center for Budget and Policy Priorities. SNAP: Combating Fraud and Improving \nProgram Integrity Without Weakening Success. June 9, 2016. o Deloitte. Federal CFO Insights Improper PaymentsAccountability of CFOs. 2015. Three Steps to Improve Improper Payments Prevention Strategies. March \n2016. o DLA Piper. [Medicare Access and CHIP Reauthorization Act of 2015]: Three \nCompliance Implications for Medicare Providers. May 2015. o IBM. The new era of incentive compensation management: simplicity, \nproductivity and profitability. 2015. o Institute for Legal Reform. Fixing the False Claims Act: The Case For Compliance-\nFocused Reforms. October 1, 2013. 38 o McKinsey & Company. Better for less: Improving public sector performance on a \ntight budget. July
2011. o Journal of State Taxation. Credit and Incentives Update; Unemployment \nInsurance Integrity: What Employers Need to Know. March / April 2013. o President's Management Advisory Board Approved Recommendations. \nSeptember 7, 2012. o Steinhoff, Jeffrey and Danny Werfel. Are You Combat Ready to Win the War \nAgainst Improper Payments? Journal of Government Financial Management. \nSummer 2014. News media sources o Medicare Cuts Back Work of Auditors Probing Improper Payments to \nHospitals. The Wall Street Journal. October 30, 2015. o New Tricare requirement for proof of payment takes effect overseas. Stars and \nStripes. October 10, 2012. 39 Appendix B List of Abbreviations AFR Agency Financial Report ANAO Australian National Audit Office CAP Cross-Agency Priority CFO Chief Financial Officer CHIP Childrens Health Insurance Program CMA Computer Matching and Privacy Protection Act of 1988 (P.L. 100-53) CMS Centers for Medicare & Medicaid Services DNP Do Not Pay DOL Department of Labor FFRDC Federally Funded Research and Development Center Finma Financial Market Supervisory Authority FY Fiscal Year GAO Government Accountability Office HHS Department of Health and Human Services HMRC Her Majestys Revenue & Customs IPERA Improper Payments Elimination and Recovery Act of 2010 (P.L. 111-204) IPERIA Improper Payments Elimination and Recovery Improvement Act of 2012 \n(P.L. 112-248) IRS Internal Revenue Service MITRE The MITRE Corporation MSPB Merit Systems Protection Board OIG Office of Inspector General OMB Office of Management and Budget OPM Office of Personnel Management SNAP Supplemental Nutrition Assistance Program SSA Social Security Administration SSI Supplemental Security Income VA Department of Veterans Affairs Introduction\n 1.1 Federal Requirements Regarding Payment Integrity\n 1.2 The Current State of Federal Payment Integrity What Motivates and Enables Agencies and Those Acting on Their Behalf to Optimize Their Ongoing Payment Integrity Efforts?\n 2.1 Organizational Motivation\n 2.1.1 External Environment\n 2.1.1.1 Visibility and Accountability\n 2.1.1.2 Legislation\n 2.1.1.3 Resources 2.1.2 Mission and Strategy\n 2.1.3 Leadership\n 2.1.4 Organizational Culture\n 2.1.5 Systems (Policies and Procedures)\n 2.1.6 Work Unit Climate\n 2.1.7 Task and Individual Skills 2.2 Individual Employee Motivation\n 2.3 Recommendations What Motivates ClaimantsIndividuals and Organizations Filing Benefits Claims, Tax Returns, Commercial Invoices, Etc.\n 3.1 Extrinsic Motivation\n 3.1.1 The Traditional or Classical Economic Deterrence Model\n 3.1.2 Impacts of the Environment 3.2 Intrinsic Motivation\n 3.2.1 Social Psychology and \"Tax Morale\"\n 3.2.2 Visibility and Accountability\n 3.2.3 Trust in Authorities and Perception of Power as Motivators\n 3.2.4 Enterprise Risk Management and Relation to Trust\n 3.2.5 Interactions Between Agencies and Claimants 3.3 Recommendations\n Appendix A Study Purpose and Methodology Appendix B List of Abbreviations\n Appendix B List of Abbreviations ",
    "text": " () 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' Note to Reviewers: These intern photos and quotes will be posted (one each month) in the hero carousel at https://www.mitre.org/careers/student-programs The first one (Sharif S.) went through PRS already and is in the hero carousel now. \"At MITRE, I've honed my programming skills, further developed my project management skills, and refined my leadership skills.\" Chris T. (Computing Security major) https://www.mitre.org/careers/student-programs\nhttp://r300resource.mitre.org/PhotoGalleries/Bedford/2017/Jul/Nolan_Poulin_Student_Voices/index.html 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"I really appreciate that MITRE is a knowledge enterprise that focuses on helping our sponsors make decisions that advance technology effectively.\" Nolan P. (Masters Program in Robotics) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"My favorite thing about interning at MITRE was being able to work on meaningful projects. I felt motivated by the impact of the work I did and proud of my contributions.\" Uma D. (Computing major) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"I'm going to use my MITRE experience to look further into the fields I learned about here and see what kinds of courses are offered in those areas.\" Milan S. (Electrical Engineering major) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"Seeing how my department applies computer vision and artificial intelligence to solving problems for the federal government has really furthered my interest in those fields.\" Sherry X. (high school intern) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"MITRE has shown me how much diversity can be incorporated into your work. The projects span all topicsnot many companies can make that claim.\" Daniel C. (Aerospace Engineering major) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"MITRE gave me a broader view and understanding of the software development process and lifecycle.\" Ellin H. (Computer Science major) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"One of the best things about MITRE was the amazing mentorship I received from my project leaders.\" Rony X. (Masters Program in Cybersecurity) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"One of the most interesting parts of interning at MITRE was being immersed in a professional atmosphere and seeing what my degree will allow me to do in the future.\" Amanda P. (Computer Science major) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"My time at MITRE has been an incredible learning experience.\" David L. (Computer Science and Russian major) 'Approved for Public Release; Distribution Unlimited. Case Number 17-3439' \"The MITRE student hackathon was great. I never thought I could work for that many hours in a row but we created a cool project and I learned how to develop apps.\" Katie B. (Electrical and Computer Engineering major) Note to Reviewers: These intern photos and quotes will be posted (one each month) in the hero carousel at https://www.mitre.org/careers/student-programs The first one (Sharif S.) ",
    "text": " 'Approved for Public Release; Distribution Unlimited. Case Number 17-3370'. Interns Tackle 3D Printing Challenge (a Student Voices article) One day, the Dronenut drone application and the Slouch Potato posture-monitoring system may become \nrecognized internationally as must-have itemsthey were the result of the 2017 intern challenge held at \nMITRE's Bedford campus this summer. The challengedeveloped and implemented by former MITRE interns (now full-time employees) Erin \nJaffke and Stephanie Medickeencouraged the company's 2017 summer interns to freely experiment \nwith 3D printing technology. The goal was to create and print an item that resolves an existing problem \nor enables a new solution. \"We wanted to create a challenge that would interest everyone,\" Medicke says. \"3D printing is cross-\ncutting. It can enable designs that aren't specific to any one department or discipline.\" More than 30 interns, working in seven teams throughout the summer, came up with an array of ideas \nfor the 2017 Bedford Intern 3D Printing Design Challenge. The winning team created a design for a \nfloating, airborne Automatic Dependent Surveillance-Broadcast (ADS-B) antenna. The members of the winning team were: Daniel Cashdollar of Embry-Riddle Aeronautical University \n(Daytona Beach, Florida); Jacob Downs, Olivia Maffia, and Keith Miller of the University of Massachusetts \nat Amherst; and Thomas Scaplen of Worcester Polytechnic Institute in Worcester, Massachusetts. They wanted to create a design that could extend the reach of the ADS-B antenna located on one of the \nMITRE buildings, at an elevation from 100 feet to 400 or 500 feetor higher. The team's solution \nincluded an ADS-B antenna, a weather balloon, a GPS receiver, air-to-ground communications, and \n80-pound line to tether the antenna to a ground system. They used 3D printing to create the system's \nknotless tie line. \"It [the knotless tie line] utilized some unique aspects of 3D printing, making shapes and cuts and the \nholes through the middle that would be pretty hard to make otherwise using conventional methods,\" \nCashdollar, who created the tie line, says. The Judging Process Four senior MITRE staffCharley Benway, Richard Games, Russell Graves, and Carole Mahoneyjudged \neach team's entries. The open-ended competition made things interesting, according to Games. \"Everyone was doing different things,\" he says. \"I found the diversity to be very impressive.\" When asked about advice for future participants, Games says, \"Choose something that you are less \nfamiliar with. You'll get more out of the activity as a learning experience than you will if you're an expert \nand you're on that path.\" A Chance to Learn The challenge provided many learning opportunities. \"I think the most important thing I learned from the challenge was how to have a group come up with \nand implement a timely solution,\" Maffia says. \"Finding a solution to a problem and then designing and 'Approved for Public Release; Distribution Unlimited. Case Number 17-3370'. assembling the product with only an hour and a half per week was a challenge.\" \"The design process takes a lot of patience,\" Scaplen says. \"Everything doesn't come out perfect the first \ntime. It took a lot of rethinking and remodeling to get everything to fit together and function properly.\" \"The most important thing I learned from this challenge was to have an open mind and value every \nteammate's ideas,\" Downs says. The 3D printing challenge, a pilot effort, met all of its objectives, according to challenge co-creator Jaffke. \"It was amazing to see all the hard work of the interns come to fruition,\" Jaffke says, noting that \nfeedback verified the project's success. \"The interns said that they liked networking with staff from \nmultiple departments and utilizing different skills by working in cross-functional teams.\" by Kathie Felix Visit Student Programs and our campus recruiting events pages to learn more about MITRE's internship \nopportunities. The Teams and Their Projects\nTeam 1: 3D-printed mechanical \"hand,\" paired \nwith a glove with sensors Team 2: ADS-B antenna, earth/ground-based \ncomponent Team 3: Phone hologram projector\nTeam 4: ADS-B antenna, floating airborne \ncomponent (challenge winner) Team 5: The Slouch Potato posture-monitoring \nsystem Team 6: The Dronenut drone application, a \nfloating platform for sea-based deliveries Team 7: Hold the Phone, a bracelet/wristband \nthat holds headphones to prevent tangles when not in use https://www.mitre.org/careers/student-programs\nhttps://www.mitre.org/careers/student-programs/campus-events _top\n _GoBack ",
    "text": " 'Approved for Public Release; Distribution Unlimited. Case Number 17-4389' Students Tackle Missile Defense and More (a Student Voices article) Have you ever analyzed space-based infrared systems and defense systems? Identified early warning \nsigns of political or social unrest around the world? Used spectral clustering to reroute air traffic? \nEmployed cognitive assistance techniques to attract co-op candidates? MITRE interns have. Several of them showcased their research at a student-focused event during the \nsummer of 2017a highlight for the students and full-time employees alike. Improving Space-Based Infrared Systems Joshua Christ, a senior majoring in computer science with an emphasis on cybersecurity at California \nState Fullerton, worked on a project that analyzed space-based infrared systems and early warning \nmissile defense systems. His work supported MITREs efforts to improve our nations ability to detect and \ndefend against incoming attacks. Part of that solution involved converting current documents to visual representations and aggregating \nthem into one constructive diagram. The simpler visualization makes them easier to track at one time. \"We want to establish a good understanding of the system we're working with, Christ said during the \nevent. And then we want to move on and create good baseline behavior and detection capabilities as \nwell as improve the resiliency of the system. The end goal is to better identify the attack surface and \nreduce some of the vectors of attack that bad actors or attackers could use to compromise the system \nwe're working with.\" Recognizing Early Warning Indicators of Global Unrest Lindsey Lozoskie, a sophomore at the Hume Center for National Security at Virginia Tech, and Sophie \nFaaborg-Andersen, a senior at the School of Foreign Service at Georgetown University, analyzed data \nlooking for non-traditional early-warning indicators of political or social unrest around the world. The team worked with senior MITRE staff to develop a cross-disciplinary warning framework, integrating \nfinancial, economic, political, and social data. The project outlined how data analysis of such indicators as \noil prices, economic policies, investments, and media campaigns could be used to better anticipate \nconflict or instability in a country or region. Improving Air Traffic Flows via Enhanced Spectral Clustering These days, theres increased demand for access to airspace, especially with the addition of commercial \nspace operators. The need for methods to rapidly and accurately assess the impact of blocking the \nairspaceas well as finding ways to quickly reroute air trafficis more important than ever. Nate Vollbrecht, a junior at the University of Michigan, developed a method, using a spectral clustering \nalgorithm, to accurately assess heavily blocked traffic routes and quickly come up with alternative \nroutings. Using techniques such as dynamic time warping and variable cluster sizing, he improved the \naccuracy of the modeling. https://www.mitre.org/careers/student-programs/co-ops-interns 'Approved for Public Release; Distribution Unlimited. Case Number 17-4389' Using Cognitive Assistance to Connect Students to MITRE How do you effectively direct students to MITRE for co-op opportunities? Job fairs are great, but what do \nyou do if the person staffing the booth is busy? Are there ways to engage a student after the fair is over? \nAnd are there leave-behinds to help potential co-op candidates understand whether MITRE is right for \nthem? Three of our co-ops spent the summer developing a solution. The teamPietari Sulkava, a senior at \nRochester Institute of Technology, majoring in computer science; Paul Galatic, a junior majoring in \ncomputer science at the Rochester Institute of Technology; and Ian Gross, a graduate student in \ncomputer science at Rensselaer Polytechnic Institutethought cognitive assistance could help. Using IBM Bluemix and Watson and back-end discovery cognitive tools, the three developed programs \nthat allow students to have conversations about MITRE and what it offers using ChatBot Client, the NAO \ninteractive robot, or the Amazon Echo Show interface. The Amazon Echo Show, for example, allowed the student to discuss MITRE by saying \"Alexa, start a \nconversation with MITRE.\" Students could also scan in a resume. The goal of the devices was to make co-op candidates learn whether the MITRE environment would be a \ngood fit for them before stepping onto the campus or a MITRE site. by Tom Nutile If these or any of our many intern opportunities interest you, check out our current Job Openings or read \nmore about our Student Programs. https://www.mitre.org/careers/job-openings/\nhttps://www.mitre.org/careers/student-programs/student-voices 'Approved for Public Release; Distribution Unlimited. Case Number 17-4389' Paul Galatic explains how his team developed ways to connect students to MITRE for \nco-op opportunities using cognitive assistance. (Photo by Michael Baker) http://info.mitre.org/people/app/person/26277#Phonebook _GoBack\n _top\n _Hlk497220109\n _Hlk497220467\n _Hlk497220677\n _GoBack\n _Hlk497220846\n _Hlk496613984\n _GoBack ",
    "text": " Approved for Public Release; Distribution Unlimited. Case Number 17-4579 Systems Visioneeringa New Class for MITRE Interns (a Student Voices article) MITRE doesn't just hire students for the skills they have. We also hire them for ones they can learn. Like most interns, MITRE's summer hires usually spend their days working with our engineers in the field \non projects, doing research, and gaining real-world skills. But for the first time this year, our interns also \nhad the opportunity to enroll in a course at the MITRE Instituteour in-house education, training, and \ndevelopment centerdesigned specifically for them. Geared Toward College Students The class kicked off on July 25, with a small but enthusiastic group of students who joined Steve Scott, a \nMITRE multi-discipline systems engineer and veteran MITRE Institute instructor. Scott worked with the \nInstitute's Lara Van Nostrand to adapt material from two of his courses into one three-hour intern class \non \"Systems Visioneering Techniques\" and \"Survey Design for Systems Engineering.\" \"'Systems visioneering' is a phrase we coined here at MITRE,\" Scott says. \"We use it as an umbrella term \nfor various types of interactive and collaborative problem-solving techniques that you apply at the front \nend of the systems engineering process.\" He designed the systems visioneering portion of the class to help students think about how to develop a \nshared understanding of a problem using collaborative and interactive brainstorming methods. \"I \nintroduced the students to collaborative methods derived from Gray, Brown, and Macanufo's book, \nGameStorming,\" Scott says. \"Then they worked as teams to develop innovative solutions to a specified \nproblem.\" The survey design portion of the class illustrated the process of designing a survey, including determining \nthe information need, instrument design, questionnaire design and wording biases, survey field \noperations, and data post-processing and presentation. Students then developed a short survey to \ndetermine attitudes and perceptions of a target population for a question of interest. Techniques Applied to a Real-World Problem Scott wanted the interns to use what they learned on an issue they could relate to. So he asked them to \nconsider the problem of the high cost of college tuition and ways to address it. The class used systems \nvisioneering to look at developing innovative ways to reduce tuition costs. The survey design activities \nfocused on examining how the various stakeholders in the college ecosystem would be affected by \nproposed solutions. \"They came up with a good mix of ideas,\" Scott says. \"They had some interesting spins on funding and \nhow students could be a part of the solution. It's a problem that affects them directly, and they used \nmany of the techniques from the class to help define the problem and find ways to address it.\" The class earned high praise from the interns. \"I feel like I absorbed more information at this class than I \nnormally do at college. I'll be using what I learned here in future group work, both professionally and \nacademically,\" says Austin Downing, an industrial and systems engineering major from Virginia Tech. Jenny Wu, a computer science major from the University of Virginia, found the class \"to be very helpful \nand was time well spent.\" https://www.mitre.org/careers/working-at-mitre/professional-development\nhttps://www.mitre.org/careers/working-at-mitre/employee-voices/a-career-on-key\nhttps://kde.mitre.org/mapping-world-class-capabilities-to-the-healthcare-domain/\nhttps://kde.mitre.org/mapping-world-class-capabilities-to-the-healthcare-domain/\nhttps://kde.mitre.org/mapping-world-class-capabilities-to-the-healthcare-domain/\nhttps://kde.mitre.org/managing-knowledge-through-systems-visioneering/\nhttps://kde.mitre.org/managing-knowledge-through-systems-visioneering/ Approved for Public Release; Distribution Unlimited. Case Number 17-4579 Avri Parker, a computer science major from the University of Southern California, said the class gave her \nvaluable insight into engineering as a career. \"I thought the systems visioneering class was really \ninteresting. I didn't know what exactly systems engineering was as a field and what systems engineers do \nat MITRE, so it was very helpful.\" Dev Das, a computer science major from the University of Virginia, felt he benefited from the small-\ngroup learning environment. \"I really enjoyed the small setting of the systems visioneering class, where \neach of the students could talk with one another or with the instructor. It made things easy to \nunderstand if you needed help. I also liked the amount of collaborative work we did.\" Scott says he's glad the MITRE Institute reached out to him about adapting the class for the summer \ninterns. \"I really appreciated the students' inputs and participation. They brought an interesting \nperspective to the conversation, and I loved having the opportunity to work with them.\" Visit our Student Programs and campus recruiting events pages to learn more about MITRE's internship \nopportunities. by Kay M. Upham https://www.mitre.org/careers/student-programs\nhttps://www.mitre.org/careers/student-programs/campus-events _top\n _GoBack\n _Hlk499813338\n _Hlk499813346\n _Hlk499813355\n _Hlk499813361 ",
    "text": " Schnitzer and Levin Page 1 of 8\nThe Hope and Challenge of Synthetic Biology December 12, 2017 *MITRE Approved for Public Release; Distribution Unlimited. Case Number 17-4670\n1 http://www.motherjones.com/media/2013/05/robots-artificial-intelligence-jobs-automation/ The Hope and Challenge of Synthetic Biology* By Jay J. Schnitzer and Peter L. Levin December 2017 By far the most important information known to mankind the human genome \nis stored in trillions of containers, inside billions of mobile agents, and dynamically \nrefreshed millions of times per year. Not every update is perfect, and miniscule \ndeviations can be healthy or self-destructive. But there are so inconceivably many \ncopies that, taken in aggregate, new versions eventually break ground along a \nmeandering path that began four thousand millennia ago. Evolution is indifferent \nto and unencumbered by quarterly reports to an owner; that class of \nexperimental freedom has created the best innovation of all: life itself. Nature organized this chemical database into forty-six (twenty-three paired) units \ncalled chromosomes, each written in a deceptively simple four-letter alphabet. \nOur molecular-scale understanding of the story told in three billion cuneiforms of \nnucleic acid is only seventy years old, eyeblink short on the time scale it took to \ncreate its letter-by-letter assembly. Yet we can already connect some metabolic-\nsignal pathways to their genetic grammar. Until the last century we hardly knew this information existed. Fifty years ago we \nbegan to attach radioactive isotopes to small segments of chromosomes to see \nwhere they landed after mitosis. Today we have machines that allow us to actively \nread-and-write genes by the base-pair, almost like a modern word processor or \nsoftware development environment. In other words, human-made hardware is now capable of changing the somatic \nsoftware that runs us, like a computer autonomously downloading new apps it \nfinds interesting, or willfully changing its operating system. Germline modification \n the ability to permanently change DNA that is transmitted to offspring is \ncoming soon. It will be inexpensive, reliable, and generally available. To understand how fast these changes will occur, consider Kevin Drums1 \nanimation that starkly demonstrates acceleration at Moores Law speed of \nchange: doubling something every eighteen months. He pretended to fill Lake Schnitzer and Levin Page 2 of 8\nThe Hope and Challenge of Synthetic Biology December 12, 2017 2 https://www.technologyreview.com/s/427787/are-smart-phones-spreading-faster-than-any-technology-in-\nhuman-history/\n3 https://www.washingtonpost.com/news/speaking-of-science/wp/2017/11/29/cells-with-lab-made-dna-produce-\na-new-kind-of-protein-a-holy-grail-for-synthetic-biology/?utm_term=.ddef0ed220dc Michigan with water, starting with one fluid ounce, and then two fluid ounces a \nyear and a half later, and then four fluid ounces three years after he started. After \nseven decades one can barely detect the results of such make-believe. Yet in only \nfifteen more years, the lake is full. Put in astronomical context: a little more than a \ncentury ago we were in the pre-Kitty Hawk days of heavier-than-air flight; two \ngenerations later we took giant leaps on the moon. Illuminating biological pathways for mischief or profit will occur faster still. The fusion of biotechnology and information science is new and uncharted. For \nmost of history, information exchange, fake or not, depended upon physical \naccess, which became sequentially easier with broadcast radio, then broadcast \ntelevision, and most recently with the internet. The adoption of movable type for \nmechanical printing took almost exactly 400 years, from Bi Shengs invention to \nthe Gutenberg Bible. The iPhone moved mainstream adoption of smartphones \nfrom 5% to 40% a typical metric of comparison in about four years.2 None of these advances remotely exploit the taproot of all information, literally \nencoded in our DNA. We can already manipulate cell-level outcomes by blocking \ncertain functions that result in disease. Tomorrow we will change DNA itself to \nanthropogenically repair mutations that cause problems in the first place. The \nday after tomorrow we will manipulate molecularly bio-similar instructions \noutside of a living organism to produce new non-biological materials with \nproperties we have never seen before, like those reported in November 2017.3 A genetic program of (only) three billion instructions can create a human baby in \nnine months. Now the underlying technology that reads the code-script, \nspecifically the ribosomes (software developers would call these compilers) that \nassemble proteins one amino acid at a time, can be teleologically reverse \nengineered. Reflect, for example, on the power to genetically modify for strength, \nintellect, longevity, or control based on the current alphabet of 20 building blocks. \nImagine synthetically extending the keyboard to include hundreds, thousands, or \nhundreds of thousands of new letters new amino acids for biological and \nnon-biological applications. Truly we are at the incunabula stage the quiet Schnitzer and Levin Page 3 of 8\nThe Hope and Challenge of Synthetic Biology December 12, 2017 4 The Philadelphia Chromosome, by Jessica Wapner, published in 2013 by The Experiment, LLC interregnum between handwritten texts and mass-produced manuscripts in our \nability to print molecular components whose attributes we-ourselves define. The public health implications of genetic de-coding are breathtaking. Prophylactic \nvaccinations against communicable disease coupled to curative therapies for \ncancer, diabetes, and heart disease mean that many of us, particularly in the \ndeveloped world, will live longer, healthier, and physiologically safer lives. An \nindividuals opportunity for creative contribution, including especially our \ncollective scientific understanding, will grow exponentially. Few would want to turn the clock back to an age before anesthetics, x-rays, \npenicillin, or imatinib4. Fewer still can conceive the convergence of carbon-born \nethics to silicon-born judgment. Developed-world innovation in artificial \nintelligence and biochemistry will exacerbate inequality, because it is \ninstitutionally and infrastructurally farther up the acceleration curve. The emerging miracles of modern biotechnology and biotech-inspired materials \nscience conceal an existential threat to a fragile balance of international powers, \nand to our own national security. If not more thoughtfully debated on the global \nstage and controlled by multi-party agreement, our very existence is challenged \nby a single laboratory accident or ideologically-driven attack. There are now \npeople in the world who perform scientific experiments that can lead to morally \ndisturbing outcomes. There are now people in the world who aim to demolish the \nfoundational institutions of modern society by any means possible. New systems, \nespecially those that biomimick natural pathogens and cognitive synthesis, will far \nexceed our governments ability to control them. Riven enemies can too easily \nturn them against us and each other; ignorance and prejudice will fuel anger and \nviolence. Scientific breakthroughs in biochemistry and microbiology will be further \nadvanced by self-reinforcing capabilities of (irreversible) computer-aided \ndecisions. For all the benefits of artificial intelligence (AI) and machine learning \n(ML) and there are many the predictive power of these new technologies is \nimperfect, and their moral judgment and executive function is nonexistent. Dan Geer, In-Q-Tels chief information security officer, told us that, Our \nintervention in evolution is just more evolution, but at a faster clock rate. Schnitzer and Levin Page 4 of 8\nThe Hope and Challenge of Synthetic Biology December 12, 2017 5 https://www.newyorker.com/magazine/2017/04/03/ai-versus-md Changes that depend on random perturbations take geologic time, including time \nto test for side effects. Changes that people design may have just as many \nunforeseen consequences, but the equilibria they punctuate are of much shorter \nduration. In other words, machine learning means self-modifying algorithms; it is \nimpossible to ask them how they made their decisions, and their impact is quick \nand permanent. The problem, Geer explained, is that nations dont have \ngeological time-scales to cull for fitness of their machine learning stock. What if \nthe current generation of people becomes an experiment in evolution? Geoffrey Hinton has wisely observed5 that the algorithm can solve a case. It \ncannot build a case. In other words, AI and ML are great at deciphering the \nwhats, wheres, and hows all questions that are essentially answered by \nextremely sophisticated pattern recognition but they cannot begin to \nunderstand why, which is the core of the human experience. AI and ML can help \neven-experienced professionals avoid poor choices, and they can suggest data-\ndriven hypotheses. But correlation is not causality, and neither can yet replace \ncompassionate bedside manner, values-based judgement, or face-saving \ndiplomatic nuance. AI and ML will continue to make marvelous contributions to \ndiagnosis and classification, but they will not, in our opinion, and certainly not in \nthe near term, be able to accurately harvest social sentiment or connect \noutcomes to social values. Even in a data drenched world, data scientists are still unable to predict the \noutcomes of plebiscites or the weather. And no computer would have anticipated \nthe physical fatigue, psychological momentum, or miraculous catch that changed \nthe otherwise prevenient outcome of the final quarter of Super Bowl LI. AI and ML \nreveal patterns; they cannot ask the right questions, detect insincere answers to \nnational polls, or hypothesize Julian Edelmans hands. There are no silicon- (or \neven carbon-) based systems that can stop torture, stop ethnic cleansing, or \nbetter teach the irrefutable science of climate change. Today we are still untangling the engineering problem of cataloging proteomic \noutcomes to genetic codes, ribosomal assembly, and the restricted spectrum of \nnatural components. Soon we will be able to create an editable biochemical code, \nwith an expanded palette of man-made materials. Civil society must demand \npolitical leadership engage in open debate to determine if the outcomes are Schnitzer and Levin Page 5 of 8\nThe
Hope and Challenge of Synthetic Biology December 12, 2017 6 https://science2017.globalchange.gov/downloads/CSSR2017_PRINT_Executive_Summary.pdf\n7 https://www.foreignaffairs.com/articles/2016-09-05/automated-war desired or not, for whom, and why. On the one hand we need to agree and \nestablish in international law acceptable scientific methods, ethical norms, and \ncommercial standards; on the other hand, we need to recognize that some \ngovernments, and powerful individuals within those governments, will flout them \nanyway. There is no single agency in the US government, or any international body, that \nowns the bio threat. This leaves the US wide open to nefarious actors, just as it \nleaves the civilized world vulnerable to the malevolent, violent, and absent \nminded. The confluence of uncharted technical capability and poor prediction is \nespecially serious now, because for the first time we have the capability not only \nto destroy ourselves on a nuclear scale, we might accidentally change the \nstructure of our embedded software species-wide. The first experiments of so-\ncalled germline embryos occurred in China. They were well intended. Soon \nenough they will be successful, and fall into the hands of less altruistic \ncommunities. The consequences are even more tragic and destabilizing than a \nsuicide bomber who kills children (as incomprehensible as that is); genetic \nchanges are heritable, persistent, and may be impossible to undo. Sonal Shah, the executive director of the Beeck Center for Social Impact and \ninnovation at Georgetown University, said the convergence of AI with \nbiotechnology is one of the most important social consideration of our times, on \npar with global warming. This is an important point, because from the scientific \nperspective, the case of carbon dioxide loading is well decided.6 General John R. \nAllen, who commanded coalition forces in Afghanistan, told us that the \nDepartment of Defense is investing in technologies that lower our carbon \nfootprint and obviate climate change. We know how to model the security \nimplications of increasing temperatures, he said, but the ethical considerations \nof autonomous systems deciding who to kill in a robot war are new and \nundecided. LaPoint and Levin made a similar point last year in these pages.7 There are plenty of examples of our collective inability to cooperate when the \nphysical evidence is clear, for instance in contaminated water, depleted fishstock \nand inexorably rising tides. The existential threat of AI-driven biotechnology is \nabstract to most people, including highly educated policymakers of every color, Schnitzer and Levin Page 6 of 8\nThe Hope and Challenge of Synthetic Biology December 12, 2017 8 Peter L. Levin is a member of the board of this non-profit, non-partisan foundation. creed, culture, and continent. But knowhow, like the atmosphere, neither \nconforms to nor respects international borders. There are five decisions to make. First and foremost, we will implicitly choose whether or not to address these \ndiscussions openly, transparently, authentically, and democratically. We have \nalready ceded a years-long head start to our friends, rivals, and enemies, primarily \nbecause of restrictions on stem-cell research. They are making dramatic progress \nin artificial intelligence and bio-engineering. So, first, we need to decide to decide. Second, assuming a more pro-active and deliberate process, the US government \nneeds to dramatically increase funding into the overlapping disciplines of bio-\nengineering and machine learning. There are, of course, undeniable benefits to \nan ageing society with a paucity of primary-care physicians. Superior pattern-\nmatching capabilities and front-line decision support to human clinicians will \nimprove quality, lower costs, extend resources, and change lives for the better. \nPedro Domingos of the University of Washington expects that AI will help screen \ndrugs for toxicity much faster than human trials. He said, We know that some \nmedicines may be poison to most people, but can save the lives of a small group \nof patients; we can use machine learning to safely reach those who will benefit. The most dire need for focused research is in the area of dementia and \nAlzheimers. George Vradenburg, founder of the non-profit USAgainstAlzheimers8 \nestimates that the global cost to support Dementia victims already exceeds $1 \ntrillion, over 1% of global GDP, and is increasing at an accelerating rate. Ironically, \nnowhere is the need for advances in computer discovery more acute than human \ncognition and rational behavior. Third, we need to protect what we discover. We blithely live in the shoals of a \nrelentless tsunami of breached personal data. This is a gigantic mistake. Our \nprofligate attitude towards cybersecurity is going to migrate from personal \ninconvenience to economic intrusion, and from intrusion to physical incursion. We \nhave lit up a fog-shrouded runway for our competitors and adversaries to land on; \nthey will not need an invitation to take the next step. So much of societally \nbeneficial innovation was born in the United States from satellite navigation to \nsemiconductor design, and from advanced industrial materials to HIV therapies Schnitzer and Levin Page 7 of 8\nThe Hope and Challenge of Synthetic Biology December 12, 2017 9 The Master Algorithm, by Pedro Domingos, published in 2015 by Basic Books but we controlled, to a greater or lesser extent, when and how they were \ndeployed. At this point not only do our rivals have a jump, they have an \nasymmetric advantage because they can see what we are, and are not, doing. Fourth, the United States needs to be keenly aware of the research and \ndevelopment efforts of other countries. Some intelligence gathering will \ninevitably fall on the shoulders of clandestine operations. Some requires more \nstructured and pro-active engagement with globally-minded scientists from other \nnations, where academic collaboration and technical trust trump selfish \ncommercial impulses (or clumsy friends) that may have detrimental or what we \ntoday perceive as detrimental effects on national security and economic \ncompetitiveness. Finally, the most difficult question of all: how much should we share? The \nconvergence of scientific discovery (based on advances in the creation and \nconstruction of bio-mimicking processes), technological capability (based on \nadvances in AI and ML), and ethical judgment (based on verifiable truthful and \nfact-based information) can lead to a richer, more peaceful world, or to horrible \nconflagration. There will be tremendous commercial advantage to the companies, \nand the nation-states that host or sponsor them, who master the science and \ntechnology of the 21st century. Left to their own devices, their human values and \npolitical goals will inevitably permeate not just consumer choice, but seats of \ngovernment. Clearly there is a case for thoughtful dialog, for investment, for \nprotection, and for nourishing communities of aligned and common interests. Domingos9 wrote, The real story of automation is not what it replaces but what it \nenables. Technologies that touch the genome shift the ethical, commercial, and \nglobal security paradigm in ways that are unprecedented in human history. \nHowever, unless and until we honestly, scientifically, and transparently approach \nthe governance of our new-found powers, we need not fear cyborg domination \nany time soon, no, just the people who control them. Jay J. Schnitzer is Vice President and Chief Technology Officer of the MITRE \nCorporation, a not-for-profit company that operates multiple federally funded \nresearch and development centers. The author's affiliation with The MITRE Schnitzer and Levin Page 8 of 8\nThe Hope and Challenge of Synthetic Biology December 12, 2017 Corporation is provided for identification purposes only, and is not intended to \nconvey or imply MITRE's concurrence with, or support for, the positions, opinions, \nor viewpoints expressed by the author. Peter L. Levin is a Non-Resident Fellow at the Beeck Center for Social Innovation \nand Impact at Georgetown University, and the CEO of Amida Technology \nSolutions. _top\n _GoBack ",
    "text": " Electromagnetically Induced Transparency (EIT) and Autler-Townes (AT) splitting in the Presence of Band-Limited White Gaussian Noise Matthew T. Simons, Marcus D. Kautz, and Christopher L. Holloway National Institute of Standards and Technology (NIST), Boulder, CO 80305, USA David A. Anderson\nRydberg Technologies, LLC, Ann Arbor, MI 48104, USA Georg Raithel\nRydberg Technologies, LLC, Ann Arbor, MI 48104, USA and Department of Physics, University of Michigan, Ann Arbor, MI 48109, USA Daniel Stack\nThe MITRE Corporation, Princeton, NJ 08540, USA Marc C. St. John and Wansheng Su\nThe MITRE Corporation, McLean, VA 22102, USA (Dated: December 18, 2017) We investigate the effect of band-limited white Gaussian noise (BLWGN) on electromagneti- cally induced transparency (EIT) and Autler-Townes (AT) splitting, when performing atom-based continuous-wave (CW) radio-frequency (RF) electric (E) field strength measurements with Rydberg atoms in an atomic vapor. This EIT/AT-based E-field measurement approach is currently being investigated by several groups around the world as a means to develop a new SI traceable RF E- field measurement technique. For this to be a useful technique, it is important to understand the influence of BLWGN. We perform EIT/AT based E-field experiments with BLWGN centered on the RF transition frequency and for the BLWGN blue-shifted and red-shifted relative to the RF transi- tion frequency. The EIT signal can be severely distorted for certain noise conditions (band-width, center-frequency, and noise power), hence altering the ability to measure a CW RF E-field strength. We present a model to predict the changes in the EIT signal in the presence of noise. This model includes AC Stark shifts and on resonance transitions associated with the noise source. The results of this model are compared to the experimental data and we find very good agreement between the two. I. INTRODUCTION Significant progress has been made in the develop- ment of a novel Rydberg-atom spectroscopic approach for radio-frequency (RF) electric (E) field strength mea- surements [111]. This approach utilizes the phenomena of electromagnetically induced transparency (EIT) and Autler-Townes (AT) splitting [13, 12], and can lead to a direct International System of Units (SI) traceable, self- calibrated measurement. For the method to be accepted by National Metrology Institutes as a new international standard for E-field measurements and calibrations, var- ious aspects of the measurement approach must be in- vestigated. One key issue is the ability of this EIT/AT- base technique to measure an RF E-field in the presence of noise. Here, we perform experiments measuring RF E-field strengths in the presence of band-limited white Gaussian noise (BLWGN). Publication of the U.S. government, not subject to U.S. copy- right. Approved for Public Release; Distribution Unlimited. Case Number 17-4520. c RIGHTS RESERVED.\n holloway@boulder.nist.gov The measurement approach used to measure the RF E- field strength when no noise is present can be explained by the schematic and the four-level atomic system shown in Figs. 1 and 2(a). (Note that when noise is present, the six-level atomic system shown in Fig. 2(b) is required, which is explained below.) A probe laser is used to probe the response of the ground-state transition of the atoms, and a second laser (coupling laser) is used to ex- cite the atoms to a Rydberg state. In the presence of the coupling laser, a destructive quantum interference occurs and the atoms become transparent to the resonant probe laser. This is the concept of EIT, in which a transparency window is opened for the probe laser light: probe light transmission is increased. The coupling laser wavelength is chosen such that the atom is in a sufficiently high state (a Rydberg state) such that a radio frequency (RF) field coherently couples two Rydberg states (levels 3 and 4 in Fig. 2(a)). The RF field in the four-level atomic system causes constructive interference of excitation pathways within the EIT transmission window, resulting in a de- creased transmission of the probe laser and AT splitting of the EIT peak. A typical measured spectrum for an RF source with different power levels is shown in Fig. 3. This figure shows the measured EIT signal for a range of 2 FIG. 1. Illustration of the vapor cell setup for measuring EIT, with counter-propagating probe and coupling beams. The RF is applied transverse to the optical beam propagation in the vapor cell. (a) (b) FIG. 2. Illustration of the atomic systems describing the mea- surement: (a) a four-level system when no noise is present and (b) a six-level system when noise is present. Coherent transi- tions are indicated by and noise induced transitions and\nshifts are indicated by !. E-field strengths (more details on these results are given below). In this figure, c is the detuning of the coupling laser (where c = c o; o is the on-resonance angu-\nlar frequency of the Rydberg state transition and c is the angular frequency of the coupling laser). Notice that the AT splitting increases with increasing applied E-field strength. Here, we explore how such measurements are affected by noise-induced transitions and level shifts in- troduced by BLWGN. Under the absence of BLWGN, the AT splitting (de- fined as 2fo) of the coupling laser spectrum is easily measured and under certain conditions is equal to the Rabi frequency of the RF transition [13], AT splitting = RF = 2fo , (1) where RF = |E|/~ is the Rabi frequency of the RF\ntransition, ~ is Plancks constant, and is the dipole\nmoment of the atomic RF transition. This relationship between the AT splitting and the Rabi frequency is ob- tained in the weak probe limit and for no Doppler av- eraging. By measuring this splitting (fm) we get a direct measurement of the RF E-field strength. In this approach, either the probe or the coupling laser can be scanned or detuned. For either case, the E-field strength is given by [2, 3], |E| = 2\n~\n\nDfm = 2 ~\n f0 , (2) where fm is the measured splitting, fo = Dfm, FIG. 3. Experimental data for the EIT signal obtained with- out noise. The figure shows the probe laser transmission through the cell as a function of coupling laser detuning c\nand for different RF E-field strengths. This dataset is for a RF of 19.7825 GHz and corresponds to the following 85Rb 4-level atomic system: 5S1/2-5P3/2-57S1/2-57P1/2. and D is a parameter whose value depends on which of the two lasers is scanned during the measurement. If the probe laser is scanned, D =\np\nc , where p and c are the wavelengths of the probe and coupling laser, respectively. This ratio is needed to account for the Doppler mismatch of the probe and coupling lasers [12]. If the coupling laser is scanned, it is not required to correct for the Doppler mismatch, and D = 1. This type of measurement of the E-field strength is considered a direct SI-traceable, self- calibrated measurement because it is directly related to Plancks constant (which will become an SI-defined quan- tity by standards bodies in the near future), the atomic dipole moment (a parameter which can be calculated very accurately [2, 14]), and only requires a relative opti- cal frequency measurement fm, which can be measured very accurately. To investigate how the EIT signals shown in Fig. 3 are influenced by the presence of BLWGN, and in turn the ability to measure an E-field strength, we perform exper- iments with four BLWGN sources: (1) BLWGN with a center frequency above the frequency of the coherently driven transition (blue-shifted BLWGN), (2) BLWGN centered about the RF transition frequency, (3) BLWGN with a center frequency below the RF transition fre- quency (red-shifted BLWGN), and (4) BLWGN with a notch around the RF transition (i.e., there is a noise band above and below the RF transition resonant frequency, but no noise at the RF transition frequency). We present a model to predict the observed behavior of the EIT sig- 3 nal in the presence of BLWGN, and show excellent agree- ment between experimental and model results. II. EXPERIMENTAL SETUP AND NOISE SOURCE A photo of the experimental setup and a block diagram of the noise source are shown in Fig. 4. The atom-based measurements are done using a 10 10 75 mm rect-\nangular vapor cell filled with 85Rb, two lasers (a probe and a coupling laser), a photo-detector, and a lock-in amplifier. A diagram of the laser orientations in the va- por cell is shown in Fig. 1. The levels |1, |2, |3, and\n|4 in Fig. 2(a) correspond respectively to the 85Rb 5S1/2\nground state, 5P3/2 excited state, and two Rydberg states 57S1/2 and 57P1/2. The probe is a 780.24 nm laser fo- cused inside the cell to a full-width at half maximum (FWHM) of 270 m, and has a power of 4.1 W. To pro- duce an EIT signal, we applied a counter-propagating coupling laser (which is overlapped with the probe laser) tuned to 479.9285 nm to couple the 5P3/2 and 57S1/2\nstates, with a FWHM of 353 m and power of 43.3 mW. A 19.7825 GHz E-field is applied via a Narda 638 stan- dard gain horn antenna (mentioning this product does
not imply an endorsement, but serves to clarify the an- tenna used) to couple the Rydberg states 57S1/257P1/2.\nWe modulated the coupling laser amplitude with a 50/50 duty-cycle 30 kHz square wave and detected the resulting modulated probe transmission with a lock-in amplifier to obtain an amplified EIT signal. A power combiner is connected to the input of the horn antenna to combine the noise signal and the continuous- wave (CW) 19.7825 GHz signal from a signal generator (SG), such that both noise and CW signals can be inci- dent on the vapor cell simultaneously. The horn antenna is placed 34.2 cm from the center of the two overlapped laser beams inside the vapor cell. The noise signal is generated by connecting a 50 resistor to a series of amplifiers, as shown in Fig. 4(b). The resistor is connected in series to two power amplifier (PA) with a gain of 26 dB, and a low low-noise amplifier (LNA) with a gain of 27 dB. The output of the LNA is sent to a band-pass filter (which was changed to the different bands during the experiment). The output of the filter was then fed into a third PA with 30 dB gain. The output of the third amplifier was connected to the power combiner shown in Fig. 4(a). To exhibit the importance of the detailed noise spec- trum on the EIT signal, several different bandpass filters are used to band-limit the noise signal. In these experi- ments we used three different filters, each with a band- width of 1 GHz, with different center frequencies as\nfollows: Filter 1 20.7 GHz (blue-shifted BLWGN), Fil-\nter 2 19.7 GHz (on-resonance BLWGN), and Filter 3\n 18.7 GHz (red-shifted BLWGN). Fig. 5 shows the noise\npower spectral density (dP/dv) of the band-pass filters, measured with a spectrum analyzer connected to the out- (a) photo of experimental setup (b) block diagram FIG. 4. Experimental setup for E-field measurements using EIT: a) photo of the setup and (b) block diagram of the noise source setup. RF absorber (blue pyramidal cones in the photo) is used to reduce RF reflections from the table and optical components. put of the power combiner (i.e., the input to the horn an- tenna). Using a power meter, we measured the integrated noise power (total power over the filter bandwidth) for each filter, measured at the output of the power combiner that feeds the horn antenna. The integrated power was 5.4 dBm for Filter 1, 6.0 dBm for Filter 2, and 6.6 dBm for Filter 3. The average noise power was intentionally set to be approximately the same for all three filters. The fourth type of BLWGN was created by combining Filters 1 and 3 (Filter 1/3 noise bands above and be- low the transition frequency, with a notch on resonance). Using a power splitter, the power output from the LNA was split, with one channel sent through Filter 1 and the other through Filter 3. These two channels were then recombined with a power combiner, and sent to the last PA. This configuration results in a noise spectrum span- ning 18.2 GHz to 21.2 GHz, with a notch from 19.2- to-20.2 GHz. The integrated noise power for Filter 1/3 was 4.95 dBm. In this configuration we added additional attenuation to ensure the integrated noise power was ap- proximately the same as for the measurements with a single filter. III. NOISE EFFECTS ON E-FIELD MEASUREMENTS In the experiments we measured the transmitted probe laser power with a photo-detector, as the coupling laser frequency was swept, for a set of CW RF power levels of 4 FIG. 5. Measured noise power spectral density (dP/dv) for the three filters used in the experiments. These data is mea- sured with a spectrum analyzer at the output of the power combiner that feeds the horn antenna. On this plot, we have indicated the CW source frequency. the coherent RF source. The CW RF power was varied by the SG, which was fed to the horn antenna through a cable. The measured coherent input power to the horn antenna ranged from 0 mW to 2.4 mW (including loss in the cable). By taking into account the gain of the antenna (G 15.7 dB at 19.78 GHz) and the distance\nfrom the antenna to the lasers (x = 0.342 m), the E-field strengths seen by the atoms are estimated by [15] |E| =\nAsw x \nc 0 2 PSG 10\nG\n10 , (3) where c is the speed of light in vacuo, 0 is the perme- ability of free-space, and PSG is the power level at the input to the horn antenna in units of Watts. There is an additional parameter Asw which is called the E-field en- hancement factor and is a correction factor of the E-field due to a standing wave formed inside the vapor cell [16]. Following the method in [4], we measured the field versus position in the vapor cell (see Fig. 6) and compared these with the far-field calculation. At the position inside the cell where the measurements were performed we found an E-field enhancement factor of Asw = 1.73. This gave a range of E-field strengths at the location of the laser beam crossing from 0 V/m to 11.6 V/m. Fig. 3 shows the measured EIT signal for this range of RF E-field strengths. Throughout the paper, the data in Fig. 3 will be referred to as CW RF data because they corresponds to an EIT signal with only a CW RF field at 19.7825 GHz (i.e., no noise present). These data will be compared to the EIT signal in the presence of various noise profiles. We placed a reference line at the RF-free 479.9285 nm Rydberg resonance (i.e., c = 0) and two additional reference lines on either side. These two additional lines indicate the linear trend that the AT-splitting would follow if the splitting remained linear FIG. 6. Measured E-field as a function of position in vapor cell, where 0 = edge of cell closest to the horn. The line shows a far-field calculation of the E-field at the cell. All data in the subsequential figures was taken at the point indicated by the red diamond. with the E-field strength. We see that for larger E-field strengths the EIT signal begins to deviate from linear behavior, with more deviation for the peaks on the c < 0 side of the EIT spectrum. This deviation is mainly due to an AC Stark shift, caused by the coherent RF signal for high applied E-field strengths [10]. When comparing the EIT signals with and without the RF source, we see that the linewidth of the EIT signals in Fig. 3 has some broadening. This broadening is due to the inhomogeneity of the E-field inside the vapor cell [11]. Adding BLWGN to the RF applied through the horn antenna (via the power combiner) distorts the EIT signal shown in Fig. 3. The amount of distortion is a strong function of both the frequency band of the noise (which bandpass filter is used) and the amount of noise power. Figs. 7-10 show the measured EIT signal for Filters 1, 2, 3 and the combined Filter 1/3, respectively. In these figures, the plots on the left-hand-side of each figure [i.e., (a), (b), and (c)] correspond to the experimental data and the plot on the right-hand-side [i.e., (d), (e), and (f)] correspond to results from a theoretical model (the model is discussed in the next section). The experimental data and theoretical data are shown side-by-side for ease of comparison later. The plots in these figures correspond to the indicated levels of attenuation of the noise sources (i.e., attenuators placed on the noise signal before feeding the horn antenna). All the plots in these figures have the c = 0 reference line for easier comparisons to Fig. 3. It is interesting to note the noise sources either red-shift or blue-shift the EIT signal. Filter 1 blue-shifts the EIT signal, whereas Filter 2 and Filter 3 red-shift the EIT signal. All the frequency shifts increase with increasing noise level. The combination Filter 1/3 blue-shifts the EIT signals. The effects of the Filter 1/3 combination are dominated by the contribution from the noise power spectrum in Filter 1. We also see that for high noise 5 power levels (i.e., 0 dB attenuation), the noise generated by either Filter 1 or Filter 2 dramatically suppresses the EIT signal. This amount of suppression is not observed for the high-noise power case when Filter 3 is used. Fig. 11 shows the measured E-fields obtained from the EIT signals from all three noise filters (i.e., the re- sults in Fig. 7-9) using eq. (2). In these calculations we use = 1120ea0 (where e is the elementary charge; a0 = 0.529177 10\n10 m and is the Bohr radius). This dipole moment for the resonant RF transition is com- posed of a radial part of 3360ea0 and an angular part of 1/3. The black line is a far-field calculation of the expected E-field strength
(taking into account the Asw\nenhancement factor) and agrees with the measured E- field for the CW RF no-noise case. Adding noise causes an increase in the measured E-field, by an amount that depends on the frequency band of the noise, the noise power, and the strength of the CW field under test. For most noise conditions, the measured E-field strengths with noise are larger by some amount when compared to the no-noise case. The highest noise levels (i.e., 0 dB) with Filters 1 and 2 does show a dramatic increase in the AT-splitting and the apparent E-field strength. In actuality, the E-field strength of the coherent signal in the vapor cell has not increased at all. It is only the AT- splitting that has increased due to the noise. This point is further explained by the model presented in the next section. To better illustrate the effect of the noise, Fig. 12 shows the percent difference of the apparent E-field obtained using eq. (2) from the no-noise case versus the coherent- signal-to-noise-power ratio (CSNR). The CSNR is calcu- lated using the CW RF power and the integrated noise power at the input to the horn antenna. We see that above a CSNR of 1, the percent difference approaches zero. Below a CSNR of 1 the effect on the E-field mea- surement strongly depends on the frequency band of the noise. When the noise is red-shifted compared to the RF transition frequency (i.e., Filter 3), the noise primarily broadens the EIT signal, and has less effect on shift- ing the EIT peaks compared to other filters. This will be shown and discussed in more detail in the next ses- sion. Thus, when the noise is red-shifted relative to the RF transition, it has a minimal effect on the ability to measure CW RF E-fields. Even with the strongest noise power (black squares in Fig. 12), the E-field measure- ment is only strongly affected below a CSNR of 0.2. The blue-shifted noise (i.e., Filter 1) has the strongest effect on the E-field measurements. In the Filter 1 case, the E- field measurements significantly differ from the CW RF below a CSNR of 1 and differ by 80% below a CSNR\nof 0.5. The influence of BLWGN on E-fields measure- ment for the on-resonance case (Filter 2) falls between the red-shifted and blue-shift cases (Filter 1 and Filter 3). The experimental results in Figs. 3 and 7-12 serve to illustrate the typical effects of BWLGN on Rydberg-EIT- AT spectra. The baseline measurement in Fig. 3 shows how a resonant, coherent microwave signal AT-splits and shifts Rydberg-EIT lines in the absence of any noise. The AT splitting in such spectra can be used to per- form an atom-based measurement of the electric field of the coherent microwave signal. Fig. 7-10 demonstrate that BWLGN added to the system can have a profound effect on the Rydberg-EIT-AT spectra. It is seen that the details of the spectral intensity distribution of the BWLGN give rise to a wide range of cases, as to how exactly the Rydberg-EIT-AT spectra change from the noise-free case. Figs. 11 and 12 then show, quantitatively, the BWLGN-induced errors in the atom-based measure- ment of the electric field of the coherent microwave sig- nal. These errors also strongly depend on the spectral intensity distribution of the BWLGN. IV. MODELING THE EFFECTS OF NOISE In order to understand how the various noise sources alter the measured EIT signals, we model these effects as follows. The effect of broadband noise on a Rydberg- atom system consists of two main contributions: (1) on- resonance transitions caused by the noise, and (2) AC Stark shift caused by the noise. The Rydberg atoms in levels |3 and |4 in Fig. 2(b), which are populated by\nthe coherent sources (lasers, coherent RF source), can transition into other Rydberg levels due to the frequency components of the noise spectrum that are resonant with transitions between Rydberg states. This process is akin to decays driven by blackbody radiation [17, 18]. The usual treatment (in which the radiation field is quan- tized and the transition rate is obtained from Fermis golden rule and summing over the possible field polar- izations and accessible final angular-momentum states) needs to be modified so that it applies to a noise field that has a well-defined polarization and propagation di- rection (given by the microwave horns geometry). Also, the black-body energy density of the field must be re- placed by the setup-specific noise characteristics. We as- sume that, at the location of the atoms, the noise has a spectral intensity (noise intensity per frequency interval, measured in W/(m2 Hz)) of I =\ndI d\n() . To conform with our typical measurement scenario (i.e., the noise is applied to the atoms via a RF horn antenna and the atoms are located in the far field of the horn), we quantize the field in one dimension only (the propagation direction of the noise field) and assume a fixed noise field polarization. For the transition rate, Rfi, from an initial state |i into a final state |f, we find Rfi =\ne2 20~2c\n|n f |r|i|2I(|fi|) , (4) where 0 is the permittivity of free-space, e is the elemen- tary charge, n is the field-polarization unit vector, and 6 (a) (d) (b) (e) (c) (f) FIG. 7. Experimental data (a) (c) and model results (d) (f) for Filter 1. The EIT signal is plotted as a function of coupling laser detuning c for different RF E-field strengths and different noise sources. This dataset is for a coherent resonant RF of 19.7825 GHz and corresponds to the following 85Rb 4-level atomic system, 5S1/2-5P3/2-57S1/2-57P1/2. (a)/(d) -12 dB attenuation, (b)/(e) -6 dB attenuation, (c)/(f) 0 dB attenuation. The squares on the plots shown in (d), (e), and (f) correspond to the peaks of the experimental EIT data shown in (a), (b), and (c). The dashed line at c = 0 is used as reference in order to guide the eye to show shifts from c = 0. 7 (a) (d) (b) (e) (c) (f) FIG. 8. Experimental data (a) (c) and model results (d) (f) for Filter 2. The squares on the plots shown in (d), (e), and (f) correspond to the peaks of the experimental EIT data shown in (a), (b), and (c). Additional details are the same as in Fig. 7. 8 (a) (d) (b) (e) (c) (f) FIG. 9. Experimental data (a) (c) and model results (d) (f) for Filter 3. The squares on the plots shown in (d), (e), and (f) correspond to the peaks of the experimental EIT data shown in (a), (b), and (c). Additional details are the same as in Fig. 7. 9 (a) (d) (b) (e) (c) (f) FIG. 10. Experimental data (a) (c) and model results (d) (f) for Filter combination 1/3. The squares on the plots shown in (d), (e), and (f) correspond to the peaks of the experimental EIT data shown in (a), (b), and (c). Additional details are the same as in Fig. 7. 10 FIG. 11. Calculated E-field strength from eq. (2) as a function input CW RF power to the antenna for various noise condi- tions (Filter #, integrated noise power). We use = 1120ea0\n(radial part of 3360ea0 and an angular part of 1/3.) FIG. 12. Percent difference between E-field measurements with added noise and measurements with no noise [based on eq. (2)], plotted vs. the coherent-signal-to-noise-power ratio (CSNR). fi is the transition frequency (i.e., (Ef Ei)/h, where\nEf and Ei are the energies of states |f and |i, respec-\ntively). These rates (Rfi) are in SI units and have the unit per atom and per second. For the given states of interest we calculate the rates, Rfi, for the known noise spectrum I(). Note Rif = Rfi. In the present case, the coherent microwave signal drives the transition between Rydberg states |3 and |4\nin Fig. 2(b). If the noise spectrum covers the transi- tion |3 and |4, it is included in the Master equation in\nthe form of two noise-induced bi-directional decay terms with equal rates, R34 = R43, and the corresponding de- cay rates for the coherences that involve levels |3 or |4, or both. For transitions |3 |f and |4 |f different from\nthe coherently driven |3 |4 transition, the noise\ndrives transitions at rates per atom of Rf3 = R3f and Rf4 = R4f . Note that the noise-populated levels |f\nhave no coherences between each other and with any of the levels |1 |4 in Fig. 2(b), because the noise-induced\ndrive has a random phase. Hence, all levels |f that be-\ncome populated from level |3, due to the noise, may be\nlumped into a fictive level |d (see Fig. 2(b)). Similarly,\nall levels |f that become populated from level |4, are\nlumped into a fictive level |e. Due to electric-dipole se-\nlection rules, there is no overlap between the levels in |d\n(which become populated by the noise from |3) and in\n|e (which become populated by the noise from |4). The\nnet rates into the fictive levels are Rd3 =\n f 6=3,4
Rf3 Re4 =\n f 6=3,4 Rf4 , (5) where Rd3 = R3d and Re4 = R4e. The master equation then includes equations for the level populations of the Rydberg states |3 and |4 and the fictive levels |d and\n|e 33 = (other terms) +Rd3(dd 33) dd = Rd3(dd 33) 44 = (other terms) +Re4(ee 44) ee = Re4(ee 44) . (6) The other terms are terms that are already explained in detail in [13]. From eqs. (4) and (5) it is seen that only transitions from the Rydberg states |3 or |4 into\nother levels, with transition frequencies that fall within the noise band, cause broadening of the Rydberg-EIT-AT lines. Note the master equation includes no equations for any coherences for the fictive levels (the coherences in- volving the fictive levels are always identical zero). The equations for the decay of coherences that involve lev- els |3 and/or |4 also need to be amended so that they\ninclude all R3d-, R3e- and R34-terms. The noise also induces AC shifts that are calculated based on the same field quantization model, and using second-order perturbation theory. The shifts of levels |i\n= |3 or |4 are found to be Ei =\n f 6=i [ e23fi|n f |r|i|\n2 hc0 max min I() 2(2 2fi)\nd ] . (7) The integration limits min and max are chosen wide enough that the entire noise spectrum is covered. Note that due to the 3fi term the signs of the transition fre- quencies are important (as expected). The AC shifts of levels |3 and |4 are added into the master equation [13]\nas noise-induced detuning terms. The AC shifts of other 11 Rydberg levels, included in the model in the form of the fictive levels |d and |e, are not important.\nComparing eqs. (4-7) it is seen that the AC shifts are harder to calculate than the decays. For the decays, only transitions with frequencies that lie within the noise band have effects and the noise spectral density is only required at these frequencies. Typically only a few sometimes even no Rydberg-Rydberg transitions involving levels |3 or |4 are within the noise band. In contrast, all\nallowed transitions involving levels |3 or |4, including\ntransitions with frequencies outside the noise band, are relevant in eq. (7). Also, for each transition an integral over the entire noise band needs to be evaluated. For transitions within the noise band some care needs to be taken because of the pole in eq. (7). For AC-shifting transitions with frequencies fi out- side the noise band, the directions of the AC shifts of the Rydberg levels |3 or |4 due to these transitions de-\npend on the line strengths, the signs, and the fi-values of the perturbing transitions in relation with the noise band (see eq. (7)). The perturbing levels are P -Rydberg states for level |3, and S- and D Rydberg states for\nlevel |4, respectively; the frequencies of the perturbing\ntransitions, fi, and their signs depend on the relevant quantum numbers and the quantum defects of the atom. For transitions that actually fall within the noise band, the integration range in eq. (7) includes the pole; in such cases the AC-shifts depend on the details of the inte- grand, including any details of the noise spectrum itself. The net AC shifts of the levels |3 and |4 then result\nfrom the sum over all AC shifts, summed over all per- turbing levels |f, as seen in eq. (7). The net AC shifts\ntherefore depend on the noise spectrum and the detailed energy level structure of the atomic species used. To evaluate Eqs. (4) and (7), one requires the noise spectral intensity function, I(). Using the free-space propagation equation given in eq. (3), I() is expressed as I() =\nA2sw x2\nc 0 2\nGL() dP d\n, (8) where x = 0.342 m (the distance from the horn antenna to the lasers) and GL() is the linear gain for the horn antenna. Using the manufacturers specification sheet, GL() is expressed as, GL() = 10\n(15+3([GHz]18)/8.5)/10 . (9) Note the frequency () is entered in GHz into this equa- tion. The parameter Asw is the correction factor that accounts for the standing-wave enhancement of the field inside the cell, and as discussed above, this is determined experimentally to be 1.73. The noise power spectral den- sity (dP\nd ) is given in Fig. 5 and is normalized such that it integrates to the power (in Watts) measured (using a power meter, values are given above) at the input to the horn antenna. The results for I() for Filters 1, 2, and 3 are shown in Fig. 13. These results are used in eqs. (4) and (7) to obtain the noise-induced decay rates and AC level shifts. These are then used in eqs. (5) and (6) and combined with standard equations for the four-level master equation [13] to yield the coherence 12 as a function of coupler-laser frequency. The AC Stark shift caused by the coherent RF source is also included in the calculations using the Floquet analysis given in Ref. [10]. The four-level master equation is also amended with the coherence-free fictive levels |d and |e that hold the net populations driven\nby the noise, out of the coherently coupled levels |3 and\n|4. The model EIT spectrum is then obtained by com- puting the Beers absorption coefficient in the medium as a function of coupler-laser detuning, (C), for the given cell temperature (see [13] for detail). This involves an integral over the Maxwell velocity distribution in the cell [13], because each velocity class has its own Doppler shifts of coupler and probe beams. The ratio of input and output probe powers is then given by exp(L), where\nthe cell length L = 75 mm. It is noted that, after us- ing all experimentally available input and the computed matrix elements for all noise-driven transitions, f |r|i,\nthere is no fit parameter left to adjust the model re- sults. Hence, absolute, fit-free agreement should be ex- pected when comparing measured and modeled spectra of the Rydberg-EIT-AT experiments under the influence of BLWGN. 17 18 19 20 21 22\n0 2 4 6 8 10 12 14 16 18 20 Band #3 Band #2 I \n [a rb\n. l in\nea r u\nni its\n] [GHz] Band #1 FIG. 13. Noise spectra I() derived from measurements, the geometry of the setup, and the horn manufacturers data on the horns gain dependence on frequency. In Figs. 7-10 we show results obtained from this model (the model results are shown in plots (d)-(f) in these fig- ures). As a comparison, in these plots we also show peak positions from the experimental data. The squares in the figures correspond to the peaks of the experimental EIT data shown on the left-hand-side of these figures. When compared to the experimental data, we see that the model predicts the same trends in the EIT signal in the presence of noise. In that, depending on the noise source, the noise either red-shifts or blue-shifts the EIT signal. Also, the modeled EIT signal tracks the loca- tion of the peaks as a function of RF very well, and when RF 0, the frequency offsets are very close. In\nthat, measured and calculated offsets are in the same directions from c = 0 and are usually within a cou- ple MHz from one another. A comparison between the 12 TABLE I. Comparison of frequency offset of EIT signal at RF = 0 for various noise filters and power levels. offset (MHz) offset (MHz) Experiments Model Filter 1 -12 dB +8 +5 -6 dB +21 +15 0 dB +56 +62 Filter 2 -12 dB -3 -3 -6 dB -8 -9 0 dB -30 -38 Filter 3 -12 dB -1 -2 -6 dB -4 -3 0 dB -13 -16 Filter 1/3 -12 dB +5 +2 -6 dB +13 +6 0 dB +35 +23 frequency offsets at RF = 0 obtained from the model and those obtained from the experimental data is shown in Table I (this is also indicated by the dashed lines in Figs. 7-9). The largest differences are for the high noise powers (i.e., 0 dB). This is mostly due to the fact that for high noise power, the measured EIT peaks are dimin- ished and are difficult to determine at times. As a further comparison, we compare the experimentally determined E-field strengths to those obtained from the model based on eq. (2). Fig. 14 shows the comparison for the three filters for the high noise powers. The results in this fig- ure show good agreement between the experimental data and the model. The model allows for further understanding on how BLWGN influences the AT-splitting. Fig. 15 shows the AT peaks in the EIT spectra obtained from the model. Shown here are the high-power noise (0 dB attenuation) cases for the three filters. It is interesting to note the AT peaks shift in filter-specific ways relative to the no-noise cases. For large values of RF , Filter 3 shows only slight shifts in the peaks relative to the no-noise case. This results in the small percentage error
shown in Figs. 11 and 14 for Filter 3. For large values of RF , the Fil- ter 2 causes both AT peaks to shift downward. While the results for Filter 3 show that one of the peaks shifts downward and one peak shifts upward relative to the no- noise case. The shift in opposite directions for Filter 1 is what causes large errors in the E-field measurements shown in Figs. 11 and 14 for Filter 1. V. CONCLUSIONS The effects of band-limited white Gaussian noise on EIT and AT splitting, when performing atom-based RF E-field strength measurements using Rydberg atomic va- por were investigated. BLWGN has the effect of shift- FIG. 14. Comparison of E-field strength obtained from ex- perimental data with those obtained from the model. The x-axis is the input CW RF power to the antenna. FIG. 15. Peaks of EIT spectra obtained from the model as a function of applied coherent-RF Rabi frequency (RF ). Shown here are the high-power noise (0 dB attenuation) cases for the three filters. ing (either red-shifted or blue-shifted) the peaks of the EIT lines depending on the noise conditions (band-width, center-frequency, and noise power). The BLWGN also has the effect of broadening the EIT lines. We present a model to predict these effects. The model incorpo- rates two contributions; (1) one including on resonance transitions between Rydberg states caused by the noise spectrum (analogous to decays driven by blackbody ra- diation) and (2) one including AC shifts caused by the noise source. The results of this model compare very well to the experimental data presented here. This indicates that these two contributions are required in a model in order to correctly predict the EIT signal in the presence of BLWGN. 13 The noise has the effect of modifying the EIT/AT sig- nal from that for the coherent RF field alone, which alters the ability to measure the E-field strength in the pres- ence of noise. The amount of deviation is a function of the noise parameters (band-width, center-frequency, and noise power). We show relative differences of measured E-field strengths for different CSNR, where we show the the relative difference increases for decreasing CSNR. The shifts and broadening of the EIT/AT signal caused by noise are dependent on the Rydberg states chosen for the experiment. With that said, for the Rydberg states used here, we can summarize that when the noise is red- shifted from the RF transition, it has a minimal effect on the ability to to measures CW RF E-fields. While the blue-shifted noise (i.e., Filter 1) has the strongest effect on the E-field measurements. Furthermore, besides understanding the effects of BLWGN on E-field strength measurements, there is a need to be able to detect various noise sources in gen- eral. In order to investigate if the EIT approach can be useful for detecting noise, we performed additional EIT experiments with various noise levels and at various tem- peratures (77 K to 400 K). This topic is addressed in [19]. 14 [1] C.L. Holloway, M.T. Simons, J.A. Gordon, P.F. Wil- son, C.M. Cooke, D.A. Anderson, and G. Raithel, IEEE Trans. on Electromagnetic Compat., 59(2), 717-728, 2017. [2] C.L. Holloway, J.A. Gordon, A. Schwarzkopf, D.A. An- derson, S.A. Miller, N. Thaicharoen, and G. Raithel, IEEE Trans. on Antenna and Propag., 62(12), 6169- 6182, 2014. [3] J.A. Sedlacek, A. Schwettmann, H. Kubler, R. Low, T. Pfau and J.P. Shaffer, Nature Phys., 8, 819, 2012. [4] C.L. Holloway, J.A. Gordon, A. Schwarzkopf, D.A. An- derson, S.A. Miller, N. Thaicharoen, and G. Raithel, Ap- plied Phys. Lett., 104, 244102-1-5, 2014. [5] J.A. Sedlacek, A. Schwettmann, H. Kubler, and J.P. Shaffer, Phys. Rev. Lett., 111, 063001, 2013. [6] H. Fan, S. Kumar, J. Sedlacek, H. Kubler, S. Karimkashi and J.P Shaffer, J. Phys. B: At. Mol. Opt. Phys., 48, 202001, 2015. [7] M. Tanasittikosol, J.D. Pritchard, D. Maxwell, A. Gau- guet, K.J. Weatherill, R.M. Potvliege and C.S. Adams, J. Phys B, 44,184020, 2011. [8] C.G. Wade, N. Sibalic, N.R. de Melo, J.M. Kondo, C.S. Adams, and K.J. Weatherill, Nature Photonics, 11, 40- 43, 2017. [9] H. Fan, S. Kumar, J. Sedlacek, H. Kubler, S. Karimkashi and J.P Shaffer, J. Phys. B: At. Mol. Opt. Phys., 48, 202001, 2015. [10] D.A. Anderson, S.A. Miller, G. Raithel, J.A. Gordon, M.L. Butler, and C.L. Holloway, Physical Review Applied, 5, 034003, 2016. [11] D.A. Anderson, S.A. Miller, A. Schwarzkopf, C.L. Hol- loway, J.A. Gordon, N. Thaicharoen, and G. Raithelet, Physical Review A, vol. 90, 043419, 2014. [12] A.K. Mohapatra, T.R. Jackson, and C.S. Adams, Phys. Rev. Lett., 98, 113003, 2007. [13] C.L. Holloway, M.T. Simons, J.A. Gordon, A. Dienstfrey, D.A. Anderson, and G. Raithel, J. of Applied Physics, 121, 233106-1-9, 2017. [14] M.T. Simons, J.A. Gordon, and C.L. Holloway, J. Appl. Phys., 102, 123103, 2016. [15] W.L. Stuzman and G.A. Thiele, Antenna Theory and Design, Second edition. John WIley & Sons, Inc, 1998. [16] H. Fan, S. Kumar, J. Sheng, J.P. Shaffer, C.L. Holloway and J.A. Gordon, Physical Review Applied, 4, 044015, Nov., 2015. [17] H.S. Friedrich, Theoretische Atomphysik. Springer Ver- lag, Berlin, 1990. [18] T.F. Gallagher, Rydberg Atoms. Cambridge University Press, New York, 1994. [19] D.A. Anderson, G. Raithel, M.T. Simons, M.D. Kautz, and C.L. Holloway, Appli. Phys. Lett., 2017. ",
    "text": " Approved for Public Release; Distribution Unlimited. Case Number 18-0058 Virginia Tech Students Get a Bird's Eye View of MITRE\nWhen you gather a flock of Hokies at a MITRE lab, the questions fly: \"Wow, there are definitely a few more levers in here than in a car,\" said one student as she took a seat in the cockpit simulator in the Center for Advanced Aviation System Development's Integration Demonstration and Experimentation for Aeronautics Lab. \"Are many employees former pilots or air traffic controllers?\" \"Do you worry about your technology getting into the wrong hands?\" asked one student during the autonomous robotics presentation. \"Whats the next big social event coming up?\" asked another. On August 15th and on January 9th, engineering students from Virginia Tech (whose school mascot is a bird called a Hokie) toured several labs at MITRE's McLean, Virginia campus. The students represented majors across different aspects of engineeringfrom data analytics to industrial and systems engineering, to computer engineering. Each rising senior met with a hiring manager, in between lab tours and presentations about the breadth and depth of MITRE's work. The studentsall DC metro area residentstook advantage of their time away from their college campuses to visit MITRE and get a head start on career opportunities ahead of graduation. The group learned about ongoing research and development in robotics, aviation safety, securing the Internet of Things, simulation experiments, and more. Putting MITRE on the Upcoming Graduates' Radar No matter how many questions the students asked, they got answersthanks to diverse participation across the company. In addition to R&D presentations, MITRE's DeAnthony Heart and Keith H. Miller gave a talk about NextUp, the companys early-career affinity group. They shared with the students the variety of career development opportunities (including mentoring) and social and community service options available at MITRE. \"These students will be considering full time employment in May 2018,\" says MITRE's Steve Roe, a Virginia Tech alumnusone of many at the company. \"Our goal is to put MITRE on their radar as they consider their career path post-graduation.\" In other words, as these students found, it's never too early to spread your wings and scope out the landscape of an exciting career. Are you a college student (from Virginia Tech or elsewhere) interested in taking your technical https://www.mitre.org/centers/center-for-advanced-aviation-system-development/who-we-are\nhttps://www.mitre.org/publications/project-stories/aviation-experimentation-moving-mitres-labs-to-the-cloud\nhttps://www.mitre.org/careers/student-programs/recent-graduates\nhttps://www.mitre.org/careers/student-programs/recent-graduates Approved for Public Release; Distribution Unlimited. Case Number 18-0058 knowledge to the next level? MITRE employed more than 400 interns last summer (19 from Virginia Tech) and is in the process of recruiting interns for next summer. Visit our Student Programs and Campus Events pages to learn more about MITRE's internship opportunities. by Karina Wright Note to Graphic Designer: new photos taken Jan. 9, 2018 http://r300resource.mitre.org/Photogalleries/McLean/2017/2018-1-9_Student_Intern_Recruiting/ Original photo used in August NC article Photo caption: Virginia Tech engineering students at the controls in the Center for Advanced Aviation \nSystem Development's cockpit simulator. https://www.mitre.org/careers/student-programs\nhttps://www.mitre.org/careers/student-programs/campus-events\nhttps://www.mitre.org/careers/student-programs/campus-events\nhttp://r300resource.mitre.org/Photogalleries/McLean/2017/2018-1-9_Student_Intern_Recruiting/ Approved for Public Release; Distribution Unlimited. Case Number 18-0058 Production note to graphic designer: More photos are available to choose from the August session: \nhttp://r300resource.mitre.org/Photogalleries/McLean/2017/2017-08-\n15_VA_Tech_Invitational_NC/content/2017-08-15_VA_Tech_Invitational-3441_large.html. http://r300resource.mitre.org/Photogalleries/McLean/2017/2017-08-15_VA_Tech_Invitational_NC/content/2017-08-15_VA_Tech_Invitational-3441_large.html\nhttp://r300resource.mitre.org/Photogalleries/McLean/2017/2017-08-15_VA_Tech_Invitational_NC/content/2017-08-15_VA_Tech_Invitational-3441_large.html _top\n _GoBack ",
    "text": " Pilot and Air Traffic Controller use\nof Interval Management during\nTerminal Metering Operations Randall S. Bone\nAndrew S. Mendolia January 2018 M T R 1 7 0 5 7 0 M I T R E T E C H N I C A L R E P O R T Sponsor: The Federal Aviation Administration Dept. No.: P123 Project No.: 0217RQ02-IM Outcome No.: 2 PBWP Reference: 2-3.D.1-1, Human Factors\nHuman-in-the-loop (HITL) Simulation of the IM-S Integrated Operation Simulation Results (Final Report) All rights reserved. Approved for public release. Distribution unlimited. Case No.: 17-4761 McLean, VA Approved By Robert C. Strain, P123 Date\nDepartment Head Elida C. Smith, H530 Date\nPortfolio Manager iii Abstract\nThis HITL simulation activity was designed to examine the integration of a relative spacing\nconcept (Interval Management [IM]) into a future absolute spacing terminal metering\nenvironment provided by Terminal Sequencing and Spacing (TSAS). Air traffic controllers and\nflight crews utilized current day automation capabilities with enhancements for terminal\nmetering and IM to test the integration for acceptability and necessary spacing awareness\ninformation. Both groups had different sets of spacing information that were examined across\nseveral traffic scenarios. The results indicate IM is compatible with terminal metering, but the\nappropriate controller and flight crew tools to support trust of IM should continue to be\nexamined. Concept and operational recommendations are made, including enhancements to\nIM-related displays. iv Executive Summary\nA human-in-the-loop simulation involving air traffic controller and flight crews was conducted\nto examine the integration of Interval Management (IM) into a time-based, terminal metering\nenvironment with Performance Based Navigation procedures. Time-based metering during\narrival operations is currently scheduled to the runway, but is only conducted in the en route\nenvironment. However, the Federal Aviation Administration (FAA) plans to deploy capabilities\nand procedures to extend time-based metering into the terminal environment by 2019 via\nTerminal Sequencing and Spacing (TSAS). IM introduces a new way for the controller to have\naircraft meet the terminal schedule, and the goal of the simulation was to test the integration\nof the concepts for acceptability and the necessary spacing awareness information. IM is a set of equipment capabilities and procedures for controllers and flight crews. Flight deck\ncapabilities are used to support a range of IM operations with a goal of managed inter-aircraft\nspacing. Ground tools can be used to support the set-up and monitoring of the IM operation. To\ninitiate IM, the controller issues an IM clearance with the appropriate information such as the\nAssigned Spacing Goal (ASG) and the lead aircraft identification. The flight crew enters that\ninformation into the flight deck IM equipment, which then provides speeds to fly to achieve\nand, if desired, maintain that ASG. Situation awareness information is also provided to assist\nthe flight crew in monitoring the progression of IM. The controller monitors the operation for\nspacing or separation issues and intervenes if any unusual spacing issues arise. Under normal\nconditions, the flight crew continues following the IM speeds and the controller continues\nmonitoring the operation until the aircraft reaches the planned termination point, where the\nspacing goal is met. At this point, the flight deck IM equipment removes the IM speed from the\ndisplays and IM is nominally terminated. IM improves spacing consistency and predictability by enabling flight crews to make more\nfrequent and efficient speed adjustments than are possible for a controller to provide using\nonly a ground-based metering capability and voice communications. Achieving a consistent,\nlow-variance spacing interval reduces the time interval between aircraft in a traffic flow, which\nallows each aircraft to be spaced closer to a given separation standard. This enables increased\narrival throughput and sector or facility capacity. During IM / relative spacing, the IM aircraft performs spacing adjustment relative to a lead\naircraft. In absolute spacing with TSAS, spacing adjustments are made with respect to crossing a\nspecific location at a designated time, independent of the lead aircraft (once the schedule is\nfrozen). When using the TSAS tools during terminal metering, the controller actively issues\nspeed instructions to aircraft to get them on schedule. During IM operations, flight crews fly\nspeeds generated by the flight deck equipment to achieve the ASG. While the IM aircraft is\nworking toward the ASG, it may not be clear to the controller how well the operation is\nprogressing or whether an aircraft will ultimately achieve the ASG and the underlying schedule.\nThe controller may also find the absolute spacing information provided by TSAS to be confusing\nfor IM operations. This could cause the controller to be concerned about the IM aircraft and\npotentially not trust or utilize IM, thereby reducing the expected benefits. v For flight crews, IM during terminal metering looks very similar to IM in other environments\nthat has been examined in past simulations. However, additional study of spacing awareness\ntools for IM in this new environment was deemed necessary to help validate the minimum\ndisplay requirements being defined by avionics standards organizations such as RTCA. Past\nwork has shown that certain features can support spacing awareness and others can cause\nconfusion. Additional work is necessary to finalize minimum requirements. Some past work has examined IM and TSAS integration. This HITL builds on it by: increasing the\npercentage of aircraft conducting IM, examining IM initiation in the terminal environment,\nintegrating the IM algorithm defined in RTCAs technical standards, and continued examination\nof flight deck and ground human information requirements. Nine air traffic controllers and 18 pilots conducted IM during terminal metering under different\nconditions: the independent variables of display information for the controller (a basic\nimplementation with IM clearance information and IM status information, the basic\nimplementation plus an IM status visual cue, or the basic implementation plus an IM status\nvisual cue and a spacing prediction) and pilot (a minimum implementation as specified in\nstandards or a minimum plus enhancements), and role of the controller (feeder or final) and\npilot. Controllers also experienced aircraft overtake conditions during IM that required an\nintervention, as well as conditions where aircraft were conducting IM prior to entering the\nterminal airspace. IM operations during terminal metering was found acceptable by controllers and flight crews. A\nvast majority of IM operations were initiated and only a few were suspended or terminated by\ncontrollers. The IM / relative spacing operation was very similar to the behavior of controllers\nwho transition from an absolute spacing operation to a relative spacing operation in the later\nstages of approach and landing during terminal metering operations. All aircraft spent a majority of their flying time on the Area Navigation (RNAV) arrivals.\nHowever, IM aircraft spent more time on the RNAV arrivals (which indicated less time being\nvectored) and had reduced spacing variance at the final approach fix when compared to non-IM\naircraft. IM and non-IM aircraft met the expected performance baselines and goals. Controller terminal metering tools did not appear to conflict with IM operations and several\nappeared to provide useful information for IM aircraft. The basic controller IM tool set was\nfound to be useful and helpful. The additional tools that were evaluated also appeared useful,\nthough no clear trends for benefits were found. For the flight crew displays, the basic IM tool\nset (based on published minimum requirements) was found acceptable on several measures.\nHowever, trends for the enhanced tool set indicate that additional features may be useful and\novercome issues if refined and implemented properly. Few to no comments were received\nabout a need for additional display features beyond the min or min+ tool sets. While IM appeared to work well in this environment, some level of discomfort in IM was\nobserved. Based on controller comments, this seemed to be related to not actively issuing\nspeeds to IM aircraft and thus not knowing what speeds would be flown and when. For flight\ncrews, the distrust seemed to be related uncertainty around the feasibility of the IM operation.\nRecommendations for addressing topics such as these are included in this report. Suggestions vi are also made for further work to understand and resolve additional issues. The results and\nrecommendations are intended to be used by the FAA and RTCA in developing IM operational,\nsafety, performance, and interface requirements. The results will also inform the FAAs\ndevelopment of ground requirements to enable IM operations in metering environments. vii Acknowledgments\nThis research was completed with funding from the Federal Aviation Administration (FAA) Next\nGeneration Air Transportation System (NextGen) Human Factors Division (ANG-C1) in support\nof the Aircraft Certification (AIR) and the Flight Standards Service (AFS). The authors thank the following people working for or supporting the FAA and National\nAeronautics and Space Administration (NASA): FAA ANG-C1 office (Regina Bolinger) and the FAA Technical Sponsors (Doug Arbuckle,\nUsmaan Javed, Cathy Swider, Paul VonHoene, and Don Walker) for their technical review\nand comment on the simulation design and final report, as well as the support to run this\nsimulation. Jeff Sparrow for his critical role in testing and reviewing scenarios, as well as controller\ntraining, which enabled smooth and successful data collection. Tim Funari for FAA AJV-7 support of the preparation and data collection activities. Wes Stoops for all his time spent testing and reviewing scenarios. All participants in the concept evaluation activities prior to the simulation, including key\nindividuals from National Air Traffic Controllers Association (NATCA) and the FAA. Kurt Swieringa of NASA for on-going discussions about flight deck IM displays. Bryan Barmore of NASA for on-going discussions about IM. The authors would like to thank the following individuals from The MITRE Corporation: The Aviation Integration Demonstration and Experimentation for Aeronautics (IDEA)\nLaboratory staff for their
development, integration, testing, and data collection / reduction\nefforts. o Key leads include Stuart Bowman, Dylan Drake, Alain Oswald, and Mitch Wynnyk. Bill Penhallegon for on-going discussions and his detailed review of the simulation\ndesign and final report. The pseudo-pilot volunteers for their time. Lesley Weitz for on-going discussions and her help in integrating and explaining the IM\nsample algorithm. Ian Levitt and the IMPAT Team for their inputs on ground system functionality. Suzette Porter for all her help with recruiting pilots and entering questionnaire data. Janet Harvey for her support in the final stages of the development of this document. Finally, we thank all the pilot and controller participants for their time and valuable feedback as\nwell as the airlines and unions that supported the participants. viii Table of Contents\n1 Introduction \n2 Background \n2.2 IM \n2.2.2 IM Benefits \n2.2.2.2 Other IM Benefits \n2.4 IM and Metering \n2.4.2 Past Research on IM and Terminal Metering with TSAS \n2.4.2.2 NASA ATD-1 Controller HITLs \n2.4.2.3 MITRE Concept Evaluation Activities \n2.5.1 ATC Topics \n2.5.1.2 IM Status Information on ATC Surveillance Displays \n2.5.1.3 IM Clearance Information on ATC Surveillance Displays \n2.5.1.4 ATC Research Needs \n2.5.2.1 Flight Deck Display Spacing Information \n2.5.2.1.2 NASA Research \n2.5.2.1.3 MITRE Research \n3 Method \n3.1.1 Flight Deck Workstation \n3.1.2 IM Sample Algorithm \n3.1.3 ATC Workstation \n3.1.3.2 TSAS Interface \n3.1.3.3 IM Interface \n3.1.3.3.2 Other IM Information on the STARS Display \n3.1.3.3.3 Slot Marker Color Change \n3.1.3.3.4 Controller Tool Sets for Evaluation \n3.1.5 Airspace \n3.1.6 Traffic \n3.3 IM Operations \n3.3.2 Communications \n3.4.1 Controller Training \n3.4.2 Pilot Training and Data collection \n3.6 Data Collection \n4.1 Analysis Method \n4.1.2 Objective Data \n4.1.3 Statistical Method and Results \nMin+ Tool Set as Compared to the Min Tool Set \n4.1.3.2 Hypothesis 2: Flight Crews will Comply with More IM Speeds with the Min+\nTool Set as Compared to the Min Tool Set \n4.1.3.3 Hypothesis 3: Flight Crews will Find the Min+ Tool Set More Acceptable than\nthe Min Tool Set \nCompared to Only the Basic \n4.2 Terminal Metering Only Operations (Baseline) \n4.3 Integrated Ground Operations \n4.4 IM Operations Conduct \n4.4.2 IM Suspensions \n4.4.3 Controller IM Terminations \n4.4.4 Flight Crew Reports of Unable \n4.4.5 IM Speeds and Flight Crew Actions \n4.4.5.2 Magnitude of IM speeds \n4.4.5.3 IM Speed Reversals \n4.4.5.4 IM Speed Increases \n4.4.5.5 Time Between IM Speed Changes and DTG \n4.4.5.6 Compliance with IM Speeds \n4.4.5.7 IM Speed Conformance Monitoring Advisory \n4.5.1 Schedule Conformance \n4.5.2 Aircraft Position as Related to Slot Markers \n4.5.2.2 Aircraft Time in Slot Markers \n4.5.2.3 Relative Slot Marker Deviation \n4.5.4 Maintenance of the ASG \n4.5.5 Events Below Separation Standard \n4.6.1 Traffic Spacing Awareness and Acceptability \n4.6.2 Workload \n4.6.3 Controller Acceptability Rating Scale \n4.7.1 Air Traffic Controllers \n4.8 Roles and Responsibilities \n4.9 Time on RNAV Arrival \n4.10 Communications \n4.11 En Route Initiation \n4.12 Simulation Assessment \n5.1 IM During Terminal Metering \n5.2 IM Conduct \n5.2.2 Flight Crew \n5.4 Displays \n5.4.2 Pilots \n5.6 IM Benefits \n6.1 IM During Terminal Metering General Acceptability \n6.2 Aircraft Spacing and Separation \n6.3 Displays \n6.3.2 Pilots \n6.5 Benefits \nAppendix A IM Validity and Feasibility Checks \nA.2 Feasibility Checks \nA.2.2 Independent Feasibility Checks \nB.1 Controller Baseline Post-Scenario Questionnaire \nB.5 Pilot Baseline Post-Scenario Questionnaire \nB.7 Pilot IM Post-Scenario Questionnaire \nC.1 Controller Post-Simulation Questionnaire \nC.3 Pilot Post-Simulation Questionnaire \nD.1 IM Operations Conduct \nD.2 IM Speeds and Flight Crew Actions \nD.3 Aircraft Spacing and Separation \nAppendix F Acronyms and Abbreviations \nFigure 2-1. Sample Graphical Depiction of Terminal Metering Operations \nFigure 2-2. Sample TSAS Prototype Tools \nFigure 2-3. Absolute (Top) and Relative (Bottom) Spacing Operations Utilization of Aircraft Spacing Error Distributions \nFigure 2-4. Various IAT SD Distributions Relative to the Separation Standard \nFigure 2-5. Spacing Distribution of Aircraft at the FAF with an En Route Metering Capability Alone (Blue Line) and an En Route Metering Capability with IM\n(Green Line) [Reprinted from Rognin et al., 2005] \n[Reprinted from Prevot et al., 2007] \nFigure 2-8. EUROCONTROL IM Controller Information [Reprinted from Aligne et al., 2003] \nFigure 2-9. MITRE IM Controller Data Block Information [Reprinted from Benson et al., 2011] \nFigure 2-10. MITRE IM Controller Data Block Information [Reprinted from Peterson et al., 2012] \nFigure 2-11. Center Controller Data Block Information from Callantine et al. (2013) [Reprinted from Callantine et al., 2013] \nFigure 2-12. TRACON Controller Data Block Information from Callantine et al. (2013) [Reprinted from Callantine et al., 2013] \nFigure 2-13. MITRE IM Window Controller Information [Reprinted from Benson et al., 2011] \nFigure 2-14. Navigation Display with IM Information from Hebraud, Hoffman, Papin et al. (2004) First Evaluation [Reprinted from Hebraud, Hoffman, Papin et al.,\n2004] \nal. (2004) Second Evaluation [Reprinted from Hebraud, Hoffman, Papin et\nal., 2004] \nEvaluation and Hebraud, Hoffman, Pene et al. (2004) [Reprinted from\nHebraud, Hoffman, Pene et al., 2004] \nOseguera-Lohr et al. (2002) [Reprinted from Baxley et al., 2014] \nFigure 2-19. PFD and Navigation Display with IM Features from Barmore et al. (2005) [Reprinted from Baxley et al., 2014 (Highlights Added)] \nFigure 2-20. PFD and Navigation Display with IM Features Implementation 1 from Murdoch et al. (2009) [Reprinted from Baxley et al., 2014] \nFigure 2-21. PFD and Navigation Display with IM Features Implementation 2 from Murdoch et al. (2009) [Reprinted from Baxley et al., 2014] \nal., 2013] \nfrom Baxley et al., 2013] \n2015] \nfrom Kibler et al., 2015] \n[Reprinted from Baxley et al., 2014] \n[Reprinted from Baxley et al., 2014] \nBaxley et al., 2014] \nBaxley et al., 2014] \nfrom Baxley et al., 2016] \nBaxley et al., 2016] \n(Left) and within 210 Seconds from ABP (Right) [Reprinted from Baxley et\nal., 2016] \nFigure 2-34. AGD with IM Features from Bone and Penhallegon (2006) \nFigure 2-35. CDTI Traffic Display with IM Features from Penhallegon et al. (2011) \nFigure 2-36. AGD with IM Features from Penhallegon et al. (2011) \nFigure 3-1. Flight Deck Simulator \nFigure 3-2. CDTI Traffic Display and AGD Locations \nFigure 3-3. Minimum Requirements for Feasibility Check and Progress Indicator \nFigure 3-4. Graphical Progress Indicator \nFigure 3-5. Graphical Progress Indicator Design / Behavior \nFigure 3-6. Speed Tape \nFigure 3-7. CDTI Traffic Display with IM Information Labeled \nFigure 3-8. AGD with IM Information Labeled \nFigure 3-9. CDTI Traffic Display and AGD During Awaiting Entry State \nFigure 3-10. CDTI Traffic Display and AGD During Evaluate State \nFigure 3-11. CDTI Traffic Display and AGD During Execute State \nFigure 3-12. CDTI Traffic Display and AGD During Execute StateIM Speed Conformance Monitoring Status Visual Advisory \nFigure 3-13. CDTI Traffic Display and AGD During Execute StateFeasibility Check Status Indication \nFigure 3-14. CDTI Traffic Display and AGD During Suspend State \nFigure 3-15. CDTI Traffic Display and AGD During Terminate State \nFigure 3-17. STARS Keyboard \nFigure 3-18. STARS-Like Display \nFigure 3-19. ATPA \nFigure 3-20. Prototype TSAS Features on STARS \nFigure 3-21. Prototype TSAS Timeline on STARS \nFigure 3-22. RNP RF Turn Traffic Geometry \nFigure 3-23. IM Clearance States and Transitions \nFigure 3-24. IM Clearance Window \nFigure 3-25. Prototype IM Features on STARS \nFigure 3-26. IM Information in Trail Aircraft Data Block \nFigure 3-27. IM Information in Trail Aircraft Data Block When Transitioning to a No Speed (NS) Solution \nFigure 3-28. IM Information in Lead Aircraft Data Block \nFigure 3-29. Pseudo-Pilot Interface (Simpilot) \nFigure 3-30. PHX Airport. \nFigure 3-31. PHX-Like Airspace Overview: Arrival Procedures and Controller Airspace \nFigure 3-32. Arrival Procedures \nFigure 3-33. Geometry Where RNAV Aircraft is Following RNP RF Turn Aircraft on the Same Arrival \nFigure 3-34. Traffic Pairing Geometries \nFigure 3-35. Sample IM Operations with the PTP and ABP Options \nFigure 4-1. 100-Point Agreement Scale \nFigure 4-2. 100-Point Agreement Scale Agreement Rating Breakdown \nFigure 4-3. Sample Summary Figure \nFigure 4-4. Symbols Used in the Summary Figures and Their Meaning \nFigure 4-5. Sample Box and Whisker Plot Defined \nFigure 4-6. Sample Heat Map \nFigure 4-7. Controller Responses to Post-Scenario Statements on the Baseline Condition without IM \nFigure 4-8. Controller Responses to the Bedford Workload Rating for the Baseline \nFigure 4-9. Controller Responses for Controller Acceptance Rating Scale for the Baseline \nFigure 4-10. Controller Ranking of Operations. Frequency by Category \nFigure 4-11. Controller Average Ranking of Operations Relative to One Another \nFigure 4-12. Controller Responses to IM is compatible with terminal metering operations \nFigure 4-13. IM Initiation Locations for Both Achieve-by IM Clearance Types \nFigure 4-14. IM Initiation Locations for Capture then Maintain IM Clearance Type \nFigure 4-15. Location of Controller Suspensions \nFigure 4-16. IM Termination Locations for Both Achieve-by IM Clearance Types \nFigure 4-17. IM Termination Locations for Capture then Maintain IM Clearance Type \nFigure 4-18. Average Rate of IM Speeds per Minute for (a) Achieve-by and (b) Maintain Stages \nFigure 4-19. Distribution of IM Speeds for Achieve-by Stage with FAF / YOKXO as ABP \nFigure 4-21. Distribution of IM Speeds for Maintain Stage \nFigure 4-22. Distribution of IM Speed Change Magnitude with (a) FAF / YOKXO as ABP and (b) Merge / DERVL as ABP \nFigure 4-23. IM Speed Reversal Locations for (a) the Min and (b) the Min+ Tool Sets \nFigure 4-24. IM Speed Reversal Locations for (a) Achieve-by and (b) Maintain Stages \nFigure 4-25. Scatterplot of Time Between IM Speeds and Distance to the PTP with FAF / YOKXO as ABP (Achieve-by Clearance Type) \nFigure 4-26. Scatterplot of Time between IM Speeds and Distance to the PTP with
Merge DERVL as ABP (Achieve-by then Maintain Clearance Type) \nFigure 4-27. Mean Duration of IM Speed Presentation Time as Related to Compliance \nFigure 4-28. IM Speed Conformance Monitoring Advisory Locations for the (a) Min Tool Set and (b) Min+ Tool Set \nFigure 4-29. IM Speed Conformance Monitoring Advisory Locations for the (a) Achieve- by and (b) Maintain Stages of the Achieve-by then Maintain Clearance Type \nFigure 4-30. Schedule Deviation at Constraint Points \nFigure 4-31. Aircraft Slot Marker Center Deviation in Mean Seconds for Feeder Controller Airspace \nFigure 4-32. Aircraft Slot Marker Center Deviation in Mean Seconds at Handoff from Feeder to Final Controller \nFigure 4-33. Aircraft Slot Marker Center Deviation in Mean Seconds for Final Controller Airspace \nFigure 4-34. Lead and Trail Position Relative to Slot Markers When the Lead Aircraft was Ahead of its Slot Marker Center (Feeder Airspace and Handoff) \nFigure 4-35. Lead and Trail Position Relative to Slot Markers When the Lead Aircraft was Ahead of its Slot Marker Center (Final Airspace, DERVL, and YOKXO) \nFigure 4-36. Lead and Trail Position Relative to Slot Markers When the Lead Aircraft was Behind its Slot Marker Center (Feeder Airspace and Handoff) \nFigure 4-37. Lead and Trail Aircraft Position Relative to Slot Markers When the Lead Aircraft was Behind its Slot Marker Center (Final Airspace, DERVL, and\nYOKXO) \nFigure 4-39. Spacing Error Distribution for IM Aircraft by IM Clearance Type and Non-IM at YOKXO \nFigure 4-40. Spacing Error Distribution for IM Aircraft at DERVL \nFigure 4-41. Spacing Error Distribution for IM Aircraft by IM Clearance Type at YOKXO \nFigure 4-42. Location Where an Aircraft was Below the Applicable Separation Standard \nFigure 4-43. Controller Responses to Post-Scenario Statement Given the appropriate training, IM during terminal metering is operationally acceptable \nFigure 4-44. Pilot Responses to Post-Scenario Statement Given the appropriate training, IM is operationally acceptable \nFigure 4-45. Summary of Controller and Pilot Responses on IM Desirability and Acceptability Statements \nacceptable \nspacing of the aircraft would remain outside my separation requirement \nwhen spacing / separation issues were developing for aircraft \nremain within tolerances to achieve and maintain the assigned spacing\ngoal \nStatements \nperforming IM \nperforming IM What percentage and above is reasonable? \nFigure 4-54. Pilot Responses to Did you ever try to out-guess the IM algorithm and the IM speeds? \nFigure 4-55. Pilot Responses to Did you choose not to fly an IM speed? \nFigure 4-56. Controller and Pilot Response Means to the Bedford Workload Rating \nFigure 4-57. Summary of Pilot Responses on Workload Statements \nFigure 4-58. Controller Response Means to Controller Acceptance Rating Scale \nFigure 4-59. Controller Responses to Post-Scenario Statement I had the necessary display elements for conducting IM operations \nFigure 4-60. Controller Responses to The terminal metering elements were helpful for the IM and non-IM aircraft \nFigure 4-61. Summary of Controller Responses on IM Display Element Statements \nFigure 4-62. Controller Responses to How did aircraft conducting IM during terminal metering effect your need to monitor traffic? \nFigure 4-63. Controller Responses to The necessary aircraft monitoring was acceptable \nFigure 4-64. Summary of Pilot Responses on Min Display Element Statements \nFigure 4-65. Summary of Pilot Responses on Min+ Display Element Statements \nFigure 4-66. Pilot Responses to Post-Scenario Statement I had the necessary display elements for conducting IM \nFigure 4-67. Pilot Responses to Did the combination of both the AGD and CDTI implementations include all the information necessary for you to conduct\nIM? \nconfusing or misleading? \ntotal percentage of time using each display \nFigure 4-71. Summary of Pilot Responses to Display Acceptability Statements \nStatements \nFigure 4-74. Controller and Pilot Responses to Did you have any issues during communications when the lead aircraft call sign was used? \nFigure 4-75. Controller Responses to Post-Scenario Statements on En Route Initiation \nFigure 4-76. Controller Responses to the Bedford Workload Rating for En Route Initiation \nFigure 4-77. Controller Responses for Controller Acceptance Rating Scale for En Route Initiation \nFigure 4-78. Summary of Controller and Pilot Responses on Simulation Assessment Statements \nFigure A-2. Feasibility Criteria When Greater than 30 NM / 7 Minutes from the ABP \nFigure A-3. Trail and Lead Aircraft Independent Feasibility Criteria Example \nFigure D-1. Slot Marker Deviation \nFigure E-1. Relative Slot Marker Deviation at Various Airspace Locations When Lead Aircraft was Ahead of its Slot Marker Center \nFigure E-2. Relative Slot Marker Deviation at Various Airspace Locations When Lead Aircraft was Behind its Slot Marker Center \nTable 2-1. Metering Capabilities and the Associated IAT SDs \nTable 2-2. NASA ATD-1 TSAS and IM Controller HITL Simulations \nTable 3-1. STARS IM Prototype Controller Input Commands \nTable 3-2. Summary of Displayed IM Information in the IM Clearance Window and Aircraft Data Blocks \nTable 3-3. Controller and Pilot Grouping and Daily Activities \nTable 3-4. Independent Variables \nTable 3-5. Flight Crew Independent Variable Exposure by Traffic File and Run \nTable 3-6. Controller Independent Variable Exposure by Day, Traffic File, and Run \nTable 3-7. Data Collection Day Details \nTable 4-1. List of Hypotheses and Statistical Tests \nTable 4-2. Mean Spacing Error in Seconds (SD) for Participant Flight Crews \nTable 4-3. Number of Planned and Analyzed Runs per Scenario Type \nTable 4-4. Aircraft Participants Across Scenarios Types \nTable 4-5. IM Initiation Sequence \nTable 4-6. Frequency of IM Operations by IM Initiation Location and IM Clearance Type \nTable 4-7. Frequency of IM Operations by Controller Tool Set and IM Clearance Type \nTable 4-8. Frequency of IM Initiations as a Percentage of the Sample \nTable 4-9. Frequency of IM Proposals Rejected \nTable 4-10. IM Initiation Delay in Mean Seconds (SD) \nTable 4-11. IM Initiation Location as a Percentage of the Sample \nTable 4-12. Frequency of IM Suspensions by Suspension Reason and Subsequent Action \nTable 4-13. Mean Time to Resume or Terminate in Seconds (SD) after IM Suspension \nTable 4-14. Percentage (and Frequency) of IM Terminations \nTable 4-15. Frequency of IM Termination Actions \nTable 4-16. Mean Time to Terminate after Initiation in Seconds (SD) \nTable 4-17. Frequencies for Reasons for Controller IM Termination \nTable 4-18. Frequencies and Reasons for Participant Flight Crew Reports of Unable IM \nTable 4-19. Total Frequency of IM Speeds \nTable 4-20. Average Number of IM Speeds (SD) \nTable 4-21. Average Rate of IM Speeds (SD) per Minute \nTable 4-22. Mean Speed Change Magnitude (SD) in Knots by Flight Crew Tool Set and Achieve-by then Maintain Stage \nTable 4-23. Percentage of Speed Reversals \nTable 4-24. Percentage of Speed Increases \nTable 4-25. Mean Time in Seconds (SD) Between IM Speeds \nTable 4-26. Percentage of IM Speed Compliance \nTable 4-27. Mean Duration (SD) of IM Speed Presentation Time (in Seconds) as Related to Compliance \nTable 4-28. Percentage of IM Speed Conformance Monitoring Advisories \nMOPS No Advisory Threshold (Should Not have been Triggered per DO-316\n[RTCA, 2015a]) \nMOPS No Advisory Threshold (Should have been Triggered per DO-316\n[RTCA, 2015a]) \nTable 4-32. Aircraft Slot Marker Center Deviation in Mean Seconds (SD) and NM (SD) \nTable 4-33. Percentage of Time Aircraft were in Slot Markers \nTable 4-34. Mean Spacing Error in Seconds (SD) at Two Points \nTable 4-35. Aircraft Role and Performance Baseline / Goal Achievement \nTable 4-36. Percentage of Time IM Aircraft were within 10 Seconds of the ASG (95% Performance Goal) During the Maintain Stage \nTable 4-37. Mean (SD) Controller Response to Post-Scenario Statement Given the appropriate training, IM during terminal metering is operationally\nacceptable for TRACON IM Initiation \nappropriate training, IM is operationally acceptable \nthat the spacing of the aircraft would remain outside my separation\nrequirement \ndetect when spacing / separation issues were developing for aircraft \nTable 4-42. Mean (SD) Controller Response to Post-Scenario Bedford Workload Rating Scale \nTable 4-43. Mean (SD) Controller Response to Post-Scenario Controller Acceptance Rating Scale \nTable 4-44. Mean (SD) Controller Response to Post-Scenario Statement I had the necessary display elements for conducting IM operations \nTable 4-45. Mean (SD) Pilot Response to Post-Scenario Statement I had the necessary display elements for conducting IM \nTable 4-46. Total Time in Seconds (SD) Aircraft were off the RNAV Path \nTable E-1. Lead and Trail Deviation in Mean Seconds (SD) Relative to Slot Markers When the Lead Aircraft was Ahead of its Slot Marker Center \nTable E-2. Lead and Trail Deviation in Mean NM (SD) Relative to Slot Markers When the Lead Aircraft was Ahead of its Slot Marker Center \nTable E-3. Lead and Trail Deviation in Mean Seconds (SD) Relative to Slot Markers When the Lead Aircraft was Behind its Slot Marker Center \nTable E-4. Lead and Trail Deviation in Mean NM (SD) Relative to Slot Markers When the Lead Aircraft was Behind its Slot Marker Center \nPrior to the introduction of any new operation into the National Airspace System (NAS),\nHuman-in-the-loop (HITL) simulations can be a tool used to reduce technical risk and answer\noperational and conceptual questions that go beyond expert judgment. These simulations can\nbe especially valuable if new concepts are being introduced that have not yet been examined\nfrom a perspective of integration with other systems. The Federal Aviation Administration (FAA) plans to deploy capabilities and procedures to\nextend time-based metering into the terminal environment by 2019 via Terminal Sequencing\nand Spacing (TSAS). This will extend metering operations from en route into the terminal /\nTerminal Radar Approach Control (TRACON) environment. In the
past, TRACON operations have\nbeen distance-based and tactical. Terminal metering introduces more structured arrival\nprocedures and time-based spacing. Terminal metering is being designed to solve the problems\nassociated with tactical control in the terminal airspace (e.g., increased time and distance\nflown, leading to increased fuel burn). It is intended to keep aircraft on optimized routes longer\nthan would otherwise be possible and to enable shorten traffic patterns. The FAA and industry are also developing flight deck requirements for a concept called IM, in\nwhich flight crews space relative to another aircraft based on an Air Traffic Control (ATC)\nclearance. This improves spacing consistency and predictability in both en route and terminal\nenvironments by enabling an aircraft to be spaced closer to a given separation standard. This\nincreases overall arrival throughput and capacity. Interval Management (IM) and TSAS have been examined in numerous simulations as\nindependent concepts. However, these concepts will need to function together in the future\nNAS environment. While some past work has examined integrated IM and TSAS operations, this\nHITL builds on that work by examining several remaining open questions. The simulation will\nexamine how controllers should use the two spacing methods (relative and absolute) to\nmanage arrival aircraft in the terminal. During IM / relative spacing, the IM aircraft performs\nspacing adjustments relative to the lead aircraft. In absolute spacing with TSAS, spacing\nadjustments are made with respect to crossing a specific location at a designated time,\nindependent of the lead aircraft (once the schedule is frozen). When using the TSAS tools\nduring terminal metering, the controller actively issues speed instructions to aircraft as\nnecessary to get them on schedule. During IM operations, flight crews fly speeds generated\nwithin the flight deck to achieve the Assigned Spacing Goal (ASG). The different spacing\nmethods and the impact on the controller and flight crew acceptability and information\nrequirements required further study. The document has six main sections, including this one. Section 2 Background introduces the\nterminal metering and IM concepts and provides a review of past literature. Section 3 \nMethods describes the simulation environment and how the simulation was conducted. Section\n4Results provides the results of the data collection. Section 5Discussion integrates the\nresults into an overall discussion of findings and conclusions. Section 6Recommendations\nsuggests how the results should be considered by conceptual and technical flight deck and\nground requirements development activities. 2-1 2 Background\nThe FAA expects to see continued traffic growth through 2030 with severe congestion at major\nairports such as HartsfieldJackson Atlanta International Airport (KATL), O'Hare International\nAirport (KORD), San Francisco International Airport (KSFO), and the New York City area airports\n(FAA, 2015). As part of the solution to address this growth, the FAA plans to implement\nNextGen enhancements such as Trajectory Based Operations (TBO) to manage future traffic\ndemands and to enable more efficient and environmentally-friendly navigation procedures\n(FAA, 2013). TBO operations utilize Performance Based Navigation (PBN) and time-based\nmetering to increase efficiency and predictability. PBN consists of stringent performance navigation requirements that enable accurate and\npredictable flight paths. PBN is used to achieve benefits such as optimally-placed routes (e.g.,\navoiding terrain) with reduced flight path length (FAA, 2016). Time-based metering manages\nflow rates of aircraft into constrained airspace by building a sequence and schedule with\nScheduled Times of Arrival (STAs) at specified points. Controllers provide instructions (often\nwith the help of automation) to aircraft to meet the schedule. PBN and time-based metering are used together to develop an optimized trajectory (negotiated\nbetween an airline and the FAA) that has accurate, predicted crossing times for specific points\nwhich leads to more efficient operations for each individual flight (e.g., fewer tactical\nmaneuvers and more time on optimized PBN routes), while predictably managing multiple\nflights in constrained airspace. In addition to PBN and time-based metering, new and advanced tools are necessary to enable\nTBO. Multiple concepts (e.g., relative spacing and absolute spacing) and capabilities (e.g., flight\ndeck and ground capabilities to support metering and data link) that are being developed\nsomewhat independently will need to work together. Additionally, different types of tools (e.g.,\ncontroller decision support tools, Required Time of Arrival [RTA] / Time of Arrival Control\n[TOAC], IM) will need to be utilized to meet the time-based schedule. Not all tools, however,\nachieve the schedule in the same way or with the same level of accuracy. The appropriate tool\nneeds to be chosen to meet the desired goal and benefit. 2.1 Metering and TSAS\nTime-based metering involves delivering aircraft at a specific point at a specific time. Time-\nbased metering is currently conducted in en route arrival operations with a system called Time\nBased Flow Management (TBFM). TBFM is used to synchronize multiple traffic flows and to\ndeliver aircraft to the TRACON boundary on schedule. Area Navigation (RNAV) route data is\nused to build four-dimensional trajectories to determine runway assignments, the overall traffic\nsequence, and STAs for individual aircraft at specified points (including points near the TRACON\nboundary). Information is presented to the en route controller to meet the sequence and\nschedule developed by TBFM. While a schedule is built to the runway, metering currently stops\nat the TRACON boundary. Once the aircraft are in the TRACON, TRACON controllers no longer\nhave the sequence and schedule information, so they must reevaluate the traffic situation and\nthen determine an appropriate sequence and schedule. TRACON controllers must maneuver 2-2 the aircraft without the sequence and schedule information, which can lead to inefficiencies.\nWhile delivering aircraft metered to the TRACON boundary can reduce fuel burn and increase\ntraffic capacity, further benefits can be realized if metering continues into the TRACON. Terminal metering is intended to solve the problems associated with tactical control in the\nterminal airspace (e.g., increased time and distance flown, leading to increased fuel burn). It is\nintended to keep aircraft on optimized routes longer than would otherwise be possible and to\nenable shorten traffic patterns such as those enabled by Required Navigation Performance\n(RNP) Radius-to-Fix (RF) turns. During terminal metering and while aircraft are still in the en route environment, Estimated\nTimes of Arrival (ETAs) are calculated by TBFM at the meter fix (where aircraft cross into\nterminal airspace), merge points, additional schedule constraints, and the runway threshold.\nETAs are used to create a schedule and sequence with STAs to the control points to satisfy\nminimum spacing and wake separation requirements (with an additional buffer). The sequence\nand schedule is frozen prior to the top-of-descent of the aircraft. Aircraft are sequenced and maneuvered in the en route environment such that only speeds\nshould be required for aircraft to meet the schedule and remain on the PBN procedure in\nTRACON airspace. En route controllers use TBFM to precondition and deliver aircraft to the\nTRACON within some error tolerance. TRACON controllers then work to the schedule by\nprimarily using speed instructions to resolve any schedule issues. Figure 2-1 shows a sample\nterminal metering operation. It shows multiple routes to the airport including some at the\nmerge. Arriving aircraft are shown with runway and sequence assignments. A table is also\nshown with STAs that aircraft are expected to meet at the various merge points. 2-3 Figure 2-1. Sample Graphical Depiction of Terminal Metering Operations Time-based terminal metering is enabled by TSAS. TSAS adds more sophisticated scheduling\ncomponents to TBFM and controller tools to Standard Terminal Automation Replacement\nSystem (STARS). On STARS, TSAS displays both scheduling and sequence information to the\ncontroller. TSAS also provides decision support tools to help the controller meet the schedule\nby getting aircraft to the appropriate points by the STA. Figure 2-2 shows a prototype set of the\nTSAS tools. Figure 2-2. Sample TSAS Prototype Tools Z 6\nAAL652\n090 24\n180 A26 21 220 Slot marker speed Slot marker Sequence number Runway assignment Aircraft IAS\nSpeed advisory or\nearly / late indicator 2-4 The tools shown in Figure 2-2 consist of the following: Runway assignment: Runway assigned to the aircraft by the scheduler Sequence number: Order of the aircraft arriving to the assigned runway Slot marker: Graphical representation of where the aircraft should be to be on schedule Slot marker speed: Indicated Air Speed (IAS), in knots, at which the slot marker is\nmoving Speed advisory or early / late indicator o Speed advisory: TBFM-calculated IAS, in knots, to get the aircraft to the next control\npoint on schedule o Early / late indicator: An E or L followed by the amount of time, in minutes:seconds,\nthe aircraft is early or late relative to the schedule (shown if a speed advisory will\nnot resolve the spacing issue) Aircraft IAS: Estimate of the aircrafts IAS, in knots, calculated by TBFM\nA timeline is also provided by TSAS that shows aircraft ETAs and STAs relative to a specified\nlocation that can be chosen by the controller. TSAS was initially developed by National Aeronautics and Space Administration (NASA) and\nexamined in numerous simulation activities (several of which are summarized in Robinson,\nThipphavong, and Johnson, 2015) TSAS was tech transferred to the FAA and is planned to be\nimplemented at select airports in 2019. 2.2 IM 2.2.1 IM Operational Overview\nIM is a set of equipment capabilities and procedures for controllers and the flight crew. Flight\ndeck capabilities are used to support a range of IM operations with a goal of managed inter-\naircraft spacing (e.g., achieve an interval on final approach) based on an ATC clearance. Ground\ntools can be used to support the set-up and monitoring of the IM operation. IM can be used in\nseveral environments (e.g., en route miles-in-trail and terminal metering operations),\ndepending on the operational objective and controller needs. ATC responsibilities, including\nseparation responsibilities, do not change. IM
is not designed to be implemented in all conditions, so controllers will use their knowledge,\nand automation support, as needed, to determine when IM operations should be conducted.\nATC will still be responsible for appropriately sequencing and spacing aircraft prior to the\ninitiation of IM. Such set-up can be conducted via current ATC capabilities or in more complex\nenvironments with new capabilities. Set-up involves ATC issuing an IM clearance that either\nuses speed adjustments alone, or a single turn and then speed adjustments. The IM clearance\nincludes information such as lead aircraft identification, IM clearance type (e.g., achieve-by 2-5 then-maintain), ASG units (i.e., time or distance) and value (e.g., 90 seconds and 15 miles), and\nIM special points (e.g., Achieve-By Point [ABP] and Planned Termination Point [PTP]). Once this information is provided to the flight crew, it is entered into the flight deck IM\nequipment. The equipment checks that the appropriate information has been entered for the\noperation and that the lead aircraft is in surveillance range. If the lead aircraft is not in\nsurveillance range, the system continues to search. Once the aircraft is in range, is on the\nexpected trajectory, and meets the necessary performance requirements, IM is initiated and\nthe equipment starts providing information (primarily the speed to fly, termed IM speed).\nSituation awareness information is also provided to assist the flight crew in monitoring the\nprogression of IM. With the presentation of each new IM speed, the flight crew ensures that the IM speed is\ncompatible with the aircrafts current configuration and environmental conditions. The flight\ncrew is expected to follow the IM speeds in a timely manner consistent with other cockpit\nduties unless other conditions (e.g., safety, operational, equipment, or regulatory issues)\nprevent doing so. If any of these issues arise, the flight crew will maintain their last\nimplemented IM speed and contact ATC to report being unable to conduct IM. Similarly, if ATC\nhas any conditions that prevent continued IM operations, the controller will contact the flight\ncrew and terminate or suspend IM. If the IM is suspended, the controller may choose to resume\nIM at a later point, should the appropriate conditions exist. If no issues arise for either the\ncontroller or the flight crew causing a suspension or termination, the flight crew continues\nfollowing the IM speeds and the controller continues monitoring the operation until the aircraft\nreaches the PTP. At this point, the flight deck IM equipment removes the IM speed from the\ndisplay and IM is terminated. For additional information on the broader IM concept and preliminary requirements, see DO-\n361 and DO-328A (RTCA, 2015a, 2015b). These documents describe near-term operations;\nhowever, updates are being developed to enable more advanced operational implementations\nsuch as dependent runway operations. For further details on the IM capabilities utilized in this\nsimulation, see Sections 3.1.1 and 3.1.2. 2.2.2 IM Benefits\nIM takes advantage of advances in technology to support current operations, and allows the\ncontroller to delegate the low-level, tactical spacing task to IM capable aircraft. Controllers\ncurrently try to achieve desired spacings by giving maneuver instructions to aircraft without the\nflight crews necessarily having an understanding of the goals. Instead of simply being able to\nassign a specific in-trail spacing goal, the controller has to provide several workload intensive\ninstructions which include trial-and-error to determine the appropriate goal. By allowing flight\ncrews to achieve or maintain an ASG, controllers may be able to more efficiently manage\nmerging aircraft and improve throughput. The remainder of this section will review the benefits\nmechanism and summarize related results from past IM activities. It will also highlight other\nexpected benefits. 2-6 2.2.2.1 Throughput Benefits\nIM is a relative spacing operation, in which trajectory corrections are made relative to real-time\nbehavior of a lead aircraft (i.e., the lead aircrafts ATA). This is in contrast to an absolute spacing\noperation, such as time-based metering, in which an aircraft is controlled to cross a specific\npoint at a designated time. IM is a tactical tool and the spacing objective can be based on an\nunderlying schedule, separation standard, or other operational need. In an absolute spacing operation, the error distribution of both aircraft must be considered\nwhen setting the schedule and spacing goals. This is because both aircraft achieve the schedule\nindependently and could contribute to a spacing that encroaches on the minimum separation\nstandard. With IM, however, the error distribution of the lead aircraft does not need to be\nconsidered because the IM Aircraft is correcting for it. Therefore, a spacing goal for an IM pair\ncan be closer than would otherwise be possible with absolute spacing alone (e.g., TOAC or\nterminal metering without IM). Figure 2-3 contrasts the error distributions that must be\naccounted for in absolute (top diagram) and relative (bottom diagram) spacing operations. Figure 2-3. Absolute (Top) and Relative (Bottom) Spacing Operations Utilization of Aircraft\nSpacing Error Distributions 2-7 With the spacing goal set, IM can further be used to improve spacing consistency and\npredictability by enabling flight crews to make more frequent and efficient speed adjustments\nthan are possible with ground-based metering and pilot-controller voice communications. This\nis because airborne equipment can provide more speeds than the ground to make trajectory\ncorrections. Also, since an aircraft will know its own trajectory more precisely than a ground\nsystem, the speeds will be generated using better information and will thus be more efficient.\nSetting, then achieving, a consistent, low-variance spacing interval reduces the time interval\nbetween aircraft in a traffic flow, which allows each aircraft to be spaced closer to a given\nseparation standard. This enables increased arrival throughput and sector or facility capacity. The performance metric used by the FAA to measure delivery benefits is termed Inter-Arrival\nTime (IAT). The IAT is defined as the difference in time when two consecutive aircraft cross a\ncommon point. For example, if a lead aircraft crosses the runway threshold at 12:30:30 and a\ntrail aircraft crosses the runway threshold at 12:31:50, the IAT is 80 seconds. A population of\nIATs will have a Standard Deviation (SD) associated with it, which indicates the extent of\nvariations in the IAT. Assuming a normal distribution, one SD will include 68% of the range of\nIATs in the population. Table 2-1 shows the assumed one IAT SD at the Final Approach Fix (FAF)\nused to model benefits for different traffic management capabilities. Table 2-1. Metering Capabilities and the Associated IAT SDs Capability IAT SD\nNo metering (baseline) 18.01 En route metering 16.52\nGIM-S and TSAS 12.03 IM 5.04 1. Singha and Haines (1975) 2. Spinoso, Coville, and Roberts (2014) 3. Weitz (2017) 4. DO-361 (RTCA, 2015a) Ground-based Interval Management-Spacing (GIM-S) Each added capability in the first column of Table 2-1 reduces the IAT variance, which means\nthat aircraft can be placed closer together relative to a separation standard (i.e., a lower\nspacing goal can be used), without an increase in the number of controller interventions\nneeded to avoid separation violations. 2-8 Figure 2-4 illustrates how IAT SD distributions relate to a separation standard. For example, if\nthe IAT SD is 12 seconds as with GIM-S and TSAS, aircraft will need to be spacing with an IAT of\napproximately 81 seconds to avoid an unacceptable number of controller interventions (as\nshown in the magenta distribution1). If a controller tries to space aircraft closer together and\nthe IAT SD is limited to 12 seconds, more controller interventions will be needed to prevent\nseparation violations. However, if the IAT SD can be reduced to 5 seconds with IM (as shown in\nthe red distribution), aircraft can be delivered at approximately 65 seconds with the same rate\nof controller interventions as the 12-second IAT SD distribution. Figure 2-4. Various IAT SD Distributions Relative to the Separation Standard [Reprinted from Weitz, 2017] 1 The 81-second value is derived assuming a uniform flow, a minimum (time-based) separation of 53 seconds at\nthe FAF, and a controller intervention rate of 1 per 100 operations. The 53-second minimum (time-based)\nseparation is derived from a minimum separation distance of 2.5 NM and an assumed groundspeed of 170 knots 0 20 40 60 80 100 120\n0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 IAT (seconds) P\nro ba\nbi lit\ny IAT SD = 5.0-sec IAT SD = 8.0-sec IAT SD = 10.0-sec Min\n(time-based) Spacing IAT SD = 12.0-sec 2-9 Rognin et al. (2005) demonstrated the benefit of accurate and low variance spacing when\ncomparing an en route metering capability only, to one with IM (i.e., all the aircraft were IM\ncapable). In the condition with IM, almost all aircraft were within 5 seconds of the ASG. The en\nroute metering capability alone had a wider and flatter distribution shown in Figure 2-5. The IM\ndistribution translated to an additional two aircraft per hour. Prevot et al (2007) found similar\nresults where IM (70% of the aircraft) had a reduced mean and variance and allowed for an\nadditional aircraft or two per hour (Figure 2-6). Figure 2-5. Spacing Distribution of Aircraft at the FAF with an En Route Metering Capability\nAlone (Blue Line) and an En Route Metering Capability with IM (Green Line) [Reprinted from Rognin et al., 2005] Figure 2-6. Spacing Error at the Runway without IM (Blue Line) and with IM (Red Line)\n[Reprinted from Prevot et al., 2007] 2-10 If IM helps deliver all aircraft with an IAT SD of 5 seconds versus 12 seconds (and the associated\nIAT of 65 seconds versus 80 seconds), an increase of approximately 11 aircraft per hour can be\nrealized. IM operations 100% of the time
may not be possible; however significant benefits are\nstill possible even with partial IM equipage. Figure 2-7 shows throughput increases at different\nlevels of IM equipage and the delivery of aircraft at the 5 second IAT SD, versus a ground\nsystem only (GIM-S and TSAS). As shown, the number of aircraft landing per hour increases as\nthe number of IM operations increases and throughput benefits are still realized at lower levels\nof equipage. Figure 2-7. Throughput Increase Relative to the IM Equipage / IM Operation Rate [Reprinted from Weitz, 2017] HITL simulations (e.g., Baxley et al., 2013; Swieringa, Wilson, and Shay, 2014; Kibler, Wilson,\nHubbs, and Smail, 2015) and field tests have shown the 5-second IAT SD to be possible. Lohr,\nOseguera-Lohr, Abbott, Capron, and Howell (2005) conducted a flight test where a 90 seconds\nIM ASG with RNAV procedures was achieved with an average of 89.3 seconds with a standard\ndeviation of 4.9 seconds. Penhallegon, Bone, and Stassen (2016a) reported a field test with a\nrelatively small number of aircraft conducting optimized RNAV routes where flight crews with\nhigh speed conformance were within +/- 6 seconds at the ABP and +/- 8 seconds of the ASG as\nthe lead aircraft touched down on the runway (after maintain operations). Swieringa et al.\n(2017) found similar behavior from a flight test where aircraft were within +/- 2 seconds of the\nASG at the PTP with SDs less than 3 seconds (after maintain operations on a RNAV Standard\nTerminal Arrival Route [STAR]). Achieve-by results from that flight test are still being examined. 0 10 20 30 40 50 60 70 80 90 100\n44 46 48 50 52 54 56 IM Equipage Rate (%) Th\nro ug\nhp ut\n (a c/\nhr ) 2-11 Past efforts have shown similar benefits. Grimaud, Hoffman, Rognin, and Zeghal (2003) found\nthat more aircraft were delivered closer to the targeted spacing interval in the extended\nterminal area with IM (42%) than without (17%). Additionally, fewer aircraft were delivered\nwith too small (or too large) spacing intervals. Overall, they reported a more homogeneous and\nstable flow at the delivery point with more aircraft achieving the targeted spacing value when\naircraft were conducting IM. 2.2.2.2 Other IM Benefits\nIM is also expected to reduce the number of controller interventions. Numerous studies have\nshown a reduction in controller interventions for similar concepts conducted in the en route\nand terminal areas (e.g., Grimaud, Hoffman, Rognin, Zeghal and Deransy, 2001; Grimaud et al.,\n2003; Aligne, Grimaud, Hoffman, Rognin, and Zeghal, 2003; and Mercer, Callatin, Lee, Prevot,\nand Palmer, 2005). A series of studies specifically examining IM in the en route and arrival\nenvironments (Bone, Penhallegon, Stassen, Simons, and DeSenti, 2007; Bone, Penhallegon, and\nStassen, 2008a; Bone, Penhallegon, and Stassen, 2008b; Penhallegon and Bone, 2008) reported\na reduction in controller instructions in IM scenarios (as compared to scenarios without IM)\neven with spacing disruptions and the introduction of other issues. Because IM is expected to reduce the number of controller interventions, a reduction in\nfrequency congestion is also expected to result. Grimaud et al. (2001) found a reduction in the\nnumber of communications when using IM, though not a reduction in the duration of the\ncommunications. In a flight test / demonstration, terminal controllers described a positive\neffect on communications with pilots (FAA, 2001). A study specifically examining IM in the en\nroute environment (Bone et al., 2007) reported both subjective and objective data indicating a\nreduction in controller-pilot communications. Controllers reported that their communications\nwere easy and were reduced with IM. Objective data revealed fewer ATC-initiated\ncommunications and less total time on the frequency during IM. Although communications\nduring IM operations were generally found to be acceptable, the IM clearance continues to be\nan area of concern due to the potential length and complexity of the communication. It will\ncontinue to be examined in this simulation. IM is expected to be particularly beneficial during optimized RNAV routes. Optimized RNAV\nroutes allow aircraft to maximize their individual efficiencies; however, this can come at the\nexpense of the efficiency of the overall stream. Past work has found that the vast majority of\npilots find optimized RNAV routes to be acceptable (Clarke et al., 2006). However, to avoid the\nlosing their benefits, optimized RNAV routes require no ATC interventions under nominal\nconditions. Appropriate spacing must be achieved in the en route environment so that terminal\ncontrollers are not required to intervene. Achieving the appropriate spacing can be challenging\ndue to uncertainty in the vertical trajectory and arrival time at the FAF (due to winds and\naircraft performance differences). Therefore, spacing at the start of the optimized RNAV route\nis greater than that realized today during high density operations (Erkelens, 2000; Ren, Clarke,\nand Ho, 2003). By having aircraft manage their own spacing with IM, aircraft conducting optimized RNAV\nroutes can effectively balance individual and stream efficiency, and operate in a manner 2-12 beneficial to the overall system. IM is used to set up the appropriate spacing at the entry to the\noptimized RNAV route and to achieve appropriate spacing on final approach by compensating\nfor uncertainties during the arrival. This should allow for an increased ability to conduct\noptimized RNAV routes due to consistent, accurate spacing and sustained capacity during\noptimized RNAV routes. Additionally, if it is possible through IM to achieve a consistent spacing\nat the entry to the optimized RNAV route and manage the spacing through the optimized RNAV\nroute, the entry spacing may be able to be reduced and the final spacing may be tighter than an\nunmanaged spacing without IM. A similar concept of the flight deck managed separation during optimized RNAV routes has\nbeen previously proposed (in t Veld, van Paassen, Mulder, and Clarke, 2003). In that work, it\nwas noted that the ATC task of spacing aircraft during an optimized RNAV route is difficult and\nthat tools such as IM could help. 2.3 PBN and RNP RF Turns\nRNAV is a method of navigation that increases efficiency by allowing aircraft to fly direct routes\nbetween selected points rather than flying from ground navigation aid to ground navigation aid.\nRNAV enables PBN operations that specify performance requirements for both RNAV and RNP\nroutes that enable accurate and predictable flight paths. PBN is used to achieve benefits such as\nensured deconfliction between defined routes, new routes that would not otherwise be\npossible due to terrain, lower approach minimums, closer routes, optimally placed route, and\nreduced flight path length. The benefits are enabled through the stringent, defined\nperformance requirements. PBN procedures and routes are already in place and are helping\nusers realize benefits (FAA, 2016). PBN RNAV has specified navigation performance standards. PBN RNP is a refinement of RNAV\nand also has specified navigation performance (in Nautical Miles [NMs]), but it requires on-\nboard performance monitoring and alerting. RNP allows for precise navigation on defined\nroutes. Advanced RNP procedures such as RNP Authorization Required (AR) approach\noperations are enabled by advanced navigation equipment and have stringent lateral\nnavigation requirements and can include a RNP RF turn (also known as RF leg). A RNP RF turn\nallows an aircraft to fly a precisely defined arc when transitioning from one leg to another\nthereby avoiding different turn paths when such a segment is not defined between the legs.\nRNP RF turns can be used with an instrument approach to reduce track mileage and aircraft can\njoin the final approach course as close as the FAF. RNP RF turns onto final approach can be\nchallenging for controllers but are expected to be supported by TSAS and will be part of arrival\nand approach procedures in the terminal metering environment (Wynnyk and Kopald, 2013). 2-13 2.4 IM and Metering\nRuigrok and Korn (2007) proposed how IM and metering could work together and be mutually\nbeneficial. They suggested using a ground based metering capability to smooth inbound flows\nand provide accurate spacing at a point like the initial approach fix where IM could be used to\nachieve further accuracy from the initial approach fix to the FAF. Callantine, Cabrall, Kupfer,\nOmar, and Prevot (2012) stated that terminal controller metering tools and IM are\ncomplementary and both can be utilized for the overall success of terminal metering\noperations. The strengths of each capability are used and the weaknesses of each are reduced.\nThe ground tool is used to sequence and merge aircraft (where absolute spacing is important)\nand the flight deck tool is used when relative spacing between aircraft becomes more\nimportant in the later stages of approach and landing. Previous simulations have shown that\ncontrollers using terminal metering make this switch from absolute spacing to relative spacing\nwhen aircraft are close to or on final approach and some have suggested using relative spacing\ntools on final (Callantine, Palmer, and Kupfer, 2010; Kupfer, Callantine, Martin, Mercer, and\nPalmer, 2011; Callantine et al., 2012). Wynnyk and Kopald (2013) stated that final controllers\nwere more focused on relative spacing / separation and that slot markers changed from a\nschedule objective to an on-going status indication of whether or not a merge was going to be\nsuccessful. The following section reviews relevant IM and metering HITL simulation activities. 2.4.1 Past Research on IM and En Route Metering\nBenson, Peterson, Orrell, and Penhallegon (2011) examined IM during en route metering. They\nexamined center controller acceptability of IM and different display implementations. They\nreported general controller acceptance of IM and all the tested interfaces. They also reported\nthat controllers found metering and IM compatible. Most controllers reported being\ncomfortable with flight crew monitoring for conformance and did not want an additional\nground tool. However, some said it may help situation
awareness. In a follow-on study, Peterson, Penhallegon, and Moertl (2012) also examined IM during en\nroute metering but with different levels of equipage and new controller display interfaces. They\nexamined center controller acceptability of IM procedures and requirements for ground\nautomation and reported general controller acceptance of IM and the interface. They also\nreported that controllers could acceptably manage a mix of IM and non-IM aircraft. Controllers\nalso found metering and IM to be compatible, though they reported some workload issues at\nhigher levels of IM equipage due to the communication requirements associated with issuing\nthe IM clearance and with managing off-nominal situations. Overall, controllers reported having\nall the necessary information to conduct IM operations and that IM information in spacing list\nand data block locations was acceptable. The authors recommended further examination of IM\nin the TRACON, including aircraft already conducting IM transitioning into the TRACON. Rognin et al. (2005) also conducted a simulation examining IM with a en route metering\ncapability. Aircraft transitioned into the TRACON, but there was no terminal metering tool.\nControllers were provided new tools to manage IM aircraft. Overall, controllers found IM and\nen route metering to be compatible and complementary. TRACON controllers reported 2-14 favorably upon receiving aircraft already conducting IM from the en route environment\nbecause the transfer conditions were more stable. 2.4.2 Past Research on IM and Terminal Metering with TSAS\nThe main body of work to examine IM in a terminal area metering environment was conducted\nby NASA under the Air Traffic management Demonstration-1 (ATD-1) umbrella of activities. The\nmajority of the HITL simulations are summarized in Robinson et al. (2015). That work will be\nreviewed next from the perspective of the controller, because from the flight crew perspective,\nboth the metering and non-metering environment look very similar. Flight crew procedures do\nnot change between the environments and the receipt of a time-based ASG may be the only\nindication to the flight crew that they are in a metering environment. 2.4.2.1 NASA ATD-1 Concept of Operations\nNASAs ATD-1 activity started in 2011 to develop, demonstrate, and transfer time-based\nspacing capabilities to the FAA. The ATD-1 concept is very similar to the time-based metering\nenvironment and the IM concept as described in Sections 2.1 and 2.2. In the ATD-1 concept, en\nroute controllers manage and meter aircraft via TBFM to deliver them to the TRACON boundary\nsuch that speed alone should achieve the schedule. Aircraft fly PBN arrival procedures with\nspeed and altitude constraints. For aircraft that are equipped, the en route controller can issue\nan IM clearance (sometimes with an associated STA). If an STA is provided, it is entered in the\nflight deck and flown until IM can begin. En route controllers hand off aircraft near the terminal\nboundary with a schedule error of less than 30 40 seconds (Robinson et al., 2015). Terminal\ncontrollers use TSAS to continue to manage and meter aircraft. They also monitor on-going IM\noperations. The final controller may also use the Automated Terminal Proximity Alert (ATPA)\ncapability to monitor separation as aircraft join the final approach. ATD-1 activities ended in\n2017 with a flight test of the flight deck IM component (Swieringa et al., 2017). 2.4.2.2 NASA ATD-1 Controller HITLs\nBetween 2012 and 2014, NASA conducted sixteen simulations under the ATD-1 activity with\ncontrollers as participants (Robinson et al., 2015). Some simulations included IM and others did\nnot. Of the sixteen simulations, seven had published reports on IM and TSAS integration with\ncontroller participants. A report on an additional HITL simulation became available in 2016\n(Baxley et al., 2016). Table 2-2 shows the dates and key papers for these simulations. In these simulations, controller participants were either active or retired controllers. In many\ncases, the same controllers participated in multiple simulations. Overall, the ATD-1 IM TSAS\nwork with controllers as participants included a low percentage (approximately 10-20%) of IM\naircraft. However, some of the simulations appeared to have fewer IM aircraft (e.g., three IM\naircraft in a 75 aircraft per hour run in Thipphavong et al. 2013) or did not have IM as part of\nthe main focus (e.g., Wynnyk and Kopald, 2013). Baxley et al. (2016) was a notable exception\nthat had a high level of IM aircraft. High level summaries and results are summarized here and\nspecific, relevant details are discussed in Section 2.5.1. 2-15 Table 2-2. NASA ATD-1 TSAS and IM Controller HITL Simulations HITL\nName Conduct\nDate Paper CA-1 Jan 2012 Cabrall, Callantine, Kupfer, Martin, and\nMercer (2012) CA-2 April 2012 Callantine et al. (2012)\nCA-3 June 2012 Callantine et al. (2012)\nFIAT-1 Oct 2012 Thipphavong et al. (2013)\nCA-4 Dec 2012 Callantine, Kupfer, Martin, and Prevot (2013)\nTSS-2 2013 Wynnyk and Kopald (2013)\nCA-5.3 2014 Callantine, Kupfer, Martin, and Mercer (2014)\nIMAC 2015 Baxley et al. (2016) CA Controller Managed Spacing (CMS) Air Traffic management Demonstration (ATD) FIAT Fully Integrated ATD-1 Test TSS Terminal Sequencing and Spacing IMAC IM Alternative Clearances The first ATD-1 simulation examining TSAS and IM integration was CA-1, as reported in Cabrall\net al. (2012). Nine controllers were participants (acting as TRACON and center controllers).\nControllers were asked to not interfere with IM operations, even if there was a spacing issue,\nto enable close examination of the behavior of the [IM] algorithm in an operational setting\n(Cabrall et al., 2012, p. 6). Eight aircraft were equipped with flight deck IM equipment. Controllers reported acceptable workload, tools, procedures, and phraseology for the\nintegrated operations and that they were able to integrate IM traffic into their operations. The\nauthors did indicate, however, that there were some spacing issues with IM aircraft, which\nseemed to be due to lack of conditioning aircraft prior to initiating IM operations. When using\nthe TSAS tools (e.g., early / late indicators, slot markers, timeline) as well as the IM data block\nindicators for IM, feeder controllers indicated that the timeline and data block indicators were\nboth helpful and useful. Their replies also indicated higher helpfulness ratings but lower\nusability ratings for the slot markers and early / late indicators for IM, even if both showed\nlarge schedule errors for IM aircraft. However, controllers seemed to want the tools to help\nmanage IM operations. Final controller ratings were not provided. Controllers reported\nfavorably on manually interacting with the IM status designators and also reported few issues\nwith the IM clearance. In the follow-on / CA-2 simulation, the focus was on pre-conditioning the traffic (Callantine et\nal., 2012). Center and TRACON controllers were participants. Eight aircraft were IM-equipped.\nThe same IM status designators and update methods for the TRACON controllers that were\nused for CA-1 were used for CA-2. Some conditions removed the slot markers and speed\nadvisories for aircraft conducting IM. Results reporting was limited; however, the IM results\nthat were reported indicated that pre-conditioning the IM traffic overcame the IM aircraft 2-16 delivery problems seen in CA-1. Additionally, center and TRACON controllers reported finding\nthe IM status designators in the data block useful. The CA-3 HITL built on the previous simulations and examined controller tools, procedures, and\nphraseology (Callantine et al. 2012), but with different IM status designators. Approximately\n11% of the aircraft were IM-equipped. Center and TRACON controllers were participants.\nOverall, controller replies indicated that the tools, procedures, and phraseology were\nacceptable and useful. Controllers reported that mixed IM and TSAS operations were not an\nissue. For this simulation, when controllers were considering terminating IM, they were\nencouraged to suspend IM instead, so they could resume IM at a later point. Center controllers\nsuspended some IM operations, mostly due to concerns with separation at merge points. The\nresults indicate that IM reduced the inter-arrival spacing variation as compared to aircraft only\nconducting TSAS operations and that trail aircraft conformed to the underlying schedule when\nthe lead aircraft did. One noted issue was the high number of issues with IM communications.\nThe authors do not provide much detail on the exact nature of the concerns, but acknowledged\nthat it needed to be addressed. FIAT-1 was conducted to further evaluate the ATD-1 operational concept and its validity\n(Thipphavong et al. 2013). There were three IM-equipped aircraft per run in a demand of\naround 75 aircraft per an hour run. In some scenarios, the lead aircraft was not in the same\nsector as the trail aircraft. Center and TRACON controllers were participants. Overall, IM\noperations worked with the TSAS operations. The authors again confirmed the need to pre-\ncondition aircraft so that speed changes alone will be sufficient to achieve the desired spacing\nin the TRACON. When aircraft were on the same route, an IM operation was more likely to be\nengaged than when the aircraft were not on the same route. All controllers reported\nmanageable workload, though the center controllers reported higher workload than the\nTRACON controllers and increased communications with IM aircraft (as compared to non-IM\naircraft). Both could be attributed to the requirement to issue the IM clearance. TRACON\ncontrollers reported lower workload than the center controllers and reported communicating\nwith the IM aircraft the same or less than non-IM aircraft. For the majority of responses, there were no reported spacing issues for IM aircraft pairs and\nnon-IM aircraft did not need to be maneuvered for IM aircraft pairs. Aircraft in IM pairs spent\nless time off path than the non-IM pairs. When compared to aircraft not conducing IM, aircraft\nthat were conducting IM showed worse schedule conformance at the meter fixes and meter\npoints in the feeder airspace, but were spaced closer with less variance at the FAF. Controllers\nreported mismatches between the trail aircraft position and the slot marker. This behavior is\nexpected based
on the IM algorithm design. Slot markers, speed advisories, and the timelines\nwere reported as less useful for IM operations. CA-4 examined the pre-conditioning of traffic, different controller tool sets, and IM integration,\namong other things (Callantine et al., 2013). There were eight IM aircraft per run in a demand\nof around 43 aircraft per runway per hour (for a fifteen-minute run). The IM status designators\nin the data block were also updated. Center and TRACON controllers were participants. Authors\nreported having some data confounding issues due to winds and system behaviors that\nnegatively affected IM operations (leading to numerous suspensions) and the ability to measure 2-17 final approach spacing accuracy for IM. However, center controllers found the IM clearance\nacceptable (in contrast to CA-3), and reported a desire to split the communication into two\nparts. IM was reported by controllers, on average, to increase task complexity without doing so\nexcessively. The TSS-2 simulation mainly examined issues related to TSAS operations (Wynnyk and Kopald,\n2013). Four TRACON controllers participated. There were three IM aircraft per run in a demand\nof around 45 aircraft per runway per hour (for a half hour run). Controllers were told IM was\nnot a key part of the simulation, and very little IM-related data was reported. However, from\nthe results that were provided, the TRACON controllers average rating was neutral for\nusefulness of the TSAS tools for IM. However, average rating for other tasks such as managing\ntraffic and managing the schedule received a similar rating. The majority of controllers reported\nthat the IM designator (indicator of the status of the IM operation) was an important part of a\ncustom toolset. The CA-5.3 simulation examined how TSAS can improve efficiency of arrival operations during\nhigh demand (Callantine et al., 2014). Center and TRACON controllers were participants.\nThough the authors did not report specific IM-related result, they did mention that maintaining\ninter-arrival spacing without IM was an issue and required further examination. Finally, the IMAC simulation mainly examined acceptability and system performance of\ndifferent IM operations (Baxley et al., 2016). Eight Center and TRACON controllers were\nparticipants (pilots were also participants). Overall, controllers rated the concept, workload,\nand displays acceptable. The Controller Acceptance Rating Scale ratings also indicated\nacceptability. The authors recommended a feasibility check prior to initiating IM and during IM\nconduct so the controller knows when the ASG is invalid. 2.4.2.3 MITRE Concept Evaluation Activities\nThree concept evaluations were conducted by MITRE in 2016 to explore IM and TSAS\nintegration issues in the MITRE Integration Demonstration and Experimentation for Aeronautics\n(IDEA) lab using a team of FAA ground system, flight deck, and ATC domain experts. The goal\nwas to seek input from experts on the integration of the TSAS and IM operations, the prototype\ndisplays, and plans for a follow-on HITL simulation (this activity) in all the capabilities being\nutilized. Each evaluation was a step in the development process as the lab capability matured.\nImprovements were made over the course of the evaluations as the lab implementation\nmatured and as input was received. Over the course of the three evaluations, sample changes\nand improvements included: increased traffic density, the reposition of an ABP to the merge of\ntwo flows, updated IM information on the STARS display, and the addition of RNP RF turns.\nThese and other relevant changes will be discussed in subsequent sections. Overall, the\nparticipants found the operations to have potential to work together, but had questions that\nwould need to be addressed in the HITL simulation. 2-18 2.5 Study Purpose and Design 2.5.1 ATC Topics\nThe understanding of an operation and the information displayed to the controller is key to the\nsuccessful implementation of an operation. Fundamental to the ATC task is keeping cognizant\nof current and evolving conditions, i.e., maintaining situation awareness. When aircraft are\nconducting IM, controllers monitor aircraft speed control instead of actively directing it.\nPrevious studies have indicated that monitoring of aircraft under flight deck spacing operations\nwas increased for non-spacing aircraft in a spacing stream (Mercer et al., 2005), but reduced for\naircraft that had been sequenced and were maintaining their spacing (Aligne et al., 2003).\nRegardless of the impact on monitoring, there did not appear to be an effect on safety or a loss\nof situation awareness. A summary report of several European IM simulations (Hebraud,\nMartin, Leone, and Troise, 2006) reported on a study of Italian airspace that found improved\ncontroller situation awareness when using IM during metering operations, which also led to\nimproved coordination between controllers. Related to situation awareness is the controllers trust in the IM operation. They must fully\nunderstand the objectives and methods IM uses to achieve and maintain spacing and they must\nbe able to trust that flight crews will properly follow the IM speeds. The degree to which their\nmental models conform to the reality of IM operations allow them to appropriately calibrate\ntheir level of trust as conditions change. For example, if IM usually proceeds in a predictable\nfashion, but one aircraft starts deviating from the expected procedures, controllers will more\nlikely be able to detect the situation and intervene before it escalates. Mercer, et al. (2005)\nfound that predictability is important for controller acceptance. During IM operations,\ncontrollers will need to know what spacing to expect at key points and that the flight crews will\noperate their aircraft in predictable ways. Over-trust, resulting in a loss of situation awareness, can also be an issue. If controllers\ncompletely trust an operation, they can become complacent and not perform their normal,\nnecessary checks on the traffic. This can result in controllers taking longer to detect a\ndeveloping situation. Therefore, ways to minimize controller over-trust must be considered by\nconcept developers. Past work has generally found IM can work in a metering environment with limited issues (e.g.,\nRognin et al., 2005; Benson et al., 2011; Baxley et al., 2016). However, some key topics remain\nopen. The remainder of this section will review the relevant work related to the open topics. 2.5.1.1 IM Operations Relative to TSAS Slot Markers\nIn Cabrall et al. (2012), TRACON controllers reported favorably on IM overall and they reported\nthat the slot markers were helpful and usable for IM operations. However, feeder controllers\nreported the slot markers were very similar in helpfulness but less usable for IM aircraft as\ncompared to non-IM aircraft. They reported confusion regarding IM spacing behavior relative\nto the slot markers and therefore, the underlying schedule. The controllers expected to have IM\naircraft also in the slot markers and were uncomfortable when the IM aircraft were not in the\nslot markers. Controllers also appeared to be unsure of IM aircraft behavior relative to the slot 2-19 markers. They reported problems with IM aircraft arriving early relative to the schedule. The\nauthors indicated that follow-on work would look at enhancements to the slot markers to\nprovide controllers information on IM operation progress. However, it was not seen in the\nsubsequent reports. In the follow-on simulation, Callantine et al. (2012) reported scenarios where the slot markers\nwere removed when aircraft were conducting IM. However, no results were reported. In the\nthird of the series of these simulations, while it is not explicitly stated, a figure seems to\nindicate that the slot markers were used for IM aircraft in the TRACON (Callantine et al., 2012).\nTRACON controllers again reported slot markers as being helpful and they reported being\nconfident in their use. However, the reported results did not differentiate between slot marker\nuse for IM and non-IM operations, so it is unclear whether the issue discussed in Cabrall et al.\n(2012) is still applicable. In the conclusion, the authors point out that the TRACON tool use\nduring IM operations requires controller acceptance as well as consistent understanding and\nuse. When summarizing this third simulation, Callantine et al. (2013) noted that controllers had\nsome misunderstanding of IM aircraft behavior. In another ATD-1 simulation, Thipphavong et al., (2013) reported that IM trail aircraft had\nworse schedule conformance at the terminal meter points (indicating slot marker deviations)\nbut better at the FAF, as compared to aircraft not performing IM. TRACON controllers reported\nthat they saw short-term, but less long-term, mismatches between the IM aircraft position and\nthe slot marker position. As the authors note, this is to be expected based on IM algorithm\nbehavior. Finally, controllers reported that the slot markers were less useful for IM aircraft than\nfor non-IM aircraft. As mentioned previously, after most ATD-1 activities, MITRE concept evaluations were\nconducted in preparation for the HITL simulation reported here. The participants in the concept\nevaluations also determined that IM spacing behavior and deviation from slot markers should\ncontinue to be examined in the concept evaluations, followed by the HITL simulation. Some\noptions were tested during the concept evaluations that led to the final simulation\nimplementation that will be reviewed in Section 3.1.3.3. One option that was tested at the third\nevaluation, was a change in slot marker color of an aircraft conducting IM. Differentiating the\nIM trail aircraft was reported as being helpful and controllers appeared to have a better\nunderstanding of IM spacing behavior and reported seeing aircraft closing to their ASG.\nHowever, some controllers still expressed concerns about on-going deviations from the slot\nmarkers in the feeders airspace. They reported that their goal was to get all aircraft into their\nslot markers so that the handoff to the final controller would be acceptable and that they felt\nuncomfortable when aircraft were not in the slot markers. 2.5.1.2 IM Status Information on ATC Surveillance Displays\nTo help controllers actively manage and monitor IM operations, IM status information should\nbe
provided directly on the surveillance display. Such information will help the controller\ndetermine which aircraft are part of an IM operation, what their role is (i.e., trail or lead), and\nthe status of the IM operation (e.g., active). Past work examined this topic and is reviewed next. 2-20 In Bone et al. (2007), a HITL simulation of an achieve-by IM operation is reported that was a\ntransitional implementation that had no active controller involvement in the set-up of IM or in\nissuing the IM information. The UPS operations center provided the IM information to the trail\naircraft based on the arrival sequence and the ASG that was agreed-upon with the TRACON.\nThe controllers monitored IM and intervened when necessary. The simulation was supporting\nan early field implementation where controller tools would not be available in time. In this\nsimulation, controllers did not know which aircraft were conducting IM, only that some in the\nstream were capable. Based on the results, the authors noted that controllers may need: to know which aircraft are actually (versus potentially) conducting IM, a better understanding of IM aircraft behavior (e.g., relationship between IM speeds\nflown and the ASG), to know whether or not the ASG can be achieved, and more information to determine when an intervention in the IM operation is necessary. In a follow-on simulation, during capture then maintain IM operations, Penhallegon and Bone\n(2008) had pilots report when conducting IM, instead of having the controller assume. While\nthe controllers did not have IM-specific display features, they were reported to use existing\ndisplay features to flag aircraft that were conducting IM. The controllers did not report the\nmonitoring and intervention needs reported in the previous simulation. However, this\ndifference may be because maintain operations may lend themselves better to monitoring the\nstatus of IM than do achieve operations because aircraft are on a common route. EUROCONTROL IM-related research with controllers (e.g., Aligne et al., 2003) used basically the\nsame tool set (Figure 2-8). Controllers were informed of IM equipage through the flight plan.\nFor the surveillance display IM features, circles were placed around the trail (larger circle) and\nthe lead (smaller circle) aircraft. A line linking the aircraft was also available as an optional\ndisplay element. The line included a numeric value of the current spacing between the aircraft\nin distance or time. The features were orange when the lead aircraft was being identified and\nselected by the trail aircraft flight crew and was green when IM became active. Controllers\nreported that the tools were useful (Aligne et al., 2003; Rognin et al., 2005). Figure 2-8. EUROCONTROL IM Controller Information [Reprinted from Aligne et al., 2003] 2-21 Benson et al. (2011) reported a simulation where center controller data blocks showed trail and\nlead aircraft role and IM status: pending versus active (in the fourth line). IM eligibility was not\nshown in the preferred IM window implementation (but was examined in an alternative\nimplementation). A flyout window was also available that allowed controllers to initiate and\nterminate IM and show the IM operation state and aircraft role in IM. It used color coding to\ndifferentiate between the IM pending (clearance issued but not yet accepted by the flight crew)\nand active states (Figure 2-9). Controllers used the option to initiate and terminate IM with the\ndata block. The data blocks were reported to have provide IM situation awareness benefits.\nMost controllers wanted the trail and lead identification and lead or trail role in data block and\nthought it was part of a minimum set of information. Figure 2-9. MITRE IM Controller Data Block Information [Reprinted from Benson et al., 2011] Peterson et al. (2012) conducted a follow-on simulation and developed an alternative data\nblock and fly-out menu for IM. In this implementation, the controller could accept or reject a\nproposed IM operation, as well as change the status states of the IM operations. The status\nstates shown were: capable (FC), pending (FP), active (FA), or terminated (FT). The flyout menu\nwas where the proposal for the IM operation was rejected and where the status states were\nchanged (Figure 2-10). The majority of controllers reported that the data block was their\npreferred method for conducting IM operations, although controller responses appeared mixed 2-22 as to the necessity to display IM information in the data block. The majority of controllers\nagreed that each of the states should be depicted. Figure 2-10. MITRE IM Controller Data Block Information [Reprinted from Peterson et al.,\n2012] In Cabrall et al. (2012), IM status information for the IM trail aircraft was provided to TRACON\ncontrollers in the second line of the data block, after the aircraft type. No IM equipped indicator\nwas shown for the trail aircraft. A was used when aircraft were flying RTAs prior to starting\nIM and an S was used when aircraft were conducting IM. Controllers manually updated the\nstatus designators based on flight crew reports. Controllers found the status information itself,\nas well as the need to manually update the status, acceptable. The information was rated as\nhighly helpful and highly usable. However, controllers reported wanting a single input\ncommand to toggle between the status states. The same method was used in the follow-on simulation reported in Callantine et al. (2012).\nHowever, there were also conditions where the TSAS speed advisories were removed during IM\nfor the IM trail aircraft. Both Center and TRACON controllers reported that the status\ninformation was useful. In the third simulation of the series, data blocks for the Center\ncontrollers had a /S indicator in the third line of the data block for the IM trail aircraft. This\nsimulation added an IM equipped indicator for the trail aircraft. A command was used to turn\nthe field magenta when IM started. A was included if the aircraft was flying the RTA prior to\nIM. A command could be used to toggle between the states. The status information was passed\nto the TRACON controller where the information was provided in the same field as the previous\ntwo simulations (Callantine et al., 2012). The TRACON controllers provided high ratings for the\nhelpfulness and their confidence in the IM status information. Center controller feedback was\nnot reported. The authors note that there were some issues with setting the status, but the\nreason for the issues was unclear from the report. In another simulation, Thipphavong et al., (2013) used a similar approach to that reported in\nCallantine et al. (2012). Data blocks for the Center controllers had a /S indicator in the third 2-23 line of the data block to indicate IM capable for the trail aircraft. A command was used to turn\nthe field magenta when IM started. TRACON controller IM designations in the data block were\nnot described. The lead aircraft was sometimes identified in the data block for the lead aircraft\ncontroller when both aircraft were not in the same sector. TRACON controllers reported that\nthe TSAS speed advisories were less useful for IM operations than for non-IM operations, but\nwere still somewhat useful. The IM status indicators were rated as more useful than the slot\nmarkers by TRACON controllers, but the slot markers were still reported to be used 40% of the\ntime. Controllers reported that they did not want to have other IM status indicators, such as\nsuspended or terminated, in the data block. When the lead aircraft was identified for the\ncontroller, IM operations were suspended less often and controllers confirmed they liked the\ninformation. In the follow-on simulation, the indicators and their location changed for both center and\nTRACON controllers (Callantine et al., 2013). Center controllers had the following information in\nthe zero line of the data block: @ for IM-equipped, R when the aircraft was flying a RTA\nprior to IM, and S for active IM operations. The @ symbol changed to magenta when the\ncontroller issued the IM clearance and made an entry. The R and S indicators were shown\nafter controller entry (Figure 2-11). For the TRACON controllers, the IM status was transfer from\nthe center controller systems. In this simulation, the designators were: FIM [Flight deck-based\nIM] for IM clearance issued, RTA when the aircraft was flying a RTA prior to IM, and SPC for\nactive IM operations. The designators for this simulation were in the third line of the data block\nreplacing the TSAS speed advisories and early / late indicator (Figure 2-12). This simulation had\nwind-related issues that affected IM operations; however, both center and TRACON controllers\nreported favorably on the IM status designators and the associated updating. Figure 2-11. Center Controller Data Block Information from Callantine et al. (2013) [Reprinted\nfrom Callantine et al., 2013] 2-24 Figure 2-12. TRACON Controller Data Block Information from Callantine et al. (2013)\n[Reprinted from Callantine et al., 2013] One of the final NASA simulations is reported in Baxley et al. (2016). As with past simulations,\ncenter controllers had IM status information in the data block (top line) which included three\nstatus levels: IM capable, IM issued, and IM active / reported paired. TRACON controllers had\nIM status information in the data block including: IM issued (FIM) and (SPC) IM active /\nreported paired. Overall, the controller reported the display elements as acceptable. The\nauthors recommended indicating in the data block of the trail aircraft: (1) whether an aircraft is\nIM capable, and (2) whether an IM clearance has been issued. In concept evaluations conducted in preparation for this HITL simulation, the IM information in\nthe data block was examined. The IM information replaced the TSAS speed
advisory and early /\nlate indicator. The first concept evaluation included the lead aircraft identification in the data\nblock of the trail aircraft, along with the aircraft role (trail or lead aircraft) and IM state status.\nControllers reported the lead aircraft identification in the trail aircraft data block as being\nunnecessary information (this information was also available in an IM clearance window). In the\nsubsequent concept evaluations, this information was removed but the aircraft role and state\nstatus information persisted. Controllers did not report issues with IM information replacing the\nTSAS speed advisories or the early / late indicator for the trail aircraft. 2.5.1.3 IM Clearance Information on ATC Surveillance Displays\nBesides needing information in the data block about the status of the IM operation, similar or\ndifferent information may be needed in a window that provides the IM clearance information.\nPrevious simulations examined this topic only from the center controller perspective and will be\nreviewed next. The information and format provided to the center controller in the first two simulations in\nCallantine et al. (2012) is unclear. However, the third simulation provided the IM information in\nthe meter list. The IM information provided was the ABP, the ASG, the lead aircraft, and the\nlead aircrafts Intended Flight Path Information (IFPI). Center controllers reported positively on\nthe overall set of tools available to them, including the meter list. The same information was\nprovided in the meter list in the simulations as was reported in Callantine et al. (2013) and\nThipphavong et al., (2013). No display issues were noted. Controllers in Thipphavong et al.,\n(2013) reported that the meter list was very useful. Baxley et al. (2016) had a similar 2-25 implementation but reported there may have been unintended consequences in their displayed\nclearance information because they did not have time to incorporate a capability to only show\nthe controller the relevant IM clearance information for each IM clearance type utilized. This\nrequired the controller to know which information was required for which operation and to\nonly issue the necessary information. They suggested fixing this for future implementations.\nHowever, controllers generally reported favorably on the display implementation. Benson et al. (2011) reported a simulation with center controllers that evaluated two different\ndisplay implementations (i.e., IM window and alert list) for IM clearance information. The IM\nwindow will be reviewed as it had more favorable objective results, was the preferred\nimplementation, and is the most relevant implementation. The IM window included four main\nareas: (1) timeline, (2) a window for the clearance information, (3) a window with IM state and\nstatus information as well as an area to initiate or terminate IM, (4) a trash can for recently\nterminated IM operations. The FIM List timeline showed when an IM clearance would be\navailable (Figure 2-13). The FIM information window showed the lead and trail aircraft\nidentifications, ASG, lead aircraft sector, and predicted spacing at the ABP. It used color coding\nto differentiate between the IM pending (clearance issued but not yet accepted by the flight\ncrew) and active states. The rest of the clearance (the ASG) was in the command info window\nwhich is where the clearance was presented. 2-26 Figure 2-13. MITRE IM Window Controller Information [Reprinted from Benson et al., 2011] The timeline received favorable feedback. For the information in the window with IM state and\nstatus, the controllers reported that the predicted interval at the ABP was useful but were split\non whether it was a requirement and just over half thought it was useful as an indicator of\n[IM] status. Controllers did not report the sector information for the lead aircraft to be very\nuseful. In a follow-on simulation, Peterson et al. (2012) used the existing TBFM metering list (which\nincluded the Meet Time Error [MTE]) to add IM information. The only IM information that was\nadded was IM status state, the ASG, and an indication of the ability of an aircraft to act as a lead\nfor an IM operation. The trail aircraft was already listed as the first element in the TMA\nmetering list and the lead aircraft was inferred to be the aircraft directly ahead in the schedule.\nThe controller was not able to interact with the list. All interactions were via the data block. The\ncurrently available MTE parameter was provided to the controllers as the spacing compliance\ntool. Controllers reported having this information was useful. However, only a slight majority of\ncontrollers reported that the MTE was useful for maintaining awareness of IM operations. More 2-27 downstream controllers found it useful than did upstream controllers. Controllers reported that\nthe IM status state, the ASG, and the lead aircraft indication were useful. 2.5.1.4 ATC Research Needs\nAs can be seen from past work, general acceptance of IM operations has been reported in\nnumerous simulations, including some examining IM during metering (e.g., Rognin et al., 2005;\nPenhallegon and Bone, 2008; Benson et al., 2011; Callantine et al., 2012; Baxley et al., 2016).\nHowever, there are still issues that need to be addressed related to the interaction between\nTSAS (absolute spacing) and IM (relative spacing), as well as controller information needs in the\nTRACON. The interactions between these two types of spacing behaviors is important to\nunderstand since both are expected to be fielded by the FAA to maximize capacity. As discussed in Sections 2.1 and 2.2, IM and TSAS operations achieve operational spacing goals\nin different ways. During IM / relative spacing, the IM aircraft performs spacing adjustments\nrelative to a lead aircraft. In absolute spacing, spacing adjustments are made with respect to\ncrossing a specific location at a designated time, independent of the lead aircraft (once the\nschedule is frozen). The following issues have been identified in past IM and metering activities. Controllers can have difficulty visualizing time-based spacing (as compared to distance-\nbased operations) (e.g., Aligne et al., 2003) Under certain conditions, separation can be an issue because the IM algorithm is only\nconsidering spacing at a point (the ABP) and not separation along the way. Baxley et al.\n(2016) recommended examining placing the ABP at the location where the aircraft routes\nmerge to ensure separation at that point. Controllers that participated in the concept\nevaluation activities also expressed concern about this potential issue. IM aircraft can be outside of the slot markers. While slot markers were found useful in\ngeneral, in some instances, they were reported as less so for IM aircraft. Proposals to\nmodify slot makers have been mentioned (e.g., Cabrall et al., 2012) but not reported or\ntested. Necessary IM information and where it should be displayed to support the controller in\nIM operations is still an open topic. For example, it remains unclear what information\ncontrollers require to monitor the progress of the IM operation and to determine\nacceptable spacing for the handoff and final spacing at the ABP. Splitting the information\nbetween a clearance window and the data block also still needs examination. While past simulations did not report issues with TRACON controllers receiving aircraft\nalready conducting IM from the en route environment, concept evaluation activities leading\nup to this simulation did have some questions from controllers about the acceptability of\nthis. Therefore, the topic should be explored further to see if HITL participants have any\nconcerns. This simulation will attempt to address these open issues and continue validation of other\ntopics from past efforts. 2-28 2.5.2 Flight Deck Topics 2.5.2.1 Flight Deck Display Spacing Information\nDisplays for IM must include the necessary information to perform IM and must not contain\ninformation that conflicts with IM tasks. Any annunciations must also be salient. In order for\npilots to trust the IM system, they must be able to develop an appropriate mental model (i.e.,\nabstract functional understanding) of the operation and to fully understand the objectives and\nmethods IM uses to achieve and maintain spacing. For example, they will need to understand\nthat the spacing to be achieved is based on a time interval, and that distance spacing will be\nvariable due to winds and compression. The degree to which their mental models conform to\nthe reality of the IM operations will allow them to appropriately calibrate their level of trust. A\ngood mental model is also important for situation awareness in that it provides a mechanism\nfor integrating and comprehending information and allows for projecting future states (Endsley,\n1995). Over the course of HITL research on IM2, there has been shown to be general acceptability of\nIM and the ability to meet the spacing goals (e.g., Hebraud, Hoffman, Pene et al., 2004;\nSwieringa et al., 2014; Penhallegon, Mendolia, Bone, Orrell, and Stassen, 2011). However, a\ndominant, re-occurring issue is flight crew understanding and trust in the IM algorithms\nbehavior and the related ability to monitor the progress of the spacing task. Past simulations\nhave attempted to support the flight crews and through examination of different display\nfeatures. The past work has shown that certain features can lead to confusion, additional\nworkload and head-down time, or simply may not be utilized. The past work also shows that an\nideal, or even reasonable, implementation has been challenging to achieve. The remainder of\nthis section will review this past work. 2.5.2.1.1 EUROCONTROL Research\nThe first IM simulations conducted by EUROCONTROL included a limited number of pilots, and\nonly a basic Cockpit Display of Traffic Information (CDTI) capability (Zeghal, Hoffman, Cloerec,\nGrimaud, and Nicolaon, 1999). Only qualitative feedback was received as the main effort was to\ndetermine the feasibility of IM. Results revealed some issues that the authors speculated were\ndue to the rudimentary CDTI (e.g., no IM speeds). The second set
of flight deck experiments was conducted in 2002 and is reported in Hebraud,\nHoffman, Papin et al. (2004). These two evaluations (May and December) were conducted after\nthe initial small-scale experiment examining feasibility of spacing and the requirements for the\nCDTI. The setup for the spacing was conducted through the Control and Display Unit (CDU), and\na CDTI traffic display was placed on the navigation display. In both experiments, pilots reported\nfavorably on their situation awareness and their active participation in the maintenance of 2 IM is used generically in this section. Not all simulation examined the full capabilities now being defined in\nnew versions of DO-361 and DO-328A (RTCA, 2015a, 2015b). Most examined only a subset of those capabilities\nor an early implementation of those capabilities, under different concept names. 2-29 spacing. Flight crews were found to be able to maintain spacing within the tolerances, with few\nexceptions. For spacing information in the May experiment, the CDTI traffic display included lead aircraft\nground speed, closure rate to lead aircraft (difference between lead aircraft and ownship\ngroundspeed), a required spacing arc and a predicted spacing cue (position on trajectory where\nspacing will be acquired) (Figure 2-14). The predicted spacing cue changed to amber if the\nspacing was predicted to be outside tolerances. IM speeds were not provided to the flight crew.\nPilots reporting desiring spacing trend information and IM speeds. Figure 2-14. Navigation Display with IM Information from Hebraud, Hoffman, Papin et al.\n(2004) First Evaluation [Reprinted from Hebraud, Hoffman, Papin et al., 2004] Based on the findings from the May evaluation, changes were made for the December\nevaluation. The required spacing arc and the data block information were removed. The CDTI\ntraffic display now included an IM speed and spacing scale (Figure 2-15). The spacing scale\nshowed current spacing, required spacing, spacing trend, closure rate, and tolerance margins\n(Figure 2-16). When current spacing was out of tolerances, the flight crew was alerted. Flight\ncrews were also prompted with the visual advisory losing spacing when spacing was an issue. 2-30 Figure 2-15. Navigation Display with IM Information from Hebraud, Hoffman, Papin et al.\n(2004) Second Evaluation [Reprinted from Hebraud, Hoffman, Papin et al., 2004] Figure 2-16. Spacing Scale from Hebraud, Hoffman, Papin et al. (2004) Second Evaluation and\nHebraud, Hoffman, Pene et al. (2004) [Reprinted from Hebraud, Hoffman, Pene et al., 2004] The majority of pilots reporting that the spacing task could be conducted with the displayed\ninformation and that the new features were helpful. Pilots reported the new spacing scale was\nintuitive and useful, though the closure rate information was of little use. Some pilots also\nthought they focused too much on the new spacing scale while others felt it was well integrated\ninto their scan. Pilots also reported liking the IM speeds and questioned the relevance of the\npredicted spacing cue. Finally, pilots reported a worry about focusing on the spacing task\nrequirements too much when busy or forgetting when no action is needed during a long period\nof time. A third flight deck evaluation was conducted in 2003 and was reported in Hebraud, Hoffman,\nPene et al. (2004). The display implementation was very similar to the December 2002\nevaluation (Hebraud, Hoffman, Papin et al., 2004). This experiment added flashing for the IM\nspeeds when there was a difference of 7 knots between the IM speed and the current IAS. 2-31 While the December 2002 evaluation prompted the flight crews with the visual advisory losing\nspacing when spacing was an issue, this experiment changed the visual advisory to either\nASAS ACCELERATE or ASAS SLOW DOWN. The 2003 evaluation found the spacing task to be acceptable and all pilots reported the spacing\nas easy. They reported favorably on their active participation in the maintenance of spacing and\nwere found to be able to maintain spacing within the tolerances with no loss of spacing with\nthe displayed information. They again reported that spacing scale may have too much\ninformation and that the closure rate information was of little use. However, pilots reported\nthe trend information was useful. They noted the flashing of the IM speed was good but that\nthere should be more alerting. Pilots reported potential fixations on the spacing scale and a\npossible reduction in monitoring other flight information. After this set of evaluations, the final flight deck requirements were defined by EUROCONTROL\n(Hoffman, Pene, and Zeghal, 2006). The requirements relevant to the spacing cues are noted\nbelow. The flight deck implementation shall include the following: Advisory if IM is infeasible (visual alert only during the feasibility check) Advisory if spacing is drifting and may exceed tolerances (visual alert) with message for\ncorrective action Caution if tolerances are exceeded (visual and aural alerts) with message for corrective\naction Warning if the clearance cannot be complied with (visual and aural alerts) with reason\nwhy the clearance cannot be complied with Spacing indicator with current spacing, required spacing, spacing trend, and tolerance\nmargins in the main field of view (preferably analog representation). Information on where\nthe ASG will be reached o Note closure rate is excluded Guidance indicator / IM speed in the main field of view 2.5.2.1.2 NASA Research\nMuch of the early work on in-trail following, spacing, and merging applications was conducted\nby NASA Langley and was from the flight crew perspective in the terminal environment during\napproach (e.g., Abbott and Moen, 1981; Williams and Wells, 1986). The work continued under\ndifferent names and programs. The most relevant recent work is reviewed here. Oseguera-Lohr, Lohr, Abbott, and Eischeid (2002) conducted an IM pilot evaluation in a high-\nfidelity simulator with active airline pilots. The CDU was used to enter the IM information and\nprovided relevant information (i.e., lead aircraft identification and groundspeed, current\nspacing, ASG, as well as current distance to the lead aircraft). The IM speed was provided on\nthe Electronic Attitude Direction Indicator in association with the standard fast / slow bug (left\nside of Figure 2-17). New IM speeds were annunciated with a box flashing for 5 seconds around 2-32 the IM speed value. On the Electronic Attitude Direction Indicator, the IM speed was shown\nimmediately numerically but the fast / slow bug for the IM speed followed a scheduled speed\nreduction (though the exact method is not described in detail). The IM speed was also shown\non the airspeed indicator. The navigation display included a highlighted target aircraft along\nwith its associated flight identification and range in NM, spacing position indicator (aka picnic\ntable), and history data from the target aircraft (right side of Figure 2-17). It also showed the\nASG (PDA field) and IM Speed (CMD field). The spacing position indicator showed the\npredicted spacing relative to the ASG. When the predicted spacing was the same as the ASG,\nthe apex of ownship fit into the v of the indicator. Figure 2-17. Primary Flight Display (PFD) and Navigation Display with IM Features from\nOseguera-Lohr et al. (2002) [Reprinted from Baxley et al., 2014] Pilots reported the tools were acceptable. Head-down time was found to be higher than\ncurrent operations, but acceptable. No major changes were proposed for the display\nimplementations. In a summary of this work, however, Baxley, Shay, and Swieringa (2014)\nstated the fast / slow symbology was found to be borderline effective, the speed change\nnotification should be longer than 5 seconds, and the spacing position indicator received\nvarying reports of usefulness. As a follow on to Oseguera-Lohr et al. (2002), Lohr et al. (2005) made minor updates to the IM\ndisplay information (e.g., the IM speed location on the fast / slow indicator was moved to be\nalongside the bug) and algorithm to conduct a flight test. Information was provided to indicate\nto the flight crew that the current IM speed was limited due to configuration or procedural\nreasons. As with the previous activity, the pilots reported the tools were acceptable. Head-\ndown time was found to be higher than current operations, but acceptable. The authors noted\nan issue with the spacing position indicator. Although pilots had been told to follow the IM\nspeeds and only use the spacing position indicator for spacing awareness, they had a desire to\nquickly drive the aircraft symbol into the spacing position indicator versus following the IM 2-33 speeds, which would progressively get them in the proper position over time. This,\nunnecessarily, led to additional workload and unnecessary speed inputs. The authors\nrecommended additional work to refine the IM tools. Prevot et al. (2004) describes a CDTI used by flight crews in their work on trajectory-oriented\noperations with limited delegation. It is described and shown in greater detail in NASA (2004).\nFigure 2-18 shows the implementation. The CDTI included lead aircraft identification, ASG,\nspacing box, and a line between the trail and lead aircraft showing the ASG and 30-second\nmarkers. The spacing box was green if the trail aircraft was within tolerance but changed to\nyellow when the aircraft was greater than 10 seconds ahead of the ASG and changed to white\nwhen greater than 20 seconds behind the ASG. Limited results were found related to the use of\nthis implementation for IM. Figure 2-18. IM Features on the CDTI from NASA (2004). [Reprinted from NASA, 2004] Barmore, Abbott, and Capron (2005) examined IM with pilots flying a desktop simulator. This\nsimulation used displays very similar to those used in previous simulations, with a few\nmodifications (e.g., no fast / slow indicator) and the use of PFDs and navigation displays (Figure\n2-19). Crews were alerted if the current speed was not within 5 knots
and closing on the IM\nspeed. The IM speeds were coupled to the autothrottle so the flight crew did not enter the IM\nspeeds through the Mode Control Panel (MCP). The Multifunction Control and Display Unit\n(MCDU) was used for set-up and provided the same information as that in Oseguera-Lohr et al.\n(2002). In a summary of this work, Baxley et al. (2014) stated the spacing position indicator was\nagain problematic (e.g., low usefulness ratings, over-control issues) and that it should be\nremoved or improved. 2-34 Figure 2-19. PFD and Navigation Display with IM Features from Barmore et al. (2005)\n[Reprinted from Baxley et al., 2014 (Highlights Added)] Murdoch, Barmore, Baxley, Abbott, and Capron (2009) conducted an IM HITL simulation during\noptimized RNAV routes. The objectives of the HITL were to assess pilot ability and acceptability\nof IM procedures during nominal and off-nominal situations and to evaluate human and system\nperformance in terms of aircraft spacing and system performance. Two separate simulation\nplatforms were used and the displays are shown in Figure 2-20 and Figure 2-21. It can be seen\nin the PFD and navigation display in Figure 2-20 that elements have been removed (relative to\nthe previous simulation) and only the IM speed and mode are shown on the PFD. Also, only the\ntarget aircraft highlighting is shown on the navigation display. The same is true with Figure\n2-21, except the spacing position indicator also appears to have been used. The MCDU was\nused for set-up and provided IM information during conduct. Using subjective measures of\nacceptability, completeness of procedures, and workload, Murdoch et al. (2009) found overall\nfavorability of IM and the tools across nominal and off-nominal events. 2-35 Figure 2-20. PFD and Navigation Display with IM Features Implementation 1 from Murdoch et\nal. (2009) [Reprinted from Baxley et al., 2014] Figure 2-21. PFD and Navigation Display with IM Features Implementation 2 from Murdoch et\nal. (2009) [Reprinted from Baxley et al., 2014] Baxley et al. (2013) conducted an IM HITL simulation during dependent runway operations.\nController Pilot Data Link Communications (CPDLC) was used to convey and load the IM\nclearance information into the flight deck IM equipment. The MCDU was used for set-up and\nprovided IM information during conduct. Three separate simulation platforms were used. The\nPFDs are shown in Figure 2-22. As can be seen, the IM speeds were shown above the airspeed\ntape and as a bug alongside the airspeed tape. A green box was placed around a new IM speed 2-36 for 10 seconds. Pilots were also notified if the IM speed was limited due to procedural speeds.\nPilots were notified if they were greater than 6 knots above the IM speed (by an Engine-\nIndicating and Crew-Alerting System [EICAS] message). No early / late (progress) indicator or\nfast / slow indicator was present. For the navigation displays, the only IM feature included was\nthe highlighting of the target aircraft, except for one exploratory run where a conformance box\nwas shown (Figure 2-23). The conformance box showed the band within which it was still\npossible to reach the ASG by the ABP. The goal of the box was to provide better spacing\npredictability. Spacing error was presented on the MCDU. Figure 2-22. PFDs with IM Features from Baxley et al. (2013) [Reprinted from Baxley et al.,\n2013] Figure 2-23. Navigation Display with IM Features from Baxley et al. (2013) [Reprinted from\nBaxley et al., 2013] 2-37 Pilots reported general acceptance of the display elements but the majority reported wanting a\nmore salient speed change notification such as flashing or an associated aural alert. Pilots also\nreported a strong preference for a progress indicator and the ability to predict new IM speeds.\nSome comments indicated that the pilots may have had a poor mental model of the\nrelationship between the spacing error and the IM speeds and the conformance box did not\nhelp much with the issue or pilot comfort in IM. However, the conformance box did provide\nuseful information for IM operations about the current time error relative to the tolerance\nboundary. Pilot reported it should be a tool available for IM. The authors recommended\nexamining tools that provide a clear indication of the relationship between the time error and\nthe arrival of new IM speeds and a tool similar to the conformance box showing the current\nstatus and trend of IM. Spacing error was only shown on the first IM page on the MCDU and the\nauthors were concerned about the amount of time the crews would spend viewing the MCDU\npage for this key piece of information. Flight crews were reported to use the spacing error\ninformation but not spending excessive amounts of time referencing the MCDU. NASA continued the IM work under its ATD-1 activity. Kibler et al. (2015) examined IM\noperations in a HITL simulation that used an auxiliary / Electronic Flight Bag (EFB) display\nlocation and an Automatic Dependent Surveillance-Broadcast (ADS-B) Guidance Display (AGD).\nIn this simulation, the EFB was used to enter the IM information. The AGD had a fast / slow\nindicator and the IM speed (Figure 2-24). New IM speeds were annunciated with a Light-\nEmitting Diode (LED) light on the AGD. The EFB display hosted the CDTI traffic display (Figure\n2-25). The traffic display included spacing information such the IM speed, a fast / slow\nindicator, and the ASG. The fast / slow indicator provided trend and acceleration and deceleration information and was\nnot simply an indication of whether the aircrafts current IAS or MCP speed matched the IM\nspeed. It was designed to assist the flight crew with matching the acceleration / deceleration\nprofile expected by the IM algorithm. The NASA algorithm attempts to keep the number of IM\nspeeds low (i.e., display one large speed command versus several smaller ones). By giving fewer\nIM speeds, the deviation from the expected speed profile can be greater so NASA provides the\nfast / slow indicator to help the flight crew follow the expected profile. The fast / slow indicator\nshows the flight crew whether the aircraft is on the expected speed profile, which is otherwise\nunknown to the flight crew. The flight crew is expected to set the IM speed in the MCP but is\nalso expected to use the fast / slow indicator to manage pitch / drag to decelerate (for\nexample) to match the profile (and to avoid poor performance when off-profile). Based on the\ndesign, there could be a situation where an IM speed is given that the flight crew quickly\ndecelerates to, which takes them off the expected profile. In this situation, the IAS / MCP speed\nwould match the IM speed but the fast / slow indicator would show the aircraft slow (because\nthe aircraft has decelerated too quickly relative to the assumed profile). 2-38 Figure 2-24. AGD with IM Features from Kibler et al. (2015) [Reprinted from Kibler et al.,\n2015] Figure 2-25. CDTI Traffic Display with IM Features from Kibler et al. (2015) [Reprinted from\nKibler et al., 2015] Pilots found the display implementation usable, but there were some concerns with the limited\namount of information in the forward field of view. Baxley et al. (2014) also noted that pilots\nexpressed some concerns about the LED indication of a new IM speed not being salient enough. Latorella (2015) examined IM operations with different display combinations and locations (as a\nwithin subjects variable) and alerting schemes (as a between subjects variable). The display\ncombinations included: (1) an EFB in an aft location; (2) an EFB in an aft location with an AGD in\nthe forward field of view; (3) an EFB in a forward location; and (4) an implementation\nintegrated into existing PFDs and navigation displays. The integrated displays were similar to 2-39 Baxley et al. (2013) except for the addition of a flashing box around new IM speeds and the lack\nof the conformance box (Figure 2-26). The EFB and AGD implementations are shown in Figure\n2-27. Fast / slow indications were also provided in a manner similar to previous simulations.\nEither the EFB or the MCDU were used for set-up. As with previous simulations, the MCDU\nprovided IM information during the conduct of IM. The alerting triggers included: (1) new IM speeds; (2) deviations from IM speeds; and (3)\nreminders if the IM speeds were not entered into the MCP. The triggers were alerted either\nvisually or visually and aurally. The three alerting methods were: (1) all visual only; (2) all visual\nand aural alerting; and (3) visual only for new IM speeds and reminders with visual and aural\nalerting for deviations from the IM speed. Figure 2-26. PFD and Navigation Display with IM Features from Latorella (2015) [Reprinted\nfrom Baxley et al., 2014] 2-40 Figure 2-27. CDTI Traffic Display and AGD with IM Features from Latorella (2015) [Reprinted\nfrom Baxley et al., 2014] Relevant results here are those related to the alerting. The all visual and aural alerting method\ngenerally did better than the all visual only alerting, and sometimes better than the visual /\nvisual and aural combination. There were also results that had interactions between the display\ncombination and the alerting scheme (as well as Pilot Flying [PF] seat position). However,\nthough most are less relevant to this work, they are important when considering the display\nand alert combination. The author recommended additional work to optimize the IM displays\nand the associated alerting schemes with a strong consideration for the use of visual and aural\nnotifications. 2-41 Swieringa et al. (2014) conducted a HITL simulation examining IM
in nominal conditions and a\ncondition where the lead aircraft slowed more than expected causing a potential issue with\nspacing. The simulation utilized a retrofit display implementation that included an EFB traffic\ndisplay (also used for set-up) and either a numeric (Figure 2-28) or graphical (Figure 2-29)\nprimary field of view AGDs. Figure 2-28. Numeric AGD with IM Features from Swieringa et al. (2014) [Reprinted from\nBaxley et al., 2014] Figure 2-29. Graphic AGD with IM Features from Swieringa et al. (2014) [Reprinted from\nBaxley et al., 2014] The flight deck platform was a desktop personal computer simulator. The numerical AGD was\nsimilar to Latorella (2015) in that it had the IM speed, a fast / slow numerical value. However, a\ntime error (predicted spacing error at the FAF/ABP) was added. The graphical AGD had fast /\nslow graphic (with trend), IM speed, IM mode, trail aircraft ID, and an early / late (progress)\nindicator graphic. The early / late (progress) indicator depicted the spacing error relative to\nfeasibility bounds (field 5 in Figure 2-29). The boundaries of the indicator were approximately\n10% of the trail aircrafts time to go to the ABP. The green bug was the difference between the\nlead aircrafts ETA and the trail aircrafts ETA at the ABP subtracted by the ASG. If the green bug\nreached the boundary, the ASG could not be achieved at the ABP. The flight crew was\npresented with a visual notification on the CDTI traffic display that the operation was no longer\nfeasible. The fast / slow field and indicator functioned as previously described. For the numerical AGD, new IM speeds would be indicated by a green LED light (field 4 in Figure\n2-28). For the graphical AGD, new IM speeds would be indicated by reverse video. Both\nindications would extinguish when the IM speed was set in the MCP. Flight crews were notified\nif they were greater than 10 knots above and diverging from the IM speed. 2-42 Several tests were conducted comparing the numerical and graphical AGDs during no\nperturbation conditions and a perturbation condition (lead aircraft slowed below profile\nspeed). Graphical AGD use during a perturbation was found to provide better situation\nawareness than the numerical AGD with no perturbations, but both had positive ratings.\nGraphical AGD use during a perturbation was found to be more intuitive than the numerical\nAGD with or without perturbations. There were no differences found between the displays and\nconditions when pilots were asked if the IM speeds made sense, but both had positive ratings.\nRelated to this finding (as the early / late [progress] indicator was attempting to support this\nunderstanding), pilots reported that they did not use the early / late (progress) indicator often\nand did not find it very useful. The fast / slow indicator was reported it to be moderately useful\nbut comments indicated pilots did not use it and did not think it should be a requirement for\ndisplay. Pilots were faster to implement the IM speeds with the graphical AGD, which the authors\nattributed to the more salient method of alerting to the new IM speeds (versus something\nbetter in the graphical elements). No significance for the deviation from the IM speeds. Overall, the graphical AGD was found to be better than the numerical AGD. However, the\nnumerical AGD was reported to be sufficient but not ideal. The authors stated reasons why the\nspecific implementation of the early / late (progress) indicator could be problematic and why\nother algorithms may have different outcomes. They also stated variations in the system can\ncause the spacing error to increase, but be nulled out later in the operation, leading to difficulty\nin understanding and interpreting the displayed information and how it relates to the possibility\nof getting a new IM speed. The authors suggest that a future simulation could examine the\nprogress indicator with a different algorithm and a different representation to increase the\nusefulness. In a summary of this simulation, Baxley et al. (2014) recommend removing the early\n late (progress) indicator if it cannot be improved. They also recommend adding an aural chime\nor flashing indicator to improve the saliency of new IM speed notifications. Baxley et al. (2016) reported the final HITL simulation of the ATD-1 activity. It included nominal\nand off-nominal events (e.g., separation issue). The simulation used an auxiliary / EFB display\n(Figure 2-30) and a graphical AGD (Figure 2-31) in the primary field of view. The EFB was used\nfor set-up. New IM speeds were annunciated by the IM speed being shown in reverse video\nuntil the IM speed was set in the MCP. If that was not done within 10 seconds, the field flashed.\nAs can be seen both an early / late indicator and a fast / slow (progress) indicator were used\n(features D and H in Figure 2-30). The early / late indicator was only shown on the auxiliary /\nEFB display (feature A in Figure 2-31). 2-43 Figure 2-30. CDTI Traffic Display with IM Features from Baxley et al. (2016) [Reprinted from\nBaxley et al., 2016] Figure 2-31. Graphic AGD with IM Features from Baxley et al. (2016) [Reprinted from Baxley\net al., 2016] As with previous work, the early / late indicator was intended to assist the flight crew in\ndetermining whether the ASG could be achieved, within tolerances, by the ABP. It was modified\nfrom previous simulations and displayed to the flight crew when specified by DO-361 (RTCA,\n2015a). Two scales were shown. One when the aircraft was greater than greater than 210 2-44 seconds from ABP and within 210 seconds of the ABP (Figure 2-32). When greater than 210\nseconds, the scale was +/- 120 seconds and the circle had a diameter of 20 seconds centered on\nthe spacing error. When within 210 seconds, the scale was +/- 45 seconds, and the circle had a\ndiameter of 20 seconds centered on the spacing error. Figure 2-32. Early / Late (Progress) Indicator When Greater than 210 Seconds from ABP (Left)\nand within 210 Seconds from ABP (Right) [Reprinted from Baxley et al., 2016] The fast / slow indicator was intended to allow the pilot to determine current IAS and IM speed\nmismatches and what action to take. As mentioned previously, it is not simply an indication of\nwhether the aircrafts current IAS matched the IM speed. In this simulation, the green triangle\non the indicator considered the IM speed, delay due to pilot behavior, and aircraft deceleration\nrate. It stayed fixed at the center of the display. The solid white triangle was the aircrafts\ncurrent IAS. The two triangles could have been aligned when an IM speed change occurred, but\nthen started to diverge when the aircraft should have been changing speed to match the IM\nspeed and the expected speed profile. Pilots reported that the fast / slow indicator was not very useful, confusing, and many were\nreported to have ignored it. The authors reported pilot confusion when the aircrafts current\nIAS matched the IM speed but the fast / slow indicator displayed a too slow alert because the\naircraft decelerated faster than the algorithm expected. A redesign and move to the speed tape\non the PFD was recommended by the authors. Pilots also reported that the early / late (progress) indicator was not very useful and could be\nconfusing. However, results were mixed and variable. The authors also stated that the pilot\naction when reaching the boundary were unclear, as it was not an indicator of infeasible\noperations. Again, the authors stated a need to improve the design, including showing the\ninfeasible limits. The authors also recommend defining pilot procedures to notify ATC when the\noperation becomes infeasible. The IM speed limit notifications were reported as confusing to pilots since there was no action\nto take based on the information. Finally, based on pilot attention concerns, the authors\nrecommended keeping the alerting scheme associated with IM speeds but to add an additional\naural alert at 15 seconds if the flight crew had not yet implemented the IM speed. 2-45 2.5.2.1.3 MITRE Research\nThe MITRE Corporation has been conducting simulations and participating in field and flight\ntests of IM over the course of many years to support concept and requirements definitions.\nSeveral were in conjunction with community activities where NASA also participated and\nsupported through the previously reported activities. The following paragraphs review the most\nrelevant MITRE activities. An early effort supporting a flight event examined IM (Bone, Helleberg, and Domino, 2003).\nTwo IM algorithms were used. In one, the symbology on the navigation display and algorithm\nwere very similar to Oseguera-Lohr et al. (2002), as the organizations were working together on\nthe capability. The navigation display included the lead aircraft identification, weight category,\nground speed, and distance from the trail aircraft. The navigation display also provided the IM\nspeed and the speed set in the MCP, as well as the spacing position indicator and history trail.\nFor this implementation, a flashing box was provided around the IM speed when a new one\nwas displayed. An IM speed bug was also presented on the airspeed tape of the PFD. For the other algorithm, the navigation display had the same features except for the spacing\nposition indictor and history trail. This algorithm included an aural alert (e.g., Reduce speed\n180) for new IM speed notifications. Based on previous feedback, a graphical prediction tool\nwas provided that attempted to provide the flight crew an independent check of the\nfunctioning of the underlying algorithm and supported the prediction of the new IM
speeds. It\nshowed a zone where getting a new IM speed was likely and a zone where getting a new IM\nspeed was unlikely. Pilots in this activity reported wanting to be able to monitor the progress of the spacing\noperation in relation to the ASG, including being able to predict when new IM speeds would be\nissued. Pilots reported wanting to know when to abandon IM due to spacing issues. Pilot\nfeedback was mixed as to whether an aural alert was necessary for new IM speeds. However,\npilots reported that flashing box for new IM speeds was insufficient. The authors recommended improving the spacing prediction tool such that the flight crew is\nbetter able to judge the underlying functionality of the algorithm and to explore making it clear\nto the flight crew when the speeds available and the existing spacing do not allow for IM to be\nconducted successfully (i.e., when to report unable). They also recommended further\nexploration on the need for an aural advisory for new IM speeds. In support of a retrofit field implementation of IM, MITRE conducted several activities to\nsupport the definition of the concept and display requirements. Key activities are reported\nnext. An initial activity conducted with FAA certification and test pilots was reported in Bone and\nPenhallegon (2006). An aft retrofit EFB was used to host the CDTI traffic display (Figure 2-33)\nand for setup. The display included the current IAS and the IM speed, a fast / slow graphical\nindicator (simply current IAS relative to IM speed), as well as the lead aircraft identification,\nweight category, ground speed, and distance from the trail aircraft. An AGD was attached to the\nMCP just below the airspeed window and was intended to provide the key pieces of\ninformation for IM conduct. It provided the IM speed, as well as closure rate and range to the 2-46 lead aircraft (Figure 2-34). New IM speeds were presented in reverse video on the AGD until the\npilot set the MCP speed to the IM speed. Figure 2-33. CDTI Traffic Display with IM Features from Bone and Penhallegon (2006) Figure 2-34. AGD with IM Features from Bone and Penhallegon (2006) The pilots questioned the use of closure rate and thought an aural may be necessary to\nannunciate a new IM speed. Further research was suggested. The pilots also believed an alert\nwas necessary if the flight crew was significantly off from the IM speed. Pilot opinions were split\non the usefulness of the fast / slow indicator. This work continued with line pilots and the first activity is reported in Bone et al. (2008a).\nNominal and off-nominal scenarios were evaluated. The traffic display implementation was the\nsame as in Bone and Penhallegon (2006). One scenario removed the traffic display and the\nflight crew only had the AGD. The intent was to examine the ability of the flight crew to conduct\nIM with only the information available on the AGD. The AGD was also the same, except the\nclosure rate field was changed to differential ground speed based on pilot feedback. One\nscenario included new fields on the AGD. The range to the lead aircraft was replaced by in-trail\ndistance and a new field was added: in-trail time. New IM speeds were presented on the AGD\nwith the same method as Bone and Penhallegon (2006). All display features were found to be useful and little discrimination was found between the\ndifferent elements. Pilots reported the in-trail time was useful, but the in-trail distance was less 140GS 260\n1200/15 15 S 12 20 GS 250 19.8 NM\nUPS350 HVY UPS350\n+09 +12 TRK MAG 275 IAS\nF S 275\nMerging & Spacing Data TGT\nFID SPC\nINT MRG\nWPT UPS350 90 sec ENL FAS MIN\nDIST 140 kt 3.0 nm STOP HIDE MENU HIDE DATA 140GS 260\n1200/15 15 S 12 20 GS 250 19.8 NM\nUPS350 HVY UPS350\n+09 UPS350\n+09 +12 TRK MAG 275 IAS\nF S 275\nMerging & Spacing Data TGT\nFID SPC\nINT MRG\nWPT UPS350 90 sec ENL FAS MIN\nDIST 140 kt 3.0 nm STOP HIDE MENU HIDE DATA 275 + 10\n19.8 CMD CR\nRNG 275 + 10\n19.8 CMD CR\nRNG 2-47 so. Pilots reported wanting additional information for the condition where the spacing was\nbecoming an issue. Pilots had issues determining when to intervene when a spacing issue was\nnoted. All pilots agreed that they had a clear understanding of the target spacing and how well\nit was being achieved. While the pilots followed a majority of the IM speeds and achieved the\nASG within tolerances, the authors report some mistrust of the IM equipment and speed. This\nwas believed to be due in part from the complexity of the algorithm, the algorithm acting on\ninformation unknown to the pilot (e.g., trajectory information), a potential for better display\nelements (e.g., in-trail time versus differential ground speed), and a potentially poor mental\nmodel. Finally, pilots were in disagreement on the need for and implementation of an aural\nalert to indicate a new CMD. Pilots reported an aural may only be necessary if the IM speed has\nbeen ignored for some period of time. A follow-on study was conducted and reported in Bone et al. (2008b). Nominal and off-nominal\nscenarios were evaluated. The traffic display implementation was the same as in the previous\ntwo activities, except a graphical position indicator (aka picnic table) was displayed (providing\nthe same information as that in previous NASA activities). The AGD displayed the IM speed and\nrange to the lead aircraft. When new IM speeds were presented on the AGD, they flashed for a\nset amount of time, depending on the difference between the current IAS and the IM speed.\nThe flashing was cleared when a speed was entered into the MCP (the speed did not need to\nmatch the IM speed) within 20 knots of the IM speed. Pilots reported the displays had the necessary information and that they understood how IM\nwas progressing. The authors speculated that there was less distrust of the algorithm and the\nassociated IM speeds than seen in Bone et al. (2008a). That was stated to be due to increased\ntraining and the removal of the differential ground speed on the AGD. Pilots spent more time viewing the CDTI traffic display when an overtake situation was\ndeveloping. Most pilots did not report a need for an aural alert to annunciate new IM speeds\nand opinions were varied on whether an aural alert is necessary if the IM speed has been\nignored for some period of time. An Aviation Communication & Surveillance Systems (ACSS) avionics implementation similar to\nthat studied in the MITRE simulations was certified, implemented on UPS aircraft, and used in\nlimited revenue flight starting in 2008. A field test of that operation is reported in Penhallegon\net al. (2016a). One noteworthy display outcome was that the visual-only alerting for new IM\nspeeds was reported by the pilots to be acceptable. After the ACSS and UPS implementation was fielded, IM research continued. Penhallegon et al.\n(2011) reported on a simulation investigating IM during the departure phase of flight. The CDTIs\ndiscussed in the 2006-2008 studies were largely based on the ACSS SafeRoute system that was\nhosted on a UPS flight deck implementation. The departure simulation, however, utilized a new\nCDTI that allowed for the integration, control, and operation of multiple ADS-B functions\n(Figure 2-35). The auxiliary / EFB displays for this activity were also in a different location and\nnearly perpendicular to the pilots forward position due to the desire to replicate certain actual\naircraft space constraints. The new locations were also closer to the pilots forward field of\nview. The traffic displays included new elements such as the lead aircraft route and information\nshown in a data block next to the lead aircraft (i.e., identification, ground speed, differential 2-48 ground speed [difference between lead aircraft and ownship groundspeed (sometimes referred\nto as closure rate in past activities)], range, aircraft category, and altitude). It also included an\nairspeed tape that showed three speeds: current IAS, MCP speed, and IM speed. Figure 2-35. CDTI Traffic Display with IM Features from Penhallegon et al. (2011) 2-49 The AGD included the lead aircraft identification, in-trail time, and the IM speed (Figure 2-36).\nNew IM speeds were indicated by depicting a box around the IM speed for 10 seconds (to be\nconsistent with the typical time period for PFD autoflight mode annunciation changes). Figure 2-36. AGD with IM Features from Penhallegon et al. (2011) Pilots showed high compliance with IM speeds and reported that the displays had the\nnecessary information. All display features were found to be useful and little discrimination was\nfound between the different elements. Target aircraft weight category had the most not very\nuseful ratings. Differential ground speed was rated overall as more useful than in-trail time;\nhowever, they were both rated highly which suggests that pilots used them together to obtain\nspacing trend / performance information. The information that differential ground speed\nprovides is whether the IM Aircraft is opening or closing on the target, and how quickly. The\ninstantaneous differential ground speed provided differences in ground speeds based on\ncurrent ground speeds, whereas the algorithm was basing the IM speeds on a past speed and\nposition of the target aircraft. Therefore, pilots would see the differential ground speed\nincrease as the lead aircraft slowed with no associated IM speed (the IM speed would arrive at\nthe future position where the target aircraft slowed, and not before). This seemed to lead some\npilots in other simulations into making a speed change and question why
the system was not\ncorrecting (e.g., Bone et al., 2008a). However, this effect was not necessarily observed in the\ncurrent study. The majority of pilots felt that they had a clear understanding of their spacing\nand how well it was being achieved. This, coupled with high IM speed conformance and\nminimal initiated speeds not issued by IM, indicated they appeared to trust the performance of\nthe system and were not confused by the differential ground speed. As with other simulations,\nthere were pilots that reported wanting more salient new IM speed annunciations, including\nmentions of an aural annunciation. 2-50 2.5.2.2 Flight Deck Display Spacing Information Research Needs\nAs can be seen from past work, much is understood about useful IM flight deck display\nfeatures. However, some questions remain open. Key topics that still need to be resolved are\nrelated to the necessary and appropriate spacing and trend information as well as the\nappropriate alerting associated with IM speed changes and deviations. Appropriate alerting to IM speed changes has been challenging to specify. Some pilots have\nexpressed a desire for aural alerting, though overall pilot feedback has been varied on whether\naural alerting is necessary at all, and, if so, for what issue (e.g., new IM speed, deviation from\nIM speed). There are also some concerns about the intrusiveness and the appropriateness of\naural alerting. This is an area where further study is necessary. For the spacing and trend information, past simulations have examined different display\nfeatures to support the flight crews in their desire to monitor the progress of and trust in the\nIM operation. The spacing information has taken on numerous forms including: current interval\nrelative to the ABP, projected interval at the ABP, differential ground speed, closure rate,\nstraight-line range, etc. Past work has shown that certain information can lead to confusion, additional workload and\nhead-down time, or lack of use. Most past work has found some analog, graphical display of\nthis information to be most useful. Some work has been successful in specifying and requiring a\nfeature for conveying required spacing relative to current spacing and spacing trend\ninformation (i.e., Hoffman et al., 2006). However, other past work has continued to recommend\n(e.g., Bone et al., 2008a; Baxley et al., 2014) a similar feature, yet the exact implementation has\nbeen difficult to specify / develop. DO-361 (RTCA, 2015a) includes requirements and\nrecommendations for a progress indicator that should now be considered in the design of such\na feature. This is an area that would benefit from additional study. The past work shows that an ideal, or even reasonable minimum, implementation has been\nchallenging to finalize. Some tools may also only be necessary for certain IM algorithms (e.g., a\nfast / slow indicator in the NASA work). This HITL simulation will continue to study these issues by examining the minimum\nimplementation defined in DO-361 (RTCA, 2015a) and an implementation that adds additional\nelements to increase pilot confidence in the operation. 3-1 3 Method\nA majority of the simulation methodology described in this section was reviewed with key FAA\nstakeholders during the concept evaluations (reviewed in Section 2.4.2.3). Reviews of the\nmethodology allowed the stakeholders to provide feedback that could be incorporated in the\nfinal simulation design. After incorporating inputs, dry run testing was executed with internal\nand external participants. Suggestions for changes from the development activities were\nincorporated prior to data collection activities. 3.1 Simulation Environment\nThe simulation was conducted in the MITRE IDEA Laboratory. The simulation utilized controller,\nflight crew, and pseudo-pilot workstations from past ADS-B simulations that were modified as\nnecessary for this effort. The following sections describe the utilized capabilities. 3.1.1 Flight Deck Workstation\nThe flight deck simulator consisted of a typical Boeing 777 flight deck layout as shown in Figure\n3-1. The equipment included standard elements such as a MCP, two radio management panels,\nEICAS, a Flight Management System (FMS) with CDU interfaces, dual PFDs, and dual navigation\ndisplays. The simulator also included a 180-degree out-the-window visual capability. New traffic\ndisplay components were added to accommodate IM (i.e., elements on the CDTI traffic display\nand AGD). Two CDTI traffic displays were hosted on auxiliary displays: one at the captains\neleven oclock position and the other located at the First Officers (FOs) one oclock position.\nThe AGD was located above the stand-by attitude indicator. The locations of the CDTI traffic\ndisplay and AGD are shown in Figure 3-2. The utilized CDTI traffic display and AGD elements\nwere based on requirements for ADS-B and IM (DO- 317B / RTCA, 2014, DO-361 / RTCA, 2015a).\nMost all the requirements were met, however, some were not implemented based on the\nexpectation that they would not be utilized in the simulation (e.g., IM turn requirements). The\nIM algorithm utilized was specified in DO-361 (RTCA, 2015a) and is described further in Section\n3.1.2. The flight deck IM equipment did not have an interface to the FMS or autothrottle system\nbased on the desire to examine a near-term, retrofit implementation. The following sections\nreview the IM implementation in detail. 3-2 Figure 3-1. Flight Deck Simulator Figure 3-2. CDTI Traffic Display and AGD Locations 3-3 3.1.1.1 CDTI\nPer DO-317B (RTCA, 2014, p. 96), the CDTI is defined as the displays and controls necessary to\nsupport [ADS-B In applications] \ncontrol sub-elements. Based on that definition, the CDTI implementation in this simulation\nconsisted of two display elements: the CDTI traffic display and the AGD. As noted previously, the IM features were based on requirements in DO-361 (RTCA, 2015a).\nDO-361 (RTCA, 2015a) specifies five CDTI states: Awaiting entry: IM operation is not yet active but system / input interface is ready for\nflight crew entry. Evaluate: IM information is being processed and is available for flight crew coordination\n confirmation. Execute: IM operation is active. Suspend: IM operation is temporarily inactive. Terminate: IM operation is complete / inactive.\nDO-361 (RTCA, 2015a) also defines over 20 information elements (e.g., IM speed, ASG, suspend\nindication, alerts) that have different display requirements per each of the five CDTI states.\nInformation elements are either required to be displayed, available to be displayed with simple\naction, or required to not be displayed. Some of the information elements are required to be\ndisplayed in the primary field of view. Other information elements are also recommended to be\ndisplayed (e.g., the graphical route of the lead aircraft). The required features were\nimplemented per the standard. Particular features of interest for this simulation and further\ndescription include the progress indictor, feasibility check status indication, and the IM speed\nconformance monitoring status visual advisory. The behavior of the IM speed conformance is defined in DO-361 (RTCA, 2015a). After an IM\nspeed is presented to the flight crew, an 11 second delay is activated that allows time for the\nflight crew and aircraft to react to the new speed. After the 11 seconds has transpired, the\naircrafts current speed is compared to an expected speed change profile (0.5 knots [kts] per\nsecond), built as a linear change of speed between the current aircraft speed and the IM speed.\nIf the aircraft deviates from that speed change profile by more than 5 knots (faster for a\ndeceleration or slower for an acceleration), the IM speed conformance visual and aural advisory\nis displayed to the flight crew. When the aircraft speed is brought within 5 knots of the IM\nspeed, the speed conformance monitoring stops and no additional advisories are provided.\nMonitoring is stopped at this point because the flight crew is within acceptable tolerances of\nthe IM speed. If any corrections are necessary after that point, a new IM speed will be\npresented and monitoring will be resumed. The HITL simulation implementation of the conformance monitoring and alerting\nunintentionally deviated from that defined in DO-361 (RTCA, 2015a). The HITL implementation\ntriggered the advisory at any speed off the expected speed change profile (i.e., the 5 kt\ntolerance was not implemented). It also advised after the aircrafts speed got within 5 knots of 3-4 the IM speed, but then again went greater than 5 knots of the profile speed (i.e., the\nmonitoring and alerting was not inhibited after the aircraft was within 5 knots of the IM speed). Per DO-361 (RTCA, 2015a), the feasibility check status indication was provided when the\nequipment determined the ASG could not be achieved even if the IM trail aircraft flew its\nfastest or slowest speeds relative to the speed profile. It was only provided during the achieve\nstage when greater than 30 NM from the ABP. A visual advisory was provided to the flight crew.\nIf the aircraft was unable to slow enough to achieve the ASG [as determined by the equation\n(Predicted Spacing Interval [PSI] + 0.15 x time-to-go [TTG]) < ASG], the flight crew was provided\nwith the message: Not feasible, ASG too large. If the aircraft was unable to speed up enough\nto achieve the ASG [as determined by the equation (PSI 0.11 x TTG) > ASG] the flight crew was\nprovided with the message: Not feasible, ASG too small. The multiplier for the TTG value is\nlarger because the aircraft has a greater capability to slow down than it does to speed up. For time-based ASGs, a progress indicator is required to be provided to the flight crew for\nsituation awareness information during the maintain stage and when within 30 NM of the ABP\nfor the achieve stage. At a minimum, the progress indication is defined as simply the display of\nthe numerical values of the ASG and either the PSI (during the achieve stage) or the Measured\nSpacing Interval (MSI) (during the maintain stage)3. The
progress indicator is one of the\ninformation elements that must be displayed in the primary field of view. The minimum implementation of the feasibility check and progress indicator in the context of\nthis simulation environment (described in 0) is shown in Figure 3-3. In that figure, the black text\nrelates to information provided when the aircraft is greater than 30 NM from the ABP and the\ngreen text relates to information provided when 30 NM or less from the ABP. Figure 3-3. Minimum Requirements for Feasibility Check and Progress Indicator 3 The MSI and PSI were, unintentionally, shown outside of 30 NM from the ABP in the simulation. However, the\namount of time that the participant flight crew was actively conducting IM outside of 30NM from the ABP was\nlimited, especially when the DERVL waypoint was the ABP. 3-5 A new feature that was examined in this simulation was called the graphical progress indicator.\nThe graphical progress indicator was a feature that was beyond the minimum requirements\nspecified in DO-361 (RTCA, 2015a) but thought by the authors to be a potentially useful feature\nand worthy of further examination based on the research reviewed and summarized in Section\n2.5.2. It was also a topic expanded upon in an appendix titled CDTI Design Considerations in DO-\n361 (RTCA, 2015a). The implementation utilized in the simulation incorporated both the\nfeasibility check and the progress indicator into a single display element. The feasibility check\nwas continued inside of 30 NM from the ABP and from the achieve to the maintain stage. The\nprogress indictor information was also provided in a graphical format. Figure 3-4 shows the\ngraphical progress indicator. Figure 3-4. Graphical Progress Indicator The band on the graphical progress indicator showed acceptable spacing tolerance and\nanywhere within the boundary was acceptable IM spacing. The triangle the showed MSI or PSI\nvalue. During the achieve stage, the graphical progress indicator displayed the PSI with the\nbounds defined by the feasibility check (reviewed in this section) narrowing to a constant value\nof +/- 15 seconds of the ASG. In the maintain stage, it displayed the MSI with the bounds\ndefined by +/- 15 seconds (3 SD / 99.7% tolerance) of the ASG. This is shown in Figure 3-5. The\ntransition from the PSI to the MSI was not annunciated to the flight crew because it was not\nbelieved to be useful information and it was not a minimum requirement. Figure 3-5. Graphical Progress Indicator Design / Behavior The ASG was known but not displayed on the graphical progress indicator. It was still available\nnumerically on the AGD. This was a specific design decision based on the desire to avoid the\nflight crew specifically targeting and chasing the ASG while within acceptable spacing as\nindicated by the band. The graphical progress indicator was intended to support flight crew\ntrust and understanding of the progress of the IM operation. It was also designed to avoid Late Early Dist (NM) to ABP Time\n(sec) 30 0 Achieve ASG\n+ 15 Maintain - 15 Feasibility\ncheck boundary then\n-15 seconds Feasibility\ncheck boundary then\n+ 15 seconds ASG PSI\nor MSI Late Early 3-6 leading the flight crew to outguess the IM algorithm and to implement speeds other than the\nIM speeds provided. Another above-the-minimum feature implemented on the CDTI was the speed tape, which was\nalso expected to be useful. The speed tape showed three speeds: the aircraft IAS, the speed set\nin the MCP, and IM speed. If all symbols aligned, the IM speed was set in MCP and aircraft was\nflying the IM speed. The speed tape was displayed on the CDTI traffic display and is shown in\nFigure 3-6. Figure 3-6. Speed Tape 3-7 The information provided on the CDTI traffic display and the AGD is shown in Figure 3-7 and\nFigure 3-8. The CDTI provided basic traffic information, and was used to set up and perform IM\noperations. The AGD served as the source of key IM information, including alert notification\n(i.e., advisory [ADV] flag), as specified in DO-361 (RTCA, 2015a). Two flight deck tool sets were\nexamined in the simulation. The first was termed min and was built to the standards specified\nin DO-361 (RTCA, 2015a). The second was termed min+ and included two features not\nrequired in DO-361 (RTCA, 2015a): the graphical progress indicator and speed tape. Figure 3-7. CDTI Traffic Display with IM Information Labeled Figure 3-8. AGD with IM Information Labeled 3-8 3.1.1.2 CDTI Traffic Display and AGD During CDTI States / Alerts\nThe following figures show sample CDTI traffic display and AGD displays during IM operations.\nThe implementations are shown with min+ implementation that was used in some scenarios. Figure 3-9 shows the CDTI traffic display and the transitions when entering information in the\ninterface. The screenshot on the left shows an aircraft selected and the Operation button at the\ntop center of the display. After pressing the Operation button, the display provided options for\nchoosing the ADS-B In application (as shown in the middle screenshot). Once IM was chosen,\nthe IM clearance options were shown. For the participant pilots in this simulation, only the IM\nachieve options were utilized. After selecting Achieve, the specific menu to IM achieve\noperations was displayed and the Pilot Monitoring (PM) then entered the necessary\ninformation by selecting a field and using soft keyboards to input the clearance. That menu is\nshown in the right screenshot and has the lead aircraft field (i.e., Behind) auto-populated\nbased on that aircraft being previously selected4. The lead aircraft field could be manually\npopulated if the lead aircraft had not been selected or a different aircraft had been selected.\nAfter entering the necessary information into the menu, a Confirm button was provided that\nallowed for cross-cockpit coordination with the PF. Once the confirm button was pressed, the\ndisplays transitioned to the evaluate state. Figure 3-9. CDTI Traffic Display and AGD During Awaiting Entry State 4 This feature is not a minimum requirement for a CDTI traffic display. 3-9 In the evaluate state, the menu with all the information entered along with the first IM speed\nwas shown to both the PM and the PF for review and coordination (Figure 3-10). The IM speed\nwas also shown on the AGD in white, to differentiate it from the green IM speeds in the execute\nstage. Once an SI and IM speed had been calculated and provided, an execute (Exec) button\nwas provided on the PMs CDTI traffic display (in the same location as the Confirm button).\nOnce both flight crew members agreed that the information was correct and the operation was\nfeasible, the PM pushed the execute (Exec) button. Figure 3-10. CDTI Traffic Display and AGD During Evaluate State 3-10 The displays during the execute state are shown in Figure 3-11. When a new IM speed was\npresented on the AGD, a white box surrounded the speed and remained for 10 seconds. The SI\nfield on the AGD presented the PSI if in the achieve stage and the MSI if in the maintain stage. Figure 3-11. CDTI Traffic Display and AGD During Execute State 3-11 Figure 3-12 shows the displays if the IM speed conformance monitoring status visual and aural\nadvisory was triggered. The AGD provided the flag for the advisory notification and the CDTI\ntraffic display presented the content of the advisory. This advisory message and all others were\nonly removed from the CDTI traffic display after the flight crew pressed the Msg Canc/Rcl\nbutton. Figure 3-12. CDTI Traffic Display and AGD During Execute StateIM Speed Conformance\nMonitoring Status Visual Advisory 3-12 Figure 3-13 shows the displays if the feasibility check status indication was triggered. The AGD\nprovided the flag for the advisory notification and the CDTI traffic display presented the content\nof the advisory. Figure 3-13. CDTI Traffic Display and AGD During Execute StateFeasibility Check Status\nIndication 3-13 Figure 3-14 shows the displays if a suspension occurred by the flight crew pushing the Suspend\nbutton. As can be seen, the majority of the information is removed from the AGD. A Resume\nbutton was provided on the CDTI traffic display which would call up the clearance menu (as\nshown in Figure 3-9 in the right screenshot) so that clearance information could be edited if\nnecessary. All fields could be edited except the lead aircraft identification. Figure 3-14. CDTI Traffic Display and AGD During Suspend State 3-14 When reaching the PTP or when IM was terminated by the flight crew pushing the Terminate\nbutton, the displays looked like those in Figure 3-15. The AGD provided the flag for the advisory\nnotification and the CDTI traffic display presented the content of the advisory. IM information\nwas removed from the displays. Figure 3-15. CDTI Traffic Display and AGD During Terminate State 3.1.2 IM Sample Algorithm\nThe IM algorithm used in the simulation was that defined in DO-361 (RTCA, 2015a). The\nparticipant aircraft only used the achieve-by then maintain IM clearance type while the pseudo-\npilot aircraft used both the capture then maintain IM clearance type and achieve-by then\nmaintain IM clearance type (with a maintain stage when there was no RNP RF turn, and without\na maintain stage for RNP RF turn operations). 3-15 The achieve operation was used when aircraft were on different routes at the start of the\noperation, as depicted in Figure 3-16. In the Achieve stage, the time-to-go algorithm was used.\nFour-dimensional reference trajectories were used to predict the lead and trail aircrafts times-\nto-go to the ABP, the PSI at the ABP (defined as the difference
between the trail aircrafts time-\nto-go at the ABP and the lead aircrafts time-to-go at the ABP), and the IM speeds. IM speeds\nwere calculated to drive the trail aircraft to an along-path position where its time-to-go to the\nABP was equal to the leads time-to-go plus the ASG (as shown by the light-blue dashed\nchevron in Figure 3-16). IM speeds were flown to make continual progress towards the ASG,\nwith higher error tolerances allowed when further from the ABP where the time-to-go\nestimates were subject to larger errors. As the trail aircraft got closer to the ABP, errors in the\npredicted times-to-go were decreased, and the IM speeds aided the flight crew in precisely\nachieving the ASG. Figure 3-16. IM Operation in the Achieve-by Stage TTG Time-To-Go Once the ABP was reached, the aircraft went into the maintain stage and the time-history\ncontrol law was used. A MSI was calculated during the maintain stage. The MSI was the\ndifference between the current time and the time when the lead aircraft crossed the trail\naircrafts along-path position. If the MSI is equal to the ASG (i.e., no spacing error), IM speeds\nwere calculated to drive the trail aircraft to match the ground speed of the lead aircraft at a\ntime equal to the ASG in the past. If there was a spacing error, the IM speed calculation\nincluded the trail aircrafts past speed plus a term that is proportional to the spacing error. The\nmaintain stage ended when reaching the PTP. The capture operation5 was used when aircraft were on, and would remain on, a common\nroute. Operationally, the behavior can be related to the achieve stage. However, the trail 5 DO-361 (RTCA, 2015a) requires extrapolation of aircraft positions at initiation if sufficient historical track data is\nnot available. This allows for the presentation of IM speeds until sufficient data is available and the spacing\ninterval and IM speed can be calculated without extrapolating. This requirement was not implemented for this\nsimulation due to a misunderstanding of the requirement. However, the authors do not believe that this gap in\nthe requirements affected the outcomes of the HITL. 3-16 aircraft captured the ASG (without a defined ABP) more quickly and then maintained the ASG\nuntil the PTP. The IM speeds were calculated as described for the maintain stage. For both operations, time-based ASGs were used. The IM speeds were presented in 10 kt\nincrements when greater than 10 NM from the ABP and in 5 kt increments when less than 10\nNM from the ABP and when in the maintain stage. The IM algorithm limited the IM speeds to\n+/- 15% of the arrival procedure profile speed. The IM speeds were also limited by the\nmaximum operating limit, the minimum final approach speed, and a regulatory restriction (250\nkts below 10,000 feet). 3-17 3.1.3 ATC Workstation\nThe ATC interface was hosted on a STARS display with added TSAS and IM functionality. The\nfollowing sections provide details on the implementations. 3.1.3.1 STARS\nThe terminal workstation had a representative 2K display that hosted a STARS interface that\nwas very similar to the currently fielded STARS system. The workstation had a STARS keyboard\nand trackball (Figure 3-17). Some keyboard entries were programmed to serve as special IM\nfunctions (described in Section 3.1.3.3). The STARS workstation software consisted of a\nTerminal Controller Workstation display (Figure 3-18), and contained the majority of the basic\nSTARS functionality. A key, relevant spacing feature presented was ATPA, which is a spacing\ntool used on the final approach course. It provided distance and alerting information relative to\nthe lead aircraft and the associated separation standard (Figure 3-19). The overall functionality\navailable for the simulation was found sufficient for the simulation by controller domain\nexperts during development and concept evaluation activities. Figure 3-17. STARS Keyboard 3-18 Figure 3-18. STARS-Like Display Figure 3-19. ATPA 3-19 3.1.3.2 TSAS Interface\nFor this simulation, TSAS and terminal metering were the foundation upon which IM was\nimplemented. The TSAS software code that was integrated into MITREs IDEA Lab was that used\nin the Operational Integration Assessment (OIA) event conducted in May of 2015 at the FAA\nWilliam J. Hughes Technical Center (Witzberger, Martin, Sharma, and Robinson, 2015). The\ninterface design was heavily based on those used in the OIA because a final design had not\nbeen specified and the OIA implementation was that used in the last major ATD-1 TSAS HITL\nsimulation activity. Minor modifications (e.g., sequence number and runway assignment field\nlocations) were made based on feedback from the concept evaluation activities leading up to\nthe HITL simulation. The TSAS features implemented included the following (shown in Figure\n3-20) as well as a timeline (shown in Figure 3-21). For more information on these TSAS features\nsee Section 2.1. Runway assignment Sequence number (for the assigned runway) Slot marker Slot marker speed Speed advisories or early / late indicators Aircraft IAS Timeline Figure 3-20. Prototype TSAS Features on STARS Z 6\nAAL652\n090 24\n180 A26 21 220 Slot marker speed Slot marker Sequence number Runway assignment Aircraft IAS\nSpeed advisory or\nearly / late indicator 3-20 Figure 3-21. Prototype TSAS Timeline on STARS 3-21 The appropriate time to remove the TSAS slot markers was discussed during the development\nof the simulation environment in the concept evaluation activities. At the time, it was expected\nthat the TSAS slot markers would not be shown for aircraft when ATPA is active unless there are\naircraft that are part of a RNP RF turn operation (Figure 3-22). It was stated that slot markers\nwould, at least, remain for the aircraft performing the RNP RF turn and the two aircraft that it\nwould go between (because the merge could be challenging for controllers without the slot\nmarkers). However, feedback from controller and ground experts indicated keeping the slot\nmarkers for all aircraft would be acceptable since the final design had not been specified and\nprevious work had slot markers present on final approach for all aircraft. Figure 3-22. RNP RF Turn Traffic Geometry During the development of the simulation environment, the impact of the TSAS features on IM\nwas considered. When using the TSAS features during terminal metering, the controller actively\nissues speed instructions to aircraft to get them on schedule. During IM, flight crews fly speeds\ngenerated within the flight deck to achieve the ASG issued by the controller. While the IM\naircraft is working toward the ASG, it may not be clear to the controller how well the operation\nis progressing or whether an aircraft will ultimately achieve the ASG or the underlying schedule.\nThis could cause the controller to be concerned about or pay extra attention to the IM aircraft.\nThe controller also needs to maintain awareness of which aircraft are conducting IM (and do\nnot need speed instructions) and which aircraft are not conducting IM (that may need speed\ninstructions). The use of the TSAS slot marker is likely to be affected by IM. Since IM is a relative spacing\noperation, an IM trail aircraft is only adjusting its path to move into its slot marker if the lead\naircraft is also doing so. While this relative spacing operation is also conducted by the controller\nat times (e.g., on final approach when not all aircraft are in their slot markers), it may be\nconfusing to the controller to have some aircraft doing it on their own via the IM speeds. IM may also lead to some confusion relative to the slot markers because it provides speeds to\nachieve the ASG at the ABP, while TSAS provides speeds to more constraint points and may get\nthe aircraft into the slot markers more quickly. In other words, it is expected that certain\ngeometries will lead to conditions where the IM trail aircraft are outside of their slot markers\nfor longer periods than aircraft being managed by controllers with TSAS features. IM working toward achieving the ASG at a single point, and TSAS managing to several constraint\npoints, could also lead to confusion if speed advisories and early / late indications are shown. 3-22 The speed advisories could be confusing if the controller sees a speed advisory that does not\nmatch the current IAS of an aircraft conducting IM. If the controller compares the speeds, it\ncould appear that IM will not meet the ASG. The early / late indication could be confusing for\nsimilar reasons. However, the equivalent of the TSAS early / late indication should probably still\nbe provided for IM if the ground system determines the IM cannot solve the spacing error. The other TSAS information elements including: runway assignment, sequence number for the\nassigned runway, slot marker indicated airspeed, aircraft indicated airspeed, and the timeline,\nare likely to be used by controllers in a similar way with or without IM. However, the aircraft\nindicated airspeed could be useful in helping the controller determine what speed the trail\naircraft flight crew is flying for IM. 3.1.3.3 IM Interface\nThe ATC IM interface was added to the lab implementation of STARS. The display was\ndeveloped in consideration of past work (e.g., Benson et al. 2011; Callantine et al., 2013) as well\nas an early draft of a preliminary design document developed within (but not released by) the\nFAA. The TSAS features were not modified for IM operations. However, the speed advisory and\nearly / late indicator were replaced by IM information for the trail aircraft. The TSAS speed\nadvisories have been reported as less useful for IM operations (Thipphavong et al., 2013) and\nremoved in other simulations (Callatine et al., 2012) as
well as concept evaluations prior to this\nsimulation. Three main features were added for IM: an IM clearance window, aircraft role in and status of\nIM in the aircraft data block, and a slot marker color change. This section will provide\nintroductory / background information and then review the specific features. IM states were shown in previous simulations, though not all the states were the same (e.g.,\nAligne et al., 2003; Benson et al., 2011; Baxley et al., 2016). For this simulation, the following\nstates were defined from a ground system perspective and were relevant to the IM interface: Pre-initiation: Automation is evaluating pairs of aircraft for IM. Eligible pairs are\npresented to the controller as an IM operation proposal. Initiation: Automation has proposed the IM clearance to the controller but the IM\noperation has not been started. Conduct: IM proposal has been accepted by the controller and is active if the controller\nissued the clearance and the flight crew engaged IM. Suspension: IM operation is temporarily inactive. Termination: IM operation is inactive.\nEach of the states can have sub-states related to the validity and feasibility of the operation (as\nshown in Figure 3-23). Transitions between states were either through controller or automation\naction. See Appendix A for further information on the validity and feasibility checks. Controller\ninputs to change states are shown in Table 3-1. 3-23 Figure 3-23. IM Clearance States and Transitions Active Active No Speed Active Invalid SuspendedEligible Eligible No Speed Eligible Invalid Resume (/ Active) Potential pair but\nfeasibility check failed Controller\ninput Validity\ncheck\nfailed Feasibility\ncheck failed\npassed / Controller\ninput Suspended No Speed Suspended Invalid Validity\ncheck\nfailed Feasibility\ncheck failed\npassed / Controller\ninput Terminated Terminated No SpeedTerminated Invalid Validity\ncheck failed\n passed Feasibility\ncheck failed\npassed / Controller\ninput Validity\ncheck\nfailed Feasibility\ncheck failed\npassed / Clearance\nremoved Controller\ninput RejectedClearance removed\nafter 30 seconds Clearance removed\nafter 30 seconds Potential pair Controller\ninput Validity\ncheck\nfailed Validity\ncheck\nfailed Validity\ncheck\nfailed From Eligible or Eligible No Speed 3-24 Table 3-1. STARS IM Prototype Controller Input Commands Desired outcome Input commands\nActivate / resume IM [MULTI FUNC] TA [SLEW TO TRAIL AIRCRAFT] [LEFT CLICK]\nTerminate / reject IM [MULTI FUNC] TT [SLEW TO TRAIL AIRCRAFT] [LEFT CLICK] Suspend IM [MULTI FUNC] TS [SLEW TO TRAIL AIRCRAFT] [LEFT CLICK]\nRe-propose rejected IM [MULTI FUNC] TE [SLEW TO TRAIL AIRCRAFT] [LEFT CLICK] Acknowledge alert [SLEW TO TRAIL AIRCRAFT] [LEFT CLICK] Prior to providing the clearance information to the controller, validity checks were conducted\n(see Appendix A). Validity checks were made to determine whether the criteria for initiating IM\nwere met. If any of the validity check failed, the clearance was not proposed to the controller.\nFeasibility checks were also conducted prior to proposing and during any eligible IM clearance\nproposal. Feasibility checks determined whether the IM operation could achieve the ASG with\nspeed alone (the equivalent of the TSAS early / late indicator). If any of the feasibility checks\nfailed, that information was presented to the controller in the status field as Eligible No\nSpeed. In order to overcome the feasibility issue, the controller needed to provide a vector or\nspeed greater or less than that IM would provide (i.e., greater or less than 15% of the profile\nspeed). Feasibility checks were also conducted during the suspended and terminated states\n(see Appendix A). 3.1.3.3.1 IM Clearance Window\nBased on past work, it was determined that an IM clearance window should be used to provide\ninformation that the controller would communicate as part of the IM clearance. The STARS\ndisplay did not have a metering list to integrate the IM information into, so one had to be\ndeveloped. It was determined that the clearance window should also show the status of the clearance\ninformation (e.g., a proposed IM clearance versus an active IM operation). The information\nprovided in the IM clearance window is expected to support that shown in the data block. Such\ninformation may be necessary if not all states are shown in the data block (e.g., suspension or\ninvalid) or may be necessary to specify that status of each pair in the list so data blocks do not\nneed to be cross referenced. Four of the five defined states were shown to the controller. Pre-initiation and initiation were\ncombined and labeled as Eligible. Conduct was labeled as Active. Suspension and\ntermination were labeled as Suspended and Terminated respectively. If the clearance was determined to be valid and feasible, the clearance information and an\nEligible status was provided in the IM clearance window to the controller with the trail\naircraft. The information in the IM clearance window was only shown to the controller with the\ntrail aircraft, whether or not that controller also had the lead aircraft. The clearance could be\naccepted or rejected by the controller. If the clearance was rejected, the Status field changed to\nRejected. The text remained for 30 seconds prior to the full IM clearance proposal being 3-25 removed. This delay allowed for awareness of the rejected operation and to allow for re-\nactivation if the rejection was in error. If an operation had been rejected, it was not proposed\nagain to the same controller / sector. However, it was proposed to the final controller. The\nsame held true for terminated operations. If the clearance was accepted, instead of rejected,\nthe status field changed to Active. The order of the IM clearances in the IM clearance window were based on the runway\nsequence. This means a new proposal did not always appear at the top of the list but could\nappear somewhere further down the list based on the lead aircraft sequence number for the\nrunway. This order was consistent with the order of the TSAS timeline. The text in the window was color-coded to indicate different statuses (shown in Figure 3-24 and\nsummarize with other information in Table 3-2 at the end of this section). White text indicated\nan action was possible (i.e., activation possible). The white text status states were one of the\nfollowing: Eligible, Eligible No Speed, or Suspended. Green text indicated an IM\noperation had been accepted by the controller. The status state was Active. Yellow text\nindicated an action was required (i.e., termination or a maneuver). The yellow text status states\nwere one of the following: Active Invalid, Active No Speed, Suspended Invalid,\nSuspended No Speed, or Terminated, Terminated Invalid, or Terminated No\nSpeed. Dark gray text indicated the information was going to be removed (based the proposal\nbeing inactive). The dark gray status state was Rejected. Note that the Terminated status\nwas intended to be dark gray instead of yellow but the mismatch was not detected in time to\ncorrect the error before data collection. Figure 3-24. IM Clearance Window IM information Trail Aircraft Clearance Type Spacing Goal Lead Aircraft (sector) ABP Lead Aircraft Route Status SWA1825 Achieve 85 (72) AWE209 DERVL EAGUL6 Eligible SWA947 Capture 83 (99) AAL431 Rejected AAL529 Achieve 100 (115) AAL227 DERVL EAGUL6 Active No speed SWA1011 Capture 93 (99) SWA2053 (F) Active 3-26 Each of the fields in the IM clearance window are labeled and were in the same order as was\nexpected in the issuance of the IM clearance over the voice frequency. Fields of note will be\nreviewed next. The clearance types used in the simulation were achieve-by then maintain and capture then\nmaintain. They were abbreviated as Achieve and Capture for brevity in the display and\nwhen issuing the clearance over the voice frequency. The ASG in the spacing goal field, was\ncalculated by TBFM and was the trail aircraft STA at the ABP minus the lead aircraft STA at the\nABP. The ASG had an IM aware buffer reduction of 0.1 NM based on the expected low\nspacing variance provided by IM (as compared to metering only operations). The ASG was\npresented with a 1-second resolution. Next to the ASG was a spacing prediction value in parentheses (shown in some scenarios).\nBenson et al. (2011) and Aligne et al. (2003) reported that controllers found the predicted\ninterval at the ABP to be useful. It may become more critical as the ABP is close to or within a\ncontrollers airspace, as was the case for this simulation. Peterson et al. (2012) also reported\ncontrollers finding it useful to having delay information. However, only a slight majority of\ncontrollers reported that the MTE was useful for maintaining awareness of IM operations. Since\nthis information is not available in the TRACON with TSAS, it was added with the granularity\nreduced to second (from a minute shown in en route). For achieve operations, the difference\nbetween the TSAS-calculated trail aircraft ETA at the ABP and the lead aircraft ETA at the ABP\nvalue was shown. For capture operations, the difference between the TSAS-calculated trail\naircraft ETA at the FAF and the lead aircraft ETA at the FAF value was shown. These values were\nprovided to allow the controllers to compare the spacing estimated by TBFM / TSAS (ETA\ndifferential / prediction) to the ASG and to determine how the operation was progressing. After the lead aircraft identification in the lead aircraft field, the sector of the lead aircraft was\nincluded if both aircraft were not in the same sector (in case coordination between the\ncontrollers was necessary). The ABP was either DERVL (the merge point) or YOKXO (the FAF and\nRNP RF turn final approach intercept) (later shown in Figure 3-32). The lead aircraft route was\nthe IFPI of the lead aircraft. If it was a capture operation, the lead aircraft route was not shown\nsince it is a requirement that both aircraft be on the same route to conduct
the capture\noperation (which was checked by TBFM in this simulation as noted in Appendix A). It was also\nnot shown so the controller knew that it was not necessary to convey in the IM clearance. If\nthe routes were different because the achieve operation was being conducted, the three\noptions for the lead aircraft route were: EAGUL6, BRUSR1, and BRUSR1.RNP (i.e., the BRUSR1\narrival with the RNP RF turn). 3-27 The clearance information was removed for the feeder controller during a handoff of active IM\noperations two minutes after the handoff of the trail aircraft. This delay was utilized to avoid IM\ninformation being cleared from the IM clearance window when a handoff of the trail aircraft\nwas accepted prior that aircraft crossing the sector boundary. It was desirable to have the IM\ninformation cleared from the IM clearance window when the trail aircraft crossed the sector\nboundary, but it was reported that this information was not readily available within the STARS\nsystem. Two minutes was chosen as a reasonable number to test. Further testing would be\nneeded to determine whether two minutes is reasonable. The clearance information was\nremoved for the final controller when the trail aircraft landed. 3.1.3.3.2 Other IM Information on the STARS Display\nIM information was also provided in other locations on the STARS display. The aircraft role in\nand status of IM indications are shown in Figure 3-25. The information for the trail aircraft was\nshown in the third line of the data block. The field was not time-shared with other information. Figure 3-25. Prototype IM Features on STARS Z 6\nAAL652\n090 24\nT(A) A26\nL(A) 21 220 Blue slot marker Trail aircraft status\nLead aircraft status 3-28 As mentioned previously, the information for the trail aircraft replaced the TSAS speed advisory\nand early / late indication because IM was the speed solution, and thus, the TSAS speed\nadvisories become unnecessary. However, an early / late indication relative to IM operations\ncould still be a key piece of information. As mentioned previously, such information was shown\nin the IM clearance window. The status states for the trail aircraft were one of the following: T(E) / eligible, T(A) / active,\nT(S) / suspended, T(I) / invalid, or T(NS) / No Speed. Termination was not shown. The\ntransitions between the major states are shown in Figure 3-26. The transitions to infeasible / no\nspeed states is shown in Figure 3-27. The infeasible state was only shown in yellow / as alerted\nfor active of suspended operations because controller action was required prior to the\noperation returning to an active state. 3-29 Figure 3-26. IM Information in Trail Aircraft Data Block 3-30 Figure 3-27. IM Information in Trail Aircraft Data Block When Transitioning to a No Speed (NS) Solution 3-31 Based on positive feedback in previous simulations (e.g., Thipphavong et al., 2013), lead aircraft\ninformation was also shown in the aircraft data block. The information for the lead aircraft was\nshown in the fourth line of the data block and did not replace any TSAS features. The field was\nnot time-shared with other information. The status states were one of the following: L(A)/\nactive and L(S)/ suspended. The lead aircraft was shown as active during invalid and infeasible\nstates so the controller had awareness that the lead aircraft was part of an IM operation that\nthe trail aircraft controller had not yet terminated. During the invalid and infeasible state, the\ncontroller with the trail aircraft was either working to correct the issue or would soon terminate\nIM. It was not expected that the lead aircraft controller needed to be notified of invalid and\ninfeasible states when the trail aircraft controller was working on the issue. It was expected to\nbe sufficient for the lead aircraft controller to simply know the lead aircraft was part of an\nactive operation. Therefore, the lead aircraft controller was only notified when the lead aircraft\nwas part of an IM operation. The lead controller was not notified of a proposed, infeasible, or\ninvalid operation. The lead aircraft controller was notified of a terminated operation by the\nremoval of IM information. The transitions between the major states are shown in Figure 3-28.\nIf an aircraft acted as both a lead and trail aircraft, the information was the same as shown in\nthe figures but the trail and lead information would be present in one aircrafts data block. The capability of an aircraft to conduct RNP RF turns was also shown in the aircraft data block\nand was shown as /W after the aircraft flight identification. Although it would have been\npreferable to show the /W after the aircraft type, it was not possible due to the available\ndevelopment time. Table 3-2 summarizes the information shown in the IM Clearance Window and the data blocks. 3-32 Figure 3-28. IM Information in Lead Aircraft Data Block 3-33 Table 3-2. Summary of Displayed IM Information in the IM Clearance Window and Aircraft\nData Blocks Stage State IM clearance window\npresentation text and (color) Trail aircraft\ndata block presentation Lead aircraft\ndata block presentation Pre-Initiation\nValid and feasible Eligible(white) T(E) None Infeasible Eligible No Speed(white) T(NS) None Initiation Valid and feasible Eligible(white) T(E) None Invalid None1 None1 None1 Infeasible Eligible No Speed(white) T(NS) None Conduct Valid and feasible Active(green) T(A) L(A) Invalid Active Invalid\n2 (yellow) T(I)\n2 L(A) Infeasible Active No Speed\n2 (yellow) T(NS)\n2 L(A) Suspension Valid and feasible Suspended(white) T(S) L(S) Invalid Suspended Invalid\n2 (yellow) T(I)\n2 L(S) Infeasible Suspended No Speed\n2 (yellow) T(NS)\n2 L(S) Termination Valid and feasible Terminated(yellow) None None Invalid Terminated Invalid(yellow) None None Infeasible Terminated No Speed(yellow) None None Notes\n1. The clearance proposal is removed so no information is shown. 2. An alert is associated with this information. The alerts are triggered during Active and\nSuspended stages. Alerts are not triggered if the IM operation is at the Pre-Initiation, Initiation,\nor the Termination stages since the controller has not started or has ended the IM operation. 3-34 3.1.3.3.3 Slot Marker Color Change\nAt the concept evaluation activities, it was determined that continued examination of the IM\nlead aircraft behavior relative to the slot markers was important for acceptable integration of\nIM and TSAS operations. At least two resolutions were discussed: the first was to make TSAS\nspacing and IM spacing operations more similar. A second option was to make modifications to\nthe TSAS slot markers for IM trail aircraft. Making IM behave similar to TSAS was considered less feasible than making modifications to\nthe slot marker. Three possibilities for slot marker modifications were considered. One option\nwas to remove the slot marker for the IM trail aircraft. This would completely remove key\nschedule information and relative spacing information. Controllers use the TSAS slot markers to\ndetermine how to manage relative aircraft positions. If controllers are dealing with a set of\naircraft where: (1) the lead is behind its slot marker, (2) it will be difficult to get that aircraft\nback into it slot marker, and (3) there is sufficient space between subsequent aircraft, the\ncontroller will make sure the trail aircraft is also behind its slot marker to ensure spacing /\nseparation. Slot markers are a key visual cue to determining that relationship. Therefore,\ncomplete removal of the slot markers was determined to be undesirable. A second possibility was to modify the slot marker for IM trail aircraft to make it a relative\nspacing slot marker. For reasons similar to those mentioned above, this may be undesirable as\nit removes information that conveys the underlying absolute spacing schedule. A third\npossibility was to keep but modify the existing slot marker by adding IM spacing information to\nit. This option continues to convey the information related to the underlying schedule, and adds\ninformation about how well the IM trail aircraft is achieving its ASG in relation to the lead\naircraft. The exact method for implementing this was not determined. Options for modifying the slot markers to make them convey relative spacing were tested but\nnot presented to participants in the first two concept evaluations. Additionally, initial fast-time\nstudies were conducted to determine how often the IM trail aircraft would be expected to\ndeviate from the slot markers. The fast-time simulations were expected to be used to\nunderstand the expected behavior and to determine whether slot marker manipulation was\ndesirable. Only preliminary data was available at the time of the third concept evaluation so\nthat data was presented to the controllers so they could be informed of the expected behavior\nthey would see in the laboratory. Therefore, none of the slot marker modifications mentioned\nabove were implemented. However, the third evaluation did include simply changing the color\nof the slot marker to blue (instead of white) for the IM trail aircraft. The goal was to see\nwhether simply differentiating IM trail aircraft from non-IM aircraft allowed the controller to\naccept the different behavior of the IM trail aircraft based on knowing who was conducting IM\nat a glance. In other words, the controllers could note that any aircraft with a blue slot marker\nmay be off its slot marker, but would be working toward that slot marker while conducting IM\n(and therefore, did not need to be issued a speed). Controllers in the third evaluation found it was helpful to differentiate the IM trail aircraft,\nthough this did not overcome all concerns about IM aircraft not being in the slot markers.\nControllers did appear to have a better understanding of IM spacing behavior and reported\nseeing aircraft closing to their ASG. However, they still expressed concern about on-going
3-35 deviations from the slot markers in the feeders airspace. They reported that their goal was to\nget all aircraft into their slot markers so that the handoff to the final controller would be\nacceptable and that they felt uncomfortable when aircraft were not in the slot markers. Based on this feedback, it was decided that the slot marker color modification (shown in Figure\n3-25) was a good initial change to test. Therefore, the chosen modification to test was the trail\naircraft slot marker color change from white to blue during some scenarios when controller\nmade the keyboard entry to indicate IM was active. The slot markers for trail aircraft remained\nblue when an IM trail aircraft was in the suspended state but returned to white when controller\nmade the keyboard entry to indicate IM was terminated. The slot markers for trail aircraft and\nall other aircraft remained white. 3.1.3.3.4 Controller Tool Sets for Evaluation\nThe following three IM tool sets were developed for the simulation to examine the controller\ninformation needs: Basic: TSAS features, the IM clearance window, as well as the IM trail and lead aircraft\nstatus fields in the data blocks Basic+ cue: The basic tool set plus the slot marker color change (cue) Basic+ cue and prediction: The basic+ cue tool set plus the spacing prediction value\n(shown in parentheses after the lead aircraft identification in the IM clearance window) 3.1.4 Pseudo-Pilot Workstation\nPseudo-pilots acted as pilots for all (some IM capable and some not IM capable) aircraft other\nthan the participant flight crews aircraft. This allowed the controller to interact normally with\nthe traffic. It also allowed aircraft to maneuver based on controller instructions, which is\nreflected on both the controller and flight crew displays. The pseudo-pilots used an interface\ntermed Simpilot which allowed users to simultaneously control multiple simulated aircraft\n(Figure 3-29). It provided basic information about the aircraft (e.g., aircraft call sign, type) and\nallowed the pseudo-pilot to control various aspects of the aircraft (e.g., heading, airspeed,\naltitude, route, communications frequency) and respond to controller instructions by entering\ncommands. The pseudo-pilots also initiated, suspended, resumed, and terminated IM per instructions from\nthe controller. When the controller entered the command to accept the IM clearance, a pop-up\nwindow with the clearance information was displayed to the pseudo-pilot. Once the controller\nissued the IM clearance via a voice communication, the pseudo-pilot acknowledged the\nclearance and then pressed ok in the window to engage the IM sample algorithm. This\nimplementation was to assist the pseudo-pilot (who was managing several aircraft) in entering\nall the information associated with the IM clearance. However, it made the acceptance and\nentry of the clearance easier than it was for the participant aircraft flight crews and is more like\na CPDLC implementation that allowed for loading of the IM clearance into the fight deck IM\nequipment without the need to memorize or write down the information and then type it in. 3-36 Figure 3-29. Pseudo-Pilot Interface (Simpilot) 3-37 3.1.5 Airspace\nThe airspace modeled for this simulation was based on Phoenix International Airport (KPHX).\nNorth RNAV operations were run and aircraft landed to the west on runway 26, which was\noperated as a landing only runway. Aircraft also landed on runway 25L but as independent\noperations (even though real-world operations at KPHX are not run independently). The airport\nenvironment is shown in Figure 3-30. The weather was visual meteorological conditions. Figure 3-30. PHX Airport. The two RNAV arrival procedures (BRUSR1 and EAGUL6) that were used were heavily based on\ncurrent arrival procedures. Minor modifications were made to have the arrival connect to the\ninstrument approach procedure. Modifications were also made to accommodate the RNP RF\nturns. RNP RF turns onto final approach can be challenging for controllers but are expected to\nbe supported by TSAS and will continue to be part of arrival and approach procedures in the\nterminal metering environment (Wynnyk and Kopald, 2013). Therefore, they were examined to\ndetermine the impact of IM. The airspace had one feeder (Apache airspace) and one final (Freeway airspace) position. Figure\n3-31 provides an overview of the airspace. The waypoints and the associated altitude and\nspeed constraints for the arrival procedures as shown in Figure 3-32. The TSAS constraint points\nused in the simulation were RHYAN (RNP RF turn start), DERVL (merge point outside final), and\nYOKXO (FAF). 3-38 Figure 3-31. PHX-Like Airspace Overview: Arrival Procedures and Controller Airspace Figure 3-32. Arrival Procedures 3-39 Based on the arrival and approach geometries, a mix of different types of aircraft pairings could\noccur. For example, aircraft flying RNAV arrivals could follow aircraft flying the same or a\ndifferent RNAV arrival. An aircraft flying the BRUSR1 arrival with the RNP RF turn could follow\nanother aircraft flying the RNP RF turn, or it could follow an aircraft flying either RNAV arrival\nwithout the RNP RF turn. Aircraft flying either arrival could follow an aircraft flying the BRUSR1\narrival with the RNP RF turn. The geometries are shown in Figure 3-34 on the next page (with\npotential IM pairings noted). One of the more interesting geometries is shown in Figure 3-33,\nwhere an aircraft flying the BRUSR1 RNAV arrival is following an aircraft flying the BRUSR1 with\nthe RNP RF turn. The sequence to the runway designed by TBFM can initially appear confusing if\nthe RNP RF turn is not considered. Figure 3-33. Geometry Where RNAV Aircraft is Following RNP RF Turn Aircraft on the Same\nArrival 3-40 Figure 3-34. Traffic Pairing Geometries 3-41 The IM operations were Multi-Stream Arrivals with Metering, as defined in Hicok and Barmore\n(2016) (Figure 3-35). Figure 3-35. Sample IM Operations with the PTP and ABP Options 3.1.6 Traffic\nSimulation traffic included the participants aircraft along with other aircraft arriving from the\nnorth for the RNAV approach to Runway 26 (as shown previously in Figure 3-31). Aircraft also\nlanded on runway 25L, but as independent operations. Attempts were made to develop traffic\nflows that were high density and kept the controller workload at a high but reasonable level.\nThe arrival rate was approximately 40 aircraft per hour to Runway 26. The higher workload\nenvironment was desirable to keep the controllers engaged, but not so much that disturbances\nin the traffic flow occurred (and vectoring became necessary). The intent was to examine the\nintegration of IM operations in the terminal metering environment without disturbances. The\ndensity of the flow was modified several times prior to selecting the final density for data\ncollection based on controller and ground expert inputs during the concept evaluations.\nEquivalent traffic levels were used through the entire simulation to avoid workload differences\nbetween scenarios. Each traffic file was derived from real world traffic files with arrivals to\nKPHX. At scenario start, traffic started arriving from the two flows and gradually built to the full\ndensity of traffic that lasted until the data collection was complete for the scenario and the 3-42 scenario was terminated by one of the researchers (typically at the point where the participant\naircraft landed and / or when the final off-nominal event occurred). All aircraft in the simulation were capable of flying the RNAV arrivals. There was a mixture of\naircraft that were capable of flying the RNP RF turn (approximately 20%) and aircraft that were\nnot capable of flying the RNP RF turn (approximately 80%). This RNP RF turn capability split was\ncoordinated with key stakeholders and believed to represent a reasonable number of aircraft\ncapable in the future of flying the more challenging routing. All aircraft in the simulation were ADS-B out and capable of as acting as an IM lead aircraft.\nThere was a mixture of aircraft that were capable as acting as an IM trail aircraft (approximately\n60%) and aircraft that were not capable as acting as IM aircraft (approximately 40%). This IM\ncapability split was also coordinated with key stakeholders and believed to represent a\nreasonable mix of aircraft. It was also an increase over past work done under ATD-1 (as\nreviewed in Section 2.4.2.2). However, it is reasonably short of 100% equipage, which is unlikely\nto be realistic in the near term and may be easier to manage based on not having to deal with\nthe difficulties of mixed equipage. The participant aircraft was always IM capable (except in one\nbaseline condition). Aircraft were delivered from the en route environment to the TRACON boundary with a set\ndeviation around the center of the slot markers, which simulated the management of aircraft\nby an en route controller prior to them entering the TRACON. Aircraft arrived no earlier than 30\nseconds and no later than 15 seconds, with a distribution between those maximum values. The\nexpected delivery for terminal metering operations is approximately +/- 30 seconds (Robinson\net al., 2015). However, based on aircraft being able to more easily decelerate than accelerate in\nthe TRACON, and the chosen arrival procedures, the 15-second threshold was chosen for this\nactivity. This is consistent with a simulation reported in Callatine et al. (2014) in which en route\ncontrollers were asked to deliver aircraft +/- 30 seconds with a preference for the early side. Pseudo-piloted aircraft were mainly large but also included heavy category aircraft. Aircraft\ntypes included: Airbus A306, Airbus A319, Airbus A320, Airbus A321, Boeing 717-200, Boeing\n737-300, Boeing B737-700, Boeing 737-800, Boeing 737-900, Boeing 767-300, Bombardier\nCRJ200, Bombardier CRJ700, Bombardier CRJ900, McDonnell Douglas DC-10, McDonnell\nDouglas MD-11, and McDonnell Douglas MD-90. Pseudo-piloted aircraft flew final approach\nspeeds of either 140 or 150 kts6. The aircraft started to slow to the final approach speed at the\nFAF. Pseudo-piloted aircraft that performed
the achieve or capture IM clearance types used the\nIM sample algorithm. The speeds were not entered by the pseudo-pilots, but were flown\nautomatically once the pseudo-pilot engaged IM. The participant flight crew aircraft was always capable of RNAV (but not the RNP RF turn) and\nIM. The participant aircraft utilized the IM sample algorithm and always flew an achieve IM\nclearance type. 6 TBFM assumed a final approach speed of 140 kts for all aircraft. 3-43 3.2 Participants\nParticipant controllers were coordinated through the FAA and NATCA. The standard procedures\ninvolved submitting a request with specific requirements, followed by approvals, and finally\nidentification of participants. Controllers were compensated for their participation through\nstandard FAA processes. Controller requirements included: Currently working at an ATC-10 or above STARS-equipped TRACON facility At least 2 years of experience as a Certified Professional Controller (CPC) Certified, operationally current, and holding a valid medical certificate (temporarily\nmedically disqualified may qualify if current) No prior TSAS simulation experience Twelve controllers were desired for the simulation, but recruiting difficulties lead to nine total\ncontrollers participating. The controllers acted as TRACON final and feeder controllers and were\nfrom a variety of TRACONs, including: Atlanta (A80), Charlotte (CLT) [x2], Miami (MIA), Orlando\n(F11), Philadelphia (PHL) [x2], Potomac (PCT), and Tampa (TPA). The tower controller positions\nwere not staffed. Controllers had an average experience of 15.4 years (with a minimum of 7\nyears and a maximum of 30.5 years) actively controlling air traffic. The average age of the\ncontrollers was 39 years with a minimum of 30 years and a maximum of 53 years. Flight crews were recruited by MITRE. A request for participation was developed and\ndistributed to members of the MITRE database. The request stated that each pilot was required\nto be an Air Transport Pilot (ATP), have at least 100 hours of Federal Aviation Regulation Part\n121 glass cockpit experience, be qualified in turbojet aircraft with auto throttles, and have\noperated an aircraft using their ATP rating within the last 12 months. Pilots were told they\nwould be compensated for their participation. It was desirable to have both pilots be from the same airline and to have a pairing of a Captain\nand a First Officer (FO) for each simulation day. However, prior to recruiting, it was determined\nthe results were not likely to be affected by not meeting either of these conditions. Therefore,\nthese were determined to be goals but not requirements. A total of 18 pilots (acting as nine flight crews) were recruited and participated in the study.\nSeven of the pilots were qualified as Captains and 11 were FOs. Their estimated average total\nflight hours was 10,110 hours (with a minimum of 2500 hours and a maximum of 25,000 hours).\nThe pilots were currently flying a variety of aircraft types, i.e., Airbus A319, A320, and A321, as\nwell as Boeing 717, 737, 747, 757, 767, and 777. During the simulation, one pilot acted as the\nPF, and one pilot acted as the PM. The roles were not switched during the simulation. MITRE staff members acted in two to four pseudo-pilot positions (depending on the number of\ncontroller participants). The authors served as observers for both the flight crew controllers. 3-44 3.3 IM Operations\nThe IM operations conducted in the simulation were as described in Section 2.2.1. This section\nnotes some specific topics where changes, or specific implementation decisions, were made for\nthis simulation. 3.3.1 Procedures\nControllers were instructed to manage aircraft and sector operations as normal for TRACON\nfacilities. They were also asked to keep aircraft on their RNAV or RNP RF route while using the\nTSAS features and IM to achieve the schedule. They were told to intervene when necessary for\nspacing or separation issues. Controllers were reminded that if they intervened when aircraft\nwere flying the profile speeds on the arrival that they needed to direct the aircraft to resume\nthe profile / normal speed. They were told to clear aircraft for the instrument approach when\nacting as a final controller. Finally, the controllers were asked to hand off all aircraft to the\ntower controller around the FAF. This is common at some facilities but less common at other\nfacilities. Handing off around the FAF gave a consistent hand off point and allowed the\ncontroller to monitor IM operations for as long as reasonably possible. For metering operations, controllers were told that the TSAS speed advisories were additional\ninformation for issuing an appropriate speed and that they did not need to be implemented\nexactly as presented. Controllers were asked to conduct IM and follow IM procedures and phraseology for any\naircraft that was IM capable. Controllers were told that only the feeder controller should issue\nthe IM clearance. They were asked to issue as many IM operations as possible, but that they\ncould reject a proposed IM clearance if there was an operational reason to do so. They were\ntold that when a no speed issue was presented to them, IM was possible between the pair of\naircraft if a more aggressive speed assignment (than the 15% of the profile speed restriction) or\nvector was utilized prior to initiating IM. They were also reminded that coordination was\nnecessary between the lead aircraft controller and the trail aircraft controller if the lead aircraft\ncontroller needed to vector that aircraft. Pilots were told they would be assigned the role of PF or PM and would remain in that role\nthroughout the simulation. They were told to follow normal cockpit procedures and if there\nwere differences in airline policies they should agree on an approach during training. They were\nalso asked to fly the flight deck simulator as if it were a large category aircraft (versus a heavy).\nThis was done based on expectations of having a larger pool of large category aircraft pilots and\nbecause the aircraft model was more similar to a large aircraft model. Pilots were briefed that the PM should enter the IM clearance information and then coordinate\nwith the PF on the entered information and the first IM speed prior to executing IM. They were\nreminded that their tasks were to fly the IM speeds and to monitor the IM operation. They\nwere told that the IM speeds overrode the profile speeds and that they should not announce\neach IM speed to the controller. They were told that if the IM speed conformance advisory was\ntriggered, that they should ensure the appropriate speed was set in the MCP and the aircraft\nwas working toward the IM speed. Pilots were told that if the feasibility check was triggered 3-45 (and they could not continue IM), to fly the current speed, contact ATC, and report unable\ninterval spacing. When the feasibility check was not in effect, but the pilots had either the\nprogress indicator or the graphical progress indicator, they were told they should determine\nwhether IM was progressing toward the ASG. If not, they were told to maintain the current\nspeed, contact ATC, and report unable interval spacing. Pilots were told that the graphical\nprogress indicator showed the acceptable tolerances of spacing and that they should not\ndeviate from IM speeds to keep the triangle symbol centered. The PF was told to fly the IM\nspeeds unless conditions prevented it or there were other operational reasons not to do so.\nThe PM was told to call out any nonconformance with IM speeds or infeasible indications. Pilots\nwere told they did not need to monitor for separation issues, as that remained the\nresponsibility of ATC. 3.3.2 Communications\nThis section will describe the specific communications used in this simulation. The phraseology\nwas developed based on the most recent IM communications material at the time of simulation\ndesign (DO-328A / RTCA, 2015b, DO-350A / RTCA, 2016a, DO-351A / RTCA, 2016b). During the\ndevelopment of DO-350A (RTCA, 2016a) and DO-351A (RTCA, 2016b), controllers reported\nissues with the use of the terms interval management or IM. The discussion led to the use\nof interval spacing in that material. Therefore, that term was used in this simulation. Steps\nwere taken to keep the IM clearance concise (e.g., avoiding using the PTP in the clearance by\nmaking it part of the procedure and known to pilots [shown in the arrival and approach\nprocedures] and controllers) The controllers had four specific IM communications: Initiation (samples) o AAL245 achieve 100 seconds by DERVL behind United 123 on EAGUL6 o SWA2598 capture 78 seconds behind FDX783 Suspend o Suspend interval spacing with speed instruction Resume o Resume interval spacing Terminate o Terminate interval spacing with speed instruction The controllers were asked to issue the IM clearance only as feeder controllers. However, either\nthe feeder or final controller could suspend, resume, or terminate IM. The final controller was\nresponsible for issuing the approach clearance for the RNAV approach with or without the RNP\nRF turn. The phraseology consisted of: Cleared RNAV runway two six approach or Cleared RNP runway two six approach 3-46 Flight crews were told to perform normal readbacks. The only new phraseology for the flight\ncrews was when reporting being unable to continue IM. They were told to say: Unable interval spacing 3.4 Simulation Procedures\nA total of eighteen pilots participated in the simulation. Two pilots participated for one day per\npair over the course of nine days. Controllers participated for a total of five days. During\nsimulation planning, the expectation was that four controllers would participate over three\nfive-day periods. However, due to recruiting issues, the number of controllers varied by the\nfive-day period. The first five-day period had
two controllers, the second had three, and the\nthird had four. The controller and pilot groupings as well as the main daily activities are shown\nin Table 3-3. The following sub-sections will provide details on simulation procedures for the\ncontrollers then the pilots. Table 3-3. Controller and Pilot Grouping and Daily Activities Day\nController Group Controller Activity\nPilot Group Pilot Activity\n1 1 (n = 2) Training TSAS\n2 Training IM during metering\n3 Data collection\n1 (n = 2) Training and data collection 4 2 (n = 2) Training and data collection\n5 3 (n = 2) Training and data collection\n6 2 (n = 3) Training TSAS\n7 Training IM during metering\n8 Data collection\n4 (n = 2) Training and data collection 9 5 (n = 2) Training and data collection\n10 6 (n = 2) Training and data collection\n11 3 (n = 4) Training TSAS\n12 Training IM during metering\n13 Data collection\n7 (n = 2) Training and data collection 14 8 (n = 2) Training and data collection\n15 9 (n = 2) Training and data collection 3-47 3.4.1 Controller Training\nBased on feedback from the concept evaluation activities leading up to the HITL, the training\nstarted with a day of terminal metering and TSAS-only training. While the simulation activity\nwas not examining terminal metering and TSAS operations alone, these operations were new to\nthe controllers so it was introduced before adding IM into those operations. The following day\nwas used to introduce IM into that terminal metering environment. The first day started with having each participant complete a demographics questionnaire. This\nwas followed by the first part of the pre-simulation briefing which contained information on the\nresearch background, the operational reason for introducing terminal metering, the terminal\nmetering concept and TSAS, the simulation environment (e.g., airport, arrivals, airspace, RNP RF\nturns), roles and responsibilities, as well as operational considerations. After the first day pre-simulation briefing, controllers were taken to the IDEA lab to familiarized\nthemselves with the STARS workstation and to ask any questions. Controllers were briefed on\nthe basic display features, information new for terminal metering and TSAS, as well as the\nsimulated KPHX airspace. Controllers were then given a cheat sheet with key information on\nit such as keyboard entries. The remainder of the day involved running through training\nscenarios. The training progressed from low to medium and finally high-density traffic during\nterminal metering operations. Controllers trained with each density and in both the feeder and\nfinal roles. The first day ended with a high-density traffic during terminal metering operations\nscenario that acted as a baseline. The second day started with the second part of the pre-simulation briefing that described IM\noperations during terminal metering. Controllers were told the simulation activity was not\ntrying to force a choice between TSAS and IM, but that they may get asked questions\ncomparing the operations and associated tools to ensure proper integration of the operations.\nThey were also informed that the researchers were not soliciting feedback on STARS and TSAS\nindependent of IM, as the goal was to have integrated IM and terminal metering operations\nand not independent operations. The briefing provided background information on IM and the\nintegration of IM into the terminal metering environment. It also provided the operational\nreason for introducing IM, IM operations, and operational considerations when conducting IM\nduring terminal metering. The briefing provided details on pilot and controller roles and\nresponsibilities, IM display features, and the communications procedures as detailed in Section\n3.3.2. After the second day briefing, controllers were taken to the IDEA lab to be familiarized with IM.\nThey were briefed on the new information for IM. The cheat sheet was reviewed for the IM\nelements such as the sample IM communications and IM keyboard entries. The remainder of\nthe day involved running training scenarios. The training progressed from low to medium and\nfinally high density traffic with IM aircraft now present in the terminal metering operations.\nControllers training with each density and in both the feeder and final roles. Based on past research (e.g., Bone, Penhallegon, Benson, and Orrell, 2013; Cardosi, personal\ncommunication, October 4, 2014), it was felt that controllers would benefit from understanding\nthe information available to flight crews. Therefore, in addition to the overviews of the flight 3-48 deck displays and the associated information from the briefing, demonstrations in the flight\ndeck simulator were provided. 3.4.2 Pilot Training and Data collection\nThe next three days for the controllers consisted of data collection. A new set of pilots joined\nthe simulation each day. While the pilots were being trained each day in the morning, the\ncontrollers participated in data collection scenarios where IM was initiated in the en route\nenvironment and continued IM into the TRACON. Only pseudo-piloted aircraft were part of\nthese scenarios. For pilots, the day started by completing a consent form and demographics questionnaire. This\nwas followed by the pre-simulation briefing. The briefing provided background information on\nIM, IM operations and communications, pilot and controller roles and responsibilities, display\nfeatures and the simulation environment, as well as operational considerations when\nconducting IM. The pilots were also given basic information about the relationship between\ntime and distance spacing during IM. After the pre-simulation briefing, the pilots were taken to the flight deck simulator for\nfamiliarization and training on the various interfaces and procedures they would encounter\nduring the data collection scenarios. The flight crew first conducted an arrival and approach,\nwithout IM or a CDTI, to become familiar with the flight deck simulator. They then conducted a\npractice BRUSR1 arrival and approach with IM where they were taught how to interact with and\nutilize the min tool set. They then conducted the EAGUL6 arrival and approach with IM but with\nthe min+ tool set. When pilot training was completed, both the controllers and pilots started the joint data\ncollection activities. Each scenario lasted approximately 40 minutes and post-scenario\nquestionnaires were given after each run / scenario. Prior to executing each scenario, pilots and\ncontrollers were informed of the specific conditions for the current scenario. Pilots were\ninformed of their call sign for the run via a note placed in the flight deck (Sun Country [SCX] was\nalways used as the company name but the flight number changed for each approach). After data collection runs, participants were provided with a final questionnaire encompassing\nthe entire simulation. Once they completed the final questionnaire, the controllers and pilots\nwere offered an opportunity to have a short, informal debrief. 3-49 3.5 Experimental Design\nThe independent variables for the simulation are shown in Table 3-4. The variables were\nintended to test where pilots and controllers had sufficient information, in their role, to\ndetermine how well IM was progressing and whether spacing issues were developing. The\ntesting of the controller variables was expected to provide some data on the necessary\ninformation for the controller that would be specified in a ground requirements document.\nOnly a very preliminary version of such a document existed at the time the simulation was\nbeing defined. However, for the flight deck displays, requirements have been already written\nfor the CDTI (traffic display and AGD implementation in this simulation) so the testing of the\nindependent variables could provide validation of the minimum set of requirements and could\nprovide data on necessary additions. Table 3-4. Independent Variables Controller Flight Crew\nRole (Within)\nFeeder Final\nTool Set\n(Within) Tool Set\n(Within) Basic MOPS CDTI minimum (min)\nBasic+ cue MOPS CDTI minimum plus (min+) [Graphical progress indicator and speed tape]\nBasic+ cue and prediction MOPS Minimum Operational Performance Standards A total of six traffic files were developed for data collection and were derived from real world\nKPHX operations. Each file was unique but very similar in traffic density (approximate rate of 40\naircraft per hour), mix of aircraft type and category (larges and heavies), aircraft capabilities (IM\nand RF RNP), and delivery relative to the schedule from the simulated en route controller. Each\ntraffic file lasted approximately 40 minutes and the controller managed traffic for the full\nscenario. The flight crew could fly one arrival and approach to landing and then be repositioned\noutside of the TRACON airspace to fly the arrival and approach a second time within the same\ntraffic file. The participant aircraft flight crew was given sufficient time to get acclimated to the\nnew position and aircraft state before checking in and receiving the first controller instruction.\nEach participant experienced the same set of data collection scenarios (in a repeated measures\ndesign). One of the traffic files (traffic file 4) was used as the en route initiation scenario without\nparticipant flight crew participation. This same traffic file was then used for the baseline\ncondition for the flight crew. In that case, the traffic file looked like the other traffic files to the\ncontroller, but the participant flight crew was not equipped to do IM. 3-50 Over the course of each data collection day, flight crews flew twice through each traffic file. The\nparticipants flew a baseline without IM in traffic file 4 and flew IM in traffic files 1, 2, 3, 5, and 6.\nWhile all pilots experienced the independent variables in the same run within the traffic file,\nthe run order of the traffic files was counterbalanced across participant groups. Flight crews\nflew two arrivals and approaches within each traffic file. The run in which they utilized either\nthe min CDTI implementation or the min+ implementation is shown in Table 3-5. Table 3-5. Flight Crew Independent Variable Exposure by Traffic File and Run Operation\nIM Tools / Independent Variable (T)raffic File-(R)un\nBaseline NA T4-R1; T4-R2 IM Min T1-R1; T2-R2; T3-R2; T5-R1; T6-R2\nIM Min+ T1-R2; T2-R1; T3-R1; T5-R2;
T6-R1 Over the course of the three-day data collection days, the controllers experienced traffic file 4\nwith en route initiation, while pilots were trained. For the remainder of the day, controllers\nexperienced the other six traffic files with the flight deck participants. The block order of the\ntraffic files was counter-balanced across participant groups. Off-nominal events were introduced for the controllers through pseudo-pilot action. Each day\neach controller experienced an event where the termination or suspension of IM was required.\nThe pseudo-pilot was told to acknowledge the IM clearance from the feeder controller but to\nfly a constant speed without engaging IM. The trail aircraft held its speed and started\nencroaching upon the lead aircraft (which eventually led to a separation issue) until the\ncontroller intervened. The issue started to evolve in the feeder controllers airspace, but the\nspacing issue may not have been fully realized until the final controllers airspace based on the\nslow progression of the overtake. Table 3-6 shows the traffic file run order and traffic overtake\nevents for the three groups of controllers. 3-51 Table 3-6. Controller Independent Variable Exposure by Day, Traffic File, and Run Note: Traffic overtake conditions are highlighted in orange. Group Operation IM Tools A Controller Role /B Controller Role\nBaseline NA Feeder/Final D1-T4-R1\nBaseline NA Final/Feeder D1-T4-R2\nIM En Route Initiation TSAS tools Feeder/Feeder D4-T4-RC1\nIM En Route Initiation TSAS tools and slot marker color change Feeder/Feeder D3-T4-RC1\nIM En Route Initiation TSAS tools, slot marker color change, and ETA differential Feeder/Feeder D5-T4-RC1\nIM TSAS tools Feeder/Final D3-T4-R1 D4-T5-R1 D5-T6-R1\nIM TSAS tools and slot marker color change Feeder/Final D3-T1-R2 D4-T6-R2 D5-T4-R2\nIM TSAS tools, slot marker color change, and ETA differential Feeder/Final D3-T2-R3 D4-T4-R3 D5-T1-R3\nIM TSAS tools Final/Feeder D3-T3-R4 D4-T1-R4 D5-T2-R4\nIM TSAS tools and slot marker color change Final/Feeder D3-T5-R5 D4-T2-R5 D5-T3-R5\nIM TSAS tools, slot marker color change, and ETA differential Final/Feeder D3-T6-R6 D4-T3-R6 D5-T5-R6\nBaseline NA Feeder/Final D1-T4-R1\nBaseline NA Final/Feeder D1-T4-R2\nIM En Route Initiation TSAS tools Feeder/Feeder D3-T4-RC1\nIM En Route Initiation TSAS tools and slot marker color change Feeder/Feeder D5-T4-RC1\nIM En Route Initiation TSAS tools, slot marker color change, and ETA differential Feeder/Feeder D4-T4-RC1\nIM TSAS tools Feeder/Final D3-T4-R2 D4-T1-R2 D5-T6-R2\nIM TSAS tools and slot marker color change Feeder/Final D3-T1-R3 D4-T2-R3 D5-T4-R3\nIM TSAS tools, slot marker color change, and ETA differential Feeder/Final D3-T6-R1 D4-T4-R1 D5-T5-R1\nIM TSAS tools Final/Feeder D3-T3-R5 D4-T5-R5 D5-T2-R5\nIM TSAS tools and slot marker color change Final/Feeder D3-T5-R6 D4-T6-R6 D5-T3-R6\nIM TSAS tools, slot marker color change, and ETA differential Final/Feeder D3-T2-R4 D4-T3-R4 D5-T1-R4\nBaseline NA Feeder/Final D1-T4-R1\nBaseline NA Final/Feeder D1-T4-R2\nIM En Route Initiation TSAS tools Feeder/Feeder D5-T4-RC1\nIM En Route Initiation TSAS tools and slot marker color change Feeder/Feeder D4-T4-RC1\nIM En Route Initiation TSAS tools, slot marker color change, and ETA differential Feeder/Feeder D3-T4-RC1\nIM TSAS tools Feeder/Final D3-T4-R3 D4-T1-R3 D5-T2-R3\nIM TSAS tools and slot marker color change Feeder/Final D3-T5-R1 D4-T6-R1 D5-T4-R1\nIM TSAS tools, slot marker color change, and ETA differential Feeder/Final D3-T6-R2 D4-T4-R2 D5-T1-R2\nIM TSAS tools Final/Feeder D3-T3-R6 D4-T5-R6 D5-T6-R6\nIM TSAS tools and slot marker color change Final/Feeder D3-T1-R4 D4-T2-R4 D5-T3-R4\nIM TSAS tools, slot marker color change, and ETA differential Final/Feeder D3-T2-R5 D4-T3-R5 D5-T5-R5 (D)ay-(T)raffic File-(R)un Order 1 2 3 3-52 A summary of each data collection day (1 day for pilots; 3 days for controllers) is provided in\nTable 3-7. Table 3-7. Data Collection Day Details Traffic\nFile(s) Flight Crew (2 per day) Controllers (3 per day) 4\n(with en route\ninitiation) Introductory Briefing and Background\nQuestionnaire. Training in lab Controller role:\nA Feeder; B- Feeder\nScenario:\nTSAS and IM en route initiation\nIndependent variable (order varied between days):\n(1) Basic,\n(2) Basic+ cue, or\n(3) Basic+ cue and prediction 1, 2, 3, 4,\n5, and 6 Pilot role (remained fixed):\nPF; PM\nOperation (order varied within day):\n(1) Baseline No IM (x2 runs)\n(2) IM (x10 runs)\nTools (order varied within day):\nMin CDTI then Min CDTI+ or\nMin CDTI+ then Min CDTI Controller role (swapped after 3rd scenario):\nFeeder; Final\nOperation (traffic file order varied within day):\nTSAS and IM (x6)\nTools (order varied within day):\n(1) Basic,\n(2) Basic+ cue, or\n(3) Basic+ cue and prediction 3.6 Data Collection\nFour methods of data collection were used for this simulation: paper questionnaires, system\nrecorded data, observations, and final debriefs (when chosen by the participants). Three types\nof questionnaires were used, including: 1. Demographics: Upon arrival, participants were asked to fill out a demographics\nquestionnaire which captured participants experience. Controllers and pilots had\nseparate questionnaires. 2. Post- scenario: After each run / scenario, participants were asked to fill out a\nquestionnaire based on the run / scenario just experienced. All post-scenario\nquestionnaires included the Bedford Workload Rating Scale (Roscoe, 1984) along with\nadditional rating scale and yes / no questions with a comment field for each. The\ncontroller questionnaires included the Controller Acceptance Rating Scale (Lee, Kerns,\nBone, and Nickelson, 2001). Pilot participants completed a post-scenario questionnaire\nafter each run during a scenario (two runs per scenario) and controllers completed this\nquestionnaire after each scenario. Separate post-scenario questionnaires were used for\nthe baseline and IM scenarios. Controllers and pilots also had separate questionnaires\n(Appendix B). 3. Post-simulation: After the final scenario, participants were asked to complete the longer,\nfinal questionnaire covering all the scenarios experienced. The questionnaire included a\nseries of rating-scale and yes / no questions with a comment field for each. Controllers\nand pilots had separate questionnaires (Appendix C). 3-53 In these questionnaires, participants were asked to provide subjective feedback on areas such\nas the overall IM concept, workload, situation awareness, head down / scan time, displays,\ncommunications, and simulation realism. Objective metric data was automatically recorded by the simulation platform or by the\nobservers and included: ATC o Interactions with displays Inputs for IM initiation, rejection, suspension, resumption, and termination o IM initiation delay o Location of IM initiations, rejections, suspensions, resumptions, and terminations All aircraft o Schedule conformance o Slot marker deviation o Events below the applicable separation standard o Frequency of infeasible / no speed events o Time on the RNAV procedure o Spacing error at key locations o How well the ASG was maintained o Arrival rates / throughput Participant aircraft o IM speeds o MCP selected speed o Distance to ABP o Frequency of IM terminations o Interactions with displays (e.g., TTF selection and data entry) 4-1 4 Results\nThis section begins with a description of the analysis method for both subjective and objective\ndata. It then describes baseline scenarios and the operations (terminal metering and RNP RF\nturns) that form the operational foundation for IM. It then covers the objective data, including:\nthe conduct of IM operations (mainly controller actions related to IM), IM speeds (for\nparticipant pilot aircraft) and flight crew actions related to those speeds, and aircraft spacing\nand separation results (for pseudo-pilot and participant pilot aircraft). Subjective data for both\npilots and controllers is covered next (e.g., acceptability of IM, displays, responsibilities). Time\non RNAV arrivals and communication results are then provided, followed by en route IM\ninitiation results, as related to controllers. Finally, the section ends with results for the\nparticipants assessments of the simulation. 4.1 Analysis Method 4.1.1 Subjective Data\nThe subjective results are based on responses to the statements from both the post-scenario\nand post-simulation questionnaires. The post-simulation questionnaires comprise most of the\ndata so in these cases, the source will not be noted unless it helps for clarity. Any data from the\npost-scenario questionnaires will be noted. Controller and pilot comments were included if they\nwere enlightening or if a sufficient number of participants made similar comments. Controller results are based on nine participants while pilot results are based on 18\nparticipants. Controller responses are divided by the independent variable of controller role.\nPilot responses are usually combined (as role was not a planned independent variable), unless\nthere was a clear reason to report the roles separately. Some questions in the questionnaires were yes / no with an opportunity for open-ended\ncomments. Most response-scale items were statements with 100 hash marks (without numeric\nlabels) and an opportunity to provide open-ended comments. The scale was anchored on the\nleft with the label Strongly Disagree and on the right with the label Strongly Agree (Figure\n4-1). Figure 4-1. 100-Point Agreement Scale Most items were presented as a statement, and participants were asked to rate their level of\nagreement. Participants were told to draw a straight line anywhere on the scale, including\nbetween the lines and right on the end points. During data reduction, responses were rounded\nto the nearest single digit between 0 and 100. In the presentation of the results, any responses\nbelow the midpoint (i.e., lower than 50) on the scale were considered to be on the disagree\nside while any responses above the midpoint (i.e., higher than 50) on the scale were considered 4-2 to be on the agree side. Any responses at the midpoint (i.e., equal to 50) were considered to\nbe neutral (Figure 4-2). Figure 4-2. 100-Point Agreement Scale Agreement Rating Breakdown When presenting results on the 100-point agreement scale in the post-simulation\nquestionnaires, the following terminology / methodology is used to describe the levels of\nagreement. All [controllers / pilots] [agreed / disagreed] o All of the participants are on the agree or disagree side of the scale The majority (n; %) of [controllers / pilots] [agreed / disagreed] o Low variability, e.g., SD of less than approximately 25 (unless one value is driving a\nSD slightly higher) [Controller / Pilot] responses were variable but the majority (n; %) [agreed / disagreed] o Responses have a SD of greater than approximately 25 and distribution is relatively\nbiased in
one direction [Controller / Pilot] responses were variable o Responses have a SD of greater than approximately 25 and the distribution is\nrelatively flat across the scale To summarize a series of related statements, figures like that shown in Figure 4-3 are shown\nlater in the relevant section to show the scale and the disagreement and agreement sides.\nSmiling or frowning faces are shown on the scale where the replies to the statements have\na subjectively positive or negative meaning. For the post-simulation questionnaires, the\nstatement is directly quoted from the questionnaire and shown to the left of the graph. If the\nsame statement was used for both controllers and pilots, it is only shown once. When the\ncontroller and pilot statements were slightly different, brackets are used and the controller text\nis presented before the / and the pilot text is presented after. For example, The spacing\n[achieved by the aircraft / I achieved] was acceptable. Figures for the post-scenario individual\nquestions show the tool set to the left of the graph. 4-3 Figure 4-3. Sample Summary Figure The means (M) and SDs are included on the figures. The means are shown by points and the\nSDs are shown by the bars. Symbols are also used to indicate the responding party and the\nparticular condition the reply relates to. Note that the symbol labels may be combined in the\nfigures where necessary. See Figure 4-4 for details on the symbols and their use. 4-4 Figure 4-4. Symbols Used in the Summary Figures and Their Meaning The Bedford Workload Rating Scale was used to measure subjective workload across scenarios.\nThe Controller Acceptance Rating Scale was used for controllers to measure operational\nacceptability. 4-5 4.1.2 Objective Data\nThe objective data for aircraft is either shown as pseudo-pilot, participant pilot / flight crew\naircraft, or combined data. Generally, the pseudo-pilot and participant pilot data is combined to\nprovide detail of the controllers experience on the overall set of aircraft (e.g., in Section 4.5 -\nAircraft Spacing and Separation). However, participant pilot aircraft data is reported separately\nwhen a distinction is made between the behavior of the participants (who operated the aircraft\naccording to their own desires during the IM operation) versus the behavior of the pseudo-pilot\naircraft (which behaved as designed by the IM sample algorithm (e.g., Section 4.4.5 IM Speeds\nand Flight Crew Actions). The arrival procedures were not the same length and did not take the same amount of time to\nfly. The BRUSR1 arrival from TRACON entry to touchdown was on average 14.2 minutes (SD =\n0.8) and the EAGUL6 arrival was 11.5 minutes (SD = 1.4). The majority of the data is comprised of IM initiations in the TRACON. Baseline / non-IM\noperations are reported in Section 4.2 and IM en route initiation is reported in Section 0. The arrival rate targeted for the simulation was 40 aircraft per hour to the runway. The average\narrival rate realized across the IM TRACON initiation scenarios was 46.5 (SD = 7.6). The average\narrival rate across the IM en route initiation scenarios was 55.1 (SD = 2.5). When the IM clearance types and stages are mentioned, the following conventions are used. Both achieve-by then maintain clearance type options o Achieve-by o Achieve-by then maintain o Achieve stage o Maintain stage Capture then maintain o Maintain stage When flying the achieve-by option, the ABP and PTP were YOKXO (FAF) and there is no\nmaintain stage. When flying the achieve-by then maintain option the ABP was DERVL (merge\npoint) and the PTP was YOKXO (FAF). Aircraft were considered in the maintain stage of the\nachieve-by then maintain clearance type once the ABP was reached. For the capture then\nmaintain clearance type, aircraft were considered in the maintain stage once the aircraft got\ninside the 10-second maintain tolerance. Data reported for the maintain stages can include the\nmaintain stages of both clearance types. Participant flight crews flew both achieve-by then maintain clearance type options. Pseudo-\npilot aircraft flew both clearance types. 4-6 When the data is presented, box and whisker plots are used. Figure 4-5 shows a sample with a\ndescription of the various points. Figure 4-5. Sample Box and Whisker Plot Defined Heat maps are also utilized to show the frequency of events along the arrival procedure. Figure\n4-6 shows an example. Colors with longer wavelengths (e.g., reds) indicate more frequent\nevents than colors with shorter wavelengths (e.g., blues). Figure 4-6. Sample Heat Map 4.1.3 Statistical Method and Results\nFour hypotheses were tested across pilot and controller participants as listed in Table 4-1.\nHypotheses one, three, and four consisted of more than one dependent measure. In these\ncases, statistical tests were used to test each measure. Alpha was set at 0.05. 4-7 Table 4-1. List of Hypotheses and Statistical Tests # Particiants Hypothesis Dependent Measure\nStatistical Test 1 Pilots Flight crews will\nachieve and\nmaintain spacing\nbetter with the\nmin+ tool set as\ncompared to the\nmin tool set 1a. Spacing error at ABP\nPaired\nSamples t-\ntest 1b. Spacing error during maintain\nPaired\nSamples t-\ntest 2 Pilots Flight crews will\ncomply with more\nIM speeds with the\nmin+ tool set as\ncompared to the\nmin tool set Frequency of IM speeds complied with Chi-square 3 Pilots Flight crews will\nfind the min+ tool\nset more\nacceptable than\nthe min tool set 1) Subjective question: I could detect\nwhether I would remain within\ntolerances to achieve and maintain the\nassigned spacing goal 2 x 2\nMixed\nANOVA 2) Subjective question: I had the\nnecessary display elements for\nconducting IM 2 x 2\nMixed\nANOVA 4 Controllers Controllers will find\nthe new display\nelements for IM\nuseful as compared\nto only the basic 1) Subjective question: I was confident\nthat the spacing of the [IM] aircraft\nwould remain outside my\nseparation requirement Repeated\nMeasures\nANOVA 2) Subjective question: I had the\nnecessary display elements for\nconducting IM operations Repeated\nMeasures\nANOVA Table 4-1 also cites the statistical test used to measure each hypothesis. The researchers\nconsidered a Multivariate Analysis of Variance (MANOVA) for hypothesis three and four given\nthere are several dependent variables to measure and to control for Type I family-wise error.\nThe general assumption for a MANOVA is for there to be some level of correlation between\ndependent measures within a range from 0.3 to 0.7 (Mayers, 2013). To test for this, a series of\nPearson Correlations were conducted across the dependent measures. All correlations\nexceeded r = 0.7 for both hypotheses; therefore, a separate Analysis of Variance (ANOVA) was\nconducted for each dependent measure. This resulted in a total of seven statistical tests. To 4-8 adjust the alpha level of p < 0.05 for family-wise error, a Bonferroni Correction was employed,\nresulting in a familywise alpha level of p < 0.01. This was the criterion used to determine\nstatistical significance. 4.1.3.1 Hypothesis 1: Flight Crews will Achieve and Maintain Spacing Better with the Min+\nTool Set as Compared to the Min Tool Set This hypothesis only includes participant aircraft. Therefore, it is a subset of the data presented\nin Sections 4.5.3 and 4.5.4 that includes both participant and pseudo-pilot aircraft. The spacing\nerror for the achieve and maintain stages is shown in Table 4-2. Table 4-2. Mean Spacing Error in Seconds (SD) for Participant Flight Crews Flight crew tool set Stage of achieve-by then\nmaintain Achieve Maintain Min 2.5(1.2)\n0.96 (0.05) Min+ 1.9(0.7)\n1.0 (0.00) For the measure of spacing error at the ABP, two measurement points were used. DERVL was\nused for trail aircraft that performed the achieve-by then maintain clearance type and had\nDERVL as the ABP (Note: Those aircraft then went into the maintain stage until the PTP). YOKXO\nwas used by trail aircraft that performed the achieve-by clearance type and had YOKXO as the\nABP. A dependent t-test was used to measure for statistical differences between the min and\nmin+ tool sets. No statistically significant result was found. Participant flight crews performed achieve-by then maintain operations with the maintain\nphase occurring after the aircraft crossed the ABP at DERVL and until crossing the PTP at\nYOKXO. This is a relatively short portion of the arrival and approach. A dependent t-test was\nused to measure for statistical differences between min and min+ tool sets. No statistically\nsignificant result was found. 4.1.3.2 Hypothesis 2: Flight Crews will Comply with More IM Speeds with the Min+ Tool Set\nas Compared to the Min Tool Set This hypothesis was measured using the number of IM speeds the flight crews complied with.\nDifferentiating crew role is irrelevant for this measure since only the PF was responsible for\nimplementing the IM speeds. The type of data analyzed is binary since the PF either implements\nor does not implement a speed; therefore, a chi-squared analysis was used to measure the\nfrequency difference between complying or not complying to each IM speed between the min\nand min+ tool sets. This test did not reveal any statistically significant differences between the\ntool sets. 4-9 4.1.3.3 Hypothesis 3: Flight Crews will Find the Min+ Tool Set More Acceptable than the Min\nTool Set The third hypothesis addressed whether flight crews will find the min+ tool set more acceptable\nthan the min tool set. The hypothesis was measured using the following post-scenario\nsubjective questions: 1) I could detect whether I would remain within tolerances to achieve\nand maintain the assigned spacing goal, and 2) I had the necessary display elements for\nconducting IM. The researchers tested for statistical equivalence using the Two One-Sided\nTest (TOST) between both pilot roles (i.e., PF and PM) so that the PF and PM results for each\ntool set could be combined across all measures. This method would increase the sample size\nwithin each condition
(i.e., from nine to 18). Four TOST comparisons were conducted, one for each set across the two measures (i.e., post-\nscenario questions). None of the tests revealed statistically equivalent results. This suggests\ndifferent uses of the tool sets between the roles, which resulted in different perceptions. In this\ninstance, pilot role was treated as another independent variable. Therefore, two 2 x 2 Mixed\nANOVAs were conducted for the tool sets and pilot role across the two measures. The tests did\nnot reveal any statistically significant results. 4.1.3.4 Hypothesis 4: Controllers Will Find the New Display Elements for IM Useful as\nCompared to Only the Basic The forth hypothesis addressed if controllers found the new display elements for IM useful\ncompared to the basic tool set. Two post-scenario questions were developed to address this\nhypothesis: 1) I was confident that the spacing of the [IM] aircraft would remain outside my\nseparation requirement, and 2) I had the necessary display elements for conducting IM\noperations. A 3 x 2 Repeated Measures ANOVA was conducted for controller role (i.e., feeder\nand final) and IM tool set (i.e., basic, basic+ cue, and basic+ cue and prediction) across each of\nthe two dependent measures. This was done in lieu of one MANOVA due to the previously-\ndescribed unfavorable correlations between dependent measures. There were no main effects\nor interactions for both Repeated Measures ANOVAs. 4-10 4.1.4 Summary Data\nOne hundred thirty participant controller runs and 108 participant flight crew runs were\nplanned. Due to technical issues with the simulation environment, three controller IM TRACON\ninitiation runs were excluded from data analysis, which also resulted in the loss of six\nparticipant flight crew runs. An additional 11 participant flight crew runs (that did not affect the\noverall controller runs) were excluded due to technical issues with the simulation environment.\nTable 4-3 shows the number of runs for both controllers and participant flight crews by scenario\ntype. Table 4-4 shows the number of aircraft per environment. Table 4-3. Number of Planned and Analyzed Runs per Scenario Type Scenario\nPlanned # of runs Analyzed # of runs Controller Flight crew Controller Flight crew\nBaseline 10 18 10 18\nIM En Route Initiation 27 --- 27 ---\nIM TRACON Initiation 90 90 87 73\nTotal 127 108 124 91 Table 4-4. Aircraft Participants Across Scenarios Types IM initiation\nlocation Aircraft role Total\naircraft En route IM trail 306\nNon-IM 418 TRACON IM trail 1151\nNon-IM 1356 None (Baseline) Non-IM 265\nTotal 3496 Table 4-5 summarizes the IM initiations for both the TRACON and en route scenarios. For IM\nTRACON initiation scenarios, 1203 total IM operations were proposed to the controllers. Of\nthose, 2.7% (33 of 1203) IM proposals were rejected by the controllers and 1170 IM operations\nwere issued. Of those, 1.6% (19) were not engaged due to the pseudo-pilot not properly\nengaging the operation or simulation technical issues7. Therefore, a total of 1151 (95.6%) IM\noperations were properly engaged and initiated. For the en route initiation scenarios, 306 IM\noperations were conducted. Table 4-5 summarizes the number of IM proposals, clearances, and\ninitiations. Table 4-6 summarizes the IM operations by IM initiation point and clearance type.\nTable 4-7 summarizes the IM operations by controller tool set and clearance type. While there\nare different totals for the different clearance types and for the three controller tool set\noptions, it is not believed to impact any feedback / results as both were frequently experienced. 7 These aircraft flew the RNAV profile instead of IM. 4-11 Table 4-5. IM Initiation Sequence TRACON IM initiation\nEn route IM initiation Total\nBoth achieve-by\nCapture then maintain Combined IM proposals presented\nto the controller --  IM proposals issued by\ncontroller --  IM operation initiated\nand engaged / flown 306 1457 Table 4-6. Frequency of IM Operations by IM Initiation Location and IM Clearance Type IM initiation location IM clearance type Achieve-by\n(no maintain) Achieve-by\nthen maintain Capture\nthen maintain Combined\nTRACON 449 \nEn route 145 81 80 306\nCombined 594 Table 4-7. Frequency of IM Operations by Controller Tool Set and IM Clearance Type Controller tool set IM clearance type Achieve-by\n(no maintain) Achieve-by\nthen maintain Capture\nthen maintain Combined\nBasic 134 147 87 368\nBasic+ cue 153 157 95 405\nBasic+ cue and prediction 146 145 87 378\nCombined 433 It should be noted that controllers sometimes had difficulty allowing aircraft to arrive in their\nplanned sequence or to achieve a large interval8 if they thought manual controller action would\nresult in a more efficient operation. They preferred to shortcut the route and / or tighten the\nspacing between aircraft (which was the reason for most vectoring). However, this did not\nalways lead to a better traffic situation, and sometime led to spacing issues. 8 Large intervals were due to the initial sequence and spacing of arrival aircraft. The TBFM/TSAS schedule does not\ncontain logic to speed an aircraft up above the profile speed to close a naturally occurring large gap. 4-12 4.2 Terminal Metering Only Operations (Baseline)\nThe baseline condition for the controllers was terminal metering operations without IM. The\npost-scenario results are presented in this section. The majority of controllers agreed with all\nstatements regardless of role (Figure 4-7). Figure 4-7. Controller Responses to Post-Scenario Statements on the Baseline Condition\nwithout IM 4-13 In the post-scenario questionnaire, controllers were asked to rate their average overall\nworkload during the baseline on the Bedford Workload Rating Scale. The majority of controllers\nfound workload to be acceptable for both roles (Figure 4-8). Figure 4-8. Controller Responses to the Bedford Workload Rating for the Baseline In the post-scenario questionnaire, controllers were asked to rate their acceptability of the\nbaseline with Controller Acceptance Rating Scale. The majority of controllers found IM\noperationally acceptable across the tool sets (Figure 4-9). Finally, there was one condition\nwhere an aircraft pairs spacing was below the applicable separation standard that occurred for\nunknown reasons and was not analyzed further. Figure 4-9. Controller Responses for Controller Acceptance Rating Scale for the Baseline 4.3 Integrated Ground Operations\nWhile the focus of the simulation was the integration of IM into the terminal metering\nenvironment, it was desirable to understand all three operations that were new to the\ncontrollers: terminal metering, RNP RF turn operations, and IM. Therefore, controllers were\nasked to rank the three operations relative to one another from the most to least challenging.\nFigure 4-10 shows each operation and how often each appeared in each category. Figure 4-11 4-14 shows each operation and the relative ranking. RNP RF turns operations had the fewest least\nchallenging rankings and appears to be the most challenging operation. Terminal metering had\nthe fewest most challenging rankings. IM ranked between RNP RF turn and metering\ncomplexity. Figure 4-10. Controller Ranking of Operations. Frequency by Category Figure 4-11. Controller Average Ranking of Operations Relative to One Another 4-15 Controllers were asked whether IM was compatible with terminal metering operations. The\nmajority (8/9; 89%) agreed (M=69.9; SD=22.1) (Figure 4-12). Figure 4-12. Controller Responses to IM is compatible with terminal metering operations 4.4 IM Operations Conduct\nThis section covers controller actions based on an IM clearance proposal as well as controller\nand participant flight crew actions related to IM once active. 4.4.1 IM Initiation\nAs described previously, a total of 1203 IM clearances were presented / proposed to\ncontrollers. Of the 1203 proposals, 97.2% (1170 of 1203) were initiated by controllers. Of\ninitiated IM aircraft, 76.4% (894 of 1170) were achieve-by then maintain operations and 23.5%\n(276 of 1170) were capture then maintain operations. Table 4-8 shows the distribution of IM\ninitiations by IM operation and condition. Table 4-8. Frequency of IM Initiations as a Percentage of the Sample Controller tool set (n = IM clearance type Both\nachieve-by Capture then\nmaintain Combined Basic 76.2 23.8 32.0\nBasic+ cue 76.0 24.0 35.2\nBasic+ cue and prediction 77.1 22.9 32.8\nCombined 76.4 23.6 100 Of the 1203 IM clearance proposals presented to the controller, thirty-three were rejected by\nthe controller entering the keyboard command. Of the 33 rejections, thirty (2.5% of all\ninitiations presented and 3.3% of all achieve-by clearances) were one of the achieve-by\nclearance type options and three (0.2% of all initiations presented and 1.0% of all capture then\nmaintain clearances) were capture then maintain (Table 4-9). On average, controllers rejected\nIM clearances 116.7 sec (SD=132.6; Range= 20 703 seconds) after they were proposed. One\ncontroller accounted for 19 (58%) of the rejections. 4-16 Table 4-9. Frequency of IM Proposals Rejected Controller tool set IM clearance type Both\nachieve-by Capture then\nmaintain Combined Basic 10 2 12\nBasic+ cue 10 1 11\nBasic+ cue and prediction 10 0 10\nCombined 30 3 33 The reasons for the rejections were often not clearly articulated but some that were noted\nincluded simply not wanting to use IM or the ASG being too large (e.g., 232 seconds). After excluding rejections, a total of 1170 IM operations were initiated by the controllers by\nentering the keyboard command. On average, controllers entered the keyboard command 30.6\nseconds (SD=28.8) after an IM operation was proposed / displayed. Table 4-10 shows IM\ninitiation delay by scenario and condition. Controllers were on average 11 seconds faster\ninitiating IM for capture then maintain clearances (M=25.3; SD=22.7), as compared to both\nachieve-by clearance type options (M=35.9; SD=36.2). Initiation delay across the controller tool\nset were similar but the basic+ cue and prediction tool set was 4.3 seconds faster than the basic\ntool set. Table 4-10. IM Initiation Delay in Mean Seconds (SD) Controller tool set IM clearance type Both\nachieve-by Capture then\nmaintain Combined Basic\n38.5 (39.0)\n26.2 (25.4)\n32.4 (32.2) Basic+ cue\n35.6 (34.3)\n27.0 (20.6)\n31.3 (27.5) Basic+ cue and prediction\n33.8 (35.2)\n22.4 (18.5)\n28.1 (26.9) Combined\n36.0 (36.2)\n25.2
(21.5)\n30.6 (28.8) Of the total IM initiations then were engaged / flown, 74.1% (853 of 1151) occurred in the first\nsegment of the BRUSR1 (between BRUSR and ANNTI) and EAGUL6 (between HOMMR and\nVNNOM) STARs. Figure 4-13 and Figure 4-14 show the IM initiation locations by IM clearance 4-17 type9. As would be expected, the majority of the operations were engaged in the feeder\ncontrollers airspace. For both arrivals combined, more capture then maintain clearance\n(85.9%) initiations occurred earlier (i.e., in the first segment) than did the achieve-by clearance\n(70.5%) (Table 4-11). Figure 4-13. IM Initiation Locations for Both Achieve-by IM Clearance Types Figure 4-14. IM Initiation Locations for Capture then Maintain IM Clearance Type 9 The colors with longer wavelengths (e.g., reds) indicate more frequent events than the colors with shorter\nwavelengths (e.g., blues). 4-18 Table 4-11. IM Initiation Location as a Percentage of the Sample Location BRUSR1 EAGUL6 Combined\nBoth achieve-\nby Capture\nthen maintain Both\nachieve- by Capture\nthen maintain Both\nachieve- by Capture\nthen maintain\nFirst segment 69.9 84.5 71.4 86.7 70.5 85.9\nAfter first segment 30.1 15.5 28.6 13.3 29.5 14.1\nCombined 82.9 17.1 69.7 30.3 76.6 23.4 4.4.2 IM Suspensions\nEight IM active operations were suspended (less than 1% [8 of 1151]). The locations of the\nsuspensions are shown in Figure 4-15. The reasons for the suspension, and the action after the\nsuspension, are shown in Table 4-12. Of the eight suspended IM operations, three later\nresumed, three never resumed,10 and two were later terminated. Five of the eight (63%), were\nfrom one controller. The times to resume or terminate the IM operation are shown in Table\n4-13. Figure 4-15. Location of Controller Suspensions 10 These were cases were the controller entered a suspend command but never re-engaged. Therefore, while the\ncontroller entered the command for suspension, IM was terminated since it never resumed. The controller,\nhowever, did not enter the command for termination. 4-19 Table 4-12. Frequency of IM Suspensions by Suspension Reason and Subsequent Action Reason Subsequent action Resumed\nNot resumed Terminated Combined\nPerceived potential to\nincrease efficiency / spacing 2 2 Lead vectored 2 2\nSpacing concern 2 2\nUnknown 1 1 2\nTotal 3 3 2 8 Table 4-13. Mean Time to Resume or Terminate in Seconds (SD) after IM Suspension Subsequent action\nResumed (n = 3) 83.3 (59.1)\nTerminated (n = 2) 91.0 (118.8) 4.4.3 Controller IM Terminations\nForty-eight terminations occurred accounting for 4.2% (48 of 1151) of the IM operations. Forty-\nfour terminations were for pseudo-pilot aircraft and four were for flight deck participant\naircraft. Table 4-14 shows the terminations by controller tool set. Percentages are based on the\nnumber of total operations conducted when that tool set was used. A higher number of\nterminations occurred for the basic+ cue and prediction tool set as compared to both other tool\nsets, with more (7) relative to the basic tool set. Figure 4-16 and Figure 4-17 show the IM\ntermination locations by IM clearance type. Table 4-14. Percentage (and Frequency) of IM Terminations Controller tool set Total\nBasic 3.5 (13)\nBasic+ cue 3.7 (15)\nBasic+ cue and prediction 5.3 (20)\nCombined 4.2 (48) 4-20 Figure 4-16. IM Termination Locations for Both Achieve-by IM Clearance Types Figure 4-17. IM Termination Locations for Capture then Maintain IM Clearance Type 4-21 Of the 48 IM terminations, 60.4% (29 of 48) were achieve-by clearances and 39.6% (19 of 48)\nwere capture operations (Table 4-15). However, 3.3% (29/882) of the terminations were from\nall the achieve-by clearances and 7.1% (19/269) were from all the capture then maintain\nclearances. The majority (81.3%; 39 of 48) of terminations were terminated by ATC, followed by the pilot\nresponding to the controllers termination instructions. Thirteen percent (6 of 48) of cases were\nwhere only the pseudo-pilot or flight crew terminated. In all six cases, the controller either gave\na speed or told the flight crew to terminate IM, but neglected to make the keyboard entry.\nFinally, there were 6.3% (3 of 48) cases where only the controller made a keyboard entry to\nterminate and potentially issued a voice instruction. In all three cases, the pseudo-pilots\nappeared to have forgotten to terminate IM (but this did not appear to cause any spacing\nissues). Table 4-15. Frequency of IM Termination Actions Termination actions IM clearance type\nBoth achieve-by\nCapture then maintain Combined\nATC termination entry only 3 0 3\nATC termination entry and pilot\ntermination entry 22 17 39 Pilot termination entry only 4 2 6\nTotal 29 19 48 The mean time from initiation to termination is shown in Table 4-16. Clearances were\nterminated later for achieve-by clearance types (M = 298.7; SD = 190.3) as compared to the\ncapture then maintain clearance types (M = 196.0; SD = 166.1) . The tool sets had similar times\nand variances, although the basic+ cue tool set had a lower variance than the others. Table 4-16. Mean Time to Terminate after Initiation in Seconds (SD) Controller tool set IM clearance type\nBoth achieve-by\nCapture then maintain Combined Basic\n303.1 (198.8)\n200.6 (203.1)\n251.9 (201.0) Basic+ cue\n332.2 (183.1)\n147.3\n(74.0) 239.8\n(128.6) Basic+ cue and prediction\n260.8 (189.0)\n240.0 (221.1)\n250.4 (205.1) Combined\n298.7 (190.3)\n196.0 (166.1)\n247.4 (178.2) 4-22 Table 4-17 shows the reasons for the IM terminations. These reasons were stated to the\nobserver or noted in the post-scenario questionnaire by the controller (if they are in a category\nother than unknown). The perceived potential to increase efficiency / spacing category\nincludes situations such as those where the controller thought the ASG was too large or that a\nlead or trail aircraft could be given a vector. It should be noted that some of the actions after\nthe termination made the traffic situation more complex and created a worse spacing situation\nthan if the original schedule and sequence had been utilized. However, in other situations it\nwas possible to space an aircraft closer than the ASG that was provided by TBFM (e.g., 180\nseconds)11. Approximately half (10 of 21; 48%) of the perceived potential to increase efficiency\n spacing events could be attributed to one controller who vectored more frequently than\nother controllers. Table 4-17. Frequencies for Reasons for Controller IM Termination Reason Total\nPerceived potential to increase\nefficiency / spacing 21 Unknown 12\nSpacing concern 10\nRF turn concerns 2\nPrefer not using IM 1\nForgot IM active 1\nTrying something 1\nTotal 48 The spacing concern category includes situations where the controller noted an IM operation\nwould create a problematic spacing situation (e.g., IM trail aircraft not slowing). The RNP RF\nturn operation concern were situations where the controller terminated IM based on a\nconcern for spacing with an aircraft that was part of an RNP RF turn operation. The prefer not\nusing IM was where a controller preferred to manually manage the speed of the aircraft. The\nforgot IM active was a situation where the controller issued a speed to an IM trail aircraft\nafter forgetting the aircraft was flying IM. Observers noted other situations where this\noccurred, but the pilot reported doing IM and the controller chose not to terminate. Finally, the\nTrying something category was where the controller stated either he wanted to try a\nmaneuver to see how IM would react, or to see if an instruction would improve a situation. 11 Large intervals were due to the initial sequence and spacing of arrival aircraft. The TBFM/TSAS schedule does not\ncontain logic to speed an aircraft up above the profile speed to close up a naturally occurring large gap. 4-23 4.4.4 Flight Crew Reports of Unable\nIn addition to the controller terminations, there were five participant flight crew reports of\nunable12. Two were due to receiving an ASG too large message when trying to initiate IM\n(Table 4-18). Three were made by the flight crews based on the information provided by the IM\ndisplay information. Table 4-18. Frequencies and Reasons for Participant Flight Crew Reports of Unable IM Flight crew tool set Reason\nASG too large\nmessage Display info\nindicated a need Combined\nMin 1 1 2\nMin+ 1 2 3\nCombined 2 3 5 4.4.5 IM Speeds and Flight Crew Actions\nThis section reports data related to IM speed characteristics and participant flight crew /\naircraft behavior relative to those IM speeds13. Flight crew participants flew the BRUSR1 arrival\n33% (24 of 73) of the time and EAGUL6 arrival 67% (49 of 73) of the time. The BRUSR1 arrival\nfrom TRACON entry to touchdown was on average 14.2 minutes (SD=0.8) and the EAGUL6\narrival 11.5 minutes (SD=1.4) based on the length of flight path for each arrival. The PTP was\nalways YOKXO. If the lead aircraft was not flying the RNP RF turn (45/73; 62%), the ABP was the\nmerge point / DERVL. However, when the lead aircraft was flying the RNP RF turn (28/73; 38%),\nthe ABP was at the FAF / YOKXO and there was no maintain stage. 12 Pseudo-pilots did not have enough information to report unable, so none did so.\n13 As a reminder, the pilot participants only flew achieve-by then maintain IM type (no capture then maintain). 4-24 4.4.5.1 Frequency of IM Speed Changes\nTable 4-19 shows the number of speeds received by participant flight crews. The average\nnumber of IM speeds is shown in Table 4-20. The average number of IM speeds is higher for the\nachieve-by stage based on the IM aircraft flying for a longer period of time in that stage (on the\norder of 7 minutes) while the average number of speeds for the maintain stage is less based on\nthe shorter period of time in that stage (on the order of one minute). Table 4-19. Total Frequency of IM Speeds Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined\nMin
526 53 579\nMin+ 469 65 534\nCombined Table 4-20. Average Number of IM Speeds (SD) Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined Min 14.2(2.1)\n1.5 (2.5)\n15.7\n(3.6) Min+ 13.0(2.7)\n2.1 (2.0)\n15.1\n(3.4) Combined 13.6(2.4)\n1.8 (2.3)\n15.4\n(3.5) While the overall number of IM speeds is important, it may be more important to understand\nthe rate of IM speeds. The rates are shown in Table 4-21. The rates were similar for the two\ntool sets. The rate of IM speeds per minute was higher with less variance for the achieve-by\nstage (M = 2.1; SD = 0.6) as compared to the maintain stage (M = 1.5; SD = 1.3). The rates for\nthe stages and tool set are shown in Figure 4-18. 4-25 Table 4-21. Average Rate of IM Speeds (SD) per Minute Flight crew tool set Stage of achieve-by then maintain\nAchieve-by (n = 73)\nMaintain\n(n = 45) Combined\n(n = 73) Min (n = 37) 2.1(0.4)\n1.7 (1.5)\n2.0 (0.4) Min+ (n = 36) 2.1(0.7)\n1.2 (1.0)\n1.9 (0.5) Combined (n = 73) 2.1(0.6)\n1.5 (1.3)\n2.0 (0.5) Figure 4-18. Average Rate of IM Speeds per Minute for (a) Achieve-by and (b) Maintain Stages The distributions of the IM speeds are shown in Figure 4-19, Figure 4-20, and Figure 4-21 with\nshading to show density (wider shaded areas have more data points). As can be seen in the\nachieve-by stage figures, the speed are less frequent further out (e.g., 45 30 NM), then\nbecome more frequent (30 15 NM), and are most frequent close to the ABP. Figure 4-21 for\nthe maintain stage, shows the IM speeds to be fairly evenly distributed across the entirety of\nthe stage (note the different scale based on the maintain stage being conducted for a shorter\namount of time). 4-26 Figure 4-19. Distribution of IM Speeds for Achieve-by Stage with FAF / YOKXO as ABP Figure 4-20. Distribution of IM Speeds for Achieve-by Stage with Merge / DERVL as ABP Figure 4-21. Distribution of IM Speeds for Maintain Stage 4-27 4.4.5.2 Magnitude of IM speeds\nThe average magnitude difference between IM speeds was 6.4 knots (SD=2.3) (Table 4-22). As\nnoted in Section 3.1.2, the algorithm was designed to present the IM speeds in 10 kt\nincrements when greater than 10 NM from the ABP, and in 5 kt increments when less than 10\nNM from the ABP and when in the maintain stage. As would be expected then, the magnitude\nchanges were higher for the achieve-by stage (M=6.6; SD=2.3) with 5 and 10-knot increments\nthan the maintain stage (M=5.0; SD=0.0) with only 5-knot increments. The magnitude changes\nwere similar for the two tool sets. Figure 4-22 shows the distribution of the speed changes and\nthe transitions at 10 miles from the ABP for the two different ABPs. The 5 and 10-kt increment\nschedules can be clearly seen. Table 4-22. Mean Speed Change Magnitude (SD) in Knots by Flight Crew Tool Set and Achieve-\nby then Maintain Stage Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined Min 6.6(2.3)\n5.0 (0.0)\n6.5 (2.3) Min+ 6.5(2.3)\n5.0 (0.0)\n6.3 (2.2) Combined 6.6(2.3)\n5.0 (0.0)\n6.4 (2.3) Figure 4-22. Distribution of IM Speed Change Magnitude with (a) FAF / YOKXO as ABP and (b)\nMerge / DERVL as ABP 4-28 4.4.5.3 IM Speed Reversals\nOf the 1113 IM speed changes issued, 3% (31/1113) were speed reversals (i.e., the previous\nspeed change was an increase followed by a decrease or vice versa). Of the 31 speed reversals,\ntwenty-nine were a speed decrease followed by a speed increase. On average, 2% (24 of 1113)\nof IM speeds were speed reversals in the achieve stage of the IM operation and 0.6% (7/1113)\nin the maintain stage. However, when considering the percentage of speeds only associated\nwith the stages, fewer speed reversals occurred with the achieve-by stage (24/995; 2.4%) as\ncompared to the maintain stage (7/118; 5.9%) (Table 4-23). Additionally, fewer speed reversals\noccurred with the min+ tool set (31/534; 2.6%) as compared to the min tool set (17/579; 2.9%).\nFigure 4-23 and Figure 4-24 show the locations of the reversals for the tool sets and stages. Table 4-23. Percentage of Speed Reversals Flight crew tool set Stage of achieve-by then maintain\nAchieve-by (n =995)\nMaintain\n(n=118) Combined\n(n =1113) Min (n = 579) 2.3 9.4 2.9\nMin+ (n = 534) 2.6 3.1 2.6\nCombined (n = 1113) 2.4 5.9 2.8 Figure 4-23. IM Speed Reversal Locations for (a) the Min and (b) the Min+ Tool Sets 4-29 Figure 4-24. IM Speed Reversal Locations for (a) Achieve-by and (b) Maintain Stages 4.4.5.4 IM Speed Increases\nOf the 1113 IM speeds changes, seventeen percent (194/1113) were speed increases and\nrequired acceleration (Table 4-24). When considering the percentage of speeds only associated\nwith the stages, fewer speed increases occurred with achieve-by stage (150/995; 15.1%) as\ncompared to maintain stage (44/118; 37.3%). Additionally, fewer speed increases occurred for\nthe Min+ tool set (86/534; 16.1%) as compared to the min tool set (108/579; 18.7%) Table 4-24. Percentage of Speed Increases Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined\nMin 14.3 62.3 18.7\nMin+ 16.0 16.9 16.1\nCombined 15.1 37.3 17.4 4-30 4.4.5.5 Time Between IM Speed Changes and DTG\nOn average, the time between IM speeds was 29.2 sec (SD=34.8) (Table 4-25). Most of the\ntimes between IM speeds were between 6 second (10th percentile) and 87.9 second (90th\npercentile). There was more time between IM speeds for the achieve-by stage (32.3) than for\nthe maintain stage (26.1). There was also more time between speed changes for the min+ tool\nset (32.7) than there was for the min tool set (25.7). Table 4-25. Mean Time in Seconds (SD) Between IM Speeds Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined Min 31.5(38.7)\n19.9 (28.2)\n25.7 (33.5) Min+ 33.1(45.1)\n32.3 (27.3)\n32.7 (36.2) Combined 32.3(41.9)\n26.1 (27.8)\n29.2 (34.8) Most IM speed changes occurred between 3.6 NM (10 percentile) and 27.4 NM (90 percentile)\nfrom the PTP. Figure 4-25 and Figure 4-26 show the relationship between the time between IM\nspeeds and the distance to the ABP and PTP. The dots show specific events and the blue line is a\ncurved of best fit. The bars on top and right side of the graph show frequencies of events for\ndistance to the PTP (top) and time between IM speeds (right). Figure 4-25 shows that relationship when the participant flight crew flew the achieve-by IM\nclearance with YOKXO as the ABP (and PTP). Figure 4-26 shows that relationship when the\nparticipant flight crew flew the achieve-by then maintain IM clearance with DERVL as the ABP\n(and YOKXO as the PTP). As can be seen in both figures, IM speeds were generally closer\ntogether and occurred more often when close to the ABP. The speeds were closest in time and\nmost frequent when the aircraft was about 10 miles to the ABP for the achieve-by IM clearance\nand about 5 miles from the ABP for the achieve-by then maintain IM clearance. 4-31 Figure 4-25. Scatterplot of Time Between IM Speeds and Distance to the PTP with FAF /\nYOKXO as ABP (Achieve-by Clearance Type) Figure 4-26. Scatterplot of Time between IM Speeds and Distance to the PTP with Merge /\nDERVL as ABP (Achieve-by then Maintain Clearance Type) 4-32 4.4.5.6 Compliance with IM Speeds\nCompliance with IM speeds is defined as the participant flight crew dialing in the IM speed in\nthe MCP speed window. For the simulation, the flight crew was considered to be in compliance\nwith the IM speed if the speed set in the MCP speed window was within 2 kts of the IM speed14. As shown in Table 4-26, flight crews complied with more IM speeds when in the achieve-by\nstage (76.6%) than when in the maintain stage (70.3%) and with the min+ tool set (79.2%) than\nthe min tool set (72.9%). However, the statistical test noted in Section 4.1.3.2, did not reveal a\nstatistically significant difference between the two tool sets. When flight crews complied with IM speeds, the IM speeds had been presented for a longer\nperiod of time (M=40.6; SD=41.4) (Table 4-27 and Figure 4-27). When flight crews did not\ncomply with IM speeds, the IM speeds had been presented for a shorter period of time (M=7.9;\nSD=10.2). Table 4-26. Percentage of IM Speed Compliance Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined\nMin 74.1 60.4 72.9\nMin+ 79.3 78.5 79.2\nCombined 76.6 70.3 75.9 Table 4-27. Mean Duration (SD) of IM Speed Presentation Time (in Seconds) as Related to\nCompliance Flight crew\ntool set Stage of achieve-by then maintain\nAchieve-by Maintain Combined Complied\nNot complied Complied\nNot complied Complied\nNot complied Min 34.1(39.1)\n8.5 (8.4)\n45.5 (40.6)\n8.4 (21.1)\n39.8 (39.9)\n8.5 (14.8) Min+ 38.1(48.7)\n8.1 (4.7)\n44.6 (37.0)\n6.7 (6.5)\n41.4 (42.9)\n7.4 (5.6) Combined 36.1(43.9)\n8.3 (6.6)\n45.1 (38.8)\n7.6 (13.8)\n40.6 (41.4)\n7.9 (10.2) 14 The MCP speed knob in the flight deck simulator sometimes made it difficult to dial in the speed to the exact kt,\nso some latitude was allowed. 4-33 Figure 4-27. Mean Duration of IM Speed Presentation Time as Related to Compliance 4.4.5.7 IM Speed Conformance Monitoring Advisory\nOut of 73 runs, thirty-eight (52%) had at least one IM speed conformance monitoring advisory.\nThere were a total of 160 advisories accounting for 14% (160 of 1113) of IM speeds. The 160\nadvisories were associated with 119 IM speeds: 86 (72.3%) were for one IM speed and 33\n(27.7%) were for the same IM speed15. For all advisories, fewer occurred with the min+ tool set (61/534; 11.4%) as compared to the\nmin tool set (99/579; 17.1%) (Table 4-28). Figure 4-28 shows the location of the advisories for\nthe
individual tool sets. Additionally, fewer advisories occurred with the achieve-by stage\n(136/995; 13.7%) as compared to the maintain stage (24/118; 20.3%). Figure 4-29 shows the\nlocation of the advisories for the stages of the achieve-by then maintain clearance type. Table 4-28. Percentage of IM Speed Conformance Monitoring Advisories Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined\nMin 16.9 18.9 17.1\nMin+ 10.0 21.5 11.4\nCombined 13.7 20.3 14.4 15 As noted previously, the implementation for this simulation allowed for multiple alerts for one IM speed. This is\nnot required / specified in DO-361 (RTCA, 2015a). 4-34 Figure 4-28. IM Speed Conformance Monitoring Advisory Locations for the (a) Min Tool Set\nand (b) Min+ Tool Set Figure 4-29. IM Speed Conformance Monitoring Advisory Locations for the (a) Achieve-by and\n(b) Maintain Stages of the Achieve-by then Maintain Clearance Type 4-35 Of the 160 advisories, 67 (41.9%) were inside the MOPS no advisory threshold (i.e., should not\nhave been triggered) and 93 (58.1%) were outside the MOPS no advisory threshold16. As seen\nfor all advisories combined, fewer advisories occurred with the min+ tool set (18/534; 3.4%) as\ncompared to the min tool set (49/579; 8.5%) when the alert should not have been triggered\n(Table 4-29). Additionally, fewer advisories occurred with the min+ tool set (43/534; 8.1%) as\ncompared to the min tool set (50/579; 8.6%), but the difference is greatly reduced when the\nalert should have been triggered (Table 4-30). The average number of advisories for the achieve-by stage (60/995; 6.0%) are very similar to\nthe maintain stage (7/118; 5.9%) when the alert should not have been triggered. However,\nfewer advisories occurred with the achieve-by stage (77/995; 7.7%) as compared to the\nmaintain stage (16/118; 13.6%) when the alert should have been triggered. Table 4-29. Percentage of IM Speed Conformance Monitoring Advisories Inside the MOPS No\nAdvisory Threshold (Should Not have been Triggered per DO-316 [RTCA, 2015a]) Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined\nMin 8.9 3.8 8.5\nMin+ 2.8 7.7 3.4\nCombined 6.0 5.9 6.0 Table 4-30. Percentage of IM Speed Conformance Monitoring Advisories Outside the MOPS\nNo Advisory Threshold (Should have been Triggered per DO-316 [RTCA, 2015a]) Flight crew tool set\nStage of achieve-by then maintain Achieve-by Maintain Combined\nMin 8.2 13.2 8.6\nMin+ 7.2 13.8 8.1\nCombined 7.7 13.6 8.4 4.5 Aircraft Spacing and Separation\nThis section reports data related to aircraft spacing and separation. It includes both pseudo-\npilot and participant flight crew aircraft17. Measures in this section indicate how well the IM\naircraft achieved or maintained the ASG, and also how well aircraft conformed to the\nunderlying schedule and the associated slot markers. A detailed analysis of each of these\nmeasures is not conducted in this paper. The main purpose of reviewing these measures is to\ncompare how IM aircraft behaved relative to non-IM aircraft and whether they generally\nbehaved the same. 16 As noted previously, the implementation for this simulation alerted more often than specified in DO-361 (RTCA,\n2015a). 17 The participant flight crews only flew the achieve-by then maintain IM clearance (i.e., no capture then maintain).\nPseudo-pilot aircraft flew all clearances. 4-36 4.5.1 Schedule Conformance\nSchedule conformance measures how well aircraft met the original schedule at the various\nconstraint points (including the ABPs and PTP for IM). The measure, termed schedule deviation,\nis the difference between the STA and the ATA of an aircraft. Table 4-31 and Figure 4-30 show the schedule deviation at the constraint points. The first two\ndata columns are the meter fixes. IM aircraft were not included at these points because it was\ndifficult to determine whether or not aircraft had started IM. The non-IM aircraft are\nrepresentative of the spacing of IM aircraft upon entering the TRACON. Aircraft, on average,\nreached the meter fix ahead of schedule (by design, as described in Section 3.1.6). At the merge / DERVL, IM aircraft (M= -2.4; SD=11.9) had more schedule deviation and slightly\nmore variance as compared to non-IM aircraft (M=0.0; SD=10.4). At the FAF / YOKXO, IM\naircraft (M= -7.1; SD=10.9) had more schedule deviation and about the same variance as\ncompared to non-IM aircraft (M= -4.9; SD=11.2). At the merge / DERVL, IM aircraft had a mean deviation from schedule of less than 6 seconds\nand similar variances but the achieve-by type (M= -5.3; SD=12.1), had more schedule deviation\nthan the achieve-by then maintain (M= -1.1; SD=12.1) or the capture then maintain (M= -2.3;\nSD=10.9). At the FAF / YOKXO, all IM aircraft terminated IM. IM aircraft had a mean deviation\nfrom schedule within 1 second of each other and similar variances. All aircraft were ahead of schedule, on average, at YOKXO (the FAF). Table 4-31. Schedule Deviation in Seconds (SD) at Constraint Points Aircraft role IM\nclearance type Constraint point\nBRUSR (BRUSR1\nmeter fix) HOMRR\n(EAGUL6 meter fix)\nDERVL (merge) RHYAN\n(RNP RF turn)\nYOKXO\n(FAF) IM trail -\nAchieve-by -- -5.3\n(12.1) -0.3\n(9.6) -6.5\n(10.1) ABP & PTP\nIM trail -\nAchieve-by then\nmaintain -- --\n-1.1 (12.1)\nABP -4.4\n(15.2) -7.5\n(12.0)\nPTP IM trail \nCapture then\nmaintain -- -2.3(10.9)\n-2.0 (11.4) -7.1\n(10.3)\nPTP IM trail -\nCombined -- -2.4\n(11.9) -2.4\n(12.7) -7.1\n(10.9) Non-IM -8.8(17.6)\n-3.3 (21.0)\n0.0 (10.4)\n-1.7\n(9.1) -4.9\n(11.2) 4-37 Figure 4-30. Schedule Deviation at Constraint Points 4.5.2 Aircraft Position as Related to Slot Markers\nThis section provides information on how each aircraft deviated from the center of the slot\nmarkers (Section 4.5.2.1 Absolute Slot Marker Deviation), the amount of time aircraft were in\ntheir slot markers (Section 4.5.2.2 Aircraft Time in Slot Markers), and the difference between\nthe deviation from the center of the slot marker for a trail aircraft as compared to its lead\naircraft (Section 4.5.2.3 Relative Slot Marker Deviation). 4.5.2.1 Absolute Slot Marker Deviation\nThe absolute slot marker deviation metric shows how close an individual aircraft was to the\ncenter of its slot marker. A positive value indicates the aircraft was (behind schedule and)\nbehind the center of the slot marker. A negative value indicates the aircraft was (ahead of\nschedule and) ahead of the center of the slot marker. A zero value indicates the aircraft was\ncentered in its slot marker (see Appendix D for examples). Aircraft were delivered from en route into feeder airspace with a distribution around the slot\nmarkers. The feeder controller was expected to work to get non-IM aircraft on schedule / into\ntheir slot markers before handing off to the final controller. IM aircraft were working toward\nachieving or maintaining the ASG, regardless of slot marker position. The final controller 4-38 received the aircraft and was expected to get non-IM aircraft on schedule / into their slot\nmarkers (until around the final approach path where the controller is likely more concerned\nabout the relative spacing between aircraft than the schedule). Table 4-32 shows both time and distance (shaded gray) for deviations from the center of the\nslot marker by overall time in feeder and final airspace and at the handoff from final to feeder.\nDistance is included for a general reference, while time is discussed for the results. Figure 4-31,\nFigure 4-32, and Figure 4-33 show the distributions of the time deviation. Lines are shown in\nthese figures for the slot marker radius for the feeder (15 seconds) and the final (5 seconds)\ncontrollers. Table 4-32. Aircraft Slot Marker Center Deviation in Mean Seconds (SD) and NM (SD) Airspace location Aircraft role IM clearance type\nIM trail  Both\nachieve-by IM trail -\nCapture then maintain\nIM trail  Combined Non-IM sec NM sec NM sec NM sec NM Feeder -15.7(20.0)\n-1.2\n(1.6) -12.5\n(16.4) -1.0\n(1.3) -14.1\n(18.2) -1.1\n(1.5) -14.6\n(13.5) -1.1\n(1.1) Handoff to final 2.0(6.4)\n0.2 (0.5)\n1.8 (5.5)\n0.2 (0.4)\n1.9 (6.0)\n0.2 (0.5)\n0.1 (4.7)\n0.0 (0.4) Final -13.6(12.8)\n-0.8\n(0.8) -12.2\n(12.4) -0.7\n(0.8) -12.9\n(12.6) -0.8\n(0.8) -11.1\n(9.3) -0.7\n(0.6) IM (M= -14.1; SD=18.2) and non-IM aircraft (M= -14.6; SD=13.5) had similar deviations ahead of\nthe slot marker center in the feeders airspace. At the handoff, the IM aircraft (M=1.9; SD=6.0)\nwere further behind schedule and further behind the slot marker center as compared to the\nnon-IM aircraft (M=0.1; SD=4.7). In final controllers airspace, IM (M= -12.9; SD=12.6) and non-\nIM aircraft (M= -11.1; SD=9.3) had similar deviations from the slot marker center and were\nahead of schedule. In the feeders airspace, aircraft with the achieve-by clearance types (M= -15.7; SD=20.0) were\nfurther behind the slot marker center as compared to aircraft with the capture then maintain\nclearance type (M= -12.5; SD=16.4). At the handoff, aircraft with the achieve-by clearance types\n(M=2.0; SD=6.4) and aircraft with capture then maintain clearance type (M=1.8; SD=5.5) had\nsimilar deviations behind the slot marker center. In the final controllers airspace, aircraft with\nthe achieve-by clearance types (M= -13.6; SD=12.8) and aircraft with capture then maintain\nclearance type (M= -12.2; SD=12.4) had similar deviations ahead of the slot marker center. The general trend appears to be that all aircraft in the feeder airspace were ahead of schedule,\non average. This is, in part, based on the distribution of aircraft around the slot marker center\nwhen received from en route airspace as more aircraft were delivered ahead of schedule (as\ndescribed in Section 3.1.6). Then, all aircraft were delivered by the feeder to final controller on\naverage within 2 seconds of their slot marker centers. In the final controllers airspace, all 4-39 aircraft were, on average, ahead of the slot marker centers. Most differences between IM and\nnon-IM aircraft, and the two IM clearance types, were minor. Figure 4-31. Aircraft Slot Marker Center Deviation in Mean Seconds for Feeder Controller\nAirspace Figure 4-32. Aircraft Slot Marker Center Deviation in Mean Seconds at Handoff from Feeder to\nFinal Controller 4-40 Figure 4-33. Aircraft Slot Marker Center Deviation in Mean Seconds for Final Controller\nAirspace 4.5.2.2 Aircraft Time in Slot
Markers\nSlot markers have a 15-second radius for the feeder controller and a 5-second radius for the\nfinal controller. Therefore, the absolute slot marker deviation metric can be used to determine\nwhether aircraft were in their slot markers. Table 4-33 shows the percentage of time aircraft\nwere in their slot markers while in the feeder and final controllers airspace. From the previous\nsection, Figure 4-31, Figure 4-32, and Figure 4-33 show the distributions of the time deviation\nas well as the radius of the slot markers (as the lines drawn at 5 and 15 seconds). Table 4-33. Percentage of Time Aircraft were in Slot Markers Airspace location Aircraft role IM clearance type\nIM Trail  Both\nachieve-by IM Trail -\ncapture then maintain\nIM trail  Combined Non-IM\nFeeder 41.2 50.5 45.9 54.2\nFinal 17.2 16.9 17.1 19.1 Overall, all aircraft were in their slot markers less often in the feeders airspace as compared to\nthe finals airspace. IM aircraft (45.9%) were in the slot markers for less time in the feeders\nairspace as compared to non-IM aircraft (54.2%). Both achieve-by clearance type aircraft\n(41.2%) spent less time in their slot marker in the feeders airspace as compared to the capture\nthen maintain aircraft (50.5%). All aircraft had similar amount of time (approximately 17.5%)\nspent in their slot markers in the final controllers airspace. In summary, IM aircraft (particularly those flying the achieve-by clearance types) appeared to\nspend more time outside the slot markers than non-IM aircraft in the feeder controllers sector.\nThis is likely because the controller was working to get non-IM aircraft into their slot markers\nprior to the handoff to the final controller, while the achieve-by aircraft were still working\ntoward the ASG at a later point (DERVL and YOKXO) in the final controllers airspace. All aircraft 4-41 ended up spending similar amounts of time in the slot markers in the final controllers airspace.\nAs seen with the slot marker deviation data, the final controller appeared to let aircraft run\nahead of schedule after receiving aircraft very close to the slot marker centers. 4.5.2.3 Relative Slot Marker Deviation\nThe relative slot marker deviation measure provides information on where the trail aircraft was\nrelative to its slot marker based on the lead aircraft position relative to its slot marker (see\nAppendix D for sample configurations). The relative slot marker deviation is broken into\nconditions where the lead aircraft was either ahead of the center of the slot marker or it was\nbehind the center of the slot marker18. The reason to examine the relative slot marker deviation\nis to determine whether the behavior of an aircraft performing IM has an unexpected position\nfor its own slot marker relative to the lead aircraft. The figures in this section portray the results of this measure for the various possible relative\ntrail and lead aircraft positions. The lead aircraft is used as the reference. The figures show the\nslot marker (scaled to the appropriate size for both feeder [15-second radius] and final [5-\nsecond radius] controllers airspace), the mean (as a dot), and the standard deviation (as the\ndashed bar). The figures are intended to show the relative position of the aircraft. The slot\nmarker radius and aircraft distance from the slot marker center are to scale, but the time /\ndistance between the slot markers is not. Additional details on the compilation of this data are\navailable in Appendix E. Figure 4-34 and Figure 4-35 show the average relative positions of the lead and trail aircraft to\ntheir slot markers when the lead was ahead of its slot marker center. The figures show that\nacross all the conditions when the lead aircraft was ahead of its slot marker center, the IM trail\naircraft was also ahead with similar variance. IM pairs and non-IM pairs also look very similar\nacross all conditions. 18 The number of events where the lead aircraft was perfectly in the center of the slot marker (i.e., 0 deviation)\nwere too rare to include. 4-42 Figure 4-34. Lead and Trail Position Relative to Slot Markers When the Lead Aircraft was\nAhead of its Slot Marker Center (Feeder Airspace and Handoff) IM pair Non-IM pair Feeder\nairspace IM pair Non-IM pair Handoff\nto Final Direction of Travel 4-43 Figure 4-35. Lead and Trail Position Relative to Slot Markers When the Lead Aircraft was\nAhead of its Slot Marker Center (Final Airspace, DERVL, and YOKXO) IM pair Non-IM pair Final\nAirspace IM pair Non-IM pair\nDERVL IM pair Non-IM pair YOKXO Direction of Travel 4-44 Figure 4-36 and Figure 4-37 show the relative positions of the lead and trail aircraft to their slot\nmarkers when the lead was behind its slot marker center. Figure 4-36. Lead and Trail Position Relative to Slot Markers When the Lead Aircraft was\nBehind its Slot Marker Center (Feeder Airspace and Handoff) IM pair Non-IM pair Feeder\nairspace IM pair Non-IM pair Handoff\nto Final Direction of Travel 4-45 Figure 4-37. Lead and Trail Aircraft Position Relative to Slot Markers When the Lead Aircraft\nwas Behind its Slot Marker Center (Final Airspace, DERVL, and YOKXO) Figure 4-36 shows (when the lead was behind the slot marker center) that the situations were\nsimilar, but the IM aircraft pairs were often further apart than the non-IM pairs in the feeder\nairspace and at the handoff to the final controller. Figure 4-37 shows the same was true over\nthe course of time that the aircraft were in the final controllers airspace. However, at both\nDERVL and YOKXO, the IM trail aircraft is also behind with similar variance. IM pairs and non-IM\npairs also look very similar for both DERVL and YOKXO. Overall, the figures show few differences between IM and non-IM aircraft. 4.5.3 Spacing Error\nThe following reviews the spacing error (the difference between the planned interval and the\nachieved interval) in seconds measured at DERVL and YOKXO. For all aircraft, the planned\ninterval was the STA of the trail aircraft minus the STA of the lead aircraft at the same point. For\nIM aircraft, the planned interval became the ASG at the ABP. For IM aircraft the spacing error is\na direct measure of how close the IM aircraft were to the ASG. For non-IM aircraft, it is a\nmeasure of how well the aircraft met the planned interval. (see Appendix D for further detail).\nFor both IM and non-IM aircraft, this is not a measure of schedule conformance. IM pair Non-IM pair\nFinal Airspace IM pair Non-IM pair\nDERVL IM pair Non-IM pair YOKXO Direction of Travel 4-46 Trail IM aircraft that did achieve-by only operations and those that did capture then maintain\ndid not have a specified spacing goal at DERVL so the aircraft are excluded for measurement at\nthat point. Those aircraft are included, along with all other aircraft for the spacing error at\nYOKXO (also the PTP and FAF). Table 4-34 shows the spacing errors by aircraft role and\noperation at the two points. Table 4-34. Mean Spacing Error in Seconds (SD) at Two Points Waypoint Aircraft role IM clearance type\nIM trail -\nAchieve- by (no\nmaintain) IM trail -\nAchieve-\nby then maintain IM trail \nCapture then\nmaintain IM trail \nTotal Non-IM DERVL ---\n0.2 (4.5)\nABP --- 0.2(4.5)\n1.0 (8.5) YOKXO\n-1.0\n(4.9) ABP & PTP 0.2\n(3.0)\nPTP 0.6\n(5.1)\nPTP 0.4\n(4.1) 0.4\n(8.2) The IM aircraft that achieved at DERVL (M=0.2; SD=4.5) had less spacing error and less variance\nthan the non-IM aircraft (M=1.0; SD=8.5). With respect to meeting performance baseline / goal\ndiscussed in Section 2.2.2.1, IM aircraft that achieved at DERVL met the performance goal\n(Table 4-35). The non-IM aircraft also met their performance baseline. When aircraft reached\nYOKXO, all aircraft had similar spacing errors, though non-IM aircraft had the largest variance.\nAll IM aircraft and non-IM aircraft met the performance baseline / goals at YOKXO. Table 4-35. Aircraft Role and Performance Baseline / Goal Achievement Waypoint Aircraft role IM clearance type IM trail -\nAchieve-by IM trail -\nAchieve-by then maintain IM trail \nCapture then maintain Non-IM\n95% 10 secs\n68% 5 secs\n95% 10 secs\n68% 5 secs\n95% 10 secs\n68% 5 secs\n68% 12 secs DERVL --- ---\nYes 95.8%\nABP Yes\n88.4%\nABP --- --- Yes75.6% YOKXO Yes\n97.4%\nABP & PTP Yes\n89.5%\nABP & PTP Yes\n98.5% PTP Yes\n93.5% PTP Yes\n100%\nPTP Yes\n100%\nPTP Yes\n77.1% 4-47 See Figure 4-38 and Figure 4-39 for the spacing error for IM and non-IM aircraft for the two\npoints. See Figure 4-40 and Figure 4-41 for more detail19 on the spacing error of only the IM\naircraft. The blue horizontal lines in the figures show the IM performance goal of 5 seconds and\nthe gray horizontal lines show the TSAS performance baseline of 12 seconds. Overall, IM and\nnon-IM aircraft met the performance baseline / goals expected for the operations. Figure 4-38. Spacing Error Distribution for IM and Non-IM Aircraft at DERVL Figure 4-39. Spacing Error Distribution for IM Aircraft by IM Clearance Type and Non-IM at\nYOKXO 19 One event during for capture then maintain clearance type was late by 55 seconds and was removed. This\nallowed greater detail to be portrayed for the remaining events. 4-48 Figure 4-40. Spacing Error Distribution for IM Aircraft at DERVL Figure 4-41. Spacing Error Distribution for IM Aircraft by IM Clearance Type at YOKXO 4.5.4 Maintenance of the ASG\nWhile aircraft performing achieve operations reach the ASG at a point, aircraft in the maintain\nstage are required to maintain the ASG throughout. The maintain stage began (1) at the ABP\n(DERVL) for achieve-by then maintain operations and (2) when the MSI was within 10 seconds\nof the ASG for capture then maintain operations. Achieve-by clearance types
when in the maintain stage were within 10 seconds of the ASG (the\n95% tolerance performance goal) on average 97.7% of the time, which met the performance\ngoal. Capture then maintain operations that were in the maintain stage were within tolerance\n100% of the time. 4-49 Table 4-36. Percentage of Time IM Aircraft were within 10 Seconds of the ASG (95%\nPerformance Goal) During the Maintain Stage IM clearance type\nAchieve-by then maintain 97.7\nCapture then maintain 100 In summary, the maintain stage of the achieve-by then maintain clearance type met the\nperformance goal over the course of the maintain stage as well as at the PTP of YOKXO (as\nshown in Section 4.5.3). For the capture then maintain clearance type, the performance goal\nwas met over the course of the maintain stage and at the merge point of DERVL and at the PTP\nof YOKXO (as shown in Section 4.5.3). 4.5.5 Events Below Separation Standard\nFive events occurred where an aircraft was below the applicable separation standard20. None of\nthe events were for trail aircraft conducting IM. One event was an aircraft that had started IM\nbut then subsequently terminated IM. The controller stated that the reason for the termination\nwas so he could speed the trail aircraft up beyond the IM speeds, so IM was unrelated to the\nseparation issue. There were no specific causes determined for the other events. Figure 4-42\nshows the locations of the events. Figure 4-42. Location Where an Aircraft was Below the Applicable Separation Standard Note: Two events occur just prior to DERVL and overlap on the figure. 20 No events inside of YOKXO were considered as the was no tower controller in the simulation. 4-50 4.6 IM During Terminal Metering Acceptability\nIn the post-scenario questionnaires, controllers were asked whether IM is operationally\nacceptable (Table 4-37 and Figure 4-43). Controllers, on average, agreed regardless of role or\ntool set. Table 4-37. Mean (SD) Controller Response to Post-Scenario Statement Given the\nappropriate training, IM during terminal metering is operationally acceptable for TRACON IM Initiation Controller tool set\nController role Feeder Final Basic 79.6(20.0)\n77.3 (20.4) Basic+ cue 73.5(21.9)\n77.4 (20.1) Basic+ cue and prediction 71.9(22.8)\n76.5 (18.9) Figure 4-43. Controller Responses to Post-Scenario Statement Given the appropriate\ntraining, IM during terminal metering is operationally acceptable 4-51 In the post-scenario questionnaires, pilots were also asked whether IM is operationally\nacceptable (Table 4-38 and Figure 4-44). The pilots, on average, agreed regardless of position or\ntool set. Table 4-38. Mean (SD) Pilot Response to Post-Scenario Statement Given the appropriate\ntraining, IM is operationally acceptable Flight crew tool set\nPilot role PF PM Min 88.0(12.7)\n81.8 (23.9) Min+ 87.3(15.8)\n82.1 (22.7) Figure 4-44. Pilot Responses to Post-Scenario Statement Given the appropriate training, IM\nis operationally acceptable Participants were asked (in the post-simulation questionnaire too) whether IM is operationally\nacceptable, the majority (7/9; 78%) of controllers agreed (M=65.0; SD=22.4) and the majority of\npilots (16/18; 89%) also agreed (M=82.9; SD=23.4). Participants were asked whether IM is\noperationally desirable. The majority (7/9; 78%) of controllers agreed (M=67.3; SD=24.7) and\nthe majority (15/18; 83%) of pilots also agreed (M=79.7; SD=23.7). All controllers reported both\nachieve-by and capture than maintain clearances to be acceptable. Controllers were asked\nwhether it was acceptable to receive aircraft already performing IM when handed off from the\nfeeder controller and when handed off from the en route environment. All controllers agreed\nwhen receiving aircraft from the feeder controller (M=88.7; SD=12.3) and the majority (8/9;\n89%) of controllers agreed when receiving aircraft from the (simulated) en route controller\n(M=78.8; SD=3.7). Figure 4-45 depicts these results. 4-52 Figure 4-45. Summary of Controller and Pilot Responses on IM Desirability and Acceptability\nStatements 4-53 4.6.1 Traffic Spacing Awareness and Acceptability\nParticipants were asked whether their level of traffic awareness was acceptable. Responses are\nshown next and in Figure 4-46. Controllers o IM trail aircraft All controllers agreed (M=86.6; SD=10.5) o Non-IM aircraft All controllers agreed (M=91.8; SD=7.6) Pilots o Lead aircraft for IM All pilots agreed (M=90.3; SD=9.6) o Aircraft other than lead aircraft The majority (16/18; 89%) of pilots agreed (M=83.6; SD=20.2) Figure 4-46. Controller and Pilot Responses to My level of traffic awareness was acceptable 4-54 In the post-scenario questionnaire, controllers were asked whether they were confident the\nspacing of the aircraft would remain outside their separation requirement. The results are\nshown in Table 4-39 and Figure 4-47. The controllers, on average, agreed regardless of role, tool\nset, or aircraft role. Higher variability was exhibited in the feeder and final replies for IM aircraft\nwith the basic+ cue and prediction tool set. As mentioned in Section 0, a statistical test was run\non this measure and no statistically significant difference was found. Table 4-39. Mean (SD) Controller Response to Post-Scenario Statement I was confident that\nthe spacing of the aircraft would remain outside my separation requirement Controller tool set Controller role\nFeeder Final IM Non-IM IM Non-IM Basic 79.7(24.2)\n83.3 (24.9)\n77.9 (20.8)\n85.1 (15.3) Basic+ cue 81.6(22.8)\n86.0 (13.3)\n80.1 (24.6)\n89.1 (16.1) Basic+ cue and prediction 75.7(26.7)\n80.3 (21.5)\n75.9 (28.0)\n88.5 (14.6) Figure 4-47. Controller Responses to Post-Scenario Statement I was confident that the\nspacing of the aircraft would remain outside my separation requirement 4-55 In the post-scenario questionnaire, controllers were asked whether they could detect spacing\nor separation issues. The results are shown in Table 4-40 and Figure 4-48. Controllers agreed,\non average, regardless of role, tool set, or aircraft role. Higher variability was exhibited in\nfeeder replies for IM aircraft with all tool sets and for non-IM aircraft with the basic tool set. Table 4-40. Mean (SD) Controller Response to Post-Scenario Statement I was able to detect\nwhen spacing / separation issues were developing for aircraft Controller tool set Controller role\nFeeder Final IM Non-IM IM Non-IM Basic 82.5(25.6)\n84.5 (25.5)\n80.2 (22.9)\n88.2 (12.8) Basic+ cue 79.8(25.1)\n84.0 (21.8)\n82.3 (21.9)\n90.0 (10.1) Basic+ cue and prediction 78.8(26.0)\n84.3 (19.6)\n81.3 (20.8)\n86.2 (15.9) Figure 4-48. Controller Responses to Post-Scenario Statement I was able to detect when\nspacing / separation issues were developing for aircraft 4-56 In the post-scenario questionnaire, pilots were asked whether they could determine if they\nwould remain within tolerances of the ASG. The results are shown in Figure 4-49. Pilots, on\naverage, agreed regardless of role or tool set. Figure 4-49. Pilot Responses to Post-Scenario Statement I could detect whether I would\nremain within tolerances to achieve and maintain the assigned spacing goal The following questions are from the post-simulation questionnaire and are summarized in\nFigure 4-50. Participants were asked whether they could detect spacing or separation issues\nduring IM. The responses were: Controllers o IM aircraft Controller responses were variable but the majority (6/9; 67%) agreed (M= 64.8;\nSD= 26.7) o Non-IM aircraft The majority (8/9; 89%) of controllers agreed (M= 85.7; SD= 18.8) Pilots o Min The majority (16/18; 89%) of pilots agreed (M= 72.6; SD= 22.7) o Min+ The majority (17/18; 94%) of pilots agreed (M= 86.2; SD= 15.8) 4-57 Controllers were asked if the spacing of the aircraft would remain outside their separation\nrequirement. The majority (7/9; 78%) of the controllers agreed for IM aircraft (M=63.1;\nSD=27.7) and all controllers agreed for non-IM aircraft (M= 80.3; SD=14.6). Participants were\nasked whether the spacing when conducting IM was acceptable. The majority (7/9; 78%) of\ncontrollers agreed for IM aircraft (M=68.7; SD=22.7) and the majority (7/8; 88%; missing=1)\nagreed for non-IM aircraft (M=82.1; SD=16.5). The majority (17/18; 94%) of pilots agreed\n(M=85.1; SD=22.4). Several comments were made on the questions related to controller confidence in monitoring\nand predicting spacing and separation. A majority (approximately 7/9; 78%) of controllers\nexpressed issues with not knowing what the [IM aircraft / flight crew] is doing / not knowing\nthe speeds to be flown and when. Controllers reported trusting the flight crew and letting it\nplay out, but feeling out of the loop. Similar comments were also made to the research\nobservers. The observers noted that even though IM appeared to perform as expected,\ncontrollers did not feel entirely comfortable allowing aircraft to conduct IM, especially when\nclose to the separation standard. Certain geometries appeared to increase that unease, e.g.,\ntwo aircraft (one acting as an IM trail aircraft) on one route with an aircraft between them\n(acting as the IM lead aircraft) on the other route. When controllers were asked whether the handed-off aircraft would be accepted with minimal\nproblems, the majority (8/9; 89%) agreed for IM aircraft (M= 84.6; SD=16.6) and all agreed for\nnon-IM aircraft (M= 93.4; SD=6.6). All designed-in off nominal events where a trail aircraft overtook its lead were detected by the\ncontrollers. Since the situation was created by speed alone, the overtake took a long time to\nevolve and appear to the controllers as problematic. However, by the time the trail aircraft was\nin the final controllers airspace, the situation became apparent and the final controller\nterminated the IM operation. This was a point where the no speed alerts were no longer\nprovided, so the controller needed to detect the situations without an alert. Pilots were asked whether they could determine if they would remain within tolerances of the\nASG. The majority (15/18; 83%) agreed (M= 75.7; SD=24.4). As mentioned in Section 0, a\nstatistical test was run on this measure and no statistically significant difference was found.\nHowever, comments for this question and other similar ones indicate that the tolerances were\nunclear, especially without the graphical progress indicator. Figure 4-50 depicts the results for\nthis line of questioning for pilots and controllers. 4-58 Figure 4-50. Summary of Controller and Pilot Responses on Spacing Acceptability Statements 4-59 The majority (8/9; 89%) of controllers agreed
that there were an acceptable number of aircraft\nperforming IM (M=77.2; SD=27.6) (Figure 4-51). Controllers reported on average that 78.6%\n(SD=19.7; missing=2) aircraft performing IM and above was / would be reasonable (Figure\n4-52). Figure 4-51. Controller Responses to There were an acceptable number of aircraft\nperforming IM Figure 4-52. Controller Responses to There were an acceptable number of aircraft\nperforming IM What percentage and above is reasonable? 4-60 Participants were asked whether it was clear that IM was driving toward appropriate spacing.\nController responses were variable but the majority (7/9; 78%) of controllers agreed for IM\naircraft (M=62.9; SD=33.9) and all (8/8; 100%; missing=1) agreed for non-IM aircraft (M=89.8;\nSD=12.0). Pilot responses were variable but the majority (15/18; 83%) of pilots agreed (M=76.5;\nSD=27.9). Pilots were asked whether they trusted that the IM algorithm was providing the\nappropriate speeds. Their responses were variable but the majority (15/17; 88%; missing=1)\nagreed (M=73.4; SD=26.0). However, six pilots, regardless of whether they agreed or not,\nreported some level of distrust. The observer noted several pilot comments indicating\nconfusion about IM speeds. For example, if aircraft had a large amount of time to make up and\ncould fly 250 kts, some pilots reported being confused about not receiving an IM speed of 250\nkts. The reason for this could have been that the IM speed was limited (as described in Section\n3.1.2) but still acceptable, or because the IM speed provided was the speed necessary,\nregardless of speed limiting. The limiting was not annunciated to the flight crew. Figure 4-53\ndepicts these results. Figure 4-53. Summary of Controller and Pilot Responses on IM Trust Statements 4-61 Pilots were asked whether they tried to out-guess the algorithm. Forty-seven percent (8/17;\nmissing=1) provided yes responses (Figure 4-54). However, the majority (15/18; 83%) of pilots\nreported they did not choose to ignore an IM speed (Figure 4-55). Figure 4-54. Pilot Responses to Did you ever try to out-guess the IM algorithm and the IM\nspeeds? Figure 4-55. Pilot Responses to Did you choose not to fly an IM speed? 4-62 4.6.2 Workload\nIn the post-scenario questionnaire, controllers and pilots were asked to rate their average\noverall workload on the Bedford Workload Rating Scale. Table 4-41, Table 4-42, and Figure 4-56\nshow the ratings for both controllers and pilots. As can be seen, controllers and pilots generally\nfound workload to be acceptable. Table 4-41. Mean (SD) Pilot Response to Post-Scenario Bedford Workload Rating Scale Flight crew tool set Pilot role PF PM Min 2.7(1.2)\n2.4 (1.0) Min+ 2.7(1.1)\n2.5 (1.0) Table 4-42. Mean (SD) Controller Response to Post-Scenario Bedford Workload Rating Scale Controller tool set Controller role Feeder Final Basic 2.8(1.4)\n2.6 (1.3) Basic+ cue 2.7(1.2)\n2.6 (1.2) Basic+ cue and prediction 2.8(1.3)\n2.5 (1.1) 4-63 Figure 4-56. Controller and Pilot Response Means to the Bedford Workload Rating 4-64 When asked about the acceptability of their overall workload, all controllers agreed that it was\nacceptable (M=88.1; SD=10.2). The pilot responses were variable (M=80.5; SD=26.2), but the\nmajority (15/18; 83%) agreed. The majority (15/18; 83%) of the pilots also agreed they received\nan acceptable number of IM speeds (M= 75.4; SD=24.9). However, at least four pilots,\nregardless of whether they agreed or not, reported that the IM speeds could be too frequent at\ntimes. Figure 4-57 depicts these results. Figure 4-57. Summary of Pilot Responses on Workload Statements 4-65 4.6.3 Controller Acceptability Rating Scale\nIn the post-scenario questionnaire, controllers were asked to rate their acceptability of IM with\nController Acceptance Rating Scale (Table 4-43 and Figure 4-58). As can be seen, controllers\ngenerally found the system to be acceptable. Table 4-43. Mean (SD) Controller Response to Post-Scenario Controller Acceptance Rating\nScale Controller tool set\nController role Feeder Final Basic 7.8(1.6)\n8.0 (1.2) Basic+ cue 7.9(1.6)\n7.8 (1.8) Basic+ cue and prediction 7.5(1.9)\n7.6 (1.5) Figure 4-58. Controller Response Means to Controller Acceptance Rating Scale 4-66 The following comments were captured in the questionnaires or were made to the observers.\nThey are not directly tied to one question, but are included for completeness. The environment of terminal metering and IM during nominal conditions created a\nrelatively low workload environment. Controllers sometimes mentioned worries about becoming monitors and being less\nengaged in this environment. 4.7 Displays 4.7.1 Air Traffic Controllers\nIn the post-scenario questionnaire, controllers were asked whether they had the necessary\ndisplay elements to conduct IM. The results are shown in Table 4-44 and Figure 4-59.\nControllers agreed, on average, regardless of role or tool set. Higher variability existed for both\nfeeder and final replies, with the basic and the basic+ cue tool sets. As mentioned in Section 0,\na statistical test was run on this measure and no statistically significant difference was found. Table 4-44. Mean (SD) Controller Response to Post-Scenario Statement I had the necessary\ndisplay elements for conducting IM operations Controller tool set\nController role Feeder Final Basic 76.8(25.3)\n71.5 (26.8) Basic+ cue 75.5(27.7)\n80.3 (25.9) Basic+ cue and prediction 81.1(21.4)\n82.3 (15.2) 4-67 Figure 4-59. Controller Responses to Post-Scenario Statement I had the necessary display\nelements for conducting IM operations 4-68 In order to understand the impact of terminal metering elements on IM operations, controllers\nwere asked whether the elements were helpful for IM and non-IM aircraft (Figure 4-60). The majority of controllers agreed for the following elements (some with higher variability): (Non-blue) Slot markers o Non-IM aircraft (6/9; 67%) (M= 79.8; SD= 22.7) Speed advisories o IM aircraft (6/9; 67%; missing n= 1) (M= 66.1; SD= 31.2) Note: Large variance driven by one 0 rating o Non-IM aircraft (6/9; 67%) (M = 69.1; SD= 25.4) Slot marker speeds o IM aircraft (8/9; 89%) (M= 76.9; SD= 28.0) o Non-IM aircraft (8/9; 89%) (M= 80.0; SD= 28.4) Aircraft indicated airspeed o IM aircraft (8/9; 89%) (M= 77.2; SD= 28.2) o Non-IM aircraft (8/9; 89%) (M= 78.4; SD= 28.3) Runway sequence number o IM aircraft (8/9; 89%) (M= 82.1; SD= 19.6) o Non-IM aircraft (8/9; 89%) (M= 82.0; SD= 19.6) Controller responses were variable for the following elements. (Non-blue) Slot Markers o IM Aircraft (M= 52.8; SD= 35.0) Early / Late indicator o IM aircraft (M= 35.9; SD= 34.1) o Non-IM aircraft (M= 30.2; SD= 24.9) Runway assignment o IM aircraft (M= 71.0; SD= 26.1) o Non-IM aircraft (M= 70.9; SD= 26.2) Timeline o IM aircraft (M= 40.7; SD= 38.9) o Non-IM aircraft (M= 34.1; SD= 36.4) 4-69 Figure 4-60. Controller Responses to The terminal metering elements were helpful for the IM and non-IM aircraft 4-70 The majority (7/9; 78%) of controllers agreed that the position of IM aircraft relative to the slot\nmarkers was logical (M= 74.4; SD=24.6). The majority (7/9; 78%) of controllers also agreed that\nthe behavior of the slot markers relative to IM aircraft was logical (M= 67.7; SD=25.6). Controllers were also asked about the new IM elements and if they were useful for IM. The\nresults were: Trail aircraft status o The majority (8/9; 89%) of controllers agreed (M= 82.1; SD= 16.8) Lead aircraft status o The majority (8/9; 89%) of controllers agreed (M= 81.9; SD= 16.9) Blue slot marker o Controller responses were variable (M= 66.7; SD= 33.7) While the controllers were not asked about the ATPA features, it was noted by some that ATPA\ndistance information covered the trail aircraft status information (e.g., T(A)) in the aircraft data\nblock. This was reported as an issue. Controllers reportedly like the status information in the\ndata block and did not want it to be removed near and on final. If this occurred and the\ncontrollers did not have the blue slot markers for the run, the only way they knew the aircraft\nwas doing IM was via the IM clearance window. Controllers were asked if the information in the IM clearance window was helpful for IM. The\nmajority (7/9; 78%) of the controllers agreed for the IM status information (M=71.1; SD=30.8).\nThe majority (7/9; 78%) of the controllers agreed for the projected spacing / ETA differential\n(M=75.1; SD=21.2). The majority (8/9; 89%) of controllers also reported that it was helpful to be\ninformed when there was no speed solution for IM (M=82.4; SD=17.9). Figure 4-61 depicts the\nresults. 4-71 Figure 4-61. Summary of Controller Responses on IM Display Element Statements 4-72 When asked about the necessary monitoring of traffic, controller responses were variable but\nthe majority of controllers (7/9; 78%) reported that the monitoring of IM traffic was increased\n(M=3.2; SD=2.0) and the controller replies were variable for non-IM traffic (M=3.8; SD=1.9)\n(Figure 4-62). When asked whether the necessary monitoring was acceptable, the majority\n(8/9; 89%) of controllers agreed for IM aircraft (M=77.6; SD=17.4) and all controllers agreed for\nnon-IM aircraft (M=85.2; SD=12.1) (Figure 4-63). Figure 4-62. Controller Responses to How did aircraft conducting IM during terminal\nmetering effect your need to monitor traffic? Figure 4-63. Controller Responses to The necessary aircraft monitoring was acceptable 4-73 4.7.2 Flight Crew\nThe pilots were asked about select, key min elements as well as the min+ IM elements. For the\nmin elements, the majority (14/18; 78%) of pilots agreed the IM speed change advisory was\nsufficient to detect the presence of a new speed (M=71.4; SD=23.5). All pilots agreed that the\nIM speed conformance monitoring alert was useful (M=85.4; SD=8.6) and the majority (17/18;\n94%) agreed that it is a minimum requirement (M=84.2; SD=18.4). Figure 4-64 depicts the\nresults. Figure 4-64. Summary of Pilot Responses on Min Display Element Statements 4-74 For the min+ elements, the majority (14/18; 78%) of pilots reported that the graphical progress\nindicator was
useful (M=81.8; SD=20.1). However, pilot responses were variable as to whether\nit was a minimum requirement (M=59.2; SD=30.3). Pilots were then asked whether the\ngraphical progress indicator was unnecessary. Responses were variable (M=59.3; SD=31.8). The following was captured in comments made to the observer, or were in notes from the\nobserver. The graphical progress indicator was generally preferred (over only the ASG and SI) to\ndetermine whether or not the ASG would be achieved or maintained. Without the graphical\nprogress indicator, pilots had no clear information on the tolerances. Even with the graphical\nprogress indicator, the situation could change as the operation evolved. A situation that was, at\none point, out of tolerance, could get within tolerance at a future point. Pilots wanted clear\nguidance from the avionics on when to report unable interval spacing. Pilot responses were variable about whether the speed tape was useful (M=59.3; SD=31.8).\nThree pilots commented that they wanted it on or near the PFD. The responses were variable\nas to whether it was a minimum requirement (M=32.9; SD=27.6), though the majority\ndisagreed that it was a minimum requirement (13/18; 72%). Figure 4-65 depicts these results. Figure 4-65. Summary of Pilot Responses on Min+ Display Element Statements 4-75 In the post-scenario questionnaire, pilots were asked whether they had the necessary display\nelements to conduct IM. Table 4-45 and Figure 4-66 shows pilots, on average, agreed,\nregardless of role or tool set. As mentioned in Section 4.1.3, a statistical test was run on this\nmeasure and no statistically significant difference was found. Table 4-45. Mean (SD) Pilot Response to Post-Scenario Statement I had the necessary display\nelements for conducting IM Flight crew tool set\nPilot role PF PM Min 83.8(17.1)\n79.3 (22.4) Min+ 89.2(14.1)\n81.6 (21.9) Figure 4-66. Pilot Responses to Post-Scenario Statement I had the necessary display\nelements for conducting IM 4-76 The majority of pilots reported the min (13/18; 72%) and the min+ (16/18; 89%)\nimplementations included all the necessary information to conduct IM (Figure 4-67). Figure 4-67. Pilot Responses to Did the combination of both the AGD and CDTI\nimplementations include all the information necessary for you to conduct IM? The majority of pilots reported that no display elements were confusing or misleading on\nneither the AGD (16/18; 89%) or CDTI traffic display (17/17; 100%; missing=1) (Figure 4-68). The\nreports of misleading information appeared to be due to initial misunderstandings or\nsimulation issues (e.g., didnt understand the box at first), not on-going issues. Figure 4-68. Pilot Responses to Did you find any elements on the displays to be confusing or\nmisleading? 4-77 Pilots reported being able to focus more on the AGD than the CDTI. The PFs reported spending\n83% of their time on the AGD while the PMs reported spending 67% of their time on the AGD\n(Figure 4-69). Figure 4-69. Pilot Responses to Considering total time on the IM displays, estimate the total\npercentage of time using each display 4-78 The majority (17/18; 94%) of pilots reported being able to perform IM by primarily focusing on\nthe AGD (M=87.4; SD=14.1). When asked if they could integrate the displays into their normal\nscan, the majority (16/18; 89%) of the pilots agreed for the AGD (M= 75.1; SD=27.1) but the\nresponses were variable for the CDTI (M=54.6; SD=32.8). The majority (16/18; 89%) of the pilots\nagreed that the necessary scan time was acceptable (M=74.4; SD=24.4). Pilot responses were\nvariable (M=63.7; SD=30.1), but the majority (13/18; 72%) agreed that the amount of head\ndown time was acceptable. Figure 4-70 depicts these results. Figure 4-70. Summary of Pilot Responses on the Instrument Scan 4-79 Pilot were asked whether the display combination was acceptable for the CDTI states of\nclearance entry, entry evaluation, and execution. The majority of pilots agreed for all states. Clearance (awaiting) entry (15/18; 83%) (M= 79.1; SD= 23.7) Entry evaluation / cross flight deck coordination (16/18; 89%) (M= 83.4; SD= 18.5) Execution / IM conduct without graphical progress indicator (15/18; 83%) (M= 69.3; SD=\n23.1) Execution / IM conduct with graphical progress indicator (16/18; 89%) (M= 83.0; SD=\n18.9) For the awaiting entry state, the research observer noted that participants often chose to type\nin the lead aircraft identification instead of selecting the lead aircraft and having the field\nautomatically populated (as described in Section 3.1.1.2). This appeared to be due to the\ndifficulty / burden associated with finding the lead aircraft on the CDTI traffic display. Finally, when asked if they would be willing to perform IM with the tested displays, the majority\n(16/18; 89%) agreed for both the minimum (M= 74.9; SD=22.3) and the minimum+ (M= 79.1;\nSD=25.5) implementations. Figure 4-71 depicts the results. As would be expected, pilot comments included ones stating a preference for having the IM\ninformation integrated into the PFD and navigation display. Figure 4-71. Summary of Pilot Responses to Display Acceptability Statements 4-80 4.8 Roles and Responsibilities\nParticipants were asked whether their roles and responsibilities were clear. The majority (8/9;\n89%) of the controllers agreed for IM aircraft (M= 87.0; SD=17.8) and all controllers agreed for\nnon-IM aircraft (M= 93.0; SD=7.9). The majority (17/18; 94%) of the pilots agreed (M= 87.1;\nSD=19.2). Figure 4-72 depicts the results. Figure 4-72. Summary of Controller and Pilot Responses on Role and Responsibilities\nStatements 4.9 Time on RNAV Arrival\nWhen aircraft were conducting IM, they were on their RNAV procedure 98.2% of the time. Non-\nIM aircraft were on their RNAV procedure 93.8% of the time. IM aircraft were off the RNAV\npath on average 222.2 seconds (SD=187.0) and non-IM aircraft for 317.7 seconds (SD=182.0)\n(Table 4-46). As can be seen, less time was spent off the RNAV path for IM aircraft as compared\nto non-IM aircraft. Table 4-46. Total Time in Seconds (SD) Aircraft were off the RNAV Path Controller tool set Aircraft role IM Non-IM Combined Basic 245.6(196.5)\n307.1 (164.9)\n276.4 (180.7) Basic+ cue 210.7(181.5)\n339.4 (160.3)\n275.1 (170.9) Basic+ cue and prediction 210.2(183.0)\n306.7 (220.7)\n258.5 (180.7) Combined 222.2(187.0)\n317.7 (182.0)\n270.0 (177.4) 4-81 4.10 Communications\nParticipants were asked whether the IM clearance was acceptable. The majority (7/9; 78%) of\ncontrollers agreed for capture then maintain (M=80.4; SD=22.1) and controller responses were\nvariable for achieve-by (M=57.9; SD=30.6) clearances. Four controllers reported wanting to\nkeep the clearance concise. Two mentioned that data link communications would help. Participant pilots only received achieve-by clearances and the majority (16/18; 89%) agreed\nthat they were acceptable (M=84.6; SD=27.3). The majority (16/18; 89%) of the pilots reported\nthat the necessary information was available in the clearance to detect and select the lead\naircraft (M=82.8; SD=22.2). Participants were asked whether the use of the lead aircraft identification in the IM clearance\nwas acceptable. The majority (7/9; 78%) of controllers agreed (M=82.9; SD=19.9). Pilot\nresponses were variable (M=79.4; SD=27.6) but the majority (14/17; 82%; missing=1) agreed.\nFigure 4-73 depicts these results. Figure 4-73. Summary of Controller and Pilot Responses on Phraseology Statements 4-82 When asked whether they had any issues when the lead aircraft identification was used in\ncommunications, the majority (8/9; 89%) of controllers and the majority (15/18; 83%) of pilots\nreported they did not (Figure 4-74). Figure 4-74. Controller and Pilot Responses to Did you have any issues during\ncommunications when the lead aircraft call sign was used? 4-83 4.11 En Route Initiation\nThe main topic to examine in the simulation was controllers initiating IM in the TRACON.\nHowever, some questions existed about receiving aircraft into the TRACON that were already\nconducting IM. Since the en route IM initiation scenarios were outside the main set of\nscenarios, the majority of the post-scenario results are presented separately in this section. The\nresults are shown in Figure 4-75. Note that the post-simulation questionnaire did not\ndistinguish between TRACON and en route initiation so the results are only from the post-\nscenario questionnaire. In the post-scenario questionnaire, controllers, on average, agreed when there were asked\nwhether they: Were confident the spacing of the aircraft would remain outside their separation\nrequirement o Higher variability existed for IM aircraft for all tool sets and for non-IM aircraft for\nthe basic+ cue tool set Could detect spacing or separation issues o Higher variability existed for IM aircraft for the basic+ cue and the basic+ cue and\nprediction tool sets IM is operationally acceptable o Higher variability existed for IM aircraft for the basic+ cue tool set Had the necessary display elements to conduct IM o Higher variability existed for IM aircraft for the basic+ cue tool set 4-84 Figure 4-75. Controller Responses to Post-Scenario Statements on En Route Initiation 4-85 In the post-scenario questionnaire, controllers were asked to rate their average overall\nworkload during en route initiation on the Bedford Workload Rating Scale. Figure 4-76 shows\nthe ratings. Controllers generally found workload to be acceptable across the tool sets. Figure 4-76. Controller Responses to the Bedford Workload Rating for En Route Initiation In the post-scenario questionnaire, controllers were asked to rate their acceptability of IM\nduring en route initiation with Controller Acceptance Rating Scale. Figure 4-77 shows the\nratings. Controllers generally found IM operationally acceptable across the tool sets but the\nbasic+ cue and prediction tool set average is in the improvement needed category. Figure 4-77. Controller Responses for Controller Acceptance Rating Scale for En Route\nInitiation There were zero cases of aircraft spacing below the applicable separation and no IM\nterminations occurred. 4-86 4.12 Simulation Assessment\nParticipants were asked whether the training they received was adequate. All controllers\nagreed for IM (M=93.0; SD=7.4) and TSAS / terminal metering (M=93.1; SD=7.1). The majority\n(16/17; 94%; missing=1) of the pilots agreed (M=82.2; SD=14.0). Participants
were also asked\nwhether the overall activity was effective for evaluating IM during terminal metering. The\nmajority (8/9; 89%) of controllers agreed (M=81.7; SD=18.3), and the majority (16/17; 94%;\nmissing=1) of pilots agreed (M=85.8; SD=13.9). Figure 4-78 depicts these results. Figure 4-78. Summary of Controller and Pilot Responses on Simulation Assessment\nStatements 5-1 5 Discussion 5.1 IM During Terminal Metering\nTerminal metering was of more interest (from a research perspective) for the controller\nparticipants, than the pilot participants, because it was new to them. Also, terminal metering\nwas less of an issue for the flight crews because it was relatively transparent to them because\nthey conduct IM operations in the same manner in and out of metering environments.\nTherefore, the flight crew questions and replies are more relevant in consideration of IM\noperations, while the controller replies cut across the entire environment of terminal metering,\nRNP RF turns, and IM. Majorities of both controllers and pilots reported IM during terminal metering was\noperationally desirable and acceptable. A majority of controllers reported IM was compatible\nwith terminal metering operations (as seen with: Rognin et al., 2005; Callantine et al., 2012;\nPeterson et al., 2012; Baxley et al., 2016). At times, the IM / relative spacing operation was very\nsimilar to the behavior of controllers who transition from an absolute spacing operation to a\nrelative spacing operation in the later stages of approach and landing during terminal metering\noperations (as seen with: Callantine et al., 2012). Controllers also reported that it was acceptable to receive aircraft from both a (simulated) en\nroute controller and a (participant) feeder controller. The majority of controllers reported they\nwere confident both IM and non-IM aircraft would be handed off with minimal problems,\nthough non-IM aircraft received higher / more positive ratings. Controllers did not appear to\nhave issues with two different ABPs, nor spacing / separation issues with IM aircraft that were\nstill in the achieve stage when passing the merge point. Controllers found mixed IM (~60%) and non-IM equipage acceptable. The percentage of IM\naircraft in this simulation was higher than other work done in the past that also found mixed IM\nand non-IM equipage to be acceptable (e.g., Callantine et al., 2012). Therefore, this level as well\nas lower levels such as those seen in early NASA ATD-1 simulations (e.g., 3 aircraft per scenario,\n10 20%) appear to be acceptable. However, equipage levels higher than 60% appear to be\nmore desirable based on controller feedback from this simulation. The majority of controllers and pilots reported that roles and responsibilities were clear. The\nmajority of both groups also reported that overall workload was acceptable, though the pilot\nresults were more variable. The majority of controllers and pilots reported acceptable traffic\nawareness, and associated monitoring, for IM and non-IM aircraft. However, though controller\nresponses were variable, the majority reported that their monitoring increased with IM aircraft.\nThis may indicate some level of distrust of IM aircraft or a shift from actively controlling to\nmonitoring aircraft. While IM during terminal metering appears acceptable, a few issues were noted about the\noverall metering environment with IM and structured arrivals that join the final approach\ncourse with speeds and altitudes for the flight crew to fly. Controllers noted that this\nenvironment created a relatively low workload environment and that it could cause controllers 5-2 to act more as monitors and be less engaged. They also reported RNP RF turns as challenging\nin general based on an aircraft joining the final approach course late in the approach / at the\nFAF. 5.2 IM Conduct 5.2.1 Controllers\nOf all the IM clearances proposed by the terminal metering system, 97% were initiated by the\ncontrollers. Of the 3% rejected, over half were by one controller. The capture then maintain\nclearances were rejected less often than the achieve-by clearance types, and were initiated\napproximately 11 seconds faster and earlier in the airspace. This seems likely due to the\ndifferent geometries of the two clearance types. In the capture then maintain operations,\naircraft are on the same path (likely easier to visualize) and the clearance information is\nreduced (likely easier to read and interpret21). Thipphavong et al. (2013) also found controllers\nwere more likely to initiate IM when the IM trail aircraft and the lead were on the same route\nas is seen in the capture then maintain clearance type. Less than 1% of IM operations were suspended and of those, less than half were resumed. Over\nhalf of the suspensions were from one controller. One quarter of the suspensions were due to\nspacing concerns. Other known reasons were related to increasing efficiency and vectoring the\nlead. Controller terminations of IM occurred in approximately 4% of the IM operations and the\nmost frequent reasons were the same as those for suspensions. There were 4% fewer\nterminations for achieve-by operations and they occurred over 1.5 minutes later in the airspace\nas compared to capture then maintain operations. Few differences were found between the\ndifferent controller tool sets. The majority of controllers reported: (1) they were confident both IM and non-IM aircraft\nwould remain outside their separation requirement, (2) the spacing achieved by IM and non-IM\naircraft was acceptable, (3) they were able to detect spacing / separation issues developing,\nand (4) it was clear aircraft were working toward appropriate spacing. However, for all four\nstatements, non-IM aircraft had more positive ratings and / or lower variability. Additionally,\nobservations and comments showed controllers did not appear to feel entirely comfortable\nallowing aircraft to conduct IM, especially when close to the separation standard. Controllers\nreported some discomfort in not actively managing the aircraft speed and not knowing when\naircraft would change speeds. Few differences were found for controller actions or replies based on controller role. Overall,\nIM operations for controllers went well, with almost all clearances issued and initiated, and\nvery few operations suspended or terminated. However, some level of discomfort in IM\noperations was observed. Based on reports from controllers, the issue seemed to be related to\nnot actively issuing speeds to IM aircraft and thus not knowing what speeds would be flown\nand when. 21 This same situation is possibly seen when comparing the results noted in Bone et al. (2007) and Penhallegon and\nBone (2008). See Section 2.5.1.2. 5-3 5.2.2 Flight Crew\nThe achieve-by operations had a rate of 1.5 speeds per minute while capture operations had a\nrate of approximately two per minute. The majority of pilots reported these rates as acceptable\nas was the case in past simulations (e.g., Swieringa et al., 2014; Kibler et al., 2015). About 6%\nfewer IM speed conformance advisories were issued for the achieve stage as compared to the\nmaintain stage. For the achieve-by stage, IM speeds occurred more frequently the closer the\naircraft was to the ABP. For the capture stage, IM speeds were fairly evenly distributed across\nthe entirety of the stage. IM speed reversals (a speed decrease followed by speed increase) can be challenging (i.e.,\nconfusing and annoying) for flight crews. Speed increases can also be challenging in arrival and\napproach operations when flight crews normally only decelerate and have to configure the\naircraft for landing (i.e., deployment of flaps). The observer noted that pilots had issues with IM\nspeeds that required an acceleration after the aircraft started the configuration for landing. This\nissue has been noted in other IM activities (e.g., Penhallegon, Bone, and Stassen, 2016b). Only\n3% of the IM speeds were reversals but 17% of the IM speeds were speed increases. Fewer of\nboth occurred for the achieve stage as compared to the maintain stage, and most speed\nreversals occurred later in the operation and when in the final controllers airspace. The majority of the pilots reported that it was clear the IM speeds were driving toward\nachieving and maintaining the ASG, though responses were variable and the observer noted\nthat participants had issues with this. Regardless, the majority of pilots reported the spacing\nachieved / maintained was acceptable and that they were able to detect whether they would\nremain within tolerances for the ASG. About half the pilots reported trying to out-guess the IM algorithm, though only a few reported\nchoosing to fly a speed other than the IM speed. As with the controllers, IM operations went well for the flight crews with most clearances being\nflown and few reports of unable. However, some level of distrust in the IM algorithm\noperations was observed. Based on reports from pilots, the issue seemed to be related to the\nquestion of feasibility of the IM operation. 5.3 Aircraft Spacing and Separation\nIn general, aircraft entered the feeder controllers airspace slightly ahead of schedule on\naverage (as described in Section 3.1.6). On average, aircraft were also ahead of, but within 3\nseconds of, schedule at the constraint points of DERVL and RHYAN. Aircraft stayed ahead of\nschedule at the FAF / YOKXO by approximately 7 seconds (for IM aircraft) and 5 seconds (for\nnon-IM aircraft). Aircraft were in their slot markers about half time in the feeder controllers airspace but IM\naircraft were inside for less time (46%) than non-IM aircraft (54%). When aircraft were outside\nof their slot markers, they were generally ahead of the slot markers (ahead of schedule). At the\nhandoff from the feeder to final controller, aircraft were on average within 2 seconds of their\nslot marker centers. Both IM and non-IM aircraft were in the slot markers approximately 18% of\nthe time in the feeder controllers airspace. Again, when aircraft were out of the slot markers, 5-4 they were generally ahead of the slot markers (ahead of schedule). Wynnyk
and Kopald (2013)\nalso found non-IM aircraft conformance with their slot markers decreased over the course of\nthe scenario, though not to the degree seen in this simulation. Although aircraft were often outside of their slot markers and ahead of schedule, the relative\nposition of the trail aircraft to the lead is important. Overall, the results show few differences\nbetween IM aircraft and non-IM aircraft based on lead aircraft position relative to its slot\nmarker. The majority of the time the trail aircraft (IM or non-IM) had the same relative position\nto its slot marker as the lead aircraft did to its slot marker. While minor differences between IM\nand non-IM pairs existed when the lead aircraft was behind its slot marker, they appeared\nminor and were resolved as the aircraft merged at DERVL and arrived at the FAF / YOKXO.\nOverall, IM and non-IM aircraft met the performance baseline / goals expected for the\noperations. Aircraft in general being out of the slot markers (yet still relatively close to the schedule) in the\nfinal controllers airspace, after arriving in the slot markers is logical. The final controllers\nbecame more concerned with relative spacing of aircraft, as seen in past simulations. For\nexample, Wynnyk and Kopald (2013) stated that final controllers were more focused on relative\nspacing / separation and that the slot markers changed from a schedule objective to an on-\ngoing status indication of whether or not a merge was going to be successful. IM has been\nconducting relative spacing prior to this point and will continue to do so, thus an IM aircrafts\nbehavior looks much like the controllers behavior at this point. Final controllers may also be\nwilling to close up spacing if any gaps exist. Several controllers in this simulation expressed an\ninterest in closing gaps and landing aircraft as soon as possible, regardless of the schedule. Some past work showed controller concerns with IM aircraft being outside their slot markers\nlonger than non-IM aircraft (e.g., Cabrall et al., 2012). This was seen in this simulation in the\nfeeder controllers airspace and most likely due to achieve-by aircraft working toward the ASG\nthough not as quickly as the controller was getting aircraft into the slot markers for handoff to\nthe final controller. The majority of controllers in this simulation reported that IM aircraft\nposition and behavior of an aircraft relative to its slot marker was logical. However, this was\nfound to be an issue in past simulations and may continue to be noted as problematic because\nthe controllers task during metering is to get aircraft into their slot markers. The controller may\nget non-IM aircraft into their slot markers more quickly than IM aircraft that are working to\nachieve the ASG at a downstream point. There were no controller comments suggesting that candidate IM aircraft should be in their slot\nmarkers in feeder controllers airspace prior to starting IM (as there were in the concept\nevaluation activities mentioned in Section 2.4.2.3). There were only five events where the spacing within an aircraft pair was below the separation\nstandard in the feeder or final controllers airspace. None of the events were for an aircraft\nactively conducting IM. The specific reasons for the events were unclear. 5-5 5.4 Displays 5.4.1 Controllers\nControllers were asked about the terminal metering tools, but only in relation to IM operations.\nThey were also asked about the usefulness of the new IM display elements. Three controller\ntool sets were examined in this simulation: Basic: TSAS features, the IM clearance window, as well as the IM trail and lead aircraft\nstatus fields in the data blocks Basic+ cue: The basic tool set plus the slot marker color change (cue) Basic+ cue and prediction: The basic+ cue tool set plus the spacing prediction value\n(shown in parentheses after the lead aircraft identification in the IM clearance window) Controller replies on the helpfulness of the terminal metering tools for IM and non-IM aircraft\nwere similar to past results. The ratings were generally positive for both IM and non-IM aircraft,\nexcept for the early / late indicator (which was not available for IM aircraft) and the timeline.\nBoth of these had lower ratings and a lot of variability. The early / late indicator was not shown\nfor IM aircraft, so this result does not suggest an issue with IM or IM integration. This\nsimulation also did not have any specific events that caused the controller to use the timeline\n(e.g., schedule disruptions), nor did any results indicate that it caused issues for IM aircraft. The ratings for the terminal metering tools were also generally similar for both IM and non-IM\naircraft except for the slot markers (without the additional IM cue). Controllers found the slot\nmarkers (without the additional IM cue) less useful for IM but the responses had a lot of\nvariability. However, observations indicate the slot markers (without the additional IM cue)\nwere still important and utilized for IM aircraft. IM aircraft behavior relative to the slot markers\nwas reported in the previous section. When considering the results for the terminal metering\ntools, they did not appear to conflict with IM operations and several seemed to provide as\nmuch useful information for IM aircraft as for non-IM aircraft. Overall, past work such as Cabrall et al. (2012) had similar results as controllers reported the\nterminal metering tools were useful when controlling IM aircraft and that the slot markers were\nless usable for IM aircraft. Thipphavong et al. (2013) also had similar results and reported\ncontrollers found the slot markers, timeline, and speed advisories were useful but less so for IM\naircraft. When asked about the IM display information in the IM clearance window, the majority of\ncontrollers reported the IM status information, the spacing prediction / ETA differential, and\nthe no speed alerting were helpful, as seen in past simulations with several of the elements\n(e.g., Peterson et al., 2012; Callantine et al., 2013; Thipphavong et al. 2013). Benson et al.\n(2011) and Peterson et al. (2012) also had controller reports of the spacing prediction / ETA\ndifferential being useful, but replies were variable as to whether it should be a minimum\nfeature. For the data block IM elements, trail aircraft and lead aircraft status indicators were reported as\nhelpful by a majority of controllers, as with past simulations (e.g., Benson et al., 2011; Cabrall et 5-6 al., 2012; Callantine et al., 2012; Callantine et al., 2013). Presenting the status of the lead\naircraft is not only helpful in understanding aircraft roles, it was found by Thipphavong et al.\n(2013) to reduce the chance of suspending an IM operation by 20%. The color change of slot markers to blue (aka cue) for trail aircraft actively conducting IM\nreceived variable responses regarding its usefulness (note these replies are for the same slot\nmarkers as noted above but this question was for the color change for IM). However,\nobservations indicate the cue was still important and utilized for IM aircraft (and may help\navoid accidentally issuing a speed to an aircraft already conducting IM). The cue may be more\nuseful for controllers who did not initiate IM, and therefore do not have memory of which\naircraft had been engaged in IM. The cue is the first visual indication of which aircraft are\nconducting IM when entering the airspace. The cue was introduced for the simulation based on\nfeedback received during the concept evaluation activities leading up to the simulation. Those\nindividuals reported the cue as useful and helpful as compared to situations without it.\nHowever, controllers in this simulation did not clearly report it to be as useful and helpful. For the different controller tool sets, statistical tests found no statistically significant difference\nbetween tool sets (or controller roles) for the question of being confident the IM aircraft\nspacing would remain outside the separation requirement. There was also no difference for the\nquestion of whether they had the necessary display elements. Other data did not reveal clear\ntrends. However, as mentioned previously, the majority of controllers reported that the spacing\nprediction / ETA differential was useful while the slot marker cue received some mixed\nresponses (although comments and observations indicated they were useful). Additional work\nis likely necessary to continue to determine the necessary controller tools. The currently-fielded ATPA feature was available and utilized in the simulation. Some\ncontrollers reported issues with the ATPA distance covering the trail aircraft IM status (e.g,\nT(A)) when aircraft were on final and ATPA was active. They liked the IM information in the data\nblock and if they did not have the slot marker cue, the only way they knew the aircraft was\ndoing IM was in the IM clearance window. 5.4.2 Pilots\nTwo flight deck tool sets were examined in the simulation. The first was termed min and was\nbuilt to the standards specified in DO-361 (RTCA, 2015a). The second was the min+ tool set\nthat included two features not required in DO-361 (RTCA, 2015a): the graphical progress\nindicator and speed tape. IM information was presented on two different displays: the CDTI\ntraffic display and the AGD. The AGD was the primary display to be used during IM and contained the key information\nelements. It was expected to be where the pilots primarily focused with an occasional reference\nto the CDTI traffic display. Pilots reported being able to primarily focus on the AGD while\noccasionally referencing the CDTI traffic display. Pilots reported the AGD was easier than the\nCDTI traffic display to integrate into the normal instrument scan. The pilot replies were
variable\nas to how well the CDTI traffic display could be integrated into their normal instrument scan.\nHowever, the majority agreed that their overall scan time was acceptable and generally agreed\nthat the required head down time was acceptable. Related to this, pilots reported wanting the 5-7 IM information integrated into the PFD and navigation display, versus into new displays such as\nan auxiliary traffic display. The min IM speed change advisory was reported as useful and a minimum requirement for IM\nby the pilots. The majority of pilots also reported that placing a box around new IM speeds was\nsufficient for detecting the presence of a new speed. Pilots did not report a need for an aural\nalert for each new IM speed. Data did show that when pilots had not complied with IM speeds\nthey had been presented for a shorter period of time (around 8 seconds) than those that were\ncomplied with. That could be due to pilots missing the IM speed (which was noted by the\nobserver in some cases) or pilots not having time to implement the IM speed before another\none was displayed. Either way, it seems that it was reasonable operationally to miss the speed\nas another one was about to be presented. All pilots agreed that the IM speed conformance\nmonitoring alert was useful and the majority agreed that it is a minimum requirement. This\nalert has an aural associated with it and seemed to be sufficient for an aural alert related to IM\nspeeds. Since the IM speed conformance alerting was, unintentionally, implemented differently than\nspecified in DO-361 (RTCA, 2015a), it is interesting to determine whether the behavior seen in\nthe simulation helps validate the requirements. Approximately 58% of the advisories provided\nin the simulation were per the standard. The other 42% were not and were inside the tolerance\nthreshold specified in the standard. The number of advisories seen in the simulation were not\nreported to be problematic and may have actually helped more with conformance than if the\nalerting was implemented per the standard. The use of this result is a bit unclear due to the\npotential interaction between the additional alerts and the speed conformance. The display implementation purposefully did not make a distinction for the pilots about\nwhether they were in the achieve or maintain stage of the achieve-by then maintain clearance\ntype. The distinction was not believed to something that the flight crew needed to act on, so\nthe information was not provided. This approach did not reveal any issues with pilot awareness\nof IM operations, which suggests this should not be a minimum requirement. A majority of pilots reported a willingness to perform IM with both the min and min+ tool sets\nand that both included the necessary information. The majority also agreed that they were able\nto detect spacing issues with both tool sets. Additionally, two statistical tests run on the use of\nthe two tool sets did not reveal any statistically significant findings. This indicates that the min\ntool set may be sufficient as a minimum implementation. However, caution should be exercised\nwith these results as past work and some data from this simulation indicate that at least the\ngraphical progress indicator should be considered for a useful minimum requirement. This\nresult and caution is similar to that reported in Swieringa et al. (2014) where a simulation\nsimilar to that reported here was conducted. The following paragraphs will review the two min+\nfeatures (i.e., the graphical progress indicator and speed tape). The graphical progress indicator was reported as useful by the majority of pilots, but opinions\nwere mixed as to whether it is a minimum requirement. However, much of the past work on IM\nhas either required this feature or has worked to perfect it. EUROCONTROL requires a graphical\nspacing cue (Hoffman et al., 2006), NASA Ames used one (NASA, 2004), and NASA Langley has\nbeen working to perfect one (e.g., Swieringa et al., 2014). MITRE recommended one but did not 5-8 have one developed based on supporting a specific implementation (Bone et al., 2003). Pilots\nhave also indicated a strong preference for such a feature (e.g., Baxley et al., 2013).\nAdditionally, the feasibility check as implemented in this simulation was based on DO-361\n(RTCA, 2015a) defined bounds that were found to be in error (based on the use in this\nsimulation). As a result, the bounds used in this simulation flagged infeasible operations more\nthan was intended by the authors of DO-361 (RTCA, 2015a). Additionally, operations that were\nshown as infeasible would become feasible again before the flight crew acted. Pilots appeared\nto have difficulty determining whether an operation was going to remain infeasible and what\naction to take. These issues could have led to questioning whether the graphical progress\nindicator should be a minimum. Pilot comments in various questions indicate that it is\nimportant to clarify tolerances and the associated actions. Pilot opinions were variable on whether the speed tape on the CDTI traffic display was useful\nand a minimum requirement. Pilot opinion of the speed tape was likely driven by the placement\nof the feature on the CDTI traffic display, which was not where the pilots were expected to, or\ndid, focus. Moving this feature to the AGD or PFD could impact this result and make the feature\nmore desirable, as it contains key details such as the IM speed, whether the IM speed is set in\nthe MCP, and whether the aircraft is flying the IM speed. Such information has been displayed\nor required in past research (e.g., Hoffman et al., 2006; Bone and Long, 2014; Latorella, 2015). Overall, the min+ tool set received more yes replies (compared to the min) when pilots\nreported whether the display included all the necessary information. Additionally, higher /\nmore positive ratings were provided (compared to the min) when pilots reported the ability to\ndetect developing spacing issues. The ratings were also higher for the min+ tool set (compared\nto the min) when pilots were asked whether the displays were acceptable during IM execution. The objective data also shows more positive trends for the min+ tool set. While the rate of IM\nspeeds per minute and magnitude of IM speed for both tool sets were similar, pilots complied\nwith approximately 6% more IM speeds and had less spacing error at the ABP for the min+ tool\nset (though the trends should only be considered in light of other trends as neither were\nstatistically significant). Pilots also received approximately 6% less IM speed conformance\nadvisories for the min+ tool set. Few to no comments were received about the need for additional display features beyond the\nmin or min+ tool sets. However, there were pilots replies from different questions asking for\ntrend information on the graphical progress indicator, especially when near or at the tolerance\nboundaries. 5.5 Communications\nThe participant pilots did not receive capture then maintain clearances, but those clearances\nare shorter and so the amount of information contained in them should also be acceptable. The\ncapture then maintain clearance was reported as acceptable by controllers. The amount of\ninformation in the achieve-by clearance type was reported as acceptable by participant pilots.\nHowever, the achieve-by clearance type acceptability had variable controller responses. Just\nless than half of the controllers reported wanting to keep the clearance concise, though efforts 5-9 had already been made in this simulation to keep the clearance concise (e.g., not stating the\nPTP in the clearance). The pilots also reported that the necessary information was available from the clearance to\ndetect and select the lead aircraft. The information provided was the lead aircraft identification\n(e.g., American one twenty-three). Once the flight crew had the lead aircraft identification, they\ncould either select the traffic by touching it on the display or they could enter the aircraft\nidentification and it would be selected for them. The majority of the time they did the latter. Pilots and controllers reported the use of the lead aircraft identification in the IM clearance was\nacceptable, though there was some variability in the pilot replies. The majority of both pilots\nand controllers reported no issues when the lead aircraft identification was used. 5.6 IM Benefits\nThe spacing error (the difference between the planned interval and the achieved interval) was\nmeasured for all aircraft at the FAF / YOKXO. For IM aircraft, the planned interval became the\nASG at the ABP and the spacing error is a direct measure of how close the IM aircraft were to\nthe ASG. For non-IM aircraft, it is a measure of how well the aircraft met the planned interval.\nBoth IM and non-IM aircraft had a small spacing error (under 1 second) but the IM aircraft had\nhalf the variance (4.1 seconds less) of non-IM aircraft. These results are similar to past work\nthat found IM reduces the inter-arrival spacing variation (e.g., Rognin et al., 2005; Prevot et al.,\n2007). IM aircraft met the ASG with a 4.1 second SD. Therefore, IM aircraft met the\nperformance goal of 5.0 seconds IAT SD mentioned in Section 2.2.2.1. Overall, IM and non-IM\naircraft met the performance baseline / goals expected for the operations. Aircraft conducting IM spent approximately 1.5 minutes more on the RNAV path (less time\nvectored) as compared to non-IM aircraft. This result is similar to that found by Thipphavong et\nal. (2013) who also found IM aircraft (and their lead aircraft) remained on the RNAV routes\nlonger than those not conducting IM. Keeping IM aircraft on their routes is an indication that\ncontrollers were allowing those aircraft
to conduct IM and that IM was not causing enough of a\nspacing / separation concern to vector the IM aircraft off the optimized RNAV routes. 6-1 6 Recommendations 6.1 IM During Terminal Metering General Acceptability\nWhile IM during terminal metering was found acceptable by controllers and flight crews in\ngeneral, some topics may require additional study. Initiation geometries different than those examined here may be more challenging. One\nexample may be when the trail aircraft performing IM is in one feeder controllers airspace\nand the lead aircraft is in another feeder controllers airspace (such as opposite corner\nposts). The display tool sets and topics examined in this simulation could also be examined\nin these more challenging geometries. For example, the topic of IM aircraft potentially\nbeing out of their slot markers more often than non-IM aircraft may be more of an issue for\nfeeder controllers who are working the aircraft into the slot markers for the next constraint\nand the handoff to the final controller. If the lead aircraft is not in the feeder controllers\nsector, this could be more of an issue. Dependent runway operations such as those\ncurrently being defined in RTCA may introduce new issues, and therefore, should also be\nexamined. Overall, the vast majority of IM operations were initiated and only a few were suspended or\nterminated by the controller. This indicated at least some level of trust on the part of the\ncontroller. Trust may also come with additional experience. However, controllers did report\nincreased monitoring and showed some signs of mistrust. The topic of controller trust in the behavior of IM aircraft should continue to be\nexamined until the appropriate operations and tools are identified to support sufficient\ntrust in IM. Controllers did not have significant issues with receiving aircraft from en route controllers that\nwere already conducting IM. This was noted as a potential issue in the concept evaluation\nactivities leading up to the simulation. Situations should be identified where receiving aircraft conducting IM from en route\ncontrollers is an issue. Once they are identified, they should continue to be examined to\ndetermine whether the issue can be addressed or those operations should be excluded. The simulation only proposed an achieve-by clearance to controllers when the ASG was\nbetween 70 and 240 seconds (as noted in Appendix A). There were times when the controller\nnoted ASGs closer to 240 seconds and did not find IM necessary for such large intervals. Consideration should be given to the maximum reasonable ASG in the terminal\nenvironment so controllers are not bothered with IM clearances they may want to reject. 6-2 Flight crews were generally in agreement about the acceptability of IM speeds and algorithm\nbehavior, but there was some variability in replies related to the clarity of IM speeds driving\ntoward the appropriate spacing. Also, approximately half the pilots reported trying to outguess\nthe algorithm. The topic of flight crew trust in the behavior of IM should continue to be examined until\nthe appropriate tools are identified to support sufficient trust (discussed further in display\nSection 6.3.2). While IM may contribute to controllers monitoring traffic more than actively engaging with\nthem, the overall environment in which IM was placed (i.e., structured arrivals that join the\nfinal approach course with speed and altitude restrictions) already had reduced controller\nactive engagement (e.g., limited vectoring). The topic of controllers as monitors may require additional study or, at least, continued\nconsideration. While not an IM issue, RNP RF turns from downwind to the FAF were found to be challenging\nfor controllers. It may be desirable to ensure controllers have the appropriate tools (e.g., slot markers\non final) to ensure these turns are not too demanding. 6.2 Aircraft Spacing and Separation\nIM aircraft appeared to behave in a manner similar to non-IM aircraft. However, an issue that\nhas been noted in past research (e.g., Cabrall et al., 2012) is that IM aircraft may be outside\ntheir slot markers for longer periods of time than non-IM aircraft. In this simulation, it was seen\nin the feeder controllers airspace and was most likely due to achieve-by aircraft working\ntoward the ASG, though not as quickly as the controller was getting non-IM aircraft into their\nslot markers for handoff to the final controller. If aircraft conducing IM are not expeditiously\ntrending toward their slot markers, this could still be an issue. The potential issue of IM aircraft being out of the slot markers for longer periods of time\nthan non-IM aircraft should be further examined to determine whether it really is an issue,\nincluding in unusual and complex traffic situations. In this simulation environment, it did not\nappear to be a major issue. Related to this topic, there were no discussions in this simulation of wanting to get IM aircraft\ninto their slot markers in the feeder controllers airspace prior to starting IM. This simulation indicated no need for this to be a standard operating procedure. 6-3 6.3 Displays\nController and pilot roles and responsibilities play a key role in the information that should be\ndisplayed to them. The flight crew needs sufficient information to tell the controller when they\nare unable to comply with the IM clearance (since controllers expected to hear that). The\ngraphical progress indicator, or something similar, could be a key element. The controller mainly needs to know when separation will be an issue. A predicted spacing /\nETA differential, or something similar, could be a key element. Controller and pilot roles and responsibilities and the necessary display information to\nsupport those roles and responsibilities should continue to be defined and explored. It is\nnot expected that many new elements are needed, but that the appropriate ones to\nsupport the roles and responsibilities need to be identified and tested. The following\nsections provide suggestions related to this topic area. 6.3.1 Controllers\nTerminal metering tools did not appear to conflict with IM operations and several seemed to\nprovide as much useful information for IM aircraft as for non-IM aircraft (similar to results in\npast simulation such as Cabrall et al., 2012 and Thipphavong et al., 2013). Based on the results of this simulation, the terminal metering tools tested did not\nconflict with IM and there were no results indicating any should be removed, including the\nslot markers. The only terminal metering information that was removed, and was suggested\nto stay removed, was the speed advisory and early / late indicator. While it is relatively early in the development of the controller information requirements for\nIM, the tool sets implemented were based on past work, including those with en route\ncontrollers. The basic tool set (i.e., the information in the IM clearance window and the trail\nand lead aircraft IM status information in the data block) was found to be useful and helpful.\nThe validity checks and feasibility checks also appeared useful. The data did not reveal clear\ntrends for the benefits of the additional tools of the slot marker IM cue or spacing prediction /\nETA differential. Additional work should be performed to continue to determine the necessary controller\ntools and the usefulness of the slot marker IM cue and spacing prediction / ETA differential. Additional work should be performed to see if a display feature (e.g., alert to a speed\nchange of a certain magnitude) would be helpful in overcoming the concern of controllers\nabout not knowing when aircraft conducting IM will change speeds and by how much. When implementing the IM features, it should be ensured that features like ATPA\ndistance information when near / on final approach do not override IM information in the\ndata block. 6-4 6.3.2 Pilots\nThe information displayed to the flight crew was based on an established community standard\n(i.e., DO-361 / RTCA, 2015a). The standard went through a long period of development and was\ninformed by past IM simulations and studies. This simulation found the minimum requirements\nin that standard to be acceptable on several measures, indicating the minimum requirements\nare reasonable and encompassing. Therefore, the MOPS should be considered mature for the\ndisplay features for the IM operations covered in that version (DO-361 / RTCA 2015a). However,\nthe following flight deck items are still recommended for consideration. This simulation chose not to distinguish between achieve stage and maintain stage\noperations (e.g., for the graphical progress indicator or the label for the spacing interval [SI]\nfield on the AGD). While DO-361 (RTCA, 2015a) does not require this, the results of this\nsimulation suggest that such a distinction is not necessary and that it should not become a\nrequirement. The need for an indication of speed limiting may also be a topic of interest for additional\nstudy. It was not examined in this simulation; however, some pilot confusion was noted that\nappeared to be related to speed limiting. While this feature has been utilized in past\nsimulations (e.g., Lohr et al., 2005; Baxley et al., 2013), the results do not appear to be\nconclusive. This information may support trust and may support the flight crew in knowing\nthe best time to configure the aircraft for landing. However, the feature may provide\ninformation that has limited usefulness (as reported in Baxley et al., 2016) or encourage\npilots to fly a non-IM speed. The usefulness of this information could be studied. When developing the next version of DO-361 (RTCA, 2015a), the impact of those new\noperations on any current requirements and findings in this report should be considered.\nAdditional validation of the requirements on new operations, such as arrivals to dependent\nrunways, should be conducted. The aural alerts for
conformance monitoring appeared sufficient for informing the flight crew of\nthe need to check the IAS against the IM speed. However, consideration should be given to the\nimplementation utilized in this simulation that (unintentionally) alerted more often than\nspecified in DO-361 (RTCA, 2015a). Several past simulations have reported a pilot desire for, or\nbetter performance with, more salient notifications (i.e., better visual indications or aural\nalerts) for each new IM speed (e.g., Bone et al., 2003; Penhallegon et al., 2011; Baxley et al.,\n2013; Swieringa et al., 2014). More salient notifications are desirable and would reduce the\ntime necessary to monitor IM displays. Features such as an aural alert for each new IM speed\nmay be too intrusive, especially when the speeds are frequent. Therefore, the following\nrecommendation is made: Continue the examination of the most appropriate scheme for alerting to the\nconformance to IM speeds. If an aural alert is considered too intrusive, testing should\ninclude sufficiently salient notifications that do not require excessive monitoring of the IM\ndisplays. While pilot opinions were mixed as to whether the graphical progress indicator should be a\nminimum requirement, the feedback on this one question should be considered in light of 6-5 simulation issues, other feedback on the tool, and past work. All major IM HITL simulation\nefforts ended up requiring or trying to perfect this type of feature (e.g., Bone et al., 2003;\nHoffman et al., 2006; NASA, 2004; Swieringa et al., 2014). The results of this simulation had\nmore speed compliance and more positive replies for the min+ tool set, and the graphical\nprogress indicator was reported as useful. The implementation in this simulation was directly driven by requirements available in DO-361\n(RTCA, 2015a). While it proved useful to have these requirements, they were found to be in\nerror (based on the use in this simulation)22. The result was that the bounds defined and used in\nthis simulation flagged infeasible operations more than was intended by DO-361 (RTCA, 2015a).\nThis caused the flight crew to see operations flagged as infeasible and then return to feasible.\nThis likely led to confusion about whether the operation was infeasible or not and what action\nto take. Not knowing what action to take was present in past simulations too (e.g., Bone et al.,\n2008a; Baxley et al., 2016). These issues likely led to questioning of what operations were\nfeasible and whether the graphical progress indicator should be a minimum. Therefore, the\nfollowing are recommendations related to the graphical progress indicator. The graphical progress indicator is believed to be a useful feature and likely a minimum\nrequirement. It should be designed to support pilot trust and an accurate mental model. It\nshould avoid providing information that causes the flight crew to try to out-guess or\noverride the IM algorithm and the associated IM speeds. It should provide clear indications\nof infeasible operations. It should not require excessive monitoring and should include\nfeatures that reduce monitoring (e.g., spacing error trend information and out-of-tolerance\nalerting [as seen in implementations like Hoffman et al., 2006]). To determine the best\ndesign, it should be studied further in future simulations in nominal and off-nominal\nsituations after setting the feasibility threshold to the corrected values. o For a non-graphical progress indicator as required per the minimum in DO-361\n(RTCA, 2015a), similar topics should be examined. For example, clear indications of\ninfeasible operations may be more important with only numerical values. The information provided in the speed tape is also considered to be a key set of information\n(i.e., the relationship between the IAS, MCP speed, and IM speed). Such information has been\ndisplayed or required in much past research (e.g., Hoffman et al., 2006; Bone and Long, 2014;\nLatorella, 2015). Consideration should be given and further research should be conducted to determine\nwhether this information is a minimum requirement and whether it should be in the\nprimary field-of-view. 22 The requirements in DO-361 (RTCA, 2015a) are being updated to fix the error. 6-6 6.4 Communications\nWhile the IM clearances were generally found to be acceptable, controllers did report some\nconcerns with the achieve-by clearance types and the amount of information in them. Efforts should continue to examine ways to keep the clearance concise. Attention\nshould also be paid to the amount of lead aircraft IFPI shared in the clearance. This\nsimulation only had one element (the name of the arrival procedure). If the clearances are\nas concise as possible, past work has found the use of an advanced organizer such as\nInterval spacing clearance available, advise when ready to copy has been well received by\npilots (Bone and Long, 2014) and controllers (Callantine et al., 2012). A few pilot requests\nfor such a communication were noted in this simulation. While the use of lead aircraft identification was included in the simulation, it was not fully\nexercised with potentially confusing call signs and the use of the participant aircraft\nidentification in IM clearances. However, no issues were identified and pilots reported they had\nthe necessary information to detect and select the lead aircraft. 6.5 Benefits\nPairs of aircraft conducting IM, as expected, had half the spacing variance of non-IM pairs at the\nFAF. However, IM and non-IM pairs had the same spacing error at the FAF. To take advantage of the reduced variance seen and expected with IM operations, the\nappropriate reduction in the spacing buffer used by TBFM for IM aircraft should be\ndetermined. 7-1 7 References\nAbbott, T. S., and Moen, G. C. (1981). Effect of display size on utilization of traffic situation\ndisplay for self-spacing task (NASA Technical Paper 1885). Hampton, VA: NASA Langley. Aligne, F., Grimaud, I., Hoffman, E., Rognin, L., and Zeghal, K. (2003). CoSpace 2002 controller\nexperiment assessing the impact of spacing instructions in E-TMA and TMS. Bretigny-sur-Orge,\nFrance: EUROCONTROL Experimental Centre. Barmore, B.E., Abbott, T.S., and Capron, W. (2005). Evaluation of airborne precision spacing in a\nhuman-in-the-loop experiment. Proceedings of the American Institute of Aeronautics and\nAstronautics (AIAA) 5th Aviation, Technology, Integration, and Operations Conference,\nArlington, VA. Reston, VA: AIAA, Inc. Baxley, B. T., Murdoch, J. L., Swieringa, K. A., Barmore, B. E., Capron, W. R., Hubbs, C. E., Shay,\nR. F., and Abbott, T. S. (2013). Experimental description and results for arrival operations using\nInterval Management with Spacing to Parallel Dependent Runways (IMSPiDR) (NASA/TP-2013-\n217998). Hampton, VA: NASA Langley. Baxley, B. T., Shay, R. F., and Swieringa, K. A. (2014). The development of cockpit display and\nalerting concepts for Interval Management (IM) in a near-term environment (NASA/TM-2014-\n218659). Hampton, VA: NASA Langley. Baxley, B. T., Wilson, S. R., Swieringa, K. A., Johnson, W. C., Roper, R. D., Hubbs, C. E., Goess, P.\nA., and Shay, R. F. (2016). Human-in-the-loop assessment of alternative clearances in Interval\nManagement arrival operations (NASA/TP-2016-219362). Hampton, VA: NASA Langley. Benson, L.M., Peterson, T. N., Orrell, G. L., and Penhallegon, W. J. (2011). Ground-based Interval\nManagement Spacing (GIM-S) controller information requirements human-in-the-loop\nsimulation (MTR110213). McLean, VA: MITRE CAASD. Bone, R., Helleberg, J., and Domino, D. (2003). Surface moving map and approach spacing\npreliminary findings: Safe Flight 21 Ohio River Valley 2001 MITRE CAASD flight simulations (MTR\n03W0000069). McLean, VA: The MITRE Corporation. Bone, R.S., and Long, K. M. (2014). Flight crew and air traffic controller interactions when\nconducting interval management utilizing voice and controller pilot data link communications\n(MTR130300R1). McLean, VA: The MITRE Corporation. Bone, R. S., and Penhallegon, W. J. (2006). Flight Deck-Based Merging and Spacing (FDMS)\ndemonstration on July 6, 2006: Initial Federal Aviation Administration (FAA) examination of a\nplanned cockpit implementation (MTR 06W0000072). McLean, VA: The MITRE Corporation. Bone, R.S., Penhallegon, W.J., Benson, L. M., and Orrell, G. L. (2013) Evaluation of pilot and air\ntraffic controller use of third party call sign in voice communications with pilot utilization of\ncockpit display of traffic information (MTR130347R1). McLean, VA: MITRE CAASD. Bone, R. S., Penhallegon, W. J., and Stassen, H. P. (2008a). Flight Deck-Based Merging and\nSpacing (FDMS) impact on flight deck en route operations: FDMS 2 simulation. August -\nSeptember 2006 (MTR 080034). McLean, VA: The MITRE Corporation. 7-2 Bone, R. S., Penhallegon, W. J., and Stassen, H. P. (2008b). Flight Deck-Based Merging and\nSpacing (FDMS) impact on flight deck en route operations: FDMS 3 simulation. February March\n2008 (MTR 080208). McLean, VA: The MITRE Corporation. Bone, R. S., Penhallegon, W. J., Stassen, H. P., Simons, E., and DeSenti, C. (2007). Flight deck-\nbased merging and spacing impact on en route air traffic control operations: FDMS 1 Simulation\n(MTR 070071). McLean, VA: The MITRE Corporation. Cabrall, C., Callantine, T., Kupfer, M., Martin, L., and Mercer, J. (2012). Controller-managed\nspacing within mixed-equipage arrival operations involving flight-deck interval management. In\nthe proceedings of the 4th International Conference on Applied Human Factors and Ergonomics,\nSan Francisco, CA. Louisville, KY: AFHE. Callantine, T. J., Cabrall, C. D., Kupfer, M., Omar, F. G., and Prevot, T. (2012). Initial\ninvestigations of controller tools and procedures for schedule-based arrival operations with\nmixed flight-deck interval management equipage. In Proceedings of the American Institute of\nAeronautics and Astronautics (AIAA) 12th Aviation, Technology, Integration, and Operations\nConference, Arlington, VA. Reston, VA: AIAA, Inc. Callantine, T. J., Kupfer, M., Martin, L., and Mercer, J. (2014). System-level performance\nevaluation of ATD-1 ground-based technologies. In Proceedings of the American Institute of\nAeronautics and Astronautics (AIAA) 14th Aviation, Technology, Integration, and Operations\nConference, Atlanta, GA. Reston, VA: AIAA, Inc. Callantine, T. J., Kupfer, M., Martin, L., and Prevot, T. (2013). Simulations of continuous descent\noperations with arrival-management automation and mixed flight-deck interval management\nequipage. Paper presented at 10th USA/Europe Seminar on Air Traffic Management Research\nand Development, Napa, California. Retrieved from:\nhttp://www.atmseminar.org/papers.cfm?seminar_ID=10.
Callantine, T. J., Palmer, E. A., and Kupfer M. (2010). Human-in-the-loop simulation of\ntrajectory-based terminal-area operations. In Proceedings of the International Council of the\nAeronautical Sciences (ICAS) Congress, Nice, France. Bonn, Germany: ICAS. Clarke, J. P., Bennett, D., Elmer, K., Firth, J., Hilb, R., Ho, N., Johnson, S., Lau, S., Ren, L.,\nSenechal, D., Sizov, N., Slattery, R., Tong, K., Walton, J., Willgruber, A., and Williams, D. (2006).\nDevelopment, design, and flight test evaluation of a continuous descent approach procedure for\nnighttime operation at Louisville International Airport, Report of the PARTNER OPD\nDevelopment Team (Report No. PARTNER-COE-2006-02). Retrieved from:\nhttp://www.mit.edu/people/liling/files/OPD_rpt.pdf. Endsley, M. (1995). Toward a theory of situational awareness in dynamic systems, Human\nFactors, 37, 65-84. Erkelens, L. J. J. (2000). Research on noise abatement procedures (NLR TP 98066). Amsterdam,\nNetherlands: NLR. FAA (2001). Operational Evaluation-2 final report. Cargo Airline Association (CAA) ADS-B\nProgram and FAA Safe Flight 21 Program. Washington, DC: FAA. 7-3 FAA (2013). NextGen implementation plan. Washington, DC: FAA. FAA (2015). FACT3: Airport capacity needs in the national airspace system. Washington, DC:\nFAA. FAA (2016). Performance based navigation. PBN NAS navigation strategy 2016. Washington,\nDC: FAA. Grimaud, I., Hoffman, E., Rognin, L, and Zeghal, K. (2003). EACAC 2001 Real-time experiments:\ninitial evaluation of limited delegation of spacing to the flight deck (EUROCONTROL report No\n380). Bretigny-sur-Orge, France: EUROCONTROL Experimental Centre. Grimaud, I., Hoffman, E., Rognin, L, Zeghal, K., and Deransy, R. (2001). EACAC 2000 real-time\nexperiments: initial evaluation of limited delegation of separation tasks to the flight deck.\n(EUROCONTROL report No 368). Bretigny-sur-Orge, France: EUROCONTROL Experimental\nCentre. Hebraud, C., Hoffman, E., Papin, A., Pene, N., Rognin, L., Sheehan, C., and Zeghal, K. (2004).\nCoSpace 2002 flight deck experiments assessing the impact of spacing instructions from cruise\nto initial approach (EUROCONTROL report No 388). Bretigny-sur-Orge, France: EUROCONTROL\nExperimental Centre. Hebraud, C., Hoffman, E., Pene, N, Rognin, L., Sheehan, C., and Zeghal, K. (2004). CoSpace 2003\nflight deck experiment assessing the impact of spacing instructions from cruise to final approach\n(EUROCONTROL report No 397). Bretigny-sur-Orge, France: EUROCONTROL Experimental\nCentre. Hebraud, C., Martin, J. L., Leone, M., and Troise, O. (2006). Validation of a European gat to gate\noperational concept for 2005- 2010 (Version 1.1). Brussels, Belgium: EUROCONTROL. Hicok, D. S. and Barmore, B. E. (2016). Concept of operations for Interval Management arrivals\nand approach. In Proceedings of the 2016 SciTech Conference, San Diego, California. Retrieved\nfrom: https://arc.aiaa.org/doi/pdf/10.2514/6.2016-1609 Hoffman, E., Pene, N., and Zeghal, K. (2006). Flight deck user requirements for airborne spacing\n(Sequencing and Merging) version 2.3. (Working paper EEC-2006-004). Bretigny-sur-Orge,\nFrance: EUROCONTROL Experimental Centre. in t Veld, A. C., van Paassen, M. M., Mulder, M., and Clarke, J. P. (2003). Pilot support for self-\nseparation during decelerating approaches. In R. S. Jensen (Ed.) Proceedings of Twelfth\nInternational Symposium on Aviation Psychology, Dayton, Ohio. Kibler, J. L., Wilson, S. R., Hubbs, C. E., and Smail, J. W. (2015). Air traffic management\nTechnology Demonstration phase 1 (ATD) Interval Management for Near-term Operations\nValidation of Acceptability (IM-NOVA) experiment (NASA/TP-2015-218767). Hampton, VA:\nNASA Langley. Klooster, J. (2007). Required time-of-arrival trials. Presented at E-Operations Workshop,\nGeorgia Tech, December 5 & 6, 2007. Arlington, VA : GE Aviation Digital Systems. 7-4 Kupfer, M., Callantine, T., Martin, L., Mercer, J., and Palmer, E. (2011). Controller support tools\nfor schedule-based terminal-area operations. Paper presented at 8th USA/Europe Seminar on\nAir Traffic Management Research and Development, Napa, California. Retrieved from:\nhttp://www.atmseminar.org/papers.cfm?seminar_ID=9. Latorella, K. A. (2015). Avionics configuration assessment for flightdeck interval management: A\ncomparison of avionics and notification methods (NASA/TP-2015-218788). Hampton, VA: NASA\nLangley. Lee, K.K., Kerns, K., Bone, R., and Nickelson, M.N. (2001). Development and validation of the\nController Acceptance Rating Scale (CARS): Results of empirical research. In Proceedings of the\n4th International Air Traffic Management Research and Development Seminar, Santa Fe, NM.\nRetrieved from: http://atm2001.eurocontrol.fr Lohr, G. W., Oseguera-Lohr, R. M., Abbott, T. S., Capron, W. R., and Howell, C. T. (2005).\nAirborne evaluation and demonstration of a time-based airborne inter-arrival spacing tool\n(NASA/TM-2005-213772). Hampton, VA: NASA Langley. Mayers, A. (2013). Introduction to Statistics and SPSS in Psychology. Upper Saddle River, NJ:\nPearson Education. Mercer, J., Callatin, T. J., Lee, P. U., Prevot, T. and Palmer, E. (2005). An evaluation of airborne\nspacing in the terminal area. Proceedings of the 2005 IEEE/AIAA 24th Digital Avionics Systems\nConference, Oct. 2005, Washington, D.C. Piscataway, N.J.: IEEE Press. Murdoch, J. L., Barmore, B. E., Baxley, B. T., Abbott, T. S., and Capron, W. R. (2009). Evaluation\nof an airborne spacing concept to support continuous descent arrival operations. Proceedings\nof the Eighth USA/Europe Air Traffic Management Research and Development Seminar\n(ATM2009). Napa, CA. NASA (2004). 3D-CDTI User Manual v2.1. Retrieved from:\nhttps://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/ .pdf Oseguera-Lohr, R. M., Lohr, G. W., Abbott, T. S., and Eischeid, T. M. (2002). Evaluation of\noperational procedures for using a time-based airborne inter-arrival spacing toolAIAA 2002-\n5824. Proceedings of the AIAA's Aircraft Technology, Integration, and Operations (ATIO) 2002,\nLos Angeles, California. Reston, VA: AIAA, Inc. Penhallegon, W. J., and Bone, R. S. (2008). Flight Deck-Based Merging and Spacing (FDMS)\nimpact on air traffic control during en route descent: FDMS 4 simulation (MTR 080304). McLean,\nVA: The MITRE Corporation. Penhallegon, W., Bone, R., and Stassen, H. (2016a). Results from a field evaluation of Interval\nManagement during an optimized profile descent arrival and approach. In Proceedings of the\n2016 SciTech Conference, San Diego, California. Retrieved from:\nhttp://arc.aiaa.org/doi/abs/10.2514/6.2016-1612 Penhallegon, W., Bone, R., and Stassen, H. (2016b). Field test of interval management-spacing\nduring an optimized profile descent arrival and approach (MTR110426R1). McLean, VA: The\nMITRE Corporation. 7-5 Penhallegon, W. J., Mendolia, A., Bone, R., Orrell, G., and Stassen, H.P. (2011). Flight deck-based\nInterval Management Spacing (FIM-S) during departures: Flight crew Human-in-the-loop\n(HITL) simulation (MTR 110382). McLean, VA: The MITRE Corporation. Peterson, T. N., Penhallegon, W. J., and Moertl, P. (2012). Mid-Term Interval Management \nSpacing for Arrivals (MTR120203). McLean, VA: MITRE CAASD. Prevot, T., Callantine, T., Homola, J., Lee, P., Mercer, J., Palmer, E., and Smith, N. (2007). Effects\nof Automated Arrival Management, Airborne Spacing, Controller Tools, and Data Link. In\nProceedings of the AIAA Guidance, Navigation, & Control Conference and Exhibit, Hilton Head,\nSC. Reston, VA: AIAA. Prevot, T., Callantine, T., Kopardekar, P., Smith, N., Palmer, E., and Battiste, V. (2004).\nTrajectory-oriented operations with limited delegation: An evolutionary path to NAS\nmodernization. In Proceedings of the 4th AIAA Aviation Technology, Integration, and Operations\n(ATIO) Conference, Chicago, IL. Reston, VA: AIAA, Inc. Ren, L., Clarke, J. P., and Ho, N. T. (2003). Achieving low approach noise without sacrificing\ncapacity. Proceedings of the 2003 IEEE/AIAA 22nd Digital Avionics Systems Conference, Oct.\n2003, Indianapolis, IN: IEEE Press. Robinson III, J. E., Thipphavong, J., and Johnson, W. C. (2015). Enabling performance-based\nnavigation arrivals: Development and simulation testing of the terminal sequencing and spacing\nsystem. Paper presented at 11th USA/Europe Seminar on Air Traffic Management Research and\nDevelopment Seminar, Lisbon, Portugal. Retrieved from:\nhttp://www.atmseminar.org/papers.cfm?seminar_ID=11. Rognin, L., Boursier, L., Cloarec, D., Favennec, B., Hoffman, E., Gordon, R., Vergne, F., and\nZeghal, K. (2005). CoSpace 2004 ground experiment: sequencing arrival flows with spacing\ninstructions and arrival manager. Bretigny-sur-Orge, France: EUROCONTROL Experimental\nCentre. Roscoe, A. H. (1984). Assessing pilot workload in flight: Flight test techniques. Proceedings of\nNATO Advisory Group for Aerospace Research and Development (AGARD) (AGARD-CP-373).\nNeuilly-sur-Seine, France: AGARD. RTCA (2014). Minimum Operational Performance Standards (MOPS) for Aircraft Surveillance\nApplications (ASA) System (DO-317B). Washington, DC: RTCA. RTCA (2015a). Minimum Operational Performance Standards (MOPS) for Flight Deck-based IM\n(FIM) (DO-361). Washington, DC: RTCA. RTCA (2015b). Safety, performance, and interoperability requirements document for Airborne\nSpacing Flight Deck Interval Management (ASPA-FIM) (DO-328A). Washington, DC: RTCA. RTCA (2016a). Safety and performance requirements standard for Baseline 2 ATS data\ncommunications (Baseline 2 SPR standard) (DO-350A). Washington, DC: RTCA RTCA (2016b). Interoperability requirements standard for Baseline 2 ATS data communications\n(Baseline 2 interop standard) (DO-351A). Washington, DC: RTCA 7-6 Ruigrok, R. C. J., and Korn, B. (2007). Combining 4D and ASAS for efficient TMA operations. In\nthe Proceedings of the 7th AIAA Aviation Technology, Integration, and Operations (ATIO)\nConference, Belfast, Northern Ireland. Reston, VA: AIAA, Inc. Singha, A. N., and Haines, A. L. (1975). Longitudinal separation standards on final approach for\nfuture ATC environments (MTR-6979). McLean, VA: The MITRE Corporation. Spinoso, L., Coville, G., and Roberts, C. (2014). Analysis of the excess inter-arrival time\ndistribution. In Proceedings of the 2014 Integrated Communications, Navigation, and\nSurveillance (ICNS) Conference, Herndon, Virginia. Swieringa, K. A., Wilson, S. R., and Shay, R. (2014). An evaluation of retrofit flight deck displays\nfor Interval Management. In Proceedings of the 14th AIAA Aviation Technology, Integration, and\nOperations Conference, Atlanta, GA. Reston, VA: AIAA, Inc. Swieringa, K. A., Wilson, S. R., Baxley, B. T., Roper, R. D., Abbott, T. S., Levitt, I., and Scharl, J.\n(2017). Flight test evaluation of the ATD-1 interval management application. In the Proceedings\nof the 17th AIAA Aviation Technology, Integration, and Operations (ATIO) Conference, Denver,\nCO. Reston, VA: AIAA, Inc. Thipphavong, J., Jung, J., Swenson, H. N., Witzberger, K. E., Lin, M. I., Nguyen, J., Martin, L.,\nDowns, M. B., and Smith, T. A. (2013). Evaluation of the controller managed spacing tools,\nflight-deck interval management and terminal area metering capabilities for the ATM\ntechnology demonstration #1. Paper presented at 10th USA/Europe Seminar on Air Traffic\nManagement Research and Development Seminar, Napa, California. Retrieved from:\nhttp://www.atmseminar.org/papers.cfm?seminar_ID=10. Weitz, L. (2017). Relationship between inter-arrival time variability and throughput.\nPresentation to CNS Task Force. McLean, VA: The MITRE Corporation. Williams, D. H., and Wells, D.C. (1986). Jet transport flight operations using cockpit display of\ntraffic information during instrument meteorological conditions (NASA Technical Paper 2567).\nHampton, VA: NASA Langley. Witzberger, K., Martin, L., Sharma, S., and Robinson, J. E. (2015). Air Traffic Management\nTechnology
Demonstration 1 (ATD-1) Operational Integration Assessment (OIA) final report.\nMoffett Field, CA: NASA Ames. Wynnyk, M. and Kopald, H. (2013). Terminal Sequencing and Spacing (TSS) simulation 2 post\nanalysis report (MP130272). McLean, VA: The MITRE Corporation. Zeghal, K., Hoffman, E., Cloerec, A., Grimaud, I., and Nicolaon, J-P. (1999). Initial evaluation of\nlimited delegation of separation assurance to the cockpit. Proceedings of the 1999 SAE/AIAA\nWorld Aviation Congress, San Francisco, California. Warrendale, PA: SAE International. A-1 Appendix A IM Validity and Feasibility Checks The following were the IM validity and feasibility checks that are expected to be conducted by\nTBFM for IM operations. Validity checks determine whether the criteria for initiating an IM\noperation, or allowing an IM operation to continue, are met. Feasibility checks determine\nwhether IM can achieve the ASG (with speed alone). A.1 Validity Checks\n In order to propose an IM operation, the following validity criteria were required to be\nmet: o The trail aircraft was in the sector of the controller o Trail aircraft was IM capable (as indicated in the flight plan) o The trail and lead aircrafts routes were the same from the ABP to PTP o Aircraft were in surveillance range, i.e., 90 NM (per IM Performance Analysis Team\n[IMPAT] 4/6/16) o Trail aircraft and lead aircraft passed their respective freeze horizons o The following validity checks were expected for a real-world implementation but\nwere not implemented for the simulation o Lead aircraft is target (lead) capable (broadcasting ADS-B of sufficient quality for\nATC surveillance) o Note: Should be checked during the Active, Suspended, and Terminated\nstages. o The trail and lead aircraft are conforming to their cleared routes. o Note: Should be checked during the Active, Suspended, and Terminated\nstates o The trail and lead aircraft are landing at the same runway in sequential order. o Note: Should be checked during the Active, Suspended, and Terminated\nstates In order to propose an Achieve-by then Maintain operation, the following validity\ncriteria were required to be met: o Both the trail and lead aircraft were on different routes until the ABP, then were on\na common route o Trail aircraft had not reached the ABP or PTP A-2 o Trail aircraft calculated ASG was between 70 and 240 seconds Note: The value of 70 seconds was expected to support the minimum separation\nstandard of 2.5 NM. 240 seconds was determined to be a maximum reasonable\nvalue. o If Trail aircraft had passed the ABP (but not the PTP) after an Achieve-by then\nMaintain clearance was eligible, the trail aircraft shall remain eligible but the\nclearance shall switch to a Capture then Maintain In order to propose a Capture then Maintain operation, the following validity criteria\nwere required to be met: o Both the trail and lead aircraft were on the same route o The trail aircraft and lead aircraft current spacing are within 30 seconds of the ASG A.2 Feasibility Checks A.2.1 Dependent Feasibility Checks\nThe following pair-dependent feasibility criteria were met prior to displaying an IM clearance to\nthe controller or during a proposed or suspended IM operation. If they were not met during a\nproposed or suspended operation, the controller was notified. If the absolute value of [trail aircraft STA ETA] [lead aircraft STA ETA] was greater\nthan 50 seconds, the infeasible / no speed solution situation was displayed to the controller.\nExample as shown in Figure A-1. Figure A-1. Trail and Lead Aircraft Independent Feasibility Criteria Example Trail\naircraft\nSTA \nETA Lead\naircraft\nSTA \nETA Difference\nAbsolute value Feasible 20 (early) -35 (late) = 55 No\n0 (on\ntime) 55 (early) = 55 No 29 (early) 30 (early) = 1 Yes Example The aircraft pair shall meet the following criteria: |[trail aircraft STA ETA] [lead aircraft STA ETA]|< 50\nseconds\n(i.e., <51 second differential) A-3 For time-based achieve-by then maintain operations, the following pair-dependent feasibility\ncriteria were met prior to displaying the IM clearance to the controller when the trail aircraft\nwas greater than 30 NM (approximately 7 minutes) from the ABP during an active, proposed, or\nsuspended IM operation. If they were not met during these states, the controller was notified. ASG > (trail aircraft ETA lead aircraft ETA) by more than 15% of the trail aircrafts TTG\nto the ABP (i.e., trail aircraft ETA trail aircraft current time) o (ETAT ETAL + 0.15 x TTGT) < ASG o ASG too large / Not able to slow down enough to achieve the ASG ASG < (trail aircraft ETA lead aircraft ETA) by more than 11% of the trail aircrafts TTG\nto the ABP (i.e., trail aircraft ETA trail aircraft current time) o (ETAT ETAL 0.11 x TTGT) > ASG o ASG too small / Not able to speed up enough to achieve the ASG Notes o This is the same feasibility check that was done on the flight deck but was using TSAS\ninformation. o It may be desirable to change the 15% to 12% and the 11% to 8% so the controller is\nable to detect and resolve potentially infeasible conditions prior to the flight crew\nreporting unable. The check is shown in a graphical representation in Figure A-2. Figure A-2. Feasibility Criteria When Greater than 30 NM / 7 Minutes from the ABP Range of attainable ASGs Fastest flyable profile Slowest flyable profile ASG too large\nNot able to slow down enough to achieve the ASG ASG too small\nNot able to speed up enough to achieve the ASG ETAT ETALETAT ETAL 0.11 x TTGT ETAT ETAL + 0.15 x TTGT A-4 A.2.2 Independent Feasibility Checks\nWhile not implemented in the simulation, the following pair-independent feasibility criteria\nshould be considered prior to displaying an IM clearance to the controller or during a proposed\nor suspended IM operation. If they are not met during a proposed or suspended operation, the\ncontroller shall be notified. See Figure A-3 for examples. There is a speed solution for TSAS (i.e., an E or L is not shown) The trail aircraft STA ETA or the lead aircraft STA ETA, is greater than 60 seconds or\nless than -30 seconds. Figure A-3. Trail and Lead Aircraft Independent Feasibility Criteria Example Status STA ETA Difference\nEarly 30 15 = 15\nOn time 30 30 = 0\nLate 30 59 = -29 Example\n(Trail or Lead Aircraft) STA ETA = 0 < 60 seconds early < 30 seconds lateLate Early Both aircraft independently shall meet the following criteria: STA ETA > 30 seconds (i.e., <30 seconds late)\nSTA ETA < 60 seconds (i.e., <60 seconds early)\n(-30 < STA ETA <60) B-1 Appendix B Post-Scenario Questionnaires B.1 Controller Baseline Post-Scenario Questionnaire\nIM DURING TERMINAL METERING HITL POST BASELINE SCENARIO ATC QUESTIONNAIRE Instructions: Please answer the questions by drawing a line through the option on each of the\nscales at the point which matched your experience or circling an option (e.g., yes / no). When\nchoosing an option, keep in mind that the integration of IM into terminal metering is the area\nof interest (not terminal metering alone). Consider only the current scenario when answering.\nIf you have any questions, please ask the experimenter. B-2 Workload 1. Using the chart below, how would you rate your average level of workload? (a) Working up from the bottom left corner, answer each yes/no question and follow the\npath. (b) Circle the numerical rating that best reflects your experience. B-3 Operations 2. I was able to detect when spacing / separation issues were developing for aircraft.\n(draw a line on each scale) Comments: 3. I was confident that the spacing of the aircraft would remain outside my separation\nrequirement. (draw a line on each scale) Comments: 4. The spacing of the aircraft was acceptable. (draw a line on the scale) Comments: 5. Given the appropriate training, this operation is acceptable. (draw a line on each\nscale) Comments: 6. Were there any times when you had an issue with an aircraft? (circle one) Yes No If yes, what was the issue? B-4 Displays 7. I had the necessary display elements. (draw a line on the scale) Comments: 8. Did you experience any display difficulties? (circle one) Yes No If yes, explain: Communications 9. Did you experience any communication difficulties? (circle one) Yes No If yes, explain: Overall 10. Did you have any other difficulties with this particular run? (circle one) Yes No If yes, explain: B-5 11. Using the chart below, how would you rate your acceptability of the operation. (a) Working from the top left-hand corner, answer each yes / no question and follow the path.\n(b) Circle the numerical rating that best reflects your experience. B-6 12. If you have any other comments about this run, please provide them. B-7 B.3 Controller IM Post-Scenario Questionnaire\nIM DURING TERMINAL METERING HITL POST IM SCENARIO ATC QUESTIONNAIRE Instructions: Please answer the questions by drawing a line through the option on each of the\nscales at the point which matched your experience or circling an option (e.g., yes / no). When\nchoosing an option, keep in mind that the integration of IM into terminal metering is the area\nof interest (not terminal metering alone). Consider only the current scenario when answering.\nIf you have any questions, please ask the experimenter. B-8 Workload 1. Using the chart below, how would you rate your average level of workload? (a) Working up from the bottom left corner, answer each yes/no question and follow the\npath. (b) Circle the
numerical rating that best reflects your experience. B-9 Operations 2. I was able to detect when spacing / separation issues were developing for aircraft.\n(draw a line on each scale) IM Aircraft: Non-IM Aircraft: Comments: 3. I was confident that the spacing of the aircraft would remain outside my separation\nrequirement. (draw a line on each scale) IM Aircraft: Non-IM Aircraft: Comments: 4. The spacing of the IM aircraft was acceptable. (draw a line on the scale) Comments: B-10 5. Did you ever need to terminate or suspend an IM operation? (circle one) Yes No If yes, why? a) Did you restart / resume the operation? (circle one) Yes No Comments: 6. Given the appropriate training, IM during terminal metering is operationally\nacceptable. (draw a line on each scale) Comments: 7. Were there any times when you had an issue with an IM aircraft? (circle one) Yes No If yes, what was the issue? Displays 8. I had the necessary display elements for conducting IM operations. (draw a line on\nthe scale) Comments: 9. Did you experience any IM-related display difficulties? (circle one) Yes No If yes, explain: B-11 Communications 10. Did you experience any IM-related communication difficulties? (circle one) Yes No If yes, explain: Overall 11. Did you have any other IM-related difficulties with this particular run? (circle one) Yes No If yes, explain: B-12 12. Using the chart below, how would you rate your acceptability of the operation. (a) Working from the top left-hand corner, answer each yes / no question and follow the path.\n(b) Circle the numerical rating that best reflects your experience. B-13 13. If you have any other comments about this run, please provide them. B-14 B.5 Pilot Baseline Post-Scenario Questionnaire\nIM (DURING TERMINAL METERING) HITL POST BASELINE SCENARIO PILOT QUESTIONNAIRE Instructions: Please answer the questions by drawing a line through the option on each of the\nscales at the point which matched your experience or circling an option (e.g., yes / no).\nConsider only the current scenario when answering. If you have any questions, please ask the\nexperimenter. B-15 Workload 1. Using the chart below, how would you rate your average level of workload? (a) Working up from the bottom left corner, answer each yes/no question and follow the\npath. (b) Circle the numerical rating that best reflects your experience. B-16 Operations 2. Overall, I found this run acceptable. 3. Were there any times when you had an issue flying the approach and arrival? (circle\none) Yes No If yes, what was the issue? Displays 4. Did you experience any display difficulties? (circle one) Yes No If yes, explain: Communications 5. Did you experience any communication difficulties? (circle one) Yes No If yes, explain: Overall 6. Did you have any other difficulties with this run? (circle one) Yes No If yes, explain: 7. If you have any other comments about this run, please provide them. B-17 B.7 Pilot IM Post-Scenario Questionnaire\nIM (DURING TERMINAL METERING HITL) POST IM SCENARIO PILOT QUESTIONNAIRE Instructions: Please answer the questions by drawing a line through the option on each of the\nscales at the point which matched your experience or circling an option (e.g., yes / no). When\nchoosing an option, keep in mind that IM is the area of interest (e.g., not a traffic display\nalone). Consider only the current scenario when answering. If you have any questions, please\nask the experimenter. B-18 Workload 1. Using the chart below, how would you rate your average level of workload? (a) Working up from the bottom left corner, answer each yes/no question and follow the\npath. (b) Circle the numerical rating that best reflects your experience. B-19 Operations 2. I could detect whether I would remain within tolerances to achieve and maintain the\nassigned spacing goal. (draw a line on the scale) Comments: 3. Did you ever consider reporting unable interval spacing and not do so? (circle one) Yes No If yes, why? Describe. 4. Did you ever report unable interval spacing? (circle one) Yes No If yes, why? 5. Given the appropriate training, IM is operationally acceptable. (draw a line on the\nscale) Comments: 6. Were there any times when you had an issue conducting IM? (circle one) Yes No If yes, what was the issue? B-20 Displays 7. I had the necessary display elements for conducting IM. (draw a line on the scale) Comments: 8. Did you experience any IM-related display difficulties? (circle one) Yes No If yes, explain: Communications 9. Did you experience any IM-related communication difficulties? (circle one) Yes No If yes, explain: Overall 10. Did you have any other IM-related difficulties with this particular run? (circle one) Yes No If yes, explain: 11. If you have any other comments about this run, please provide them. C-1 Appendix C Post-Simulation Questionnaires C.1 Controller Post-Simulation Questionnaire\nIM DURING TERMINAL METERING HITL POST EVALUATION ATC QUESTIONNAIRE Instructions: Please answer the questions by drawing a line through the option on each of the\nscales at the point which matched your experience or circling an option (e.g., yes / no). When\nchoosing an option, keep in mind that the integration of IM into terminal metering is the area\nof interest (not terminal metering alone). Unless otherwise indicated, consider all scenarios\nwhen answering. If you have any questions, please ask the experimenter. C-2 Operational Integration 1. Rank the operations from most challenging to least challenging aspect of the simulation\nenvironment. Enter terminal metering, RNP RF turn operations, and Interval Management in the\ncells below. Each operation should appear only once. Most challenging Least challenging Comments: a. Did one operation make another more challenging? (circle one) Yes No If yes, describe: 2. Provide any comments on or concerns about terminal metering or RNP RF turns\n(independent of IM) below. (The remainder of the questionnaire is related to IM\nintegration into that terminal metering environment with RNP RF turns). Terminal metering: RNP RF turns: IM Operations 3. IM is operationally desirable. (draw a line on the scale) Comments: C-3 4. IM is compatible with terminal metering operations. (draw a line on the scale) Comments: 5. Given the appropriate training, IM during terminal metering is operationally acceptable.\n(draw a line on each scale) Comments: 6. I was confident that the spacing of the aircraft would remain outside my separation\nrequirement. (draw a line on each scale) IM Aircraft: Non-IM Aircraft: Comments: 7. It was acceptable to receive aircraft already performing IM from the feeder controller.\n(draw a line on the scale) Comments: 8. It was acceptable to receive aircraft already performing IM from the center. (draw a line\non the scale) Comments: C-4 9. It was clear that the speed changes made by the aircraft were driving towards the goal\nof appropriate spacing. (draw a line on the scale) IM Aircraft: Non-IM Aircraft: Comments: 10. The spacing achieved by the aircraft was acceptable. (draw a line on each scale) IM Aircraft: Non-IM Aircraft: Comments: 11. I was able to detect when spacing / separation issues were developing for aircraft. (draw\na line on each scale) IM Aircraft: Non-IM Aircraft: Comments: C-5 13. I was confident that the aircraft I was handing off would be accepted with minimal\nproblems. (draw a line on each scale) IM Aircraft: Non-IM Aircraft: Comments: 14. Did you notice a difference between IM aircraft conducting Achieve operations versus\nCapture operations? (circle one) Yes No If yes, describe: Which operation was acceptable? (circle one) Achieve Capture Both If one is not acceptable, explain: 15. There were an acceptable number of aircraft performing IM. (draw a line on the scale) What percentage and above is reasonable? (This simulation had ~ 60% IM equipped) % Explain: C-6 16. My roles and responsibilities were clear. (draw a line on the scale) IM Aircraft: Non-IM Aircraft: Comments: 17. My overall workload was acceptable. (draw a line on the scale) Comments: 18. My level of traffic awareness was acceptable. (draw a line on each scale) IM Aircraft: Non-IM Aircraft: Comments: 19. How did aircraft conducting IM during terminal metering effect your need to monitor\ntraffic? (circle one per row) IM\naircraft Greatly\nIncreases Increases Somewhat\nIncreases No\nEffect Somewhat\nReduces Reduces Greatly\nReduces --------------\nNon-IM\naircraft Greatly\nIncreases Increases Somewhat\nIncreases No\nEffect Somewhat\nReduces Reduces Greatly\nReduces Comments: C-7 20. The necessary aircraft monitoring was acceptable. (draw a line on each scale) IM Aircraft: Non-IM Aircraft: Comments: Communications 21. The IM clearance instruction was acceptable. (draw a line on each scale) Achieve: Capture: Comments: 22. Did any of the IM clearance elements cause you any difficulties? (circle one) Yes No If yes, which elements? (circle all that apply): 1. Trail aircraft identification\n2. Clearance type\n3. Assigned spacing goal\n4. Achieve-by point\n5. Lead aircraft identification\n6. Lead aircraft route Describe any difficulties: C-8 23. Did you have any issues during communications when the lead aircraft call sign was\nused? (circle one) Yes No If yes, describe: 24. Use of the lead aircraft call sign in the IM clearance is operationally acceptable. (draw a\nline on the scale) Comments: Display 25. The terminal metering elements were helpful for the IM and non-IM aircraft. (draw a\nline on each scale) Z AWE652\n090 B738/W\n180 A26 21\n220 Slot Marker Slot Marker\nSpeed Aircraft IAS Speed\nAdvisory RNP-Capable\nIndicator 0\nPHX26 AWE652\nAWE652 CTAS ETA CTAS STA DAL1921 SWA2053 SWA1011 AWE209 SWA1825 AWE24 DAL1921 SWA2053\nSWA1011 AWE209\nAWE221 SWA1825 AWE273 AWE24 AWE251\nSWA2197
30 35 SWAP\nT PHX26 Timeline SWA2053\n085 B738\nL 0:50 A26 Z 12 Runway\nAssignment Sequence\nNumber 10 21 210 Early/Late\nIndicator C-9 (Non-Blue) Slot Markers IM Aircraft (Non-Blue) Slot Markers Non-IM Aircraft Speed Advisories IM Aircraft Speed Advisories Non-IM Aircraft Early / Late indicator IM Aircraft Early / Late indicator Non-IM Aircraft Slot Marker Speeds IM Aircraft Slot Marker Speeds Non-IM Aircraft C-10 Aircraft Indicated Airspeed IM Aircraft Aircraft Indicated Airspeed Non-IM Aircraft Runway Sequence Number IM Aircraft Runway Sequence Number Non-IM Aircraft Runway assignment IM Aircraft Runway assignment Non-IM Aircraft Timeline IM Aircraft Timeline Non-IM Aircraft Comments: C-11 26. The IM elements were helpful for IM operations / aircraft. (draw a line on each scale) Trail aircraft status (i.e., T(E) Eligible, T(A) Active, T(S) Suspended) Lead aircraft status (i.e., L(A) Active, L(S) Suspended) Blue slot marker (to differentiate between IM aircraft from non-IM aircraft) Comments: Z 21 220 2\nDAL456\n21\nT-(A) A26\nL-(A) P Trail Aircraft\nStatus Lead Aircraft\nStatus C-12 27. The information in the IM window was helpful for IM operations / aircraft. (draw a line\non each scale) IM status information (i.e., Eligible, Active, Suspended, Terminated) Projected spacing / ETA differential [i.e., (87)] alongside the spacing goal Comments: 28. The position of IM aircraft relative to the slot markers was logical. (draw a line on the\nscale) Comments: 29. The behavior of IM aircraft relative to the slot markers was acceptable. (draw a line on\nthe scale) Comments: 30. It was helpful to be informed and alerted to when IM was predicted to have no speed\nsolution. (draw a line on the scale) Comments: Trail\nAircraft Clearance\nType Spacing\nGoal Lead\nAircraft\n(sector) ABP Lead Aircraft\nRoute Status SWA1825 Achieve 85 AWE209 DERVL EAGUL6 Eligible SWA1011 Capture 93 (99) SWA2053 Active C-13 Overall\n31. What was the most difficult situation to deal with when aircraft were conducting IM during terminal metering operations? 32. What was the easiest situation to deal with when aircraft were conducting IM during\nterminal metering operations? 33. How could the conduct of IM during terminal metering operations be improved? Evaluation\n34. The training I received was adequate. (draw a line on each scale) IM operations: Terminal metering operations: Comments: 35. The overall activity was effective as a context for evaluating IM during terminal metering\noperations. (draw a line on the scale) Comments: 36. Was there anything about the event that artificially affected using it as a context for\nevaluating IM during terminal metering operations? (circle one) Yes No Dont Know If yes, explain: C-14 C.3 Pilot Post-Simulation Questionnaire\nIM (DURING TERMINAL METERING) HITL POST EVALUATION PILOT QUESTIONNAIRE Instructions: Please answer the questions by drawing a line through the option on each of the\nscales at the point which matched your experience or circling an option (e.g., yes / no). When\nchoosing an option, keep in mind that IM is the area of interest (e.g., not a traffic display\nalone). Unless otherwise indicated, consider all scenarios when answering. If you have any\nquestions, please ask the experimenter. Operations 1. I received an acceptable number of IM speeds. (draw a line on the scale) Comments: 2. I trusted that the algorithm was providing me the appropriate IM speeds to achieve and\nmaintain my assigned spacing goal. (draw a line on the scale) Comments: 3. It was clear that the IM speeds were driving towards the goal of appropriate spacing.\n(draw a line on the scale) Comments: C-15 4. The spacing I achieved / maintained when conducting IM was acceptable. (draw a line\non the scale) Comments: 5. I was able to detect whether I would remain within tolerances to achieve and maintain\nthe assigned spacing goal. (draw a line on the scale) Comments: 6. Did you ever try to out-guess the IM algorithm and the IM speeds? (circle one) Yes No Describe: 7. Did you choose not to fly an IM speed? (circle one) Yes No If yes, describe the situation(s) and why: 8. Normal termination (e.g., termination at the FAF upon completion of IM) procedures\nwere clear. (draw a line on the scale) Comments: 9. Abnormal termination (e.g., termination prior to the FAF due to a spacing issue)\nprocedures were clear. (if applicable) (draw a line on the scale) Comments: C-16 10. Suspend procedures were clear. (if applicable) (draw a line on the scale) Comments: 11. Resume procedures were clear. (if applicable) (draw a line on the scale) Comments: 12. Did you notice a difference between Achieve operations versus Maintain\noperations? (circle one) Yes No Comments: Which operation was acceptable? (circle one) Achieve Maintain Both If one is not acceptable, explain: 13. My roles and responsibilities related to IM operations were clear. (draw a line on the\nscale) Comments: 14. My overall workload was acceptable. (draw a line on the scale) Comments: C-17 15. My level of traffic awareness was acceptable. (draw a line on each scale) Lead aircraft for IM: Aircraft other than the lead aircraft: Comments: 16. IM is operationally desirable. (draw a line on the scale) Comments: 17. Given the appropriate training, IM is operationally acceptable. (draw a line on the scale) Comments: Communications 18. The amount of information communicated by ATC in the IM clearance was acceptable.\n(draw a line on the scale) Comments: C-18 19. Did any of the IM clearance elements cause you any difficulties? (circle one) Yes No If yes, which elements? (circle all that apply): 1. Clearance type (i.e., Achieve)\n2. Assigned spacing goal\n3. Achieve-by point\n4. Lead aircraft identification\n5. Lead aircraft route Describe any difficulties 20. Did you have any issues during communications when the lead aircraft identification\nwas used? (circle one) Yes No If yes, describe: 21. With additional experience and practice, use of the lead aircraft identification would be\noperationally acceptable. (draw a line on the scale) Comments: C-19 Display 22. The CDTI and AGD displays are acceptable for the following stages (draw a line on each\nscale) Clearance Entry: Entry evaluation / cross-flight deck coordination: Execution / IM conduct (without the graphical progress indicator on the AGD and\nairspeed tape on CDTI): Execution / IM conduct (with the graphical progress indicator on the AGDand\nairspeed tape on CDTI): Suspension (if applicable): Resumption (if applicable): Termination (if applicable): Comments: C-20 23. The necessary information was available from the ATC clearance to detect and select\nthe lead aircraft (draw a line on the scale) Comments: 24. I was able to perform IM by primarily focusing on the AGD information while\noccasionally referencing the CDTI. (draw a line on the scale) Comments: 25. Considering total time on the IM displays, estimate the total percentage of time using\neach display (total should equal 100). (enter a value for each display) Display Percentage Use AGD\n----------------- CDTI\n----------------- Total 100% Comments: C-21 26. I was able to detect when spacing issues were developing during IM operations. (draw a\nline on each scale) With only the ASG and SI numeric information on the AGD With the ASG and SI numeric information & graphical progress indicator on the AGD Comments: 27. The graphical progress indicator on the AGD is useful for IM. (draw a line on the scale) Comments: 28. The graphical progress indicator on the AGD is a minimum requirement for IM. (draw a\nline on the scale) Comments: 29. The graphical progress indicator is unnecessary. The numeric ASG (Assigned Spacing\nGoal) and numeric SI (Spacing Interval) are sufficient information to determine whether\nthe assigned spacing goal will be achieved and maintained. (draw a line on the scale) Comments: C-22 30. The speed tape on the CDTI is useful for IM. (draw a line on the scale) Comments: 31. The speed tape on the CDTI is a minimum requirement for IM. (draw a line on the scale) Comments: 32. The IM speed change advisory (e.g., box around IM Speed on AGD) was sufficient to\ndetect the presence of a new IM speed. (draw a line on the scale) Comments: 33. The IM speed conformance monitoring alert (e.g., visual and aural alert when the IM\nspeed was not being flown) is useful for IM. (draw a line on the scale) Comments: C-23 34. The IM speed conformance monitoring alert (e.g., visual and aural alert when the IM\nspeed was not being flown) is a minimum requirement for IM. (draw a line on the scale) Comments: 35. Did the combination of both the AGD and CDTI implementations include all the\ninformation necessary for you to conduct IM? (circle one for each) Without the graphical progress indicator on the AGD and airspeed tape on CDTI\nYes No With the graphical progress indicator on the AGD and airspeed tape on CDTI\nYes No If no, describe any instances where you would have liked more information, and the\nform in which the additional information would have been most useful. 36. Did you find any elements on the displays to be confusing or misleading? (circle one per\nrow) AGD Yes No\n----------------- CDTI Yes No If yes, describe: 37. Did you have any issues with the two separate displays? (circle one) Yes No If yes, describe: C-24 38. I could integrate the displays into my normal instrument scan. (draw a line on each\nscale) AGD: CDTI: Comments: 39. The necessary scan time was acceptable. (draw a line on the scale) Comments: 40. My level of head down time was acceptable. (draw a line on the scale) Comments:
41. I would be willing to perform IM with the CDTI and AGD I used today (ignore simulation\nissues if any existed, e.g., readability of text on the displays). (draw a line on each scale) Without the graphical progress indicator on the AGD and airspeed tape on CDTI With graphical progress indicator on the AGD and airspeed tape on CDTI Comments: C-25 Overall 42. What was the most difficult situation to deal with when conducting IM? 43. What was the easiest situation to deal with when conducting IM? 44. How could IM be improved? Evaluation 45. The training I received was adequate. (draw a line on the scale) Comments: 46. The overall activity was effective as a context for evaluating IM. (draw a line on the\nscale) Comments: 47. Was there anything about the event that artificially affected using it as a context for\nevaluating IM? (circle one) Yes No Dont Know If yes, explain: D-1 Appendix D Descriptions of Objective Measures This section provides descriptions and, where appropriate, details on each of the objective\nmeasures. D.1 IM Operations Conduct\n IM initiation delay by the controller o Definition: Difference in time between when the IM clearance was presented to the\ncontroller and it was accepted by controller action IM initiation point o Definition: Position where IM started as defined by controller acceptance action Frequency of IM initiations by the controller o Definition: Number of times the controller initiated IM after an IM operation was\npresented Frequency of IM rejections by the controller o Definition: Number of times the controller refused an IM clearance after it was\npresented Frequency and location of IM suspensions by the controller o Definition: Location and number of times the controller took action to make IM\ntemporarily inactive Frequency and location of IM terminations by the controller, as well as flight crew\nreports of unable IM o Definition: Location and number of times IM is made inactive Frequency of flight crew reports of unable IM o Definition: Number of times participants reported being unable to conduct IM D.2 IM Speeds and Flight Crew Actions\n Frequency of IM speed changes o Definition: Number of times a new IM speed is presented Magnitude of IM speed change relative to previous IM speed o Definition: Degree of change between IM speeds D-2 Frequency of IM speed reversals o Definition: This occurs when a previous IM speed change was an increase that is\nthen followed by an IM speed decrease (or vice versa). Table D-1 provides examples\nof situations that are and are not considered reversals. Table D-1. Speed Reversal Determination Methodology IM speed\n(current -2) IM speed\n(current -1) IM speed\n(current) Reversal? 180 Increase to 190 Increase to 200 No 180 Increase to 190 Decrease to 180 Yes 200 Decrease to 190 Increase to 200 Yes 200 Decrease to 190 Decrease to 180 No Frequency of IM speed increases o Definition: This occurs when the previous IM speed was lower than a new IM speed Time between IM speed changes and distance to go o Definition: How often IM speeds changed relative to how close the aircraft was from\nthe runway Frequency of flight crew compliance with IM speeds o Definition: Measure of whether the flight crew dialed the IM speed into the MCP\nwindow o Note: While ideally compliance would be zero difference between the MCP speed\nand the IM speed, the simulation MCP implementation sometimes made it difficult\nto match the number exactly. Therefore, setting the MCP speed to +/- 2 knots of the\nIM speed was considered compliance in this simulation Frequency of IM Speed Conformance Monitoring Advisories o Definition: The number of times the equipment determined that the IM speed was\nnot being conformed with and displayed an advisory to the flight crew D-3 D.3 Aircraft Spacing and Separation\n Schedule conformance at various points (e.g., TRACON entry, constraint points) o Definition: Difference between the aircrafts STA and ATA o Note: This measure is an indication of whether aircraft were on schedule (but does\nnot directly indicate whether aircraft were in their slot markers or how their\nschedule conformance relates to the aircraft ahead or behind) Absolute slot marker deviation o Definition: Difference between aircraft position and the center of the slot marker o Note: This measure is more operational than the schedule conformance measure\nand provides information about whether an aircraft was in the slot marker, and if\nnot, how far outside. It does not indicate how its slot marker position relates to the\naircraft ahead or behind. o Note: The on-going measures in the controller airspace were determined by voice\nfrequency changes (e.g., feeder airspace was bounded by checking in on the feeders\nfrequency and then checking in on the finals frequency) o Note: See Figure D-1 for slot marker deviation examples Aircraft time in slot markers o Definition: The amount of time aircraft were inside the slot markers o Note: Slot markers had a radius of 15 seconds in the feeder controllers airspace and\n5 seconds in the final controllers airspace Relative slot marker deviation o Definition: Difference between trail aircraft position and the center of the slot\nmarker and the lead aircraft position and the center of the slot marker o Note: This measure is more operational than the schedule conformance measure\nand provides relative spacing information. For example, if a lead is outside its slot\nmarker, this measure will show if the trail aircraft is outside its slot marker in the\nsame or opposite direction. When aircraft are performing IM, the expected behavior\nat the ABP would be that the trail IM aircraft is outside its slot marker in the same\ndirection and magnitude as the lead aircraft. o Note: This was measured when the lead (instead of the trail) crossed the points to\navoid any issues (e.g., lead landed) inside the FAF. o Note: See Figure D-1 for relative slot marker deviation examples D-4 Figure D-1. Slot Marker Deviation Relative Slot Marker Deviation Trial position same\n0 relative error Trail ahead an equal amount\n0 relative error Trail behind slot marker\nPositive relative spacing error Lead in center of the slot marker Lead ahead of the center of the slot marker Lead behind the center of the slot marker Trail ahead of slot marker\nNegative relative spacing error Trail behind a different amount\nPositive relative spacing error Trail behind an equal amount\n0 relative error Trail ahead a different amount\nPositive relative spacing error Trail ahead a different amount\nNegative relative spacing error Trail not ahead\nPositive relative spacing error Trail not behind\nNegative relative spacing error Trail behind a different amount\nNegative relative spacing error D-5 Spacing error o Definition: Error in meeting the ASG (for trail IM aircraft) or the TBFM interval (for\nnon-IM aircraft) o Note: This measure indicates how well a pair did relative to the planned interval\nbetween aircraft, even if off the original schedule (slots irrelevant). This is a relative\nmeasure. For trail IM aircraft, it is a measure of how well the ASG was met. For non-\nIM aircraft, it is a measure of how well aircraft met the TBFM-planned interval. o Note: For the IM aircraft: (ATAtrail at the ABP- ATAlead at the ABP) ASG For non-IM aircraft: (ATAtrail at the ABP- ATAlead at the fix) (STAtrail at the ABP -\nSTAlead at the fix) How well the ASG was maintained o Definition: Difference between ASG and current spacing of the trail IM aircraft from\nthe lead aircraft Note: For capture operations, started measure once trail IM aircraft got within\n10 seconds Frequency and location where aircraft pairs spacing was below the separation standard o Definition: Location and number of times spacing between an aircraft pair was\nbelow the applicable separation standard for the aircraft pairing and location Arrival rates / throughput (AAR number of aircraft per hour) o Definition: Number of aircraft landing (AAR number of aircraft per hour) Time aircraft remained on the RNAV arrival procedure o Definition: Amount of time aircraft remained on their route o Note: Indication of whether a spacing operation was working well enough to avoid\naircraft being vectored off their optimized route E-1 Appendix E Relative Slot Marker Analysis Detail This section provides the data used to derive the figures in Section 4.5.2.3. Slot marker\ndeviations are shown in Table E-1 (seconds) and Table E-2 (NM) when the lead aircraft was\nahead of its slot marker center. Figure E-1 shows a graphical representation. Slot marker\ndeviations are shown in Table E-3 (seconds) and Table E-4 (NM) when the lead aircraft was\nbehind its slot marker center. Figure E-2 shows a graphical representation. Table E-1. Lead and Trail Deviation in Mean Seconds (SD) Relative to Slot Markers When the\nLead Aircraft was Ahead of its Slot Marker Center Aircraft role IM\nclearance type Airspace location Feeder\nairspace Handoff to\nfinal Final airspace DERVL\n(merge) YOKXO (FAF) Lead Trail Lead Trail Lead Trail Lead Trail Lead Trail IM trail Achieve-\nby -23.0\n(11.7) -15.9\n(15.7) -8.1\n(6.8) -4.6\n(11.5) -12.7\n(8.9) -15.3\n(12.9) -6.8\n(3.7) -6.0\n(3.3) -9.1\n(7.0) -8.8\n(6.9) IM trail Achieve-\nby then maintain -16.5\n(9.4) -17.5\n(17.2) -6.8\n(4.8) -1.5\n(12.6) -11.0\n(9.2) -10.0\n(14.5) -6.4\n(4.7) -5.7\n(4.2) -12.3\n(12.6) -11.4\n(11.3) IM trail Capture\nthen maintain -17.9\n(8.6) -12.1\n(14.9) -8.4\n(5.6) -4.2\n(10.4) -13.4\n(7.5) -9.7\n(12.4) -7.2\n(5.4) -6.3\n(4.8) -10.1\n(8.1) -9.7\n(7.8) IM trail Total -19.0(10.4)\n-15.2\n(16.2) -7.7\n(5.8) -3.3\n(11.7) -12.2\n(8.7) -11.4\n(13.7) -6.8\n(4.8) -5.9\n(4.3) -10.5\n(9.7) -10.0\n(9.0) Non-IM trail -11.5(10.0)\n-9.9 (12.3)\n-6.3\n(5.5) -3.4\n(8.8) -9.3\n(8.5) -5.4\n(10.2) -5.6\n(3.8) -4.9\n(3.3) -8.9\n(9.2) -8.3\n(8.5) Table E-2. Lead and Trail Deviation in Mean
NM (SD) Relative to Slot Markers When the Lead\nAircraft was Ahead of its Slot Marker Center Aircraft role IM\nclearance type Airspace location\nFeeder airspace\nHandoff to final Final airspace\nDERVL (merge)\nYOKXO\n(FAF) Lead Trail Lead Trail Lead Trail Lead Trail Lead Trail\nIM trail Achieve-\nby -1.8\n(0.9) -1.4\n(1.4) -0.6\n(0.5) -0.3\n(1.0) -0.8\n(0.5) -1.0\n(0.9) -0.3\n(0.2) -0.2\n(0.4) -0.4\n(0.3) 0.3\n(0.4) IM trail Achieve-\nby then maintain -1.3\n(0.7) -1.6\n(1.5) -0.5\n(0.3) -0.1\n(1.1) -0.7\n(0.6) -0.7\n(1.0) -0.3\n(0.2) -0.3\n(0.4) -0.6\n(0.6) 0.6\n(0.7) IM trail Capture\nthen maintain -1.4\n(0.7) -1.0\n(1.3) -0.6\n(0.4) -0.3\n(0.9) -0.8\n(0.4) -0.6\n(0.9) -0.3\n(0.2) -0.2\n(0.5) -0.6\n(0.4) 0.4\n(0.6) IM trail Total -1.5(0.8)\n-1.3\n(1.4) -0.6\n(0.4) -0.2\n(1.0) -0.8\n(0.5) -0.8\n(0.9) -0.3\n(0.2) -0.3\n(0.4) -0.5\n(0.5) 0.5\n(0.6) Non-IM trail -0.9(0.8)\n-0.8\n(1.1) -0.5\n(0.4) -0.2\n(0.7) -0.6\n(0.5) -0.3\n(0.7) -0.3\n(0.2) -0.2\n(0.4) -0.5\n(0.5) 0.5\n(0.6) E-2 Figure E-1. Relative Slot Marker Deviation at Various Airspace Locations When Lead Aircraft\nwas Ahead of its Slot Marker Center E-3 Table E-3. Lead and Trail Deviation in Mean Seconds (SD) Relative to Slot Markers When the\nLead Aircraft was Behind its Slot Marker Center Airspace location Aircraft role IM\nclearance type Feeder\nairspace Handoff to\nfinal Final airspace DERVL\n(merge) YOKXO\n(FAF) Lead Trail Lead Trail Lead Trail Lead Trail Lead Trail\nIM trail Achieve-\nby 6.1\n(5.9) -4.8\n(21.4) 7.9\n(5.5) 5.3\n(12.1) 5.7\n(4.4) 3.3\n(11.2) 10.0\n(4.9) 8.6\n(4.1) 7.8\n(6.8) 7.0\n(5.4) IM trail Achieve-\nby then maintain 13.0\n(7.6) -1.7\n(14.9) 13.0\n(6.6) 4.7\n(11.4) 7.0\n(5.1) 3.0\n(11.6) 8.0\n(5.5) 7.0\n(5.0) 7.5\n(5.1) 7.3\n(5.0) IM trail Capture\nthen maintain 7.2\n(4.3) 5.6\n(8.5) 9.7\n(3.8) 8.0\n(4.6) 7.0\n(4.5) 7.5\n(4.8) 14.1\n(9.5) 10.9\n(6.0) 8.9\n(8.2) 7.8\n(6.5) IM trail Total 9.2(7.2)\n-1.4 (17.1)\n10.4\n(6.1) 5.6\n(10.7) 6.4\n(4.7) 4.0\n(10.6) 9.8\n(6.5) 8.3\n(5.1) 8.1\n(6.8) 7.5\n(5.7) Non-IM trail 12.7(8.0)\n-9.9 (15.9)\n11.8\n(8.4) -2.1\n(9.7) 5.0\n(5.7) -5.2\n(9.9) 8.4\n(7.1) 7.2\n(6.1) 7.5\n(6.2) 7.0\n(5.6) Table E-4. Lead and Trail Deviation in Mean NM (SD) Relative to Slot Markers When the Lead\nAircraft was Behind its Slot Marker Center Aircraft role IM\nclearance type Airspace location\nFeeder airspace\nHandoff to final Final airspace\nDERVL (merge)\nYOKXO\n(FAF) Lead Trail Lead Trail Lead Trail Lead Trail Lead Trail\nIM trail Achieve-\nby 0.5\n(0.5) -0.3\n(1.8) 0.6\n(0.4) 0.5\n(1.0) 0.4\n(0.3) 0.3\n(0.8) 0.4\n(0.2) 0.6\n(0.4) 0.4\n(0.2) 0.2\n(0.5) IM trail Achieve-\nby then maintain 1.1\n(0.6) -0.2\n(1.3) 1.0\n(0.5) 0.3\n(0.9) 0.5\n(0.3) 0.2\n(0.8) 0.4\n(0.3) 0.2\n(0.5) 0.4\n(0.2) 0.4\n(0.4) IM trail Capture\nthen maintain 0.6\n(0.3) 0.5\n(0.7) 0.7\n(0.3) 0.6\n(0.4) 0.5\n(0.3) 0.5\n(0.3) 0.5\n(0.4) 0.3\n(0.5) 0.3\n(0.2) 0.3\n(0.4) IM trail Total 0.8(0.6)\n-0.1\n(1.5) 0.8\n(0.5) 0.5\n(0.9) 0.4\n(0.3) 0.3\n(0.7) 0.4\n(0.3) 0.3\n(0.5) 0.3\n(0.2) 0.3\n(0.4) Non-IM trail 1.1(0.6)\n-0.8\n(1.3) 0.9\n(0.7) -0.1\n(0.8) 0.4\n(0.4) -0.3\n(0.7) 0.4\n(0.3) 0.0\n(0.4) 0.3\n(0.2) 0.0\n(0.4) E-4 Figure E-2. Relative Slot Marker Deviation at Various Airspace Locations When Lead Aircraft\nwas Behind its Slot Marker Center F-1 Appendix F Acronyms and Abbreviations Acronym Definition\nA80 Atlanta TRACON\nABP Achieve-By Point\nACSS Aviation Communication & Surveillance Systems\nADS-B Automatic Dependent Surveillance-Broadcast\nADV Advisory\nAGD ADS-B Guidance Display\nANOVA Analysis of Variance\nASG Assigned Spacing Goal\nATC Air Traffic Control\nATD Air Traffic management Demonstration\nATP Air Transport Pilot\nATPA Automated Terminal Proximity Alert\nCA CMS ATD\nCARS Controller Acceptance Rating Scale\nCDTI Cockpit Display of Traffic Information\nCDU Control and Display Unit\nCLT Charlotte TRACON\nCMS Controller Managed Spacing\nCPC Certified Professional Controller\nCPDLC Controller Pilot Data Link Communications\nEFB Electronic Flight Bag\nEICAS Engine-Indicating and Crew-Alerting System\nETA Estimated Time of Arrival\nF11 Orlando TRACON\nFAA Federal Aviation Administration\nFAF Final Approach Fix\nFIAT Fully Integrated ATD-1 Test F-2 Acronym Definition\nFIM Flight deck-based Interval Management\nFMS Flight Management System\nFO First Officer\nHITL Human-in-the-loop\nIDEA Integration, Demonstration, and Experimentation for Aeronautics\nIFPI Intended Flight Path Information\nGIM-S Ground-based Interval Management-Spacing\nIAS Indicated Air Speed\nIAT Inter-Arrival Time\nIM Interval Management\nIMAC Interval Management Alternative Clearances\nIMPAT IM Performance Analysis Team\nKATL HartsfieldJackson Atlanta International Airport\nKORD O'Hare International Airport\nKPHX Phoenix International Airport\nKSFO San Francisco International Airport\nkt knot\nLED Light-Emitting Diode\nM Mean\nMANOVA Multivariate Analysis of Variance\nMCDU Multifunction Control and Display Unit\nMCP Mode Control Panel\nMIA Miami TRACON\nMOPS Minimum Operational Performance Standards\nMSI Measured Spacing Interval\nMTE Meet Time Error\nNAS National Airspace System\nNASA National Aeronautics and Space Administration\nND Navigation Display F-3 Acronym Definition\nNM Nautical Miles\nOIA Operational Integration Assessment\nPBN Performance Based Navigation\nPCT Potomac TRACON\nPF Pilot Flying\nPFD Primary Flight Display\nPHL Philadelphia TRACON\nPM Pilot Monitoring\nPSI Predicted Spacing Interval\nPTP Planned Termination Point\nRF Radius-to-Fix\nRNAV Area Navigation\nRNP Required Navigation Performance\nRTA Required Time of Arrival\nSCX Sun Country\nSD Standard Deviation\nSI Spacing Interval\nSTA Scheduled Time of Arrival\nSTAR Standard Terminal Arrival Route\nSTARS Standard Terminal Automation Replacement System\nTBFM Time Based Flow Management\nTBO Trajectory Based Operations\nTOAC Time of Arrival Control\nTPA Tampa TRACON\nTRACON Terminal Radar Approach Control\nTSAS Terminal Sequencing and Spacing\nTSS Terminal Sequencing and Spacing\nTTG Time-To-Go Disclaimer\nThe contents of this material reflect the views of the author and/or the Director of the Center\nfor Advanced Aviation System Development (CAASD), and do not necessarily reflect the views\nof the Federal Aviation Administration (FAA) or the Department of Transportation (DOT).\nNeither the FAA nor the DOT makes any warranty or guarantee, or promise, expressed or\nimplied, concerning the content or accuracy of the views expressed herein. This is the copyright work of The MITRE Corporation and was produced for the U.S.\nGovernment under Contract Number DTFAWA-10-C-00080 and is subject to Federal Aviation\nAdministration Acquisition Management System Clause 3.5-13, Rights in Data-General, Alt. III\nand Alt. IV (Oct. 1996). No other use other than that granted to the U.S. Government, or to\nthose acting on behalf of the U.S. Government, under that Clause is authorized without the\nexpress written permission of The MITRE Corporation. For further information, please contact\nThe MITRE Corporation, Contract Office, 7515 Colshire Drive, McLean, VA 22102 (703) 983-\n6000. \nauthored by a contractor or affiliate of the Government. As such, the Government retains a\nnonexclusive, royalty-free right to publish or reproduce this document, or to allow others to do\nso, for Government Purposes Only. ",
    "text": " LEGEND MUST APPEAR ASSOCIATED WITH TEXT (end note acceptable)\nThe author's affiliation with the MITRE Corporation is provided for identification purposes only and is not intended to \nconvey or imply MITRE's concurrence with, or support for, the positions, opinions, or viewpoints expressed by the \nauthor. Approved for Public Release; \nDistribution Unlimited. Case Number 18-0141 State and Local ICT Policy: \nA Framework for Cybersecurity, IOT, Cloud, Block Chain, etc. Michael A. Aisenberg, Esq. Assistant Editor \nChairman, ABA Information Security Committee\nPrincipal Cyber Policy Counsel, The MITRE Corporation\nThe author's affiliation with the MITRE Corporation is provided for identification \npurposes only and is not intended to convey or imply MITRE's concurrence with, \nor support for, the positions, opinions, or viewpoints expressed by the author. February, 2018 ICT in the States: The Problem is one of Federalism When Alexis de Tocqueville visited the young United States preparing to author \nDemocracy in America in 1836, he tempered his celebration of the Constitutional tools of \nthe American Federal experiment with observations about the unique relationship \nbetween the individual states and the fledgling Federal government. De Tocqueville \nspecifically bemoaned the absence of effective executive functions at the state level, \ncapable of carrying out common public purposes: Certain undertakings are of \nimportance to the whole State; but they cannot be put in execution, because there is no \nState administration to direct them. (Chap V. Democracy in America, 1898 ed.) Over our history, even as the Federal role in regulation of business and technology has \nadvanced some argue, exploded-in the pursuit of the public interest, convenience \nand necessity so too have the states acquired new and diverse roles not envisioned by \nthe framers or in their own original constitutional fabrics. The roles of Texas as national \narbiter of public school text book content, of California as a center for innovation in \nworkplace policy and of New York as a front line cyber security regulator all mirror \nfunctions present to varying degrees in Federal policy structures; yet each of these, as \nwell as dozens of other state regulatory rgimes exhibit unique, distinct \nimplementations reflective of local economic activity and public demands for policies \ntuned to the character of the individual jurisdiction. The advent of pervasive reliance on information and communications technologies (ICT) \nover the past four decades, accelerated by the Internet since the availability of the World \nWide Web in the 1990s has resulted in a state-centered level of activity which \ncumulatively exceeds the Federal ICT infrastructure. Not only is a uniquely state- 1 Californias Breach Notification bill, S.B. 1386, 2002, became Civil Code sections 1798.29, 1798.82 and 1798.84, \nand variants have been adopted in over 40 states. In the intervening period, nineteen Congressional subcommittee \nhearings on Breach notification proposals have been held, with no passage in either House.\n2 In March of 2017, the New York Superintendent of Financial Services promulgated 23 NYCRR Part 500, a regulation establishing \ncybersecurity requirements for financial services companies. As of August 28, 2017, banks, insurance companies, and other \nfinancial services institutions regulated by NYSDFS are required to have a cybersecurity program designed to protect consumers \nprivate data; a written policy or policies that are approved by the board or a senior officer; a Chief Information Security Officer to help \nprotect data and systems; and controls and plans in place to help ensure the safety and soundness of New Yorks financial services \nindustry. \n3 NARA Catalog of EOs 2000-2017. https://www.archives.gov/federal-register/executive-orders/disposition.\n4 See e.g., National Conference of State Legislatures (NCSL) Cyber Security legislation 2017. \nhttp://www.ncsl.org/research/telecommunications-and-information-technology/cybersecurity-legislation-2017.aspx; Table of Computer \nCrime Statutes, http://www.ncsl.org/GoogleResults.aspx?q=computer%20crime%20statutes. sponsored activity (public education) frequently the locus of individual citizen initiation of \nexposure and training on IT devices, but the myriad institutions of state government \nhave become the most prevalent consumer of ICT equipment, software and services. \nAs documented by Gartner annual survey data, state-supported public and higher \neducation, courts, law enforcement and criminal justice, corrections, taxation, benefits \nsystems and health care are all also notoriously ICT dependent. Examples of the public policy consequences of this emerging state and local ICT center \nof gravity abound. Among the most visible examples of state squeaky wheel policy \nresponses are the proliferation of the California model of data breach response in the \ndata breach statutes in over 40 states1, and the 2017 adoption of a rigorous data \nsecurity obligation on New York-present financial service and banking institutions, \nadministered by the NY State Department of Financial Services2. Contributing Cause: Congressional Policy Gridlock The emergence of state and other sub-federal regulation of technology activities is often \nattributed to a lack of progress at establishing Federal consensus regulatory and \nresponse structures through legislation. The brutal debates and episodic inertia on \ndata breach notification is a poster child case in point, as a series of Federal response \nschemes has failed to achieve Congressional consensus beginning in the mid-2000s, \neven as multiple, sometimes wildly divergent approaches to data abuse proliferated in \nthe states. While it is not the purpose of this essay to argue that point, abundant \nevidence in simple statistical observation of the number of bills introduced in Congress \nwith a cyber component, compared to the number of measures actually passed since \n2000 reveals a striking disparity, with observable consequences. This absence of Congressional policy action on many cyber issues has resulted in two \ndemonstrable responses: one, in the form of a body of Executive Orders and \nPresidential directives addressing aspects of cyber security, crime and information \nsharing across Administrations from Clinton to Bush II, Obama and Trump. 3 The \nsecond is a body of state statutes addressing Cyber Crime, Data Breach notification and \nother ICT niche topics.4 But one need not look very far back in our history to understand that, at least for issues \nwhich couldand arguably, would benefit from being addressed through comprehensive http://www.dfs.ny.gov/legal/regulations/adoptions/dfsrf500txt.pdf\nhttp://www.dfs.ny.gov/legal/regulations/adoptions/dfsrf500txt.pdf\nhttps://www.archives.gov/federal-register/executive-orders/disposition\nhttp://www.ncsl.org/research/telecommunications-and-information-technology/cybersecurity-legislation-2017.aspx\nhttp://www.ncsl.org/GoogleResults.aspx?q=computer%20crime%20statutes 5 Citations for Clinger Cohen, FISMA, FISMA II FITARA; OMB Circular A-130 (rev. 2016) as implementing policy for agency cyber \nsecurity.\n6 See DFARS Safeguarding Covered Defense Information and Cyber Incident Reporting.\nhttp://www.acq.osd.mil/dpap/dars/dfars/html/current/252204.htm# , and associated FAQs. (27 January 2017.) Federal policy in the form of Congressional legislative action, orders of the Executive \nbranch directing agency behavior and practice are at best, limited and ultimately, may \nbe counter-productive, especially when promptly reversed by a successor \nAdministration. Some Federal ICT policy structures have worked well; the directives in the complex of \nClinger-Cohen, FISMA, FISMA II and FITARA5 designed to provide cyber security \nprotection in the acquisition and deployment of Federal agency ICT capabilities is well \ndesigned and reasonably well adapted across DoD and national security agencies. But \nthe uneven results in Federal civilian agency security is evidence that the scope of that \nstructure is limited: it does not reach necessary private sector partners (notwithstanding \nrecent efforts to back door private sector cyber responsibility through the agency of \nControlled Unclassified Information (CUI) (formerly Sensitive but Unclassified)) rules6. \nIt also does not deal with the risks arising from abuses of counterfeiting and product \nimpersonation in the commercial ICT supply chain; and it does not address the $65 \nbillion in ICT hardware and software added annually by the states and 16,000 sub \nfederal localities to the already trillion-dollar ICT installed base in state, county, \nmunicipal and tribal (SLTT) infrastructure. The corpus of Executive Orders and other Presidential directives which has proliferated \nin parallel with the asserted diminishing capacity of the Congress to reach consensus \nand pass substantive legislation is well documented. It is not, however as dramatic nor \npervasive as champions and critics claim. For example, during the Obama \nAdministration, the following major ICT/Cyber legislation was passed by the Congress: National Cybersecurity Protection Act of 2014\nFISMA II\nFITARA During the same eight-year period, the following Cyber-focused Executive Orders and \nPresidential directives were issued: EO Subject Date\nEO 13587 Improve the Security of Classified Networks 2011\nEO 13636 Improving Critical Infrastructure Cyber Security 2013\nEO 13691 Cybersecurity Information, promotion of private sector sharing 2015\nEO 13694 Cyber-Related Sanctions Designations, Treasury Dept. 2015\nEO 13702 National Strategic Computing Initiative 2015\nEO 13718 Enhancing National Cybersecurity Commission; establishment 2016\nEO 13757 Malicious Cyber-Enabled Activities 2017\nPPD 21 Critical Infrastructure Resilience and Security 2/12/2013\nPresidential Memorandum Establishment of the Cyber Threat Intelligence Integration Center\n2/25/2015 PPD 41 United States Cyber Incident Coordination 7/26/2016 http://www.acq.osd.mil/dpap/dars/dfars/html/current/252204.htm# \nhttp://www.acq.osd.mil/dpap/dars/dfars/html/current/252204.htm# \nhttp://www.privsecblog.com/2014/12/articles/cyber-national-security/congress-passes-the-national-cybersecurity-protection-act-codifies-national-cybersecurity-center-creates-federal-agency-data-breach-notification-law/\nhttps://www.archives.gov/federal-register/executive-orders/2013.html#13636\nhttps://www.archives.gov/federal-register/executive-orders/2016.html#13718 7 Gartner sub Federal ICT spending report: http://www.comproinc.com/wp-content/uploads/2015/06/CPI_Market-\nInsight_State-and-Local-Government-IT.pdf In fairness, the intent and appetite of the last administration to engage in top-to-bottom \nICT/Cyber policy reinvigoration was substantial; in February of 2016, eleven months \nbefore leaving office, the Obama Administration released a broad multi-pronged \nCybersecurity National Action Plan, a comprehensive agenda for action which SHOULD \nhave been an omnibus cyber policy statute, but instead became a largely unfulfilled \ncyber shopping list incorporating, inter alia: Establishment of the Commission on Enhancing National Cybersecurity. Emphasizing partnerships between Federal, State, and local government and the private sector in the development, promotion \nand use of cybersecurity technologies, policies, and best practices. Proposal of a $3.1 billion Information Technology Modernization Fund, which will enable the retirement, replacement, and modernization \nof legacy IT that is difficult to secure and expensive to maintain.Formation of a new position the Federal Chief Information Security \nOfficer A new
National Cybersecurity Awareness Campaign launched by \nthe National Cyber Security Alliance Partner with technology firms like Google, Facebook, and Microsoft , and financial services companies such as MasterCard, Visa, PayPal, to \nsecure their online accounts and transactionsA Federal government agency identity proofing and authentication \naction Systematic review to reduce USG reliance on Social Security Numbers \nas an identifier of citizens.Investment of over $19 billion for cybersecurity as part of the \nPresidents Fiscal Year (FY) 2017 Budget. While some of these proposals were incorporated in EOs and agency initiatives, most of \nthese recommendations failed to secure Congressional action and remained aspirational \nat the end of the previous Administration, and some which were adopted in 2016 were \nsummarily reversed on January 20, 2017 and by EO 13800 later in 2017. It is a well-recognized principal of policy under our federal rgime that Congressional \nactionadoption of legislation and its codification in Federal public law-- is preferable to \npresidential actions, whether through executive order or memoranda, which by their \nnature are limited in effect to the conduct of Federal agencies under Article II authority, \nand do not reach the conduct of states, localities or individual citizens. In Information and Communications Technologies, the scope and scale of local interest \nis large, and growing. Studies in 2010-2015 report sub-federal ICT investments in the \n$70-75 billion range, expected to have reached at least $78 billion by 2017, and \ndestined to pass $100 billion annually by 2020.7 The scope of the sub-federal interest is \nthus large, and growing. Yet the domains of interest of state policy action, especially \nstatutory action, to date have been limited to squeaky wheel responses, addressing \nnotorious issues such as cybercrime and data breach notification. In fact, the areas of concern, and of potentially harmful behavior resulting in injury to \ncitizens and economic loss reach far beyond these tip of the iceberg issues and include \nthe entire scope of ICT reliance in personal and business activities of citizens, as well as \nthe reliance of state and local institutions on ICT to assure their proper conduct. http://www.comproinc.com/wp-content/uploads/2015/06/CPI_Market-Insight_State-and-Local-Government-IT.pdf\nhttp://www.comproinc.com/wp-content/uploads/2015/06/CPI_Market-Insight_State-and-Local-Government-IT.pdf\nhttps://obamawhitehouse.archives.gov/the-press-office/2016/02/09/executive-order-commission-enhancing-national-cybersecurity\nhttps://obamawhitehouse.archives.gov/the-press-office/2016/02/09/executive-order-commission-enhancing-national-cybersecurity\nhttps://obamawhitehouse.archives.gov/the-press-office/2016/02/09/executive-order-commission-enhancing-national-cybersecurity\nhttps://www.usajobs.gov/GetJob/ViewDetails/428904900\nhttps://www.usajobs.gov/GetJob/ViewDetails/428904900 Failures of technology, abuses, frauds and un-remediated anomalous functioning all \nmay contribute to economic AND physical harm. And in many instances, these harms \noccur without remedy, as slow or absent Federal policy fails to keep pace with exploding \npresence of ICT in local Critical Infrastructures, local businesses, workplaces, highways \nand homes. Framework for Action There are 4 areas of sub-federal interest which are ripe for addressing through \nlegislative and structural revisions of current practice which from a cost-benefit \nperspective may reap enormous benefits to the state and local ICT infrastructure, that of \ndependent non-governmental entities and individual citizens. Undo Federal pre-emption of civil suits for regulated connected (IOT) 1.\ndevices Improve action against ICT vendor sharp practices and insider fraud by 2.\nestablishing local expert investigative bodies such as emerging state and local \nInspectors General Modernize local government contracting for technology3. 4. Use the 79 existing multi-jurisdictional state-operated Fusion Centers to share \ninformation regarding cyber-attacks, system failures and vulnerabilities across \nstates Once a critical mass of consensus on these approaches is reached in the state and local \ncommunity, the framework of authorities and organizational structures to implement \nthem could be formalized and harmonized thru a uniform state statute to be developed \nby the Uniform Law Commission/National Conference of Commissioners of Uniform \nState Laws) (ULC/NCCUSL). Individual tailoring could readily be accomplished to \nrespond to unique local environments or interests, such as the presence of significant \nindustries (financial services in New York, media and technology in California). Lets briefly examine each of these 4 proposed areas for state ICT policy action. Reverse existing Federal preemption of state civil jurisdiction for IOT injuries The first element of the proposed 4-part framework for improving the state ICT \nenvironment deals with absence of clear Federal guidance regarding the explosion of \nthe Internet of Things and the connectivity of every manner of device to the global IT \nnetwork. A variety of connected devicesdevices operating on global networks as part of the \nInternet of Things (IOT)--are subject to federal regulation; as a result, injured individuals \nwho may wish to seek a remedy from the vendor of a failed devicea manufacturer of \nan unmanned vehicle, or of a connected medical device, or of an electrical appliance 8 An excellent review of the case law on Federal preemption of state tort jurisdiction for FDA-regulated products is \nfound at Marcia Boumil, FDA Approval of Drugs and Devices: Preemption of State Laws for Parallel Tort Claims, 18 \nJ. Health Care L. & Pol'y 1. Available at: http://digitalcommons.law.umaryland.edu/jhclp/vol18/iss1/2 which malfunctions and causes harm may find their path to a judgement is blocked by \nthe Federal regulatory scheme. For example, under present Federal law administered by HHS Food and Drug \nAdministration (FDA), connected medical devicesparticularly Class III medical devices \nwhose operation might directly impact patient safety and the failure of which might result \nin serious injury or death--are regulated by HHS FDA under the Food, Drug and \nCosmetics Act (FDCA) and its related Medical Device Amendments (MDA). Both the \nstatutory framework and associated jurisprudence with regard to the issue of state tort \nliability of drug manufacturers and device manufacturers for claims of damage in state \ncivil litigation are convoluted, evolving and nearly silent on the specific issue of \ntechnology injuries. These are injuries resulting not from a failure of an FDA-regulated \ndevice to conform to its traditional FDCA safety and efficacy requirements, but from \nharm resulting from a software error, connectivity failure or other cyber fault unique to \nthe fact of the devices connection to a network by which its functioning can be \ncontrolled, monitored and impaired. For much of the FDA regulatory landscape, including branded and generic drugs and \nmany medical devices, the statutory schemes and jurisprudence have identifiable \ncenters of gravity which can be summarized as three classes of federal preemption \narticulated in the Supreme Courts opinions in several cases since 2009 (express, \nimplied and obstruction preemption).8 Particularly for the many existing and emerging devices which can provide life-\nsustaining functionality of essential physiological systems, largely falling under Class III \npre- and post-market agency reviews, the issue of regulatory compliance is based on \nthe devices medical functionality and safety: does the infusion pump deliver the proper \nvolume of medication at the proper intervals, does the oxygen concentrator resist \ncontamination, will the defibrillator continue to deliver accurate voltage during a power \nfailure ? FDA regulatory review of these thousands of different devices, deployed to millions of \nhealth providers and individual patients have historically NOT been structured to \ndetermine if the devices have reliable networking software, are secure from external \nattacks and malicious tampering because of effective firewalls and encryption, or \npossess access controls which prevent unauthorized individuals from interacting with \nthe device and the patient. The various state tort liability statutes indeed seem to permit an individual to commence \na suit for injury against a device manufacturer; however, withstanding a motion to \ndismiss based on federal statutory direction of regulatory preemption is far less certain \nand has produced a line of cases across multiple jurisdictions, with multiple Supreme \nCourt reviews detailed in the Boumil article which in sum lead to the conventional http://digitalcommons.law.umaryland.edu/jhclp/vol18/iss1/2 wisdom that such suits are preempted by federal law. The resulting barrier to remedy for these thousands of injured individuals works an \nobvious unfairness, especially when the failure was related to an aspect of the device \nnot subject to the Federal regulatory agency review. Even those agencies which are \nbeginning to address technology flaws such as bad software, counterfeit chips and failed \nnetwork security are doing so prospectively, meaning, for example in the case of \nconnected medical devices that millions of devices may be in use, connected to \nnetworks but never having been subject to expert review to identify flaws and failures of \nthese network functions. The result is an environment where citizens injured by network-rooted failures of these \ndevices may be left with no recourse other than a complaint to the regulatory agency, \nwith unlikely prospects of being made whole, particularly where the harm was not simple \neconomic loss, but physical injury or death. The solution to this uncertain, unfair and potentially catastrophic limitation of jurisdiction \nis to counter it with a statutory grant of specific jurisdiction at the state level with \nparticular reference to the federal regulatory rgimes and focused specifically on \ndevices where the software and network connectivity capabilities of the devices were \nnever reviewed by the Federal regulatory agency. Improve contracting for information & communications technology devices, software, \nservices The second promising area for state action is one which recognizes the economic reality \nof the information economy. While we are quick to describe the cyber ecosystem as a \ncreature of invisible bits and bytes moving virtually undetected across the almost \nmythical world wide web, the fact is that the devices and appliances which enable this \ntraffic, and its associated trillions of dollars worth of commerce and other economic \nactivity itself constitutes an enormous economic force. As discussed earlier, according to Gartner and other surveys since 2010,
state and local \ngovernment purchases of information and communications technology devices \n(computer work stations, servers, laptops, routers, printers, smart phones, tablets and \nassociated software) grew from $50 billion past $70 billion to about $75 billion annually \nin 2017, to reach an anticipated $100 billion per year before 2025. This makes ICT procurement, along with real estate costs and vehicles, one of the top \nthree acquisition areas of every jurisdiction in the nation; ICT is what citizens tax \npayments are being used to pay for. At the Federal level, the statutory scheme outlined \nearlier has produced a model of controls and reviews intended to allow most federal \nagencies to buy commercial, off-the-shelf ICT products at favorable terms and pricing. \nNonetheless, over $100 billion a year is spent on ICT by the Federal government; the \nrecognized presence of costly mishaps, poor negotiation, faulty pricing, supply chain \nabuse and counterfeiting, not to mention outright insider theft, fraud and other \nmisconduct has resulted in an explosion in the ICT-related work of each agencys 9 See Department of Defense Instruction (DoDI) 5000.02, Operation of the Defense Acquisition System Inspector General, as well as the Congressional spending watch-dog agency, the \nGovernment Accountability Office (GAO). Statutes such as the Clinger-Cohen Act and FITARA provide direction to Federal \nacquisition officers on how to negotiate and obtain desired devices at the best value. \nTotal life cycle cost and best value negotiation have become commonplace in \ncommercial contracting as a result of programs and practices evolved in federal \nagencies to assure the best use of tax dollars; yet, much dissatisfaction remains in the \nagencies, the Congressional funding committees and the watch dogs. Due to its size, \ncritical missions and enormous IT budget, the Defense Department has evolved a \nvariety of acquisition practices under the Defense Acquisition Regulations (DFAR) \nintended to make program planners and acquisition officers tasks easier. One of the invaluable tools which has evolved in the wake of various statutory directions \nhas been the Program Protection Plan (PPP).9 The PPP is a planning and tracking tool \nconsolidating all protection efforts associated with a sensitive ICT acquisition in the \nDefense Department, but over time it has evolved to be used across the breadth of the \nnational security community, as well as Federal agencies seeking to exercise close \ncontrol over their ICT investments. As such, it would find useful applicability in state \ncourts, law enforcement, corrections, taxation and other domains. It is designed to deny \naccess to Critical Program Information (CPI) to anyone not authorized, not having a \nneed-to-know and prevent inadvertent disclosure of leading edge technology to foreign \ninterests, by tracking each engagement, document and other transactional element \nduring the planning, consummation and deployment of an ICT procurement. DoD Departmental guidance describes the process used to prepare a PPP when one is \nrequired: Any program, product, technology demonstrator, or other item developed as part of a separate \nacquisition process, and used as a component, subsystem, or modification of another program, \nshould publish a PPP.\nEffectiveness of the PPP is highly dependent upon the quality and currency of information available to \nthe program office.\nCoordination between the Program Management Office (PMO) and supporting [law enforcement] and \nsecurity activities is critical to ensure that any changes in the system CPI, threat, or environmental \nconditions are communicated to the proper organizations.\n[Law enforcement activities] supporting the program protection effort should provide timely notification \nto the PM of any information on adverse interests targeting their CPI without waiting for a periodic \nproduction request. Adoption of the PPP tool to support sensitive and large-volume/high value acquisitions is \nonly one of multiple tools and techniques available to revise state acquisition model to \nadd technology expertise/best practices throughout the ICT life cycle of system \nrequirement definition, procurement planning, acquisition, deployment and operations \nand retirement. Institution of Inspector General (IG) functions http://acqnotes.com/acqNote/critical-program-information\nhttp://acqnotes.com/acqNote/program-management-office-pmoprogram-management In addition to protecting the interests of citizens through expanded civil jurisdiction and \nimproving the potential ROI of individual procurements, another tool to add the sub-Federal ICT \narsenal is an expert body to investigate, prosecute and recover ill-gotten gains in the course of \nICT acquisition and use. Technology acquisition is complex: it goes wrong even when well \nplanned and managed. Along with the dramatic growth in total IT acquisition by local \ngovernments have come increased cost-draining complexities, vendor problems and outright \nfraud and abuse in the acquisition and deployment of Information and Communications \nTechnology systems to support local government operations These reported problems threaten to \nobliterate the economic benefits of data automation and frequently result in distractions of \ngovernments core mission of public service, all the expense of the taxpayer.\nLocal governments are challenged to adapt to the responsibility of this growing stewardship of \ncomplex IT infrastructure investments. One response to increasing ethical, financial and criminal \nabuses in local government operations has been the establishment of local independent Inspectors \nGeneral offices by a growing number of major urban municipalities and counties, including \nChicago, Philadelphia, Yonkers, Jacksonville, Broward, Miami-Dade and Palm Beach Counties \nin Florida, Albuquerque, New Mexico, New Orleans and Montgomery County, Maryland.\nThe dominant competing approach to the role of an Inspector General in local government is to \ndo nothing. Other approaches in some jurisdictions include the use of local auditors offices or \nfinancial crimes sections of local prosecutors. These, however, only focus on criminal behavior \nor statutory violations of procurement procedures, not the broader abuses within the scope of IG \ninvestigations.\nIG offices may be established by statute, local ordinance, by the local executive, by a public \ninitiative or even an NGO (for example, in Chicago, the IG effort has its roots in the independent \nBetter Government Association). But the major competing approach today is inertia-the \nabsence of any investment by local governments in rooting out fraud, waste and abuse.\nThe skill sets for local IGs typically are focused on auditing and investigations, supported by law \nenforcement and regulatory/legal policy. Leadership and professional staff typically hold terms \nthat transcend executive and legislative terms. In the case of ICT procurement fraud, operational, \nproduct and technical expertise are clearly desirable.\nThe IG role itself may be selected by a blue-ribbon panel, as is the case in Miami-Dade. In \nMontgomery County, a nominating committee of citizens appointed by the County Executive \nmakes recommendations of a slate of candidates to the County Council who select the final \nchoice.\nWhile the principal area of conflict in roles arises with respect to criminal investigations and \njurisdiction between prosecutors and the IG, these issues are typically addressable through a clear \nMoU between the agencies describing the role of the IG in any investigation prior to and once an \ncriminal charge has been filed. Criminal investigatory powers, including subpoena power and \ndirect prosecution for non-cooperation are common.\nThe core capability of a successful IG function is the offices ability to investigate and report on \nunacceptable practice; the metric of success is a record of changed behavior by acquiring \nagencies of government.\nThe establishment of the function will eliminate the limitation engendered by its absence; \nInspectors General act to identify and investigate waste and inefficient expenditure of public \nfunds, which while related to roles filled by ethics officers and prosecutors, are not their \nresponsibility. In the absence of IG roles, the investigation, auditing and remediation of abuses of \nlocal government operations could continue undetected and unaddressed, resulting in continuing \ncost to taxpayers. Significant successes are being achieved by the jurisdictions which have \nestablished local IG offices. Fusion Centers for IOT Flaw Information Sharing The fourth capability in this suite of ICT enhancements is to repurposeor more \npreciselyexpand the jurisdiction of the 79 existing Fusion Centers which were \nestablished across the nation in the wake of the 9/11 attacks and have continued to \noperate since that time. While the principal purposes of these centers established by \nthe interagency DoJ/DHS Fusion Center capability were counter-terrorism intelligence \nand drug interdiction, their structure and capabilities, coupled with multi-agency state \nand local representation make them an ideal additional eyes and ears function in \nsupport of improved state and local ICT environments. Because they maintain both an intra-state and national cross-Fusion Centers \ncommunications capacity, these centers can provide relief for a chronic problem of the \nICT environment: the failure to promptly share and communicate the details of systems \nand networks failures, attacks and other anomalies. By sharing in real-time the \nexistence of flaws in IT systems, software and services, these centers can become a \nbackbone element of a nationwide sharing environment long contemplated by the ISAC \ncommunity, the Sector Coordinating Councils and the ISAOs developed under the \nDHS/NIST Cyber Framework There is nothing particularly magical or unprecedented by any of these proposals. Civil \njurisdiction debates around Federal preemption have swirled for years. The importation \nof federal best practices for ICT procurements that are relevant to the concerns of states \nand localities is neither unduly complex nor itself unprecedented. {States have been free \nto utilize GSA schedule procurement vehicles in a number of product areas for two \ndecades.} As discussed the number of localities adopting local Inspectors General \ncapabilities is now perhaps in the hundreds, and growing. And Fusion centers
are \ncurrently utilized to share information on a 24x7 basis; it simply would be novel for them \nto adapt their capabilities to the routine sharing of ICT/IOT flaw, error, anomaly or attack \ninformation. Path Forward While it is certainly possible to draft and introduce individual pieces of legislation in state \nlegislatures to establish these functions and address the jurisdictional concern, or to \nissue proclamations from the desks of governors and mayors, a broader and more \ncomprehensive approach to achieving a fabric of improved ICT deployment in the states \nand localities could be utilized. All of the benefits of these improvements could be simultaneously achieved through the \nbundling of these proposals into legislative titles (Jurisdiction, Procurement reform and \nFraud Investigation, and ICT Anomaly Information sharing), and then further combining \none or more of these into a Framework instrument to be discussed and improved under \nthe aegis of the Uniform Laws Commission/NCCUSL. Whatever the vehicle for establishment of the mechanisms, the benefits to state and \nlocal government operations and the ultimate benefit to the taxpayers suggests these are worthy goals, in a to date neglected environment. ### The author's affiliation with the MITRE Corporation is provided for identification purposes only and is not intended to \nconvey or imply MITRE's concurrence with, or support for, the positions, opinions, or viewpoints expressed by the \nauthor. _top\n _GoBack ",
    "text": " DECEMBER 2017ADVANCED TECHNOLOGIES www.mitre.org Live-Action Simulations Test Ideas, Save Time and Money\nWill your new technical capability actually work in a joint mission? What about a natural disaster or other \ncivil emergency? MITREs SIMEX process uses advanced simulations and the latest tactics to increase \nmission success using realistic scenarios. In the Decision Theater, MITRE personnel experiment with various presentation styles in preparation for a SIMEX. The rails in the ceiling allow \nthe nine stacks of displays at the front to move forward and backward to change operational scenarios. Imagine youre a Navy officer who needs to see if a new joint mission capability involving underwater drones is feasible. Or a civil-agency manager who wants to test out new \ncommunications processes for first responders. How do you \nassess complicated ideas quickly without spending a fortune? If youre that Navy officer, will your machine-to-machine \ncommunication conflict with the need for human decision-making? \nAnd if youre using new processes and devices, will interoperability \nbetween joint commands be an issue? If youre a civil agency \nmanager, will your communications connect your cooperating \nagencies without delay or misunderstandings? One way to find out is with a MITRE SIMEXTM session. \nSIMEX is a contraction for simulation experiment. It offers \na special mix of technical and operational capabilities for \ngovernment agencies that want to try out new ideas by using \ndedicated, state-of-the-art laboratories. A SIMEX allows mission personnel to develop concepts \nof operations, or CONOPS, in a realistic, controlled synthetic \nenvironment at MITRE facilities in McLean, Virginia. Operators \npractice techniques and procedures using the latest technology. \nSIMEXs use real command-and-control systems with simulated \nweapons and sensors so military and civilian operators can execute \nthe various crisis scenarios. Save Time, Keep Costs Down\n SIMEXs allow agencies to wring out a proof-of-concept faster and \nat lower cost than a full-blown in-the-field exercise. For example, in \na recent classified SIMEX, the sponsor noted: In three experimental \nruns, operators made real-time decisions for weapon assignment, \nengagement timing, and movements. The interaction of live operators, \nwith high-fidelity engagement simulation, enabled weapon tactics to \nevolve rapidly and iteratively over the course of the SIMEX. In another classified experiment, representatives from different \nmilitary organizations worked with personnel sitting in multiple \nlocations. The SIMEX addressed 36 different scenarios related to an \nadvanced weapon system. Participants gained new insights into \noperations and identified areas for improvement in their current \nsystems. The event reduced overall costs and avoided hundreds of \nunnecessary staff hours. The activity also set the stage for a live \ndemonstrationall before burning a single gallon of fuel. SIMEXs provide quantitative analysis while still allowing for \ninnovation and serendipity, says Jim Dear, who manages and \ncoordinates all the SIMEX laboratory experiments. Dear has been \ninvolved with nearly 60 SIMEXs since they began in 2001. Hes \noverseen experiments on important topics ranging from joint surface \nwarfare, bio-security, and maritime domain awareness, to special \noperations, missile defense, irregular warfare, and more. MITRE Project Stories Many of them are classified, but MITRE \nalso conducts unclassified SIMEXs for \nagencies such as the Census Bureau, Border \nPatrol, Homeland Security, and IRS. For \nexample, a few years ago, MITRE worked \nwith national law enforcement agencies and \nVirginia state agencies to conduct a SIMEX \nto demonstrate how social media could help \nor hinder response times during a crisis. Two Exceptional Labs: \nNSEL and SEAL\n The events typically occur in two MITRE \nlabs, both in McLean, Virginia. The first lab \nis the National Security Experimentation \nLaboratory, or NSEL, which is sponsored by \nthe Office of the Secretary of Defense. Created \nin 2001, its the computational workhorse for \na SIMEX. Mission managers can connect to \nseveral government and contractor facilities to \nrun experiments that are service-specific, or \njoint in operation. NSEL uses real command-and-control \nsystems with simulated weapons and \nsensors. Military and civilian personnel can \nexecute crisis action scenarios to improve \ntheir planning and reaction times. To test \ninteroperability in a distributed environment, \nthe NSEL uses a variety of secure networks. The newest Simulation, Experimentation \nand Analysis Lab, or SEAL, opened in \nearly 2017. The SEAL supports analysis, \nexperimentation, testing, training, and mission \nrehearsal for classified and unclassified \noperations. It puts sponsors (friendly Blue Cell \noperators) in a visual environment that shows \nhow their new mission capabilities will work \nagainst opposing forces (Red Cell operators). \nHuge, high-definition monitors can be moved \nto change the look of command centers for the \nBlue Cell. Observers can see a SIMEX in action \nwithout disturbing operators in either the Blue \nCell or the Red Cell. (See The SEALWhere \nthe Action Is.) From Scenario Planning to \nPost-Event Analysis\n The whole SIMEX process from planning \nto final report is normally five to six months, \nDear says. First, MITRE staff work with \nour sponsors to design the simulation \ninfrastructure. During the integration \nand testing process, our data collection \nteam leader builds the Data Collection and \nAnalysis Plan that defines essential data \ncollection to support the SIMEX objectives. The SIMEX itself takes place over two \nweeks. The first week includes operator \ntraining on the new SIMEX CONOPS and \ntechnology. The second week includes 8 to 10 \nthree-hour scenarios when mission operators \nexecute the SIMEX. MITRE staff capture \nparticipants observations and experiences \nfor reference. These can be used to develop \nstrategy, tactics, and related technologies. In parallel, the NSEL data collection team \nexecutes the Data Collection and Analysis \nPlan and produces incremental After-Action \nReviews. Post-SIMEX analysis captures \nlessons learned, operator feedback, and data \ndriven measures of effectiveness. This gives \nprogram managers, science and technology \ndirectors, and warfighters, the information \nto make informed decisions. About a month \nafter the SIMEX, the data collection team \nproduces a briefing and final report on the \nSIMEX results, using the agreed-upon data \ncollection plan. Augmenting the written \nreports for every SIMEX are 8-10-minute video \nhighlight reels depicting the crucial moments \nduring SIMEX execution. Each SIMEX is custom-designed to test \na new mission capability to its maximum, \nDear says. As new technology rapidly \ncomes along, theres a good chance of \ninteroperability problems, or man-machine \ninterface issues. Every SIMEX teaches our \nsponsors and us something new. We have a \ngreat combination of capabilities that allow \nour sponsors to simulate any situation. The Decision Theater area is re-arranged, allowing Air Force and Army \noperators to do a hot wash (quickly discuss the results) of a live scenario. Contact: For more information on this and other MITRE programs, see www.mitre.org. \n by David A. Van Cleave If you work for a government agency \nand want to learn how a SIMEX can \nsupport your military or civilian missions, \ncontact MITRE at simexinfo@mitre.org. MITRE SIMEX is a trademark of the MITRE Corporation. The SEALWhere the Action Is\nThe Simulation, Experimentation and \nAnalysis Lab, or SEAL, manages the \npresentation portion of a SIMEX. Its \nwhere the Blue Cell, the good guys, take \non the Red Cell guys, says Jim Dear. About half of the SEALs 5,000 sq. ft. is \nthe Decision Theater, where Blue Cell \noperators interact with the simulation. The \nRed Cell operators, using the latest field \ntactics against the Blue Cell, work in the \nEvent Support area that is smaller and \nseparate from the Decision Theater. The Decision Theater holds SEALs rapidly \nreconfigurable A/V equipment. In the front \nare nine ceiling-mounted tracks, each \ncarrying a stack of three 55-inch displays. \nEach stack can move 30 feet back and forth. \nAt the side of the room are six ceiling-\nmounted tracks that carry a stack of three \nlarge displays, and can move 10 feet back \nand forth. We reconfigure the stacks to represent \nvarious kinds of command centers and \ndifferent set-ups depending on the \nmissions, Dear says. We can also divide \nup the commands and isolate command \nelements by moving the displays around. \nSo, every SIMEX is a little different. The \nDecision Theater also has fully customizable \nceiling-mounted theater lights to provide a \nhuge combination of ambiance settings for \nsimulation purposes. The Observation Room allows visitors \nto watch SIMEX scenarios without \ndistracting operators. The A/V capability \npresents various rooms on a display in the \nObservation Room so that visitors can see \nand hear what the operators are saying. The SEALs embedded audio and video \nrecording capability captures everything \nthat happens during the SIMEX, classified \n or unclassified. Thats important, Dear \nsays. It allows us to capture insights as they \noccur, and supplement our briefings and \nafter-action reports. Theres also a Unit Operations area \nthat supports simulated individual unit \noperations, and a Reception Room for \nvisitors, credentialing, and lab overviews. ",
    "text": " PPT Presentation Corporate Overview Predictive Analytics for Mental Health Outcomes: A Case for Novel Applications of the Hedonometer* \nMarch 6, 2018 Presented by Josh Park and Lisa Tompkins-Brown\n*Hedonometer developed in collaboration between University of Vermont and MITRE (Matt McMahon and Brian Tivnan)\nApproved for Public Release. Distribution Unlimited. Case No. 18-0717. | # | \n \nWelcome to today's presentation. My name is \nWith so many interesting presentations and exhibits going on right now I really appreciate your interest in exploring an emerging area of using advanced analytics to gain insight from large data sets to make informed decisions that ultimately lead to better health outcomes for our Nation. In today's talk we will talk about a tool that was developed in collaboration between MITRE and Academia (the University of Vermont) that measures happiness and how it has been and can be extended further to predict mental health outcomes in the general population and the Veteran community.\n1 Discussion Overview\nIntroduction:\nThe Hedonometer is an instrument to remotely-sense emotional states and levels, in real time or post hoc. \nThe Hedonometer provides an analytical platform to perform large-scale, sentiment analysis on many corpora in 10 global languages. \nDevelopment:\nThe Hedonometer arose from a longstanding collaboration between the Computational StoryLab at the University of Vermont (UVM) and The MITRE Corporation.\nAdvancement: \nThe team has explored various applications of the Hedonometer as an initial screening tool for detecting mental health outcomes in advance of clinical diagnoses.\nToday: \nOur collaborative pursuit: applying the Hedonometer as an initial screening tool to identify those Veterans at greatest risk to attempt suicide. | # | \n \nThe happiness measuring tool is called the Hedonometer. I'll conduct a demo Lisa will go over couple extensions of this tool Then I'll go over how it's being used for VA as part of our independent R&D efforts.\n2 Discover new possibilities Create unexpected opportunities Lead \nby pioneering together with our sponsors and partners MITRE: Solving Problems for a Safer World \nOur work connects people and data to change the health market and reinvent the health experience | # | \n \nMITRE works in the public interest across finance, health, national security, cyber, aviation, and more to solve problems for a safer world. MITRE only operates FFRDCs currently 7 of them which cover most federal govt agencies. Federally funded research and development centers play an important role in working with government and industry to deliver game-changing solutions to complex challenges. FFRDCs must:\nMeet a \"special long-term research and development need\" that cannot be met by in-house staff or traditional contractor resources. \n\"Operate in the public interest with objectivity and independence\" and \"be free from organizational conflicts of interest.\"\nReceive access to sensitive and proprietary data \"beyond that which is common to the normal contractual relationship.\" This ensures that sponsoring organizations receive fully informed guidance that reflects an understanding of all critical points of view.\nForm channels of expertise from multiple sources to advance government missions. These characteristics enable FFRDCs to act as long-term strategic partners with the government in such areas as:\nSystems engineering and integration\nResearch and development\nStudy and analysis FFRDCs are an especially valuable resource when an agency confronts a challenge for which there is no obvious solution or a situation in which there are many viable solutions. In these cases, and independent analysis is required to determine which choice offers the agency the greatest benefits in terms of efficiency, effectiveness, and affordability. 3 Sponsor Engagement Data is the next level of innovation in health Mission-driven Objective insight Unique vantage point Technical know-how Pioneering together We believe in the power of partnership and trusted engagement to solve our nations toughest health problems, for a safer world. | # | \n \nData is the new frontier. Using data in meaningful ways to drive mission success is MITREs strength and passion. Our work connects people and data to change the health market and reinvent the health experience. As Eric Schmidt said in his opening key note, data and information will drive the next wave of innovations through use of AI, machine learning, and predictive analytics to gain valuable insight so humans can make informed decisions. Like augmented reality, AI will augment human intelligence.\n4 MITRE Partners with Academia to Discover Novel Way to Measure Public Sentiment\nMITRE invests in partnership with University of Vermont (UVM) Resulting in the development of the Hedonometer\nAnalytical tool to perform large-scale sentiment analysis of social media content Extensions of Hedonometer to improve health outcomes for veterans\nEarly warning of emerging mental health issues like depression and PTSD\nVeteran-ometer Application of Hedonometer specifically tuned for veterans | # | \n \nThe Hedonometer was jointly developed in partnership with the University of Vermont. The experts at MITRE is Matt McMahon and Brian Tivnan. The tool in essence is a large-scale sentiment analysis of social media content. This can then be extended to measure a signal (MITREs roots lie in signal detection and processing radar, GPS, etc..). This signal can be detected and measured to determine an early warning system for mental health issues like depression and PTSD and help improve suicide prevention. We use a simple, fast method for measuring the happiness of texts that hinges on two key components: (1) human evaluations of the happiness of a set of individual words, and (2) a naive algorithm for scaling up from individual words to texts. we first use a pattern-matching script to extract the frequency of individual words in a given text. We then compute the weighted average level of happiness for the text neutral words averaging around 5\n5 www.Hedonometer.org | # | \n \nIdeally, we open a browser here and navigate to the site: www.Hedonometer.org so we can explore some of the dynamics rather than rely on static image Expand and shift time window\nClick on an event walk through components\nWalk through tabs\nProjects\nWords Google Mechanical Turk (Mturk)\nPress\nPapers What we do: we look at the sentiment of populations, by applying the hedonometer algorithm to all tweets and then computing average happiness along with word shifts which explain changes in happiness over time. What we dont do: we cant legally filter and examine individual peoples tweets. So, for example we can look at all tweets that mention veterans, and examine the effect of public announcements by the VA on sentiment and word usage, but we cannot look at all tweets by an individual. 6 Hedonometer has been extensively vetted Additional Applications\nPattern of Life\nGeography of Happiness\nLexicocalorimeter\nScientific Rigor of Hedonometer | # | \n 7 References: Scientific Foundation of Hedonometer\nSeveral examples of peer-reviewed publications in top-tier, scientific journals Extension of Hedonometer beyond English to 10 global languages \nProceedings of the National Academy of Sciences, Human language reveals a universal positivity bias. Link to Publication\nThis paper won MITREs 2015 Best Paper competition. Link to MITRE Announcement\nRecognized as #100 of Top Scientific Studies to Capture the Public Imagination in 2015. More here: https://www.altmetric.com/top100/2015/\nComputational approach for efficient and scalable screening for depression via Instagram\nEPJ Data Science, Instagram photos reveal predictive markers of depression. Link to publication\nRecognized as #17 of Top Scientific Studies to Capture the Public Imagination in 2017. More here: https://www.altmetric.com/top100/2017/#list&article=10422853\nExtension of efficient and scalable screening for depression and PTSD via Twitter\nNatures Scientific Reports, Forecasting the onset and course of mental illness with Twitter data\nLink to publication\nConfirmed by controlled experiments, Hedonometer is without peer\nEPJ Data Science, Sentiment analysis methods for understanding large-scale texts. \nLink to Publication Many more here: http://hedonometer.org/papers.html | # | \n \nBig picture: The results of our work and that of colleagues suggest that early-warning signs of emerging mental health issues like depression and PTSD can be observed in social media, even before any clinical diagnosis is made. The goal here is to build technology that identifies early warning signs of mental health problems, and connects individuals to a doctor sooner.\n8 Predicting Depression from Instagram | # | \n \nAbstract: Using Instagram data from 166 individuals, we applied machine learning tools to successfully identify markers of depression. Statistical features were computationally extracted from 43,950 participant Instagram photos, using color analysis, metadata components, and algorithmic face detection. Resulting models outperformed general practitioners average unassisted diagnostic success rate for depression. These results held even when the analysis was restricted to posts made before depressed individuals were first diagnosed. Human ratings of photo attributes (happy, sad, etc.) were weaker predictors of depression, and were uncorrelated with computationally-generated features. These results suggest new avenues for early screening and detection of mental illness. We also employed a suite of supervised machine learning algorithms to estimate the predictive capacity of our models. We report prediction results only from the best-performing algorithm, a 100-tree Random Forests classifier. Depressed individuals in the study tended to post photos that were, on average, bluer, darker, & grayer than those posted by healthy individuals. Their photos also tended to have less faces than those posted by healthy participants. These markers are evident in the Instagram feeds of two UVM students (who did not participate in the study but agreed to provide their Instagram data for the purpose of raising awareness to mental health issues)
and consistent with the psychological literature: depression has been shown to cause people to literally see the world through a colorless lens, and reduce their social activity. So while the results are not necessarily surprising, what is remarkable is that they hold even when we restrict model training to pictures posted prior to the date of diagnosis, demonstrating predictive skill. Furthermore, the model outperformed general practitioners average unassisted diagnostic success rate for depression. 9 Predicting Depression and PTSD from Twitter | # | \n \nIn a companion study, we investigated predictors of depression & PTSD using twitter messages. Linguistic style, sentiment, and meta-data were used to train supervised learning algorithms. Resulting models successfully discriminated between depressed and healthy content, and compared favorably to general practitioners average success rates. Again, the results held even when the analysis was restricted to content posted before first depression diagnosis, suggesting that onset of depression and PTSD may be detectable several months prior to formal diagnosis. Machine learning models. We trained supervised machine learning classifiers to discriminate between affected and healthy sample members observations. Classifiers were trained on a randomly-selected 70% of total observations, and tested on the remaining 30%. Out of several candidate algorithms, a 1200-tree Random Forests classifier demonstrated best performance. \nWe trained a two-state Hidden Markov Model (HMM) to detect differential changes between affected and healthy groups over time. 10 Pilot Study at University of Vermont (UVM): \nPredictors of Suicide Risk\nUsing social media to identify predictors of suicide risk Extending from two previous studies (Instagram and Twitter) Leveraging unique dataset from UVM hopstial \n1500 individuals who have died by suicide in VT, NH and northern NY\nNames, cities, activity matched w/100 billion tweets in last decade | # | \n \nBig picture: The results of our work and that of colleagues suggest that early-warning signs of emerging mental health issues like depression and PTSD can be observed in social media, even before any clinical diagnosis is made. The goal here is to build technology that identifies early warning signs of mental health problems, and connects individuals to a doctor sooner. 11 Veteran ometer\nApplication of Hedonometer specifically tuned for veterans\nNearly ten years of Twitter data\nSentiment analysis for tweets containing veteran \nRelative count of tweets in the veteran set that contain opioids | # | \n \nRed: overall Hedonometer values Blue: veteran-ometer [ambient happiness for veterans] Green: relative count of of veteran-ometer tweets containing the word opioids Note: January 2017 was the date U.S. Secretary of Veterans Affairs Dr. David J. Shulkin announced that VA has begun publicly posting information on opioids dispensed from VA pharmacies, along with VAs strategies to prescribe these pain medications appropriately and safely. https://www.blogs.va.gov/VAntage/44376/va-becomes-first-hospital-system-release-opioid-prescribing-rates/ \n12 Veteran ometer\nZoom in to 2016-2018:\nDates Highlighted Jan 2, 2018\nMost mentions of opioids\nVeterans Day\nVeterans Day\nOct 9, 2017\nMemorial Day\nNotes: We are working to add dates, events, VA press releases, and analysis around all the outlier datesextreme lows and highs in the data. | # | \n \nWe are working to add dates, events, VA press releases, and analysis around all the outlier datesextreme lows and highs in the data.\n13 Veteran ometer: Explaining differences with Word Shifts. Nov. 14, 2017 (Veterans Day)\nAverage Happiness: 6.40\nWhats making this day happier than the previous seven days:\nMay 29, 2017 (Memorial Day)\nAverage Happiness: 6.05\nWhats making this day happier than the previous seven days: October 9, 2017\nAverage Happiness: 5.14\nWhats making this day sadder than the previous seven days: | # | \n \nThe Happiness time series, along with the opioid frequency data, explain the What: What is average happiness in the veteran data on a given day?\nWord Shifts explain the Why: Why is a particular day happy or sad relative do another day? 14 Potential Applications at VA\nAssessing and understanding veteran sentiment\nLeverage well established MITRE & UVM team of Data Scientists, Computational Social Scientists, and Psychiatrists\nQuantifying and comparing analytics\nRigorous emphasis on quantifiable sentiment, insight into longitudinal changes over time \nInsight into the relevance of metadata relating location, TOD, relationships with other datasets, etc.\nProof of concept studies increasingly suggest there are linguistic & other behavioral predictors of state of mental health state, including suicidal.\nComplete pilot study initiated at UVM Medical Center and potentially extend to VA, given a training set of VA data \nveterans w/wo mental health diagnosis who have died by suicide\nveterans w/wo mental health diagnosis who have not attempted suicide\nBuild algorithm to identify predictors in classification task, validate on separate set of data. | # | \n 15 Thank you!\nJosh Park\njpark@mitre.org Lisa Tompkins-Brown\nltompkins@mitre.org Technical POC: Matt McMahon\nmcmahon@mitre.org | # | \n 16 Follow up To download a copy of this presentation, visit: https://health.mitre.org/himss18 Improving the \nPatient Experience\nFollow us on social media: @MITREhealth | # | \n 17 |12| www.Hedonometer.org | # | \n presentgeneralpractitionersunassisteddiagnosticaccuracyasreportedinMitchell,Vaze,and \nRao(MVR)(24) .6 Results BothAlldataandPrediagnosismodelsweredecisivelysuperiortoanullmodel\n.Alldatapredictorsweresignificantwith99%probability.57.5(KAll = 1 K 49.8) Pre = 1 \n7 PrediagnosisandAlldataconfidencelevelswerelargelyidentical,withtwoexceptions: \nPrediagnosisBrightnessdecreasedto90%confidence,andPrediagnosispostingfrequency \ndroppedto30%confidence,suggestinganullpredictivevalueinthelattercase. Increasedhue,alongwithdecreasedbrightnessandsaturation,predicteddepression.This \nmeansthatphotospostedbydepressedindividualstendedtobebluer,darker,andgrayer(see \nFig.2).ThemorecommentsInstagrampostsreceived,themorelikelytheywerepostedby \ndepressedparticipants,buttheoppositewastrueforlikesreceived.IntheAlldatamodel,higher \npostingfrequencywasalsoassociatedwithdepression.Depressedparticipantsweremorelikely \ntopostphotoswithfaces,buthadaloweraveragefacecountperphotographthanhealthy \nparticipants.Finally,depressedparticipantswerelesslikelytoapplyInstagramfilterstotheir \npostedphotos. Fig.2.MagnitudeanddirectionofregressioncoefficientsinAlldata(N=24,713)andPrediagnosis(N=18,513) models.Xaxisvaluesrepresenttheadjustmentinoddsofanobservationbelongingtodepressedindividuals,per \nstandardizedunitincreaseofeachpredictivevariable.Oddsweregeneratedbyexponentiatinglogisticregression \nlogoddscoefficients. 6Comparingpointestimatesofaccuracymetricsisnotastatisticallyrobustmeansofmodelcomparison.However, \nwefeltitwasmoremeaningfultoframeourfindingsinarealisticcontext,ratherthantobenchmarkagainstanaive \nmodelthatsimplypredictedthemajorityclassforallobservations. \n7K abbreviatestheBayesFactorratiobetweenthesubscriptedmodelandanullmodel.SeeSIAppendixIVforK \nvaluelegend. 8 presentgeneralpractitionersunassisteddiagnosticaccuracyasreportedinMitchell,Vaze,and \nRao(MVR)(24) .6 Results BothAlldataandPrediagnosismodelsweredecisivelysuperiortoanullmodel\n.Alldatapredictorsweresignificantwith99%probability.57.5(KAll = 1 K 49.8) Pre = 1 \n7 PrediagnosisandAlldataconfidencelevelswerelargelyidentical,withtwoexceptions: \nPrediagnosisBrightnessdecreasedto90%confidence,andPrediagnosispostingfrequency \ndroppedto30%confidence,suggestinganullpredictivevalueinthelattercase. Increasedhue,alongwithdecreasedbrightnessandsaturation,predicteddepression.This \nmeansthatphotospostedbydepressedindividualstendedtobebluer,darker,andgrayer(see \nFig.2).ThemorecommentsInstagrampostsreceived,themorelikelytheywerepostedby \ndepressedparticipants,buttheoppositewastrueforlikesreceived.IntheAlldatamodel,higher \npostingfrequencywasalsoassociatedwithdepression.Depressedparticipantsweremorelikely \ntopostphotoswithfaces,buthadaloweraveragefacecountperphotographthanhealthy \nparticipants.Finally,depressedparticipantswerelesslikelytoapplyInstagramfilterstotheir \npostedphotos. Fig.2.MagnitudeanddirectionofregressioncoefficientsinAlldata(N=24,713)andPrediagnosis(N=18,513) models.Xaxisvaluesrepresenttheadjustmentinoddsofanobservationbelongingtodepressedindividuals,per \nstandardizedunitincreaseofeachpredictivevariable.Oddsweregeneratedbyexponentiatinglogisticregression \nlogoddscoefficients. 6Comparingpointestimatesofaccuracymetricsisnotastatisticallyrobustmeansofmodelcomparison.However, \nwefeltitwasmoremeaningfultoframeourfindingsinarealisticcontext,ratherthantobenchmarkagainstanaive \nmodelthatsimplypredictedthemajorityclassforallobservations. \n7K abbreviatestheBayesFactorratiobetweenthesubscriptedmodelandanullmodel.SeeSIAppendixIVforK \nvaluelegend. 8 Figure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays fromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines representcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, witherrorbarsindicating95%CIoncentraltendencyofdailyvalues. Figure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom traumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple verticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded regionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial regressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating 95%CIoncentraltendencyofdailyvalues. 13 Figure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays fromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines representcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, witherrorbarsindicating95%CIoncentraltendencyofdailyvalues. Figure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom traumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple verticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded regionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial regressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating 95%CIoncentraltendencyofdailyvalues. 13 Figure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays fromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines representcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, witherrorbarsindicating95%CIoncentraltendencyofdailyvalues. Figure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom traumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple verticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded regionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial regressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating 95%CIoncentraltendencyofdailyvalues. 13 Figure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays fromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines representcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, witherrorbarsindicating95%CIoncentraltendencyofdailyvalues. Figure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom traumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple verticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded regionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial regressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating 95%CIoncentraltendencyofdailyvalues. 13 \nFigure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays \nfromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines \nrepresentcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, \nwitherrorbarsindicating95%CIoncentraltendencyofdailyvalues. \nFigure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom \ntraumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple \nverticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded \nregionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial \nregressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating \n95%CIoncentraltendencyofdailyvalues. \n13 \nFigure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays \nfromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines \nrepresentcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, \nwitherrorbarsindicating95%CIoncentraltendencyofdailyvalues. \nFigure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom \ntraumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple \nverticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded \nregionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial \nregressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating \n95%CIoncentraltendencyofdailyvalues. \n13 \nFigure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays \nfromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines \nrepresentcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, \nwitherrorbarsindicating95%CIoncentraltendencyofdailyvalues. \nFigure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom \ntraumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple \nverticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded \nregionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial \nregressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating \n95%CIoncentraltendencyofdailyvalues. \n13 \nFigure2.HiddenMarkovModelshowingprobabilityofdepression(N=74,990).Xaxisrepresentsdays \nfromdiagnosis.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Trendlines \nrepresentcubicpolynomialregressionfitswith95%CIbands,pointsareaggregationsof14dayperiods, \nwitherrorbarsindicating95%CIoncentraltendencyofdailyvalues. \nFigure3.HiddenMarkovModelshowingprobabilityofPTSD(N=54,197).Xaxisrepresentsdaysfrom \ntraumaevent.Healthydataareplottedfromaconsecutivetimespanofequivalentlength.Thepurple \nverticallineindicatesmeannumberofdaystoPTSDdiagnosis,posttrauma,andthepurpleshaded \nregionshowstheaverageperiodbetweentraumaanddiagnosis.Trendlinesrepresentcubicpolynomial \nregressionfitswith95%CIbands,pointsareaggregationsof30dayperiods,witherrorbarsindicating \n95%CIoncentraltendencyofdailyvalues. \n13 ",
    "text": " \nApproved for Public Release; Distribution Unlimited: 18-0671. Empowering Patients in their Own Healthcare A Conversation with Kristina Sheridan Q: Why have you been focusing your research on empowering patients? SHERIDAN: Im a mom to four kids, two of whom have been battling chronic conditions for many years. \nThe experience of being their caregiver inspired me to get involved in research for empowering patients. \nSo, for the last seven years Ive been leading the research at MITRE around empowering patients to \npartner with their providers for best care. Theres a lot of evidence that shows that patient engagement \nis very important and that it makes a big difference to health outcomes. But theres very little research \nthat shows how to empower those patients to engage in a beneficial way. We've been focusing upon \ndetermining what tools patients need to empower them to engage, and how to integrate their \ninformation through the healthcare system. Q: What challenges are we trying to address with your research to help patients and their providers? SHERIDAN: The problem is that right now we dont view patients or their caregivers as experts in the \nhealthcare industry. Patients have important information that only they can provide. Often, its referred \nto as the patient voice. Right now, the problem is they cannot easily capture that information in a way \nthat they can leverage to make better decisions, or in a way that their providers can look at and use to \nmake better decisions on the clinical side. We must recognize that patients are the only ones who can \nreally explain whats happening to them, accurately, and how their illness is impacting them daily. Q: Why are chronic health problems particularly challenging? SHERIDAN: Managing chronic conditions is difficult. Patients have little time in the day to organize \neverything that is happening to them. Without tools to help them, it is not reasonable to expect patients \nto collect information, and share it in a way thats usable. We want to determine the type of tools that \nwill support patients in the management of their care and in the collection and sharing of the \ninformation. Q: What are the barriers to patient empowerment within a clinical setting? SHERIDAN: The overarching challenge is integrating patient data through the clinical setting in such a \nway that it doesnt add burden to the doctors, but allows them to use it to make improved decisions. \nThere are three key barriers that keep this from happening. The first is that patients dont have tools to \nhelp them to collect this information in a way that they and providers can leverage. The second is that \nthe provider electronic health record systems arent designed to integrate this specific type of patient-\ngenerated data so that the providers can use it effectively. And the third is that measures and policies \ndont specifically address how we can leverage this data to evaluate the quality of care thats being \nprovided. Q: What is MITRE doing to address these barriers? SHERIDAN: We're looking at three areas within patient engagement. The first is determining what tools \nApproved for Public Release; Distribution Unlimited: 18-0671. patients need to capture patient-generated data that is useful to them and their providers. Weve \ndeveloped the Patient Toolkit that will support patients in gathering this data. The second is were \nexecuting clinical studies to look at how specifically these tools and this data would integrate through the \nclinical workflow. For instance, when does the provider look at the information? How does it need to be \nintegrated into their electronic health record systems? And third, MITREs looking at the clinical quality \nmeasures and the types of incentives that are available to providers to encourage them to use this type \nof data within the clinical setting. That way, we can identify the gaps and what must be put in place to \nincentivize the use of patient-generated data. Q: You mention toolshaven't patient information tools of different kinds existed for some time? SHERIDAN: Yes, but most existing patient tools are designed around one disease state. We created the \nPatient Toolkit to allow patients to capture their existing state of health. For example, within the tool, we \nhave a symptom picker that allows the patient to identify a full set of symptoms across all their disease \nstates, and track those symptoms that are specific to them. And to fully empower patients, we not only \nhave to develop a tool, but must understand and demonstrate how that tool fits end-to-end into the \nhealthcare ecosystem. Q: What partners are you working with? SHERIDAN: We're working with the Billings Clinic in Montana to pioneer research in how tools like the \nPatient Toolkit can be integrated not only at home, but all the way through the hospital setting. And we \npartnered with the University of Virginia to prove that collecting patient-generated data at home, rather \nthan in the clinic, was as reliable as if they were sitting right in front of their provider. That study also \nproved that as patients track their symptom data at home, that they gain an increased understanding of \ntheir health situation. The information from that study informed the development and design of the \nPatient Toolkit, because patients also gave us feedback in terms of how they wanted to capture that \ninformation. We also partnered with Carnegie Mellon on a national provider survey that showed us that \nproviders wanted longitudinal symptom severity data and medication compliance data to help inform \ntheir clinical decisions. Q: Who will find the Patient Toolkit useful? SHERIDAN: The toolkit is particularly beneficial for patients who have multiple chronic conditions. For \nexample, for veterans seeing multiple providers both inside and outside the VA for multiple conditions, \nthe toolkit allows them to capture all their information across all their illnesses and ensures that each \nprovider has the same set of information. It also helps the patients capture that information remotely. If \nthey have a long way to travel, patients need an accurate understanding of whats happening to them \nbefore they pick up the phone and call their providers. Q: How do you measure success in patient empowerment? SHERIDAN: Patients leave the hospital today with a piece of paper. When we truly empower patients, \ntheyll leave with tools that will help them manage at home, capture information that they can share \nwith their doctors, and partner for better health outcomes. Were executing a clinical study that looks at \nthe barriers that patients face in leveraging these tools, and the impact the tools and this data have on \nthe clinicians' workflow to ensure it doesnt add burden. And were looking at the health outcomes of \nthe patients when this patient data is integrated in and leveraged by the providers. Were also looking at \nApproved for Public Release; Distribution Unlimited: 18-0671. the cost implications to the hospital. Are there incentives available to support the use of this data and \nthese tools, and does the use of these tools reduce the costly part of hospital care? For example, do \npatients have a reduced number of ER visits and readmissionsand increased numbers of standard \nvisits? We also need to evaluate if this patient data can be used to measure the quality of care to \npatients and potentially increase the level of incentives hospitals receive. _top\n _GoBack ",
    "text": " 1 University of New South Wales Canberra at Australian Defence Force Academy, Systems Capability Centre, Canberra, \nAustralia, k.joiner@adfa.edu.au\n2 University of Sydney, Centre for International Security Studies and Sydney Cyber Security Network, Australia, \nsimon.atkinson@sydney.edu.au\n3 University of New South Wales Canberra at Australian Defence Force Academy, Australian Centre for Cyber Security\nCanberra, Australia, e.sitnikova@adfa.edu.au \n4 Mitre Corporation, pchris@mitre.org \n5 The examination of the cybersecurity challenges and processes for the Australian Future Submarine Program was \npresented to the Submarine Institute of Australias annual conferences in 2017 [1] and the Institute has kindly agreed for these \naspects to be used herein for broader implications. Cybersecurity for Allied Future Submarines Keith F. Joiner,1 Simon Reay Atkinson;2 Elena Sitnikova;3 Pete Christensen4 ABSTRACTI.\nCyber has become a supposedly cheap first-strike weapon of political choice by potential adversaries in a milieu \nplacing insurgency, terrorism, international crime and state-based influences in close un-regulated proximity. The \nmerging of electronic and cyber warfare means that not even submarines, however unconnected or firewalled they \nmay be, are immune. The quantum attack surface of submarines are as much in the past, as they are in their designs \ntoday and operations tomorrow: they must survive to be credible and ideally should be a contemporary offensive \ncyber deterrent. Such critical defensive systems require robust security systems engineering and cybersecurity test and \nevaluation to build and sustain their cyber-resilience. This paper uses Australias future submarine program5 to outline \nkey facets needed in a submarine program to achieve cyber resilience, including how to adapt U.S. Department of \nDefense (DoD) best practices to engineer, test and sustain cyber-resilient submarine systems. Strategies are needed \nthat provision sovereign-owned and operated land-based test sites to design, build, demonstrate and sustain critical \nsubmarine systems. This work is most relevant to countries allied to the U.S. and importing submarine capabilities, \nsuch as within lesser European powers and also in the Indo-Pacific where both cyber warfare and submarines are \nproliferating. KEYWORDS II.\ncyber-resilience, future submarine design, land-based test sites, quantum attack surface, test and evaluation INTRODUCTION III.\nThe Australian National Audit Office [2] gives an overview of Australias future submarine program and the decision to select the French Naval Group and Lockh eed Martin as the designers of Australias new Short-Fin \nBarracuda class. Furthermore, Stanford in [3] covers the economic, technical, strategic and other risks of this Program \nand the choices made thus far, in a comprehensive and somewhat contrary public policy report and exposition. From a \ntechnical risk perspective, Joiner and Reay Atkinson [4] summarised significant lessons learnt from the Collins \nSubmarine program concerning inadequate test and evaluation and insufficient land-based testing capability (i.e., in [5], \n[6]). A concern of both of these reviews is the emerging risk of the Australian Submarine Program in not yet \nconducting preview test and evaluation of reference design classes to disclose technical and operational risks prior to \ndesign down-select and contract. This paper will use this risk context to illustrate the particular threat of cyber warfare \nto future submarines generally and early in their design, and then how best to leverage U.S. DoD cybersecurity test and \nevaluation processes for such an allied submarine design against these new threats. Cybersecurity concerns were first raised publically in Australia about releases of the French-Indian submarine, after \nwhich Australias Minister Pyne gave assurances about the cybersecurity to be applied to French-Australian \nsubmarine planning [7], [8]. Such cybersecurity risks and mitigation and contingency planning for Australias future \nsubmarine program have not yet been outlined. The increasing threat of cyber-enabled warfare for Australia has been \nreviewed extensively by Austin [9], following instances of cyber espionage; including the Australian Secret Intelligence \nOrganisation building [10], [11]; and increasing instances of cyber-attack [12]. The Australian Government has focused \nits DoD on meeting the new threat [13], however, according to Joiner [14] much more could be done practically to 2 leverage U.S. DoD initiatives in cybersecurity T&E. Proposals by Joiner, Sitnikova and Tutty [15] on how to engineer \ncyber-resilient systems in the Australian DoD has been followed more recently by an extensive exposition by Joiner and \nTutty [16] examining how the U.S. DoD has undertaken at least six major initiatives to give more integration and \ninformation assurance to its complex and interconnected systems and how that may be leveraged by the Australian \nDoD. This paper extends on these broader works with research into how those initiatives can specifically apply to future \nsubmarines. In particular, recent research into how to create trusted supply chains for software-intensive systems will \nbe overviewed [17], [18], [19] and compared with public efforts thus far by the Australian Submarine Program to shape \nsovereign industry involvement. SOVEREIGN TESTINGIV.\nSovereign Testing essentially introduces the broader concept of Knowledge Sovereignty, which may be considered as:\nThe independent authority of a state without interference from outside sources or bodies to abduce, conceive, \ndeduce, design, induce, devise new ontologies and transfer info-technological skills, understanding, comprehension, \nexpertise, proficiency, capacity, capability, learning, science and wisdom for its own socio-ethical purposes. [20]\nCritically Sovereign Testing connects with Knowledge Transfer as part of Knowledge Sovereignty; as distinct from but clearly connected with Sovereign Intellectual Property and Sovereign Capability:\nKnowledge Transfer goes beyond the translation of technical manuals from the French into Australian Books of \nReference (ABRs) and engineering / data sheets. Without it there is no point to building in Australia. Without a \nsovereign capability over the asset, even the ability to support and maintain the programme is in jeopardy. The \nmore so given the added risk in replacing the existing nuclear propulsion system Without understanding the socio-\ncultural context in which the submarine was abduced, abstracted, conceptualised, deduced, designed, induced, \nmodelled, built and operationalised, it will not be possible to de-risk Knowledge Transfer, or to successfully \ntranslate and sustain, build and maintain its operations in the Australian context. [21]\nKnowledge Transfer is essentially a quantum phenomenon; connecting past, present and future with the indivisible knowledge that is both socio and info-technological [22]. In this respect, programs need to consider the impact of \ncyber as synthesising and combining both socio and info-technological systems and being: A technologically bounded, largely immeasurable, strongly scientific, stochastic control space; comprising virtual-\nmedia and the display of data dealing with the real communication of [historical] facts and the conceptualization of \nother plausible possibilities, themselves capable of generating strong physical and weaker more social effects and \ninfluencing them . [23]\nIn 2016 the Australian Chief of Navy and his Submarine Project Director committed to the necessary submarine land-based test sites that would commence build in South Australia in 2018 and complete in 2019 [24], [25]. Moreover, \nVice Admiral Tim Barrett [24] outlined that a rolling build philosophy has been identified as a keystone of this \nprogram [that] will ensure the regional superiority we pursue can be attained and endure. The importance of these \nland-based test sites to informed decisions and thus governance on the Australian Submarine Program has been covered \n[4], [26]. For example, the broad aim of the Submarine Program used by Bradley et al. [26] to illustrate a complex \nsystems governance model for the Australian Program is similar to Barretts [24] and it reiterates the key strategic role \nthese test sites have in areas like sovereignty, early public confidence, evolving to meet new threats including \ncybersecurity, and ultimately avoiding another imported design for Australia in about 40 years from now: To maintain political, military and public trust that the FSM capability is continually evolving to meet the maritime \nthreat with adequate efficiency. (p. 6) The cybersecurity lessons learned in the U.S. [27] need not be relearned by Australia. Early, strategic investment in \nsecurity systems engineering and cybersecurity test and evaluation improve program cost, schedule and performance. \nConversely, failure to make those investments has adverse programmatic and mission impacts. The proposed land-based test sites align the Australian submarine program with best practice (i.e. [4], [16],[27-30] ), \nAustralian DoD test policy [31], [32] and the lessons learned from the Collins program [5], [6]. A risk with any delays \nin test capability is that the foreign designers and builders may soon hold technical sway over knowledge transfer and \nso project direction, and it may suit their commercial purposes for such test sites to be deferred, so foreign sites retain \nknowledge sovereignty. Such an outcome risks seriously impairing a sovereign testing capability and would almost 3 certainly lead to difficulties in knowledge transfer. It may also lead to the Australian DoD giving further deference \nessentially creating a colonial mindset so as to avoid political sensitivity. For example, difficulties in Knowledge \nTransfer for sovereign testing occurred on a previous foreign project in the Mu90 Lightweight Torpedo. The Torpedo \nwas mistakenly thought to be off-the-shelf (2000-2004); yet took some 13 years to get properly tested for operational \nrelease. The last seven years of which occurred after full commitment to all production and delivery of Australian DoD \nwar-stock [33], [34]. Independence in test and evaluation is crucial in factual results being equally available unfettered to investors, \ntechnical authorities and operational managers. Unfettered sovereign test results have been shown in Australian \nParliamentary evidence and audit reports to have been essential
in hindsight [35] both as part of Defence market testing \nand acceptance into initial service. If major capabilities outsource conduct of developmental and acceptance testing, \nsafety assessments, usability trials and operating procedures to a contractor without adequate residential project staff \nand representative operators present, then the transfer of risk and delay in resolving risk is contrary to the very intent of \nthe project in giving these tasks to the contractor in the first place [5], [28], [32]. If the French Naval Group undertake significant portions of Australias submarine systems virtual, constructive and \nlive simulation testing in France, significant Knowledge Transfer issues will make the flow of test results much harder. \nSimilarly, if Lockheed Martin undertake the simulation testing of their submarine systems in the U.S., there are risks to \ntest results making it unfettered to the stakeholders, especially if they were to use proprietary simulation models that \nhave not been accredited by the U.S. and/or Australian DoD(s). Constraints on travel budgets hampered representation \nof operators and technical experts on Australias Landing Helicopter Dock ship during safety and usability assessments \nand that program only involved travel within Australia [32], [35], much less than would be the case for Cherbourg, \nFrance and Rhode Island, U.S.. Cybersecurity assessments for cooperative vulnerability and penetration testing further \nchallenge outsourcing of such work without close cooperation between the DoD and contractors [29], [36]. Work by \nFowler et al. [37] shows there are extant Australian DoD practices like systems safety that can be leveraged to \ncooperate with industry in independent cybersecurity, provided these practices are being followed and not overly \noutsourced. Also, Joiner and Tutty [16] outline U.S. DoD initiatives to efficiently manage independent cybersecurity \ntesting through distributed simulation, experimentation exercises and through the test network infrastructure on which \nthese are based. For Australias Submarine Program, representative land-based test sites across all submarine systems should be \nin Australia and under Australian DoD control as soon as possible if the design work is to be successfully exported in \nan enduring way, enable knowledge sovereignty and provide for timely and informed decision making and taking [38]. \nSuch test sites should significantly de-risk any such submarine program by helping to maintain public support, and \nenabling fully representative technical and operational participation throughout the rolling complex software-intensive \nsystems development in safety, usability [39], reliability, maintainability, availability and cybersecurity assessments. \nCybersecurity has traditionally been considered as one of the ilities with tests focussed on mandatory compliance and \nresponses to incidents during the operational phase of land-based tests, mostly as a reactive process, rather than for \ndeveloping social trusts and assurances. Perspectives on how to build security in can establish a common language to \nuse in designing the software-intensive systems, thus making risk trade-offs throughout projects acquisition lifecycles, \nminimizing the number of systems vulnerabilities, and reducing time for land-based tests. Moreover, early investment \nin representative land-based sites can be expected to add some up-front cost to the submarine program because they \nentail high fidelity virtual and bench-level representations of the submarine systems in progressive upgrade ahead of all \nfuture boats. As observed by the U.S DOD [27], the return on investment in test infrastructure can drive down acquisition costs, \nbecause the technical debt, typically incurred because of flawed engineering and deferred testing, can be dramatically \nreduced. Sovereign controlled land-based test sites will have additional workforce and National Security benefits. Land-\nbased test infrastructure should provide fertile ground to grow and enhance local cybersecurity workforce. From a \nNational Security perspective, this infrastructure would enable countries adopt agile, iterative and incremental \nacquisition and testing approaches that ultimately enhance their sovereign ability to keep pace with adversaries in \ncyberspace. Despite these lessons learned, land-based test sites like those in Australia are likely to face enormous pressure to be \nscaled back, as they did on the Collins Program, in favour of foreign test sites and the actual build. Such pressure is \nlikely to be a system-by-system argument, where for example, propulsion and power systems may get an Australian test \nsite, but sonar, weapons, combat and communication systems remain foreign. Any such parsing of the submarine 4 systems puts enormous risk on the higher-order aim of any submarine program, on the actual submarines to resolve \noperational and technical issues in-build and in-the-water rather than beforehand, and to become truly sovereign \ncapabilities. In developing land-based test sites to enable live, virtual and constructive distributed simulations [16], it is \ncrucial that the simulations are accredited for intended use, as is required in the U.S. Do D [40]. While such \naccreditation seems a significant non-recurring expense, if the complex adaptive software elements and \ninterconnectedness of the submarine exhibits emergent properties, as many modern defence systems are, then the quid \npro quo of the test sites will be the wherewithal to begin software verification much earlier and continue that into life as \ndetailed by Hecht [41], Normann [42] , and Cofer [43]. CYBER WARFARE THREAT AND OPPORTUNITYV.\nCyber is becoming the cheap first-strike weapon of political choice by potential adversaries in a kind of merging of insurgency, terrorism, international crime and state-based influences [44]. The merging of electronic warfare and cyber-\nwarfare means that no platform, however unconnected or firewalled it may be, is immune to probing within its systems \n[14], [19]. A future submarine must not only survive and be credible in this Information Age, but actually ought to be a \npotential purveyor of offensive cyber like that described by the Australian Prime Minister [12], so that it remains a \ncontemporary deterrence. Cyber first and foremost is connected to the socio, meaning interfering with the socio-functioning of the system, for \nexample by cyber-attacks, creating an instability in the synthetic ecology which interferes with the human psyche; \ncreating further instability and uncertainty [22]. Sovereign Testing of the entire quantum attack surface is therefore \nfundamental to Knowledge Transfer and cybersecurity, without which countries like Australia would not have \nKnowledge Sovereignty over their future submarine. Cyber-power is relatively cheap, available and largely anonymous, such that it is attractive for peacetime as it is for \nwar [45], especially for deterrence by smaller powers in the Asia-Pacific region [44]. These attributes also make cyber-\npower attractive to non-state actors [13], [46] such as cyber criminals, terrorists, hackers, and proxy actors engaged or \nsupported by numerous foreign governments [44, p.126], [47, p.5]. Heinl [44] forecasts that within a few years most \nstates in the Asia-Pacific will develop some form of offensive cyber program , most of whom are also pursuing \nsubmarine capabilities for deterrence [48]. Few Indo-Pacific countries pursuing these two defence capabilities are likely \nto have examined the risk of cyber warfare to their new submarine capabilities because it is a delicate and futuristic \nbalance of defensive and offensive new technologies [48]. While Australia often relies on deterrence by alliances, kinetic military power like that referred to by Hashim [49] \ncan be unusable in cyber warfare because attribution is slow and difficult [50], [51], [52], cyber-effects are hard to \ncontain, and the adversaries may be globally dispersed [53]. For Australias major military platforms like the future \nsubmarine, which are intended to operate throughout the Asia-Pacific region, they are likely to be a cyber-warfare target \nstarting from the first supply of software-intensive componentry for the test sites. The quantum attack surface for such \nsubmarine programs are likely to be defined throughout their entire life by resupplies and software updates and every \ncontractor and subcontractor with access. Defence acquisitions have sought to reduce costs and risks while improving interoperability for coalitions by \nutilising commercial components, especially computer components and software applications. As such, most defence \nplatforms probably have a larger cyber-attack surface than they realise [18]. The increased use of commercial hardware \nand software to perform essential functions for mission critical systems is likely to have increased the vulnerability of \ncountries like Australia to cyber-threats. Commercial components can be exposed to supply chain attacks as well as \nmalicious tampering. Because re-use of commercial hardware and software is encouraged by international standards for \ninteroperability [16], [54], [55], vulnerabilities are even more-likely to be discovered at some stage. Weapons Systems \nwhich use commercial hardware and software are extensively interconnected with other platforms [17], which increases \nthe quantum attack surface and cyber risks. Improving the dynamic (as in continuous and ongoing) cyber-resilience of defence platforms has three main threads \nidentifiable from the U.S. DoD: improved security systems engineering and cybersecurity test and evaluation so as to design and build in cyber-\nresiliency [14], [15] [27], [29]; trusted cyber supply chains as covered in the next section of this paper [17], [19]; and 5 trusted cyber-security modules or other resident cyber-threat adaptive sub-systems [19], [37].\nTrusted cyber-threat adaptive modules have been the subject of recent review by the U.S. DoDs Defense Science Board [19], as these offer the ability to preserve cost-effective use of commercial off-the-shelf componentry but \nmonitor and correct the use of such componentry with Defence-only add-ins to the architecture. The Boards proposal is \nas follows (p. 93): Further work remains in optimizing methods for hardware- and software-based integrity validation, autonomous \nassessment of subsystem compromise, and
autonomous adaptation, including the restoration or shutdown of \nsubsystems. It may be useful to develop so-called trusted sidecar modules that can easily integrate with various \nvehicle platforms under meaningful size, weight, and power constraints. These modules could execute out-of-band \nsystem-integrity assessments as well as host and restore the known good subsystem images. Such sidecars could also \nhold slight variations in subsystem images, to increase the likelihood of resistance to any specific attack. As well, a \nsidecar architecture could facilitate between-mission updates. Autonomous systems, especially those unable to \ncommunicate with humans, require the ability to defend themselves autonomously. Even for autonomous subsystems \nthat are components of larger systems with humans in the loop, the timescale required to respond to cyber-attack can \nbe far too short to allow human involvement. CYBERSECURITY ACQUISITION AND TEST PLANNING FOR SUBMARINESVI.\nThe U.S. DoDs revised acquisition policy with cybersecurity integrated was issued in January 2015 and is comprehensive [29], [30]. The policy is underpinned by a clear and comprehensive Cybersecurity T&E Guide [56] that \nis readily available on-line. According to Joiner and Tutty [16], the early heart of the process for developing projects \nor project proposals is the Program Protection Plan, which links the traditional efforts in security, requirements and \nT&E with the new cybersecurity assurance requirements and activities. A program protection plan is normally a \nrequirement of the U.S. DoD prior to market testing and design development, since it assesses the criticality of each of \nthe systems, assigns security levels and then guides the necessary levels of cybersecurity assessment of the industry \nbeing solicited for the design [29], [56]. The types of tasks necessary to recover cybersecurity planning for the \nAustralian submarine program were illustrated at [1] and they are necessary precursors to cybersecurity verification \nplanning and to all land-based test sites and design costings. Use of the U.S. DoD guidebook for such planning is \nwarranted not only because it is best practice, but because the U.S. combat system being designed into the Australian \nsubmarine warrants the same protections it would in the U.S. DoD. The US DoD has been implementing this approach for cybersecurity test and evaluation for some time. There are \nmany lessons learned based upon cybersecurity testing accomplished at the National Cyber Range (NCR) [27]. The \nNCR provisions representative cybersecurity test infrastructure, similar to what should be needed by Australia, to \ndeliver testing as a service to meet customer requirements. Each test event provides actionable recommendations for \nhardening information technology and weapon systems and improving operational tactics, techniques, and procedures. \nKey lessons learned from NCR testing include [27]: Start small and grow.\n Cybersecurity testing is an important engineering and design tool. \n The cyber table top exercise is an effective tool to understand mission risks and prioritize testing.\n Focus cybersecurity testing on the mission.\n Cybersecurity testing must be executed with key information technology staff, incident responders, network defenders, and cyber-protection teams. \nThe processes in the U.S. DoD Cybersecurity T&E Guidebook [56] are only intended for the DoD level. Much work has been done by the International Council of Systems Engineers (INCOSE) to produce an industry standard for \nsecurity systems engineering, now published as NIST 800-160 [57]. This standard embodies cybersecurity and \ninterleaves it with standard system engineering practices [58]. The recent work by Nejib et al. [58] to produce a \nrelatively simple industry matrix of cybersecurity planning and activities against standard system engineering practices \nhas further simplified the task for DoDs to set statements of work when contracting and for major Defence primes to \ninculcate and be readily compliant with U.S. DoD cybersecurity processes. This recent cybersecurity matrix framework \nand the NIST 800-160 standard are recommended for any submarine program [57, 58]. 6 TRUSTED CYBER SUPPLY CHAINS AND ANTI-TAMPER FOR SUBMARINESVII.\nCybersecurity craft in the U.S. has found that the most critical of Defense systems, like submarines, nuclear weapons and space surveillance, require to be trusted systems, meaning that their computer and software components, \napplications and architectures need to be designed, assembled, tested and refreshed using personnel, companies and \nprocedures that are, and remain, highly-trusted suppliers [19]. Trust in this regard moves beyond a tick-box, \ninformation technology, rule-based approach and introduces notions such as assurance and shared awareness, necessary \nto enable srte, more than commodified (often privatised) notions of security. This returns to Knowledge Sovereignty, \nin which Trust (as distinct from blind faith) may be: A function of the Likelihood of a person or system being able to comprehend, explain, understand by logic \n(where understanding by logic can be described as Intelligibility, taken to be a function of comprehension: \nexplainable and understandable by logic) and deal with a set of outcomes or events, or: Trust is a function of the Likelihood of a person or system being able to intelligibly deal with a set of \noutcomes or events. [59] In addition the U.S. DOD Program Protection Planning Guidance includes the requirement to plan for and \nimplement software assurance, anti-tamper and manage supply chain risks for critical components. Australia has a \nprecious few chip, processor, board and software manufacturers for their Defence Industry, all who should be key for \ntheir future submarine, including for the test sites. The Australian DoD has outsourced most of its repair and \nmaintenance to a cost-effective hub and spoke acquisition and sustainment model [60]. Unfortunately, this model \nprovides an increase in the quantum attack surface of Defence materiel, since according to Ferguson [60] the lower \ndown the supply chain the sub-contractor is, the less it is directly affected by Defence s policy and processes. \nAccording to Alberts et al. [17], while supplier, vendor, and contracts relationships provide cost savings and flexibility \nto the DoD, they also come with risk. With cybersecurity, one-off assessments of suppliers of software-intensive \ncomponentry and applications is no longer adequate and the assurance cost will be in perpetuity of the componentry and \napplication use, since the vulnerability against continuously emerging threats mean an assured system and supplier of \ntoday is vulnerable tomorrow. Some strong policies exist on people, processes and technology used on Australian DoD \ninformation technology networks, however software-intensive platforms and capabilities that are not information \ntechnology networks have no similar controls [61], [62]. All acquisitions need to have cyber planning resources \navailable, such as experts in cyber vulnerability assessments and penetration testing , with the necessary test \ninfrastructure to do threat-representative evaluations through virtual, constructive and then live systems design and \nsimulation. The need for such expertise and test infrastructure is more important for something as developmentally \ncomplex as a future submarine re-design, especially when such submarines will deploy into international waters where \nthey are highly likely to be exposed to cyber threats aimed at cheaply limiting their deterrent value. Earlier it was noted there was no public evidence yet of the necessary industry engagement in Australia to establish \ncyber-trusted supply chains, certainly for the imminent submarine test sites. The Australian DoD may need to urgently, \nassuredly (on the bases of trust development) and systematically scrutinise cybersecurity protections resident in its \nforeign designers and builders. This would involve providing DoD strategic cybersecurity requirements and acquisition \nstrategy to address anti-tamper and supply-chain risk management options in the redesigns all of which is also \nfundamental to enabling Knowledge Transfer and establishing Knowledge Sovereignty over the future submarine. \nForeign contractors are unlikely to be commercially motivated to adjust extant supply chains, or subject them to new \nscrutiny, in order to establish a robust and independent cybersecurity test framework for countries like Australia. They \nshould not therefore be given untested and unfettered technical deference to Knowledge Sovereignty in this key future \nthreat area before trusts are established. RECOMMENDATIONSVIII.\nBased on the case study of the Australian Submarine Program and the U.S. DoD best practice, any submarine program \nallied to the U.S. should consider: \n Provisioning representative land-based test sites across all submarine systems to be established sovereignly as \nsoon as possible so as to successfully export design work in an enduring way and so as to enable Knowledge \nSovereignty and timely and informed decisions on the program. \n Automating land-based test sites to create efficiencies in submarine development, deployment, and \nredeployment. 7 Using test sites to significantly de-risk the submarine program by helping to build trust, maintain public \nsupport, and enabling fully-representative technical and operational participation throughout the rolling development \nin safety, usability, srte, cybersecurity, reliability, maintainability and availability assessments.\n Using test sites to also improve overall cost schedule and performance and position the ally for long term \nsustainment. \n Applying the U.S. acquisition guidebooks for cybersecurity as these protections are apropos to any U.S. DoD \nsystems being used and they represent best practice. \n Including targeted sovereign information technology industry in the cybersecurity acquisition strategy.\n Exploiting cybersecurity testing as a continuous engineering design tool to improve and retain cyber \nresilience.\n Executing cyber table top exercises as a tool to understand mission risks and prioritize testing.\n Using the recently developed industry cybersecurity matrix framework and the NIST 800-160 standard for all \nthe supply chain options as a fundamental requirement of integrating cybersecurity into the systems engineering.\n Linking new land-based
test facilities and laboratories, wherever they are, to the U.S. test and evaluation \nnetworks or their equivalents, with appropriate training and assurances so as to enable distributed live, virtual and \nconstructive experimentation and cybersecurity vulnerability assessments and penetration testing of every software-\nintensive system on the submarine to the latest cybersecurity threat levels.\n Using linked and distributed test facilities to enable agile development and test, so the ally can reduce \ndevelopment, test, operations and sustainment costs and stay ahead of cyber adversaries.\n Undertake Quantum Network Mapping (the subject of ongoing research by Authors one and two) of each \nsubmarines unique cyber-attack surface.\n Obtaining independent review by cybersecurity and test professionals of all test concept strategies and plans. CONCLUSIONIX.\nAustralias Future Submarine Project illustrates the modern challenge of advancing a significant new complex deterrent while being resilient to new cyber warfare threats, and doing so without risking fundamental design rework \nand associated capability limitations. Key to any submarine development are land-based test sites and using them to \nattain and maintain cyber-resilience of the critical systems. A serious concern with any delays in such test capability is \nthat the foreign designer and builder can hold technical sway over Knowledge Transfer and project direction. It may \nsuit commercial purposes for such test sites to be deferred, so foreign sites pick up the slack. Such an outcome would \nseriously impair Knowledge Sovereignty, Knowledge Transfer and independent test capability in the difficulties of \nforeign release. Cyber is becoming the cheap first-strike weapon of choice by potential adversaries in a kind of merging of \ninsurgency, terrorism, international crime and state-based influences. The merging of electronic warfare and cyber-\nwarfare means not even submarines, however unconnected or firewalled they may be, are immune to probing of, and \ninterference with, its systems. Future submarines must not only survive and be credible in this Information Age, but \nactually ought to be a potential purveyor of offensive cyber if it is to be our contemporary deterrence. To do so, \nsubmarine systems have to respond dynamically to a quantum attack surface for its past designs, current builds, and \nfuture operations. Cybersecurity craft in the U.S. has found that the most critical of Defence systems, like submarines, \nnuclear weapons and space surveillance, require to be trusted systems, meaning that their computer and software \ncomponents, applications and architectures need to be designed, assembled, tested and refreshed using personnel, \ncompanies and procedures that are, and remain, highly-trusted suppliers. Moreover, recent work in the U.S. may enable \ntrusted sidecar cyber-threat adaptive embedded components to give greater cybersecurity assurance while retaining \ncost effective use of commercial computers and software. Some countries like Australia have precious few chip, processor, board and software manufacturers for Defence \nIndustry, all who should be key for sovereign resilience of a submarine program, including its test sites. The high-level \nrequirements of submarines need to have cyber-resilience as a key feature and then flow these through to the key \ncybersecurity plans like those usual in a U.S. project (i.e. Project Protection Plan). There needs to be sovereign industry \nengagement to establish cyber-trusted supply chains in time for the test sites and sovereign oversight of the \ncybersecurity of any foreign designers and builders, or otherwise these prime contractors will not be commercially \nmotivated to adjust extant supply chains, or subject them to new scrutiny, in order to provide for Knowledge Transfer \n(and so Knowledge Sovereignty) and to establish a robust, perennial and independent cybersecurity test framework. 8 Foreign contractors should not be given untested and unfettered technical deference in this key future threat area or \nexpensive new deterrent submarines risk being vulnerable to relative low-cost cyber warfare threats. ACKNOWLEDGMENT X.\nThe examination of the cybersecurity challenges and processes for the Australian Submarine Program was presented initially to the Australian Submarine Institutes annual conferences in 2017 [1] and the Institute has kindly agreed for \nthese aspects to be used herein for broader implications.This research was greatly assisted by a number of students \nundertaking postgraduate coursework in cybersecurity, in particular Mr Kenan Erem, Mr Thomas Coughlin, Mr \nChristopher Leedham and Ms Anne Coull. REFERENCESXI. Joiner, K. F.; Atkinson, S. R.; & Sitnikova, E., 2017. Cybersecurity Challenges and Processes for Australia s [1]\nFuture Submarine, Proceedings of the 4th Submarine Science, Technology and Engineering Conference, Adelaide, \nAustralia, pp. 166-174. Australian National Audit Office, 2016. Report No.48 201617, Performance Audit, Future [2]\nSubmarineCompetitive Evaluation Process. Canberra, ANAO. Stanford, J., 2017. Australias Future Submarine Getting This Key Capability Right. In: Jon Stanford (ed) Public [3]\nPolicy Report to Submarines for Australia. Canberra: Insight Economics Pty. Ltd., public policy report, Insight \nEconomics Pty Ltd, September. Joiner, K. F. & Atkinson, S.R., 2016. Australias Future Submarine: Shaping Early Adaptive Designs through [4]\nTest and Evaluation. Australian Journal of Multi-Disciplinary Engineering, Engineers Australia, pp. 1-23, DOI: \n10.1 .2 . Australian National Audit Office (ANAO), 2002. Audit Report No. 30: 200102 Test and Evaluation of Major [5]\nDefence Equipment Acquisitions, Canberra, ANAO RAND Corporation, 2011. Learning from Experience, Volume IV Lessons from Australia s Collins Class [6]\nSubmarine Program. Santa Monica, CA: RAND Corporation on Behalf of Australian Department of Defence. \nwww.dtic.mil/dtic/tr/fulltext/u2/a552686.pdf. Stewart, C., 2016. Our French submarine builder in massive leak scandal, The Australian Newspaper, 29 [7]\nAugust, available http://www.theaustralian.com.au/national-affairs/defence/our-french-submarine-builder-in-\nmassive-leak-scandal/news-story/3fe0d25b7733873c44aaa0a4d42db39e. Keany, F., 2016. French shipbuilder DCNS learned of submarine breach via the media, Pyne accuses Xenophon [8]\nstaffer of leak. ABC News, 15th December, available http://www.abc.net.au/news/2016-12-15/submarine-french-\ncompany-unaware-of-breach-until-media-reports/8122548 Austin, G. (2016). Australia rearmed! Future needs for cyber-enabled warfare. Discussion Paper No. 1 of the [9]\nAustralian Centre for Cyber Security at University of New South Wales, Canberra, released publically on 19 \nJanuary 2016. Retrieved from https://www.unsw.adfa.edu.au/australiancentre-for-cyber-security/news/australia-\nrearmed Fitsanakis, J., 2013, Chinese hackers stole blueprints of Australian spy agencies new HQ. Intelnews, 28 May, [10]\navailable https://intelnews.org/2013/05/28/01-1267/. Grubb, B., 2013. Blueprints for new ASIO headquarters stolen , The Sydney Morning Herald, May 28, [11]\navailable http://www.smh.com.au/it-pro/security-it/blueprints-for-new-asio-headquarters-stolen-20130527-\n2n7kz.html. Pearce, R., 2016. Cyber deterrant: PM talks up Australia s offensive capabilities. Computerworld, [12]\nhttps://www.computerworld.com.au/article/598443. http://www.dtic.mil/dtic/tr/fulltext/u2/a552686.pdf\nhttp://www.theaustralian.com.au/national-affairs/defence/our-french-submarine-builder-in-massive-leak-scandal/news-story/3fe0d25b7733873c44aaa0a4d42db39e\nhttp://www.theaustralian.com.au/national-affairs/defence/our-french-submarine-builder-in-massive-leak-scandal/news-story/3fe0d25b7733873c44aaa0a4d42db39e\nhttp://www.abc.net.au/news/2016-12-15/submarine-french-company-unaware-of-breach-until-media-reports/8122548\nhttp://www.abc.net.au/news/2016-12-15/submarine-french-company-unaware-of-breach-until-media-reports/8122548\nhttps://www.unsw.adfa.edu.au/australiancentre-for-cyber-security/news/australia-rearmed\nhttps://www.unsw.adfa.edu.au/australiancentre-for-cyber-security/news/australia-rearmed\nhttps://intelnews.org/2013/05/28/01-1267/\nhttp://www.smh.com.au/it-pro/security-it/blueprints-for-new-asio-headquarters-stolen-20130527-2n7kz.html\nhttp://www.smh.com.au/it-pro/security-it/blueprints-for-new-asio-headquarters-stolen-20130527-2n7kz.html\nhttps://www.computerworld.com.au/article/598443 9 Australian DoD, 2016. Defence White Paper 2016. p. 50 & pp. 81-82 www.defence.gov.au.[13] Joiner, K., 2017. How Australia can catch up to U.S. cyber resilience by understanding that cyber survivability [14]\ntest and evaluation drives defense investment, Information Security Journal: A Global Perspective, Vol. 26, Issue \n2, 2017 Joiner, K., Sitnikova, E., and Tutty, M.G., 2016. Structuring defence cyber-survivability T&E to research best [15]\npractice in cyber-resilient systems, paper presented at Systems Engineering Test and Evaluation Conference, \nMelbourne. Joiner, K. F. & Tutty, M. G., 201 8 (accepted) A tale of two allied Defence Departments: New assurance [16]\ninitiatives for managing increasing system complexity, interconnectedness, and vulnerability Australian Journal \nof Multi-Disciplinary Engineering, Engineers Australia. Alberts, C.; Haller, J.; Wallen, C.; Woody, C., 2017. Assessing DoD System Acquisition Supply Chain Risk [17]\nManagement, CrossTalk, 30(3), pp. 4-8. U.S. Defense Acquisition University (DAU), 2016. The Road Ahead for Defence Acquisition, available [18]\nhttp://dau.dodlive.mil/2016/04/18/cybersecurity-the-road-ahead-for-defense-acquisition/. U.S. DoD Defense Science Board (DSB), 2016. Summer Study on Autonomy, June, pp.28-30, [viewed 24 Aug [19]\n2017] https://www.hsdl.org/?view&did=794641. Reay Atkinson, S., and J. J., Bogais. Socio-Ethics to Critical Thinking. in Royal Australian Navy Fleet Air Arm [20]\nTactical Forum 24 Aug. 2017. HMAS Albatross, Nowra, NSW: SARN. Reay Atkinson S., J.J., Bogais, & R. MacLeod, Future Submarine Systems and Cultural Awareness Systems Brief. [21]\nCISS Think Piece., 2016. Dated 2 Sep 2016. Reay Atkinson, S., and J. J., Bogais. Quantum AI Future Imperfect? in Data Centre Dynamics (DCD) [22]\nConverged, 27 Jun. 2017. International Convention Centre, Sydney: SARN. Reay Atkinson, S., Cyber-: Envisaging New Frontiers of Possibility. UKDA Advanced Research & Assessmnent [23]\nGroup, 2009. Occasional Series, 03/09. Barrett, T., 2016. An expanded submarine fleet: Meeting the challenges, Chief of Navy Address to the 8th [24]\nBiennial Conference of the Submarine Institute of Australia, 15 November, Shine Dome, Canberra Sammut, G., 2016. The Future Submarine Program, slide 11, Head of Future Submarine Program address to the [25]\n8th Biennial Conference of the Submarine Institute of Australia, 15 November, Shine Dome, Canberra Bradley, J. M.; Joiner, K. F.; Efatmaneshnik, M.; Keating, C. B., 2017. Evaluating Australia s most complex [26]\nsystem-of-systems, the future submarine: A case for using new Complex Systems Governance, proceedings 27th \nAnnual INCOSE International Symposium (IS 2017), Adelaide, Australia, July 15-20. Christensen, P., 2017. Cybersecurity Test and Evaluation: A Look Back, Some Lessons Learned, and a Look [27]\nForward! ITEA Journal, Vol 38 #3, 221228. Australian Senate, (2012). Senate Inquiry into Defence Procurement., Chapter 12, Canberra: Australian [28]\nParliament House. Brown, C., Christensen, P., McNeil, J., & Messerschmidt, L., 2015. Using the developmental evaluation [29]\nframework to right size cyber T Woody C.C; Cyber Security Engineering: A Practitional Approach for Systems and Software [30]\nAssurance , 2017 Pearson Education, ISBN-13:970-0-134-18980. Joiner, K. F. 2015. How New Test and Evaluation Policy is Being Used to De-risk Project Approvals through [31]\nPreview T 36, pp. 288-297 Australian National Audit Office, 2015. Report No. 9 201516: Test and Evaluation of Major Defence Equipment [32]\nAcquisitions. Canberra: ANAO. http://www.defence.gov.au\nhttps://www.hsdl.org/?view&did=794641 10 Australian National Audit Office, 2010. Report No. 37 2009-10: Lightweight Torpedo Replacement Project [33]\nDepartment of Defence. Canberra: ANAO. Australian National Audit Office, 2013. Report No. 26 2012-13: Remediation of Lightweight Torpedo [34]\nReplacement Project. Canberra: ANAO. Australian Parliament, 2016. Joint Parliamentary Committee for Accounts and Audit (JCPAA) hearing with
[35]\nDefence and the Australian National Audit Office, accessed on 3 March 2016 at \nhttp://www.aph.gov.au/Parliamentary_Business/Committees/Joint/Public_Accounts_and_Audit/Reports_Nos_52_\n3_an d_9 with video viewed at \nhttp://parlview.aph.gov.au/mediaPlayer.php?videoID=296010 Staples, M.; & Nguyen, T., 2014. The need for software architecture evaluation in the acquisition of [36]\nsoftware-intensive systems. Fishermans Bend: Aerospace Division, Defence Science and Technology \nOrganisation. Fowler, S.; Sweetman, C.; Ravindran, S.; Joiner, K. F.; & Sitnikova, E., 2017. Developing cyber-security policies [37]\nthat penetrate Australian defence acquisitions, Australian Defence Force Journal, Issue 202, July. Reay Atkinson, S., A., Vakarau Levula, N.H.M., Caldwell, R.T.,Wigand, L., Hossain, Signalling Decision Making [38]\nand Taking in a Complex World, in International Conference on Information Technology and Management \nScience (ICITMS 2014), 1-2 May. 2014, WIT Transactions on Engineering Sciences Hong Kong. Wickens, C. D.; J. Lee; Y. Liu; & S. D. Becker. 2014. An Introduction to Human Factors Engineering. 2nd Ed. [39]\nNew York: Pearson Prentice Hall. Elele, J. N.; Hall, D. H.; Davis, M. E.; Turner, D.; Faird, A.; & Madry, J., 2016. M&S Requirements and VV&A [40]\nRequirements: Whats the Relationship? ITEA Journal, 37, pp. 333-341. Hecht, M. 2015. Verification of software intensive system reliability and availability through testing and [41]\nmodeling, ITEA Journal, 36, pp. 304-312. Normann, B., 2015. Continuous system monitoring as a test tool for complex systems of systems, ITEA Journal, [42]\n36, pp. 298-303. Cofer, D., 2015. Taming the complexity beast, ITEA Journal, 36, pp. 313-318.[43] Heinl, C.H., 2016. The Potential Military Impact of Emerging Technologies in the Asia-Pacific Region: A focus [44]\non cyber capabilities, in Emerging Critical Technologies and Security in the Asia-Pacific, R.A. Bitzinger, Editor, \nPalgrave Macmillan: Hampshire, UK. Sheldon, J. B., 2012. Toward a theory of cyber power: Strategic purpose in peace and war, chapter in Reveron, [45]\nD. S. editor, p. 212, 2012. Cyberspace and national security threats, opportunities, and power in a virtual world, \nGeorgetown University Press, Washington, DC. Reveron, D. S. editor, 2012. Cyberspace and national security threats, opportunities, and power in a virtual world, [46]\nGeorgetown University Press, Washington, DC. RAND Corporation, 2015. Perspective on 2015 DoD Cyber Strategy, September, available www.dtic.mil/get-tr-[47]\ndoc/pdf?AD=ADA621794. Bitzinger, R. A. editor, 2016. Emerging Critical Technologies and Security in the Asia Pacific, Pallgrave [48]\nMacmillan, Hampshire, U.K., pp. 37-62 & 91-106. Hashim, A., 2013, Warfare in New Domains: The Future of Asymmetric Operations and Information Warfare, [49]\n15th Asia Pacific Programme for Senior Military OfficersThe Future of War, RSIS Singapore, 5 August. Adres, R. B., 2012. The emerging structure of strategic cyber offense, cyber defense, and cyber deterrence, p. 92 [50]\nchapter in Reveron, D.S. editor, 2012. Cyberspace and national security threats, opportunities, and power in a \nvirtual world, Georgetown Uni Press, Washington, DC. http://parlview.aph.gov.au/mediaPlayer.php?videoID=296010&operation_mode=parlview\nhttp://www.dtic.mil/get-tr-doc/pdf?AD=ADA621794\nhttp://www.dtic.mil/get-tr-doc/pdf?AD=ADA621794 11 Fidler, D. P., 2012. Inter arma silent leges Redux? The Law of Armed Conflict and Cyber Conflict, p.76, chapter [51]\nin Reveron, D. S. editor, 2012. Cyberspace and national security threats, opportunities, and power in a virtual \nworld, Georgetown University Press, Washington, DC. Geers, K.; Kindlund, D.; Moran, N.; Rachwald, R., 2017. World War C: Understanding Nation-State Motives [52]\nBehind Today s Advanced Cyber Attacks, Fireeye Corporation, available \nhttps://www.fireeye.com/content/dam/fireeye-www/global/en/current-threats/pdfs/fireeye-wwc-report.pdf. Demchak, C., 2012. Cybered conflict, cyber power, and security resilience as a strategy, p. 120, chapter in [53]\nReveron, D. S. editor, 2012. Cyberspace and national security threats, opportunities, and power in a virtual world, \nGeorgetown University Press, Washington, DC. Hardung, B.; Kozlow, T.; Kruger, A., 2004. Reuse of software in distributed embedded automotive systems. [54]\nProceedings of the 4th ACM international conference on embedded software, ACM, pp. 203-210. Pretschner, A.; Broy, M.; Kruger, I. H.; Stauner, T., 2007. Software engineering for automotive systems: A [55]\nroadmap, Future of Software Engineering, IEEE Computer Society, pp. 55-71. U.S. DoD, 2015. Cybersecurity T McEvilley, M.; & Oren, J. C., 2016. NIST Special Publication 800-160, Systems Security Engineering [57]\nConsiderations for a Multidisciplinary Approach in the Engineering of Trustworthy Secure Systems, U.S. \nDepartment of Commerce, available http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-160.pdf Nejib, P.; Beyer, D.; & Yakabovicz, E., 2017. Systems Security Engineering: What Every System Engineer [58]\nNeeds to Know, 27th Annual INCOSE International Symposium (IS 2017), Adelaide, Australia, July 15-20. Reay Atkinson, S., A.M., Maier, N.H.M., Caldwell, & P.J., Clarkson., Collaborative trust networks in engineering [59]\ndesign adaptation, in International Conference of Engineering Design, ICED11. 2011: Technical University of \nDenmark, Lyngby. Ferguson, G., 2012. Product innovation success in the Australian defence industry an exploratory study, The [60]\nUniversity of Adelaide, available \nhttps://digital.library.adelaide.edu.au/dspace/bitstream/2440/79198/8/02whole.pdf. Australian DoD, 2017a. Defence Procurement Policy Manual, available at [61]\nhttp://www.defence.gov.au/casg/multimedia/DPPM_(4_May_2017-9-7937.pdf. Australian DoD, 2017b. Defence Security Manual, available at [62]\nhttp://www.defence.gov.au/DSVS/resources/DSM/PUBLIC%20%DSM%20Part%201.0.pdf. BIOGRAPHYXII. Dr Keith Joiner, CSC, [Group Captain (Retd), PhD, MSc (Aerosystems), MMgmt, BEng(Aero), MIEAust, \nCPEng, MAIPM, CPPD] joined the Air Force in 1985 and became an aeronautical engineer, project manager and \nteacher over a 30-year career before joining the University of New South Wales in 2015 as a senior lecturer in test and \nevaluation. From 2010 to 2014 he was the Director-General of Test and Evaluation for the Australian Defence Force, \nwhere he was awarded a Conspicuous Service Cross. Associate Professor Simon Reay Atkinson [Captain RANR, PhD, MPhil, Eur Ing, CPEng, FIET] is an Australian \n(RAN Captain and associate professor at the University of Sydney, RN Retd), He served on the staffs of Generals Eric \nK. Shinseki and David Petraeus and was twice mentioned in despatches: Bosnia (19961997) and Sierra-Leone (2000). \nA weapons system engineer, he has an MPhil in International Relations (majoring in Law and Economics) and a PhD in \nEngineering Design Adaptation (in Complex Adaptive Systems), both from St Catherines College, Cambridge. Dr Elena Sitnikova [PhD, BE (Hons), CSSLP] is a researcher and academic within the Australian Centre for Cyber \nSecurity (ACCS) at the University of NSW at ADFA. Her main research interests are in critical infrastructure protection \nand cyber security, software and systems engineering, quality assurance and enterprise process capability improvement. https://www.fireeye.com/content/dam/fireeye-www/global/en/current-threats/pdfs/fireeye-wwc-report.pdf 12 Elena currently leads the critical infrastructure area, carrying out research projects in cyber security in Industrial \nInternet of Things (IIoT) and Intrusion Detection Systems (IDS) for SCADA and industrial control systems. Mr Peter H. Christensen, [U.S. Navy Commander, RET] assigned as an EA-6B Naval Flight Officer on the EA-6B \nProwler, electronic warfare aircraft in the U.S. Navy before retiring in 1995. Since then he has been employed by the \nMITRE Corporation and has served on Intergovernmental Personnel Assignment with the US DOD as Scientific \nAdvisor for the Marine Corps Operational Test and Evaluation Activity and more recently as the Director of the \nNational Cyber Range for the Test Resource Management Center. Pete is currently the cyber-lead for MITRE \nCorporation support to the U.S. Office of the Secretary of Defence Deputy Assistant Secretary of Defense for C3, \nCyber and Business Systems. Petes affiliation with The MITRE Corporation is provided for identification purposes \nonly, and is not intended to convey or imply MITRE's concurrence with, or support for, the positions, opinions, or \nviewpoints expressed by the author. Approved for Public Release; distribution Unlimited Case 18-0522 _top\n _Ref505674660\n _GoBack ",
    "text": " Thinking Outside the Boxes and Lines: Beyond Organizational Restructuring Thinking Outside the Boxes and Lines: Beyond \nOrganizational Restructuring MITRE Human & Organizational Systems 1 Toma, Andrew, Fabrice Roghe, Brad Noakes, Rainer Strack, Julie Kilmann, and Ralf Dicke. Flipping the Odds for Successful Reorganization. \nThe Boston Consulting Group, April 2012. During times of transition, leaders commonly look for ways to better deliver on an agencys mission. \nOften, a new leaders first instinct is to look critically at the organizations structure, believing that \nmoving organizational boxes and lines will improve results. However, changing an organizations \nstructure will not necessarily resolve organizational performance issues, particularly given the high rate \nof reorganization failure.1 New leaders can more effectively achieve sought-after results by considering \nthe broader system of organizational elements that impact performance. of the current organizational environment, both internal \nand external. By conducting a baseline organizational \nassessment leaders can better diagnose areas for needed \nimprovement and perhaps completely avoid the need for \na redesign. Before Moving Boxes: Understand the Current \nState of the Organization The Burke-Litwin Model (Figure 1) provides a proven \nframework to help organizations understand the By rushing the decision to restructure or restructuring \nwithout clear evidence that the structure is the problem, \nan organization risks lowering employee engagement, \nlosing mission critical skills, and interrupting essential ser-\nvice delivery. Moreover, an organization that restructures \nbefore assessing the myriad interrelated factors impacting \nperformance can obscure genuine, root cause problems \nand quickly generate new ones. Before undertaking an organizational restructuring effort, \nit is critical for new leaders to have a clear understanding Figure 1. Burke-Litwin Causal Model of Organizational Performance and Change Leadership Motivation Work Unit Climate Management Practices External \nEnvironment Individual and\nOrganizational\nPerformance Individual Needs and \nValuesTask and Individual Structure Mission and Strategy Systems (Policies and \nProcedures) Organizational Culture Boxes in the model indicate primary variables affecting organizational performance Higher level variables (in blue) have greater weight in affecting organizational change organizational and environmental variables that impact \nperformance and how these variables link to each other.3 The model allows leaders to take a systematic approach \nto evaluating the organization and managing the complex \nnature of change. The boxes in the model represent key \nvariables affecting organizational performance. Arrows \nindicate critical linkages between the variables. A change \nin any variable will ultimately affect every other variable. \nIdeally, an organization should strive to appropriately align \nthese variables to enhance organizational performance. Higher-level variablesMission and Strategy, Leadership \nand Organizational Cultureare considered transforma-\ntional. External environmental forces most directly affect \nthese variables, and improving these transformational \nvariables usually requires new behavior from organizational \nmembers. The lower, more operational and transactional \nvariables can be impacted by relatively short-term adjust-\nments in the workforce. Together, these transformational \nand transactional factors affect motivation, which, in turn, \naffects performance. Higher-level variables have greater \nweight in affecting organizational change. An organizational assessment using this model, conducted \nthrough a series of targeted interviews and focus groups \nwith internal and external stakeholders, provides leaders \nwith qualitative data regarding each of these causal \nfactors. By taking a more holistic view of the organization If an organizational restructuring is warranted after all If the results of an organizational assessment indicate \nthat restructuring will best help the organization deliver \non its mission, leaders should keep in mind the following \ncritical factors for successful redesign efforts: Obtain leadership commitment at each level of the\norganization impacted by the change; Ensure alignment of the organizations strategy with\nthe new organization design; Actively engage stakeholders impacted by the\ntransformation throughout the effort; Uphold transparency and objectivity in the redesign\nand implementation process; Allocate the necessary time and resources to\nimplement the new organization design; and Develop transition plans for the new organization\nstructure which accommodate and address varying\nlevels of change readiness. across all these variables, leaders can then identify the \nappropriate organizational factors to address to enhance \nperformance. After the Assessment: Alternatives to \nOrganizational Restructuring Assessment data often reveal that an organizations \nstructure is sound and other factors are the cause of poor \nperformance. For example, if an assessment reveals a \nnew or pressing organizational demand is causing internal \nstress, a leader can construct temporary structures or \nteams to address the issue while keeping the formal struc-\nture constant. Likewise, by looking across a set of primary \ntransactional variables of the model (Structure, Manage-\nment Practices and Systems), a leader may determine \nthat while the structure is sound, the true issue resides in \nintegrating mechanisms used by the organization. Inte-\ngrating mechanisms are the informal linkages that support \ncoordination and communication across the structural \nboundaries of an organizationthe wiring between the \nboxes on the organization chart and the networks at the \nheart of the organization. A comprehensive organizational assessment provides \nleaders insight into the myriad factors impacting the orga-\nnizations performance. With this data, leaders can better \ntarget the true cause of an organizations performance \ndeficiencies and develop corrective actions to address \nthose areas moving forward. For more information about MITREs Organizational Change Management capabilities, contact ESTTech@mitre.org Research demon strates that less than \n25% of organization restructuring efforts \nsucceed, with nearly one-third failing to \nmeet objectives or enhance per formance \nafter implementation.2 2 Aronowitz, Steven, Aaron De Smet, and Deirdre McGinty. Getting Organizational Redesign Right. McKinsey Quarterly 3 (2015): 98-109. 3 Burke, W. W. & Litwin, G. A causal model of organizational performance and change. Journal of Management, 1992, Vol. 18. ",
    "text": " Approved for Public Release; Distribution Unlimited. Case Number 18-0564 Mentoring Early Career Engineers Contributes to Antenna Advances (an \ninterview with Wajih Elsallal) What Wajih Elsallal truly enjoys is bringing early career engineers onto his MITRE \nprojects, presenting them with new challenges, and helping them learn. But to get \nto this position, he first had to challenge himself. As a high-school student in Saudi Arabia, Elsallal didnt do very well in physics his \nfirst trimester. But he was determined to succeed, so he applied himselfand \nearned the highest score in the class next trimester. \"Thats when I started to love electromagnetics and math,\" he said. He also began \nto work with some of the other students on an informal basis, tutoring them in math \nand physics. \"That process of mentoring people and teaching them motivated me to continue in \nthe path of electromagnetics and, eventually, antennas.\" Elsallal went on to earn a bachelors degree in petroleum and minerals at King Fahd \nUniversity in Dhahran, Saudi Arabia. He later completed his masters in electrical \nengineering at Georgia Tech, a doctorate in electrical engineering at the University \nof Massachusetts Amherst, and an MBA at the University of Iowa. He was selected \nas the best graduate teaching assistant at Georgia Tech. He began his career in the private sector developing communications systems for \nhand-held devices, and then phased arrays for research labs, aerospace companies, \nand U.S. government agencies. During that time, he built on his Ph.D. thesis about \nbalanced antipodal Vivaldi antennas to develop a new generation of the traditional \nVivaldi (tapered slots) antennas. Elsallal joined MITRE in 2013, in part because he wanted to be in an environment \nthat focused on research and innovation, addressed technical questions with a high \ndegree of objectivity, and solved the sponsors most challenging problems. He \ncontinues to specialize in wideband phased array developments and radar systems. He appreciates the fact that MITRE operates FFRDCsfederally funded research and \ndevelopment centersfor the U.S. government. This allows him to have the best of \nboth worlds. He also likes the corporate culture he observes at MITRE. \"Im surrounded by an excellent management team that empowers the employees \nand inspires themthey dont micromanage them. They give us all the support we \nneed to do our jobs.\" Developing the Next Generation of Antennas At MITRE, Elsallal has helped develop a new class of radiating elements for \nwideband phased array antennas for the Navy. Working with a team from the https://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/about/culture-of-knowledge-sharing\nhttps://www.mitre.org/about/culture-of-knowledge-sharing\nhttps://www.mitre.org/about/culture-of-knowledge-sharing\nhttps://www.mitre.org/about/culture-of-knowledge-sharing\nhttps://www.mitre.org/about/culture-of-knowledge-sharing Approved for Public Release; Distribution Unlimited. Case Number 18-0564 sponsor and MITRE, he developed FUSE, an acronym for Frequency-Scaled Ultra-\nWide Spectrum Element. FUSE is modular, so that a large antenna can be built from several small FUSE \nsubarrays that could be easily reconfigured. Because FUSE doesnt require \nconnectors, large phased arrays can be made at a fraction of the cost of others their \nsize. And since FUSE is an all-metal design, it has three to five times more power-\nhandling capability than a comparable wideband phased array made with printed \ncircuit board technology. Working with Jamie Hood, a MITRE mechanical engineer, Elsallal also developed \nanother new generation of low-profile wideband phased-array antenna. The MITRE \nteam later collaborated with a start-up 3-D printing company in Boston, Voxel8, to \nfind a way to manufacture the phased array using a compact Voxel8 printer that \ncan be deployed in the field. Elsallal looks at his development of new products as more of a collaborative process \nthan a solo act. Just as he worked with classmates in high school, he brings junior \nengineers onto his projects, helps teach them, and, in turn, learns from them. \"MITRE encourages mentoring. I get support from management to allocate people \nwho are new to the company or dont have the same experience as I do, and we \nwork together.\" Two of his mentored colleagues went on to lead their own projects. \nAnd now Elsallal is mentoring three more engineers to become future leaders. The company also supports his outreach efforts to the wider scientific community. \nIn 2016, for example, he served as technical program co-chair of the IEEE Phased \nArray Systems and Technologies Symposium. And this year he serves as technical \nprogram co-chair of the IEEE International Symposium on Antennas and \nPropagation. A Team Approach to Innovation His teamwork-driven approach extends to his government partners as well. Coming \nup with groundbreaking designs for the Navy, for example, is the result of close \ncollaboration with a \"hands-on\" Navy sponsor who provided some of the innovation, \nas well as working with an excellent MITRE team. \"This is the result of weekly meetings with our sponsors, looking outside the box, \nand borrowing from the expertise of people at MITRE from different backgrounds \nfrom my own.\" MITRE has used Elsallals FUSE innovation work on other projects to help sponsors \nsolve complex antenna issues. And well soon have an active electronically scanned \narray capability based on FUSE technology with flight heritage. Meanwhile, hes always looking for ways to encourage the next generation of \ninnovators. In addition to Jamie Hood, some of the other early career engineers he \nhas worked with at MITRE include John Liston, a lead antenna/electromagnetics https://www.mitre.org/publications/project-stories/mitre-finds-innovative-solutions-to-government-problems-in-the-start-up\nhttps://www.mitre.org/news/press-releases/mitre-taps-boston-innovation-to-tackle-national-challenges\nhttps://www.mitre.org/news/press-releases/mitre-taps-boston-innovation-to-tackle-national-challenges\nhttps://www.mitre.org/news/press-releases/mitre-taps-boston-innovation-to-tackle-national-challenges\nhttps://www.mitre.org/news/press-releases/mitre-taps-boston-innovation-to-tackle-national-challenges\nhttps://www.mitre.org/news/press-releases/mitre-taps-boston-innovation-to-tackle-national-challenges\nhttps://www.mitre.org/careers/working-at-mitre/professional-development\nhttps://2018apsursi.org/APSURSI2018_CallForPapers.pdf\nhttps://2018apsursi.org/APSURSI2018_CallForPapers.pdf\nhttps://2018apsursi.org/Default.asp\nhttps://2018apsursi.org/Default.asp Approved for Public Release; Distribution Unlimited. Case Number 18-0564 engineer, and Cecelia Franzini, a former MITRE intern who is now a senior sensor \nsystems engineer and has filed for two patent disclosures. by Tom Nutile _top\n _GoBack ",
    "text": " blockchain_tech_report_final_2018 Blockchain Technology for \nGovernment Authors: Dave Bryson \n Dave Penny \n David C. Goldenberg \n Gloria Serrao \nDecember 2017 MT R 18 00 46 MIT R E T E C H N I C A L R EPO R T Project No.: 10MSRF18-AA \nThe views, opinions and/or findings \ncontained in this report are those of \nThe MITRE Corporation and should \nnot be construed as an official \ngovernment position, policy, or \ndecision, unless designated by other \ndocumentation. \nApproved for Public Release; \nDistribution Unlimited. Case \nNumber 18-1069 \n \nALL RIGHTS RESERVED. ii Approved By iii iv Abstract \nThis document presents an introduction to blockchain technology with a specific focus on the \ncore technologies, platforms, and applications that may be beneficial to MITREs government \nsponsors. The document is intended to introduce MITRE and its sponsor to blockchain \ntechnology, and establish a base of knowledge upon which to further explore MITRE sponsor \nblockchain use cases and research. An introduction to blockchain and its critical components \nincluding cryptography, consensus, and distributed ledgers is provided. Public and permissioned \nblockchains are compared, and a framework is provided that outlines when it is beneficial to use \nblockchain solutions. Use cases applicable to MITRE sponsors such as healthcare, identity, \nsupply chain, and the Internet of Things (IoT) are considered. A survey of leading permissioned \nblockchains such as Ethereum and Tendermint is presented, and important emerging features \nsuch as private transactions and state channels that strengthen enterprise blockchains are \ndiscussed. v vi Executive Summary \nBlockchain technology is evolving at a very rapid pace. Understanding the core components of \nthe technology and how they work together is critical to tracking the state of the art. While each \ncomponent plays a critical role in the technology stack, consensus is at the heart of the system \nand important to understand. Carefully choosing the right consensus algorithm based on the \ndesired level of trust and security will be critical to a successful blockchain application. While public blockchains provide the most security as they are designed to operate in a trust-less \nenvironment, government users will be most interested in a permissioned blockchain. However, \nthe nature of a permissioned blockchain requires careful planning and governance to establish \nthe parties participating in the consensus process. Without proper governance, there may be a \npossibility of politically centralizing some of the key functionality of the blockchain, limiting its \ncapabilities, and providing a false sense of security. As more look to permissioned blockchains to modernize traditional applications, there are \nseveral requirements that need to be addressed. For example, privacy and confidentiality on the \nblockchain, transaction scalability, and blockchain-to-blockchain connectivity. While theres \nongoing active research in these areas across several open-source communities, permissioned \nblockchains need to further evolve to fully meet the needs of the government user. vii Table of Contents 2.1 What a Blockchain Does \n2.2 How it Operates \n3.1.1 Hash Function \n3.1.2 Digital Signature \n3.2.1 Proof of Work (Nakamoto Consensus) \n3.2.2 Byzantine Fault Tolerant (BFT) Consensus \n3.4 Smart Contracts \n3.5 Peer to Peer Network \n3.6 Typical Transaction Flow \n4.2 Permission Blockchain \n6.2 Identity \n6.3 Supply Chain and Logistics \n6.4 Internet of Things \n7.2 Quorum \n7.3 Tendermint \n7.4 Hyperledger Fabric \n7.5 Guardtime \n8.2 State Channels \n8.3 Bulk Data Storage \n8.4 Connecting Blockchains \nFigure 1. Blocks are Linked by the Hash of Their Contents. \nFigure 2. Following a Transaction Through the Blockchain (Blockgeeks, 2017). \nFigure 3. Blockchain Decision Chart (IEEE: Do you need a blockchain). \nTable 1. Consensus Comparison. \nTable 2. Public vs. Permissioned Blockchain. \nTable 3. Guardtime Pros and Cons \nIn 2009, a developer (or developers) by the name of Satoshi Nakamoto created an electronic \npayment system named Bitcoin (Nakamoto, 2009). The goal of Bitcoin was simple: allow two \nparties to directly exchange a digital currency without the need for a trusted 3rd party (e.g., a \nbank) to mediate the transfer. Over the past eight years, Bitcoin has grown to be one of the most \nsuccessful cryptocurrencies. It has also proved to be one of the first public-facing, fault-tolerant \ndistributed systems capable of operating in an adversarial environment. As of 2017, there are over 1000 different cryptocurrencies, many based on Bitcoin, with a \ncombined market capitalization approaching $1 trillion. (CoinMarket Cap, 2017). The success of \nBitcoin and the emergence of new platforms such as Ethereum that offer programmable smart \ncontracts, is pushing the technology beyond the cryptocurrency use case and driving the growing \ninterest in blockchain technology. The level of interest is especially high in enterprise applications. The recently formed Ethereum \nEnterprise Alliance (Enterprise Ethereum Alliance, 2016) and the open-source Hyperledger \nproject (Hyperledger, 2017) now have hundreds of members across a broad spectrum of Fortune \n500 companies. Virtually every major software vendor is offering services and consulting on \nblockchain technology. What is a Blockchain? \nA blockchain can be compared to a bank ledger containing transactions. It provides information \nabout the date, time, and amount of money or other property of interest changing ownership. \nOnce transactions are written to the ledger, they are permanent; they cant be changed or deleted. \nTransactions are bundled into blocks and these blocks are linked to form the ledger, which is \ncalled blockchain. A blockchain is distributed over multiple nodes using an underlying peer-to-\npeer (P2P) network protocol for node discovery and communication. The components of blockchain are discussed in detail in Section 3, but are briefly described \nbelow for context. Cryptography: hash functions that link blocks together providing integrity of the chain \nand digital signatures providing integrity for the transactions. Consensus Algorithm: The process by which parties to a blockchain decide on the \nordering and presence of transactions on the ledger. Distributed Ledger: A distributed, replicated, representation of all transactions \n P2P Protocol: The protocol that manages the peer nodes of the network that support blockchain. Performs communication between nodes, flow control, node discovery, and \nframing. Smart Contracts: business rules or logic that can extend the functionality of a blockchain 2.1 What a Blockchain Does \nAt its core, a blockchain enables a network of peer computers (or nodes) to validate, settle, and \nagree on a record of transactions. It establishes a form of trust between parties that may not \notherwise trust each other, and does so without relying on traditional centralized services, or \ntrusted 3rd parties. This new form of decentralized trust has generated interest with users across a \nwide range of domains. Companies are investing research and development efforts into 2 blockchain technology, with the hopes of revamping existing processes to reduce cost while \nimproving security, accountability, and transparency. 2.2 How it Operates \nA blockchain is a replicated state machine. A given state is synchronized across a set of \nmachines, or nodes, such that these nodes function as a single machine, despite the potential that \nsome will fail either through normal faults or malicious activity. The state of a blockchain is driven by incoming transactions, each transaction causing a state \ntransition. What the state represents depends on the goal of the blockchain. In the case of \ncryptocurrency, the state is the balance of accounts, while in an enterprise blockchain, the state \nmay represent other forms of information. A transaction can be thought of as the fundamental unit of work in a blockchain. It is the input to \nthe system, an atomic operation, that drives a state transition. It either succeeds and updates the \nstate of the system, or it fails and is ignored. A transaction is redundantly verified by every \nblockchain node in the network and multiple transactions are batched into blocks for efficient \nprocessing. The consensus protocol enables all nodes to agree on the transactions in a block and the order of \nthe blocks ensuring identical copies of the blockchain are stored on every machine. These new \nblocks are cryptographically linked to the prior block to prevent them from being altered once \nagreed upon. The combination of a tamper-proof transaction log and a deterministic state \ntransition ensures that all machines can compute the same state given the same transaction log. Key Components of a Blockchain 3.1 Cryptography \nA blockchain relies on two cryptographic primitives for many of its security properties: \ncryptographic hash functions and digital signatures. 3.1.1 Hash Function \nA cryptographic hash function is a mathematical function that takes in an input string of any size \nand produces a fixed sized output. Cryptographic hash functions have two main properties that \nare used to secure blockchains. 1. It is possible to efficiently compute the hash function in the forward direction; however, \nits nearly impossible to compute the inverse of the hash function. In other words, its \ninfeasible to learn any valid input from the output hash. 2. Small changes in the input to a hash function result in large and unpredictable changes in \nthe output. As an example of the above two properties, using the SHA-256 hash function, \nwe can create a unique fingerprint of the word HELLOWORLD: sha256(HELLOWORLD) = \n'0x0b21b7db59cd154904fac6336fa7d2be1bab38d 49584068cdcb74' The hash of the word results in a 256-bit value and it will always be the same value given \nthe same input. However, given the 256-bit
output value, it is computationally infeasible \nto discover the original input HELLOWORLD in our example. Furthermore, changing 3 even one character (dropping the H) in the original input results in a completely different \nhash value: sha256(ELLOWORLD) = \n'0x7d26a27cec234907afe7ce f4b8eebb d3c5d1c100e' This makes it easy for hash functions to detect even the slightest change in an input string. \nAlthough its easy to detect changes in our simple example by looking at the text, hash functions \ncan help to guarantee the authenticity of more complex content where changes may not be as \neasily noticeable. Hash functions are used to both ensure an individual block of transactions cannot be altered and \nthat the order of blocks in the overall blockchain remains consistent. Once a block is created it \ncannot be altered, and one cannot remove blocks or insert blocks into the middle of the \nblockchain. This is further explained in Section 3.3. 3.1.2 Digital Signature \nAnother cryptographic primitive used by blockchain technology is the digital signature. \nCryptographic digital signatures are based on public key cryptography. They are the digital \nequivalent of a traditional signature but are much more secure. Essentially a digital signature \nprovides a way for anyone to mathematically verify that a party is willing to attest to some \ndigital content. A digital signature requires a cryptographic key pair. The key pair consist of a private key, \nsometimes referred to as the signing key, and a public key, also known as the verification key. \nThe signing key is a securely generated random value, while the verification key is generated \nfrom the signing key. The math behind the signature scheme ensures that it is computationally \ninfeasible to reverse the processyou cannot learn the signing key from the verification key. The \nsigning key should be securely controlled by the owner and never shared. On the other hand, the \nverification key can be shared with anyone and is used along with the signed content to verify \nthe validity and authenticity of the signature. For example, Bob is the owner of a key pair and uses his private key to sign the cryptographic \nhash of some content to generate a signature on that content1. Given the corresponding public \nkey, the content, and the generated signature, anyone can verify that Bob (uniquely) signed the \ncontent. In the context of the blockchain, signature verification of a transaction is a critical step. If the \nsignature is invalid, the transaction is rejected. Signatures are primarily used to ensure that all \ndata and state on the blockchain cannot be illegitimately modified. Most blockchain implementations use Elliptic Curve Digital Signature Algorithm (ECDSA); \nECDSA is a U.S. government standard. The algorithms behind ECDSA have undergone \nconsiderable cryptographic analysis and are considered secure and more efficient than other \nperhaps better known cryptographic algorithms such as RSA/Digital Signature Algorithm \n(DSA). (Narayanan, Bonneau, Felten, Miller, & Goldfeder, 2016) \n1 Quite often for efficiency a cryptographic hash of the content is signed, and not the content itself. If correctly implemented this \ndoes not introduce any weaknesses in security. 4 3.2 Consensus \nConsensus makes it possible for a decentralized network of machines to agree upon and share the \nstate of the system. It is critical in ensuring participants can trust the transactions processed on \nthe blockchaineven when they may not trust each other. For example, say Alice transfers 10 \ndigital tokens to Bob. What prevents Alice from transferring the same 10 digital tokens to Carl? \nIn the cryptocurrency world, this is known as the Double Spend Problem (Double Spend \nProblem, 2017). Somehow the system must reconcile and share account information across a \nnetwork of independent nodes to ensure Carl is not cheated out of his payment from Alice. Before Bitcoin, it was impossible to electronically transfer digital money without relying on a \ncentralized authority to manage the state of the system. Bitcoin cleverly solved the double spend \nproblem and eliminated the need for a middleman by simply distributing a copy of the ledger to \nevery node on the network, so anyone can check the state of an account. However, this creates a new problem. How does a blockchain node know its being sent valid \ninformation? What if messages are lost? What if a malicious actor is falsifying transactions or \nblocks? This problem is best illustrated by the well-known Byzantine Generals Problem \n(Byzantine Fault Tolerance, 2017). In the Byzantine Generals Problem, there is a group of generals surrounding a city. The generals \nhave the ability to conquer the city if they coordinate the time of attack. However, if they do not \nattack at the same time, they risk being defeated by the enemy. The generals can only coordinate \nthrough messengers with no way to verify the authenticity of the message. Messengers may be \ncaptured, preventing the delivery of a message. And traitors among the generals may deliberately \nsend bad messages to disrupt coordination. How can this group successfully coordinate the attack \nwithout relying on a centralized authority? Bitcoin solved the Byzantine Generals Problem \nthrough a new form of consensus called Proof of Work (PoW). 3.2.1 Proof of Work (Nakamoto Consensus) \nPublic blockchains such as Bitcoin or Ethereum, allow anyone to participate in the consensus \nprocess as a miner. Miners compete (or effectively vote) to add new transactions to the \nblockchain with computing power by expending a certain amount of Central Processing Unit \n(CPU) cycles to solve a mathematical puzzle. This puzzle is intentionally computationally \ndifficult to solve (Nakamoto, 2009), yet it is very easy to verify the answer. To add a block of new transactions to the blockchain, a miner must solve the puzzle. The first \nminer to solve the puzzle sends (proposes) the block to the rest of the network for agreement. If \nthe network agrees on the solution to the puzzle, the miner is rewarded for creating the block and \nthe block is added to the blockchain (the miner wins this round of competition). Through a \ncombination of game theory and economics (effectively betting CPU cycles, which cost money, \nto win the reward), PoW incentivizes consensus instead of attempting to enforce it. Essentially a \nminer is rewarded for securing the network. When nodes synchronize to the network, there is a chance malicious actors may try to send \ninvalid blocks in an attempt to double spend. To prevent this, nodes follow a simple rule of \nalways synchronizing to the longest chain of blocks. This is because the longest chain reflects the \nmajority vote by the networkit is the one miners have done the most work on. Following the longest chain rule also reduces the number of protocol messages traditionally \nrequired to synchronize a large number of distributed nodes, making it possible for a public 5 blockchain to scale to thousands of nodes. However, the downside of using the longest chain rule \nis that blocks are never truly final. This is why public blockchains may advise waiting for 12 or \nmore block confirmations to accept a transaction (Block Confirmation, 2016). An example of why this is necessary is that there are rare instances when the chain will split \nunder normal operationwhen multiple miners solve a puzzle at virtually the same time. As \nnoted, nodes choose to build on the longest chain. However, in this case, there are two valid \nchoices. Based on PoW one chain will eventually win, becoming the longest chain (the \nprobability of chains extending in parallel for more than one or two blocks is exceedingly small). \nThe blocks in the shorter chain are often referred to as orphaned; and all transactions in these \nblocks are effectively invalid until they are packaged into a new block. Thus, consensus is reached, but transaction settlement times are relatively long and transaction \nrates are limited. 3.2.2 Byzantine Fault Tolerant (BFT) Consensus \nWhile public blockchains rely on PoW, enterprise (or permissioned) blockchains tend to use \nmore traditional BFT consensus protocols (Byzantine Fault Tolerance, 2017). BFT consensus is \nbased on the idea that a pre-selected, authorized group of validators2 will create, verify, and attest \nto new blocks. These validators take turns creating new blocks and submit a newly created block to other \nvalidators for verification and vote. Each validator votes for a block by cryptographically signing \nit. Once the network receives at least a 2/3 majority vote for a block, it is finalized and added to \nthe blockchain. Since valid blocks will contain the digital signatures of the validators, nodes \nsynchronizing to the blockchain need only check the validator signatures in a block to ensure \nthey are following the correct blockchain. BFT consensus usually requires a certain minimum number nodes to ensure the network can \noperate in the face of malicious actors, for example, 3F+13, where F is the number of faulty \nnodes. Compared to PoW, this approach also requires the exchange of more protocol messages to \ncoordinate the consensus process, limiting its scalability. While PoW can support thousands of \nnodes, BFT is limited to at most hundreds. Table 1. Consensus Comparison. BFT Nakamoto Speed (transactions per second) Potentially 1000s < 20 on average Network Scalability 100s of nodes 1000s of nodes
Block Finality Instant Eventual \nThere is not a one size fits all consensus algorithm for blockchain technology. Selecting a \nconsensus algorithm for a given use case will require a lot of thought and attention to detail both \nin the application itself and in the externalities involved. \n2 A validator is the term used for a miner in a blockchain using BFT. \n3 This may vary based on the specific protocol. 6 3.3 Distributed Ledger \nA blockchain uses the notion of a ledger to capture and record a history of all transactions. The \nledger is distributed and replicated across every machine on the network. New blocks can be \nappended to the blockchain but prior blocks cannot be modified or deleted. The term blockchain comes from the fact that transactions are batched together in a block \nand blocks are linked together to form a chain. Each block is linked to its parent via a SHA256 \ncryptographic hash of the contents of the previous block, forming the chain of blocks over time \n(Figure 1). The cryptographic hash of the contents of a block serve as a fingerprint of the blocks \ncontents. Changing anything in the contents of a block results in a completely different hash \nvalue, breaking the connection between blocks. The use of a hash to link the blocks coupled with \nthe consensus protocol provides the immutability of the ledger. Figure 1. Blocks are Linked by the Hash of Their Contents. Anyone can verify the provenance and authenticity of the blockchain and its contents by \nfollowing the links and validating the hash in each block as show in Figure 1. For an adversary to \nalter the blockchain they would need to rebuild the links connecting the blocks from the point of \nthe altered block, which is mathematically impossible based on the hash function described in \nSection 2.1. The feasibility of such an attack is dependent on the consensus algorithm used by \nthe blockchain because that algorithm decides the conditions for a transaction to be added. The \ncomplete blockchain consisting of all blocks and their constituent block data (transactions, \nmetadata, and the hash of the parents contents) is stored on every node in a key-value database \nsuch as Googles open-source LevelDB. In addition to the block data the key-value store also \ncontains the root hash of the Merkle Tree (Merkle Tree, 2017). The Merkle Tree is a compact representation of the current state of the application for the given \nset of transactions in a block. A Merkle Tree root hash value efficiently represents the overall \nstate of the data, making it easy to use the root of the tree to determine if a particular data item is \na member of the blockchain state. What the actual state represents depends upon the state \ntransition logic of the blockchain application. Mutating application state is accomplished by sending transactions to the blockchain and \nprocessing those transactions for a given block, possibly through smart contracts. 3.4 Smart Contracts \nA smart contract is the business logic of a blockchain. It dictates the rules of how state is \nchanged on an object over time. A smart contract provides the ability for developers to extend \nthe functionality of a blockchain by adding application-specific logic. Although the term smart contract has been around since the late 1990s, Ethereum popularized the \nterm by being the first public blockchain to provide a Turing complete smart contract language. 7 The goal of Ethereum is to provide a world computer for which anyone can build and deploy \nblockchain-based applications, often referred to as Decentralized Applications (DAPPS). While \nother blockchains provide different approaches for adding business logic to the blockchain, \nEthereum was specifically designed with a custom virtual machine for running full-featured, \ndeterministic smart contracts. A critical requirement of any smart contract is that they must execute in a deterministic \n(Deterministic System, 2017) fashion. Every miner node on the network must agree on the \noutput of their computation. Therefore, its critical smart contracts always return the same result \nfor a given input. If different machines are getting different results from the execution of the \nsame smart contract, the blockchain will not be able to reach consensus on the correct state of the \nsystem. 3.5 Peer to Peer Network \nA blockchain application requires both a client and server application, which is often referred to \nas a blockchain node. Nodes connect directly to other nodes to form a fully decentralized \nnetwork on top of the internet. While the main responsibility of a peer-to-peer network on the blockchain is to propagate \ntransactions and block information across the network, P2P networks use a specific protocol to \nprovide other functions as well, among those are maintaining connectivity, flow control, node \ndiscovery, communicating the consensus protocol, and filtering malformed or non-verified \ntransactions. Since blockchain P2P networks do not rely on centralized services they are very resistant to \nfailures and denial of service attacks. 3.6 Typical Transaction Flow \nBy following a transaction through its lifecycle, we can see how all the components of a \nblockchain work together. 1. A transaction is constructed by an end user, for example Bob wants to transfer 10 widgets \nto Alice. 2. The transaction is cryptographically signed by Bob and sent to the blockchain network \nover the P2P network. 3. Each node in the network validates the transaction to ensure it is properly signed and \ncorrect. If validation fails, the transaction is dropped and not propagated on to other \nnodes. 4. At some point in time, a validator or miner node batches a set of transactions together, \nexecutes them against one or more smart contracts, creates a block, and proposes the \nblock to the network. 5. Once the majority of the network agrees to the validity of the block, it is added to the \nblockchain and linked by the cryptographic hash of the parent block. 6. The transaction is complete and permanently recorded on the blockchain. 8 Figure 2. Following a Transaction Through the Blockchain (Blockgeeks, 2017). Public vs. Permissioned Blockchain \nThere are primarily two4 different types of blockchains based upon the consensus algorithm they \nuse: public and permissioned. 4.1 Public Blockchain \nPublic blockchains are the most well-known and battle-tested implementations in production. \nBitcoin and Ethereum are two examples. Anyone can join a public blockchain by simply \ndownloading and running the respective open-source implementation. Public blockchains are \ninherently designed to run in a trust-less environment with the assumption there will be malicious \nactors. In order to operate in such an environment, most public blockchains use Nakamoto Consensus \n(Section 3.2.1), which uses a combination of game theory and economic incentives to secure the \nnetwork via a cryptocurrency with value. Therefore, you must have a cryptocurrency balance in a \npublic blockchain account in order to transact on the blockchain, whether it be a simple financial \ntransaction or a function call to a smart contract. Because of the cryptocurrency requirement, \ntheres no real sense of identity on a public blockchain. Users are associated with a \npseudonymous address, which is derived from the public key they use to sign transactions. 4.2 Permission Blockchain \nIn contrast, a permissioned blockchain is a closed network often using a BFT algorithm. The \nvalidators responsible for building the blockchain, as well as the participants in the network, are \nselected by the group and held accountable for their actions. \n4 There are actually more, but public and permissioned are the dominant models. 9 There is stronger notion of identity on a permissioned blockchain versus a public one. Because of \nidentity there is no need for a cryptocurrency, or other forms of a token, to secure the network. Table 2. Public vs. Permissioned Blockchain. Who can Participate? Requires a Cryptocurrency? Identity of Participants Public Anyone Yes Pseudonymous Permissioned Closed No Known to the group Considerations for Using a Blockchain \nBringing trust to a trust-less network is one of the most appealing features for using a \nblockchain. Many of todays applications have a need to share or move information across \norganizational boundaries between parties that may or may not trust one another. Blockchain has the potential to bring trust to such an environment without relying on a 3rd party \nto mediate transactions. However, careful consideration should be made to determine if \nblockchain technology is the right fit for the given problem. 1. Current blockchain implementations are not capable of the same volume of transaction \nthroughput that you may find with traditional database technology. For example, public \nblockchains such as Ethereum can currently process approximately 12-15 transaction per \nsecond (TPS), while Bitcoin is capable of about half of that. Permissioned blockchains \nare much faster ranging from tens to thousands TPS depending on the consensus \nalgorithm. As a comparison, both public and permissioned blockchains are much slower \nthan networks like the Visa processing network, which can process tens of thousands of \ntransactions per second. 2. Blockchain data is not private. Anyone with access to a node, can read all transaction and \napplication state data. However, there are current efforts to provide private transactions \nusing advanced cryptography. 3. The decentralized nature of the
technology will in many cases require a redesign of the \nbusiness processes, as most are based on centralized control and/or trusted 3rd parties. \nForce-fitting existing processes into a blockchain could result in centralizing a blockchain \nand limiting its potential. 4. Application development is difficult. Smart contracts operate under an asynchronous \nprogramming model as you dont know exactly when or if a transaction is added to the \nchain. This is in sharp contrast to the dominant request/response model used by most web \napplications today. Additionally, application logic must be programmed to be \ndeterministic, which can limit the potential logic that can be ported to a smart contract. 5. There are variants of consensus algorithms used by permissioned blockchains. Not all are \nintended to operate in a trust-less environment. Careful attention should be used in \nselecting the right consensus algorithm for a given use case. 6. In the case of a permissioned blockchain, consideration needs to be made in terms of the \ngovernance process. Since a permissioned blockchain is a closed group, participants must \ndecide who will serve as the validating nodes in the consensus process. Additionally, a \nprocess for managing user access must be consideredwho can participate, who has the \npower to add or restrict users, etc. Without careful planning and proper governance, this \ncould lead to a politically centralized blockchain by putting too much power in the hands \nof a few. Potentially reducing some of the advantages and reasons for considering a \nblockchain in the first place. 10 As noted in Section 4, there are predominately two types of blockchains. Each fit a specific need \ndepending on the use case and the needs of the organization. Here are some additional factors \nyou should consider when exploring blockchain technology: Do all participating parties trust each other? \n Will more than one user be writing data to the system? \n Is a trusted party required as part of the business process? \n Do all participants need to see a synchronized view of the data? \n Does the data need to be private? \n Do you need to control who can deploy smart contracts to the system? One potential blockchain evaluation framework is shown in Figure 3. Potential Use Cases \nApplication areas under investigation and of potential value to MITRE sponsors are numerous \nand include healthcare, identity, supply chain (and logistics), Internet of Things (IoT), additive \nmanufacturing, and secure information sharing among others. Several of these uses cases are \npresented below. 6.1 Healthcare \nBlockchain is being investigated as the foundation for numerous healthcare applications \nincluding patient records, drug trials, medical supply chain, and payment processing. Bruce Broussard, president and CEO of Humana, posits blockchain will become the next big \nhealthcare technology innovation, particularly as it relates to payments and payer contracts. For \nexample, in a situation when a health plan and patient are dealing with a contract, the blockchain \ncan automatically verify and authorize information and the contractual processes. There is no \nmore back-and-forth haggling with the health plan about what was paid, why it was paid or \nwhether it should have been paid, he wrote. With transparency and automation, greater \nefficiencies will lead to lower administration costs, faster claims and less money wasted. \n(Healthcare Information Tech) Another potential healthcare application is population health. Instead of relying on health \ninformation exchanges or other ways to aggregate data, organizations can eliminate the \nmiddleman and access patient databases on a large, population scale. Spending time and \nresources verifying members' trustworthiness (e.g., Health Information Exchange [HIE], all-\npayer claims database, or local Electronic Medical Records [EMRs]) no longer makes savvy \nbusiness sense. Blockchain will leap frog population health by providing trust where none exists \nfor continuous access to patient records by directly linking information to clinical and financial \noutcomes, reports CIO. (Blockchain Apps for Healthcare) 11 Figure 3. Blockchain Decision Chart (IEEE: Do you need a blockchain). A registry of all devices connected to the Veterans Affairs (VA) IoT is a potential beneficial use \nof blockchain. A second use could be digitizing the transactions of Veterans monetary benefits, \nlike pension and compensation. Health researchers are also exploring using blockchain in \nhealthcare records management. Blockchain could be used to securely exchange large volumes \nof data while ensuring patient privacy and maintaining data integrity. Further, a blockchains \nrecord-keeping ability could be used in VA hospitals to track a patients hospital visit, with \ndevelopments tracked in a ledger as a transaction. (Tech Insight: Blockchain) 6.2 Identity \nOnline identity management remains a time-consuming and costly process. There is much churn \nwith respect to identity: for example, the Equifax breach has driven Congress and others to \nrethink two major parts of the current credit system: having credit bureaus store most Americans \nidentity data and using Social Security numbers as a primary identifier. 12 The ability to record, track, and manage identity on a blockchain has the potential to vastly \nimprove the efficiency and minimize the cost of identity management; an immutable, trusted \nsource of identity will make it difficult to steal, hack, modify, or otherwise damage reputation, or \ncompromise identity to steal real assets or perpetrate fraud. A well-constructed blockchain identity solution would help consumers, businesses, and \ngovernment alike; users can choose how much information to release on an as-needed basis. \nTrusted information will save businesses and government time and money. Theres no doubt \nthat the blockchain concept, with its power to prevent duplication and divergence from the chain, \nis highly promising for identity, said Jo Ann Barefoot, a former deputy comptroller at the Office \nof the Comptroller of the Currency. (Build a Better Credit Bureau, 2016) Identity is central to many activities of a typical consumers life. Its also applicable across a \nwide range of MITREs sponsors. For example, the Department of Homeland Security (DHS) \nrecently awarded a Blockchain Tech development grant for identity. DHS is developing an \nidentity management solution built on a permission-less blockchain, with a focus on \nconfidentiality (with selective information disclosure), integrity, availability, non-DHS \nrepudiation, provenance, and pseudo-anonymity. (DHS Awards Blockchain Grant) A good use case related to identity is trusted propagation of cancelled credentials; once your \ncredentials are cancelled on the shared truth blockchain, it is visible to all valid participants and \ntheres no way to game the system. Advances in biometrics plus digital identity and blockchain present interesting possibilities for \nMITRE sponsors. HYPR is a startup using blockchain and biometrics for enterprise identity \napplications. HYPR decentralizes and secures any type of credentials including passwords, \nPersonal Identification Numbers (PINs), and biometric authentication such as fingerprint, face, \nhand, retina, iris, voice, and behavior. (Decentralized Access Control) As with any asset management solution, there are issues of data freshness and integrity. \nStandards for identity management using blockchain are not yet set and best practices are still \nbeing developed. Research is needed into the blockchains ability to protect private information. \nOnce information is recorded on the blockchain, it remains accessible to all parties in the \nnetwork, so users must be aware to minimize any private information. 6.3 Supply Chain and Logistics \nThe United States Department of Defense (DoD) is one of, if not the, largest logistics \norganizations in the world; the challenges of procuring, tracking, deploying, and managing goods \nis enormous. DoDs supply chain depends on an enormous number of globally distributed \ncompanies, making it hard to oversee them all. This has traditionally been part of the challenge \nof developing anti-counterfeit systems. Blockchain may offer a simpler way to comply, \nbroadening the set of companies that can compete for military contracts without watering down \noversight. (Pentagon has the World Largest Logistic Problem) Blockchain provides each participant end-to-end visibility based on their level of permission. \nEach participant in the supply chain ecosystem can view the progress of goods through the \nsupply chain to include origin, transit, and destination. They can also see the status of customs \ndocuments, or view bills of lading and other data. Detailed visibility of the goods progress \nthrough the supply chain is enhanced with the real-time exchange of original supply chain events \nand documents. No one party can modify, delete, or even append any record without consensus \nfrom others. This level of transparency helps reduce fraud and errors, reduce the time products 13 spend in the transit process, improve inventory management, and ultimately reduce waste and \ncost. Blockchain supply chain solutions could extend to many other government groups as well, e.g., \nverifying the provenance of medical equipment within the VA, tracking food and drug shipments \nfor the Food and Drug Administration (FDA), and generally managing supply chain risk any \ngovernment entity. System issues must be carefully considered when using blockchain in supply chain and \ncoordination applications. Data must be entered securely and accurately. Access to controlled \nassets must be managed so that systems physical (and software) configurations remain in sync \nwith the blockchain. Smart sensors, various ID tags, and workflow processes are critical items to \nbuilding a complete blockchain-supported supply chain. 6.4 Internet of Things \nThe IoT is impacting every segment of industry, consumers, and government. With tremendous \ngrowth in smart devices comes many challenges including:
security, lifecycle management, \ndevice and data integrity, and device authentication. A potential use case: In June 2016, the DHS Science and Technology (S&T) Division awarded a \n$199,000 contract to Factom to study possible blockchain-based advancements for the security \nof digital identities for the IoT, the upcoming connection and convergence of mobile devices, \ninformation technology networks, and connected sensors and devices. The project, titled Blockchain Software to Prove Integrity of Captured Data From Border \nDevices, will create an identity log that captures the identification of a device, who \nmanufactured it, lists of available updates, known security issues, and granted authorities while \nadding the dimension of time for added security. The goal is to limit would-be hackers' abilities \nto corrupt the past records for a device, making it more difficult to spoof. It's interesting to note \nthat a North Atlantic Treaty Organization request for proposal also included an IoT section, \nwhich underlines the synergy between IoT and blockchain technologies for military applications. (DHS Awards Blockchain Grant of Identity Managment, 2016) IoT devices are embedded within our daily lives-from the vehicle we drive to devices we wear \nit's critical to safeguard these devices from adversaries, said DHS Under Secretary for Science \nand Technology, Dr. Reginald Brothers. S&T is excited to engage our nation's innovators, \nhelping us to develop novel solutions for the Homeland Security Enterprise. (DHS Awards \nBlockchain Grant of Identity Managment, 2016) Survey of Permissioned Blockchains 7.1 Ethereum \nEthereum (Ethereum Blockchain Application Platform, 2015) is an open-source blockchain \nplatform that enables developers to build and deploy decentralized applications. In addition to \nthe common blockchain components, Ethereum includes a custom virtual machine known as the \nEthereum Virtual Machine (EVM) for executing smart contracts. The EVM is tightly integrated into an Ethereum node, storing the state of smart contracts in a \nMerkle Tree on the blockchain alongside transactions. Smart contract applications are written in \nthe Solidity language in a syntax that closely resembles JavaScript. Solidity code is compiled to a 14 binary format and deployed to the blockchain for execution. The flexibility of the EVM allows \nfor the creation of powerful smart contracts. The default version of Ethereum is a public blockchain using a PoW consensus algorithm. The \ncryptocurrency of Ethereum is known as Ether and is divisible up to 18 decimal places allowing \nfor very small micro payments. The Ethereum codebase has a pluggable interface for consensus algorithms, providing the ability \nto use an alternative consensus model. This is in part due to the growing interest in using \nEthereum as a permissioned blockchain in the enterprise space (Enterprise Ethereum Alliance, \n2016). Recently, a company contributed a more traditional BFT consensus plug-in that would be \na good fit for permissioned blockchains. Initial claims show support of up to 1200 transactions \nper second. 7.2 Quorum \nQuorum (Quorum, 2016) is an open-source version of Ethereum maintained by J.P Morgan. It is \nspecifically designed for permissioned blockchains yet shares many features with Ethereum. \nQuorum includes three alternatives for consensus: QuorumChain, Raft, and Istanbul BFT. QuorumChain: The first consensus alternative is an innovative round-robin voting \nconsensus algorithm implemented through an Ethereum smart contract. Parties that can \ncreate and/or vote on blocks are pre-configured in the initial block (genesis block) and \nbecome part of the state of the QuorumChain contract. Calls to consensus are through the \ntraditional Ethereum transactions model. Since the contract uses a simple round-robin \nvoting approach to consensus (it is not BFT), it is not immune to malicious actors and \nshould not be used in a network with untrusted participants. Raft: The second consensus alternative is an implementation of the well-known Raft \nalgorithm (Ongaro & Ousterhout, 2014). Like QuorumChain, Raft is not BFT and should \nnot be used in a trustless environment. Istanbul BFT: The third option is based on a BFT algorithm. This is targeted to support \nlimited-trust environments. However, as of this writing the code has not yet been merged \ninto the official release and is still undergoing testing. One of the key features of Quorum is its support for private transactions. While Quorum supports \ntraditional Ethereum public transactions, it also provides for private transactions between parties. \nQuorum extends the Ethereum transaction model by running additional nodes called \nConstellation that are responsible for securing and processing private transactions. Constellation is a general-purpose system for submitting information in a secure way. It is \ncomparable to a network of MTA (Message Transfer Agents), where messages are encrypted \nwith PGP (Pretty Good Privacy). It is not blockchain-specific, and is potentially applicable in \nmany other types of applications where you want individually sealed message exchange within a \nnetwork of counterparties. (Quorum Overview) Quorum stores the state of private and public transactions separately so that private transactions \ncan only be read and processed by the intended parties with access to a specific node. The \ndownside to this approach is that anyone with access to the node can read the private \ntransactions. 15 7.3 Tendermint \nTendermint (Tendermint Blockchain Consensus, 2017) is an open-source blockchain platform, \nconsisting of three chief technical components: a consensus engine, P2P network layer, and a \ngeneric application interface for developing smart contracts. Tendermints consensus engine is a BFT consensus protocol ensuring blocks are validated and \nrecorded on every machine in the same order. Tendermint block times are on average 1 second \nor less, allowing thousands of transactions per second. For smart contracts, Tendermint provides an extensible application interface, called the \nApplication Blockchain Interface (ABCI). Using the ABCI interface developers can implement \nsmart contracts in several different programming languages to include: Go, Python, JavaScript, \nErlang, C++, and more. Tendermint is designed to be easy-to-use, simple-to-understand, highly performant, and useful \nfor a wide variety of distributed applications. (Introduction to Tendermint, 2016). MITRE has \nused Tendermint for several prototypes. 7.4 Hyperledger Fabric \nHyperledger Fabric (Hyperledger Fabric, 2016) takes a similar approach to Tendermint as a \nframework for building blockchain applications. It provides a consensus engine with a BFT \nconsensus algorithm based on Practical Byzantine Fault Tolerance (PBFT), as well as an \napplication program interface (API ) for interacting with the blockchain. The original \nimplementation of Fabric was contributed to the open-source Linux Foundation by Digital Asset \nand IBM. Smart contracts in Fabric are referred to as chaincode and are currently implemented in the Go \nlanguage and must be run in Docker containers. In addition to chaincode, Fabric also provides \nadditional features: Membership service provider: a service to facilitate the enrollment of members that are \nauthorized to participate in the blockchain application Channels: the ability for group to create a separate ledger of transactions for privacy 7.5 Guardtime \nGuardtime is an Estonian and U.S.-based company that offers a few proprietary blockchain \nsolutions to governments and industry. One of their main solutions is known as Keyless \nSignature Infrastructure or KSI (Keyless Signatures 2013). The goal of KSI is not to provide a secure immutable-state machine, but rather to provide a \nsecure methodology to make assertions about the time and integrity of all sorts of digital records \nwhile removing as many cryptographic and human assumptions from the security of the system \nas possible (Guardtime Technology 2017). Guardtime does this through a trusted infrastructure \nand hash-based signatures instead of asymmetric key-based ones. Guardtimes KSI is a very different technology than other blockchain platforms, with some \nbenefits and drawbacks as compared to other blockchain systems. 16 Table 3. Guardtime Pros and Cons Pros Cons 1. Extremely fast signature processing and \nverification 2. Immutable time-stamping of signatures \n3. Does not require permission to use the blockchain \n4. Its security comes from minimal assumptions (mostly the cryptographic \nproperties of hash functions) 5. Quantum resistant 1. Proprietary \n2. Requires trusted infrastructure of signer nodes to sign data \n3. Does not store data on the blockchain, only signatures of the data \n4. While verifying a given signatures presence is easy, searching for a given \nsignature is hard/impossible Emerging Features \nBlockchain technology is advancing at a very fast pace. There are a few features currently in \ndevelopment across several open-source communities that will be of value to future \npermissioned blockchain applications. 8.1 Private Transactions \nBlockchains were originally intended to be publicly auditable. Therefore, all information stored \non the ledger (transactions and state) are readable by anyone with access to a node. Recently, a \nfew public blockchains such as Zcash and Monero were developed to protect the privacy of \ntransactions between parties by shielding the contents of a cryptocurrency transaction to \neveryone but the parties involved. Privacy of transactions in a permissioned blockchain is one of the most desired features for \nenterprise users, but production-level support is generally lacking in most permissioned \nblockchains. The Quorum blockchain outlined in section 7.2 provides support for private \ntransactions. And there is active interest in using sophisticated cryptographic techniques already \nused by Zcash known as Zero-Knowledge Succinct Non-Interactive Argument of Knowledge \n(zk-SNARKS) (Non-Interactive Zero-Knowledge Proof, 2017). Support for adding zk-SNARKS \nto Ethereum is currently under development. 8.2 State Channels \nBlockchain transaction throughput is not nearly at the level of speed that most enterprise users \nare accustomed to with traditional database technology. This is due
largely to the overhead of the \nconsensus process. One solution to increase the transaction speed of a blockchain is through the \nuse of state channels. A state channel is a bi-directional channel between parties. Messages in the channel take the \nform of transactions. Parties sign messages in the channel and anchor certain transactions to the \nblockchain at specific checkpoints, making the series of interactions leading to the final \ntransaction impossible to refute later. The majority of these transactions take place entirely off the blockchain and exclusively between \nthe participants, meaning they are cheap and very fast to execute compared to on-chain \npayments. (What are State Channels, 2016) 17 The open-source project Raiden Network (Raiden Network, 2017) has deployed initial support \nfor state channels on Ethereum; however, current efforts are focused primarily on token \ntransfers. 8.3 Bulk Data Storage \nBlockchains are not designed to store large data. Information sharing within the enterprise will \nrequire the ability to manage large data without directly storing it on the blockchain. One \nalternative is to store large data in external decentralized storage such as the InterPlanetary File \nSystem (IPFS) (IPFS Distributed Web, 2016) and use a hash fingerprint of the document in a \ntransaction on the blockchain as a reference to the externally stored content. MITRE has \nconducted initial experiments using this approach with moderate success. Other efforts, such as the BigchainDB (BigchainDB, 2017) project, are working to connect the \nimmutability and decentralization of blockchain technology with traditional database technology \nto create a best-of-breed approach for the enterprise. 8.4 Connecting Blockchains \nAs more organizations deploy blockchain solutions there will be a need to allow multiple parallel \nblockchains to interoperate. This can be difficult depending on transaction models and the \nvarious consensus algorithms used by blockchains. Various open-source projects, such as Cosmos (Cosmos Whitepaper, 2017) and Polkadot \n(Polkadot, 2017), are working on solutions to provide interoperability between blockchains, but \ncurrent efforts are predominately focused on public blockchains. Conclusion \nBlockchain technology is evolving at a very rapid pace. Understanding the core components of \nthe technology and how they work together is critical to tracking the state of the art. While each \ncomponent plays a critical role in the technology stack, consensus is at the heart of the system \nand important to understand. Carefully choosing the right consensus algorithm based on the \ndesired level of trust and security will be critical to a successful blockchain application. While public blockchains provide the most security as they are designed to operate in a trust-less \nenvironment, government users will be most interested in a permissioned blockchain. However, \nthe nature of a permissioned blockchain requires careful planning and governance to establish \nthe parties participating in the consensus process. Without proper governance, there may be a \npossibility of politically centralizing some of the key functionality of the blockchain, limiting its \ncapabilities, and providing a false sense of security. As more look to permissioned blockchains to modernize traditional applications, there are \nseveral requirements that need to be addressed. For example, privacy and confidentiality on the \nblockchain, transaction scalability, and blockchain-to-blockchain connectivity. While theres \nongoing active research in these areas across several open-source communities, permissioned \nblockchains need to further evolve to fully meet the needs of the government user. 18 Bibliography \nBigchainDB. (2017). Retrieved from BigchainDB: https://www.bigchaindb.com/ \nBlock Confirmation. (2016). Retrieved from Bitcoin Wiki: https://en.bitcoin.it/wiki/Confirmation \nblockchain apps for healthcare. (n.d.). Retrieved from CIO:  https://www.cio.com/article/3042603/innovation/blockchain-applications-for-\nhealthcare.html Blockgeeks. (2017). Retrieved from Blockgeeks: https://blockgeeks.com/ \nBuild a better credit bureau. (2016). Retrieved 2017, from American Banker: https://www.americanbanker.com/news/can-blockchain-be-used-to-build-a-better-credit-\nbureau Byzantine Fault Tolerance. (2017). Retrieved from Wikipedia: \nhttps://en.wikipedia.org/wiki/Byzantine_fault_tolerance Coinmarket Cap. (2017). Retrieved from Coinmarket Cap: https://coinmarketcap.com/ \nCosmos Whitepaper. (2017). Retrieved from Cosmos: https://cosmos.network/whitepaper \nDecentralized Access Control. (n.d.). Retrieved from HYPR Corp: https://www.hypr.com/decentralized-authentication/ \nDeterministic System. (2017). Retrieved from Wikipedia: https://en.wikipedia.org/wiki/Deterministic_system \nDHS awards blockchain grant. (n.d.). Retrieved from Nasdaq: http://www.nasdaq.com/article/department-of-homeland-security-awards-blockchain-\ntech-development-grants-for-identity-management-and-privacy-protection-cm667365 DHS Awards Blockchain grant of Identity Managment. (2016). Retrieved from Nasdaq: \nhttp://www.nasdaq.com/article/department-of-homeland-security-awards-blockchain-\ntech-development-grants-for-identity-management-and-privacy-protection-cm667365 Double Spend Problem. (2017). Retrieved from Wikipedia: \nhttps://en.wikipedia.org/wiki/Double-spending Enterprise Ethereum Alliance. (2016). Retrieved from Enterprise Ethereum Alliance: \nhttps://entethalliance.org/ Ethereum Blockchain Application Platform. (2015). Retrieved from Ethereum : \nhttps://www.ethereum.org/ healthcare information tech. (n.d.). Retrieved from Becker Hospital Review: \nhttps://www.beckershospitalreview.com/healthcare-information-technology/9-things-to-\nknow-about-blockchain-in-healthcare.html Hyperledger. (2017). Retrieved from Hyperledger: https://hyperledger.org/ \nHyperledger Fabric. (2016). Retrieved from Hyperledger Fabric: https://www.hyperledger.org/projects/fabric \nIEEE: Do you need a blockchain. (n.d.). Retrieved from IEEE Spectrum: https://spectrum.ieee.org/computing/networks/do-you-need-a-blockchain \nIntroduction to Tendermint. (2016). Retrieved from Tendermint: https://tendermint.readthedocs.io/en/master/introduction.html \nIPFS Distributed Web. (2016). Retrieved from IPFS: https://ipfs.io/ \nMembers. (n.d.). Retrieved from Enterprise Ethereum Alliance: https://entethalliance.org/ \nMerkle Tree. (2017). Retrieved from Wikipedia: https://en.wikipedia.org/wiki/Merkle_tree \nNakamoto, S. (2009). Bitcoin: A Peer-to-Peer Electronic Cash System. \nNarayanan, A., Bonneau, J., Felten, E., Miller, A., & Goldfeder, S. (2016). Bitcoin and Cryptocurrency Technologies. 19 Non-interactive zero-knowledge proof. (2017). Retrieved from Wikipedia: \nhttps://en.wikipedia.org/wiki/Non-interactive_zero-knowledge_proof Ongaro, D., & Ousterhout, J. (2014). In Search of an Understandable Consensus Algorithm. \nPentagon has the world largest logistic problem. (n.d.). Retrieved from Defense One: http://www.defenseone.com/ideas/2017/10/pentagon-has-worlds-largest-logistics-\nproblem-blockchain-can-help/141500/ Polkadot. (2017). Retrieved from Polkadot: https://polkadot.io/ \nQuorum. (2016). Retrieved from JP Morgan: https://www.jpmorgan.com/country/US/en/Quorum \nQuorum Overview. (n.d.). Retrieved from Github: https://github.com/jpmorganchase/quorum/wiki/Quorum-Overview \nRaiden Network. (2017). Retrieved from Raiden: https://raiden.network/ \nReitwiessner, C. (n.d.). zkSNARKS in a nutshell. Retrieved from Ethereum Blog: https://blog.ethereum.org/2016/12/05/zksnarks-in-a-nutshell/ \nTech Insight: Blockchain. (n.d.). Retrieved from VA: Office of Information Technology: https://www.oit.va.gov/library/programs/ts/ti/2017/blockchain.pdf \nTendermint Blockchain Consensus. (2017). Retrieved from Tendermint: https://tendermint.com/ \nWhat are State Channels. (2016). Retrieved from State Channels: https://blog.stephantual.com/what-are-state-channels-32a81f7accab 20 Acronyms Acronym Definition ABCI Application Blockchain Interface \nBFT Byzantine Fault Tolerant \nCPU Central Processing Unit \nDAPPS Decentralized Applications \nDHS Department of Homeland Security \nDoD United States Department of Defense \nDSA Digital Signature Algorithm \nECDSA Elliptic Curve Digital Signature Algorithm \nEMR Electronic Medical Record \nEVM Ethereum Virtual Machine \nFDA Food and Drug Administration \nHIE Health Information Exchange \nIoT Internet of Things \nIPFS InterPlanetary File System \nKSI Keyless Signature Infrastructure \nMTA Message Transfer Agents \nP2P Peer to Peer \nPBFT Practical Byzantine Fault Tolerance \nPIN Personal Identification Number \nPoW Proof of Work \nPGP Pretty Good Privacy \nS&T Science and Technology \nTPS Transaction Per Second \nVA Veterans Affairs \nzk-SNARKS Zero-Knowledge Succinct Non-Interactive Argument of Knowledge ",
    "text": " 1 Principal Simulation Modeling Engineer, M/S 450, AIAA Senior Member, MST Committee member.\n2 Lead Computer Scientist, M/S 450.\n3 Senior Principal Aviation Systems Engineer, M/S 450, Associate Fellow AIAA.\n4 Principal Software Application Developer M/S 450, Member AIAA. Generating Diverse Reroutes for Tactical Constraint \nAvoidance Christine Taylor1, Sheng Liu2, Craig Wanke3, and Timothy Stewart4\nThe MITRE Corporation, McLean, VA 22102 Decision support capabilities that provide flight-specific reroutes around constraints can enable more flexible and agile management of the airspace. For this benefit to be realized, automation must reliably provide operationally-acceptable alternatives to traffic managers. This paper proposes an approach for generating a small number of diverse, feasible solutions for further evaluation by traffic managers. Using a variation on Dijkstras shortest path algorithm, reroutes are designed for one or more flights, where multi-flight problems promote the active design of reroute flows. A multi-objective genetic algorithm is employed to evaluate trade-offs between multiple criteria of operational acceptability, removing the need to pre-define relative metric weightings. Finally, a combination of Principal Components Analysis and Spectral Clustering is used to identify distinct groups of solutions and representative reroutes that capture different trade-offs between metrics of operational acceptability. Results are generated for a historical convective weather event and evaluated for their characterization of the trade-space. IntroductionI.\nN todays operation, if a flights route is blocked by convective weather or other en-route capacity constraints, a traffic manager must manually identify, coordinate, and communicate an alternate route. Developing individualized solutions is time-consuming; if a high number of flights are expected to be impacted, large-scale traffic management actions (e.g., airspace flow restrictions, adherence to published routes, etc.) are issued instead. To capture all targeted flights, these large-scale actions must be issued well in advance of the predicted constraints. Given the uncertainty in both traffic and constraint forecasts, these restrictions may ineffectually or even unnecessarily impact flights. To make the best use of available capacity, a more dynamic and agile traffic I management response is needed. Decision support capabilities that reliably provide traffic managers with viable alternatives in the tactical (under 90 minutes) timeframe can attain the benefits sought. Reliability is key for successful deployment traffic managers must trust that the automation will identify alternatives for most, if not all flights. Furthermore, these alternatives must be operationally acceptable, providing traffic managers with real options. However, as automation may not fully capture the operational environment, returning multiple, distinct solutions increases the likelihood that at least one option is viable. The challenge is that operational acceptability is determined by numerous factors which are often difficult to express and vary based on the overall environment. Published routes are pre-coordinated to ensure their acceptability; however, these routes provide few options for avoiding large-scale constraints, especially weather, which may block the predominant jetways. Given the dynamic nature of the constraints, research has focused on generating larger option spaces, trading increased reliability of returning a solution for potential loss in operational acceptability of the solution. Route-based approaches extend the option space to include historically-flown routes, as these solutions are more likely to be operationally acceptable and are fast to construct and evaluate. However, the challenge of finding constraint-free solutions using this approach persists for the same reasons as noted above [1]. Extending the option space to include alternatives constructed by modifying established routes can work well within restricted airspaces, such as the terminal area [2, 3], but these are not readily extensible to all airports (due to a paucity of published departure/arrival routes and/or the constraints blocking all such routes) or airborne flights (due to limited variability in the routes defined between the origin and destination pair). In contrast, free space approaches provide the greatest degree of flexibility as they are not constrained to conform to airspace structures (i.e., fixes, waypoints, routes). Generally, approaches in this category overlay a grid of nodes with connections defined between adjacent points. Weather or other airspace constraints can be captured by removing affected nodes or penalizing impacted arcs [4]. One advantage of these approaches is that efficient graph- based optimization algorithms (e.g., Dijkstras Shortest Path (DSP) Algorithm [5]) can be used to generate the least- cost reroute, where factors other than distance can be used to compute arc costs [6, 7]. However, graph-based optimization approaches are limited to direct evaluation of arc costs; path-dependent evaluation criteria must be measured post-optimization. Iterative post-optimization of shortest path reroutes can improve the viability of these reroutes [8]. An intermediate approach proposed in our previous work [9] defines a network constructed from historically- flown fix-pair segments, which are derived by decomposing historically-flown routes into a string of named fixes and airports. Each pair of points is defined as a fix-pair to highlight the historical directional connection between them. The network creation was inspired by terrestrial routing research [10], where any existing roadway can be considered as a possible segment of a reroute. Extending this concept to air traffic rerouting implies that any previously-flown segment can be included in a reroute, even if it is not normally used by traffic travelling between the origin and destination pair of the flight. Formal optimization approaches can be applied to these networks, but enhancements are required to increase the operational acceptability of the reroutes generated. In Reference [9], a K-shortest path algorithm is used to generate multiple (top K) paths through the network. Returning multiple paths overcomes the limitations associated with generating only a single option, as the reroute is constructed based on a limited set of criteria. However, we found only modest improvements were realized as there was little variation among the reroutes returned. This paper builds upon previous research, employing a combination of algorithms that can generate a small number of distinct, operationally-acceptable solutions. The solution process begins with a Problem Set, a group of flights which are encountering a common constraint (typically weather) and should logically be considered for coordinated rerouting. Using a variant of DSP, termed DSP-M, a larger and more diverse set of candidate reroutes is generated for each flight from the fix-pair segment network. Advisory Sets, which define the coordinated set of reroutes for the multi-flight problem, are constructed using a Multi-Objective Genetic Algorithm (MOGA). The MOGA evaluates each Advisory Set against a number of metrics which characterize different aspects of operational Fig. 1 Flow Diagram of Proposed Approach 5 The current implementation defines distance based on miles flown, however, wind could be readily incorporated. acceptability. The MOGA returns the trade-space of good solutions without requiring that the relative importance of each metric be pre-specified. A combination of Principal Components Analysis (PCA) and clustering reduces the number of Advisory Sets while maintaining the desired diversity. Fig. 1 depicts the proposed solution approach. This paper begins with a brief overview of the operational-acceptability metrics that define the solution trade- space. Section III describes the process of generating flight-specific reroutes using DSP-M and the coordinated reroute Advisory Sets using MOGA. Section IV introduces PCA and discusses how the principal components can be used to identify a reduced number of diverse Advisory Sets. Section V illustrates the proposed approach using a historical convective weather example involving nine (9) flights. The analysis shows that first, DSP-M can reliably generate reroutes for tactical constraint avoidance and that PCA can capture critical trade-offs within a multi-metric space. The reroutes corresponding to three selected Advisory Sets are visualized, highlighting the ability to naturally identify coordinated reroute flows for the multi-flight problem. This section finishes with a discussion on the extensibility of the approach and continuing work. Section VI summarizes the contributions of the paper. Evaluating Operational AcceptabilityII. The operational acceptability of a reroute is determined by many factors, where the relative importance of each factor may vary based on the current operational environment. Drawing on previous work, this paper evaluates reroutes based on ten metrics, which are grouped into five categories for convenience. The metrics are outlined qualitatively here due to space limitations, but full detail can be found in the references [1, 9, 11-14]. We readily acknowledge that the metrics considered are by no means exhaustive, but posit that the groupings characterize the set of important considerations and trade-offs and as such, the value of the proposed approach can be demonstrated regardless of the specific metric calculations used. Measures of Design AcceptabilityA.\nDesign acceptability metrics characterize the geometric properties of the route with respect to airspace geometry and nominal operating procedures. In this paper, we define two metrics to characterize design acceptability; distance and flow conformance. Distance Metric1.\nA proposed reroute can either increase or decrease the length5 of the route, where a decrease is preferable. However, any change is more impactful if the flight is already active (within 20 minutes of departure or already en route) as the flight has already been fueled. The distance cost computes the change in distance between the proposed reroute and original route, where decreases are rewarded. The metric is scaled between zero and one where the proportional effect of the distance difference is weighted depending on whether the flight is
active [9, 11]. Flow Conformance Metric2.\nWhen large, severe weather systems occur, greater deviation from the original route may be required to define a good reroute that avoids the weather. As it is preferable to employ reroutes that contain highly utilized segments, the flow conformance of a reroute is defined as the sum of the usage fractions on the fix-pairs in the reroute, where the usage fraction of a fix-pair is the usage count of that fix-pair divided by the total usage of all fix-pairs in the network [9]. Note that, while this metric will reward options that follow typically-used air traffic patterns, it does not necessarily capture all norms set down in letters of agreement (LOA) between facilities or in facility standard operational procedures (SOP). However, for avoidance of severe constraints, it may be desirable or necessary to violate such rules, and thus options that do so may be acceptable [11]. Measures of Management AcceptabilityB.\nMetrics of management acceptability capture challenges associated with issuing a reroute. In this paper, we define three metrics of management acceptability: coordination, return to original route, number of segments. Coordination Cost1.\nIf a proposed reroute includes one or more new segments that are outside of the current controlling facility, additional coordination is required to issue the reroute it. The coordination cost is the accumulation of costs associated with each additional Air Route Traffic Control Center (ARTCC) that the reroute traverses. The specific values for each ARTCC are relative to the controlling facility, with neighboring ARTCCs incurring lower costs than ones farther away [11]. Return to Original Route2.\nIf a reroute doesnt return to the original route prior to arrival at the destination airport, additional coordination may be required to ensure conformance with the airports arrival routes and/or configuration. As such, a unit cost penalty is incurred for reroutes that do not rejoin the original route prior to the destination airport [1]. Reroute Complexity3.\nReroutes that contain multiple fixes are more difficult to issue than ones with fewer fixes. To discourage the generation of reroutes that are marginally more efficient but have a large number of fixes, a cost, proportional to the number of fixes, contained in the reroute is assessed. Only fixes between the deviation and rejoin points are considered, and reroutes that include ten or more points incur the same, maximum cost. As with the other metrics, the route string length cost is bounded between zero and one [11]. Measures of Constraint AvoidanceC.\nEn route constraints arise when there is a reduction or loss in airspace capacity. Frequently, convective weather is the driving constraint for a reroute; however, flights planning to fly through congested sectors or restricted airspace regions may necessitate that a reroute be issued. As weather and the associated forecast uncertainty is the most frequent constraint, we define two metrics: route blockage and blockage probability. The final metric, sector congestion, evaluates the impact of reduced airspace capacity (due to reasons other than convective weather). Route Blockage1.\nThe route blockage metric penalizes reroutes that intersect predicted weather areas with discounted penalties for incursions further in the future, to account for forecast uncertainty. Specifically, a two-hour convective weather prediction is divided into eight 15-minute intervals [12]. For each interval, the proposed reroute is compared to the predicted weather location using a geographic grid overlaid on the affected region [11]. Furthermore, this blockage is altitude dependent, as thunderstorms have varying tops, and can sometimes be safely overflown. (This is discussed further within the context of the Blockage Probability metric described next.) The first 15-minute interval determined to contain a weather blockage is used as an index to calculate the cost. Blockages occurring earlier in the reroute are assigned higher weights (costs), since weather prediction is more certain. Table 1 lists the cost weights applied for the eight quarter-hour intervals of the two-hour horizon: Table 1 Route Blockage Cost Weights Prediction Index (15-minute prediction \ninterval) Weight (cost) 1 1.0 2 0.875 3 0.750 4 0.625 5 0.500 6 0.375 7 0.250 8 0.125 When a route segment is predicted to be blocked by weather, the cost factor of the first prediction interval containing the blockage is applied. If no blockage is predicted during any interval of the two-hour prediction range, then the cost is set to zero. These cost weight values are based on a simple assumption of linearly-decreasing weights with prediction time, which should be validated by future research. Blockage Probability2.\nBlockage probability, on the other hand, measures the relative likelihood of constraint incursions as compared to the original route. The goal of this metric is to encourage reroutes that reduce the likelihood of using constrained areas, even if the existence or severity of the constraints is uncertain [12]. For this metric, researchers identified flight and situational factors that would estimate the probability that a flight will deviate around weather. The analysis relies on the identification of a Weather Avoidance Field (WAF) [13]an airspace volume predicted to contain severe weather, that pilots are likely to avoid. Using contingency table analysis, five factors were identified for predicting a flight deviation: WAF Altitude: The top of the WAF along the blocked segment Altitude Difference: The highest WAF altitude minus flight altitude: the difference is evaluated as Positive or Zero/Negative Problem Length: The distance in nautical miles along the blocked segment Prior Avoidance-1: An exponentially weighted moving average of the weather avoidance behavior of earlier flights (i.e., earlier on the same day) experiencing weather impacts in the sector where a flight path deviation will likely commence Prior Avoidance-2: An exponentially weighted moving average of the weather avoidance behavior of earlier flights (on the same day) experiencing weather impacts in the sector where the weather blockage occurs Other factors were examined (e.g., airline, aircraft performance, and arrival ARTCC), but were not found to be useful. The five identified factors were considered together to estimate the probability that a flight will suffer a path and/or altitude deviation due to weather. Details regarding the proposed calculation of probability from each of these factors can be found in [1] We note that the blockage probability metric can be readily extended to capture predicted interactions with non-weather constraints. Sector Congestion3.\nAn important consideration when developing a reroute is whether the new advisory will contribute to congestion. Sector congestion occurs when the number of flights within a 15-minute period exceeds the nominal or weather- impacted sector capacity [11]. To predict sector congestion, demand forecasts are compared to predictions of future sector capacity, which is nominally defined by the Monitor/Alert parameter (MAP), and provides both a moderate and severe alert threshold. To compute the contribution to sector congestion associated with a proposed reroute, the trajectory is analyzed to determine when the flight would be in each sector proposed by the advisory. By comparing this schedule to the sector congestion alerts, the proportional impact of the proposed trajectory is computed. The accumulated impact along the route is returned as the sector congestion contribution of the reroute. Note, that closed sectors can be viewed as having no capacity and reroutes using this airspace can be penalized or even removed from consideration. Metrics of Flight Operator AcceptabilityD.\nIf severe weather or congestion requires a flights filed plan to be amended using a reroute, it is highly desirable that the change not affect the airlines operating schedule. Although different flight operators have different operational plans, it is reasonable to assume that the longer the delay, the more severe the impact, where delay is the difference between the estimated arrival time of the advisory and the original route, binned into 15-minute intervals. Furthermore, the impact on the schedule depends on the flights departure time, which is binned into 30-minute intervals between 6am and midnight local time. Delays incurred earlier in the day are more likely to produce delays later in the day, and thus are assigned a higher solution cost. As such, the airline schedule disruption metric captures the non-linear impact that delay can have on an airlines operation [14]. Flights in Flow MetricE.\nThe final metric, flights in flow, is distinguished from the above metrics as it evaluates the joint relationship of reroutes within the Advisory Set. Generating routes with common consecutive segments is valuable to traffic managers as it reduces the coordination effort required for rerouting subsequent flights. In addition, generating reroute flows creates structure in the airspace, a benefit when operating in an off-nominal environment. This paper proposes the flights in flow metric to reward Advisory Sets that contain reroutes that share consecutive common segments. Note that no artificial constraints are imposed the algorithm does not specify which flights will form flows nor does it constrain where flows begin and end. Instead, the metric computes the Longest Common Segment (LCS) between each pair of reroutes in the Advisory Set. The LCS does not measure physical distance, as we are interested routes that use the exact same segments, as opposed to nearby routes; instead it calculates the number of consecutive shared fixes between two paths. The LCS is the length of the longest sequence. Recall that candidate reroutes
are generated for each flight using the DSP-M algorithm. For a given flight f, we define the candidate reroute transiting through the specified intermediate node as . If we define to be the LCS between and , then the similarity of the Advisory Set is defined as (1) where refers to the set of flights defined in the Problem Set. Note, the notation in simply implies that the intermediate node m need not be the same as in . Evaluating Reroute AcceptabilityF.\nA common approach for evaluating a solution against multiple metrics is to compute the weighted sum, resulting in a single measure of reroute acceptability. This approach requires the set of weights, which capture the relative importance of each metric in the overall decision, be pre-specified. These pre-specified weights would need to be validated for such an approach to be used within real operations. The alternate approach proposed in this paper is to compute the Pareto Set of solutions. The Pareto set is defined as the set of non-dominated solutions, where one solution is said to dominate another if at least one of the metrics is better than the corresponding metric from a second solution, and if none of the other metrics is worse than those of the second solution. Put another way, the Pareto set includes all the best solutions, in that any solution not in the Pareto set is inferior to any solution in the set. Fig. 2 depicts a simple example of a Pareto Set, representing the trade-off between metric A and metric B. Note that in this example, we seek to minimize metric A but maximize metric B. The Utopia Point (which is hypothetical and not a potential solution) refers to the desired performance direction, namely lowest values of metric A and highest values of metric B. Viewing Fig. 2, the four solutions in the Pareto Set are represented as filled circles while the other dominated solutions are shown as smaller, un-filled circles. This section defined 10 metrics, each of which will create a dimension in the Pareto Set. The first nine metrics defined in Section II.0-II.D are evaluated against individual reroutes, producing nine values for each flight in the Advisory Set. The corresponding Advisory Set score for each metric is the sum of the scores for the individual flight reroutes, where the goal is to minimize these metrics. The final metric, flights in flow, is calculated by first comparing the LCS between each pair of flights in the Advisory Set, then summing these values, as described in Section II.E. For this metric, we seek solutions that maximize value. Generate Candidate Advisory SetsIII. This section describes the approach for generating reroutes and subsequent Advisory Sets that provide a small number of diverse solutions for further evaluation by traffic managers. First, reroute candidates are defined for each flight using a variation of the DSP algorithm. The MOGA evaluates how combinations of these reroutes produce Advisory Sets that characterize useful trade-offs between the multiple metrics generated. For example, one set might produce the lowest additional flying time across flights, while another would group most of the flights along a common route segment to promote operational \nFig. 2 Description of Pareto Front acceptability. Network OptimizationA.\nThe first step in the proposed approach generates a candidate pool of reroutes for each flight. The flights are generated as paths through a network constructed from fix-pairs [9]. This section briefly describes the steps required to create the network and generate flight-specific reroutes using the DSP-M algorithm. Constructing the Network4. The original route of flight is deconstructed into the route string the set of fixes from the current position to the destination airport. The deviation point, , is the first fix on the original route from which the reroute can diverge and will correspond to the departure airport if the flight is not yet active. Similarly, the rejoin point, , is the final fix on the original route at which the reroute can reconnect, nominally at the destination airport. Using the method proposed in [9], the geographic boundary of the network is calculated as an ellipse encompassing the original route between the deviation and rejoin points, as shown in Fig. 3. The orientation of the ellipse corresponds to the direction of the great circle route connecting the deviation () and rejoin point (). The semi-major axis of the ellipse is calculated as half the total length of the great circle route plus the deviation and rejoin buffer distances, denoted as and , respectively. The buffer distances are defined to provide flexibility for maneuvering on or off the original route. Furthermore, when either the deviation or rejoin point correspond to an airport, the corresponding buffer is set to a higher value to include alternate departure and arrival fixes in the Fig. 3 Depiction of Flight Specific Ellipse network. The semi-minor axis is defined to be either of the semi-major axis or 100 nm greater than the maximum lateral deviation [9] of the original route with respect to the great circle distance. The reroute network for flight , denoted as , is defined as the subset of fix-pair segments drawn from a database of historically-flown reroutes (denoted as FF) contained within the ellipse. The fix-pair segments or arcs are defined as , . (2) The original route is included in the network to ensure connectivity and provide increased flexibility for diverging from and reconnecting to the original route. Measuring Costs in a Network5. Each arc in the network has an assigned cost , which may be different for each flight using arc . The arc cost can represent a weighted sum of multiple measures; however, all measures must be defined solely based on the arc and not the path that may include the arc (as many different paths can contain the same arc in a different sequence). Based on previous analyses, we define three arc cost measures: normalized great-circle distance, flow conformance and weather avoidance [9]. The arc cost is defined as the sum of these three measures. Generating Reroute Candidates6.\nThe candidate set of reroutes for each flight is generated using a variation of the DSP algorithm, referred to here as DSP-M, where the M represents the inclusion of a specified intermediate node through which the shortest path is constrained to pass. Although DSP-M does not generate shortest paths, it produces a more diverse set of candidates, potentially resulting in solutions with higher operational acceptability. For every flight f, the sub-network ; however, for computational efficiency, it is beneficial to further constrain this relationship. To encourage reroute flows within the multi-flight context, the selection of can be constrained to identify nodes common to multiple networks. As such, we define that for every node there exists some pre-specified number of flight-specific networks such that . DSP-M generates candidate reroutes using the following approach. Given a node , the shortest path from to is computed using DSP. DSP also computes the shortest path from to . The two paths are concatenated and the repetitive is removed. The process repeats until all nodes have been evaluated. Multi-Objective Genetic AlgorithmB. Each flight can have as many as paths, potentially resulting in unique Advisory Sets. Given the exponential growth of the design space, enumeration of all possible sets is prohibitive. Instead, a MOGA is employed to conduct an intelligent search and identify optimal trade-offs between the operational acceptability metrics. Algorithm Overview1.\nA Genetic Algorithm (GA) is a heuristic optimization approach that emulates biological evolution [15]. Each individual or chromosome corresponds to a candidate Advisory Set and the genes in the chromosome specify which DSP-M generated reroute is selected for each flight. The fitness of each individual (Advisory Set) is calculated using the operational acceptability metrics described in Section II. For the first nine metrics, the MOGA computes the sum of each metric as evaluated against the individual reroutes specified in the chromosome. The final metric, flights in flow, is evaluated using the definition provided in Section II.E. Based on their individual fitness, pairs of individuals are selected to populate the successive generation. A pair of parent solutions swap portions of their chromosomes (i.e. sections of their design vectors) via a cross-over operation to generate offspring for the subsequent generation. The GA introduces random changes to individual genes (single parameter values) during a mutation operation to maintain parameter diversity and search the design space beyond local minima. This process continues until the specified termination criteria is met, nominally a fixed number of generations. Creating the Pareto Set2.\nFor multi-objective genetic algorithmswhich evaluate multiple criteria to define the fitness of individualswe instead consider the set of non-dominated solutions. To obtain the Pareto Set of solutions, we use the non-dominated sorting genetic algorithm II (NSGA-II) [16]. The NSGA-II selects parents in a generation based on their non- dominance rank and crowding distance. The non-dominance rank of a solution roughly evaluates how close to the Pareto front the solution is. Specifically, if we assign a non-dominance rank of 1 to the global Pareto front, then the set
of non-dominated solutions after removing the global Pareto front has non-dominance rank of 2, and so on. The algorithm then sorts solutions within each non-dominance rank based on their crowding distance, or the average Euclidian distance from each solution to its nearest neighbors with the same non-dominance rank. Solutions farther from their nearest neighbors are more desirable for selection in order to promote more uniformly spaced fronts. The set of non-dominated solutions consists of Advisory Sets that provide the best trade-offs between the multiple metrics considered. The MOGA populates the Pareto front with solutions from every generation, if qualified. Therefore, the result may contain more solutions than the population of a single generation. Generating Advisory SetsIV. The Pareto Set identified by the MOGA is likely to contain many more solutions than can be evaluated and therefore clustering approaches are typically used to identify a smaller number of distinct solutions [17, 18, 19]. However, for large-dimensional trade-spaces, direct evaluation is likely to obscure the key trade-offs sought. As such, this paper proposes to use PCA to identify correlations within the trade-space, reducing the dimensionality of the problem. Spectral clustering is performed on the reduced dataset and representative solutions that characterize critical trade-offs that persist can be readily identified for further evaluation. Principal Components AnalysisA.\nPCA is a mathematical approach for identifying the rotation matrix of the axes such that the primary axis (first Principal Component, PC1) captures the maximum variation within the Pareto Set. Each subsequent axis is orthogonal and aligns with the next highest direction of variation. Each solution in the Pareto Set corresponds to a point in the objective space, defined by its value for each metric, and therefore, solutions can be expressed as linear combinations of metric values. The correlation matrix, which characterizes the relative co-variation between these metrics, can be readily computed. Using matrix algebra, the correlation matrix is then transformed into its diagonal components, or eigenvalues. The corresponding eigenvectors provide new directions for the coordinate axes. The directions are ordered by the magnitude of the eigenvalues, where the largest eigenvalue defines the first principal component. The number of principal components is the same as the original dimension (10, in this case). However, as the variation captured by later components is often quite small, these dimensions can be ignored with little loss in representation. As a general rule, only components with corresponding eigenvalues greater than one are needed to adequately represent the trade-space. Clustering the Pareto SetB.\nClustering can now be done using the remaining principal components. Specifically, a modified spectral clustering algorithm [20] iteratively partitions a group of solutions into two until the stopping criteria are reached. This algorithm does not require that the number of desired groups be determined a priori. Rather, it employs scale factors for the number of nearest neighbors considered to define the mean and variance of a given cluster, which can be tuned to produce a reasonable number of clusters. Selecting Representative SolutionsC.\nWithin each cluster, a single Advisory Set is selected to represent that corresponding portion of the trade-space. As such, it is desirable that the Advisory Set contains the reroutes most common among these solutions. To evaluate the relative importance of each flights reroute to the cluster, we calculate the central design for each cluster using the approach developed in [21]. The central design of a cluster is defined by the most common reroutes selected for each flight. Specifically, if we consider to be the set of design vectors in cluster , then we can compute the probability mass function for the values of each design attribute , denoted as . Using the probability mass function, we can then define the most common value for each design attribute as well as its frequency of occurrence for the specified attribute across the cluster of design vectors. (3) (4) As the design vector may not correspond to an existing Pareto Set solution, we seek the closest Pareto solution to this vector. The distance between a Pareto solution and the central design measures whether two attributes have the same value. As such, the most prominent attributes of the cluster (in our example, reroute candidates) will be part of the representative solution. To compute categorical distance, we use the weighted Jaccard distance [22], where the weights are defined by the frequency of the most common value. If each solution in is described by a design vector, , consisting of design attributes, the Jaccard distance, is defined as shown in Equation 5. (5) Here, represents the logical and, and represents the logical or. The representative solution for the cluster corresponds to the design with the lowest Jaccard distance to the central design. Results and AnalysisV.\nA historical example used to evaluate the proposed approach involves nine flights requiring reroutes around convective weather, as illustrated in the snapshot shown in Fig. 4. Fig. 4 Snapshot of Convective Weather Blocking Routes for Nine Flights on 20 April 2009 at 20:30 Using DSP-M, reroute candidates were generated for each of the nine flights, showing the reliability of the \napproach. Table 2 lists the origin and destination of each flight and the number of candidates generated. The final \ncolumn in Table 2 lists the color used to display each flights reroute in the figures at the end of this section. Viewing Table 2 we note that the number of candidates varies by flight, which has implications for the diversity in Pareto Set solutions. However, this candidate pool still results in 1.8 x 10^17 possible Advisory Sets. Due to the size of the design space and to ensure that the 10-D trade-space is adequately populated, the MOGA returns 5000 Pareto-optimal solutions. Application of Principal Components AnalysisA.\nThe Principal Components of the Pareto Set are shown in Fig. 5. Figure 5a (left) displays, in descending order, the ten eigenvalues of the correlation matrix which indicates the variation captured in each corresponding direction. The line to the right of the bars indicates the cumulative variation captured by each subsequent principal component, Table 2 Flight Origin, Destination, Number of Options and Reroute Color Flight Origin Destination # Color A Westchester County (HPN) Raleigh Durham International (RDU) 64 White B LaGuardia (LGA) Raleigh Durham International (RDU) 62 Green C Reagan National (DCA) Charleston International (CHS) 17 Dark Blue D Norfolk International (ORF)\nOrlando International (MCO) 84 Red E Raleigh Durham International (RDU) Reagan National (DCA) 90 Aqua Blue F Charlotte Douglas International (CLT) LaGuardia (LGA) 275 Yellow G Hartsfield Jackson Atlanta International (ATL) LaGuardia (LGA) 272 Green H Baltimore Washington International (BWI)\nNorfolk International (ORF) 15 Light Yellow I Hartsfield Jackson Atlanta International (ATL) LaGuardia (LGA) 322 Dark Yellow Fig. 5 Principal Components: left (a) displays eigenvalues and cumulative variation, and right (b) \ndisplays eigenvectors of the first two principal directions revealing that over 80% of the variation is captured by the first two components. As subsequent components have \neigenvalues less than one, the remainder of this analysis focuses on these first two principal components, referred to \nas PC1 and PC2, respectively. Fig. 5b (right) lists the correlation of each original metric to these first two directions. PC1, which accounts for 64% of the variation in the Pareto Set, has a strong correlation with all but 2 metrics of operational acceptability. These metrics, Route Blockage and Schedule Disruption, are instead correlated with the second direction, PC2, which accounts for an additional 18% of the variation. To understand these correlations intuitively, we refer to the metric categories described in Section II. The first category, design acceptability, is defined by two metrics, distance and flow conformance, where low values of each indicate higher acceptability. The correlation between these metrics and PC1 is 96% and 71%, respectively, implying that solutions with low PC1 values have higher design acceptability. Similarly, the metrics defining management acceptability, namely coordination, return to route and number of segments have correlations of 79%, 98% and 91%, respectively, with PC1. Again, as low values in the original metrics indicate better management acceptability, solutions with low values of PC1 will exhibit better management acceptability. The flights in flow metric is also highly correlated with PC1; however, the positive correlation here is misleading. Recall from Section II.0, that the flights in flow metric computes the number of consecutive common segments between reroutes in the Advisory Set. As such, Advisory Sets with high values in PC1 will have more reroutes organized into flows. This relationship indicates the first critical trade-off for this example. The final two metrics with high correlations to PC1 are sector congestion (81%) and blockage probability (91%). Recall that PCA characterizes the variations exhibited by solutions in the Pareto Set, which is problem-specific. In this example, little variation in blockage probability is exhibited by any of the candidates listed in Table 2 and the small variations that exist are due to differences in the underlying reroutes in the Advisory Set, and thus can be correlated with the other metrics, for example distance. For sector congestion, the lack of variation is due to the selection of reroutes included in the Pareto
Set of solutions. Although the original candidates show variations in performance with respect to sector congestion, the Advisory Sets defined by the MOGA include only reroutes that exhibit the lowest (best) sector congestion. By capturing these relationships explicitly, PCA readily identifies the critical trade-offs that exist in the set of candidates returned. The remaining two metrics, route blockage and schedule disruption are inversely correlated with each other and Fig 6 Principal Components of Pareto Set Solutions highly correlated with PC2. The inverse relationship implies that Advisory Sets which perform better in schedule disruption (lower values) will be represented by solutions with low values in PC2, while solutions that perform better in route blockage (lower values) will be represented by solutions with high values in PC2. This inverse relationship identifies the second critical trade-off in the Pareto Set for this example. Fig 6 displays the Pareto Set of solutions as points in the two-dimensional space defined by PC1 and PC2. Fig 6 is annotated to include the relationship between the principal components and the original ten metrics. In Fig 6, we see four distinct groups of solutions. These groups clearly capture the correlations between the original metrics represented in PC1, but which would likely have been obscured in a higher dimension space. Comparison of Pareto Set ClusteringB. To illustrate the benefits of reducing trade-space dimensionality, we employ the clustering procedure described in Section IV. Fig 7 shows the clusters and representative solution generated when clustering the solutions based on their similarity in the two principal components. Thirty-nine (39) clusters are generated and are distinguished by color in Fig 7. Within each cluster, the representative solution is shown as a rectangle. Viewing Fig 7 we see that Fig. 8 Comparison of Representative Solutions Across Critical Trade-Space Metrics. (Marker size \ncorresponds to Flights in Flow values) Fig 7 Clustering using Principal Components the associated distance versus schedule disruption \ntrade-offs, and flights in flow is shown by marker \nsize, where larger (higher) values indicate more \nAdvisory Sets that create more flows. Examining Fig. 8, we see the general trend between the trade-offs defined by PCA, namely that distance varies inversely with flights in flow and that route blockage varies inversely with schedule disruption. However, this trend is not universal, and solutions exist that balance these objectives. Specifically, the middle panel in Fig. 8 captures solutions that have different levels of schedule disruption for the same route blockage cost. Almost all representatives in this category were generated by the PCA-defined clusters; directly clustering the 10 metrics fails to capture this critical region in the trade-space. Comparison of Representative Advisory Sets C.\nThe gray arrows in Fig. 8 correspond to three Advisory Sets from different regions of this trade-space. These three solutions were selected to illustrate how the reroutes within these Advisory Sets characterize the associated trade-offs. Table 2 lists the color corresponding to each flights reroute. Fig. 9 shows the reroutes for Advisory Set 1, representing a solution that performs well in distance and route blockage, moderately in schedule disruption, but poorly in flights in flow. Viewing Fig. 9, we see that the reroutes move around the weather shown in Fig. 4 (corresponding to the airspace south of the Washington-area airports). As the flights in flow metric is not a priority for reroutes in this area of the trade-space, the reroutes do not generate flows. Fig. 10 shows the reroutes for Advisory Set 2, drawn from the critical trade-space identified in Fig. 8. Viewing the reroutes in Fig. 10, we see that several reroutes overlap for portions of their new route, forming the flows prioritized by solutions in this region of the trade-space. The most prominent flows are located in the NY-area region (top right of the figure), which is a particularly important area for adding structure. Fig. 11, displays the reroutes for Advisory Set 3, which prioritizes schedule disruption above all else. As Fig. 9 Reroutes in Advisory Set 1 expected, the reroutes are fairly direct; however, the high route blockage costs indicate that they do not avoid the primary constraint of the problem. DiscussionD.\nThe results generated by the proposed approach provide the reliability sought via the success rate for generating constraint-free solutions using DSP- M [1] while also characterizing the critical trade- space available to traffic managers for consideration. The above analysis highlights the value of PCA in reducing the size of the trade-space and identifying the critical trade-offs that exist. The resulting clusters show the benefit of reducing the design space in this manner, namely that critical trade-offs are better represented than through directly clustering all metrics, where the latter approach can overlook regions of the trade-space containing diverse solutions. However, both approaches still produce too many clusters for a traffic manager to evaluate and further reduction is needed. Although this is an area of continuing research, a few promising directions have been identified. First, PCA can be directly included within the MOGA, as suggested by Reference [23]. This approach would limit the size of the Pareto Set produced by the MOGA and could significantly reduce the computation effort required; however, additional analysis is required to ensure that the solutions generated would provide diverse and viable options to traffic managers. An alternate approach is to use PCA to identify persistent correlations between the multiple metrics \nFig. 10 Reroutes in Advisory Set 2 Fig. 11 Reroutes in Advisory Set 3 considered, potentially identifying a set of relative weightings that can be used to rank solutions. As opposed to a single static prioritization between metrics, this approach could propose multiple weightings, resulting in multiple solutions being returned. Furthermore, the selection of potential weightings could be influenced by problem-specific parameters. For example, if congestion isnt a major consideration, then weights that emphasize congestion-avoiding solutions could be replaced by weights that vary the importance of other metrics. Incorporating input from traffic managers, either in advance by selecting metrics of higher importance or post-computation by selecting to review Advisory Set reroutes based on the corresponding metrics prioritized by a given solution is likely required. It is not the aim of this approach to eliminate the need for this invaluable input, only to provide the best selection of reroutes for review. In either case, additional testing on multiple examples is required. Although this problem is representative of a convective weather situation, flights were limited to those that could be captured on a fix-pair segment network, an assumption that would need to be relaxed for more general applications. Furthermore, the computation time associated with the MOGA is relatively fast but not fast enough for real time. However, MOGA computation time is directly related to the size of the Pareto Set sought; insights gained through additional analysis can identify appropriate methods for reducing the Pareto Set and the associated computation requirements of the MOGA. ConclusionsVI.\nThis paper describes an approach for generating a set of weather/constraint avoidance reroutes for tactical traffic flow management applications. In this approach, multiple flights are considered in a coordinated way, and several feasible sets of reroutes (Advisory Sets) are produced that offer meaningful tradeoffs among important performance metrics. This will provide traffic managers with multiple, distinct options for resolving constraints, making it more likely that an operationally acceptable solution can be found quickly. The approach leverages multi-objective optimization, principal component analysis, and spectral clustering to characterize and search huge design spaces, and to isolate the critical design trade-offs that must be considered. Notice This work was produced for the U.S. Government under Contract DTFAWA-10-C-00080 and is subject to Federal Aviation Administration Acquisition Management System Clause 3.5-13, Rights In Data-General, Alt. III and Alt. IV (Oct. 1996). The contents of this material reflect the views of the authors and The MITRE Corporation and do not necessarily reflect the views of the FAA or the DOT. Neither the Federal Aviation Administration nor the Department of Transportation makes any warranty or guarantee, or promise, expressed or implied, concerning the content or accuracy of these views. Approved for Public Release; Distribution Unlimited. Case Number 18-0951. References [1] C. Taylor et al., Design of the SFMA Trajectory Advisory Function, MITRE Technical Report 160139, The MITRE Corporation, McLean, VA, June 2016. [2] J. Krozel et al., Automated Route Generation for Avoiding Deterministic Weather in Transition Airspace, AIAA Journal of Guidance, Control, and Dynamics, vol. 30, no. 1, pp. 144173, JanuaryFebruary 2007. doi: 10.2514/1.22970 [3] J. Prete and J. Mitchell, Safe Rerouting of Multiple Aircraft Flows in the Presence of Time-Varying Weather Data, in AIAA Guidance Navigation and Control Conference and Exhibit, Providence, RI, 2004. doi: 10.2514/6.2004-4791 [4] H. K. Ng, S. Grabbe, and A. Mukherjee, Design and Evaluation of a Dynamic Programming Flight Routing Algorithm using the Convective Weather-Avoidance Model, in AIAA Guidance, Navigation, and Control Conference, Chicago, IL, 2009. doi: 10.2514/6.2009-5862 [5] R. Ahuja, T. Magnanti, and J. Orlin, Network Flows: Theory, Algorithms, and Applications. Englewood Cliffs, NJ: Prentice Hall Inc., 1993. [6] S. Grabbe, B. Sridhar, and A. Mukerjee, Sequential Traffic Flow Optimization with Tactical Flight Control Heuristics, Journal of Guidance,
Control, and Dynamics, vol. 32, no. 3, pp. 811820, MayJune 2009. doi: 10.2514/1.40300 [7] S. Bokadia and J. Valasek, Severe Weather Avoidance using Informed Heuristic Search, in AIAA Guidance Navigation and Control Conference and Exhibit, Montreal, CA, 2001. [8] W. Heagy and T. Waters, Trajectory-Based Operations in Severe Weather, The MITRE Corp., McLean, VA, Doc. MTR100305, 2010. [9] C. Taylor and C. Wanke, Improved Dynamic Generation of Operationally Acceptable Reroutes using Network Optimization, Journal of Guidance, Control, and Dynamics, vol. 34, July 2011. doi:10.2514/1.52957 [10] D. Weyns, T. Holvoet, and A. Helleboogh, Anticipatory Vehicle Routing using Delegate Multi-Agent System, in Proceedings of the 2007 IEEE Intelligent Transportation Systems Conference, Seattle, WA, 2007. doi:10.1109/ITSC.2 [11] J. DeArmon and e. al, \"User Evaluation of Numeric Attributes of Automatically Generated Reroutes,\" 11th American Institute of Aeronautics and Astronautics (AIAA) Aviation Technology, Integration, and Operations (ATIO) Conference, Virginia Beach, VA, 2011. doi: 10.2514/6.2011-6847 [12] T. Stewart, J. DeArmon and D. Chaloux, \"Using Flight Information to Improve Weather Avoidance Predictions,\" in 13th American Institute of Aeronautics and Astronautics (AIAA) Aviation Technology, Integration, and Operations (ATIO) Conference, Los Angeles, CA, 2013. doi: 10.2514/6.2013-4377 [13] R. DeLaura and e. al, \"Modeling Convective Weather Avoidance in En Route Airspace,\" 13th Conference on Aviation, Range, and Aerospace Meteorology (ARAM), American Meteorological Society, New Orleans, LA, 2008. [14] R. Beatty and e. al, \"Preliminary Evaluation of Flight Delay Propagation through an Airline Schedule,\" 2nd USA/Europe ATM R&D Seminar, Orlando, FL, 1998. doi:10.2514/atcq.7.4.259 [15] A. P. Alves da Silva and D. M. Falcao, \"Fundamentals of Genetic Algorithms,\" in Modern Heuristic Optimization Techniques: Theory and Applications to Power Systems, K. Y. Lee and M. A. El-Sharkawi, Eds., Hoboken, NJ, John Wiley & Sons, Inc., 2008, pp. 25-42. [16] Deb, K., Pratap, A., Agarwal S., Meyarivan, T., A Fast Elitist Multiobjective Genetic Algorithm: NSGA-II, IEEE Transactions on Evolutionary Computation, Vol. 6, No. 2, pp. 182-197, April 2002, doi: 10.1109/4235.996017. [17] Rosenman, M., and Gero, J. S., Reducing the Pareto Optimal Set in Multicriteria Optimization Engineering Optimization, Vol. 8, No 3, pg 189-206, 1985, doi: 10.1 508902489 [18] Taboada, H., and Coit, D., Data Clustering of Solutions for Multiple Objective System Reliability Optimization Problems Quality Technology and Initiative Management Vol. 4, No. 2, pp 191-210, 2007, doi: 10.1.1.182.8638 [19] Zio, E. and Bazzo, R., A clustering procedure for reducing the number of representative solutions in the Pareto Front of multiobjective optimization problems, European Journal of Operational Research, Vol. 210, pp. 624-634, 2011, doi:10.1016/j.ejor.2010.10.021. [20] Tien, S-L., Taylor, C., and Wanke, C., Representative Weather-Impact Scenarios for Flow Planning, 2014 Aviation Technology, Integration, and Operations Conference, Atlanta, GA, June 2014, AIAA 2014-2714. [21] C. Taylor, T. Masek, and C. Wanke, Designing Traffic Flow Management Strategies using Multiobjective Genetic Algorithms Journal of Guidance, Control and Dynamics, Vol. 38, No. 10, 2015, pp. 1922-1934. doi: 10.2514/1.G000765 [22] Vereepa, V., Letier, E., Understanding Clusters of Optimal Solutions in Multi-Objective Decision Problems, 2011 IEEE 19th International Requirements Engineering Conference, 29 August 2 September 2011, pg. 89-98, Trento, Italy, doi: 10.1109/RE.2 . [23] K. Deb and D-K Saxena, On Finding Pareto-Optimal Solutions through Dimensionality Reduction for Certain Large- Dimensional Multi-Objective Optimization Problems 2006 IEEE Congress on Evolutionary Computing, January 2006. _top\n _Hlk507636863\n _Hlk507636847\n _Hlk507635856\n _Ref488927920\n _Hlk507481945\n _Ref488930244\n _Ref488932941\n _Hlk507637647\n _Ref488932952\n _Ref488930260\n _Hlk507640838\n _Hlk507635360\n _Hlk507558089\n _Ref488932855\n _Ref488928855\n _Ref507642137\n _Hlk507636306\n _Ref488931672\n _Ref488932879\n _Ref488929896\n _Ref488930086\n _Ref488931556\n _Ref488931610\n _Ref488931115\n _Ref489358165\n _Ref488931286\n _Hlk507639808\n _Ref488931368\n _Ref488931446\n _Hlk507566565\n _Ref488932894\n _GoBack ",
    "text": " Microsoft Word 18-0982 AustCyber MDS Analysis Final Analysis of the NIST Mobile Device \nSecurity Practice Guides Applicability to \nAustralia Prepared for \nAustCyberthe Australian Cyber Security \nGrowth Network Authors: Christopher Brown \nSallie Edwards Irving Lachow \nMarch 2018 M IT RE T E C HN I C A L R E P OR T The views, opinions, and/or findings \ncontained in this report are those of The \nMITRE Corporation and should not be \nconstrued as an official government position, \npolicy, or decision unless designated by other \ndocumentation. Approved for Public Release; Distribution \nUnlimited 18-0982 \nAll rights reserved. \n2 Executive Summary \nThe Australian Cyber Security Growth Network (AustCyber) contracted with The MITRE \nCorporation (MITRE) to assess the applicability of the National Institute of Standards and \nTechnology (NIST) Cybersecurity Practice Guide for Mobile Device Security: Cloud and Hybrid \nBuilds (the Practice Guide) to organizations within Australia to consider opportunities for \nstandards harmonization and proactive regulatory reform. \nMobile devices, most frequently in the form of smartphones and tablets, are a key feature of \nAustralias society and its business activitiessecuring those devices and the data they carry is \ncritical. While MITRE has considered the role of government and larger enterprises in this \nreport, considerable attention is paid to small and medium-size enterprises (SMEs) due to their \nimportant role in the Australian economy. Many of these organizations have limited operational \nknowledge of cybersecurity. Australian organizations, and particularly SMEs, need practical \nadvice that helps them understand their need for cybersecurity, along with easily consumable \nguidelines that are affordable and easy to implement. \nMITRE found that the abundance of standards and guidelines available to Australian \norganizations at both the federal and state/territory level caused confusion around what advice \nshould be adopted. Cyberaware organizations are overregulating, doing nothing, or applying a \nmixture of domestic and international standards for guidelines. The result is inefficient and is a \nbarrier to improving Australias cyber resilience. The Australian government can begin to \naddress this issue by taking steps to harmonize the guidelines it provides to industry and other \nlevels of Australian government. \nThis report is a starting point for Australian government and industry to further examine the \nexisting overlaps and gaps that Australian organizations face in following the multiple \ncybersecurity requirements and guidelines. MITRE found that the Practice Guide is helpful to \nAustralian organizations, including government, because it offers comprehensive standards-\nbased guidelines. The Practice Guide attempts to provide practical, real-world security guidelines \nthat most organizations can adopt on unclassified networks. For smaller organizations, the \nPractice Guide focuses on the use of cloud architecture on mobile devices, while more mature \norganizations are given guidelines on the use of hybrid architecture. \nMITRE identified the Australian Signals Directorates (ASD) Information Security Manual \n(ISM) and the Essential Eight mitigation strategies as having the most relevance to mobile device \nsecurity for organizations in Australia, as well as the Office of the Australian Information \nCommissioners (OAIC) guide to securing personal information when considering the recent \nPrivacy Amendment (Notifiable Data Breaches) Act 2017. These three resources were mapped \nto the Practice Guide to identify overlaps and gaps. \nOverall the ISM had the strongest relationship to the Practice Guide, and the gaps identified are \nlargely due to the difference in the intended audience. The Practice Guide was designed for \nindustry, whereas the ISM is focused on defense and federal agencies. The Essential Eight were \nfound to be useful guidelines for mobile device security, with the Practice Guide security \ncharacteristics addressing six of the eight Essential Eight strategies. The OAIC guide to securing \n3 personal information is also relevant for SMEs concerned about mobile device security, though it \nalso has broader applicability. \nIn summary, our analysis showed that the Practice Guide provided useful and practical \nguidelines on the specific issue of mobile device security within the Australian ecosystem. The \nPractice Guide can be a useful adjunct to the existing set of Australian guidelines and could serve \nas a preeminent and comprehensive reference for organizations seeking to improve the \ncybersecurity of mobile devices. Furthermore, the Practice Guide could become even more \nuseful for SMEs with several modifications described at the conclusion of this report. MITRE \nrecommends that AustCyber, a government-funded and industry-facing independent entity, take \nthe lead in facilitating intergovernmental and multistakeholder discussions on cybersecurity \nstandards harmonization both domestically and internationally (the latter is especially relevant \nfor organizations that export and/or have multinational operations), with mobile device security \nserving as the initial use case because of its broad applicability across both SMEs and larger \nenterprises. \n4 Table of Contents \n Introduction \nICT Arrangements \n5 Device Integrity \n6 Introduction \nAustralian organizations attempting to secure their cyberenvironment face a complex mix of \nregulations, standards, and guidance. Businesses that desire to do business with governments \nface competing standards that are recommended, if not required, by different government \nagencies. A perceived lack of practical cybersecurity guidance has left some businesses \nstruggling to comply with stringent security controls that exceed the level of security necessary \nfor their environment and often with the levels of security appropriate for implementing their \nsolutions in customer environments. \nFurther complicating matters is the fact that the Australian economy is driven by small- and \nmedium-size enterprises (SMEs). The criteria defining an SME varies. The Australian Bureau of \nStatistics (ABS) defines an SME as a business employing 20 people or fewer, while the \nAustralian Tax Office (ATO) defines a small business as an entity with less than AU$10 million \nin yearly turnover [1] and a large business with turnover of more than AU$250 million. In fact, \nthe Australian governments 2014 Financial System Inquiry report found that Australias two \nmillion small- to mid-size organizations employ almost 70 percent of the total workforce and \ncontribute half of the output of the private sector [2]. It is unrealistic to expect businesses of this \nsize to comply with inconsistent regulations, standards, or guidance that is better suited for large \nenterprises with dedicated IT staffs; however, the health and security of SMEs impacts not only \nindividual businesses but government and larger corporations as well. \nSME owners rely heavily on mobile devices to carry out key business functions. These SMEs \nneed practical advice to help them be aware of cyber risks when interacting with mobile devices \nand to implement guidance that will prevent, detect, and respond to cybersecurity incidents. \nThere are some high-level cybersecurity best practices available, such as Keep your business \nsafe from cyberthreats and the Stay Smart Online website [3][4]. Each of these online \ngovernment resources provides valuable broad-level cybersecurity information. However, there \nis a need for practical information for more specific business functions facing SMEs. Mobile \ndevices, most frequently in the form of smartphones and tablets, are a key feature of Australias \nsociety and its business activitiessecuring those devices and the data they carry is critical, yet \nit is not clear how SMEs should best address this challenge. Mobile device cybersecurity is \nfurther complicated by the impact of increased cloud service usage to store data that is critical to \nbusiness operations, as highlighted in a report from the Australian Bureau of Statistics [5]. The During industry consultations, participants noted several resources that provided practical \ncybersecurity guidance for mobile devices. The Center for Internet Security (CIS), a nonprofit \norganization whose mission is to identify, develop, validate, promote, and sustain best-practice \nsolutions for cyberdefense, was mentioned as a resource. The CIS produces benchmark best-\npractice security configuration guides on many topics, including mobile devices. Other examples \nthat were mentioned were the United Kingdoms National Cyber Security Centre (NCSC) Cyber \nEssentials self-help website and the business-focused mobile device security guidance produced \nby the Australian governments Stay Smart Online website. While these publications are \nsomewhat similar in nature to the NCCoE practice guides, they lack a strong relationship with a \ncommon, internationally accepted cybersecurity framework. \n7 activities conducted to develop this report explore a possible option for providing more specific \npractical cybersecurity advice for Australian SMEs. 1.1 Background \nThis report leverages the Mobile Device Security Project performed by the National \nCybersecurity Center of Excellence (NCCoE) in the United States. The NCCoE is a public-\nprivate partnership that creates practical cybersecurity solutions by using a standards-based \napproach. NCCoE uses currently available commercial technology to produce easily adaptable \nsolutions to address cybersecurity challenges facing industry. Example solutions or reference \narchitectures are documented in a practice guide that contains three parts: Volume AExecutive Summary, a high-level overview of the project, including \nsummaries of the challenge, solution, and benefits Volume BApproach, Architecture, and Security Characteristics, a deep dive into \nchallenge and solution, including approach, architecture, and security mapping to \nrelevant standards Volume CHow-to guide providing detailed instructions on how to implement the \nsolution, including components, installation, configuration, operation, and maintenance The National Institute of Standards and Technology (NIST) Cybersecurity Practice Guide for \nMobile Device Security: Cloud and Hybrid Builds (the Practice Guide), also known as NIST \nSpecial Publication 1800-4, is among the cybersecurity practice guides produced by the NCCoE. \nAll NCCoE practice guides leverage the United States NIST-published Framework for \nImproving Critical Infrastructure Cybersecurity, commonly referred to as the Cybersecurity \nFramework, or CSF.
The Cybersecurity Framework was developed via collaboration among \ngovernment, industry, and academia in response to White House Executive Order 13636 calling \nfor a framework to reduce cybersecurity risks to critical infrastructure. The framework references \nglobally recognized standards for cybersecurity to guide organizations of all sizes and technical \nsophistication on elements that should be included in a comprehensive cybersecurity program. The Practice Guide was published in draft format in November 2015 and authored through a \ncollaborative process among MITRE, industry participants, and NCCoE researchers. Since \npublication, the Practice Guide has received feedback from the public and cybersecurity industry \nthat will be addressed in an update to the Practice Guide. The forthcoming Practice Guide will \nfocus on the current threat landscape and will incorporate mobile-focused cybersecurity \ntechnologies that have evolved since the original publication. A full mapping of the Practice Guide security characteristics to the Cybersecurity Framework \nand other relevant standards is included in Appendix A. 1.2 Scope \nThis projects objective is to assess the applicability of the Practice Guide to Australian \norganizations by determining how the Practice Guide maps to laws, regulations, standards, and \nguidelines that drive mobile device security practices within Australia. The remainder of the \ndocument describes the approach and analysis used in this effort. Furthermore, this report \n8 provides AustCyber with a recommended path forward for improving mobile device security for \nAustralian organizations. 1.3 Report Structure \nSection 2, Mobile Device Environment, describes the use and types of mobile devices within \nAustralian organizations. Section 3, Approach, speaks to the process followed to create this \nreport. Section 4, Identified Laws, Standards, and Guidelines, lists the laws, standards, and \nguidelines reviewed to create this report. Section 5, Laws, Standards, and Guidelines, maps those \nlaws, standards, and guidelines determined to be most relevant to mobile devices to practice \nguide security characteristics. Section 6, Findings and Recommendations, suggests modifications \nwhere practice guide recommendations may be tailored to best address the mobile cybersecurity \nconcerns facing Australian organizations that have limited cybersecurity expertise. Mobile Device Environment \nThe first step in our analysis was to understand the Australian environment within which mobile \ndevices are used. This section summarizes that environment by looking at the following issues: \nthe way those devices are utilized, the types of mobile devices used by Australian organizations, \nand the mobile device threat landscape. 2.1 Mobile Device Usage \nMobile devices have become an integral component of day-to-day operations for Australian \nbusinesses. Organizations largely use cloud-based email and social media tools in their day-to-\nday mobile business applications. Googles GSuite and Microsofts Office365 services are two \ncommonly cited for basic email functionality. This is due to their low cost, ease of use, and \nfunctionalityso these tools are often used without considering the business risks and benefits. A \n2014 report by the Australian Communications and Media Authority (ACMA) notes that 47 \npercent of SMEs connected to the internet used some type of cloud computing service [6]. \nFurther, a 2015 report entitled Report 1Australians Digital Lives asserts that 26 percent of \nbusinesses utilize social media for marketing/advertising purposes [7]. Also, organizations are \nheavily dependent on cloud-based file backup and accounting systems on mobile devices to store \npersonal information, corporate data, and financial, health, and other sensitive records. \nOrganizations across different sectors tend to allow personal devices to access the \naforementioned business applications with very little thought given to threat mitigation. \nAustralian organizations, particularly SMEs that are implementing bring-your-own-device \n(BYOD) policies, may note a gap at the how to level due to the lack of a specific BYOD \narchitecture. This was informed by roundtable discussions where the use of BYOD deployment \nmodel by Australian organizations, particularly SMEs, was deemed commonplace. 2.2 Mobile Device Types \nSimilar to the environment in the United States, organizations in Australia tend to use off-the- \nshelf mobile devices such as Apple iPhones and various Android devices, including the Samsung \nGalaxy Series, to conduct business. DeviceAtlas, a popular source of device data, appears to bear \nthis out with iPhone and Galaxy devices composing all the top 20 positions of device usage for \nAustralia [8]. \n9 Apple iOS was found to be the preferred platform for organizations overall. A few factors play \ninto this, including a perception that iOS is generally more secure. The wide breadth of available \nAndroid devices makes enforcement of security policies even more difficult. The ability for \nmanufacturers to take the Android Open Source Project and modify it to their own needs makes \nthe update cycle unpredictable for businesses [9] [10]. Telecom approval for Android updates \nadds to the delay of operating system security updates. This is a known global issue and is being \naddressed in Android 8.0 (Oreo) through Project Treble [11]which makes the upgrade process \neasier regardless of device manufacturer and carrier. Finally, organizational device owners did \nnot want to lose access to familiar iOS ecosystem components (such as iMessage). This \nfamiliarity and user experience appeared to be the most qualitative factor behind purchasing \ndecisions. In contrast, the Android platform was more customizable for those organizations and \nindividuals with the skills to modify the operating system directly. 2.3 Mobile Threat Landscape \nThe Practice Guide broadly speaks of threats and vulnerabilities that the portable nature of \nmobile devices presents to an organization. Threats such as mobile malware, stolen devices, and \neavesdropping are mapped to technology solutions used within each architecture. The Practice \nGuide recognizes that vulnerabilities can occur not only within the operating system but also \nwithin third-party developer applications and device firmware. The Practice Guide addresses \nvulnerabilities found in third-party developer applications, whereas operating system and \nfirmware vulnerabilities were deemed out of scope for the Practice Guide. \nIn the course of this research, MITRE has attempted to ascertain unique threats in the Australian \ncontext that would require modifications to the current Practice Guide. We primarily consulted \nthe NIST Mobile Threat Catalogue (MTC), an online resource that describes, identifies, and \nstructures the threats posed to mobile information systems [12]. Each entry in the MTC contains \nseveral pieces of information: an identifier, a category, a high-level description, details on its \norigin, exploit examples, common vulnerabilities and exposures (CVEs) examples, possible \ncountermeasures, and academic references. The threats identified within the MTC align with the \nthreats identified in the ASDs Protection Profile for Mobile Device Fundamentals, which \nprovides security requirements for the evaluation of IT products. Thus, the threat landscape is \nlargely the same as what is experienced in the United States (lost devices, malware, ransomware, \netc.) [12]. \nAdditionally, device owners expressed concerns that indicated security is still viewed as an \nobstacle to usability. This can lead to undesirable behavior where end users attempt to disable \nsecurity controls to accomplish business tasks. Those organizations aware of the importance of \ncybersecurity remain concerned about the onerous nature of technical activities necessary to \nimplement mobile device security controls. In particular, SMEs tend to focus on day-to-day \nbusiness operations and have little time to think about security. One way to address that \nchallenge is to include stories and/or infographics to SMEs that identify risks posed by the use of \nmobile devices and how mobile device security impacts them. \nHowever, there are a few threats worthy of more investigation, including scams that port phone \nnumbers without device owner consent [13] and phishing attempts designed to trick victims into \nhanding over valuable personal information such as bank account details and passwords [14]. \n10 Furthermore, SMEs increasingly need to travel overseas for business and do not often understand \nthat such travel increases the risks around their mobile device. A good reference point for SMEs \nis guidance provided by smaller government agencies across the tiers of Australian governments \non the risks to their staffs, such as the South Australian governments ISMF Guideline 30a on \nWorking Away from the Office or Abroad. \nMobile payment methods are an evolving threat vector to monitor in the future, especially for \nSMEs. External credit card readers such as the Square Reader allow small businesses to accept \ncredit card payments from a consumer mobile device [15]. Modern versions of these peripherals \noperate using Bluetooth technology, which is vulnerable to a wide range of attacks, especially if \nnot configured properly. Organizations should ensure that any external peripheral follows \nBluetooth best security practices, such as those presented in NISTs Special Publication 800-121 \nRevision 2 Guide to Bluetooth Security [16]. Approach \nMITRE followed a four-step process to assess the applicability of the Practice Guide to \nAustralian organizations: Step 1: MITRE collaborated with AustCyber to identify existing mobile device \ncybersecurity-related laws, regulations, standards, and guidelines that guide the behavior \nof Australian organizations (Appendix C). Step 2: Upon review, MITRE selected from the initial list of more than 40 existing laws, \nstandards, and guidelines to map those identified as most relevant to the guidelines found \nin the Practice Guide. Step 3: MITRE conducted analysis, including holding on-site consultations with \nAustralian organizations. These consultations included stakeholders from the Australian \nfederal and state governments, telecommunications industry, university and research \ncommunity, industry associations, and SMEs. This research and analysis allowed us to \ndetermine if the Practice Guide could be adopted as is by Australian organizations
and \nto suggest modifications as appropriate. Step 4: Summarized findings and recommendations in the final report. Here we \ndocumented the results of our research, comparing security characteristics included in the \nISM, Essential Eight, and privacy guidelines, to the Practice Guide. We stated how the \nPractice Guide aligns with Australian mobile device security standards and guidelines as \nwell as gave recommendations for tailoring it for the needs of Australian organizations. 3.1 Assumptions \nThis report refers to Australian organizations generally, but it is most applicable to small and \nmedium enterprises. For the purposes of this research, an SME may follow either the Australian \nTax Office definition of an entity with less than AU$10 million in yearly turnover, and less than \na large business with turnover of more than AU$250 million; or the Australian Bureau of \nStatistics definition of a business employing fewer than 20 people [17]. Also, this report uses the \nNIST definition of a mobile device as having the following characteristics [18]: a small form factor \n11 at least one wireless network interface for network access (data communications). This \ninterface uses Wi-Fi, cellular networking, or other technologies that connect the mobile \ndevice to network infrastructures with connectivity to the internet or other data networks local, built-in (nonremovable) data storage an operating system that is not a full-fledged desktop or laptop operating system applications available through multiple methods (provided with the mobile device, \naccessed through web browser, acquired and installed from third parties) This report refers to the cloud and hybrid reference architectures described within the Practice \nGuide. The cloud architecture is geared toward smaller organizations wanting to operate and \nmaintain systems external to their enterprise environment to lower operational expenses. The \nhybrid architecture is meant for more mature organizations that are concerned with the risks \nassociated with storing and processing confidential enterprise information in the cloud. Each \ndocumented architecture is based on a set of security characteristics that are required to mitigate \nin large part the risks of storing enterprise data on mobile devices and transmitting enterprise \ndata to and from mobile devices. The identified security characteristics are data protection, data \nisolation, monitoring, identity and authorization, and privacy [19]. These characteristics are \nspecifically crafted to address the unique mobile security environment rather than general IT \nsecurity. \nFor this project, MITRE focused on standards and guidelines most broadly relevant to Australian \nentities that use mobile devices as tools to conduct business. An exhaustive mapping of all \ndocuments that may affect any Australian organization is beyond the scope of this document. Identified Laws, Standards, and Guidelines \nIn this report, the term laws refers to binding rules that are required for applicable entities. \nStandards establish specifications to ensure reliability and consistency, while guidelines provide \noptional information or advice [20]. There is some overlap between standards and guidelines. \nDocuments that function as optional guidelines for some entities may be considered standards for \nanother in the sense that they are used to measure compliance to mandates. Deciphering \ncybersecurity-related laws, standards, and guidelines is a significant challenge for SMEs. It is \nfurther complicated by the fact that guidelines produced by government agencies across the \nfederal and state levels are often inconsistent, which could be confusing for industry. \nMITRE researched Australian laws, standards, and guidelines to identify those with specific \napplication to mobile device security. General, government, and privacy items that were \nreviewed are listed in the following table. A description of each regulation or standard and how it \ndoes or does not apply to mobile device security is provided in the narrative following the table. \nEach of the documents in the following table was deemed to be potentially relevant for mobile \ndevice security implementations in Australia. Our analysis describes each law, standard, and \nguideline and then briefly explains whether it is sufficiently important to be selected for detailed \nmapping against the Practice Guide. \n12 Table 1Cybersecurity Laws, Standards, and Guidelines Name Type Issuing Authority Source Cyber Security for \nContractors Guidelines \n(standard for \nfederal \ngovernment) Australian Signals \nDirectorate https://www.asd.gov.au/publication\ns/protect/Cyber_Security_for_Contr\nactors.pdf Cybercrime Act 2001 Law Australian Parliament \nhttps://www.legislation.gov.au/Det\nails/C2004C01213 Essential Eight Guidelines \n(standard for \nfederal \ngovernment) Australian Signals \nDirectorate https://www.asd.gov.au/publication\ns/protect/essential-eight-\nexplained.htm ISO 27001/2 Standard \nInternational \nOrganization for \nStandardization https://www.iso.org/isoiec-27001-\ninformation-security.html Framework for \nImproving Critical \nInfrastructure \nCybersecurity Guidelines NIST https://www.nist.gov/cyberframework Risk Management of \nEnterprise Mobility, \nIncluding Bring Your \nOwn Device Guidelines Australian Signals Directorate https://www.asd.gov.au/publication\ns/protect/enterprise_mobility_bring\n_your_own_device_byod.htm Strategies to Mitigate \nCyber Security \nIncidents Guidelines Australian Signals Directorate \nhttps://www.asd.gov.au/infosec/mi\ntigationstrategies.htm Information Security \nManual (ISM) Standard for \nfederal \ngovernment Australian Signals \nDirectorate https://www.asd.gov.au/infosec/is\nm/ Information Security \nManagement \nGuidelines: Risk \nmanagement of \noutsourced ICT \narrangements \n(including Cloud) Standard for \nfederal \ngovernment Australian \nGovernment https://www.protectivesecurity.gov.\nau/informationsecurity/Documents/\nAustralianGovernmentInformationS\necurityManagementGuidelines.pdf Information Security \nRegistered Assessors \nProgram (IRAP) Standard Australian Signals Directorate https://www.asd.gov.au/publication\ns/irap/IRAP_Policy_and_Procedures.\npdf Protective Security \nPolicy Framework Guidelines Australia https://www.protectivesecurity.gov.\nau/Pages/default.aspx Privacy Amendment \n(Notifiable Data \nBreaches) Act 2017 Law Australian Parliament \nhttps://www.legislation.gov.au/Det\nails/C2017A00012 \n13 4.1 National Laws \nThe items listed here are federal laws and were reviewed for their potential applicability to \nmobile device security in Australia. 4.1.1 Cybercrime Act 2001 The Cybercrime Act 2001 is a law that provides a mechanism to prosecute those who use \ncyberspace to perpetrate crime. It defines computer offenses, addresses enforcement authority, \nand outlines penalties for violations. While the act is of interest, it is not directly relevant to \nimproving mobile device security as the emphasis is on hacking and computer crimes; thus, it is \nnot included as a mapping component. 4.1.2 Privacy While the Commonwealth Privacy Act 1988 (the Privacy Act) and Privacy Amendment \n(Notifiable Data Breaches) Act 2017 are listed individually in Table 1, they are addressed \ntogether here under the Privacy header. \nThe Privacy Act defines personal information and regulates how it may be handled. The Privacy \nAct established the 13 Australian Privacy Principles (APP). It intersects with mobile devices due \nto the myriad of transaction types and tasks conducted via mobile device, some of those actions \nusing personal information. However, it is the Privacy Amendment (Notifiable Data Breaches) \nAct 2017 that is most noted when addressing mobile device security due to the potential for data \nbreach via a mobile device. The Privacy Amendment (Notifiable Data Breaches) Act 2017 \nestablished a mandatory data breach notification scheme in Australia. The amendment is \napplicable to entities covered in the Privacy Act, including businesses that have an annual \nturnover of more than AU$3 million, organizations that have Privacy Act security obligations in \nrelation to particular types of information, and other organizations that have voluntarily opted in \nto Privacy Act compliance [21]. \nMITRE found that elements of the Guide to Securing Personal Information more closely align to \nmobile device security and selected that document for mapping privacy elements rather than \neither the Privacy Act or Privacy Amendment (Notifiable Data Breaches) Act 2017. 4.2 Standards and Guidelines \nMost of the material published to influence organizations cybersecurity activity fits within the \ncategory of standards and guidelines. Although compliance with standards may be required for \ncertain entities (e.g., federal agencies may have to comply with certain government-mandated \nstandards), standards are typically not treated as mandates by private-sector entities. Guidelines- Privacy Act 1988 Law Australian Parliament \nhttps://www.oaic.gov.au/privacy-\nlaw/privacy-act Guide to securing \npersonal information Guidelines Office of the \nAustralian \nInformation \nCommissioner https://www.oaic.gov.au/agencies-\nand-organisations/guides/guide-to-\nsecuring-personal-information \n14 level documents are advisory; they provide recommendations and/or suggestions but are purely \noptional. Although the terms standards and guidelines appear to be well-defined and \ndistinctive, there is crossover, often due to procurement processes requiring applicants to \ndemonstrate compliance with one or more standards, which creates a confusing area for \norganizations. From its consultations with industry, MITRE learned that this contributed to some \norganizations not taking any actions while larger organizations described using a combination of \nstandards and guidelines documents from international and Australian sources, including the \nNIST Cybersecurity Framework. \nThis section provides a description of the standards and guidelines documents we deemed to be \nrelevant to the Practice Guide. The focus below is on federal-level documents. However, as part \nof our research we reviewed the procurement policies of each Australian state and territory. \nWhile states do have cybersecurity requirements in their procurement policies, these policies \napply only to those organizations that are doing business with the states. This could lead to \nsituations where businesses trying to work with multiple states, as well as with the federal \ngovernment, are forced to comply with a myriad of different policies. In addition, only the New \nSouth Wales state government provided clear guidelines for entities pursuing mobile device \nprocurement through the NSW Government Device & Application Framework. However, the \nNSW Framework lacks a clear linkage to federal government policies. Organizations doing \nbusiness with the multiple Australian jurisdictions need to review the procurement policy for \neach state. This has the potential to further fragment any cybersecurity advice. The list of state \nprocurement policies reviewed for this effort is shown in Appendix D. 4.2.1 Strategies to Mitigate Cyber Security Incidents ASDs Strategies to Mitigate Cyber Security Incidents provides relevant guidelines to all \norganizations seeking methods to reduce cybersecurity incidents. Along with its companion \ndocument Strategies to Mitigate Cyber Security IncidentsMitigation Details, this ASD \nguideline is a useful resource for Australian organizations. However, these publications focus on \nenterprise security rather than mobile device security and already
incorporate a portion of the \nEssential Eight [22]; therefore, they are not included in the mapping of the Practice Guide. 4.2.2 Cyber Security for Contractors ASDs Cyber Security for Contractors publication is designed to assist government contractors \nas they seek to protect government data contained on their systems. The key provisions of the \ndocument are the Essential Eight [22]. Because this report has included the Essential Eight in the \nmapping of the Practice Guide, the inclusion of Cyber Security for Contractors publication \nwould be repetitive. Further, the publication recommends that contractors review the guidelines \npublished by the Australian Cyber Security Centre (ACSC). While the ACSCs guidelines are \nnot specifically related to mobile devices, the reader concerned with mobile device security \nshould review Cloud Computing Security for Tenants, which lists essential mitigations for data \ncompromise [23]. As discussed earlier in this report, mobile devices often leverage cloud \nservices during business operations. \n15 4.2.3 Essential Eight ASDs Essential Eight as documented in the Essential Eight Explained build on ASDs previous \nTop 4 Mitigation Strategies for Targeted Cyber Intrusions with the goal of being a cybersecurity \nbaseline for organizations [22]. The research undertaken for this project found the Essential \nEight to be widely used in Australia, even beyond government organizations, and that they also \nhave some applicability to mobile devices. Therefore, we use the Essential Eight as a basis for \nmapping to the guidelines found in the Practice Guide. 4.2.4 ISO 27001/27002 The International Organization of Standardization (ISO)/International Electrotechnical \nCommission (IEC) 27000 series of standards is applicable to any entity implementing a mobile \ndevice security solution. The Practice Guide includes ISO/IEC 27002, which provides best-\npractice recommendations on implementing security in its security characteristics mapping. ISO \n27002 is included in the currently published version of the Practice Guide; therefore, it is not \naddressed separately in this document. Those seeking information on how ISO 27002 relates to a \nmobile device security implementation should review the Practice Guide. 4.2.5 NIST Cybersecurity Framework Published in February 2014 by NIST, the Cybersecurity Framework is a guide for entities \nseeking to employ a flexible, risk-based, and comprehensive cybersecurity program. The \nframework itself is not a standard; rather, it is an approach developed in consensus with industry \nthat is based on standards. The core of the framework includes five functions: identify, protect, \ndetect, respond, and recover. The functions are broken down further into subcategories and \ncross-referenced with other commonly used standards. The framework provides the basis for the \nPractice Guide. The full mapping of the Practice Guide to the Cybersecurity Framework can be \nfound in Appendix A. 4.2.6 Risk Management of Enterprise Mobility Including Bring Your Own Device The Risk Management of Enterprise Mobility Including Bring Your Own Device published by \nASD provides relevant information for organizations considering deploying a bring your own \ndevice (BYOD) policy. It explores risk tolerance and business usage; however, it is not included \nin our mapping because its focus is on business cases rather than practical implementation \nguidelines. 4.2.7 Protective Security Policy Framework (PSPF) The Protective Security Policy Framework, authored by Australias Attorney-Generals \nDepartment, takes a broad approach to security that includes governance, personnel security, \ninformation security, and physical security. Australian government agencies are required to \ncomply with its 36 requirements, and it is provided to state and territory governments as a \nholistic model for public-sector security management. Because it is a high-level document \nwithout a direct correlation to the technical recommendations in the Practice Guide and it applies \nto the Australian government, it is not included in the mapping provided in the next section. \n16 4.2.8 Information Security Manual The ISM, authored by ASD, is the flagship document for the application of risk-based \ninformation security principles and controls for Australian government agencies, thereby \nfunctioning as the standard that governs the security of Australian government information and \ncommunication technology (ICT) systems. [24]. The ISMs suggested audience is Information \nTechnology Security Advisors, Information Technology Security Managers, Information \nSecurity Registered Assessors and other security practitioners across government. The role and \ntechnical skill level of this audience is similar to the Practice Guides target audience in its Part \nB, which is focused on chief information officers, chief information security officers, and \nsecurity managers. While the ISM is focused on federal agencies, it is mapped to the Practice \nGuide because of its flagship status on Australian cybersecurity. 4.2.9 Information Security Management Guidelines: Risk Management of \nOutsourced ICT Arrangements Information Security Management Guidelines: Risk Management of Outsourced ICT \nArrangements (Including Cloud), authored by Australias Attorney-Generals Department, is \nintended for government agencies. While much of the information included in this document \nmay benefit any organization considering cloud services, it is tailored to government needs only. \nAlso, it is primarily aimed at the organizational and policy levels. Thus, it is not included in the \nmapping of the Practice Guide. 4.2.10 Information Security Registered Assessors Program (IRAP) IRAP is an ASD initiative to ensure that individuals conducting cybersecurity assessments have \nan appropriate skill level to produce consistent quality. IRAP is not a standard, though it is often \nmistaken to be such; rather, it demonstrates that IRAP members have attained the experience, \nsecurity certifications, and technical understanding to independently assess systems against the \nISM and Protective Security Policy Framework. This program is especially important for entities \nthat desire to provide IT services to Australian government agencies (and increasingly adopted \nby state and territory governments) due to the ASDs recommendation of compliance with IRAP \nbefore procurement. IRAP is included on the list of identified standards as MITRE research \nfound it frequently referenced, at times, as if it were a standard. IRAP leverages the ISM as a \nbasis for assessment of technical controls for services that go through the accreditation process. \nIt does not apply in the context of mobile device security for SMEs. Because it is not an actual \nstandard and applies only to government or entities opting in to IRAP, it is not mapped to the \nPractice Guide. 4.2.11 Privacy Guidelines The Office of the Australian Information Comminssioners (OAIC) Guide to Securing Personal \nInformation provides technical guidelines that businesses can use to comply with the Australian \nPrivacy Principles requirements [25]. This research uses the Guide to Securing Personal \nInformation as a basis for mapping to the guidelines found in the Practice Guide. It is important \nto note that this mapping is limited to the extent that the findings and recommendations from the \nOAIC guidelines are limited to personal information and that the Practice Guide includes any \ndata. Additionally, the OAIC guide includes specific reference to mobile devices that were not \n17 included in the mapping in this report. General guidelines are provided for businesses to adopt \npolicies regarding the use of mobile devices, including the separation of business and personal \ndata, password protection, and an awareness program for employees regarding the risks of using \npersonal devices for business activities. \nWhile the OAIC guide is beneficial to organizations with mobile devices, it lacks the technical \nspecificity necessary for mapping to the Practice Guide. Additionally, the Guide to Securing \nPersonal Information refers to the OAICs Mobile PrivacyA Better Practice Guide for \nMobile App Developers [26]. While useful for entities that develop mobile applications within \ntheir own organizations, the Practice Guide used mobile applications provided by commercial \nvendors and therefore did not include any mobile application development recommendations for \nprivacy protection. For the purposes of the project, it is assumed that most SMEs will be users of \nmobile applications and not developers of mobile applications. However, in circumstances where \nAustralian organizations, particularly start-ups, develop applications to support their businesses, \nthis guide is useful. Laws, Standards, and Guidelines Mapping \nMITRE analyzed the laws, standards, and guidelines identified in Section 4 of this report and \ndetermined that three of the documents were directly relevant to mobile device security \nguidelines contained within the Practice Guide. This section provides a detailed analysis showing \nhow the most relevant Australian laws, standards, and guidelines map to the Practice Guide. It \nincludes tables that illustrate how specific controls found in the Australian documents align to \ncomparable elements within the Practice Guide. For example, in Table 2, which compares the \nISM to the Practice Guide, the Security Characteristic column identifies elements from the \nPractice Guide that are needed to reduce the risk from mobile devices storing or accessing \nenterprise data. The Example Capability column, taken from the Practice Guide, identifies \ntechnical features that can be applied to address the accompanied security characteristic. The \nfinal column, Information Security Manual Control, shows how technical controls align to the Practice Guides corresponding security characteristics. 5.1 Information Security Manual \nThis section maps the ISM Control Manual to guidelines found in the Practice Guide. This section also uses visual representations to make the mapping easy to understand. We began \nby identifying the six security characteristics from the Practice Guide and representing them as \nhexagons in a heat map. The color of each hexagon represents the degree of overlap between the \nAustralian document and the Practice Guide. In the ISM mapping, green denotes that the \nPractice Guide security characteristic was mapped
to five or more ISM controls while yellow \nrepresents that one to four controls have been mapped. In the Essential Eight and Privacy Law \nmapping, green denotes that a security characteristic was mapped to two or more guidelines, \nwhile yellow represents a mapping to one guideline. In all cases, red denotes that the security \ncharacteristic was not mapped to a control or guideline, thus signifying a gap. \n18 The Australian Government ISM Control Manual provides a comprehensive view of \ncybersecurity and addresses IT security controls, governance, physical security, personnel \nsecurity, and other aspects of an organizational risk management program. The IT security \ncontrols that are most relevant for mobile security were found in the Working Off-Site section of \nthe ISM, so our comparison primarily focuses on controls from that section of the report. \nOverall, our analysis found that the Practice Guide mapped nicely to ISM controls. Table 2-ISM to Practice Guide Security Characteristic Mapping Security \nCharacteristic Example Capability \nInformation Security \nManual Control Data Protection protected storage: device encryption, secure containers, \ntrusted key storage, hardware security modules, remote \nwipe; protected communications: virtual private network \n(VPN), to include per-app VPN; data protection in process: \nencrypted memory, protected execution environments 0869, 1085, 0864, 0705, 0700, \n0701, 0702, 1345 Data Isolation \nvirtualization, sandboxing, memory isolation, trusted \nexecution, device resource management, data flow control, \ndata tagging, baseband isolation 1047 Device Integrity baseband integrity checks, application black/whitelisting; \ndevice integrity checks: boot validation, application \nverification, verified application and OS updates, trusted \nintegrity reports, policy integrity verification 1399, 1367 Monitoring \ncanned reports and ad-hoc queries, auditing and logging, \nanomalous behavior detection, compliance checks, asset \nmanagement, root and jailbreak detection, geofencing 0862, 0863 Identity and Authorization local user authentication to applications, local user \nauthentication to device, remote user authentication, \nremote device authentication, implementation of user and \ndevice roles for authorization, credential and token storage \nand use, device provisioning and enrollment ISM controls not mobile specific Privacy Protection \ninformed consent of user, data monitoring minimization, \nprivacy notification provided to user ISM controls not mobile specific \n19 Figure 1 ISM Control Mapping \nThe following sections provide more detailed explanations of each security characteristic \nmapping to the ISM. A summary of each mapped ISM control and its applicability to the \nPractice Guide is provided in the narrative. 5.1.1 Key Findings The ISM and the Practice Guide align in the use of encryption, in enabling device security \nfunctions, and in the ability to destroy data on lost devices. Additionally, the Practice Guide \nprovides some alignment with the ISM on device integrity and the need for audit and monitoring. \nThe Practice Guide exceeds the ISM controls by addressing the identity and authorization and \nprivacy protection security characteristics in the mobile context. While these topics are addressed \nby the ISM from an enterprise level, the Practice Guide provides specific practical \nimplementations of these characteristics that directly affect mobile device usage. Personnel awareness (Control 1083), however, is not addressed by the Practice Guide. Australian \norganizations that attempt to implement the Practice Guide should take steps to make device \nowners aware of the activities that are permitted for data communications. For example, an \norganization may want to inform personnel that communicating sensitive budget data over Green denotes that the Practice Guide security characteristic was mapped to five or more ISM \ncontrols, while yellow represents that one to four controls have been mapped. Red denotes the \nsecurity characteristic was not mapped to the control or guideline, thus signifying a gap. \n20 insecure transport such as short message service (SMS) is inappropriate. Further, the use of \nprivacy filters or screens as a method to dissuade shoulder surfing is not included in the Practice \nGuide as a threat mitigation tactic. The Practice Guide attempts to find a reasonable balance \nbetween security and user functionality. As such, the use of screen filters was not included in the \nPractice Guide because it minimally reduces the threat surface while simultaneously having a \nnegative effect on mobile device functionality due to reduced screen viewing area. The ISM Control Manual encourages adopting organizations to ensure that the carrier service \ncan provide security updates to the mobile device as soon as they become available. This is an \nimportant consideration for organizations, especially those that rely on Android devices. Updates \nto the Android operating systems are typically delivered through the carrier that provides service \nto the device [27]. This can lead to unreasonable delay in receiving important security updates. \nThe Practice Guide does not incorporate this risk into the guidelines, but it is advisable for \nadopting organizations to assess this risk. A final observation is that some of the gaps identified between the ISM and the Practice Guide \nare largely due to the difference in the intended audience. The intended audience for the Practice \nGuide is industry rather than government. The Practice Guide attempts to provide practical, real-\nworld security guidelines that most organizations can adopt rather than bespoke solutions that a \nfederal agency charged with protecting classified data requires. 5.1.2 Technical findings Data Protection ISM Control 0869 directs the use of cryptographic protection on all mobile devices utilized by an \norganization. This is directly addressed by the Practice Guide with a device-level encryption \npolicy that recommends using the file encryption on mobile device capability, which employs \nFederal Information Processing Standards (FIPS) 140-2approved cryptographic modules. Control 1085 directs the use of encryption over public communication mechanisms for sensitive \nor classified information. The Practice Guide does not address any classified data but does \nrecommend data-in-transit encryption for all communications over untrusted networks. The \nPractice Guide documents the use of transport layer security (TLS) for all communications to \ncloud services and on-premises components. Control 0864 directs agencies to prevent device owners from disabling security functions once \nprovisioned. For example, if a security policy disables the use of the camera, the device user \nshould not be able to circumvent the control and activate the camera. This control is directly \naddressed in the Practice Guide and involves using a mobile device management (MDM) \ncapability built into the mobile operating system. The mobile operating system prevents any \nmodification of security policy by the device user when under management. Controls 0705 and 1345 disable the use of VPN split tunneling on devices when the mobile \ndevice is capable of such a configuration. Split tunneling could potentially allow an attacker \nfrom an unsecured network to infiltrate a secure VPN connection. The architecture described in \nthe Practice Guide does not allow the use of split tunneling when accessing organizational \nresources by the established network security policies and a lack of VPN exercised within the \narchitecture. \n21 Controls 0700, 0701, and 0702 all relate to the ability to destroy data that resides on the device in \nan emergency. This functionality is supported in the Practice Guide through the remote wipe \ncapability within the MDM. When executed, remote wipe renders access to enterprise data \ninfeasible through cryptographically secure processes. Data Isolation ISM Control 1047 mandates the use of a technical means to separate sensitive organization-\nowned data from any personal information that is stored on the mobile device. This functionality \nis described in the Practice Guide: Use native operating system process isolation techniques that \nprevent applications from accessing, gathering, or modifying information from other \napplications. Device Integrity ISM Control 1399 permits the use of personally owned mobile devices only when the \nconfiguration of the mobile device meets security policy. This is supported by the Practice Guide \ncloud-only architecture through the deployment of mobile threat detection (MTD) on the mobile \nendpoint. The MTD client has the capability of reporting device integrity status (such as if the \ndevice has been rooted or jailbroken) to an administrator. IT security personnel can revoke \naccess to organization resources if the MTD client reports that a mobile device is out of \ncompliance. Control 1367, similar to control 1399, directs the use of a security policy enforcement capability \nwhen the mobile device is organizationally owned. The Practice Guide hybrid architecture \nsatisfies this requirement by using MDM capabilities. IT security personnel can revoke access to \norganizational resources when the MDM reports noncompliance of a mobile device. Monitoring Controls 0862 and 0863 recommend regular auditing and configuration control of mobile devices \nin the same manner as devices in an office environmentas a method to ensure that the state of \nsecurity on the mobile device has not degraded over time. As mentioned in previous sections, the \nuse of an MDM will apply technical controls to a mobile device that complies with \norganizational security policy, but regular monitoring is essential to detect abnormalities that \nrepresent a coordinated attack. The hybrid architecture in the Practice Guide addresses this \nrequirement by deploying a systems management software product in the enterprise. The \nsolution can deploy configuration controls for both traditional workstation endpoints and mobile \ndevices through one administrative console. Similarly, hardware and software inventories are \navailable for audit through the systems management solution. Identity and Authorization The ISM control manual coverage of identity and authorization security characteristics is at an \nenterprise level and is not mobile specific. Specifically, the ISM Control Manuals Access
\nControl section is geared toward the management of traditional PCs rather than mobile device \ncontrols such as the use of authentication methods to unlock the mobile device. Privacy Protection The ISM control manual coverage of privacy security characteristics is not mobile specific. \n22 5.2 Essential Eight \nThis section maps ASDs Strategies to Mitigate Cyber Incidents, Essential Eight, to guidelines \nfound in the Practice Guide. \nThe following table decomposes ASDs Essential Eight into requirements to facilitate mapping \nto the security characteristics in the Practice Guide. The Identifier column provides a shorthand \nnotation for each Essential Eight requirement in the second column. As noted in the ISM, some \ntechnologies (such as mobile devices) may lack the functionality to feasibly implement the \nEssential Eight. In such cases and in this mapping exercise, implementing the Essential Eight on \nmobile devices can be achieved by using controls that meet the general principles behind the \nEssential Eight [24]. Table 3-Essential Eight Requirements Identifier Essential Eight Requirement \nEE-1 Application whitelisting: A whitelist only allows selected software applications to run on computers. EE-2 Patch applications: \nA patch fixes security vulnerabilities in software applications. EE-3 Disable untrusted Microsoft Office macros: \nMicrosoft Office applications can use software known as macros to automate routine tasks. EE-4 User application hardening: \nBlock web browser access to Adobe Flash Player (uninstall if possible), web ads, and untrusted Java code \non the internet. EE-5 Restrict administrative privileges: \nOnly use administrator privileges for managing systems, installing legitimate software, and applying \nsoftware patches. These should be restricted to only those who need them. EE-6 Patch operating systems: \nA patch fixes security vulnerabilities in operating systems. EE-7 Multifactor authentication: \nThis is when a user is granted access only after successfully presenting multiple, separate pieces of \nevidencetypically something you know, like a pass phrase; something you have, like a physical token; \nand/or something you are, like biometric data. EE-8 Daily backup of important data: \nRegularly back up all data and store it securely offline. \n23 Table 4 maps the requirements above to the security characteristics found in the Practice Guide. Table 4-Essential Eight Requirements to Practice Guide Security Characteristic Mapping Security \nCharacteristic Example Capability \nEssential Eight \nRequirement Data Protection protected storage: device encryption, secure containers, \ntrusted key storage, hardware security modules, remote \nwipe; protected communications: virtual private network \n(VPN), to include per-app VPN; data protection in process: \nencrypted memory, protected execution environments EE-5, EE-6 Data Isolation \nvirtualization, sandboxing, memory isolation, trusted \nexecution, device resource management, data flow control, \ndata tagging, baseband isolation EE-4 Device Integrity baseband integrity checks, application black/whitelisting; \ndevice integrity checks: boot validation, application \nverification, verified application and OS updates, trusted \nintegrity reports, policy integrity verification EE-1, EE-2, EE-6 Monitoring \ncanned reports and ad-hoc queries, auditing and logging, \nanomalous behavior detection, compliance checks, asset \nmanagement, root and jailbreak detection, geofencing No mapping exists to Essential \nEight requirements Identity and Authorization local user authentication to applications, local user \nauthentication to device, remote user authentication, \nremote device authentication, implementation of user and \ndevice roles for authorization, credential and token storage \nand use, device provisioning and enrollment EE-7 Privacy Protection informed consent of user, data monitoring minimization, \nprivacy notification provided to user No mapping exists to Essential \nEight requirements \n24 \nFigure 2 Essential Eight Mapping 5.2.1 Key Findings Australian organizations adopting the Practice Guide have the baseline strategies of the Essential \nEight addressed by the cloud and hybrid architectures. The Practice Guide security \ncharacteristics address six of the eight Essential Eight requirements. Data protection, data \nisolation, device integrity, and identity and authorization mechanisms provided in the Practice \nGuide align with Essential Eight requirements. The remaining requirements disable untrusted \nMicrosoft Office macros and daily backup of important data were deemed out of scope in the \nmobile security context. Microsoft Office macros are not used in a mobile operating system \nenvironment and therefore are not applicable. Backup of critical data is best addressed through a \nnonmobile-specific enterprise policy for data retention and/or by leveraging the benefits of cloud \ntechnologies. Further, the Practice Guide architectures would address the monitoring security \ncharacteristic, which goes beyond the strategies of the Essential Eight. Green denotes that the Practice Guide security characteristic was mapped to two or more \nrequirements, while yellow represents a mapping to one requirement. Red denotes that the \nsecurity characteristic was not mapped to any requirements, thus signifying a gap. \n25 The architecture described in the Practice Guide enables the use of BYOD, company owned \npersonally enabled (COPE), and other mobile device deployment models, but none are \nspecifically addressed in the Essential Eight. ASDs publication Risk Management of Enterprise \nMobility Including Bring Your Own Device addresses BYOD through the discussion of business \ncases but does not provide practical how-to guidance that SMEs could potentially adopt quickly \nwithin their own organization. 5.2.2 Technical Findings Data Protection Requirement EE-5 in the mobile context is supported by the Practice Guide through the \nimplementation of an MDM. Organization administrators can take actions on the mobile device \nthat require elevated privileges, such as applying security restrictions, through the MDM. Mobile \noperating systems further ensure the legitimacy of remote MDM administrative commands by \nverifying the integrity through cryptographic methods. Requirement EE-6 in the mobile context is supported by the Practice Guide through the guidance \nfor organizations to keep mobile devices regularly updated to receive the latest preventive \nmeasures against vulnerabilities. The architecture also allows for a policy that blocks access to \norganizational resources when the mobile device lacks the latest OS patch level. Data Isolation Requirement EE-4, user application hardening, is not directly addressed in the Practice Guide. \nMobile application development best practices were deemed out of scope to include in the \ncurrently published version of the Practice Guide. However, application-level policies \ndocumented in the Practice Guide architecture disable attachments of email messages, which \nattackers can use to distribute malware to mobile devices, thereby isolating the malicious email \nattachment from the rest of the data on the device. Device Integrity Requirement EE-1, application whitelisting, is supported by the Practice Guide hybrid \narchitecture through managed applications. Managed applications are specially compiled \napplications where security controls are applied that comply with an organizations policy. The \nMDM allows an administrator to deploy managed applications to the organization by either \nrequiring the installation, making it optional, or marking it not applicable. These options give an \norganization the ability to allow, or whitelist, only approved applications. The Practice Guide \nused this functionality to seamlessly distribute an email application to mobile devices regardless \nof hardware platform. Requirements EE-2 and EE-6, application and operating system patch updates, are supported by \nthe Practice Guide by using ecosystem-specific integrity checks via cryptographically protected \napplications. Mobile application stores require the developer to digitally sign the software update \n(or patch) with a trusted cryptographic key before uploading to the application store. The mobile \ndevice also verifies the digital signature of application and operating system updates before final \ninstallation. These actions prevent attackers from modifying software patches to include malware \nor other exploits. \n26 Monitoring No Essential Eight requirements directly map to this Practice Guide security characteristic. \nOrganizations seeking Australia-specific guidelines on monitoring need to go through the ISM \n(noting this is limited, as discussed above) or other sources. Identity and Authorization Requirement EE-7, multifactor authentication, is not directly supported by the documented \nPractice Guide architectures, but the capability exists. The hybrid architecture uses identity \nfederation services to link the device owners identity to cloud organizational resources. This \nlinkage requires the device owner to authenticate by using an enterprise password before \naccessing organizational resources. However, a multifactor authentication scheme could be \nimplemented with additional configuration. Privacy Protection No Essential Eight requirements directly map to this Practice Guide security characteristic. \nOrganizations seeking Australia-specific guidelines need to obtain information from another \nsource. 5.3 Privacy Laws \nThis section maps Australian Information Commissioners Guide to Securing Personal \nInformation [8] to guidelines found in the Practice Guide. The following table decomposes the \nOffice of the Australian Information Commissioners Guide to Securing Personal Information \n[8] into requirements to facilitate mapping to the security characteristics in the Practice Guide. \nThe requirements table does not represent the Guide to Securing Personal Information in its \nentirety; rather, it uses the Information and Communication Technology Security section as a \nbasis. The Identifier column provides a shorthand notation for each ICT Requirement in the \nsecond column. \nTopics such as governance were deemed out of scope for comparison to guidelines found in the \nPractice Guide. However, the Guide to Securing Personal Information describes the security \ncharacteristics of cloud services that an organization should consider when storing personal \ninformation remotely in the cloud. These considerations are important for any organization that \nadopts either of the reference architectures in the Practice Guide because of the dependence of \ncloud services for email and mobile device management. Dependence of Australian \norganizations on cloud and mobile platforms was confirmed by MITREs consultation effort for \nthis project. For example, the OAIC guide recommends verifying security controls of a cloud service \nprovider to a sufficient level of detail, such as through independent testing and validation. An \norganization adopting the Practice Guide
architecture could satisfy this OAIC recommendation \nby reviewing the audit reports available on the Microsoft Azure (the cloud platform that supports \nIntune and Office365 practice guide products) website [27]. \n27 Table 5-ICT Requirements Table Identifier ICT Requirement ICT-1 \nIt is expected that entities regularly monitor the operation and effectiveness of their ICT \nsecurity measures to ensure that they remain responsive to changing threats and \nvulnerabilities and other issues that may affect the security of personal information. ICT-2 \nYou should be aware of the personal information you hold on your ICT system and where it is \nlocated. ICT-3 \nYour ICT security measures should ensure that all of your systems are secure and that they \nprovide a safe environment for your staff to carry out your business. ICT-4 Your ICT security measures should ensure that all of your systems are secure and that they \nprovide a safe environment for your customers to interact with your agency or business, for \nexample, when they make payments or provide their banking details and/or other personal \ninformation. ICT-5 \nICT security measures help mitigate the risks of internal and external attackers and the \ndamage caused by malicious software such as malware, computer viruses, and other harmful \nprograms. ICT-6 \nYou need to consider the security of all systems that use or interact with your ICT system. \nThis includes securing your website(s), social media platforms, and mobile device applications \n(apps). ICT-7 \nAs well as ICT security against external and internal threats, it is important to consider the \npossibility of human error (for example, misplacing devices such as laptops and data storage \ndevices, noting that encryption and password protection can mitigate this risk). ICT-8 \nAs well as ICT security against external and internal threats, it is important to consider the \npossibility of hardware or software malfunctions. ICT-9 \nAs well as ICT security against external and internal threats, it is important to consider the \npossibility of power failure. ICT-10 \nAs well as ICT security against external and internal threats, it is important to consider the \npossibility of system failure caused by natural disasters such as earthquakes, floods, and \nextreme weather conditions. \nTable 6 maps the requirements above to the security characteristics found in the Practice Guide. Table 6 ICT Requirements to Practice Guide Security Characteristic Mapping Security \nCharacteristic Example Capability ICT Requirement Data Protection protected storage: device encryption, secure containers, \ntrusted key storage, hardware security modules, remote \nwipe; protected communications: virtual private network \n(VPN), to include per-app VPN; data protection in process: \nencrypted memory, protected execution environments ICT-5, ICT-7 Data Isolation \nvirtualization, sandboxing, memory isolation, trusted \nexecution, device resource management, data flow control, \ndata tagging, baseband isolation ICT-5 \n28 Device Integrity baseband integrity checks, application black/whitelisting; \ndevice integrity checks: boot validation, application \nverification, verified application and OS updates, trusted \nintegrity reports, policy integrity verification ICT-5 Monitoring \ncanned reports and ad-hoc queries, auditing and logging, \nanomalous behavior detection, compliance checks, asset \nmanagement, root and jailbreak detection, geofencing ICT-1 Identity and Authorization local user authentication to applications, local user \nauthentication to device, remote user authentication, \nremote device authentication, implementation of user and \ndevice roles for authorization, credential and token storage \nand use, device provisioning and enrollment ICT-7 Privacy Protection informed consent of user, data monitoring minimization, \nprivacy notification provided to user No mapping exists to ICT \nrequirements \n29 \nFigure 3 Guide to Securing Personal Information Mapping 5.3.1 Key Findings The only government regulation that has a nationwide, direct effect on Australian organizations \nimplementing a mobile device security program is the Privacy Amendment (Notifiable Data \nBreaches) Act 2017. The recent introduction of the Privacy Amendment (Notifiable Data \nBreaches) Act 2017 will require organizations with obligations under the Privacy Act 1988 to \ncomply with data protection regulations when handling personal information [28]. Australian \norganizations should consider the effect of mobile device usage within their organization when \nhandling personal consumer data, and more broadly, the Australian Privacy Principles. The ICT requirements if adapted for the mobile environment provide broad coverage of the \nsecurity characteristics described in the Practice Guide. One characteristic that is covered in the \nPractice Guide but not addressed specifically by the ICT is privacy protection. It is worth noting \nthat the focus of the Practice Guide is on specific security controls and standards that support \nprivacy, for example, by enabling confidentiality of data. Such detailed controls and standards \nare often missing from government regulations or guidelines, which is not necessarily an issue if \nthe goal of such documents is to provide high-level direction rather than specific technical \nguidelines. For this reason, companies following the ICT requirements would need to augment Green denotes that the Practice Guide security characteristic was mapped to two or more \nrequirements, while yellow represents a mapping to one requirement. Red denotes that the security \ncharacteristic was not mapped to any requirements, thus signifying a gap. \n30 that information with practical mobile-specific guidelines that address the challenges faced when \nimplementing a secure mobile program. Conversely, the Practice Guide does not address four \nICT requirements that relate to IT governance because they are out of scope for this particular \nPractice Guide. 5.3.2 Technical Findings Data Protection ICT-5 and ICT-7 are broad requirements to ensure that security measures are in place to protect \nagainst external and internal threats. These requirements cite a need for protection against \nmalicious software and human error, both of which apply to mobile devices. The Practice Guide \narchitectures (cloud-only and hybrid) protect against malicious software (more commonly \nreferred to as malware in a mobile context) with the deployment of an MTD client on the mobile \ndevice as a requirement before the device owner is permitted to access organizational resources. \nIn addition, the Practice Guide describes the use of device ecosystemprovided application store \nmalware detection tools (e.g., Google Play Protect) that scan applications from developers as \napplications are uploaded, which prevents the spread of malware to end users. Human error, \nsuch as the device owner losing the mobile device, is protected against by use of an MDM. With \nappropriate organizational policy, the device owner is required to report a missing device to the \nappropriate personnel. The MDM administrator is then able to take actions such as wiping or \nphysically locating the phone through features of the MDM. Data Isolation The Practice Guide architectures protect against mobile malware (ICT-5) by using common \noperating system techniques. Process isolation prevents malware on the mobile device from \naccessing, gathering, or modifying information from other legitimate applications. Trust \nexecution environments further isolate sensitive operations from malware on the device. Device Integrity The Practice Guide architectures protect against mobile malware (ICT-5) by using device-\nspecific integrity checks such as operating system boot validation, cryptographically protected \napplication, and operating system updates. The first technique blocks the execution of the \noperating system when modifications have been detected. The use of cryptographically protected \napplications and operating system updates increases the difficulty of an attacker to distribute \nmobile malware. Monitoring Requirement ICT-1 uses regular monitoring of systems as a method to detect threats and \nvulnerabilities that may provide an attacker a vector to access, gather, or modify personal data. \nThe Practice Guide hybrid build supports this requirement through automated alerts that are sent \nto designated personnel when policy violations occur, such as when malware is detected on the \ndevice. The mobile device can then be remotely wiped or other actions performed as \norganizational policy dictates. \n31 Identity and Authorization Requirement ICT-7 suggests the use of passwords as a mechanism to protect against human \nerror, such as when a device is lost by the device owner. The Practice Guide cloud-only and \nhybrid builds support this requirement through enforcement of an MDM policy that requires the \ndevice user to set a pass code needed to unlock the device. The device automatically locks after a \nconfigured number of attempts and can be unlocked only by administrator action. At an \napplication level, the hybrid build further requires an enterprise password to access resources \nsuch as email, calendar, and contacts. Privacy Protection No ICT requirements directly map to this Practice Guide security characteristic. This is discussed \nfurther below. 5.4 Mapping Overview \nA diagram summarizing MITREs mapping of key Australian mobile security guidelines to the \nPractice Guide is provided in Figure 4. Three of the six security controlsdata protection, data \nisolation, and device integritywere addressed by all three Australian documents to some \nextent. One of the controls, monitoring, was addressed only by the ISM. Another control, \nidentity and authorization, was addressed by the Essential Eight and ICT guidelines but not in the \nISM. The privacy protection security control was found to be a gap across all three Australian \nguidelines. In addition, privacy on mobile devices can be achieved by implementing other \ntechnical security controls. For example, in the Practice Guide, privacy protection as a security \ncontrol includes informed consent of user, data monitoring minimization, and privacy \nnotification provided to user. \n32 Figure 4 Security Control Mapping Comparison ISM Control Mapping Essential Eight Mapping \nGuide to Securing \nPersonal Information Mapping \n33 Findings and Recommendations \nMany organizations in Australia, most notably SMEs, have little understanding of the risks
they \nface when using mobile devices. Some companies who do attempt to address these risks struggle \nto find relevant laws, standards, and guidelines that are easy to understand and implement. This \nis further complicated by the fact that guidelines produced by government agencies across the \nfederal and state levels are often inconsistent. For example, there is often confusion about what \nsteps are mandatory and which actions are voluntary. In addition, some of the guidelines related \nto cybersecurity that can be applied to mobile devices lead to stringent security controls that \nexceed the level of security necessary for many enterprises, especially for SMEs. \nMITREs assessment found that out of 47 security regulations, laws, standards, and guidelines, \nthree are particularly relevant and useful for mobile device security: ASDs Information Security \nManual, ASDs Essential Eight, and the OAICs Guide to Securing Personal Information. By \nmapping the Practice Guide to those three documents, MITRE was able to identify strengths, \nweaknesses, overlaps, and gaps. For example, our analysis found that the ISM mobile security \ncontrols and the Essential Eight were the most relevant to Australian organizations in part due to \nprocurement processes that reference these documents. \nOur analysis also showed that the Practice Guide provided useful and practical guidelines on the \nspecific issue of mobile device security within the Australian ecosystem. The Practice Guide \nfinds a reasonable balance between security and user functionality, which works well for \nAustralian organizations. \nAt present, the Practice Guide can be a useful adjunct to the existing set of Australian guidelines \nand could serve as a preeminent and comprehensive reference for organizations seeking to \nimprove the cybersecurity of mobile devices. Furthermore, MITREs analyses and consultations \nwith industry revealed that, with several modifications, the Practice Guide could become even \nmore useful for SMEs: Simplify the Practice Guides technical language to make the report more accessible to a \nwider audience, especially SMEs employing BYOD policies. Use infographics where \nappropriate. Include mobile security best practices and concrete examples in the Practice Guide. Discuss the benefits and limitations of using cloud-based solutions that provide built-in \nsecurity for SMEs relying on mobile devices for core business functions. \n Include a deeper discussion of the touchpoints between security and privacy. For example, the Guide could provide more information on the risks and benefits of storing \ndata on a mobile device versus saving it in a cloud. While the Practice Guide discusses \nthe use of encryption for data in transit, it could tailor that discussion to address easy-to-\nimplement approaches for SMEs. It could also include guidelines on encryption for data \nat rest. \n34 Organizations attempting to secure mobile devices must sift through a lengthy list of possible \nlaws, regulations, standards, and guidelines to discern what steps they must take and what \nactions are recommended as best practices. The Australian government can begin to address this \nissue by harmonizing the guidelines it provides to industry. In this area, Australia could learn \nfrom the United States experience in consolidating multiple competing government compliance \nframeworks, most notably the Department of Defenses transition from the Defense Information \nAssurance Certification and Accreditation Process to the NIST Cybersecurity Framework. One \nbenefit of using the Practice Guide is that it is based on that same framework, which is gaining \nsignificant traction globally [29], including within Australia. \nThis study only scratched the surface of this complex issue by mapping specific controls in three \ndocuments to those in the Practice Guide. Further analyses of this type could yield important \ninsights into the overlaps and gaps that organizations face in following the multiple cybersecurity \nrequirements and guidelines emanating from government. \nMITRE recommends that AustCyber, as a government-funded and industry-facing independent \nentity, take the lead in facilitating intergovernmental and multistakeholder discussions on \ncybersecurity standards harmonization with mobile device security serving as the initial use case \nbecause of its broad applicability across both SMEs and larger enterprises. \nA-1 Appendix A NIST Special Publication 1800-4 Security Control Map \nThe table below is the original mapping of practice guide security characteristics to the NIST Cybersecurity Framework, NIST Special \nPublication 800-53 controls, ISO 27002 and the Council on Cybersecuritys Critical Security Controls for Effective Cyber Defense. Example Characteristic Cybersecurity Standards and Best Practices Security \nCharacteristic Example Capability CSF \nFunction CSF Category CSF \nSubcategory NIST SP 800-53 rev4 IEC/ISO \n27002 CAG20 Data Protection protected storage: device \nencryption, secure containers, \ntrusted key storage, hardware \nsecurity modules, remote \nwipe; protected \ncommunications: virtual \nprivate network (VPN), \nincluding per-app VPN; data \nprotection in process: \nencrypted memory, protected \nexecution environments Protect Data Security, \nProtective \nTechnologies PR.DS-1 \nPR.DS-2 \nPR.DS-5 \nPR.PT-4 AC-20, AU-9, IA-6, IA-\n7, MP-6, SA-13, SC-8, \nSC-11, SC-12, SC-13, \nSC-17, SI-12 6.2.1 \n9.4.3 \n9.4.4 \n9.4.5 \n10.1.2 \n12.4.2 \n12.4.3 \n13.1.1 \n13.2.1 \n13.2.3 \n14.1.3 CSC-15 Data Isolation virtualization, sandboxing, \nmemory isolation, trusted \nexecution, device resource \nmanagement, data flow \ncontrol, data tagging, \nbaseband isolation Protect Data Security, \nProtective \nTechnologies PR.DS-1 \nPR.DS-5 \nPR.PT-3 CM-11, SA-13, SC-3, \nSC-11, SC-35, SC-39, \nSC-40, SI-16 6.2.1 \n6.2.2 \n9.4.1 \n9.4.4 \n12.2.1 CSC-7 \nCSC-12 \nCSC-14 Device Integrity baseband integrity checks, \napplication black/whitelisting; \ndevice integrity checks: boot \nvalidation, application \nverification, verified \napplication and OS updates, \ntrusted integrity reports, policy \nintegrity verification Protect, \nDetect Data \nProtection, \nAnomalies and \nEvents, Security \nContinuous \nMonitoring PR.DS-6 \nDC.CM-4 \nDE.CM-5 \nDE.CM-6 AC-20, CM-3, IA-3, \nIA-10, SA-12, SA-13, \nSA-19, SC-16, SI-3, \nSI-4, SI-7 6.2.1 \n12.2.1 \n14.2.4 \n15.1.3 CSC-3 \nCSC-6 \nCSC-12 \nA-2 Monitoring canned reports and ad-hoc \nqueries, auditing and logging, \nanomalous behavior detection, \ncompliance checks, asset \nmanagement, root and \njailbreak detection, geofencing Identify, \nProtect, \nDetect Asset \nManagement, \nMaintenance, \nProtective \nTechnology, \nAnomalies and \nEvents, Security \nContinuous \nMonitoring, \nDetection \nProcesses ID.AM-1 \nID.AM-2 \nPR.DS-3 \nPR.MA-2 \nPR.PT-1 \nDE.AE-1 \nDE.AE-1 \nDE.AE-3 \nDE.AE-5 \nDE.CM-1 \nDE.CM-3 \nDE.CM-4 \nDE.CM-5 \nDE.CM-6 \nDE.CM-7 \nDE.CM-8 \nDE.DP-2 \nDE.DP-4 AC-2, AC-3, AC-7, \nAC-21, AC-25, AU-3, \nAU-5, AU-5, AU-7, \nAU-8, AU-9, AU-10, \nAU-12, AU-13, \nAU-14, AU-15, \nAU-16, CA-7, CM-2, \nCM-3, CM-6, CM-8, \nCM-11, IA-4, IR-4, \nIR-5, IR-7, IR-9, MA-\n6, SA-13, SA-22, \nSC-4, SC-5, SC-7, \nSC-18, SC-42, SC-43, \nSI-3, SI-4, SI-5 6.1.4 \n6.2.1 \n6.2.2 \n8.1.1 \n8.1.2 \n9.2.3 \n9.2.5 \n9.4.4 \n9.4.5 \n10.1.2 \n12.2.1 \n12.4.1 \n12.4.2 \n12.4.3 \n12.5.1 \n12.6.1 \n12.7.1 \n13.1.1 \n15.1.3 \n16.1.2 \n16.1.4 \n16.1.5 \n18.2.3 CSC-1 \nCSC-2 \nCSC-5 \nCSC-6 \nCSC-10 \nCSC-11 \nCSC-12 \nCSC-13 \nCSC-14 \nCSC-18 \nA-3 Identity and \nAuthorization local user authentication to \napplications, local user \nauthentication to device, \nremote user authentication, \nremote device authentication, \nimplementation of user and \ndevice roles for authorization, \ncredential and token storage \nand use, device provisioning \nand enrollment Protect, \nDetect Access Control, \nProtective \nTechnologies, \nAsset \nManagement ID.AM-1 \nPR.AC-1 \nPR.AC-3 \nPR.AC-4 \nPR.PT-3 \nDE.CM-3 \nDE.CM-7 AC-2, AC-3, AC-4, AC-\n5, AC-6, AC-7, AC-16, \nAC-17, AC-18, AC-19, \nAC-20, AU-16, CM-5, \nCM-7, IA-2, IA-3, IA-\n5, IA-6, IA-7, IA-8, IA-\n9, IA-11, MP-2, SA-9, \nSA-13, SA-19, SC-4, \nSC-16, SC-40 6.2.1 \n6.2.2 \n9.1.1 \n9.1.2 \n9.2.1 \n9.2.2 \n9.2.3 \n9.2.4 \n9.3.1 \n9.4.1 \n9.4.2 \n9.4.3 \n13.1.1 \n13.1.2 \n13.2.2 \n13.2.3 \n14.1.2 \n14.1.3 CSC-8 \nCSC-9 Privacy \nProtection informed consent of user, data \nmonitoring minimization, \nprivacy notification provided \nto user Identify, \nProtect Governance, \nTraining and \nAwareness ID.GV-3 \nPR.AT-1 AR-4, AR-7, DM-1, \nIP-1, IP-2, SE-1, TR-1, \nUL-1 18.1.4 CSC-17 \nB-1 Appendix B NIST Special Publication 1800-4 Australian Privacy Principles Coverage \nThe table below presents the applicability of Australian Privacy Principles to the Mobile Device Security Practice Guide. Principle Sub Principle 1800-4 Coverage Australian Privacy Principle 1open and transparent management of personal information Compliance with the Australian Privacy Principles, etc. Not Applicable APP privacy policy Partial Applicability Availability of APP privacy policy, etc. Applicable Australian Privacy Principle 2anonymity and pseudonymity Option of not identifying or use of a pseudonym Not Applicable Australian Privacy Principle 3collection of solicited personal information Personal information other than sensitive information Applicable Sensitive information Applicable Means of collection Applicable Solicited personal information Applicable Australian Privacy Principle 4dealing with unsolicited personal information Dealing with the receipt of PI without solicitation Not Applicable Australian Privacy Principle 5notification of the collection of personal information Reasaonable steps to notify individuals of PI collected Partial Applicability Australian Privacy Principle 6use or disclosure of personal information Use or disclosure Not Applicable Written note of use or disclosure Not Applicable Related bodies corporate Applicable Exceptions Not Applicable Australian Privacy Principle 7direct marketing Direct marketing Not Applicable Exceptionspersonal information other than sensitive information Not Applicable Exceptionsensitive information Not Applicable Individual may request not to receive direct marketing communications, etc. Not Applicable Interaction with other legislation Not Applicable Australian Privacy Principle 8cross-border disclosure of personal information Disclosure of PI to overseas recipients Not Applicable Australian Privacy Principle 9adoption, use, or \ndisclosure of government-related identifiers Adoption of government-related identifiers Not Applicable Use or disclosure of government-related identifiers Not Applicable Regulations about adoption, use, or disclosure Not Applicable Australian Privacy Principle 10quality of personal information PI collected is accurate and complete Partial Applicability \nB-2 Australian Privacy Principle 11security of personal information All Applicable Australian Privacy Principle 12access to personal information Access Partial Applicability Exception to accessagency Not Applicable Exception to accessorganization Partial Applicability Dealing with requests for access Not Applicable Other means of access Not Applicable Access charges Not Applicable Refusal to give access Not Applicable Australian Privacy Principle 13correction of personal information Correction Partial Applicability Notification of correction to third parties Not Applicable Refusal to correct information Not Applicable Request to associate a statement Not Applicable Dealing with requests
Not Applicable C-1 Appendix C Applicable Cybersecurity Regulations, Standards, \nand Guidelines The table below is an exhaustive list of applicable regulations, standards, and guidelines grouped \nby sector or industry. Sector/Audience Name Hyperlink \nBanking and Finance APRA CPG 235 http://www.apra.gov.au/CrossIndustry/Documents/Pru dential-Practice-Guide-CPG-235-Managing-Data-\nRisk.pdf Banking and Finance PPG 234 http://www.apra.gov.au/crossindustry/documents/ppg\n_ppg234_msrit_012010_v7.pdf Banking and Finance ISO 27001/2 https://www.iso.org/isoiec-27001-information-\nsecurity.html Banking and Finance COBIT 5 http://www.isaca.org/cobit/pages/default.aspx \nGeneral NIST Cybersecurity Framework https://www.nist.gov/cybersecurity-framework \nGeneral Cybercrime Act 2001 https://www.legislation.gov.au/Details/C2004C01213 \nGeneral Risk Management of Enterprise Mobility Including Bring Your Own Device (BYOD) \nhttps://www.asd.gov.au/publications/protect/enterpris\ne_mobility_bring_your_own_device_byod.htm General Cyber Security for Contractors https://www.asd.gov.au/publications/protect/Cyber_S\necurity_for_Contractors.pdf General Privacy Amendment (Notifiable Data Breaches) \nAct 2017 https://www.legislation.gov.au/Details/C2016B00173 General and Government Strategies to Mitigate Cyber Security Incidents https://www.asd.gov.au/infosec/top-\nmitigations/mitigations-2017-table.htm Government Australian Government Protective Security Policy \nFramework (PSPF) https://www.protectivesecurity.gov.au/Pages/default.a\nspx Government Information Security Manual (ISM) https://www.asd.gov.au/infosec/ism/ \nGovernment iRAP https://www.asd.gov.au/infosec/irap.htm \nGovernment and \nHealthcare TGA https://www.tga.gov.au/publication-issue/medical-\ndevices-safety-update-volume-4-number-2-march-2016 Government Information Security Management \nGuidelines: Risk Management of Outsourced ICT \nArrangements (Including Cloud) https://www.protectivesecurity.gov.au/informationsec\nurity/Documents/AustralianGovernmentInformationSe\ncurityManagementGuidelines.pdf Healthcare Royal Australian College of General Practitioners \n(RACGP) Computer and Information Security \nStandards https://www.racgp.org.au/your-\npractice/standards/computer-and-information-\nsecurity-standards/ Healthcare National Health and Medical Research Councils \n\"The Regulation of Health Information Privacy in \nAustralia\" https://www.nhmrc.gov.au/_files_nhmrc/publications/\nattachments/nh53.pdf Healthcare ISO 27001/2 https://www.iso.org/isoiec-27001-information-\nsecurity.html Healthcare COBIT 5 http://www.isaca.org/cobit/pages/default.aspx \nInsurance Breach Notification http://www.apra.gov.au/CrossIndustry/Pages/Breach- Notification.aspx \nISP Telecommunications (Interception) and Listening Device Amendment Act \nhttps://www.legislation.gov.au/Details/C2004C01072 ISP Communications Alliance C650:2014 icode http://www.commsalliance.com.au/ data/assets/pdf_\nfile/0019/44632/C650_2014.pdf ISP Australian Communications and Media \nAuthority's Australian Internet Security Initiative \n(ACMA, 2015) https://www.cert.gov.au/aisi ISP ISO 27001/2 https://www.iso.org/isoiec-27001-information-\nsecurity.html ISP COBIT 5 http://www.isaca.org/cobit/pages/default.aspx \nManufacturing ISO 27001/2 https://www.iso.org/isoiec-27001-information- security.html \nManufacturing COBIT 5 C-2 Mining ISO 27001/2 https://www.iso.org/isoiec-27001-information-\nsecurity.html Mining ISO 27019 \nMining COBIT 5 http://www.isaca.org/cobit/pages/default.aspx \nNSW Government Digital Information Security Policy https://www.finance.nsw.gov.au/ict/priorities/managin g-information-better-services/information-security \nGeneral Privacy Act 1988 https://www.legislation.gov.au/Details/C2017C00283 \nGeneral Telecommunications Consumer Protection Code http://www.commsalliance.com.au/Documents/all/cod es/c628 \nGeneral Spam Act https://www.legislation.gov.au/Details/C2014C00214 \nGeneral Do Not Call Register Act https://www.legislation.gov.au/Details/C2015C00258 \nGeneral Payment Card Industry Data Security Standard https://www.pcisecuritystandards.org/pci_security/sta ndards_overview \nGeneral Mobile PrivacyA Better Practice Guide for Mobile App Developers \nhttps://www.oaic.gov.au/agencies-and-\norganisations/guides/guide-for-mobile-app-developers General Guide to Securing Personal Information https://www.oaic.gov.au/agencies-and-\norganisations/guides/guide-to-securing-personal-\ninformation Telecommunications \nProviders Telecommunications (Interception) and Listening \nDevice Amendment Act https://www.legislation.gov.au/Details/C2004C01072 Telecommunications \nProviders Australian Communications and Media \nAuthority's Australian Internet Security Initiative \n(ACMA, 2015) https://www.cert.gov.au/aisi Telecommunications \nProviders ISO 27001/2 https://www.iso.org/isoiec-27001-information-\nsecurity.html Telecommunications \nProviders COBIT 5 http://www.isaca.org/cobit/pages/default.aspx Utilities ISO 27001/2 https://www.iso.org/isoiec-27001-information-\nsecurity.html Utilities ISO 27019 \nUtilities COBIT 5 http://www.isaca.org/cobit/pages/default.aspx \nUtilities NERC-CIP V5 http://www.nerc.com/pa/Stand/Pages/CIPStandards.as px D-1 Appendix D Australian State Mobile Device Procurement Policies \nThe table below provides hyperlinks to relevant Australian state procurement policies for mobile devices. Note that some resources may \nnot be mobile device specific but instead refer to general IT requirements. State Mobile Procurement Policy Hyperlink \nNew South Wales NSW Government Mobile Device and Application Framework https://www.finance.nsw.gov.au/ict/sites/default/files/resources/NSW \npercent20Government20Mobile%20Device%20%20Application%20Framework.pdf General IT requirements protecting consumer data, security, and \nprivacy http://ec2-54-66-245-30.ap-southeast-2.compute.amazonaws.com/?q=node/194 http://beta32.procurepoint.nsw.gov.au/?q=node/239 Victoria No specific policies found but previous mobile device security-\nrelated procurements exist through telecommunications \ncontracts. Note that Microsoft O365 includes minimal EMM \nfunctionality. http://www.procurement.vic.gov.au/State-Purchase-Contracts/Telecommunications-TPAMS2025-Services http://www.procurement.vic.gov.au/State-Purchase-Contracts/Microsoft-Enterprise-Agreement Northern \nTerritory No mobile-specific policy found. Last IT procurement policy dated \n2009. https://nt.gov.au/industry/government/procurement-conditions-framework/conditions-\ncontract/others/government-information-technology-contract South Australia No mobile-specific policy found. Queensland No mobile-specific policy found, but Departments should ensure \nthat all legal and regulatory obligations under which they operate \nare observed when conducting procurement processes. https://www.qgcio.qld.gov.au/documents/procurement-and-disposal-of-ict-products-and-services-\nimplementation-guideline https://www.qgcio.qld.gov.au/documents/information-security-is18-information-standard Tasmania No mobile-specific policy found, but Networking Tasmania \nprotects the security, integrity and availability of your \ninformation assets through security practices based on industry \nstandards, such as ISO 27001/. These supplier security practices \nare regularly audited and reviewed to ensure compliance with \nGovernments requirements. https://www.tmd.tas.gov.au/networking_tasmania/learn_about_networking_tasmania Western Australia The Department of Finance site recommends consideration of \nASD Cloud Computing Security Considerations when assessing \nrisk factors during procurement of cloud services. https://www.finance.wa.gov.au/cms/Government_Procurement/Cloud_Computing/Cloud_Computing_Resour\nces.aspx Australian Capital \nTerritory No mobile-specific policy found. E-1 Appendix E Abbreviations and Acronyms \nABS ACMA Australian Bureau of Statistics Australia Communications and Media Authority ACSC APP Australian Cyber Security Centre Australian Privacy Principles ASD Australian Signals Directorate ATO Australian Tax Office AustCyber Australian Cyber Security Growth Network BYOD bring your own device COPE company owned personally enabled CVE common vulnerabilities and exposures FIPS Federal Information Processing Standards ICT information and communication technology IEC International Electrotechnical Commission IRAP Information Security Registered Assessors Program ISM Information Security Manual ISO International Organization for Standardization MDM mobile device management MTC Mobile Threat Catalogue NCCoE National Cybersecurity Center of Excellence NICE National Initiative for Cybersecurity Education NIST National Institute of Standards and Technology OAIC Office of the Australian Information Commissioner PSPF Protective Security Policy Framework SME small and medium enterprise SMS short message service VPN virtual private network F-1 Appendix F References \n[1] G. Gilfillan. (2018, Feb 7). Definitions and Data Sources for Small Business in Australia: a quick guide, Parliament of Australia. Available: \nhttps://www.aph.gov.au/About_Parliament/Parliamentary_Departments/Parliamentary\n_Library/pubs/rp/rp1516/Quick_Guides/Data. [2] Financial System Inquiry. (2018, Jan 4). Small- and Medium-Sized Enterprises. \nAvailable: \nhttp://fsi.gov.au/publications/interim-report/03-funding/small-med-enterprises/. [3] Australian Government: Business. (2018, Jan 4). Keep Your Business Safe from \nCyber Threats, business.gov.au. Available: \nhttps://www.business.gov.au/info/run/cyber-security/keep-your-business-safe-from-\ncyber-threats. [4] Australian Government. (2018, Jan 4). Stay Smart Online. Available: \nhttps://www.staysmartonline.gov.au/. [5] Australian Government. (2018, Feb 1). 8129.0Business Use of Information \nTechnology, 2015-16, Australian Bureau of Statistics. Available: \nhttp://www.abs.gov.au/ausstats/abs@.nsf/mf/8129.0. [6] Australian Government. (2014, Jan). Report 1Australian SMEs in the Digital \nEconomy, Australian Communications and Media Authority. Available: \nhttps://www.acma.gov.au/-/media/Research-and-Analysis/Report/pdf/Australian-\nSMEs-in-the-digital-economy-pdf.pdf?la=en. [7] Australian Government. (2015, Mar). Report 1Australians Digital Lives, \nAustralian Communications and Media Authority. Available: \nhttps://www.acma.gov.au/~/media/Research%20and%20Analysis/Research/pdf/Austr\nalians%20digital%20livesFinal%20pdf.pdf. [8] DeviceAtlas. (2018, Jan 4). Web Usage of Device Names by Country. Available: \nhttps://deviceatlas.com/device-data/explorer/webusage-by-country/traffic/no-\ntablet/country/au/type/device_marketing. [9] Android Open Source Project. (2018, Jan 4). About the Android Open Source \nProject. Available: \nhttps://source.android.com/. [10] Android Open Source Project. (2018, Jan 4). Security Updates and Resources. \nAvailable: https://source.android.com/security/overview/updates-resources. [11] L. Newman. (2017, Sept). Inside Android Oreos Quest to Protect Your Phone, \nWIRED. Available: \nhttps://www.wired.com/story/android-oreo-security-improvements/. [12] Mobile Threat Catalogue, NIST NCCoE, 2018. Available: \nhttps://pages.nist.gov/mobile-threat-catalogue/. [13] Australian Government. (2018, Feb). Hacking, Australian Competition and \nConsumer Commission. Available: \nhttps://www.scamwatch.gov.au/types-of-scams/attempts-to-gain-your-personal-\ninformation/hacking. [14] Australian Government. (2018, Feb). Phishing, Australian Competition and \nConsumer Commission. Available: F-2 https://www.scamwatch.gov.au/types-of-scams/attempts-to-gain-your-personal-\ninformation/phishing. [15] press-au@squareup.com. (2018, Jan 4). Square Reader Now Sold in More Than 490 \nRetail Stores Across Australia, Through Officeworks, Apple and Bunnings, Square, \nInc. Available: \nhttps://squareup.com/au/news/square-reader-now-sold-in-more-than-490-retail-stores-\nacross-australia-through-officeworks-apple-and-bunnings. [16] Guide to Bluetooth Security, NIST Special Publication 800-121 Revision 2, National \nInstitute of Standards and Technology, Gaithersburg, Maryland, 2016. Available: \nhttps://csrc.nist.gov/CSRC/media/Publications/sp/800-121/rev-\n2/draft/documents/sp800_121_r2_draft.pdf. [17] Australian Government. (2018, Jan 4). Small Business Entity Concessions, \nAustralian Taxation Office. Available: \nhttps://www.ato.gov.au/business/small-business-entity-concessions/eligibility/. [18] Guidelines for Managing the Security of Mobile Devices in the Enterprise, NIST \nSpecial Publication 800-124 Revision 1, 2013. Available: \nhttp://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-124r1.pdf. [19] Mobile Device SecurityCloud and Hybrid Builds Approach, Architecture, and \nSecurity Characteristics, NIST Special Publication 1800-4, 2015. Available: \nhttps://nccoe.nist.gov/publication/1800-4b. [20] Standards Australia. (2018, Feb 7). What Is a Standard? Available: \nhttp://www.standards.org.au/StandardsDevelopment/What_is_a_Standard/Pages/defau\nlt.aspx. [21] Australian Government. (2018, Jan 4). Entities Covered by the NDB Scheme, \nOffice of the Australian Information Commissioner. Available: \nhttps://www.oaic.gov.au/privacy-law/privacy-act/notifiable-data-breaches-\nscheme/entities-covered-by-the-ndb-scheme#small-business-operators. [22] Australian Signals Directorate. (2018, Jan 4). Essential Eight Explained, Information \nSecurity Advice. Available: \nhttps://www.asd.gov.au/publications/protect/essential-eight-explained.htm. [23] Australian Signals Directorate. (2018, Jan 4). Cloud Computing Security for \nTenants. Available: \nhttps://www.asd.gov.au/publications/protect/cloud-security-tenants.htm. [24] Australian Government Information Security Manual. (2017). Australian Signals \nDirectorate. Available: \nhttps://www.asd.gov.au/publications/Information_Security_Manual_2017_Controls.p\ndf. [25] Australian Government. (2018, Jan 4). Guide to Securing Personal Information, \nOffice of the Australian Information Commissioner. Available: \nhttps://www.oaic.gov.au/agencies-and-organisations/guides/guide-to-securing-\npersonal-information. [26] Australian Government. (2018, Jan 4). Mobile PrivacyA Better Practice Guide for \nMobile App Developers, Office of the Australian Information Commissioner. \nAvailable: \nhttps://www.oaic.gov.au/agencies-and-organisations/guides/guide-for-mobile-app-\ndevelopers. F-3 [27] W. Fabritius. (2017, April). Assessment Report Microsoft Corporation Micrcosoft \nAzure, bsi. Available: \nhttps://servicetrust.microsoft.com/ViewPage/MSComplianceGuide?command=Downl\noad&downloadType=Document&downloadld=498137f0-31da-4100-a323-\n35abf229b13b&docTab=4ce99610-c9c0-11e7-8c2c-f908a777fa4d_ISO%20Reports. [28] Australian Government. (2018, Feb 7). Privacy Amendment (Notifiable Data \nBreaches) Act 2017, Federal Register of Legislation. Available: \nhttps://www.legislation.gov.au/Details/C2017A00012. [29] Crowell Moring. (2018, Jan 4). The Global Uptake of the NIST Cybersecurity \nFramework. Available: \nhttps://www.crowell.com/files/20160215-The-Global-Uptake-of-the-NIST-\nCybersecurity-Framework-Wolff-Lerner-Miller-Welling-Hoff.pdf. ",
    "text": " 3/27/18 iVAS Project Story for mitre.org Approved for Public Release; Distribution Unlimited. 18-1115 Intelligent Voice Agent Improves Customer Service for Government Agencies If smart machines could answer the typical questions asked by callers to government agencies, it \ncould greatly reduce customer wait times. MITRE's Intelligent Voice Agent & Service prototype \ndemonstrates how to do just that by interacting with customers, improving customer service, and \nstreamlining communications. Callers to government agencies often hear messages like, \"Thank you for calling. Your call is important to \nus. You are the 10th caller in the queue and your expected hold time is X amount of minutes.\" The more callers in the queue, the longer the \"X\" amount of minutesand the higher a caller's frustration. Although government agencies have web-based resources to assist customers, extended hold times at \nfederal agency call centers persist. Exploring how government agencies can improve their interaction with \nthe public, a team of MITRE researchers developed a voice agent that can effectively answer the typical \nquestions asked by callers. Using it leaves agency staff free to answer the tough questions, which \nsignificantly reduces caller wait time. Say \"hello\" to MITRE's Intelligent Voice Agent & Service, or iVAS. The interactive voice agent \nincorporates both natural-language understanding and artificial intelligence technologies to interpret a \ncaller's spoken questions in context, understand the different ways people ask the same question, and asks \nthe caller for specific information to clarify the question. iVAS then delivers precise, personalized \nanswers. AI and Natural Language Understanding: A Powerful Combination Unable to find a commercial speech-recognition technology that could meet their needs, various \ngovernment agencies began exploring their options. MITRE's experience in speech recognition, natural \nlanguage learning, and artificial intelligence provided the perfect combination of expertise to develop a \nsystem that could be adapted for use across all government organizations. MITRE's Jim Lockett, Qian Hu, and an interdisciplinary research team are researching and developing \niVAS to meet the specific needs of government agenciesfor example, it aims to work with all the \ncommonly used voice assistants that people use at home. \"MITRE developed this technology to help government call centers provide meaningful, relevant, \nindividualized answers that people can act on after making a call,\" says Hu, MITRE's chief scientist for \nspeech technology and artificial intelligence. Intelligent Voice Agent Effectively Solves a Problem What makes iVAS different from commercial voice assistants like Amazon's Alexa, Apple's Siri, or \nGoogle Assistant? Hu explains that commercial voice assistants are search retrieval-based. They mainly \ndeal with general and popular topics. In other words, they can't deliver the kind of concise, personalized, \nand relevant answers that callers to a government agency are seeking. \"The iVAS system deals with domain-specific information and frequently asked questions for a particular \nagency,\" she says. \"For example, if the system is being used by the IRS, questions and response are https://www.mitre.org/publications/project-stories/mitre-technology-lets-you-use-your-voice-to-protect-mobile-devices\nhttps://www.mitre.org/publications/project-stories/mitre-technology-lets-you-use-your-voice-to-protect-mobile-devices\nhttps://www.mitre.org/publications/project-stories/mitre-technology-lets-you-use-your-voice-to-protect-mobile-devices\nhttps://www.mitre.org/publications/project-stories/mitre-technology-lets-you-use-your-voice-to-protect-mobile-devices\nhttps://www.mitre.org/publications/project-stories/deeplang-teaches-computers-to-measure-their-words\nhttps://www.mitre.org/publications/project-stories/deeplang-teaches-computers-to-measure-their-words\nhttps://www.mitre.org/publications/project-stories/deeplang-teaches-computers-to-measure-their-words\nhttps://www.mitre.org/publications/project-stories/deeplang-teaches-computers-to-measure-their-words\nhttps://www.mitre.org/publications/project-stories/deeplang-teaches-computers-to-measure-their-words\nhttps://www.mitre.org/publications/project-stories/deeplang-teaches-computers-to-measure-their-words\nhttps://www.mitre.org/news/in-the-news/mitre-among-top-investors-in-artificial-intelligence\nhttps://www.mitre.org/news/in-the-news/mitre-among-top-investors-in-artificial-intelligence\nhttps://www.mitre.org/news/in-the-news/mitre-among-top-investors-in-artificial-intelligence\nhttps://www.mitre.org/news/in-the-news/mitre-among-top-investors-in-artificial-intelligence specific to tax-related topics.\" Another feature that sets iVAS apart from commercial voice assistants is the system's interactivity. \nNatural language understanding allows iVAS to interpret and respond to the various ways a caller might \nask the same question. Artificial intelligence enables the system to anticipate and ask additional questions, \nrefining a caller's query to deliver the most relevant and personalized response. iVAS can also synthesize \nresponses from callers so the system can adapt and learn. [embed 2-minute video here] Future Applications for Intelligent Voice Agent Technology According to Hu, government feedback of iVAS has been very positive. \"When we demonstrated the \ncapabilities of the iVAS prototype to our sponsors, they were already thinking about how they could \nimplement the technology.\" The same underlying technologynatural language understanding and anticipatory question-and-answer \ncapabilityis also being used for government use of chatbots and text-to-speech recognition capabilities. \"There's a lot of potential for how this technology can be applied,\" says Lockett, a principal system \nengineer who specializes in information and agile systems. \"For instance, the Department of Veterans \nAffairs could use it for depression screening and the IRS could help people check their refund status.\" \"When you have a multi-disciplinary team like ours working together, it creates the power to deliver \ngreater capabilities,\" Hu says. \"In this way we're better able to solve crucial problems for our sponsors, \nwhich means we're solving problems for the public.\" --by Lisa Pacitto https://www.mitre.org/publications/project-stories/exploring-speech-features-to-assist-ptsd-diagnosis _top\n _GoBack ",
    "text": " 1 National Cybersecurity Center of Excellencehttps://www.nccoe.nist.gov/about-the-center/strategy Approved for Public Release: 18-1343.\nCopyright has been transferred to another party. Reuse is restricted. Contact the Contracts Management Office for \nguidance. Practical and Actionable Cybersecurity Solutions for Securing Protected Health \nInformation By Sue Wang and Zach Furness, The MITRE Corporation This article discusses how the National Cybersecurity Center of Excellence (NCCoE) develops practical \nand usable cybersecurity guidance that can be adopted across industries, including the healthcare \nsector. The NCCoE works across public-private partnerships to create National Institute of Standards \nand Technology (NIST) Special Publication (SP) 1800 Series practice guides that are focused on specific \nindustry challenges that companies can adopt for use. Over the past decade, cyberattacks against industry and the government have continued to grow, \ndespite increases in spending, advances in security products, and public awareness of the problem. \nCybersecurity is not just a technical problemit is also complicated by a landscape of policy and \nregulation mandates, business and operation needs, and human behavior. These complexities require \napproaches that can bring together participants from across the public and private sectors to work on \njoint solutions that can bridge these domains. The NCCoE was established in 2012 and is co-sponsored by NIST, the State of Maryland, and \nMontgomery County to support trustworthiness in government and commercial sectors while also \nworking to strengthen economic growth for Maryland and the nation. Its mission is to accelerate \nadoption of secure technologies by collaborating with innovators to provide real-world, standards-based \ncybersecurity capabilities.1 It does this by undertaking projects that include stakeholders from industry \nalong with government and commercial security companies to develop reference solutions that are \nfocused on cybersecurity challenges identified by industrial sectors. NCCoE Practice Guides NCCoE guidance is documented via NIST SP 1800 Series practice guides. These guides complement the \nmore traditional and well-known NIST SP 800 Series IT security guidance, which has been adopted across \nindustry and the federal government. Practice guides focus on the practical application of existing \nstandards and guidance rather than create new standards. This is in line with a philosophy that most \ncyberattacks can be prevented by using current standards and technology. What is lacking is a general \nunderstanding of how to apply those capabilities against specific problems. NCCoE practice guides follow several core tenets: Standards-based. As mentioned above, practice guides focus on applying existing standards and \ntechnology as opposed to creating new standards and technology. A key element of a guide is \nmapping functions within the challenge problem to appropriate security controls such as those \ndocumented in NIST 800-53, ISO/IEC (27001), and other relevant standards. The NIST https://www.nccoe.nist.gov/about-the-center/strategy 2 Cybersecurity Framework is used in each practice guide to map these controls.\nModular. Practice guides provide a reference solution, which is one of many possible solutions that can be applied to a problem at hand. Functional elements of the solution, such as an \nIntrusion Detection System, firewall, or Security Event and Information Management system, \ncan be met by more than one commercial component. These solutions are modular, allowing \nother security products to be substituted in place of the one used in the practice guide. Repeatable. Volume C of a practice guide contains all of the supporting documentation, such as \nscreenshots and installation procedures, that one would need to replicate the work done in \ndeveloping the reference solution. This allows an engineer or IT security integrator to \nunderstand the details of the build that was done in the NCCoE labs. Commercially available. No custom software or hardware is employed in a practice guideall the \ncomponents are commercially available. This helps promote the idea that a solution exists that \ncan be readily implemented by an end user and that is based on existing technology. Usable. Creating the reference solution in the NCCoE labs helps ensure that the implementation \nwill be usable. By employing the solution in the context of the intended problem, we can \nunderstand how usable the solution is. Open and transparent. The overall process for practice guide development is open to anyone \nfrom the industrial sector or product vendors who are interested in contributing to the solution. \nPractice guides are freely available on the NCCoE website to anyone who wishes to integrate \nthe guidance into his or her solutions. The figure below provides an overview of the practice guide development process. It begins by defining a \ncybersecurity challengetypically brought forward based on discussions with industry organizations that \nmake up one of our communities of interest (COI). The COI helps validate the problem and works with \nNCCoE engineers to document a formal use case and project description. The project description is used \nto solicit requests for interested organizations to participate in the projecttypically through a Federal \nRegister Notice. Organizations that are selected to participate in the build provide technology necessary \nto re-create the challenge problem within the NCCoE lab. The integration of those components results in \na reference implementation that can serve as a guide to industry in addressing the original problem. \nResults of the work are documented in a NIST SP 1800 Series practice guide and are freely shared with \nindustry and government. 3 2 Nick Ismail, Is safeguarding data the rising challenge in the rapidly changing world of healthcare IT?, Information \nAge (June 14, 2017) \nhttp://www.information-age.com/safeguarding-data-challenge-healthcare-123466743/ \n3 U.S. Department of Health and Human Services, Office for Civil Rights, Breach Portal \nhttps://ocrportal.hhs.gov/ocr/breach/breach_report.jsf \n4 Elizabeth Snell, Healthcare Hacking Leading Cause for 2017 Incidents, HealthITSecurity (June 6, 2017)\nhttps://healthitsecurity.com/news/healthcare-hacking-leading-cause-for-2017-incidents \n5 Ponemon Institute, 2017 Cost of Data Breach Studyhttps://www-\n01.ibm.com/marketing/iwm/dre/signup?source=urx-15763&S_PKG=ov58441&S_VCPI=Search_Google-_-\nSecurity_Optimize+the+Security+Program-_-WW_NA-_-ponemon+Institute_Exact_-\n6 2017 HIMSS Cybersecurity Survey \nhttp://www.himss.org/sites/himssorg/files/2017-HIMSS-Cybersecurity-Survey-Final-Report.pdf \n7 Gavin OBrien, Sue Wang, Brett Pleasant, Kangmin Zheng, Nate Lesser, Colin Bowers, and Kyle Kamke, Securing Since its establishment, the NCCoE has published 11 practice guides that support industry and broad \ntechnology areas. Solutions are derived either from problems in specific industries or from broad \ntechnology challenges that are common to multiple sectors. While the sector-specific approaches are \nprimarily focused on aspects relevant to that sector, it is possible to reuse a solution from one sector to \nanother if the underlying challenges have much in common. For example, the core elements of an IT \nasset management solution for the financial services sector could be reused in healthcare or energy \nunder appropriate circumstances. NCCoE Healthcare Sector Projects Technology is the driving force behind modern healthcare and provides many benefits to patient care. \nThe modern healthcare ecosystem presents challenges in protecting privacy of patient information due \nto the rising number of security threats that lead to medical records, including patients personally \nidentifiable information (PII) and protected health information (PHI), ending up in the wrong hands.2 According to the U.S. Department of Health and Human Services Office for Civil Rights, Breach Portal, \nhealthcare data breaches have continued to increase in recent years.3 Multiple studies show that the \nlargest healthcare data breaches in 2017 were due to hacking. The rise in hacking incidents can be \nexplained in part by the increase in ransomware attacks on healthcare providers in 2017, and data \nbreach costs are the highest among surveyed sectors.4 The Ponemon Institutes study on the cost of data \nbreaches estimates that data breaches could be costing the healthcare industry $6.2 billion. No \nhealthcare organization, regardless of size, is immune from data breach.5 According to a 2017 Health \nInformation and Management Systems Society Cybersecurity Survey report, patient safety and data \nbreaches are the top two concerns among healthcare organizations.6 In the next sections, we highlight three of our applied cybersecurity projects in the healthcare space. \nAlthough each project focuses on a different subdomain of healthcare, the common goal is to help \nimprove the cybersecurity posture of healthcare organizations and the protection of PHI and PII. Securing Electronic Health Records on Mobile Devices\nIn collaboration with community members and technology vendors, the NCCoE has developed a \nreference solution for securing electronic health records (EHR) on mobile devices. The reference solution \nis detailed in the NCCoEs Cybersecurity Practice Guide SP 1800-1, Securing Electronic Health Records on \nMobile Devices.7 SP 1800-1 specifically shows how security engineers and IT professionals, using \ncommercially available, open-source tools and technologies that are consistent with cybersecurity http://www.information-age.com/safeguarding-data-challenge-healthcare-123466743/\nhttps://ocrportal.hhs.gov/ocr/breach/breach_report.jsf\nhttps://healthitsecurity.com/news/healthcare-hacking-leading-cause-for-2017-incidents\nhttps://www-01.ibm.com/marketing/iwm/dre/signup?source=urx-15763&S_PKG=ov58441&S_VCPI=Search_Google-_-Security_Optimize+the+Security+Program-_-WW_NA-_-ponemon+Institute_Exact_-\nhttps://www-01.ibm.com/marketing/iwm/dre/signup?source=urx-15763&S_PKG=ov58441&S_VCPI=Search_Google-_-Security_Optimize+the+Security+Program-_-WW_NA-_-ponemon+Institute_Exact_-\nhttps://www-01.ibm.com/marketing/iwm/dre/signup?source=urx-15763&S_PKG=ov58441&S_VCPI=Search_Google-_-Security_Optimize+the+Security+Program-_-WW_NA-_-ponemon+Institute_Exact_-\nhttp://www.himss.org/sites/himssorg/files/2017-HIMSS-Cybersecurity-Survey-Final-Report.pdf 4 Electronic Health Records on Mobile Devices, NIST SP 1800-1 (July 2015) \nhttps://www.nccoe.nist.gov/sites/default/files/library/sp1800/hit-ehr-nist-sp1800-1-draft.pdf standards, can help healthcare organizations share patients health records more securely on mobile \ndevices. The guide uses a layered security strategy to achieve these results. Business Challenge Healthcare providers increasingly use mobile devices to store, process, and transmit patient information. \nWhen health information is stolen, inappropriately made public, or altered, healthcare organizations can \nface penalties and lose consumer trust, and patient care and safety may be compromised. Unfortunately, many organizations have not implemented safeguards to ensure the security of patient \ndata when doctors, nurses, and other caregivers use mobile devices in conjunction with an EHR system. \nThe absence of effective safeguards, in the face of a need to leverage mobile device technologies to \nmore rapidly and effectively deliver healthcare, poses a significant business challenge to providers. Approaches and Solution The reference architecture for the secure exchange of electronic health records on mobile devices in a \nhealthcare organization is shown
below. This architecture formed the basis of the use case and was \nagreed upon through discussion with industry representatives, security vendors, and members of the \nNCCoEs healthcare COI. Additional details can be found in NIST SP 1800-1. After establishing the reference architecture, we re-created a representation of a healthcare \norganizations enterprise infrastructure so that we could approximate the conditions that EHR systems https://www.nccoe.nist.gov/sites/default/files/library/sp1800/hit-ehr-nist-sp1800-1-draft.pdf 5 8 Gavin OBrien, Sallie Edwards, Kevin Littlefield, Neil McNab, Sue Wang, and Kangmin Zheng, Securing Wireless \nInfusion Pumps in Healthcare Delivery Organizations, NIST SP 1800-8 (May 2017) \nhttps://www.nccoe.nist.gov/sites/default/files/library/sp1800/hit-infusion-pump-nist-sp1800-8-draft.pdf and mobile devices would operate within. A next step was to work with actual security products to \ncreate a working instance of the architecture that would allow us to understand how these components \nworked together. Among the products we used were: Archer GRC (RSA): provides centralized enterprise, risk, and compliance management\nOpenEMR (MedTech Enginuity): web-based and open-source EHR and supporting technologies\nMaaS360 (Fiberlink): cloud-based mobile device policy manager\nVPN server, WAP, Mobile NAC (Cisco): RADIUS-based authentication, VPN server, Wi-Fi Access \npoint\nOther IT components (Ramparts, Intel, Symantec) With the guides help, an organization can choose to adopt the same approach. Commercial and open-\nsource standards-based products are easily available and interoperable with commonly used information \ntechnology infrastructure and investments. The guide has a modular design, allowing organizations to \nadopt as much or as little of the reference design as suits their needs. Benefits The NCCoEs solution provides several benefits. First, it helps protect PHI and the systems used in \ntransacting PHI without disrupting the quality of care. Second, it provides a defense-in-depth approach \nto protecting PHI by securing all elements of the EHR ecosystem. Next, it supports implementation by \neither an organizations in-house IT security staff or external system integrators. Finally, it enables \norganizations to employ the solution by using their existing IT infrastructure without having to start from \nscratch. Securing Wireless Infusion Pumps\nFor organizations focused on delivering high-quality patient care, it can be difficult to take advantage of \nthe latest technological advances while also ensuring that new medical devices or applications are \nsecure. For many healthcare delivery organizations (HDOs), this can result in improperly configured \nnetworks and components that increase cybersecurity risks. The goal of securing medical devices was the \nfocus of the NCCoEs second project supporting the healthcare sector and resulted in SP 1800-8, Securing \nWireless Infusion Pumps in Healthcare Delivery Organizations, which was published on May 8, 2017.8 Business Challenge Unlike prior medical devices, which were once stand-alone instruments, todays wireless infusion pumps \nconnect to a variety of healthcare systems, networks, and other devices. Although connecting infusion \npumps to point-of care medication systems and electronic health records can improve healthcare \ndelivery processes, this can also increase cybersecurity risk, which could lead to operational or safety \nrisks. Tampering, intentional or otherwise, with the wireless infusion pump ecosystem can expose an \nHDO to serious risk factors, such as access by malicious actors; a breach of protected health information; \nloss or disruption of healthcare services; and damage to an organizations reputation, productivity, and \nbottom-line revenue. \nWith an increasing number of infusion pumps connecting to networks, the vulnerabilities and risk factors \nbecome more critical as they can expose the pump ecosystem to external attacks, compromises, or 6 9 Principles for medical device securityRisk Management, Advancement of Medical Instrumentation (AAMI) \nTechnical Information Report (TIR)57, AAMI TIR57: 2016 (June 5, 2016) interference. Approach and Solution This project had two fundamental objectives: (1) protect the wireless infusion pumps from cyberattacks, \nand (2) protect the healthcare ecosystem should a wireless infusion pump be compromised. It was \nextremely important to understand not only the behavior of the device but also how it operates with all \nthe devices that are part of a healthcare setting. Additionally, we felt it necessary to understand where \nsecurity risks may have safety implications. The AAMI TIR579 was particularly useful in this regard, as it \nspecified elements of medical device security by using NISTs Risk Management Framework and \nstandards such as IEC 80001-1, IEC/TR 80001-2, and ISO 14971. As part of our approach, we performed a risk assessment based on guidance from NIST SP 800-30 and \ndocumented several risks associated with insecure medical devices: Infusion pumps and server components may be leveraged for advanced persistent threats and serve 1.\nas pivot points to cause adverse conditions throughout a hospitals infrastructure.\nInfusion pumps may be manipulated to prevent effectively implementing safety measures, such as 2.\nthe drug library.\nInfusion pump interfaces may be used for unintended or unexpected purposes, leading to degraded 3.\nperformance of the pump.\nPHI may be accessed remotely by unauthorized individuals.4.\nPHI may be disclosed to unauthorized individuals should the device be lost, stolen, or improperly 5.\ndecommissioned.\nConnections to improper third-party vendors may be created, introducing a security concern.6. The reference architecture, as shown in the figure below, was developed by working with security \nvendors, healthcare organizations, infusion pump manufacturers, and subject matter experts in the \nhealthcare community. The goal of this architecture design is to provide countermeasures to mitigate \nchallenge areas identified in the risk assessment process. In our example solution, segmentation and \ndefense-in-depth are the security models we used as security measures to build and maintain secure \ndevice infrastructure. 7 As with other practice guides, we replicated a healthcare network within the NCCoE labs and invited \nboth infusion pump vendors and security product vendors to participate. The following products and \ncompanies were part of the build: Infusion pumps (Baxter Healthcare, B. Braun Medical, Becton, Dickinson and Company, \nHospira, Smiths Medical)\nAccess Points, Wireless LAN (Cisco): Wireless LAN infrastructure\nClearwater (Clearwater Compliance): Information Risk Management \nCertCentral (Digicert): Certificate Authority\nMyID (Intercede)\nMDRAP (MDISS)\nPFP Cybersecurity: Device Monitoring\nRamparts: Risk Assessment\nEndpoint Protection, Advanced Threat Protection (Symantec)\nConsoleWorks (TDi Technologies) As with other practice guides, the use of commercially available products helps build confidence that the \nreference solution will address the challenge. The guide can help design an entirely new infrastructure. \nHowever, it is geared toward those organizations with an established infrastructure, as that represents \nmost organizations. Hospitals and clinics are likely to have some combination of the capabilities \ndescribed in this reference solution. Benefits 8 10 Jennifer Cawthra, Kevin Littlefield, Robert Niemeyer, Sue Wang, and Kangmin Zheng, Securing Picture Archiving \nand Communication System (PACS) Project Description, NIST NCCoE (January 2018) \nhttps://www.nccoe.nist.gov/sites/default/files/library/project-descriptions/hit-pacs-project-description-final.pdf These are some of the potential business benefits of the example implementation developed in this \nproject: Reduction of cybersecurity risk, and potentially reduced effect on safety and operational risk, such as \nthe loss of patient information or interference with the standard operation of a medical device \nDevelopment and execution of a defense-in-depth strategy that protects the enterprise with layers \nof security to avoid a single point of failure and provides strong support for availability \nImplementation of current cybersecurity standards and best practices while maintaining the \nperformance and usability of wireless infusion pumps Securing Picture Archiving and Communication System\nIn January 2018, the NCCoE defined and published the Securing Picture Archiving and Communication \nSystem (PACS) Project Description.10 This project is addressing the challenge of securing the PACS \necosystem in HDOs by collaborating with industry and the information technology community, including \nvendors of cybersecurity solutions. This project will include developing a reference design and will use \ncommercially available technologies to develop an example solution that will help healthcare \norganizations implement more secure PACS solutions by using stronger security controls. Business Challenge A PACS is made of technology used to document, store, process, and manage medical images such as X-\nrays, computed tomography (CT) scans, and ultrasound and magnetic resonance imaging (MRI) images. \nThe systems are composed of the actual imaging machines themselves, the network used to share \nimages, the workstations and mobile devices used to process and view images, and the storage media \nused to archive images. As medical treatment relies more and more on advanced imagery to diagnose \nand treat problems, these systems have grown in complexity. Compromise of a PACS can result in significant data loss and could also serve as an avenue to disrupt a \nhospitals other IT systems. If information were altered or misdirected, a compromise could impede \ntimely diagnosis and treatment. As healthcare organizations become more attractive targets for \nmalicious actors, the need to improve protection of PACS is paramount. Scope and High-Level Architecture The scope of the project includes the PACS ecosystem to allow for the storage, retrieval, management, \ndistribution, and presentation of medical images. The figure below shows the high-level architecture \ndiagram of a representative PACS ecosystem. Distinct components will be isolated on the network so \nthat they do not reside on the same internet protocol (IP) network. For example, Digital Imaging and \nCommunications in Medicine viewers and PACS workstations may operate in networks that support \nclinical services; modalities may be deployed to separate medical device zones that prevent inherent \ntrust per medical device zone; and PACS web and application servers may be deployed to segregated \nclinical demilitarized zones (DMZs), separate from the core components of the PACS and segregated \nfrom production DMZ demarcations. As appropriate and as may be implemented, components within \nthe PACS may be tiered as well. https://www.nccoe.nist.gov/sites/default/files/library/project-descriptions/hit-pacs-project-description-final.pdf 9 Summary and Conclusions The development of practical, real-world cybersecurity references by
the NCCoE can help accelerate the \nadoption of solutions across industryincluding the healthcare sector. The three projects described \naboveSecuring Electronic Health Records on Mobile Devices, Securing Wireless Infusion Pumps, and \nSecuring Picture Archiving and Communication Systemprovide evidence on how to incorporate \nexisting commercial tools and standards into reference implementations that can help industry. The \nNCCoE invites members of the healthcare sector to participate in our process, and members of other \nindustry sectors to participate in our other practice guide work. _GoBack\n _top\n _Hlk510279710 ",
    "text": " _top\n _GoBack ",
    "text": " Asia Pacific Nations Collaborate to Improve Aviation Safety In the Asia Pacific, MITRE is working with four nations and 12 aviation industry \norganizations on a project that uses shared aviation information to identify \npotential safety issues and address them before serious incidents can occur. In the fall of 2017, with MITRE's support, several Asia Pacific governments and airlines launched a \ncollaborative project that uses data sharing to improve aviation safety in the region. The inspiration for the project is a U.S. data sharing initiativethe Aviation Safety Information Analysis \nand Sharing (ASIAS) program. ASIAS (pronounced \"A-sigh-us\") is credited with dramatically improving the \nsafety of commercial aviation in the United States over the last decade. \"We're taking that successful U.S. capability and adapting it to the Asia Pacific context,\" says Greg \nNelson, who heads MITRE Asia Pacific Singapore. We established this state-of-the-art research and \ndevelopment center in 2015 with the support of the Civil Aviation Authority of Singapore (CAAS). CAAS also spearheaded the effort to create an aviation safety data sharing program in the Asia Pacific. In \n2013, CAAS commissioned MITRE to evaluate the feasibility of implementing such a program at the \nregional level. That study examined a variety of factors, such as the availability of safety data and the \nunique regulatory, budgetary, and technological environments of the different nations in the region. \"In the United States, we have a single regulator and air navigation service provider [ANSP]the Federal \nAviation Administration,\" explains project leader Wallace Feerrar. \"But in the Asia Pacific, there is no \ncentral regulatory authority. Each state governs and regulates its own airspace, ANSP, and the airlines \ncertificated in that state, so the environment is quite different from the one ASIAS operates in. \"That meant we had to take into consideration the unique environments, needs, cultures, and concerns \nof all the interested parties.\" After nine months of study, the research team's findings were in favor of a data sharing initiative. \nGovernment and industry stakeholders in the region also agreed that a regional data collection, analysis, \nand information sharing effort would enhance the Asia Pacific's ability to identify safety hazards and \ndevelop targeted safety improvements. MITRE Develops a Framework Suited to the Asia Pacific Context That finding was the green light for further work. Over the next few years, MITRE worked in partnership \nwith the Flight Safety Foundation (FSF)an aviation safety advocacy organization with members in more \nthan 150 countriesto develop the framework for an Asia Pacific safety data sharing demonstration \nproject. Because of its expertise in the governance and administration of intergovernmental programs, FSF \ndeveloped the framework that would govern data sharing among the program participants. Due to MITRE's technical capabilities, previous experience with data sharing initiatives, and not-for-profit \nobjectivity, we were selected to serve as the trusted third party that would analyze the regional https://www.mitre.org/publications/project-stories/government-and-industry-collaborate-to-improve-safety-through-data-sharing\nhttp://www.mitre-ap.sg/\nhttps://www.mitre.org/news/in-the-news/caas-and-mitre-collaborate-to-establish-air-traffic-management-research-and\nhttps://www.mitre.org/news/in-the-news/flight-safety-foundation-and-mitre-collaborate-to-transform-global-aviation information that was collected. We would also disseminate findings and facilitate discussions about \npotential mitigations. To create the demonstration project, MITRE and FSF worked with Asia Pacific government and industry \nrepresentatives. The group outlined the program's foundation and principles, set clear participant roles \nand responsibilities, and addressed issues such as how members' information would be protected and \nshared, and how program decisions would be made. Governments and Industry Join the Effort In 2017, four nationsSingapore, the Philippines, Indonesia, and Japancommitted to participating in \nand financing the project. At least six other nations have expressed interest in participating as well. \nAirlines, aircraft manufacturers, and regional trade organizations have also agreed to supply information \nand subject matter expertise. Created as a demonstration project, the initiative will last three years. During that time, the project will \npool results and information from participants and analyze safety issues of concern across the region. It \nwill also provide participants an opportunity to assess and refine the program's structure and benefits. Initial Study Focuses on Mid-Air Collision Risk The demonstration project's initial focus is on mid-air collision risk. \"Although mid-air collisions are rare, near-misses sometimes occur,\" Feerrar says. \"By tracking those \nincidents and analyzing the data associated with them, we can better understand why they are occurring \nand recommend mitigations.\" To conduct that analysis, MITRE is using a combination of state-provided reports, data airlines have \nsupplied to their regional trade organizationthe International Air Transport Association (IATA)and a \nglobal dataset we have compiled over the last several years. \"Several years ago, we established licensing agreements with global vendors of Automatic Dependent \nSurveillance-Broadcast [ADS-B] datasets,\" Feerrar says. ADS-B is equipment that allows aircraft to \nbroadcast their positions to similarly equipped aircraft and ground stations. \"It's pseudo-radar, \nessentially,\" he explains. \"We now have a three-year archive of that data, and it's helping inform our \nresearch in the Asia Pacific.\" Already, MITRE researchers have identified several mid-air collision risk hot spots that warrant additional \nstudy. \"These incidents are occurring more commonly at the seamsat the borders between countries in the \nregion,\" Feerrar says. \"Our analysis is ongoing, but we've already begun to identify the traffic flows and \nthe factors in normal operations that are causing these incidents. \"By fall 2018, we believe we'll have a more complete understanding of the situation and can make \nrecommendations for some potential fixes.\" Marlis McCollum Approved for Public Release; Distribution Unlimited. Case Number 18-1438. _top\n _Hlk505787933\n _GoBack ",
    "text": " Supply Chain Attacks and Resiliency \nMitigations Guidance for System Security Engineers Authors: William J. Heinbockel\nEllen R. Laderman\nGloria J. Serrao October 2017 Sponsor: NSA/CSS I4\nDept. No.: P522\nContract No.: W56KGU-16-C-0010 \nProject No.: 0717N871-SC The views, opinions and/or findings \ncontained in this report are those of The \nMITRE Corporation and should not be \nconstrued as an official government \nposition, policy, or decision, unless \ndesignated by other documentation. Approved for Public Release; \nDistribution Unlimited. Case \nNumber: 18-0854. \nAll rights reserved. Bedford, MA MTR170477 MITRE TECHNICAL REPORT Approved By Rosale McQuaid/ Rosalie McQuaid, T8A2, Cyber Resiliency 19 October 2017\nDepartment Head Abstract \nCyber Resiliency Engineering can be applied to systems, missions, business functions, \norganizations or a cross-organizational mission. In this paper, cyber resiliency is applied to the \nproblem of mitigating supply chain attacks. The adversarys goals for attacking a supply chain \nare described using the cyber-attack lifecycle framework and the Department of Defense (DoD) \nAcquisition lifecycle. Resiliency techniques are recommended considering adversary goals and \nbest options to defend against the attacks. The analysis in this document found that the most \neffective point to apply cyber resiliency mitigations is the Production and Deployment phase \nbecause this reduces the number of attacks overall. The best place to gain information about \nadversary targets and activities are both the Engineering and Manufacturing Development phase \nand the Production and Deployment phase. An example of how to apply these resiliency \ntechniques is provided based on the Commercial Solutions for Classified capability package for a \nWireless Local Area Network (WLAN). iv Acknowledgments\nThe authors would like to acknowledge the expert input from Bob Martin and Peter Kertzner. \nThe authors would also like to acknowledge the valuable review given by Jenine Patterson, Paul \nBicknell, Deb Bodeau, Richard Graubart. i Table of Contents \n1 Introduction \n2 Background \n2.2 Supply Chain Attack \n2.3 DoD Acquisition Lifecycle \n2.4 Cyber Attack Lifecycle \n3.1 Primary Goals \n3.2 Achieving Goals by Actions Taken throughout the Acquisition Life Cycle \n3.3 Example Adversary Actions \n3.4 Adversary Advantages Gained Via Supply Chain Attacks \n5 Cyber Resiliency Mitigations for Supply Chain Attacks \n5.2 Defender Goals \n5.3 Cyber Resiliency Mitigations Considering Adversary and Defender Goals \n5.3.2 Technology Maturity and Risk Reduction Phase \n5.3.3 Engineering and Manufacturing Development Phase \n5.3.4 Production and Deployment Phase \n5.3.5 Operations and Support Phase \n5.4.1 Operations and Support \n5.4.2 Production and Deployment \n5.4.3 Engineering and Manufacturing \n5.4.4 Technology Development & Materiel Solutions Analysis \nAppendix A References \nAppendix B Analysis of Known Supply Chain Attacks \nAppendix C Analysis of Applicable Existing Supply Chain Risk Management Guidance \nAppendix D Summary of Cyber Resiliency Techniques and Approaches \nAppendix E Cyber Resiliency Mitigations Applied to the Acquisition Lifecycle \nAppendix F Abbreviations and Acronyms \nFigure 1. DoD Acquisition Lifecycle \nFigure 2. Cyber Attack Lifecycle \nFigure 3. Cyber Attack Lifecycle in the Context of the Acquisition Lifecycle \nFigure 4. Multi-level Domain Campus WLAN Solution \nFigure 5. Example Campus WLAN Continuous Monitoring Points \nFigure 6. Supply Chain attack steps within the Acquisiton Lifecycle \nTable 1. Cyber Attack Lifecycle and the Associated Adversary Goals \nTable 2. Adversary Goals, the Acquisition Lifecycle and the Cyber Attack Lifecycle \nTable 3. Supply Chain Threats and the Associated Mission Risks (Operations and Support) \nTable 4. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission \nSystem (Operations and Support) \nTable 5. Improving Recovery and Evolution of the Capability Against Future Supply Chain \nThreats (Operations and Support) \nTable 6. Supply Chain Threats and the Associated Mission Risks (Production and Deployment)5-\n34\nTable 7. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission \nSystem (Production and Deployment) \nTable 8. Improving Recovery and Evolution of the Capability Against Future Supply Chain \nThreats (Production and Deployment) \nTable 9. Supply Chain Threats and the Associated Mission Risks (Engineering and \nManufacturing) \nTable 10. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission \nSystem (Engineering and Manufacturing) \nTable 11. Improving Recovery and Evolution of the Capability Against Future Supply Chain \nThreats (Engineering and Manufacturing) \nTable 12. Supply Chain Threats and the Associated Mission Risks (Technology Development \nand Materiel Solutions Analysis) \nTable 13. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission \nSystem (Technology Development and Materiel Solutions Analysis) \nTable 14. Improving Recovery and Evolution of the Capability Against Future Supply Chain \nThreats (Technology Development and Materiel Solutions Analysis \nTable 15. Cyber Resiliency Activities Compared to Risk Management Framework Activities.C-1\nTable 16. Key Practices Guidance and Its Relation to Cyber Resiliency \nTable 17. Cyber Resiliency Techniques \nTable 18. Definitions of Cyber Resiliency Approaches \nTable 19. Cyber Resiliency Mitigations for Materiel Solutions Analysis Phase \nTable 20. Cyber Resiliency Mitigations for Technology Maturity and Risk Reduction Phase.. E-4\nTable 21. Cyber Resiliency Mitigations for Engineering and Manufacturing Development Phase\n \nTable 22 . Cyber Resiliency Mitigations for Production and Deployment Phase \nTable 23. Cyber Resiliency Mitigations for Operations and Support Phase \nreport to avoid confusion with the variety of systems used to support an acquisition program. The mission can be to provide \ninfrastructure or supporting services, as illustrated by the example.\n2 The DoD-published catalog of 41 supply chain attacks [3] includes, for each attack, identification of the attack points (Program \nOffice, Prime Contractor, Subcontractor, Integrator Facility, Software Developer, Hardware Developer, Physical Flow, \nInformation Flow). The importance of defending such systems is also highlighted in Directive-type Memorandum (DTM) 17-001 \n Cybersecurity in the Defense Acquisition System [8].\n3 Cyber resiliency engineering is an emerging specialty systems engineering discipline. It is closely aligned with security \nengineering, safety engineering, and system survivability engineering. It differs from other specialty disciplines in its assumption \nof advanced cyber threats Tiers V and VI in the hierarchy defined by the Defense Science Board (DSB) Report on Resilient \nMilitary Systems and the Advanced Cyber Threat [30]; its focus on mission assurance rather than on ensuring the conventional \nsecurity objectives of confidentiality, integrity, and availability; and its use of analytic methods which accommodate the high \ndegree of uncertainty associated with advanced cyber threats. Introduction1\nThis report provides analysis and guidance to help Systems Security Engineers (SSEs) supporting \nDepartment of Defense (DoD) acquisition programs apply cyber resiliency techniques to supply \nchain attacks throughout the acquisition lifecycle. The focus is on supply chain attacks against a \nmission system1 consisting of information and communications technology (ICT); however, the \nanalysis approach is designed to be extensible to a broader range of mission systems (in \nparticular, those integrating ICT and embedded systems). Cyber resiliency enables an \noperational mission and the systems which support it to better anticipate, withstand, recover, and \nevolve despite adversary attacks and other adverse effects.\nThis analysis can be used by SSEs to apply cyber resiliency techniques and analysis methods \nthroughout the acquisition lifecycle. This will enable programs to develop and execute Program \nProtection Plans (PPPs) that address cyber supply chain risks effectively, despite such \nprogrammatic constraints as reliance on legacy components, components of uncertain \nprovenance, or shared services. SSEs will be able to evaluate how well a given program is \napplying cyber resiliency throughout the acquisition lifecycle to reduce supply chain risks due to \ncyber attacks.\nTo apply these recommendations, Programs need to include requirements motivated by cyber \nresiliency into contractual documents, specifically Statements of Work (SOWs) and Functional \nRequirements Documents (FRDs). Cyber resiliency related requirements in SOWs will lead \ncontractors (the Prime or Integration Contractor, the Maintenance Contractor if different, and \nsubcontractors as appropriate) to apply selected cyber resiliency techniques in the design, \nproduction, test, and maintenance environments, to make the supply chain more cyber resilient.2 \nCyber resiliency related requirments in FRDs make acquired mission systems more resilient \nagainst cyber attacks that exploit weaknesses in the supply chain. \nUsing the Cyber Resiliency Engineering Framework (CREF) [1] [2], this paper recommends \ncyber resiliency techniques to address supply chain attacks. Cyber resiliency engineering3 \nassumes a sophisticated adversary and an adversary who attacks the supply chain is indeed \nsophisticated and usually a nation state actor. \nIn conducting this analysis, the MITRE team leveraged prior work that cataloged forty-one \nsupply chain attacks and associated each one with a phase in the acquisition life cycle [3]. It is \nimportant to note that the target for these 41 supply chain attacks are predominetly ICT \ncomponents. An attack within the DASD-SE paper is the successful insertion, modification or \nsubstitution to/of a component within the supply chain (regardless of whether or not it makes it vi into an operational system.) For this paper, these attacks are referred to as attack steps that \nare taken to complete a full cyber-attack on the end mission or system, using the Cyber Attack \nlife-cycle. \nGrouping these attack steps by their effects on the to-be-acquired mission system (modification, \nsubstitution or insertion), we analyzed the number of attack steps that occurred in each phase of \nthe acquisition life cycle. We thus determined the proportion of attack types that occur within \nacquisition life cycle phases as well as in CAL stages. For example, substitution attack steps are \nhighest in number and happen most often in production and deployment and occur predominately \nin the pre-exploit phase of deliver. The complete results of this analysis are in Appendix B, and \nit formed
our initial understanding of the adversarys objectives.\nTo demonstrate cyber resiliency mitigations against an active cyber adversary, we leveraged \nexisting supply chain risk management (SCRM) guidance but added the perspective of adversary \ngoals and defender goals to describe success (i.e., the adversarys goals are not achieved and the \ndefenders goals are met.) This continuum of actions, reactions, constraint, and adaption to and \nrecovery from adverse attacks (in this case supply chain attacks) is characteristic of cyber \nresiliency. Through our analysis, we recognized that while the adversarys ultimate goal is to \nimpact the operational mission system, the adversary will exercise the complete CAL in earlier \nacquisition lifecycle phases in order to achieve intermediate goals. These intermediate goals \ninclude gathering information about mission system development and developing and inserting \nexploit tools to place hooks in contractor environments for later use.\nIn Section 2, we introduce key definitions and the frameworks used in our analysis. Section 3 \ndescribes the adversarys goals in attacking a supply chain to exploit a targeted operational \nenvironment and describes and provides examples for attacking the systems and components in \neach stage of the acquisition life cycle. \nSection 4 walks through an example using the Commercial Solutions for Classified capability \npackage for a Wireless LAN. It describes the adversarys goals and possible actions they might \ntake to achieve those goals in this example targeted system. \nSection 5 provides our analysis of adversary goals and what a defender hopes to achieve against \nan adversarys actions. This analysis leads us to conclude that the most effective point at which to \napply cyber resiliency mitigations is the Production and Deployment phase because this reduces \nthe number of attacks overall. The best place to gain information about adversary targets and \nactivities are both the Engineering and Manufacturing Development phase and the Production \nand Deployment phase. This is where the adversary activity is focused. This section contains \nrecommendations for cyber resiliency mitigations that can be applied to systems throughout the \nacquisition life cycle and where we believe those mitigations are most effective. \nIn addition to the recommended mitigations in Section 5, all potentially applicable cyber \nresiliency techniques are listed in Appendix E, associated with each acquisition life cycle phase, \nadversary goals and defender goals. These tables serve as a starting point as an SSE analyzes a \nsystem for supply chain attacks and the application of cyber resiliency mitigations. SSEs should \nfurther tailor this guidance to the specific system or components being assessed and provide \nsecurity guidance to developers, security architects, security assessments and network defenders. \nTo assist with this tailoring, refer to the example of supply chain attacks on an operational \nnetwork component (using the Wireless LAN Commercial Solutions for Classified (CSfC) \ncapability package) provided in Section 5.4. This example describes each stage of the acquisition \nlife cycle and applies the most effective resiliency techniques to thwart an attack on the \ncomponents of this solution. vii Finally, Section 6 contains a summary and next steps. viii ix Background2\nThis section introduces key definitions and frameworks used throughout the paper to characterize \nsupply chain attacks, when they occur, what the adversary wants to accomplish and the best way \nto defend against them. It also describes the DoDI 5000.02 [4] acquisition lifecycle and the cyber \nattack lifecycle (CAL). For supply chain, the CAL is used as a structure of a cyber campaign \nagainst a mission system where the cyber campaign spans the acquisition life cycle. A large \nbody of work exists on Supply Chain Risk Management (SCRM) and was consulted for this \nanalysis. A subset of this body of work was analyzed and is listed together with their \napplicability in Appendix C. Supply Chain2.1\nThe Information and Communications Technology (ICT) supply chain is defined in NIST 800-\n161 [5] as a linked set of resources and processes between acquirers, integrators, and suppliers \nthat begins with the design of ICT products and services and extends through development, \nsourcing, manufacturing, handling, and delivery of ICT products and services to the acquirer. \nThis supply chain can include vendors, manufacturing facilities, logistics providers, distribution \ncenters, distributors, wholesalers, and other organizations involved in the manufacturing, \nprocessing, design and development, handling and delivery of the products, or service providers \ninvolved in the operation, management, and delivery of the services.\nThe Defense Science Board (DSB) identifies three interconnected supply chains for DoD \nweapons systems acquisitions [6]: (1) the global commercial supply chain, which is the source of \nmost microelectronics; (2) the DoD acquisition supply chain, which is designed by the prime \ncontractor; and (3) the DoD sustainment supply chain, which includes aftermarket suppliers. \nThese supply chains are also relevant to ICT systems. For example, the global commercial \nsupply chain also includes sources of commercial off-the-shelf (COTS) software and components \n(e.g., operating systems, servers, routers). The DoD acquisition supply chain includes systems \nused by the Program Office to define and track compliance with requirements, systems operated \nby the Prime or Integration contractor to manage information related to the mission system, \nsystems operated by the Prime or Integration contractor to develop the mission system, and \nmaintenance systems. Supply Chain Attack 2.2\nA Supply Chain Attack is defined for this paper as an intentional malicious action (e.g., \ninsertion, substitution or modification) taken to create and ultimately exploit a vulnerability in \nInformation and Communication Technology (hardware, software, firmware) at any point within \nthe supply chain with the primary goal of disrupting or surveilling a mission using cyber \nresources. This definition is based on the definition found in [3].\nAs part of an attack, an adversary wants to achieve success in: inserting malware, tainted hardware, or false information into the supply chain,1.\nsubstituting a bad or corrupt component for a good one, or2.\nmodifying an existing component to affect its performance adversely (e.g., degrade, deny, 3.\nmake unreliable, or cause to malfunction harmfully). The Defense Science Board Task Force on Cyber Supply Chain [6] identifies several reasons for the x 4 A tainted product as defined in Open Trusted Technology Provider Standard (O-TTPS) Version 1.1, Mitigating Maliciously \nTainted and Counterfeit Products is a product that is produced by the provider and is acquired through a providers authorized \nchannel but has been tampered with maliciously. [28] rising importance of supply chain attacks ranging from the increasing complexity of the \nprogrammable electronic components to the extended lifetime of system configurations. This \nreport cites the heavy reliance on integrated circuits produced outside the United States and the \nfact that most PPPs do not carry over to the sustainment phase.\nIn the DoDI 5200.44 [8] definition of supply chain risk, it states the adversary may sabotage, \nmaliciously introduce unwanted function, or otherwise subvert the design, integrity, \nmanufacturing, production, distribution, installation, operation, or maintenance of a system to \nsurveil, deny, disrupt, or otherwise degrade the function, use, or operation of such system.\nThis can happen at any phase of the acquisition lifecycle pictured in Figure 1 below. The method \nof an attacker in this context is to gain access to the supply chain, execute a malicious insertion, \nsubstitution, or modification of ICT, and achieve persistence until the altered component is a part \nof an operational mission and/or system. \nThis paper focuses on supply chain attacks that are operationally successful. Often a supply \nchain attack is thought of as successful if the insertion, substitution or modification is completed. \nHowever, for true success in the operational environment, an adversary uses the supply chain \nentry point to control, execute and maintain the software, hardware or firmware containing that \nmalicious modification in order to impact the mission operations. DoD Acquisition Lifecycle2.3\nThe DoD Acquisition Lifecycle ( [4], Figure 1) represents a series of phases, separated by \nmilestones and decision points, that an acquisition program moves through from conception to \nultimate operational use and disposal. Adversaries can initiate and conduct malicious activities \nduring any and all of these phases. Some of those activities can take the form of supply chain \nattacks. Ensuring the integrity and security of the supply chain is paramount to the development \nand operation of a secure and resilient platform. If an adversary can attack the supply chain and \ntaint4 components, insert malicious compenents into the mission system, or otherwise undermine \nthe ability of the as-delived mission system to meet its requirements, the adversary can \ncompromise the operational system before or during its use. Figure 1. DoD Acquisition Lifecycle Cyber Attack Lifecycle2.4\nThe cyber-attack lifecycle (CAL), first articulated by Lockheed Martin [9] as the cyber kill \nchain, depicts the stages of a cyber campaign against a mission system. These stages are what an \nadversary does to achieve the objectives of establishing, using and maintaining (or removing) a xi 5 Actions in each stage have defined objectives. Each action has one or more Indicators. Objectives and representative examples \nof actions are included in the published lexicon. However, these published examples are focused on a mission system in the O&S \nstage and do not include supply chain attacks. presence in an enterprise information infrastructure [10]. The stages are shown in Figure 2 \nbelow and are: Reconnaissance the adversary gathers information and identifies a target; Weaponize the attack is put in a form
to be executed on the victim's system/network (a \ncyber weapon typically a piece of malware, but in the context of supply chain attacks \ncould also be a tainted software component such as a Dynamic-Link Library (DLL) file or \na subverted operating system (OS), a tainted data file, a hardware component which \nincludes malicious logic); Deliver the cyber weapon is delivered to the target system; Exploit the cyber weapon takes advantage of a vulnerability in the target system to \ninstall malware; Control the initial installed malware establishes a command and control (C2) channel \nto the adversary if necessary, and malware propagates from the initial target system more \nbroadly; Execute the adversary achieves the desired cyber effect (which can in turn result in a \nmission impact); and Maintain long-term access is preserved. Figure 2. Cyber Attack Lifecycle Figure 2 shows a single, linear version of the CAL with one end goal and one successful exploit. \nHowever, these attack stages are completed multiple times across the acquisition lifecycle, \ntargeted at different systems. Within each phase of the acquisition lifecycle, there are systems and \ninformation that can be leveraged by the adversary to attack systems and information in \nfollowing phases of that lifecycle. For example, the adversary may attack a Program Office \nsystem, resource or information in the Materiel Solutions Analysis and Technology Maturity and \nRisk Reduction phase to perform reconnaissance and/or start to weaponize (create an exploit for \nlater use.) Then, using that information or weapon created, the adversary could execute \nanother attack on the integration contractors systems in a later phase of the acquisition lifecycle \nsuch as the Production and Deployment phase. In this case the adversary has cycled through at \nleast two complete CALs as part of the larger CAL directed at the operational mission.\nOther forms of a CAL have been defined. In particular, the Office of the Director of National \nIntelligence (ODNI) has published its Cyber Threat Framework (CTF) [11]. The CTF defines \nfour broad stages of adversary actions: Preparation, Engagement, Presence, and Effect / \nConsequence5; these were used in the DSB Report on Cyber Supply Chain. However, the CTF xii does not provide enough granularity with respect to the immediate consequences of adversary \nactions to enable us to analyze which cyber resiliency techniques could be effective against those \nactions. In addition, the structure of a cyber campaign illustrated above is consistent with NIST \nSP 800-30R1 [12] and the DoD Guidelines for Cybersecurity Developmental Test and Evaluation \n(DT&E) [12]. We therefore use the seven-stage CAL illustrated above in Section 3, which \nprovides a good representation of a cyber campaign used across the acquisition lifecycle. xiii 6 The words in parenthesis come from [10]. Adversary Goals in the Context of the Cyber Attack and 3\nAcquisition Life Cycle This section details the adversary goals and how an adversary might leverage the CAL at \ndifferent phases of the acquisition life cycle to impact the operational system and overall mission. \nIt also identifies that the goal of achieving persistence of the weapon on the operational \nenvironment without detection is a strong motivator for the adversary to use the supply chain as \nentry onto an operational network. The CAL is recursive and therefore each stage of the \nacquisition life cycle can be targeted by an adversary and the entire CAL can be executed within \nany or all of acquisition lifecycle phases. This document is focused on showing the bigger \npicture of how the CAL is used over the entire acquisition lifecycle, the impact on the Operations \nand Support phase of the acquisition lifecycle, and the cyber resiliency mitigations that can be \napplied to reduce or eliminate these impacts. This focus does not imply that addressing the full \nCAL within each acquisition lifecycle phase is unnecessary or not as useful; it is just not the \nfocus of this paper. Primary Goals3.1\nAn adversary using supply chain attacks against a mission system can have any of a variety of \ngoals, related to the mission, to the information handled by the system, or to the role of the \nsystem or mission in a larger context [14]. In the abstract, the primary goal of the adversary is to \nimpact confidentiality, integrity, and/or availability (CIA) of an end system and, ultimately, the \nmission it supports. To accomplish this, the adversary carries out the stages of the CAL (e.g., \nexploit, control, execute, and maintain), as referenced in Section 2.4, above. This means our \nanalysis approach may be applied to a wide range of missions. Possible cyber effects6 on the \nmission system include: Violate Confidentiality (intercept): gain unauthorized access to information; Reduce Integrity (modify, fabricate): cause the system to malfunction; cause end users to \nmistrust the information and information system; or cause end users to do unintended \nthings (e.g., friendly fire); Reduce Availability (degrade, interrupt): making the system and information or resource \nunavailable when it is needed; or, Use resources for illegitimate purposes (unauthorized use or usurpation): use for \npotentially harmful reasons and violate the confidentiality, integrity, or availability of \nother resources that trust the information asset being attacked by the adversary (as they \ndont know it is compromised). In line with the focus of this analysis on Operations and Support, this section describes what an \nadversary wants to achieve in each stage of the acquisition life cycle in order to exploit the final \nmission system. \nIt is recognized that adversaries will also attack systems within each life cycle stage. Systems \nand environments, for example those that produce system design requirements or support \nacquisition and development of a final mission system, are subject to attack. Many of the cyber \nresiliency techniques recommended here can also be applied to systems whose mission is to xiv develop, purchase or maintain another operational mission system. Achieving Goals by Actions Taken throughout the Acquisition Life 3.2\nCycle As identified by our analysis of supply chain attacks, attacks are most effective when started in \nearlier stages of the acquisition life cycle [3] and continue through all stages to Operations and \nSupport. For example: During the Materiel Solution Analysis Phase and the Technology Maturity and Risk \nReduction Phase, the adversary is focusing on Reconnaissance that is, finding out as \nmuch as possible about the mission needs, functional requirements, and expected \ntechnical architecture of the mission system for later use. The adversary is mainly \ntargeting the Program Office during this phase. In the Engineering & Manufacturing Development phase and the Production & \nDeployment phase, the adversary is doing more reconnaissance, developing weaponized \ntools, delivering them to the environment and executing the initial exploit (getting their \nhooks into applications and systems). The adversary is mainly targeting contractor \nsystems (both prime and subcontractor) during this phase If the adversary attack is successful, during the Production & Deployment phase and the \nOperations & Support phase the adversary achieves their goal of controlling weaponized \ntools, executing the attack and maintaining their presence for further attacks. During this \nphase the adversary is targeting contractor systems, integrator facilities, software and \nhardware development, as well as the physical flows and information flows. Figure 3 below is a representation of the ways an adversary moving through the stages of the \nCAL might interact with the acquisition lifecycle. An individual adversary attack may not \nnecessarily target each acquisition phase using every stage in the CAL shown in ; however, since \neach acquisition phase could be targeted as part of an extended campaign against the final \nmission system, resilience against those attacks and adverse effects should be considered within \nthat acquisition phase. This mapping reflects stages in the acquisition lifecycle where the \nadversary will focus their efforts to achieve their desired CAL objectives, rather than a \ndescription of a specific attack flow. The adversary may choose to go beyond these focus areas. \nA different perspective of the acquisitions-CAL relationship is shown in Table 2 below. xv Figure 3. Cyber Attack Lifecycle in the Context of the Acquisition Lifecycle For the remainder of this paper, the adversary goals with respect to the mission system will be \nreferenced as shown in the Table 1. below. This allows for a clearer understanding and \napplication of the CAL to the action an adversary wants to achieve in that stage of a supply chain \nattack. Table 1. Cyber Attack Lifecycle and the Associated Adversary Goals Recon Weaponize Deliver Exploit Control Execute Maintain Acquire \ninformation Develop \ntools for \nattack (craft \na cyber \nweapon) Deliver \nthe \ncyber \nweapon Take advantage \nof a \nvulnerability to \ninstall the cyber \nweapon, making \nit part of the \nmission system Control the \nattack in the \nmission \nsystem \nenvironment Achieve the \nintended \neffects on \nthe mission \nsystem Maintain \npresence \nfor future \nattacks The Table 2 below shows the actions the adversary wants to accomplish (goals) for each phase of \nthe acquisition life cycle and each stage of the CAL with example target systems listed. To \naccomplish these goals, the adversary would execute the full CAL against the target system(s). Table 2. Adversary Goals, the Acquisition Lifecycle and the Cyber Attack Lifecycle Acquisition \nLifecycle Phase Associated \nCyber Attack \nLifecycle Stage Target System Examples Adversary Goals
with Respect \nto Mission System Materiel \nSolutions \nAnalysis Reconnaissance Program Office systems handling \ninformation about needs, \nconcept of operations, interfaces Acquire information about the \nto-be-acquired mission \nsystem Technology \nMaturity and Reconnaissance Program Office systems handling \ninformation about technical Acquire information from \ndesign review xvi Risk Reduction \nPhase alternatives, risks Engineering & \nManufacturing \nDevelopment Reconnaissance Program Office, contractors and \nsubcontractor systems handling \ninformation about design \ndecisions and implementation \nprocesses Acquire information about \ntechnical architecture of \nmission system Weaponize There are no target system \nexamples because this activity \ntakes place on an adversary \nsystem using information gained \nin previous stages Develop cyber weapon, based \non expected technical \narchitecture of the mission \nsystem Deliver Contractor and sub-contracter \nsystems used to manage and \nexecute design and \nimplementation processes Deliver the cyber weapon \nget the cyber weapon / \nmalicious component into the \ncontractors development \nenvironment, so that it will be \nintegrated into the mission \nsystem Exploit Contractor and subcontractor \nsystems used to manage and \nexecute design and \nimplementation processes Take advantage of a \nvulnerability to install the \ncyber weapon, i.e., to make it \npart of the mission system Control / \nMaintain Contractor and subcontractor \nsystems used to manage and \nexecute design and \nimplementation processes; \nProgram Office systems handling \ninformation from design reviews Prevent the detection of the \ninsertion of the cyber weapon \ninto the mission system \nundermine contractor quality \nassurance processes and tools \nto prevent the insertion of the \nmalicious component from \nbeing detected. Production & \nDeployment Weaponize There are no target system \nexamples because this activity \ntakes place on an adversary \nsystem using information gained \nin previous stages Develop cyber weapons based \non technical architecture and \nidentified characteristics of \nthe mission system (e.g., \nspecific products or \ncomponents) Deliver Contractor and subcontrator \nsystems used to manage and \nexecute design and \nimplementation processes; COTS \nsupply chain for previously \nidentified components Deliver cyber weapons get \nthe cyber weapon / malicious \ncomponent into the \ncontractors development \nenvironment, so that it will be \nintegrated into the mission \nsystem Exploit Contractor and subcontractor \nsystems used to manage and \nexecute design and \nimplementation processes; COTS \nsupply chain for previously Take advantage of a \nvulnerability to install the \ncyber weapon, i.e., to make it \npart of the mission system xvii identified components\nControl / \nMaintain Contractor and subcontractor \nsystems used to manage and \nexecute design and \nimplementation processes Prevent the detection of the \ninsertion of the cyber weapon \ninto the mission system \nundermine contractor quality \nassurance processes and tools \nto prevent the insertion of the \nmalicious component from \nbeing detected Execute Execute malware so it \nsuccessfully corrupts or \notherwise undermines critical \ncontractor developed systems Execute malware the \ndefenders environment in the \ndeployed system before being \nmigrated to Operations and \nSupport Maintain Systems used in test and \nevaluation, at prime contractor, \nindependent validation and \nverification (IV&V) organization, \nor cyber range Prevent the detection of the \ninsertion of the cyber weapon \ninto the mission system \nundermine quality assurance \nprocesses and tools to \nprevent the insertion of the \nmalicious component from \nbeing detected; modify test \nresults Operations & \nSupport Control Mission system Control the Attack in the \nMission System Environment Execute Mission system Achieve the intended effects \non the mission system Maintain Mission system; systems used for \nmaintenance and support Maintain Presence for Future \nAttacks Example Adversary Actions3.3\nThis subsection discusses example actions of attacks at each acquisition phase in the abstract. \nSection 4 provides a notional example that is more specific. These attacks, typically employ \ncommon cyber attacks along with coordination across multiple attacks, are part of the larger, \nrecursive, cyber attack lifecycle described in Section 3.2. \nIn the Materiel Solutions Analysis and Technology Maturity and Risk Reduction Phases, the \nadversary is focused on reconnaissance trying to find out about the end system. The \nreconnaissance activities the adversary most likely uses in these phases are extremely hard to \ndetect because they are frequently passive (e.g., collecting data by listening to traffic on a \nnetwork) or hidden (e.g., hiding information exfiltration in normal network traffic). These \nactivities can still be mitigated against by using one or more of the techniques described in \nsection5. Addressing the reconnaissance activities in the Materiel Solutions Analysis phase and \nthe Technology Maturity and Risk Reduction phase is one of the most effective ways of \naddressing the adversarys weaponization activities. If the adversary does not have adequate \ninformation it is hard for them to develop effective weaponized tools.\nThe adversary focuses their weaponization, attack delivery, and installing the exploit in the \nEngineering and Manufacturing Development Phase and the Production and Deployment phase. xviii 7 Attacks A6, A 27 and A29 from [3] are examples of this type.\n8 Attack A37 from [3]is an example of this type of attack. There is also further reconnaissance to determine what to do in this and later acquisition lifecycle \nphases. Examples of these types of attacks include7 microprocessors or other chips with secret \nback doors substituted for legitimate hardware components, malicious code inserted into open \nsource software libraries, and establishing rogue processes in an integration facility to \nclandestinely insert maliciously altered components.\nThe adversary shifts towards Control, Execute and Maintain activities as the acquisition lifecycle \nprogresses into the Production and Deployment phase and the Operations and Support phase. By \nthe Production and Deployment phase, the adversary already has a foothold in the mission \nsystem. While the adversary is likely still developing or honing their weapons, delivering new \nversions or updates, and initiating new attacks; their interests have transitioned to controlling \ntheir tools, executing the attack on the mission, and maintaining their presence (e.g., when the \nsystem goes through independent verification and validation). This is particularly true as the \nsystem moves towards the later portion of the phase. Some examples of what the adversary might \ndo are: corrupt critical operational data by injecting false but believable data into the system \nduring configuration8, or leverage backdoors previously inserted into software or compromised \nhardware or firmware to control systems.\nDuring the Operations and Support phase, the adversary focuses on Control, Execute and \nMaintain activities. The adversary may trigger their backdoors to establish C2 channels. \nAlternately, their cyber weapon could be set to auto-trigger based on conditions that can be \ndetected within the mission system. Adversary Advantages Gained Via Supply Chain Attacks3.4\nAs stated above, when employing a supply chain attack, the adversary wants to impact \nconfidentiality, integrity, and/or availability (CIA) of critical mission systems so as to affect the \nmission which depends on those systems. Supply chain attacks, just like any cyber attack, \nexploit a target system and then seek to control, execute and maintain presence on that system. \nSo, a supply chain attack once delivered, will appear to a network defender like any other cyber-\nattack. It will use the same tactics, techniques and procedures (TTPs) (establish persistence, gain \ncredential access, lateral movement etc.). In their delivery, however, supply chain attacks are \nunique and the adversary has the advantages of establishing persistence early by embedding the \nattack within one component of the end mission system and delivering the cyber weapon \nundetected. Cyber-attacks are, for the most part, delivered from an external source to an \noperational network. Therefore, perimeter defenses such as intrusion detection devices and \nfirewalls are effective tools to detect and stop attacks upon entry. However, a supply chain attack \nis often initiated by an embedded change to a component of the system which is accepted as a \nknown good. An approved or trusted delivery mechanism such as a software update \nfunction delivers the supply chain attack unsuspected by a network defender. As stated in the \nrecent Defense Science Board Task Force on Cyber Supply Chain when done effectively, \nmalicious insertion will not be detectable until actuated and it may present as a design flaw when \nultimately observed [6].\nThe supply chain attack is initiated early in the system design so that persistence can be \nestablished before the system is built. Once present in a low-level component such as firmware, \na supply chain attack is difficult to detect on an operational network and is a key advantage of \nsupply chain attacks. xix A recent example of an attack in which the software supply chain was compromised is Nyetya \n(Cisco TALOS naming convention) or NotPetya (widely known name) ransomware of late June \n2017. This ransomware, per preliminary reports, did not gain access via an email or office \ndocument. Instead, the entry point is thought to be via the update system for a Ukrainian tax \naccounting package (MeDoc) [15]. Once entry was gained, the adversary enumerated the \nnetwork components, stole credentials, moved laterally eventually encrypting large amounts of \ninformation. \nAnother example of an effective supply chain attack is a Basic Input Output System (BIOS) \nimplant. This implant can be done at a point within the supply chain prior to operations or by an \nautomated firmware management function such as Intel Active Management Technology or Intel \nStandard Manageability (AMT, LMS) that operate below the OS (unobservable from OS/kernel). \nA BIOS or unified extensible firmware interface (UEFI) implant establishes presence and \nmaintains that presence even if the operating system is re-installed. \nIn summary, supply chain attacks can be distinctive
in their delivery methods. They provide an \nadvantage for achieving undetectable delivery and early persistence. xx 4 xxi Notional Example of Supply Chain Attack5\nThis section describes an example of a supply chain attack in the context of the acquisition \nlifecycle, detailing the steps throughout each acquisition phase and the ultimate impact in the \nOperations and Support Phase. In this notional example, a wireless local area network is to be \nacquired and deployed at a campus (e.g., a military base or a set of buildings in a metropolitan \narea).\nWe examine a supply chain attack within the context of the Campus Wireless Local Area \nNetwork (WLAN) Commercial Solutions for Classified (CSfC) Capability Package (CP) [16]. \nThe intent of this CP is to minimize the risk of wireless devices accessing sensitive data and \nenterprise service domains. Figure 4 shows an example deployment of the capability that \nsupports wireless access to multiple classification domains. Figure 4. Multi-level Domain Campus WLAN Solution During the early stages of the acquisition i.e., the Materiel Solutions Analysis and Technology \nMaturation and Risk Reduction phases, the acquiring organization identifies capabilities and \nmission system-level requirements, including the requirement for wireless access to multiple \nclassification domains. The acquisition team identifies several plans for such architectures, \nincluding the Campus WLAN CP. An adversary would want to engage in this phase primarily for \nreconnaissance. Initial capabilities and requirements documents (e.g., ICD, CDD) hold valuable \ninformation such as key performance parameters (KPPs) and key system attributes (KSAs), that \ncan give adversaries insight into potential designs or likely product choices. For example, the \nnumber of simultaneous users or VPN performance requirements may limit the number of \nproduct options. With this information, adversaries can begin to target those specific technology \nvendors and start researching potential vulnerabilities.\nIn addition to reconnoitering, adversaries may also have opportunities to influence requirements \nto degrade the overall security or survivability of the mission system. Adversaries may engage by \ndirectly accessing and modifying the files or by targeting acquisitions personnel to convince them \nto make the necessary changes. This might be done by planting information that certain vendors \nare experiencing product difficulties.\nDuring the Engineering & Manufacturing Development phase, the technical planning and xxii development gets underway. External personnel are brought in through contracts for capability \ndevelopment and integration. For the WLAN CP requirements, the acquiring organization starts \nto specify the architecture and develop the initial hardware and software designs. The \nAcquisitions Office also begins to identify the appropriate cybersecurity and resiliency needs \n(Figure 5). Figure 5. Example Campus WLAN Continuous Monitoring Points These activities translate to increased opportunities for an adversary. As the acquisitions shift \nfrom soft requirements to hard deliverables, the adversary can begin weaponizing and delivering \nexploits for eventual integration. Adversaries may target the design specifications for specific \nhardware and software components. They will look for weaknesses in the systems defense and \nsurvivability capabilities such as flaws in the VPN or wireless frequencies that can be exploited. \nThey may reverse engineer potential safeguards and verification capabilities. Defensive cyber \noperations pose an interesting supply chain target for adversaries, as the defenses are usually \nmonitored less and are not considered mission essential, but are often deployed in line with more \ncritical components.\nAdditional external involvement of people and organizations only increases the attack landscape. \nInstead of targeting the more protected and aware program office, the adversary can focus on the \nprimary and secondary contractors. The farther the supply chain level is from the acquisition \norganization (e.g., subcontractors, component suppliers), the more likely an adversary will be \nable to successfully target as their OPSEC requirements are likely to be less stringent. Instead of \ngoing after the prime WLAN CP integrator, the adversary may engage or otherwise target the \nsubcontractor providing the WLAN access points or the supplier of the authentication \nmanagement software (e.g., as a front company).\nAs acquisitions shifts into the Production & Deployment and Operations & Sustainment phases, \nthe adversarial tactics transition to the more typical supply chain attacks against the components. \nWhile the acquisition activities in Production & Deployment and Operations & Sustainment are \ndifferent, adversaries will target the supply chain in similar ways to implant and modify \ncomponents. Production & Deployment is an inject point for counterfeit hardware components, \nbut similar opportunities present themselves in Operations & Sustainment through testing, \ntroubleshooting, and periodic upgrade or refresh cycles. A determined adversary will examine the xxiii supply chain to attack the weakest points, regardless of whether it is hardware, firmware, or \nsoftware.\nAnother potential supply chain attack vector is through the configuration. Even a small \nenvironment such as the WLAN CP has multiple configurations to enable authentication and \naccess management. These include WLAN access lists, VPN configuration and authentication \nlists, gray management service configurations, firewall rules, IDS/IPS rules, and network \nappliance and routing rules. Configuration files are rarely modified and less likely to be \npersistently monitored. Most often, the configurations are brought in from a contractor \ndevelopment lab via a test facility, or through an external vendor. As it would be evident if an \nadversary were to tamper with the configuration to degrade the environment, they could use \nconfigurations to expand the system attack surface by enabling other capabilities or disability \nsecurity services. Enabling weaker crypto mechanisms on the wireless signals or VPN may be \njust enough for the adversary to gain access to an otherwise secure WLAN. xxiv xxv 9 Cyber resources are Separately manageable resources in cyberspace, including information in electronic form, as well as \ninformation systems, systems-of-systems, network infrastructures, shared services, and devices. derived from [9].\n10 Appendix A provides a brief discussion of the potential effects on the adversary using the cyber resiliency approaches described \nin this paper. These are discussed in more detail in Table H-6 of [18] and in [33].\n11 Cyber resiliency objectives are described in [2]. Cyber Resiliency Mitigations for Supply Chain Attacks6\nThe previous sections described adversary intentions and methods and examined them through \nthe wireless LAN example. This section recommends cyber resiliency techniques to mitigate \nadverary attacks on the supply chain. This section introduces cyber resiliency mitigations, defines \na set of goals for a defender, and then recommends resiliency techniques and approaches that can \nbest achieve the defenders goals to thwart supply chain attacks throughout all stages of the \nacquisition lifecycle. The recommended mitigations are listed in the below text. In addition, \ntables in Appendix D contain a more extensive list of cyber resiliency mitigations and what \nadversary goals are thwarted and what defender goals are achieved for each.\nThe SSE combines their knowledge of the specific system under review and the deployment \nenvironment, with known adversary tactics and techniques. This section can then be used to cross-\nreference that information with the appropriate cyber resiliency techniques to augment traditional \nsecurity solutions (e.g., redundancy, privilege restriction, substantiated integrity) and those that \nadd less traditional cyber resiliency techniques (e.g., diversity, deception, dynamic positioning) \nthat can change the attack surface [17]. The authorizing official should also consider cyber \nresiliency in making a risk management judgment and trying to reduce risk to an acceptable \nlevel. Cyber Resiliency Summary6.1\nCyber resiliency (also referred to as cyber resilience) can be defined as the ability to anticipate, \nwithstand, recover from, and adapt to adverse conditions, stresses, attacks, or compromises on \ncyber resources.9 Appendix D Summary of Cyber Resiliency Techniques and Approaches \nsummarizes candidate mitigations for achieving cyber resiliency against supply chain attacks. It is not feasible to apply all cyber resiliency techniques to an architecture, so the system architect \nis compelled to select the most effective subset of those techniques while considering the impact \non the overall system. Some considerations when selecting cyber resiliency techniques are: How the technique addresses the types of risks in the architecture under consideration\nThe relative maturity and readiness for cyber resiliency application\nThe potential interactions between the techniques both conflicting and synergistic\nThe effects on the adversary10 \nAdditional political, operational, economic and technical (POET) factors. It is not possible to adequately incorporate these considerations in an assessment without a \nspecific architecture and environment. Cyber resiliency techniques are focused on achieving one \nor more cyber resiliency objectives.11 In addition, some techniques work better in certain types of \narchitectures than others. For this reason, the discussion here is focused on applicability and will \nalso discuss the interactions between, the resiliency techniques but will not discuss the specific \nPOET factors. \nThe reader should consult Appendix D: Summary of Cyber Resiliency Techniques and \nApproaches as background information before reading the following sections. It is key to xxvi 12 These acctivities are associated with the effects on threat events described in Appendix H of NIST SP 800-160 [18]. Reducing \nan attack covers the categories of Redirect, Preclude and Preempt; limiting the effectiveness of attacks covers the categories \nof Impede and Limit; and gaining and sharing information covers the categories of Detect and Expose. understanding the cyber resiliency techniques and approaches recommended in this section.\nBecause the following discussion applies to missions in general, Section 5.2 will discuss defender \ngoals in general terms and the resulting recommendations need to be tailored when applying \nthem to a mission. This is so that
the resiliency needs of that specific mission are addressed. \nSection 5.3 provides a more detailed description of specific recommendations based on \nenvironmental factors. Section 5.4 will show how resiliency mitigations might be tailored for a \nspecific environment by revisiting the example attack described in Section 4.\nThe application of cyber resilience mitigations to supply chain attacks must take both the threat \nenvironment and the mission environment into account. The discussion in Section 3 described the \nthreat in terms of adversary actions in the abstract, while the discussion in Section 4 described the \nthreat in terms of adversary actions in a theoretical environment. Defender Goals6.2\nThe overall defender goal is to enable missions to succeed despite being under attack. In some \nsituations, the mission is a single event. More frequently the mission is ongoing and the defenses \nmust evolve as the adversarys attack evolves. This defense is supported by four underlying \ndefender activities.12 Just as with attacker goals, each defender goal is supported by a different \ncombination of cyber resiliency mitigations. The defender goals are: Reduce Attacks: While defenders cannot eliminate all attacks the number and range of \nattacks in the Operations and Support phase can be reduced by cyber resiliency \nmitigations in earlier phases of the acquisition lifecycle. Diminish Success of Attacks: Cyber resiliency mitigations applied throughout the \nacquisition lifecycle can make attacks that are not eliminated less successful. This can \nmean either limiting the overall impact to the mission or limiting the impact on the \nspecific element of the environment being attacked. Gain and Share Information about Adversary Activity: Sharing information about \nadversary activity throughout the acquisition provides knowledge of adversarial activities \nwithin the Operations and Support phase. Defenders can use the information acquired \nfrom adversary activities in prior acquistion phases to detect and stop attacks as well as to \nchange mission operations so that attacks do not stop the mission. Recover: Using information gained from earlier phases along with appropriate \npreparations, helps defenders achieve recover operational abilities quickly enough to \nensure the mission is accomplished. For this analysis, we provide a general characterization of defender activities undertaken to \nenable mission success. It should be noted, however, that defenders focus may differ based on \ntheir role within an acquisition lifecycle phase. For example, early in the acquisition lifecycle, \nthe defender is the service element which provides ICT support to the Program Office. The \ndefender is focused on preventing exfiltration of sensitive information about the system to be \nacquired, and preventing specifications from being modified. \nLater, in the acquisition lifecycle (during the Engineering and Manufacturing Development and \nProduction & Deployment), the defender is the prime contractor, together with subcontractors xxvii and suppliers. The overall goals are to prevent exfiltration and to prevent unauthorized \nmodification of specifications, design documents, and to-be-deployed-system components.\nDuring the Operations & Sustainment phase, two defenders are active: the defender of the as-\ndeployed system, and the defender of the maintenance environment. The defender of the as-\ndeployed system is focused on mission assurance; the defender of the maintenance environment \nis focused on protecting the portion of the supply chain for which they are responsible.\nThe recover goal is usually part of limiting the effectiveness of attacks as refered to in [18]. \nIn the case of supply chain attacks the difficulty of recovery and the need to specifically focus on \nthat aspect makes it appropriate to emphasize this goal along with the other three. Effective Defense Throughout the Acquisition Lifecycle6.2.1\nDefenders can more effectively address adversary activity if they defend the acquisition lifecycle \nas a whole, rather than viewing each phase in isolation without sharing information or \nconsidering the other phases. This is challenging because the environment and its ownership \n(e.g., program office, contractor, or mission environment) changes as the acquisition lifecycle \nprogresses. The Engineering and Manufacturing Development and Production and Deployment \nphases provide the greatest opportunity for defenders both in terms of Cyber resiliency \ntechniques and approaches (i.e., greatest number of techniques possible) as well as in terms of \nimpact across the goals (i.e., the adversary has the most widely varied activity and is most active \nin these phases). In addition, if defenders wait until Operations and Support to address the \nadversarys threat to Operations and Support, the adversary has already acted and the \npossibilities of remedy are limited because the environment is less flexible.\nAs the system moves through the acquisition lifecycle, the adversary priorities change from \nobtaining information about the system to developing and delivering initial exploits to get hooks \ninto the development environment and the finally to attacking the end system and maintaining \ncontrol. Similarly, as the system moves through the acquisition lifecycle, the defender priorities \nshould shift from protecting information to protecting the component development environment \nand gaining information about the adversary for defense activity in Engineering and \nManufacturing Development and Production and Deployment and finally to detecting and \nresponding to adversary activity in Production and Deployment and Operations & Sustainment. \nMore specifically, the set of potential cyber resiliency mitigations increases over the acquisition \nlifecycle to include: Protecting information from unauthorized access \nAnalyzing what the adversary is doing, detecting their presence, \nMaking it harder for the adversary to function in the development environment by making \nit more diverse and deceptive, \nResponding to the adversary activities in such a way that it minimizes the adversarys \nability to successfully complete an attack and o\ncause the adversary to expose their activities as much as possible.o Based on the adversary activities as described in [19], the most effective points at which to apply \nthe cyber resiliency mitigations to reduce the number of attacks in the Operations and Support \nand gain the most information about adversary targets and activities are in the Engineering and \nManufacturing Development phase and the Production and Deployment. xxviii Cyber Resiliency Mitigations Considering Adversary and Defender 6.3\nGoals Cyber resiliency countermeasures are any response taken to prevent, mitigate, or recover from \none or more attack impact. Preventative countermeasures reduce the likelihood of an adverse event or subsequent \neffect by avoiding or preventing the initial attack vector. Mitigating countermeasures constrain or otherwise decrease the rate of degradation \ncaused by the adverse impact. Recovery countermeasures improve the rate of reconstitution, such as through restoring \nlost capabilities or making additional resources available. Countermeasures can occur across people, processes, technology, and policy. The information \ngained from these countermeasures can be used to evolve the mission operations and systems, \nincreasing cyber resiliency.\nBelow is a discussion of cyber resiliency countermeasures that can be used to mitigate the \noperational impacts caused by successful supply chain attacks. The most widely applicable and \neffective mitigations will be highlighted in this text. The rest can be found in the tables in \nAppendix D. Materiel Solutions Analysis Phase6.3.1\nIn the Materiel Solutions Analysis phase, the adversary goal is to gain information. Defenders \nare usually not able to gain specific information about adversary interests because of the passive \ntechniques used by, and the adversarys diverse interests at this point in their attack lifecycle. In \ngeneral, defender environments tend to be enterprise IT and techniques such as Non-Persistence, \nPrivilege Restriction and Segmentation are the best ways of defending against the adversary \nactivities in this phase. \nSpecifically, the Non-Persistence Information approach wipes information as soon as it is no \nlonger needed. This approach can be applied to information caches and other temporary \ninformation storage areas. Non-Persistent Services and Non-Persistent Connectivity approaches \nremove the services and connectivity respectively when they are not being used for authorized \npurposes thereby denying paths to the information. All three approaches reduce the opportunities \nfor unauthorized access to information.\nThe Privilege Management approach of the Privilege Restriction technique reduces the number \nof resources accessible with individual resources based on criticality. Within the Material \nSolutions Analysis phase, this causes the adversary to spend more effort to gain access credentials \nto the resources most useful in gaining reconnaissance information. Similarly, the Privilege-\nBased Usage Restriction approach reduces the opportunity for the adversary to gain access to \nresources by restricting access to only those individuals who need a resource to perform their \nduties. With this approach in place, the adversary must spend additional effort in identifying \nwhich individuals have access to the resources they need. The Dynamic Privileges approach is \none that changes the level of privileges assigned to users as well as the level of privileges needed \nto access resources dynamically. For example, access to certain resources after regular work \nhours could be restricted to a smaller group of people, thereby making it harder for the adversary \nto conduct activities at times they would not be noticed. xxix There are two Segmentation approaches Predefined Segmentation and Dynamic Segmentation \nthat are useful within the Material Solutions Analysis phase. Both these approaches reduce the \nadversarys ability to exfiltrate data defeating their main goal in this phase. \nIn addition, using the Temporal Unpredictability approach of the Unpredictability technique in \nconjunction with Privilege Restriction can boost that techniques effectiveness by making it even \nmore difficult for the adversary to determine which privileges are needed at a specific time. For \nmore details please refer to Appendix C. Technology Maturity and Risk Reduction
Phase6.3.2\nRecommendations for mitigations within the Technology Maturity and Risk Reduction phase are \nlike those in the Materiel Solutions Analysis phase. However, there is more specificity in this \nphase. The defenders are more focused on solutions and the adversaries may have made some \nchoices about what technology to investigate further. For these reasons, the Deception technique \nis added to the recommended techniques to consider. There are three approaches Obfuscation, \nDissimulation/Disinformation and Misdirection that are included within the Deception \ntechnique that are applicable to the Technology Maturity and Risk Reduction phase. Obfuscation \n(i.e., encryption) makes it difficult for the adversary to identify and target high value information \nresources. Dissimulation/disinformation purposely provides the adversary with false information \nso that attacks developed for later phases are ineffective. Misdirection wastes the adversary \nresources by directing them to deception environments (i.e., honeynets). Engineering and Manufacturing Development Phase6.3.3\nDuring the Engineering and Manufacturing Development phase the initial exploit may occur. \nThe adversary goals expand to developing and delivering this exploit, initiating it and then \ncontrolling the subsequent attack. With a more active adversary, the defenders can gain \ninformation about the adversary in addition to reducing and limiting the attacks that reach the \nOperations and Support phase. In addition to the Deception technique, the Analytic Monitoring \ntechnique can be effective in gathering information to share with later phases of the acquisition \nlifecycle. Both Substantiated Integrity and Non-Persistence techniques can make it difficult for \nthe adversary to deliver an exploit, hopefully reducing the number of attacks. Substantiated \nIntegrity provides mechanisms for checking whether resources such as critical services, \ninformation stores, information streams and components have been corrupted. Non-Persistence \nprovides opportunities to refresh those critical resources from known good sources. The Non-\nPersistence technique also reduces the time resources are available to be attacked. When these \ntwo techniques are combined with the Unpredictability technique, the adversarys ability to \ncreate accurate and precise plans decreases, thus reducing the number of attacks that later appear \nin the Operations and Support phase of the Acquisition Lifecycle. \nSensor Fusion and Analysis is an approach within Analytic Monitoring that helps expose \nadversary activity. Defenders use monitoring data and preliminary analysis results from various \ncomponents and integrates this information with external threat intelligence to identify potential \nor actual adversary activity. The Malware and Forensic Analysis approach to Analytic \nMonitoring focuses on known adversary activities and artifacts to identify the presence and \nactivities of the adversary. Both approaches provide information that can be used to eliminate \nthe initial exploit and follow-on control exerted by the adversary. The information gained using \nthis technique can also be shared with later acquisition lifecycle phases and make it easier for the \ndefender to make effective recovery plans. xxx The Non-Persistence approaches described above can be used in the Engineering and \nManufacturing Development phase to reduce the adversarys ability to deliver, initiate and \ncontrol attacks by reducing the paths into the environment through the Non-Persistent Services \nand Non-Persistent Connectivity approaches. The Non-Persistent Information approach can be \nimplemented by reimaging the environment from known clean images.\nThe Substantiate Integrity technique approaches Integrity Quality Checks, Provenance \nChecking, and Behavioral Validation are all useful in ensuring that the clean images \nreferenced in the previous paragraph are indeed clean and reimaging the environment with these \nimages will not cause the adversary to persist.\nAs previously described, the approaches within the Unpredictability technique can be used to \nincrease the effectiveness of other approaches. Within the Engineering and Manufacturing \nDevelopment phase, defenders can combine Temporal Unpredictability with the Non-Persistence \napproaches to increase the uncertainty for the adversary. For example, the adversary will have a \nmuch more difficult time executing successful attacks and remaining undiscovered if they are \nuncertain about how long a service will be available, a connection will stay open or their exploit \nwill remain in the environment. Likewise, combining Contextual Unpredictability with integrity \nquality checks makes it more difficult for the adversary to emulate components and get \ncompromised components into fielded systems. Production and Deployment Phase6.3.4\nThe Production and Deployment Phase is an attractive target for the adversary because this phase \nhas the most mature products prior to the Operations and Support phase but the safeguards that \nare in the Operations & Support phase may not be in place in this environment. If the defenders \n the prime contractors and subcontractors are using cyber resiliency techniques such as \nAnalytic Monitoring, Deception, and Dynamic Representation, there is a high likelihood that they \nwill be able to identify and understand adversary behavior. Even if they are unable to completely \nstop the adversary activity, they will be able to gather information and share it with the \nOperations & Support phase environments so that they are better able to limit the impact of the \nattacks there. In addition, it may be easier to stop or limit the attacks in the Production and \nDeployment phase with techniques such as Adaptive Response because there may be more \nflexibility in this phase than in the operational environment. Likewise, some aspects of \nCoordinated Defense and Diversity techniques may be easier prior to the operational \nenvironment. \nThe approaches within the Dynamic Representation technique Dynamic Mapping & Profiling, \nDynamic Threat Modeling, and Mission Dependency & Status Visualization are focused on \nconstructing and maintaining representations of the environment or mission in light of cyber \nevents and actions (both adversarial and defense). The Dynamic Mapping & Profiling approach \nidentifies software and components that do not conform to policy requirements or that are \nbehaving in unexpected ways. The Dynamic Threat Modeling approach reveals patterns and \ntrends in adversary behavior and the Mission Dependency & Status Visualization approach \nidentifies consequences of adversary execution. The information gained from these approaches \ncan be combined with the other information used in Analytic Monitoring along with information \ngained from Deception activities to increase the likelihood of identifying and understanding \nadversary behavior and targeting for this Acquisition Lifecycle phase as well as Operations and \nSupport. With this information, recovery plans for the Operations and Support phase can be \ndefined and tested. xxxi Operations and Support Phase6.3.5\nOnce the Acquisition Lifecycle has moved into the Operations and Support phase, there is \nfrequently less flexibility in what mitigations can be employed as well as limits on what the \nmitigations can do. The malware will already have been implemented in the targeted mission \nsystem so it is harder to preclude an attack in this phase. For example, because the environment \nmay not be flexible, the ability to deploy Adaptive Response mitigations is limited. Similarly, \nmany of the deployed solutions may need to be very lean, this reduces the opportunity for \nAnalytic Monitoring, Dynamic Representation and Redundancy. While the cyber resiliency \ntechniques mentioned here will be useful, in these cases, they will primarily be leveraging what is \nalready in the environment and so are not optimized for the defender goals of reducing and \neliminating attacks and gaining and sharing information about those attacks. Note that the \nenvironment being defended is now the mission system\nThe approaches within the Adaptive Response technique Dynamic Reconfiguration, Dynamic \nResource Allocation and Adaptive Management are focused on nimbly implementing courses of \naction to manage risk. These approaches can most effectively be leveraged in the Operations and \nSupport phase if they have been designed into the environment and used with the Technical \nDefense-in-Depth approach of the Coordinated Defense technique. The combined techniques \nprovide the defenders with the ability to adaptively respond to attacks this enables the defenders \nto recover from attacks more effectively and faster than would otherwise be possible. The use of \nthese approaches depends on the flexibility of the operational environment and so these \napproaches are not usually successful unless planning for them has started early in the design. Method for Applying Cyber Resiliency Mitigations and Worked 6.4\nExample Cyber resiliency enables the operational mission and supporting systems to better anticipate, \nwithstand, recover, and evolve despite adversary attacks and other adverse effects. Thus, when \napplying supply chain cyber resiliency mitigations to a mission system acquisition, the \nmitigations ought to be contextualized by, and support, the operational mission. The most \neffective way for a mission system to achieve maximal cyber resiliency is to start with the to-\nbe operational system and work backwards through the acquisitions lifecycle. For each \nacquisitions phase, these are the appropriate questions that should be asked: Which supply chain threats pose the largest mission risk?\nInstead of focusing solely on the mission criticality of assets, we want to apply a broader \napproach that acknowledges that an adversary is likely to exploit the easiest attack vectors \nto achieve their objective. To do this we want to identify which threats pose the most risk \nto the mission those threats that are the most likely and may cause the most harm to the \noverall mission. How might the mission system be improved to mitigate the most damaging supply \nchain attacks or compromises?\nIf some of the supply chain attacks will be successful, we want to assure the mission \nsystem and the supply chain against those that pose the largest risk. How might we improve the recovery & evolution of the system against future supply
\nchain threats?\nMitigating existing and known threats is a good start to protect against the latest supply \nchain threats. However, the adversaries will continue to evolve new tactics and techniques xxxii that take advantage of new technologies. Adopting flexible design and engineering \ndecisions will help operators and system engineers better support and defend the system \nthroughout its operational sustainment. For each acquistion phase these three questions and a sample set of answers are listed below to \ndemonstrate how to apply this mindset to develp mitiations using the Multi-level Domain \nCampus WLAN Capability and attacks (Section 1, Figure 4). Operations and Support6.4.1\nIn the Operations & Support phase, the full mission system, including our WLAN capability is \ndeployed and fully operational. The system is being actively used by users and is under attack by \nadversaries. The major supply chain threats come from changes to the system by way of \nconfiguration changes, security patches, feature additions, and technology refresh cycles. At this \npoint, there are no changes to the tech baseline and the supply chain adversary should have \nsufficient knowledge of the architecture, including hardware and software vendors, versions, and \nconfigurations.\nTable 3 contains sample answers to the question of which supply chain threats pose the biggest \nmission risks during the Operations and Support phase. Table 3. Supply Chain Threats and the Associated Mission Risks (Operations and Support) Supply Chain Threat Mission Risk\nModified configurations and software Management Services, Authentication Services impacts mission risk across confidentiality, integrity, \nand availability vectors Compromised end user wireless devices and \nVPN client software Large integrity and confidentiality risk for the \ndomains and data they are permitted to access Modified configurations and software Red-side IPS/IDS impacts mission risk across \nconfidentiality and availability Modified configurations or software on the \nVPN Gateway Mission confidentiality (using less secure channels) \nand availability Modifications to configurations and \nfirmware/software for grey-side Network, \nGateway, and Firewall devices Mission availability Limited updates to firmware and hardware \nthreat likelihood Minor impact on mission risk Table 4 contains sample answers to the question of how to improve the mission system to \nmitigate the most damaging supply chain attacks and compromises during the Operations and \nSupport phase. Table 4. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission System \n(Operations and Support) Cyber Resiliency \nTechnique Application Substantiated Integrity Preserve the integrity and provenance of the configuration and \nsoftware to mitigate most of the risk Substantiated Integrity in Adopt two-person configuration change authority. Implement xxxiii combination with Privilege \nRestriction processes to require at least two different user authorizations before \nsoftware and configuration changes become operational Substantiated Integrity in \ncombination with \nconfiguration and change \nmanagement solutions Leverage triple entry accounting [19] approaches to provide integrity-\nassured change management. Approaches include blockchain and \ncertain distributed version management, which can be combined with \ndigital signatures to provide a cryptographically tamperproof chain of \ncustody for soft assets Substantiated Integrity in \ncombination with \nRedundancy Version control assets as virtual machine (VM) images. Do change \nmanagement over the entire asset as a VM, multiple versions of a VM \ncan be simultaneously supported, allowing for staged, incremental \nrollouts as well as efficient rollback to minimize impacts from malicious \nsupply chain injects or substitutions Substantiated Integrity in \ncombination with \nRealignment Tailor V&V efforts. Identify unique and comprehensive functional and \noperational verification & validation (V&V) approaches specific for the \nmission system and perform testing before deploying anything to \nproduction. Every mission system should have a testing facility that can \naccurately simulate operational conditions. Tests should examine \nfunctionality, minimizing updates impact on integrity or availability, as \nwell as the baseline performance, and aiding in counterfeit \nidentification. By policy, all new and modified hardware, firmware, \nsoftware, or configuration changes should be thoroughly tested in such \na facility before being approved for operational use Segmentation Isolate software execution. Segment the OS from the hardware and \nfirmware through virtualization and hypervisors. Use application \ncontainers or other execution sandboxes to contain execution impact \nand minimize the ability for supply chain implants to establish and \nmaintain footholds Privilege Restriction: Constrain Resource Usage. Placing limits on software resource usage \nlimits an adversarys effectiveness as well as the overall adverse impact \na software supply chain implant could have Diversity Consider alternatives to traditional security patching. If an attacker can \ninfiltrate an upstream software vendor, their biggest challenge becomes \nhow to move the compromised software into the target environment. \nLeveraging security patching is one method. Instead of immediately \napplying new security patches, consider the need for the patch and \npotential alternative methods for detection and mitigation (e.g., \ndisabling noncritical features, IDS/IPS signatures) Analytic Monitoring Monitor performance. While the Operation & Sustainment phase is late \nfor adapting design or improving mission system flexibility, supply chain \nimplants will consume some resources and affect performance or data \nintegrity. By monitoring historical performance characteristics across \nresources, certain types of implants may be detectable (e.g., grey \nmarket, time bombs) Coordinated Defense Adopt proven SCRM controls. Follow supply chain risk management [5] \nand physical protection [20] guidance to sustain provenance integrity \nand decrease chances of compromise during operations xxxiv Table 5 provides sample answers to the question of how to improve the recovery of and evolve \nthe capability of the mission system against future supply chain attacks during the Operations \nand Support phase.\nTable 5. Improving Recovery and Evolution of the Capability Against Future Supply Chain Threats (Operations and Support) Cyber Resiliency \nTechnique Application Adaptive \nResponse, Dynamic \nRepresentation Monitor (supply chain) threat landscape. Continually monitor the threat \nlandscape and update processes, detection, and countermeasures for potential \nadverse supply chain tactics, techniques, and protocols (TTPs) against current or \npotential vendors and suppliers as well as similar technologies or components, \nwhich may be applied against current or future supply chain channels Realignment Take advantage of refresh and Plan of Action and Milestones (POA&M) cycles. \nMinor improvements can be made through technology refresh cycles and \nsimilar point upgrades by migrating towards products that support common \nindustry standards, allowing for future flexibility Production and Deployment6.4.2\nDuring the Production & Development phase, the mission system architecture has been finalized \nand the various hardware and software components are being mass produced per specifications. \nThe components are being delivered to the organization and being integrated and tested to ensure \nthe composite system meets functionality and operational requirements. A supply chain \nadversary could tamper with the production and delivery, potentially injecting or modifying \ncomponents. This is the adversarys opportune time to compromise commercial (non-custom) \nhardware.\nTable 6 contains sample answers to the question of which supply chain threats pose the biggest \nmission risks during the Production and Deployment phase. Table 6. Supply Chain Threats and the Associated Mission Risks (Production and Deployment) Supply Chain Threat Mission Risk\nModified software for Management Services, and \nAuthentication Services Risks across confidentiality, integrity, and \navailability vectors Compromised end user wireless devices and VPN \nclient software Large integrity and confidentiality risk for \nthe domains and data they are permitted to \naccess Modified software to the red-side IPS/IDS Compromises mission confidentiality and \navailability Modified software on the VPN Gateway Compromises mission confidentiality (using \nless secure channels) and availability Modified grey-side Network, Gateway, and Firewall \nhardware, firmware, and software Risk mission availability Configuration is not a concern as that is done primarily \nduring integration at the start of the O&S phase N/A xxxv Table 7 contains sample answers to the question of how to improve the mission system to \nmitigate the most damaging supply chain attacks and compromises during the Production and \nDeployment phase. Table 7. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission System \n(Production and Deployment) Cyber Resiliency Technique Application \nSubstantiated Integrity Preserve the integrity and provenance of the software to mitigate most of the highest risks. \nSubstantiated Integrity in \ncombination with Diversity Use digital signatures with verified authorities to sign software and \nfirmware updates Substantiated Integrity in \ncombination with Analytic \nMonitoring Perform functional and operational verification & validation (V&V) \ntesting. Some issues, such as VPN tunnels using weaker encryption or \nexposing side channels, are detectable through monitoring and \nbaselining during the V&V processes Coordinated Defense Follow supply chain risk management guidance [5] to sustain \nprovenance integrity and decrease chances of compromise during \nproduction and delivery (e.g., blind buys and tamper evident packaging) Table 8 provides sample answers to the question of how to improve the recovery of and evolve \nthe capability of the mission system against future supply chain attacks during the Production \nand Deployment phase.\nTable 8. Improving Recovery and Evolution of the Capability Against Future Supply Chain Threats (Production and Deployment) Cyber Resiliency \nTechnique Application Adaptive Response, \nDynamic \nRepresentation Continually monitor the supply chain threat landscape. Update processes and \nmonitoring to detect potential threats and tactics against current or potential \nvendors, suppliers and similar technologies or components, which may be \napplied against current or future supply chain channels Diversity Maintain up-to-date lists of alternative suppliers to enable rapid re-purchases \nof equipment if supply chain issues are identified with the primary supplier Redundancy Identify other organizations with similar capabilities and components to \nprovide an option to use or borrow equipment in cases of supply chain \ncorruption Engineering
and Manufacturing6.4.3\nEarlier phases of the acquisitions lifecycle shift the focus from materiel assets to data assets, \nincluding mission system architecture, design, and development documents and specifications. \nChanges made to these softer components will have an impact on the actual design and \nproduction of the final components. \nIt is during the Engineering and Manufacturing Development phase that the custom system \ncomponents are functionally specified, designed, built, and initially tested. In our example, the \nWLAN CSfC is developed using commercial solutions, so we do not have to worry about the \nsupply chain threats to customized or unique component development. If we did have such a xxxvi component, it would most likely be a critical component and be at the top of the list as having the \nlargest mission risk. Therefore, our example will focus largely on preserving the integrity of the \nengineering and design decisions, rather than new capability development.\nTable 9 contains sample answers to the question of which supply chain threats pose the biggest \nmission risks during the Engineering and Manufacturing phase.\nTable 9. Supply Chain Threats and the Associated Mission Risks (Engineering and Manufacturing) Supply Chain Threat Mission Risk\nModified hardware, firmware, and software \ndesigns and components for critical components Risks across confidentiality, integrity, and \navailability vectors WLAN CSfC developed from commercially \navailable solutions for hardware, firmware and \nsoftware Minor Risk Adversaries would have a hard time \ntargeting a specific organization and would have \nto compromise the product across its entire user \nbase, increasing the likelihood of detection Table 10 contains sample answers to the question of how to improve the mission system to \nmitigate the most damaging supply chain attacks and compromises during the Engineering and \nManufacturing phase.\nTable 10. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission System (Engineering and Manufacturing) Cyber Resiliency \nTechnique Application Substantiated Integrity Preserve the integrity and provenance of data assets (e.g., \ndocumentation, design, firmware, software). Substantiated Integrity in \ncombination with \nRedundancy Use distributed version control. Encourage contractors and vendors to use \ndistributed, triple entry accounting [21] approaches to provide integrity-\nassured version management, which can be combined with digital \nsignatures to provide a cryptographically tamper proof chain of custody \nfor soft assets Dynamic Positioning, \nDiversity Give preference to individual components over integrated solutions. \nStovepipe engineering and manufacturing efforts enables the acquisition \nto compartmentalize knowledge, making it harder for the adversary to \nunderstand and compromise the entire mission system design. For \nexample, the WLAN acquisition may prefer to purchase the WLAN \ncontroller and wireless access points from different vendors rather than \nas a package Diversity Use distributed processing across multiple hardware platforms. \nDistributed processing decouples the command execution from the \nspecific operational data flow. Distributing the processing, makes it \ndifficult for an adversary to precisely target a specific capability or \nalgorithm through supply chain hardware modification. Additionally, the \nredundancy requires an adversary to compromise exponentially more \nsystems to increase operational impact Redundancy Use redundant processing paths for critical capabilities. Compare the \nresults of critical, repeatable and consistent algorithms across multiple \nruns on multiple platforms. By performing a calculation multiple times \nwith the same input, it is easy to spot discrepancies in the results, xxxvii indicating a potential loss of supply chain integrity Table 11 provides sample answers to the question of how to improve the recovery of and evolve \nthe capability of the mission system against future supply chain attacks during the Engineering \nand Manufacturing phase. Table 11. Improving Recovery and Evolution of the Capability Against Future Supply Chain \nThreats (Engineering and Manufacturing) Cyber Resiliency \nTechnique Application Adaptive Response Adopt industry standards. The use of industry standards and supporting \nproducts can accelerate recovery and system evolution through the \npromotion of standardized capabilities and communications. This allows \nproducts to be more easily switched to ones with less supply chain risk, \nwithout major impact to the system. These standards usually come with a \nlarger user community and vendor interoperability testing, providing \nadditional levels of supply chain mitigations and assurances. In the WLAN CP, \nthis could mean leverage standard authentication protocols (e.g., Extensible \nAuthentication Protocol (EAP), 802.1X, Kerberos), IPSec VPNs, and \nInformation Technology Infrastructure Library (ITIL) or ISO/IEC 20000 \ncompatible management frameworks. Dynamic Positioning Prefer swappable components. Some components are more easily replaced \nwith alternatives. For example, the WLAN wireless access points are probably \neasy to change. Similarly, most software can be run on a variety of hardware \nplatforms, which can be quickly swapped in case of a supply chain threat. \nThere are also swappable hardware components, such as disk drives and \nother chassis. Diversity Evaluate potential hardware and software alternatives. If a supply chain \nthreat is realized, a standby list of potential alternatives will improve recovery \nspeed. For higher risk, higher threat environments, it may be beneficial to \nperform and maintain some level of regular functionality and integration \ntesting for one or two alternatives during sustainment Technology Development & Materiel Solutions Analysis6.4.4\nThe earliest, pre-systems acquisition phases are primarily focused on data and documents, \nnamely requirements and metrics such as key performance parameters (KPPs) and key system \nattributes (KSAs). This focus limits the number of people, organizations, and technologies, \nsignificantly limiting the attack vectors available to supply chain adversaries. However, any \nsuccessful attacks could have far reaching implications through all subsequence acquisitions \nphases, including Operations & Sustainment.\nTable 12 contains sample answers to the question of which supply chain threats pose the biggest \nmission risks during the Technology Development and Materiel Solutions Analysis phases xxxviii Table 12. Supply Chain Threats and the Associated Mission Risks (Technology Development and \nMateriel Solutions Analysis) Supply Chain Threat Mission Risk\nModified requirements document can lessen the \nrobustness, security, and resiliency of the overall \nmission system and any custom components can reduce the robustness, security, and \nresiliency of the overall mission system and any \ncustom components Table 13 contains sample answers to the question of how to improve the mission system to \nmitigate the most damaging supply chain attacks and compromises during the Technology \nDevelopment and Materiel Solutions Analysis phase.\nTable 13. Mitigating the Impact of Supply Chain Attacks and Compromises on the Mission System (Technology Development and Materiel Solutions Analysis) Cyber Resiliency \nTechnique Application Substantiated Integrity Preserve the integrity and provenance of documentation and related \nrequirements for both mission system and contractor performance. Substantiated Integrity in \ncombination with \nRedundancy Use distributed version control. Encourage contractors and vendors to use \nand audit integrity-assured version management, which can be combined \nwith digital signatures to provide a cryptographically tamperproof chain \nof custody for soft assets Substantiated Integrity in \ncombination with \nDiversity Diversify development. Develop documents and requirements using a \nvariety of applications and formats. This minimizes the impacts that an \nadversary can have by targeting a single document or application. For \nexample, requirements writing may use a combination of word \nprocessing, system engineering, and spreadsheet tools from different \nvendors. An adversary would have to make corresponding changes to \neach different document to avoid detection Substantiated Integrity in \ncombination with \nRealignment Prefer simpler formats. Contrary to diversifying development, many \napplications use custom binary or complex file formats. These formats \nmake it difficult to determine and audit changes across versions, and \nsynchronize revisions across documents. By using simpler, text based \nformats, acquisitions teams can focus on specific requirements and \nmaintain a clean provenance trail Substantiated Integrity in \ncombination with \nPrivilege Restriction Minimize write access. Limit the number of users with the authority to \nmake changes to the official versions of the documents and designs Segmentation Segment development efforts. Stovepipe pre-system acquisition \ndevelopment efforts and compartmentalize knowledge, making it harder \nfor the adversary to understand and impact the overall mission system \ndevelopment and requirements Table 14 provides sample answers to the question of how to improve the recovery of and evolve \nthe capability of the mission system against future supply chain attacks during the Technology \nDevelopment and Materiel Solutions Analysis phase. Table 14. Improving Recovery and Evolution of the Capability Against Future Supply Chain xxxix Threats (Technology Development and Materiel Solutions Analysis Cyber Resiliency \nTechnique Application Realignment, \nAdaptive Response Adopt a composable system architecture. Design the mission system using \ntechnologies that provide future flexibility, such as virtualization, software-\ndefined networking (SDN), and other dynamic representation approaches. \nThe ability to change and adapt the system will make it easier to mitigate later \nsupply chain threats, as well as improve later engineering and operational \nflexibility Segmentation Own the data interfaces. Design the system around data services using service-\noriented architecture (SOA) concepts. The organization should own and \nspecify the critical data interfaces. By owning these interfaces, an organization \ncan better define, monitor, and secure the channel (e.g., read/write \nprivileges, cross-domain validation), while increasing the ability to switch out \nthe components behind the interface xl xli Next Steps7\nThis report has presented a general analysis approach for applying cyber resiliency techniques \nand approaches to the acquisition lifecycle. It focuses on demonstrating how the adversary uses \nthe CAL over the entire acquisition life cycle and the impact on the Operations and Support \nphase of the acquisition life cycle. The cyber resiliency mitigations are those that can be applied \nto reduce or eliminate impacts to the operational end
mission system. \nWe have also demonstrated that the CAL is recursive and each stage of the acquisition life cycle \nand those systems used within that phase are a target for an adversary.\nWe identify systems and system environments within the acquisition lifecycle that an adversary \nmight target in planning and executing supply chain attacks. Next, we associate the adversary \ngoals with respect to the stages of the cyber attack lifecycle against these systems and system \nenvironments keeping in mind that the adversarys end goal is to impact the mission. We \nidentify which cyber resiliency techniques and which approaches to implementing or applying \nthose techniques might be effective in preventing the adversary from achieving this goal. \nSystems security engineers can use the analysis presented in this report as a starting point for \nprogram-specific refinement, enabling development and execution of a Program Protection Plans \n(PPP) that addresses cyber supply chain risks effectively. Program-specific refinement of the \ngeneral analysis presented in this report needs to take into consideration such programmatic \nconstraints as reliance on legacy components, components of uncertain provenance, or shared \nservices. SSEs supporting a Program Office will be able to evaluate how well the Program Office \n(and its ICT support), the Prime or Integration Contractor, and other organizations (e.g., the \nMaintenance Contractor if different from the Prime, IV&V, cyber range) are applying cyber \nresiliency throughout the acquisition lifecycle to reduce supply chain risks due to cyber attacks.\nTo apply these recommendations, Programs will need to include requirements motivated by \ncyber resiliency into contractual documents, specifically SOWs and FRDs. SOW requirements \nwill lead to contractors (the Prime or Integration Contractor, the Maintenance Contractor if \ndifferent, and subcontractors as appropriate) applying selected cyber resiliency techniques in the \ndesign, production, test, and maintenance environments, to make the supply chain more cyber \nresilient. FRD requirements will make acquired mission systems more resilient against cyber \nattacks that exploit weaknesses in the supply chain. \nNext steps could include development of detailed notional worked examples, with sample \ncontractual language; extending the analysis beyond the focus on ICT to include weapons \nsystems or platform IT (PIT); and application to a specific mission system. xlii i ReferencesAppendix A\n[1] D. Bodeau and R. Graubart, \"Cyber Resiliency Engineering Framework,\" September 2011. [Online]. Available: http://www.mitre.org/sites/default/files/pdf/11_4436.pdf.\n[2] D. Bodeau, R. Graubart, W. Heinbockel and E. Laderman, \"Cyber Resiliency Engineering Aid The Updated Cyber Resiliency Engineering Framework and Guidance on Applying \nCyber Resiliency Technique,\" The MITRE Corporation, Bedford, MA, 2015. [3] M. Reed, J. F. Miller and P. Popick, \"Supply Chain Attack Patterns: Framework and \nCatalog,\" 2014. [Online]. Available: http://www.acq.osd.mil/se/docs/Supply-Chain-WP.pdf. [4] Office of the Under Secretary of Defense for Acquisition, Technology and Logistics \n(OUSD/AT&L), \"Department of Defense Instruction 5000.02,\" 7 January 2015. [Online]. \nAvailable: http://www.acq.osd.mil/fo/docs/500002p.pdf. [5] J. Boyens, C. Paulsen, R. Moorthy and N. Bartol, \"NIST Special Publication 800-161: \nSupply Chain Risk Management Practices for Federal Information Systems and \nOrganizations,\" April 2015. [Online]. Available: https://doi.org/10.6028/NIST.SP.800-161. [6] DoD Defense Science Board, \"DSB Task Force Report on Cyber Supply Chain,\" February \n2017. [Online]. Available: https://www.hsdl.org/?view&did=799509. [7] D. o. D. D. C. (AT&L), \"Defense Technical Information Center,\" 25 August 2016. [Online]. \nAvailable: http://www.esd.whs.mil/portals/54/documents/DD/issuances/dodi/520044p.pdf. \n[Accessed 10 July 2017]. [8] E. M. Hutchins, M. J. Cloppert and R. M. Amin, \"Intelligence-Driven Computer Network \nDefense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains,\" \n[Online]. Available: \nhttp://www.lockheedmartin.com/content/dam/lockheed/data/corporate/documents/LM-\nWhite-Paper-Intel-Driven-Defense.pdf. [9] D. Bodeau and R. Graubart, \"Characterizing Effects on the Cyber Adversary: A Vocabulary \nfor Analysis and Assessment,\" February 2014. [Online]. Available: \nhttp://www.mitre.org/publications/technical-papers/characterizing-effects-on-the-cyber-\nadversary-a-vocabulary-for. [10] ODNI, \"Cyber Threat Framework,\" [Online]. Available: \nhttps://www.dni.gov/index.php/cyber-threat-framework. [11] National Institute of Standards and Technology, \"Guide for Conducting Risk Assessments, \nNIST SP 800-30 Rev 1,\" September 2012. [Online]. Available: \nhttp://csrc.nist.gov/publications/nistpubs/800-30-rev1/sp800_30_r1.pdf. [12] Office of the DASD (DT&E), \"Guidelines for Cybersecurity DT&E, version 1.0,\" 19 April \n2013. [Online]. [13] D. Bodeau and R. Graubart, \"Cyber Prep 2.0: Motivating Organizational Cyber Strategies in \nTerms of Preparedness (MTR 150264, PR 16-0939),\" The MITRE Corporation, Bedford, \nMA, 2016. [14] Cisco TALOS , \"New Ransomeware Varient \"Nyeta\" compromises systems Worldwide,\" \n27 June 2017. [Online]. Available: http://blog.talosintelligence.com/2017/06/worldwide-\nransomware-variant.html (still under investigation). [Accessed 7 July 2017]. [15] NSA Information Assurance Directorate (IAD), \"Campus Wireless Local Area Network \nCapability Package,\" 27 April 2016. [Online]. Available: \nhttps://www.nsa.gov/resources/everyone/csfc/capability-packages/assets/files/campus-wlan-\ncp.pdf. ii [16] R. Graubart and D. Bodeau, \"The Risk Management Framework and Cyber Resiliency,\" \nThe MITRE Corporation, McLean, VA, 2016. [17] R. Ross, M. McEvilley and J. C. Oren, \"NIST SP 800-160 System Security Engineering: \nConsiderations for a Multidisplinary Approach in the Engineering of Trustworthy Secure \nSystems,\" May 2016. [Online]. Available: http://csrc.nist.gov/publications/drafts/800-\n160/sp800_160_second-draft.pdf. [Accessed 21 June 2017]. [18] J. F. Miller, \"Supply Chain Attack Framework and Attack Patterns,\" 2013. [Online]. \nAvailable: https://www.mitre.org/sites/default/files/publications/supply-chain-attack-\nframework-14-0228.pdf. [19] Joint Task Force Transformation Initiative, \"NIST Special Publication 800-53 Revision 4: \nSecurity and Privacy Controls for Federal Information Systems and Organizations,\" April \n2013. [Online]. Available: \nhttp://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r4.pdf. [20] I. Grigg, \"Triple Entry Accounting,\" 25 December 2005. [Online]. Available: \nhttp://iang.org/papers/triple_entry.html. [21] The MITRE Corporation , \"Common Attack Pattern Enumeration and Classification,\" 9 \nJanuary 2017. [Online]. Available: https://capec/mitre.org/data/. [Accessed 31 August \n2017]. [22] National Institute of Standards and Technology, \"NIST Special Publication 800-37rev1: \nGuide for Applyuing the Risk Management Framework to Federal Information Systems: A \nSecurity Life Cycle Approach,\" February 2010. [Online]. Available: \nhttp://csrc.nist.gov/publications/nistpubs/sp800-37-rev1-final.pdf. [23] NIST, Computer Security Division, Information Technology Laboratory, \"NIST Special \nPublications,\" February 2004. [Online]. Available: \nhttp://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.199.pdf. [Accessed 11 July 2017]. [24] DoD, \"DoD Program Managers Guidebook for Integrating the Cybersecurity Risk \nManagement Framework (RMF) into the System Acquisition Lifecycle, Version 1.0,\" 26 \nMay 2015. [Online]. [25] SCRM Program Management Office (PMO) Globalization Task Force (GTF) OASD(NII)-\nCIO/ODASD(CIIA), \"Key Practices and Implementation Guide for the DoD \nComprehensive National Cybersecurity Initiative 11 Supply Chain Risk management Pilot \nProgram,\" 2010. [26] National Institute of Standards and Technology, \"NIST Special Publication 800-30rl: Guide \nfor Conducting Risk Assessments,\" September 2012. [Online]. Available: \nhttp://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-30rl.pdf. [27] The Open Group, \"Open Trusted Technology Provider Standard (O-TTPS), Version 1.1,\" \nJuly 2014. [Online]. Available: https://www2.opengroup.org/ogsys/catalog/c147. [Accessed \n11 July 2017]. [28] A. Temin and S. Musman, \"A Language for Capturing Cyber Impact Effects, MTR 100344, \nPR 10-3793,\" The MITRE Corporation, Bedford, MA, 2010. [29] DoD Defense Science Board, \"Task Force Report: Resilient Military Systems and the \nAdvanced Cyber Threat,\" January 2013. [Online]. Available: \nhttp://www.acq.osd.mil/dsb/reports/ResilientMilitarySystems.CyberThreat.pdf. [30] USD(AT&L), \"Directive-type Memorandum (DTM) 17-001 Cybersecurity in the Defense \nAcquisition System,\" 11 January 2017. [Online]. Available: \nhttps://www.hsdl.org/?view&did=797977. [31] NIST, \"NIST SP 800-39, Managing Information Security Risk: Organization, Mission, and iii Information System View,\" March 2011. [Online]. Available: \nhttp://csrc.nist.gov/publications/nistpubs/800-39/SP800-39-final.pdf. iv i 13 The categories of insertion modification and substitution were created to combine information included in the goal, impact, \nthreat and vulnerabilities descriptions in the DASDE-SE paper. Analysis of Known Supply Chain Attacks Appendix B In August, 2014, the Office of the Deputy Assistant Secretary of Defense for Systems \nEngineering (DASD-SE) described 41 known supply chain attacks [3]. Subsequently, the \nCommon Attack Pattern Enumeration and Classification [22] was updated to include these 41 \nattacks. In the DASD-SE paper, each attack is characterized by: Target (hardware, software, firmware or system information)\nDescription\nVector (path followed by attacker)\nOrigin (e.g., insider, outsider)\nGoal (Disruption, Corruption, Disclosure, Destruction) \nImpact\nReferences\nThreat\nVulnerabilities exploited\nAttack Points within the Supply Chain\nApplicable Acquisition Life Cycle Phases It is important to note that the target for these 41 supply chain attacks are predominetly ICT \ncomponents. An attack within the DASD-SE paper is the successful insertion, modification or \nsubstitution13 to/of a component within the supply chain (regardless of whether or not it makes it \ninto an operational system.) In this paper, the DASD-SE attacks are referred to as attack \nsteps that are taken to complete a full cyber-attack on the end mission or system, using the \nCyber Attack life-cycle. These steps (or actions) are mapped to the stages in the cyber attack \nlifecycle described in Section 2.4, using the following definitions and rationale: Reconnaissance the adversary develops a target; Example: Gathering information \nabout components used in the end mission system\nWeaponize the attack is put in a form to be executed on the victim's \ncomputer/network;Example: An piece of software is modified during the development \nstage\nDeliverthe vulnerability is delivered to the target; Example: the modified software is \noffered and accepted as a patch\nExploit the initial attack on target is executed;Example: The modified software is on \nthe end system and ready to execute\nControlmechanisms are employed to manage the initial victims; Example: The \nadversary has a way into receive and manage the results from the successful exploit\nExecute leveraging numerous techniques, the adversary executes the plan; and \nMaintain long-term access is achieved. To better understand the adversarys objectives in using the supply chain to exploit a targeted \nnetwork and end mission system, we have analyzed the 41 defined supply chain attacks steps \n[19] by grouping them by methods used: Insertion, Substitution, or Modification. These methods ii are used by an adversary to achieve their goals working across the acquisition life cycle with the \nfocus on impacting an end mission system in the Operations and Support phase. \nThese attack method types are defined as follows: Insertion: Adding additional information, code, or functionality to an ICT module or \ncomponent which performs a new, malicious function or otherwise subverts the intended \nsystem functions. For example, adding malicious code to a software library. Most attacks \nof this
type are applicable to systems under development. Substitution: A complete replacement of a module or component (hardware, software, \nfirmware) to be integrated into the system with one that has already been tampered with \nin order to maliciously change its intended function or operation. Modification: Any change of existing design or other information that defines the system \nunder development. In most cases, the change will be to cause a degradation or weakness \nin later development or production. The intent of this analysis is to understand and characterize the adversarys goals within the \nacquisition life cycle. This analysis does not represent the frequency of actual attack steps, but \ninstead groups the 41 attack steps in relation to the acquisition lifecycle to observe trends in the \noccurrence of the attack steps and relate them to the adversarys goals. \nThe breakdown of substitution attack steps across the acquisition life cycle (Figure 6, below), \nshows that they occur in both the Engineering & Manufacturing Development (15 attack steps) \nand Production & Deployment (14 attack steps) phases nearly equally. Eleven of those attack \nsteps occur in both the Engineering and Manufacturing Development and Production and \nDeployment phases. Access to a component supplier is usually a prerequisite for performing a \nsubstitution attack step. Understanding the adversarys goal of substituting hardware in the \nEngineering & Manufacturing Development, Production & Deployment and Operations and \nSupport phases of the acquisition life cycle, means that resiliency mitigations should be focused \non hardware integrity and tracking. For an operational network, it can be assumed that some \nhardware has been compromised. Software as a substitution attack frequently occurs during the \nOperations and Support phase of the acquisition life cycle as software products are maintained.\nInsertion can be directed at software, hardware, firmware or information. The number of attack \nstepss characterized as insertion (9 attack steps) is smaller than substitution attack steps (24 \nattack steps). \nIt is important to note that many of the 41 attacks cited in the sources require some knowledge of \nthe system under development, the suppliers, the development and production environments, etc. \nIf access to information is properly controlled, adversarial reconnaissance can be curtailed. iii Operations and Support Production and Deployment Engineering and Manufacturing Development Technology Maturation and Risk Reduction Material Solution Analysis 0 2 4 6 8 10 12 14 16 Substitution Insertion Modification Figure 6. Supply Chain attack steps within the Acquisiton Lifecycle iv i Analysis of Applicable Existing Supply Chain Risk Appendix C\nManagement Guidance \nThe SCRM controls described in existing guidance and the resiliency mitigations proposed in \nthis report complement each other as discussed below. Both should be used by SSEs. Below are \nthe National Institute for Standards and Technology (NIST) documents reviewed for this task: NIST Special Publication (SP) 800-161 Supply Chain Risk Management Practices for \nFederal Information Systems and Organizations [5]. This document is a supply chain \nrisk management overlay for NIST SP 800-53 R4 [20].\nNIST SP 800-30, Revision 1, Guide for Conducting Risk Assessments [12]\nNIST SP 800-37, Revision 1, Guide for Applying the Risk Management Framework \n(RMF) to Federal Information Systems [23] \nNIST Federal Information Processing Standard (FIPS)199, Standards for Security \nCategorization of Federal Information and Information Systems, [24] When conducting a risk assessment in accordance with the DoD Program Managers Guidebook \nfor Integrating the Cybersecurity Risk Management Framework (RMF) into the System \nAcquisition Lifecycle [24], using NIST SP 800-161 and NIST SP 800-30R10R1, an SSE works \nwith their customer to assess risk at the mission and information system level. The \nrecommendations of resiliency mitigations in Section 5 of this paper will guide the SSE to \ninclude cyber resiliency as one method of risk mitigation. Table 15 below summarizes the \nactivities an SSE performs when conducting a risk assessment and the complementary activities \nperformed as part of a cyber resiliency analysis. For a discussion of how cyber resiliency relates \nto the RMF, see the MITRE white paper The Risk Management Framework and Cyber \nResiliency [17]. Table 15. Cyber Resiliency Activities Compared to Risk Management Framework Activities Risk Management Framework Activities \nfor Assessing Risk Cyber Resiliency Analysis Activities Criticality Analysis Determine Mission essential cyber resources and cyber \nresiliency objectives Analyze Threats and Known Vulnerabilities Analyze adversary capabilities, intent and targeting\nDetermine likelihood of a threat exploiting \na vulnerability Address inherent weaknesses in mission/business \nprocesses, weaknesses in information security, \narchitecture and cyber defense processes. Determine impact to system/mission Determine impact with a focus on Consequence to \nMission Accept, Mitigate, Share, Transfer or Avoid \nRisk Mitigate Adversary TTPs via cyber resiliency techniques Ensure mission and system can anticipate, withstand, \nrecover from and adapt to adverse conditions, stresses, \nattacks, or compromises on cyber resources The document Key Practices and Implementation Guide for the DoD Comprehensive National \nCybersecurity Initiative 11 Supply Chain Risk Management Pilot Program provides 32 key ii practices for managing supply chain risks throughout a system design lifecycle [26]. It focuses \non practices that enable the development and operation of systems to meet their cost, schedule \nand performance requirements within a globalized market and with active adversaries. The \naudience is system engineers, program managers, government prime contractors and \nsubcontractors and those responsible for delivery and supporting systems with supply chain \nassurance. \nWe analyzed the key practices against cyber resiliency techniques and discovered where the key \npractice supports cyber resiliency, is a part of cyber resiliency, has no overlap or is a complete \noverlap with cyber resiliency. There are four key practices that overlap with cyber resiliency \ntechniques: Table 16. Key Practices Guidance and Its Relation to Cyber Resiliency Key Practice Cyber Resiliency Technique\nKP8 Protect Critical Elements and \nProcesses Cyber resiliency technique selection driven by mission/business \nobjectives, environment architecture and threat environment KP 9 Use defensive Design Cyber resiliency technique selection driven by mission/business \nobjectives, environment architecture and threat environment KP 10 Use/Create standard \ninterfaces to increase supplier \ndiversity Part of the Diversity technique KP19 Perform Penetration \nTesting Activities in this practice are part of Coordinated Defense \nTechnique The key practices guide is a good source document for SSEs but focuses on recommendations for \nprogram managers and acquisition specialists. iii Appendix D i Summary of Cyber Resiliency Techniques and Appendix E\nApproaches Table 17 summarizes cyber resiliency techniques and the rationale for applying them (i.e., the \nobjective an organization using it expects to achieve). Table 17. Cyber Resiliency Techniques Cyber Resiliency Technique Rationale\nAdaptive Response: \nImplement nimble cyber \ncourses of action to manage \nrisks Optimize the organizations ability to respond in a timely and \nappropriate manner to adverse conditions, stresses, or attacks, thus \nmaximizing the ability to maintain mission operations, limit \nconsequences, and avoid destabilization. Analytic Monitoring: Gather, \nfuse, and analyze data on an \nongoing basis and in a \ncoordinated way to identify \npotential vulnerabilities, \nadverse conditions, stresses, \nor attacks, and damage Maximize the organizations ability to detect potential adverse \nconditions, reveal the extent of adverse conditions, stresses, or \nattacks, and identify potential or actual damage. Provide data \nneeded for cyber situational awareness. Coordinated Defense: \nManage multiple, distinct \nmechanisms in a non-\ndisruptive or complementary \nway Ensure that failure of a single defensive barrier does not expose \ncritical assets to threat exposure. Require threat events to overcome \nmultiple safeguards; in the case of adversarial events, this makes it \nmore difficult for the adversary to successfully attack critical \nresources, increasing the cost to the adversary, and raising the \nlikelihood of adversary detection. Ensure that uses of any given \ndefensive mechanism do not create adverse unintended \nconsequences by interfering with other defensive mechanisms. Deception: Mislead, confuse, \nor hide critical assets from \nthe adversary Mislead or confuse the adversary, or hide critical assets from the \nadversary, making them uncertain how to proceed, delaying the \neffect of their attack, increasing the risk to them of being discovered, \ncausing them to misdirect or waste their attack and expose their \ntradecraft prematurely. Diversity: Use heterogeneity \nto minimize common mode \nfailures, particularly attacks \nexploiting common \nvulnerabilities Limit the possibility of a collapse of critical functions due to failure of \nreplicated common components. In the case of adversarial threats, \ncause the adversary to work harder by developing malware or other \nTactics, Techniques, and Procedures (TTPs) appropriate for multiple \ntargets, increase the chance that the adversary will waste or expose \nTTPs by applying them to targets for which they are inappropriate, \nand maximize the chance that some of the defending organizations \nsystems will survive the adversarys attack. Dynamic Positioning: \nDistribute and dynamically \nrelocate functionality or \nassets Increase the ability of an organization to rapidly recover from non-\nadversarial events (e.g., fires). Impede an adversarys ability to \nlocate, eliminate or corrupt mission/business assets, and cause the \nadversary to spend more time and effort to find the organizations \ncritical assets, thereby increasing the chance of the adversary \nrevealing their actions and tradecraft prematurely. ii Dynamic Representation: \nConstruct and maintain \ncurrent representations of \nmission posture in light of \ncyber events and cyber \ncourses of action Support situational awareness, enhance understanding \ndependencies among cyber and non-cyber resources, reveal \npatterns/trends in adversary behavior; and validate the realism of \ncourses of action. Non-Persistence: Generate \nand retain resources as \nneeded or for a limited time Reduce exposure to corruption,
modification or compromise. \nProvide a means of curtailing an adversarys advance and potentially \nexpunging an adversarys foothold from in the system. Privilege Restriction: Restrict \nprivileges required to use \ncyber resources, and \nprivileges assigned to users \nand cyber entities, based on \nthe type(s) and degree(s) of \ncriticality Limit the impact and probability that unintended actions by \nauthorized individuals will compromise information or services. \nImpede the adversary by requiring them to invest more time and \neffort in obtaining credentials; curtail the adversarys ability to take \nfull advantage of credentials that they have obtained. Realignment: Align cyber \nresources with core aspects \nof mission/business \nfunctions Minimize the connections between mission critical and non-critical \nservices, thus reducing likelihood that a failure of non-critical \nservices will impact mission critical services. Reduce the attack \nsurface of the defending organization by minimizing the chance that \nnon-mission/business functions could be used as an attack vector. Redundancy: Provide \nmultiple protected instances \nof critical resources Reduce the consequences of loss of information or services; facilitate \nrecovery from the effects of an adverse cyber event; limit the time \nduring which critical services are denied or limited. Segmentation/Isolation: \nDefine and separate (logically \nor physically) components \nbased on criticality and \ntrustworthiness Contain adversary activities and non-adversarial stresses (e.g., fires) \nto the enclave/segment in which they have established a presence; \nfor adversarial cyber activities, this limits the number of possible \ntargets to which malware can easily be propagated. Substantiated Integrity: \nAscertain whether critical \nservices, information stores, \ninformation streams, and \ncomponents have been \ncorrupted Facilitate determination of correct results in case of conflicts \nbetween diverse services or inputs. Detect attempts by an adversary \nto deliver compromised data, software, or hardware, as well as \nsuccessful modification or fabrication; provide limited capabilities for \nrepair. Unpredictability: Make \nchanges randomly or \nunpredictable Increase the adversarys uncertainty regarding the cyber defenses \nthat they may encounter, thus making it more difficult for them to \nascertain the appropriate course of action. Cyber resiliency approaches are specific ways to implement cyber resiliency techniques. For \nthe above resiliency techniques, the Cyber Resiliency Engineering Framework (CREF) [2] \ndefines 44 representative approaches to implementing those techniques. Table 18 provides the \nCREF definitions for selected resiliency approaches. Table 18. Definitions of Cyber Resiliency Approaches iii Cyber \nResiliency \nTechnique Cyber Resiliency \nApproach Definition Adaptive \nResponse Dynamic \nReconfiguration Make changes to an element or component while it continues \noperating. Dynamic \nResource \nAllocation Change the allocation of resources to tasks or functions \nwithout terminating critical functions or processes. Adaptive \nManagement Change how defensive mechanisms are used based on changes \nin the operational environment as well as changes in the threat \nenvironment. Analytic \nMonitoring Monitoring and \nDamage \nAssessment Monitor and analyze behavior and characteristics of \ncomponents and resources to look for indicators of adversary \nactivity, detect and assess damage, and watch for adversary \nactivities during recovery and evolution. Sensor Fusion \nand Analysis Fuse and analyze monitoring data and preliminary analysis \nresults from different components, together with externally \nprovided threat intelligence. Malware and \nForensic Analysis Analyze malware and other artifacts left behind by adversary \nactivities. Coordinated \nDefense Technical \nDefense-in-\nDepth Use multiple protective mechanisms at different architectural \nlayers or locations. Coordination \nand Consistency \nAnalysis Apply processes, supported by analytic tools, to ensure that \ndefenses are applied and cyber courses of action are defined \nand executed in a coordinated, consistent way that minimizes \ninterference. Deception Obfuscation Hide, transform, or otherwise obfuscate information from the \nadversary. Dissimulation/ \nDisinformation Provide deliberately misleading information to adversaries. Misdirection/ \nSimulation Maintain deception resources or environments and direct \nadversary activities there. Diversity Architectural \nDiversity Use multiple sets of technical standards, different technologies, \nand different architectural patterns. Design Diversity Use different designs to meet the same requirements or \nprovide equivalent functionality. Synthetic \nDiversity Transform implementations to produce a variety of instances. Information \nDiversity Provide information from different sources or transform \ninformation in different ways. Command, \nControl, and \nCommunication \nPath Diversity Provide multiple paths, with demonstrable degrees of \nindependence, for information to flow between components. Supply Chain \nDiversity Use multiple, demonstrably independent, supply chains for \ncritical components. iv Dynamic \nPositioning Functional \nRelocation of \nSensors Relocate sensors, or reallocate responsibility for specific \nsensing tasks, to look for indicators of adversary activity, and to \nwatch for adversary activities during recovery and evolution. Functional \nRelocation of \nCyber Assets Change the location of assets that provide functionality (e.g., \nservices, applications) or information (e.g., data stores), either \nby moving the assets or by transferring functional \nresponsibility. Asset Mobility Physically relocate physical assets (e.g., platforms or vehicles, \nmobile computing devices). Distributed \nFunctionality Distribute functionality (e.g., processing, storage, and \ncommunications) across multiple components. Dynamic \nRepresentation Dynamic \nMapping & \nProfiling Maintain current information about resources, their status, and \ntheir connectivity. Dynamic Threat \nModeling Maintain current information about threat activities and \ncharacteristics (e.g., observables, indicators, TTPs). Mission \nDependency & \nStatus \nVisualization Maintain current information about mission dependencies on \nresources, and the status of those resources with respect to \nthreats. Non-Persistent \nInformation Refresh information periodically, or generate information on \ndemand, and delete the information when no longer needed. Non-\nPersistence Non-Persistent \nInformation Refresh information periodically, or generate information on \ndemand, and delete the information when no longer needed. Non-Persistent \nServices Refresh services periodically, or generate services on demand \nand terminate services after completion of a request. Non-Persistent \nConnectivity Establish connections on demand, and terminate connections \nafter completion of a request or after a period of non-use. Privilege \nRestriction Privilege \nManagement Define, assign, and maintain privileges associated with end \nusers and cyber entities, based on established trust criteria, \nconsistent with principles of least privilege. Privilege-Based \nUsage \nRestrictions Define, assign, maintain and apply usage restrictions on cyber \nresources based on mission criticality and other attributes. Dynamic \nPrivileges Elevate or deprecate privileges assigned to a user, process, or \nservice based on transient or contextual factors. Realignment Purposing Ensure cyber resources are used consistent with critical mission \npurposes. Offloading/ \nOutsourcing Offload supportive but non-essential functions to a service \nprovider that is better able to support the functions. Restriction Remove or disable unneeded risky functionality or connectivity, \nor add mechanisms to reduce the risk. Replacement Replace risky implementations with less-risky implementations. v Redundancy Protected \nBackup and \nRestore Back up information and software (including configuration \ndata) in a way that protects its confidentiality, integrity, and \nauthenticity, and to restore it in case of disruption or \ndestruction. Surplus Capacity Maintain extra capacity for information storage, processing, \nand/or communications. Replication Duplicate information and/or functionality in multiple locations \nand keep it synchronized. Segmentation Predefined \nSegmentation Define and separate components on the basis of criticality and \ntrustworthiness. Dynamic \nSegmentation/ \nIsolation Change the definition of enclaves or protected segments, or \nisolate resources, while minimizing operational disruption. Substantiated \nIntegrity Integrity/Quality \nChecks Apply and validate checks of the integrity or quality of \ninformation, components, or services. Provenance \nTracking Identify and track the provenance of data, software, and/or \nhardware elements. Behavior \nValidation Validate the behavior of a system, service, or device against \ndefined or emergent criteria. Unpredictabilit\ny Temporal \nUnpredictability Change behavior or state at times that are determined \nrandomly or by complex functions. Contextual \nUnpredictability Change behavior or state in ways that are determined \nrandomly or by complex functions. vi vii Appendix F i Cyber Resiliency Mitigations Applied to the Appendix G\nAcquisition Lifecycle Based on the effects of cyber resiliency techniques in the cyber attack lifecycle (table 6 of the \nEngineering Aid) and the cyber resiliency approaches and their specific effects (tables 7-20 of the \nEngineering Aid [2]; Table H-6 of [18]) we developed the following tables. It is important to note that because we are applying the CAL to an adversary using the entire \nacquisition lifecycle with the objective of exploiting the end mission system some of the \napproaches had slightly different effects than described in the tables referenced because those \nreferences assumed a single environment rather than a sequential environment such as acquisition \nlife cycle. These tables are a starting point and should be tailored based on the specific \nenvironments and concerns. ii iii Table 19. Cyber Resiliency Mitigations for Materiel Solutions Analysis Phase A\nc\nq\nu\ni\ns\ni\nt\ni\no\nn \nL\ni\nf\ne\nc\ny\nc\nl\ne Resiliency Mitigations Adversary Goals (per the \nCAL) Defender \nGoals in O&S A\nc\nq\nu\ni\nr\ne \nI\nn\nf\no D\ne\nv\ne\nl\no\np \nt\no\no\nl\ns D\ne\nl\ni\nv\ne\nr \nA\nt\nt\na\nc\nk I\nn\ni\nt\ni\na\nl \nE\nx\np\nl\no\ni\nt Co\nntr\nolli\nng \natt\nac\nk Ex\nec\nut\nin\ng \nAt\nta\nck M\nai\nnt\nai\nn \nPr\nes\ne\nn\nce R\ne\nd\nu\nc\ne \na\nt\nt\na\nc\nk\ns L\ni\nm\ni\nt \na\nt\nt\na\nc\nk G\na\ni\nn\n \nS\nh\na\nr\ne \nI\nn\nf\no R\ne\nc\no\nv\ne\nr M\na\nt\ne\nr\ni\ne\nl \nS\no\nl Deception\nObfuscation make identifying and targeting high value information resources difficult x x\nDissimulation/disinformation provide the adversary with false information so the attacks \ndeveloped are ineffective in Operations and Support x x x Misdirection reduce attacks by wasting adversary resources x x x x\nNon-Persistence\nNon-Persistent Information Reduce availability of information on system needs and development x x x\nNon-Persistent Services Reduce the chance the adversary has corrupted services in the \nenvironment to gain information x x x Non-Persistent Connectivity reduce means to get information on system needs and \ndevelopments x x x iv u\nt\ni\no\nn\ns \nA\nn\na\nl\ny\ns\ni\ns Privilege Restriction\nPrivilege Management reduce the number of resources accessible with individual credentials \ncausing the adversary to invest more time and effort x x x Privilege-Based Usage Restrictions cause the adversary to expend more time and effort to get \ncredentials x x x Dynamic Privileges increase the difficulty for the adversary in gaining credentials x
x x\nRealignment \nRestriction reduce the paths (via risky functionality or connectivity) used by adversaries x x x\nSegmentation/Isolation\nPredefined Segmentation reduces adversarys ability to exfiltrate and the amount of data that \ncan be exfiltrated limiting the amount of information they can gain x x x Dynamic Segmentation/Isolation contains adversary activities (e.g., the insertion of malware in \nrunning processes and control of compromised processes) limiting how they can gain information x x x Unpredictability \nTemporal Unpredictability combine with Dynamic Privileges increase the difficulty for the \nadversary in gaining credentials x x x v Table 20. Cyber Resiliency Mitigations for Technology Maturity and Risk Reduction Phase A\nc\nq\nu\ni\ns\ni\nt\ni\no\nn \nL\ni\nf\ne\nc\ny\nc\nl\ne Resiliency Mitigations Adversary Goals (per the \nCAL) Defender \nGoals in O&S Ac\nqu\nire \nInf\no De\nvel\nop \nto\nols De\nliv\ner \nAt\nta\nck Ini\ntia\nl Ex\npl\noit Co\nntr\nolli\nng \natt\nac\nk Ex\nec\nut\nin\ng \nAt\nta\nck M\nai\nnt\nai\nn \nPr\nes\ne\nn\nce Re\ndu\nce \natt\nac\nks Li\nmi\nt att\nac\nk Ga\nin/\nSh\nar\ne Inf\no Re\nco\nve\nr T\ne\nc\nh\nn\no\nl\no\ng\ny Deception \nObfuscation make identifying and targeting high value information resources difficult x x\nDissimulation/disinformation provide the adversary with false information so the attacks \ndeveloped are ineffective in Operations and Support x x x Misdirection reduce attacks by wasting adversary resources x x x x\nNon-Persistence\nNon-Persistent Information limit the adversarys ability to gain information by limiting the time the \ninformation is available x x x Non-Persistent Services limit the amount of time the adversary can exploit a service x x x\nNon-Persistent Connectivity limit the amount of time paths into the environment are available x x x vi D\ne\nv\ne\nl\no\np\nm\ne\nn\nt Privilege Restriction \nPrivilege Management reduce the number of resources accessible with individual resources \ncausing the adversary to invest more time and effort x x x Privilege-Based Usage Restrictions cause adversary to use more time and effort to get credentials x x x\nDynamic Privileges increase the difficulty for the adversary in gaining credentials x x x\nRealignment\nRestriction reduce the paths (via risky functionality or connectivity) used by adversaries x x x\nSegmentation\nPredefined Segmentation reduces adversarys ability to exfiltrate and the amount of data that can \nbe exfiltrated limiting the amount of information they can gain x x x Dynamic Segmentation/Isolation contains adversary activities (e.g., the insertion of malware in \nrunning processes and control of compromised processes) limiting how they can gain information x x x Unpredictability\nTemporal Unpredictability combine with Dynamic Privileges increase the difficulty for the \nadversary in gaining credentials x x x vii Table 21. Cyber Resiliency Mitigations for Engineering and Manufacturing Development Phase A\nc\nq\nu\ni\ns\ni\nt\ni\no\nn \nL\ni\nf\ne\nc\ny\nc\nl\ne Resiliency Mitigations Adversary Goals (per the \nCAL) Defender \nGoals in O&S A\nc\nq\nui\nre \nIn\nfo D\ne\nv\nel\no\np \nto\nol\ns D\nel\niv\ner \nAt\nta\nck In\niti\nal \nEx\npl\noi\nt C\no\nnt\nro\nlli\nn\ng \nat\nta\nck Ex\nec\nut\nin\ng \nAt\nta\nck M\nai\nnt\nai\nn \nPr\nes\ne\nn\nce R\ne\nd\nu\nce \nat\nta\nck\ns Li\nm\nit \nat\nta\nck G\nai\nn/\nS\nh\nar\ne \nIn\nfo R\nec\no\nv\ner E\nn\ng\ni\nn\ne\ne\nr\ni Analytic Monitoring \nSensor Fusion and Analysis exposes adversary activity allowing defenders to gain information \nabout the adversary attacks and share them with later Acquisition lifecycle phases x x x x Malware and Forensic Analysis analyze adversary activities and artifacts left behind x x x x x\nDeception\nDissimulation/disinformation provide the adversary with false information so the attacks \ndeveloped are detected in this phase or the next, or are less effective in O&S x x x x x x Misdirection diverting attacks to a honeynet environment, enables defenders to analyze attack \nTTPs for future defense, eliminates attacks in this phase before they are passed to the next x x x x x x x x x viii n\ng \na\nn\nd \nM\na\nn\nu\nf\na\nc\nt\nu\nr\ni\nn\ng \nD\ne\nv\ne\nl\no\np\nm\ne\nn\nt Acquisition lifecycle, and provides information about adversary targets\nDiversity\nArchitectural Diversity/Heterogeneity adversary must use more time and effort to develop tools \nthat work across diverse implementations and initial exploit may not be as effective x x x x x Design Diversity/Heterogeneity adversary must use more time and effort to develop tools that \nwork across diverse implementations and initial exploit may not be as effective x x x x x Supply chain diversity adversary must use more time and effort to compromise more supply \nchains or accept that only be a subset of target components will be compromised x x x x Non-persistence\nNon-Persistent Information limit the adversarys ability to deliver an attack, decrease the \nprobability of the initial exploit being successful and reduce the adversarys ability to control \nmalware by limiting the time information is available x x x x x x Non-Persistent Services limit the adversarys ability to deliver an attack, decrease the probability \nof the initial exploit being successful and reduce the adversarys ability to control malware by \nlimiting the amount of time the adversary can exploit a service x x x x x x Non-Persistent Connectivity limit the adversarys ability to deliver an attack, decrease the \nprobability of the initial exploit being successful and reduce the adversarys ability to control \nmalware by limiting the amount of time paths into the environment are available x x x x x x Privilege Restriction\nPrivilege Management cause the adversary to expend more time and effort to get credentials to \ncontrol the malware. x x x Privilege-Based Usage Restrictions cause the adversary to expend more time and effort to get \ncredentials to control the malware. The initial exploit may also fail due to lack of credentials. x x x x Dynamic Privileges increase the difficulty for the adversary in gaining credentials x x x x\nRedundancy\nProtected Backup and Restore reduce threat of backups being corrupted by adversary and used as \na way into the environment or to maintain a presence x x x x Segmentation\nPredefined Segmentation reduces adversarys ability to deliver and propagate and control \nmalware x x x x x Dynamic Segmentation/Isolation contains the adversarys activities (such as the insertion of \nmalware in running processes and control of compromised processes) limiting deliver and x x x x x ix propagate and control malware\nSubstantiated Integrity\nIntegrity Quality checks detect the presence of compromised components and remove them from \nthe environment reducing the number of exploits and possibility of information exfiltration x x x x Provenance Tracking detect the adversarys attempts to deliver compromised components and \nremove them from the environment x x x x Behavior Validation Identify the presence of compromised component in the environment x x x x x\nUnpredictability\nTemporal Unpredictability combined with non-persistence increase the difficulty for the adversary \nin to deliver malware, initiate the exploit and gain enough control to impact O&S x x x Temporal Unpredictability combine with Dynamic Privileges increase the difficulty for the \nadversary in gaining credentials x x x x x Contextual unpredictability combined with integrity quality checks make it more difficult for the \nadversary to emulate components and get compromised components into fielded system x x x Table 22 . Cyber Resiliency Mitigations for Production and Deployment Phase A\nc\nq\nu\ni\ns\ni\nt\ni\no\nn \nL\ni\nf\ne\nc\ny\nc\nl\ne Resiliency Mitigations Adversary Goals (per the \nCAL) Defender \nGoals in O&S A\nc\nq\nui\nre \nIn\nfo D\ne\nv\nel\no\np \nto\nol\ns D\nel\niv\ner \nAt\nta\nck In\niti\nal \nEx\npl\noi\nt C\no\nnt\nro\nlli\nn\ng \nat\nta\nck Ex\nec\nut\nin\ng \nAt\nta\nck M\nai\nnt\nai\nn \nPr\nes\ne\nn\nce R\ne\nd\nu\nce \nat\nta\nck\ns Li\nm\nit \nat\nta\nck G\nai\nn/\nS\nh\nar\ne \nIn\nfo R\nec\no\nv\ner P\nr\no\nd\nu\nc\nt\ni\no Analytic Monitoring\nMonitoring and Damage Assessment Defenders obtain indications and warnings of adversary \nactivities to share later in the Acquisition Lifecycle x x x x Sensor Fusion and analysis exposes adversary activity allowing defenders to gain information \nabout the adversary attacks and share them with later Acquisition lifecycle phases x x x Malware and Forensic Analysis provide the defenders with the adversarys TTPs and capabilities x x x x x\nCoordinated Defense \nTechnical Defense-in-Depth degrades the attackers ability to initiate, control, execute or maintain \nattacks because they must develop attacks against multiple defensive technologies deployed x x x x x x x xi n \na\nn\nd \nD\ne\np\nl\no\ny\nm\ne\nn\nt concurrently\nCoordination and Consistency Analysis reduce the attackers ability to use unintended \nconsequences or unforeseen dependences to disruptions to initiate exploits x x x x x Deception\nDissimulation/disinformation provide the adversary with false information so the attacks \ndeveloped are ineffective in O&S x x x x x x Misdirection diverting attacks to a honeynet environment, enables defenders to analyze attack \nTTPs for future defense, eliminates attacks in this phase before they are passed to the next \nAcquisition lifecycle, and provides information about adversary targets x x x x x x x x Diversity\nArchitectural Diversity/Heterogeneity adversary must use more time and effort to develop tools \nthat work across diverse implementations and initial exploit may not be as effective x x x x x x x Design Diversity/Heterogeneity adversary must use more time and effort to develop tools that \nwork across diverse implementations and initial exploit may not be as effective x x x x x x x Command, Control and Communications Path Diversity increase the defenders ability to remove \nattackers by using uncompromised communications channels once defenders become aware of \nexploit x x Supply chain diversity adversary must use more time and effort to compromise more supply \nchains or accept that there will only be a subset of target components compromised x x x Dynamic Positioning\nFunctional Relocation of Sensors increase the likelihood of detecting adversary by tailoring sensor \nlocation this also makes it harder for the adversary to maintain their presence x x x x x Distributed Functionality increase the number of elements the adversary must compromise to \ndeny or corrupt functionality x x x Dynamic Representation \nDynamic Mapping and Profiling identify software and components that do not conform to policy \nrequirements or that are behaving in unexpected ways x x x Dynamic Threat Modeling reveal patterns and trends
in adversary behaviors to share with O&S \nphase x x x Mission Dependency and Status Visualization identify consequences of adversary execution to \nshare with O&S phase x x Non-persistence xii Non-Persistent Information limit the adversarys presence from delivery through maintenance by \nlimiting the time information is available x x x x x x x Non-Persistent Services limit the adversarys presence from delivery through maintenance by \nlimiting the time the adversary can exploit a service x x x x x x x Non-Persistent Connectivity limit the adversarys presence from delivery through maintenance by \nlimiting the time paths into the environment are available x x x x x x x Privilege Restriction\nPrivilege Management cause the adversary to expend more time and effort to get credentials to \ndeliver, initiate, control and execute the attack as well as maintain their presence x x x x x x x Privilege-Based Usage Restrictions cause the adversary to expend more time and effort to get \ncredentials to do anything in the environment x x x x x x x Dynamic Privileges increase the difficulty for the adversary in gaining credentials x x x x x x\nRedundancy\nProtected Backup and Restore reduce threat of backups being corrupted x x\nSegmentation\nPredefined Segmentation reduces adversarys ability to initiate exploit, control the malware, \nexecute attacks and maintain their presence x x x x x Dynamic Segmentation/Isolation contains the adversarys activities (such as the insertion of \nmalware in running processes and control of compromised processes) limiting the adversarys ability \nto initiate exploit, control the malware, execute attacks and maintain their presence x x x x x Substantiated Integrity\nIntegrity Quality checks detect the presence of compromised components and remove them from \nthe environment reducing the number of exploits and possibility of information exfiltration x x Provenance Tracking detect the adversarys attempts to deliver compromised components and \nremove them from the environment x x Behavior Validation Identify the presence of compromised component in the environment x x x x x x\nUnpredictability\nTemporal Unpredictability combined with non-persistence increase the difficulty for the adversary \nin to deliver malware, initiate the exploit and gain enough control to impact O&S x x x x x x x Temporal Unpredictability combine with Dynamic Privileges increase the difficulty for the \nadversary in gaining credentials x x x x x x x Contextual unpredictability combined with integrity quality checks make it more difficult for the x x x xiii adversary to emulate components and get compromised components into fielded system xiv Table 23. Cyber Resiliency Mitigations for Operations and Support Phase A\nc\nq\nu\ni\ns\ni\nt\ni\no\nn \nL\ni\nf\ne\nc\ny\nc\nl\ne Resiliency Mitigations Adversary Goals (per the \nCAL) Defender \nGoals in O&S A\nc\nq\nu\ni\nr\ne \nI\nn\nf\no D\ne\nv\ne\nl\no\np \nT\no\no\nl\ns D\ne\nl\ni\nv\ne\nr \nA\nt\nt\na\nc\nk I\nn\ni\nt\ni\na\nl \nE\nx\np\nl\no\ni\nt C\no\nn\nt\nr\no\nl \nA\nt\nt\na\nc\nk E\nx\ne\nc\nu\nt\ni\nn\ng \nA\nt\nt\na\nc\nk M\na\ni\nn\nt\na\ni\nn \nP\nr\ne\ns\ne\nn\nc\ne R\ne\nd\nu\nc\ne \na\nt\nt\na\nc\nk\ns L\ni\nm\ni\nt \nA\nt\nt\na\nc\nk G\na\ni\nn\n \nS\nh\na\nr\ne \nI\nn\nf\no R\ne\nc\no\nv\ne\nr O\np\ne\nr\na\nt\ni\no\nn\ns Adaptive Response\nDynamic Reconfiguration making configuration changes during operations makes it harder for \nthe adversary to control malware limiting the success of attacks x x x x x Dynamic Resource Allocation changes the resources available for the adversary to exploit x x x x x\nAdaptive Management changing how defensive mechanisms are used based on changes in the \noperational environment or threat environment forces the adversary to continue adapting to \nchanges in the environment x x x x x Analytic Monitoring\nMonitoring and Damage Assessment Defenders obtain indications and warnings of adversary \nactivities to share x x x xv a\nn\nd \nS\nu\np\np\no\nr\nt Sensor Fusion and analysis exposes adversary activity allowing defenders to gain information \nabout the adversary attacks x x x Malware and Forensic Analysis provide the defenders with the adversarys TTPs and capabilities x x x\nCoordinated Defense\nTechnical Defense-in-Depth degrades the attackers ability to initiate, control, execute or \nmaintain attacks because they must develop attacks against multiple defensive technologies \ndeployed concurrently x x x x x Coordination and Consistency Analysis reduce the attackers ability to use unintended \nconsequences or unforeseen dependences to disruptions to initiate exploits x x x x x Diversity\nArchitectural Diversity/Heterogeneity adversary must use more time and effort to develop tools \nthat work across diverse implementations attacks may not be as effective x x x Design Diversity/Heterogeneity adversary must use more time and effort to develop tools that \nwork across diverse implementations and attacks may not be as effective x x x Command, Control and Communications Path Diversity increase the defenders ability to \nremove attackers by using uncompromised communications channels once they become aware of \nexploit x x x Supply chain diversity adversary must use more time and effort to compromise more supply \nchains or accept that there will only be a subset of target components compromised x x Dynamic Positioning\nFunctional Relocation of Sensors increase the likelihood of detecting adversary by tailoring \nsensor location this makes it harder for the adversary to maintain their presence x x x x x Distributed Functionality increase the number of elements the adversary must compromise to \ndeny or corrupt functionality x x x x Dynamic Representation\nDynamic Mapping and Profiling identify software and components that do not conform to policy \nrequirements or that are behaving in unexpected ways x x x Dynamic Threat Modeling reveal patterns and trends in adversary behaviors x x\nMission Dependency and Status Visualization identify consequences of adversary execution x x\nNon-persistence\nNon-Persistent Information limit the adversarys presence throughout the CAL by limiting the \ntime information is available x x x x x x xvi Non-Persistent Services limit the adversarys presence throughout the CAL by limiting the time \nthe adversary can exploit a service x x x x x Non-Persistent Connectivity limit the adversarys presence throughout the CAL by limiting the \ntime paths into the environment are available x x x x Privilege Restriction\nPrivilege Management cause the adversary to expend more time and effort to get credentials to \ncontrol and execute the attack as well as maintain their presence x x x x x Privilege-Based Usage Restrictions cause the adversary to expend more time and effort to get \ncredentials x x x x Dynamic Privileges increase the difficulty for the adversary in gaining credentials x x x x\nRedundancy\nProtected Backup and Restore reduce threat of backups being corrupted x x x\nSegmentation\nPredefined Segmentation reduces adversarys ability to control the malware, execute attacks \nand maintain their presence x x x x Dynamic Segmentation/Isolation contains the adversarys activities (such as the manipulation of \nmalware in running processes and control of compromised processes) limiting the adversarys \nability to control the malware, execute attacks and maintain their presence x x x x x Substantiated Integrity \nIntegrity Quality checks detect the presence of compromised components and remove them \nfrom the environment reducing the number of exploits and possibility of information exfiltration x x x Provenance Tracking detect the adversarys attempts to deliver compromised components and \nremove them from the environment x x x x Behavior Validation Identify the presence of compromised component in the environment x x x x\nUnpredictability\nTemporal Unpredictability combined with non-persistence increase the difficulty for the \nadversary in to gain control of the fielded system x x x x Temporal Unpredictability combine with Dynamic Privileges increase the difficulty for the \nadversary in gaining credentials x x x x Contextual unpredictability combined with integrity quality checks make it more difficult for the \nadversary to emulate components and get compromised components into fielded system x x x x x i Abbreviations and Acronyms Appendix H AMT Active Management System\nBIOS Basic Input Output System\nC2 Command and Control\nCAL\nCAPEC Cyber Attack Lifecycle\nCommon Attack Pattern Enumeration and Classification CDD Capability Development Document\nCIA Confidentiality, Integrity and Availability\nCOTS Computer off-the-shelf\nCP Capability Package\nCREF Cyber Resiliency Engineering Framework\nCSfC Commercial Solutions for Classified\nCTF Cyber Threat Framework\nDASD-SE Deputy Assistant Secretary of Defense/Systems Engineering\nDIMFUI Degradation, Interruption, Modification, Usurption and Interception\nDLL Dynamic-Link Library\nDoD Department of Defense\nDSB Defense Science Board\nDT&E Developmental Test and Evaluation\nEAP Extensible Authentication Protocol\nFIPS Federal Information Processing Standard\nFRD Functional Requirements Document\nICD Initial Capabilities Document\nICT Information and Communications Technology\nIDS Intrusion Detections System\nIEC International Electrotechnical Commission \nIPS Intrusion Prevention System\nISO International Organization for Standards\nITIL Information Technology Infrastructure Library\nKPP Key Performance Parameters\nKSA Key System Attributes\nLAN Local Area Network ii LMS Local Manageability Service\nNIST National Institute for Standards and Technology\nOS Operating System\nO-TTPS Open Trusted Technology Provider Standard\nPIT Platform IT\nPOA&M Plan of Action and Milestones\nPOET Political, Operational, Economic and Technical\nRMF Risk Management Framework\nSCRM Supply Chain Risk Management\nSDN Software Defined Network\nSOA Service Oriented Architecture\nSOW Statement of Work\nSSE System Security Engineer\nTMRR Technology Maturation and Risk Reduction\nTTP Tactics Techniques and Procedures\nUEFI Unified Extensible Firmware Interface\nV&V Verification and Validation\nVM Virtual Machine\nVPN Virtual Private Network \nWLAN Wireless LAN _GoBack\n _Toc214668640\n _Toc214701175\n _Toc489307658\n _Toc508022099\n _Toc489307659\n _Ref494109296\n _Toc508022100\n _Toc489307660\n _Toc508022101\n _Toc489307661\n _Toc508022102\n _Ref494109287\n _Toc489307662\n _Toc508022103\n _Ref485190063\n _Toc494715822\n _Toc489307663\n _Ref494270364\n _Ref494270380\n _Ref494713736\n _Toc508022104\n _Hlk493164432\n _Ref485191486\n _Toc494715823\n _Toc489307664\n _Ref494110271\n _Toc508022105\n _Toc489307665\n _Toc508022106\n _Toc489307666\n _Ref494109840\n _Toc508022107\n _Ref494095461\n _Toc494715824\n _Ref486599519\n _Ref485188797\n _Ref494109771\n _Toc489308436\n _Toc508029584\n _Ref494109761\n _Toc489308437\n _Ref494713803\n _Toc508029585\n _Toc489307667\n _Toc508022108\n _Toc489307668\n _Toc508022109\n _Ref488733330\n _Toc489307669\n _Ref494109310\n _Ref494109829\n _Ref494110260\n _Ref494110279\n _Toc508022110\n _Ref485824394\n _Ref485824360\n _Toc494715825\n _Ref486597368\n _Toc494715826\n _Toc489307670\n _Ref494109320\n _Ref494109389\n _Ref494109850\n _Ref494111181\n _Toc508022111\n _Toc489307671\n _Toc508022112\n _Toc489307672\n _Ref494110230\n _Toc508022113\n _Toc489307673\n _Toc508022114\n _Toc489307674\n _Ref494110238\n _Toc508022115\n _Toc489307675\n _Toc508022116\n _Toc489307676\n _Toc508022117\n _Toc489307677\n _Toc508022118\n _Toc489307678\n _Toc508022119\n _Toc489307679\n _Toc508022120\n _Toc487006017\n _Toc487198284\n _Toc489307680\n _Ref494109404\n _Ref494110245\n _Toc508022121\n _Toc489307681\n _Toc508022122\n _Ref494110759\n _Toc508029586\n _Ref494110794\n _Toc508029587\n _Ref494110803\n _Toc508029588\n _Toc493668889\n _Toc493672188\n _Toc493668896\n _Toc493672195\n _Toc493668907\n _Toc493672206\n _Toc493668911\n _Toc493672210\n _Toc508022123\n _Ref494110815\n _Toc508029589\n _Ref494110825\n _Toc508029590\n _Ref494110832\n _Toc508029591\n _Toc493668913\n _Toc493672212\n _Toc493668915\n _Toc493672214\n _Toc493668918\n _Toc493672217\n _Toc493668919\n
_Toc493672218\n _Toc493668920\n _Toc493672219\n _Toc493668925\n _Toc493672224\n _Toc489307683\n _Toc508022124\n _Ref494112850\n _Toc508029592\n _Ref494112931\n _Toc508029593\n _Toc508029594\n _Toc493668927\n _Toc493672226\n _Toc493668930\n _Toc493672229\n _Toc493668933\n _Toc493672232\n _Toc493668936\n _Toc493672235\n _Toc493668937\n _Toc493672236\n _Toc489307684\n _Toc508022125\n _Toc508029595\n _Toc508029596\n _Toc508029597\n _Toc493672240\n _Toc493672241\n _Toc493672243\n _Toc493672245\n _Toc493672250\n _Toc493672251\n _Toc493672252\n _Toc487198290\n _Toc487198307\n _Toc487198308\n _Toc489307685\n _Ref494109414\n _Toc508022126\n _Toc489307686\n _Toc508022127\n _Toc489307687\n _Ref494713558\n _Toc508022128\n _Ref494110974\n _Toc494715827\n _Ref494109138\n _Toc489307688\n _Toc508022129\n _Toc508029598\n _Toc488156418\n _Toc488156419\n _Toc488156420\n _Toc488156421\n _Toc488156422\n _Toc488156423\n _Toc488156424\n _Toc488156425\n _Toc488156426\n _Toc488156427\n _Toc488156428\n _Toc488156429\n _Toc488156430\n _Toc508029599\n _Toc489307689\n _Ref494109987\n _Ref494110019\n _Ref494110194\n _Ref494110663\n _Toc508022130\n _Toc508029600\n _Toc508029601\n _Ref492971851\n _Ref494110878\n _Toc489307690\n _Ref494109362\n _Toc508022131\n _Ref494110888\n _Toc489308438\n _Toc508029602\n _Toc489308439\n _Ref494110898\n _Toc508029603\n _Toc489308440\n _Toc508029604\n _Toc489308441\n _Toc508029605\n _Toc489308442\n _Toc508029606\n _Toc489307691\n _Toc508022132\n _Toc468868734\n _Toc468869317 ",
    "text": " Operational Integration of Required \nTime of Arrival with Time-Based \nManagement: Concept of Operations \nand Human-in-the-Loop Simulation \nResults Roland Sgorcea\nJohn Timberlake\nSteven Osborne\nWilliam Symionow\nDr. Gabriele Enea May 2018 MTR180031 MITRE TECHNICAL REPORT Approved for Public Release; Distribution \nUnlimited. Case Number 18-0770 \nAll rights reserved. McLean, VA Center for Advanced Aviation System Development ii Abstract\nThis paper presents the concept of operations (ConOps) and the results of a Human-In-The-Loop \n(HITL) simulation for the Time Based Management Required Time of Arrival (TBM-RTA) \nconcept. This concept leverages the Required Time of Arrival capability that is available in many \nFlight Management Systems (FMS). Under the TBM-RTA concept, controllers can issue \nequipped aircraft an RTA to a fix, which pilots enter into the FMS. The aircrafts speed is then \nadjusted by the FMS such that it meets the RTA. Additionally, if the RTA time is found to \nexceed the speed envelope of the aircraft, the concept included using a Path Stretch Advisory \nfunction which allowed controllers to assign an automation-provided Path Stretch solution along \nwith an RTA. The Path Stretch maneuver reroutes the aircraft off the current route to a specified \npoint, which is represented as a radial and nautical miles distance from the rejoin fix. Results \nfrom the evaluation showed that the concept is operationally acceptable for pilots and controllers. \nMoreover, RTA-operated flights showed lower cancellation rates and higher delivery accuracy at \nthe meter point with smaller speed adjustments when compared to non-RTA flights. Based on \nthese results, MITRE believes that the TBM-RTA concept has potential to move operations \ncloser to Trajectory-Based Operations (TBO). iii Table of Contents\nAbstract \n1 Introduction \n2 Concept of Operations for TBM-RTA \n3 Part-Task Human in the Loop Simulation \n3.2 High-Fidelity FMS Flight Simulators \n3.3 Core TBM-RTA Software Functions \n3.4 Operational Scenario \n3.5 Evaluation Phraseology \n3.6 Traffic Scenarios \n4.1 Summary of HITL Flights \n4.2 Operational Acceptability \n4.3 Reasons for Canceled RTAs \n4.4 RTA Flights Metering Delivery Accuracy \n4.5 Aircraft Separation at Meter Fix Crossing \n4.6 RTA Flights Speed Profile Data \n4.7 Controller and Pilot Feedback \n4.7.2 Controllers Qualitative Results \n4.7.2.2 Comments on the Integrated ConOps \n4.7.2.3 General TBM Comments \n4.9 Pilots Qualitative Results \n6 Next Steps \n7 Acknowledgments \n8 References \nAppendix A Acronyms \nFigure 1. TBM-RTA Capabilities Overview \nFigure 2. RTA with Path Stretch Advisories in Extended Metering Environment \nFigure 3. High Fidelity FMS Simulation \nFigure 4. RTA Assignment and Tracking \nFigure 5. RTA-equipped Flights on MRP List \nFigure 6. ZAB Airspace Simulated During the HITL \nFigure 7. RTA and Path Stretch Phraseology \nFigure 8: Illustration of simulated traffic level \nFigure 9. Summary of all Flights Crossing SLIDR \nFigure 10. Summary of Flights Assigned an RTA and Crossing SLIDR \nFigure 11. SLIDR Delivery Accuracy \nFigure 12. Summary of Aircraft Separation at SLIDR by Evaluation Run \nFigure 13. AAL346 FMS Flight in Evaluation Run #3 \nFigure 14. Average Controller Scores \nFigure 15. Average FMS Pilot Scores \nFigure 16. Average Pseudo Pilot Scores \nTable 1. Summary of Canceled RTAs \nTable 2 Reasons for Canceled RTAs \nTable 3. SLIDR Delivery Accuracy Statistics \nTable 4. Aircraft Separation Statistics at SLIDR \nTable 5. FMS RTA Flights Summary \nThe Federal Aviation Administration (FAA) is implementing new automation capabilities, which \nleverage investments made by both the FAA and Operators in Performance-Based Navigation \n(PBN) and other flight deck capabilities; this will help transform the National Airspace System \n(NAS) to Trajectory Based Operations (TBO) which is part of the Next Generation Air \nTransportation System (NextGen) program. TBO is an air traffic management (ATM) method for \nstrategically planning, managing, and optimizing flights by using time-based management \n(TBM), information exchange between air and ground systems, and the aircrafts ability to fly \nprecise paths. Expected benefits of TBO include enhanced flight efficiency, maximized airspace \nand airport throughput, improved operational predictability, and increased operational flexibility. \nThe successful operational transition to TBO relies in part on effective TBM, and for some origin-\ndestination pairs, gate-to-gate TBM. TBM uses time to efficiently integrate traffic demand for \nconstrained NAS resources; this goal is accomplished by use of automation to generate a \nschedule at designated points of interest, which consists of flight-specific crossing times to \nachieve the appropriate spacing interval. Effective TBM depends on accurate predictions by \nautomation of expected flight crossing times and accurate calculation of a schedule, as well as the \nuse of decision support tools (DSTs) by controllers and traffic managers to help meet the \nschedule (e.g., meet time advisories) and modify it as schedule disruptions occur. \nThe FAA has deployed numerous PBN procedures and routes throughout the NAS, and airspace \nusers have started to realize benefits. However, the full set of PBN benefits will only be realized \nwith TBOrequiring full integration between aircraft PBN capability, aircraft flight \nmanagement capabilities, and air traffic strategic planning and TBM. TBM, also referred to as \nmetering, is largely provided via the Time-Based Flow Management (TBFM) ground-based \nsystem which is used to manage traffic to/from several airports today. Additionally, several \nTBFM scheduling enhancements, such as Coupled Scheduling and Extended Metering \nfunctionality, and new DSTs, that provide automated speed advisories and path change advisories \nfor controllers, are in the process of implementation or planned for use across ATC domains [1]. \nThese enhancements and tools will help controllers better manage flights to meet the \ndesired/scheduled crossing times (i.e., aircraft delivery) at designated points (e.g., metering arcs, \narrival fixes) along arrival routes and procedures. Moreover, some existing flight-deck \ncapabilities can further improve upon the accuracy and efficiency by which those crossing times \nare met. \nThe most relevant of these existing flight deck capabilities, present in many aircraft Flight \nManagement Systems (FMS), is the capability to accept an ATC-issued Required Time of \nArrival (RTA) clearance to cross a given point in space at a specified time. The RTA clearance is \nmet using real-time aircraft speed adjustments executed by the FMS. One advantage of using the \nFMS to meet the time requirement is that the FMS can better account for wind and flight profile \nuncertainties as compared with ground-based automation advisories. Moreover, the FMS RTA \ncapability provides a tightly coupled closed-loop solution, updating its speed automatically to \nadjust for forecast wind errors and unmodeled aircraft dynamics in order to meet the assigned \nRTA. As a result, ATC does not need to frequently issue updated speed assignments to achieve \nflight adjustments required to more accurately meet the metering crossing time target.\nStakeholders have shown strong interest in using RTA-capable flights to achieve near-term TBM \nobjectives [9]. The performance and behavior of airborne RTA has been extensively studied in \nsimulations and operational trials [2], [3], [4] but not in the context of the FAAs envisioned ii TBO scope. Building on those previous studies, The MITRE Corporations Center for Advanced \nAviation System Development (MITRE CAASD) performed analyses to develop and refine a \nconcept for using RTA to more accurately meet a scheduled crossing time [6]. In this study, \nMITRE simulated use of RTA in the context of a future en route TBM environment (consistent \nwith initial TBO) that included TBM scheduling enhancements and DSTs that provided meet-\ntime advisory options to aid controllers in managing flights to their scheduled crossing times in \nan extended metering operation; the scope included Ground-based Interval Management-Spacing \n(GIM-S) speed advisories [7] (currently available), the Delay Countdown Time (DCT) (currently \navailable), and Path Stretch advisories [8] (a future capability). The proposed concept for \nleveraging the aircraft RTA function is referred to in this paper as the TBM-RTA concept. iii Concept of Operations Summary for TBM-RTA2\nAs indicated in Figure 1, the TBM-RTA concept combines the advanced arrival scheduling \ncapabilities provided by the TBFM system and the aircraft FMS RTA function to enable \nimproved delivery accuracy of multiple arrival streams to the terminal airspace boundary [1]. \nCurrently, controllers issue speed and heading commands to pilots to meet the scheduled flight \nspecific crossing times generated by the TBFM system. With the TBM-RTA concept, controllers \nare envisioned as issuing an RTA clearance to the pilot using the TBFM generated Scheduled \nTime of Arrival (STA) value (i.e., flight-specific crossing time) as the basis for the RTA; the \npilot would input that value into the FMS and the avionics would adjust the aircraft speed to \ncross the designated point at the STA. Figure 1. TBM-RTA Capabilities Overview The TBM-RTA operation is envisioned to be conducted in en route airspace only for meeting \nSTAs at the Terminal Radar Approach Control (TRACON) boundary Meter Fix (MF) or a \nCoupled/Extended Meter Point (MP). The TBM-RTA operation begins when an aircraft crosses \nthe respective en route TBFM scheduling Freeze Horizon (FH) and the TBFM system assigns an \nSTA for a Meter Reference Point (MRP) of interest (which can be a MF or a MP). The relevant \nMRP schedule information is directly available on the situation display for en route controllers \nwho issue the arrival procedure to aircraft along with specific instructions for aircraft to meet \nassigned STAs at the associated MRPs. The meet-time advisory options for each flight are \nindicated (and can be accepted or rejected by the controller) both in the MRP list and in the flight \ndatablock.\nUnder the TBM-RTA concept,
pilots of aircraft that are RTA capable are issued the TBFM-\nderived STA as an RTA clearance by controllers. For aircraft that are not RTA capable, \ncontrollers use their DST capabilities (such as the speed advisories or DCT) to efficiently manage \nflights to meet the TBFM system generated STAs. When the required flight adjustment (i.e., iv crossing time delay) is predicted to exceed what can be accomplished at the current Flight Level \nwith speed alone, the en route controller will need to either use a manual vector (e.g., s-turn) or \nissue an interim altitude clearance to a lower Flight Level and then revert to use of RTA when the \nautomation determines it is feasible. Given that aircraft RTA equipage is not yet available as part \nof the International Civil Aviation Organization (ICAO) flight plan, several alternatives to \ndetermine RTA equipage by the operational system can be implemented. These alternatives \ninclude: using an aircraft equipage table to determine RTA capability or using an FAA specific \nextension of the ICAO flight plan to allow operators to submit RTA equipage information until a \nstandardized ICAO version will be available.\nAlternatively, if Path Stretch advisories are available (expected to be deployed within the same \ntimeframe as TBM-RTA) the controllers will be able to assign the automation-provided path \nchange solution along with an RTA to achieve the flight-specific crossing time. The Path Stretch \nadvisory provides a two-legged maneuver (i.e., path change) for the flight that takes the aircraft \noff the current route to a specified point, expressed as a radial and nautical miles distance from an \navailable adjacent navigation fix, and back toward the current route. If the controller decides to \nissue a Path Stretch advisory, the controller would communicate the path change to the pilot first \nfollowed by the RTA clearance; the pilot programs their FMS to input the path change and RTA \ncommand, in this order. Pilot confirmation to the controller that the RTA clearance is achievable \nis required; once that is confirmed, the controller would accept the advisory on the situation \ndisplay which would update the MRP list for that flight.\nIf at any point during the RTA operation, it appears that the targeted flight-specific crossing time \nwill not be met, the controller can suspend the TBM-RTA operation and revert to traditional \nstrategies to meet the STA, such as applying speed control, vectoring, and altitude assignments. \nWhile the concept document describes how RTAs can be used in en route airspace both in the \ncruise phase of flight as well as in descent, for this evaluation the TBM-RTA concept was \nexplored only during level flight in cruise in an extended metering (XM) context as depicted in \nFigure 2. v Figure 2. RTA with Path Stretch Advisories in Extended Metering Environment vi 1 Refers to simulations that provide instruction on only a part of the whole job or task. Part-Task Human in the Loop Simulation3\nFollowing the development of the ConOps presented in Section 2, MITRE CAASD executed a \npart-task1 human-in-the-loop (HITL) evaluation to assess the operational feasibility of the \nconcept [5]. Simulation Environment3.1\nThe simulation was conducted in the MITRE CAASD Aviation Integrated Demonstration and \nExperimentation for Aeronautics (IDEA) Lab. The hardware used for the simulation is the same \nhardware used by field controllers, including two 4K displays, keyboards, track ball, and push-to-\ntalk audio. Additionally, the evaluation occurred in a data collection environment that provided a \nsimilar general workstation layout and setup to that of sectors at an air traffic control facility. \nThe software used to conduct the TBM-RTA Part Task Evaluation was a combination of actual \n(operational) software and an emulation of capabilities that are typically used as part of an Air \nRoute Traffic Control Center (ARTCC) facility. The simulation software architecture was \ncomposed of the following distinct components: TBFM Applications: this consists of an operational version of the TBFM software \nthat was integrated in the MITRE IDEA Lab. This version of TBFM software \nprovides the ability to issue GIM-S Speed Advisories. TBFM Connector: MITRE software used to interface the IDEA Lab simulation assets \nto the operational TBFM system. The interfaces provide TBFM with track data and \nflight plans and also receives metering information from the TBFM system. En Route Automation Modernization (ERAM) Emulator: Consists of the MITRE \nJoint En Route Decision Support System (DSS) Infrastructure (JEDI) software that \nwas built to provide an emulation of ERAM. The software includes prototyped Path \nStretch functionality that has not yet been operationally developed or fielded. Controller Stations: This consists of the controller Display System Interface (DSI) \nemulation which is part of the ERAM software but is available as a modular \ncomponent in the IDEA Lab. Flight Modeler: Consists of MITRE software capability used to realistically represent \nthe characteristics of much of the current airplane fleet. Pseudo Pilots: Consists of an IDEA Lab software capability that can be used to \ncontrol simulation traffic. The software is designed such that a single pilot can control \nmultiple aircraft in a simulation. High-Fidelity FMS Flight Simulators3.2\nIn addition to aircraft simulated using the IDEA Lab flight model, aircraft simulators that utilize \nactual FMS control logic were also used in the simulation. The FMS simulators were introduced \nbecause they more closely represent behavior of commercial aircraft avionics, which was \nconsidered critical for evaluating the feasibility of TBM-RTA. In each of the four runs, two pilots \nflew two simulators. Figure 3 provides a snapshot of the FMS workstation interface used. As vii indicated, the software interface is complex because it incorporates a full FMS interface. \nConsequently, these simulators had to be staffed by dedicated Airline Transport Pilot License \n(ATPL) certified pilots, unlike the IDEA Lab simulated aircraft where one pseudo-pilot managed \nmultiple aircraft at once. Figure 3. High Fidelity FMS Simulation Core TBM-RTA Software Functions3.3\nAside from the core software components described in Section 3.1, additional software \nmodifications were implemented on the ATC automation to support the TBM-RTA concept \nevaluation. A summary of the core software functions implemented is described here. \nOne core function consists of the RTA assignment and tracking functions, which provides \ncontrollers the means to monitor RTA assignments as aircraft progress through the sector and are \nhanded off to subsequent sectors. Figure 4 shows an example for an aircraft that has been issued \nan RTA clearance. As indicated, the MRP List is updated with the RTA assignment. \nAdditionally, the data block is updated to indicate the assigned RTA. viii Figure 4. RTA Assignment and Tracking Another software change was made to clearly show to the controller which flights are and are not \nRTA-equipped. The STA on the MRP list is bold and underlined for flights that are RTA \nequipped, as shown by SWA474 in Figure 5. Non-equipped flights have gray STAs, such as \nAAL433. Once a flight is assigned an RTA or speed clearance, the RTA or speed is listed in the \nSpeed (SPD) column (the right-most column). This is a critical feature as not all aircraft will be \ncapable of performing an RTA. Figure 5. RTA-equipped Flights on MRP List Operational Scenario3.4\nThe concept was evaluated in a two-sector, en route environment representing the northeast \ncornerpost flow into Phoenix Sky Harbor International Airport (KPHX) in the Albuquerque \nARTCC, abbreviated ZAB. The two sectors simulated were ZAB 93, which primarily handles \nflights in their cruise phase, and ZAB 39, which handles the descent phase of the arrival prior to \nentering the TRACON. The focus of the evaluation was the metering operations in ZAB 93 \n(highlighted in dark blue) to the extended metering point (XMP) identified as SLIDR \n(pronounced slider). SLIDR is located at the en route merge near the airspace sector boundary \nof ZAB 93 and ZAB 39 on the EAGUL6 Arrival Procedure (solid black line), as depicted in \nFigure 6. ix Figure 6. ZAB Airspace Simulated During the HITL SLIDR is also a coupled meter point (CMP) in relation to the meter fix (MF), identified as \nHOMRR (pronounced homer). That means the sequence of flights crossing SLIDR is held \nconstant (or coupled) with the sequence of those same flights across HOMRR. In the current \noperation, HOMRR is where the en route traffic is delivered to the TRACON. \nIn this evaluation, all operations were executed with voice communication. Controllers were \nasked to issue (based on equipage) RTA clearances or advisory-provided speed clearances to \nSLIDR to make the flight adjustments necessary to meet the targeted crossing times in the \nextended metering environment. Path Stretch advisories were also provided by automation to be \nused in combination either with the RTA or speed clearance in cases where the flight adjustment \nneeded could not be accomplished with speed or time alone. Controllers were notified if a Path \nStretch was necessary once a flight crosses the FH for SLIDR (Figure 6). Controller participants \nwere also instructed to meet MRP crossing times as accurately as possible while ensuring \nseparation. Flights were expected to cross SLIDR within 30 seconds of the STA. Evaluation Phraseology 3.5\nIn this evaluation, all operations were executed with voice communications. Controllers issued \nspeeds, RTAs, path changes, or a combination of those clearances to meet the TBFM system \ngenerated
flight-specific crossing times. In doing so, controllers used a standardized phraseology. \nIf dual clearance was required (e.g., issue an RTA with Path Stretch advisory), controllers were \ninstructed to issue as two separate clearances, each with a pilot readback. The path change \nclearance was stated first so the pilot could inform the FMS of the route, followed by the RTA \nclearance. Figure 7 shows an example of an RTA with Path Stretch available to SWA474, \nincluding the developed controller phraseology. x PS and RTA command ATC says:\n SWA474, for arrival flow, proceed direct \nto the ZUN three one five at zero six zero-\nmile fix, then direct to ZUN <pilot readback> SWA474, cross SLIDR @ Time 130824 <pilot readback> Figure 7. RTA and Path Stretch Phraseology Traffic Scenarios3.6\nDuring the two-day evaluation period in August 2017, two FAA controllers and four MITRE \npilots participated in four, one-hour long scenarios. Controllers managed sustained traffic \nscenarios that required the use of Path Stretch, and either GIM-S speed or RTA clearances. About \n70% of the flights were RTA-equipped.\nThe traffic level in all of the scenarios represented 130% of the peak demand for the northeast \ncorridor at KPHX with an average delay of 1:45 minutes per flight to be managed by the sector \n93 controller position. Figure 8 illustrates the traffic density that the controllers managed. xi Figure 8: Illustration of simulated traffic level. xii Results4\nThis section provides an overview of both quantitative and qualitative findings from the two-day \nHITL simulation. Although the primary objective of the HITL simulation was to assess the \noperational feasibility of using the flight-deck RTA capability in an en route metering operation, \nwith and without Path Stretch, additional data was recorded. The data was used to evaluate \nmetrics in four major areas: Operational feasibility of integrating Path Stretch and RTA capabilities.1.\nController and pilot workload acceptability.2.\nMetering delivery accuracy of RTA flights.3.\nSpeed profile data for RTA flights.4. MITRE analyzed the operational feasibility by looking at the individual outcomes of the RTAs \nand interviewing controllers and pilots involved in the HITL simulation about their perceived \nworkload. The latter also included a controller participant questionnaire and feedback from brief-\nout sessions with the controller participants and FAA headquarters staff. \nThe metering delivery accuracy was collected to assess if RTA operations met the desired 30 \nseconds accuracy to SLIDR. Lastly, MITRE analyzed the speed profile data for RTA flights to \nidentify if excessive speed variations were necessary to achieve the RTAs. Summary of HITL Flights4.1\nA total of 96 flights crossed SLIDR across the four evaluation runs. Of the flights crossing \nSLIDR, 66 were equipped for RTA operation (69% equipage level) and 30 were not equipped. \nAs described in section 3.1, several meet-time advisory options were available to controllers \nduring the evaluation. Depending on aircraft equipage, controllers had the ability to meet the \nSTA via speed assignment, RTA, or a combination of Path Stretch with speed or RTA. If ATC \nissued an RTA (or RTA with Path Stretch), the flight may have executed the initial RTA \nassignment to completion (crossing SLIDR), the initial RTA assignment may have been canceled \nby the controller, or the initial RTA assignment may have been updated (e.g., new/reissued RTA, \nor updated path change). Delivery accuracy to SLIDR was determined for each aircraft by \ncomparing the actual flight crossing time at SLIDR (referred to as the Actual Time of Arrival \n(ATA)) to the TBFM system-generated schedule value (STA). The HITL simulation metering \ndelivery accuracy target (ATA to STA) was 30 seconds. Any aircraft crossing SLIDR within \n30 seconds (either before or after the STA) would meet this target. \nFigure 9 provides a summary of all flights in the HITL simulation. The four sets of black vertical \nlines represent groupings in each category labeled at the top. For example, in the Equipage \ncategory on the left, flights were categorized as Not RTA Equipped or RTA Equipped. The \nvertical height of the bar represents how many flights are in that group; the percentage of all \nflights crossing SLIDR is given in the group label. The flows branch from each category, left to \nright, to show all possibilities. The width of each flow represents the percentage of flights. For \nexample, the largest flow in red labeled Not RTA Equipped branches and connects to the \nSpeed Only grouping. This shows that, for flights not equipped for RTA, the majority received \nan advisory-provided speed command. From left to right, Figure 9 provides the complete story \nof simulated flights. Focusing on the RTA Equipped flights, most flights were assigned just an \nRTA clearance to meet the crossing time (as noted by RTA Only) and only a small percentage xiii were issued an RTA clearance with a path change (as noted by RTA w/ PS). Most of these \nflights went on to cross SLIDR within 10 seconds of the assigned RTA. xiv Figure 9. Summary of all Flights Crossing SLIDR Because the TBM-RTA concept was the focus of this evaluation, particular focus was given to flights that were assigned an RTA. Figure 9 \nprovides the same flow diagram, filtered to only the 51 flights that received an RTA and crossed SLIDR. The percentages offered in this \ndiagram are from the flights that received an RTA (e.g. 20% of flights that were issued an RTA were also issued a Path Stretch). Overall, \n98% of flights that received an RTA crossed SLIDR within the 30-second tolerance. Section 4.4 discusses delivery accuracy in more detail. xv Figure 10. Summary of Flights Assigned an RTA and Crossing SLIDR xvi Operational Acceptability4.2\nAcross all the evaluation runs, there were 66 flights equipped with the RTA function, either \nflown with the FMS simulators or by the pseudo pilots, and therefore eligible to receive an RTA \nclearance. Of these 66 RTA flights, 51 received an RTA clearance (77%), either with a Path \nStretch clearance or without. To assess the operational acceptability of combined Path Stretch \nand RTA clearances, MITRE collected the number of canceled RTA operations. The RTA \ncancellation rate was 13.7% of the total number of RTA operations and was slightly higher for \nthe RTA clearances paired with Path Stretch (20%). Reasons for Canceled RTAs 4.3\nAs shown in Table 1, seven flights had their RTAs canceled across all evaluation runs. MITRE \nconducted an analysis of recorded FMS data, pilot commands, and ATC instructions to determine \nthe possible reason for each cancellation. These are provided in Table 2. Table 1. Summary of Canceled RTAs Issued RTAs Canceled RTAs Cancellation Rate\nPS + RTA 10 2 20.0%\nRTA Only 41 5 12.2% Total 51 7 13.7% Table 2. Reasons for Canceled RTAs Run Flight Reason for RTA Cancelation\n1 DAL714 Aircraft received an incorrect Path Stretch due to an error in the simulation. ATC then issued a GIM-S speed advisory to speed the aircraft up to meet the schedule, which canceled the RTA. \n2 SWA412 ATC likely canceled the RTA due to uncertainty with aircraft compression. Analysis shows that no loss of separation occurred and the aircraft would have likely met its scheduled \ncrossing time. 3 AAL1731 Path Stretch and RTA were insufficient to meet the targeted crossing time. The RTA \nalgorithm did not adequately slow the flight, likely due to a simulation error. The controller \nwas offered a slower GIM-S speed advisory and issued it to the aircraft, which canceled the \nRTA. 3 AAL2235 This flight was the first in the simulation to cross SLIDR. It was meeting its schedule \nperfectly and was properly spaced from all other aircraft. It is unclear why ATC canceled its \nRTA. 4 AAL230 These three flights were all canceled together due to perceived sequencing issues. Aircraft \nspacing was close, but no loss of separation occurred and flights were not compressing. Post \nanalysis shows that the schedule would have been met without issue via the assigned RTAs. 4 AAL538\n4 AAL619 The fourth hour-long scenario had the most cancellations. However, these cancellations were all \nrelated to a single event in the simulation. The three-aircraft involved in the event (AAL230, \nAAL538, and AAL619) were adjacent to each other in the schedule. As the aircraft approached \nSLIDR, they began to merge onto a coincident path for the final segment of the operation. Each \naircrafts RTA function was performing to a high level (maximum observed error was 10 \nseconds). The inter-aircraft spacing was stable at approximately 7.5 NM between aircraft with no \ncompression occurring, nor any active conflict alert warnings. At this moment, the system could \nbe described as achieving its designed performance: high delivery accuracy and throughput \ntargeting the maximum desired airspace adapted values (approximately 8 NM between aircraft). \nHowever, it is clear the controller was not comfortable with the situation. The RTA operations \nwere canceled and aircraft were assigned headings and speeds. There are several factors that xvii could have contributed to the decision to cancel the operation. The most critical was that each \naircraft was flying different speeds (between Mach .74 and .76). Given the proximity of the \naircraft to each other, the uncertainty of how the trajectories would unfold was likely the primary \ncause of the cancellations. \nThe
post-analysis shows that the aircraft speeds were desirable and the sequencing was likely to \nbe successful. However, this case may demonstrate a need for additional controller feedback \nmechanisms that can quickly reassure controllers that aircraft are not likely to compress below \nrequired minimum separation. In this case, the lack of a Conflict Alert activation was not \nsufficient to give the controller confidence in the situation. Finally, lack of familiarity or \nconfidence in the newly-developed capabilities, only utilized for a single simulation, may have \ncontributed to the event. RTA Flights Metering Delivery Accuracy4.4\nThe ATC participants were instructed to target a delivery accuracy at SLIDR of 30 seconds. \nDelivery accuracy was determined by comparing the Actual Time of Arrival (ATA) to the final \nTBFM issued STA for each flight. Figure 11 provides a histogram of delivery accuracy for all 96 \nflights crossing SLIDR. Two categories are highlighted: (1) Flights that received an RTA from \nATC and flew it completely to SLIDR, and (2) Flights that were never issued an RTA or received \nan RTA and had it canceled prior to SLIDR. Flights to the right of zero crossed SLIDR late \n(ATA was after STA); flights to the left crossed SLIDR early. As Figure 11 shows, most flights \ncrossed SLIDR within 30 seconds. Only two flights crossed outside of tolerance. Both flights \nhad their RTA canceled prior to SLIDR. Figure 11. SLIDR Delivery Accuracy Table 3 provides a statistical summary of delivery accuracy to SLIDR. As shown, both the mean \nand standard deviation were smaller for flights completing an RTA. This result shows improved \ndelivery accuracy for flights under the TBM-RTA concept. Table 3. SLIDR Delivery Accuracy Statistics xviii RTA not Issued or RTA \nCanceled RTA \nCompleted Mean (seconds) 3.06 2.00\nStandard Deviation (seconds) 11.12 7.95 Aircraft Separation at Meter Fix Crossing4.5\nIn addition to targeting a delivery accuracy at SLIDR, the ATC participants were also responsible \nfor ensuring safe separation of aircraft. The spacing between the crossing flight and the \nassociated trailing flight was calculated for each aircraft crossing SLIDR base on when the lead \naircraft crossed SLIDR. Figure 12 provides a summary plot of distances between crossing and \ntrailing aircraft pairs at SLIDR. For example, in evaluation run #1, the median spacing between \ncrossing and trailing aircraft at SLIDR was about 10 NM and the maximum was 26 NM. Figure 12. Summary of Aircraft Separation at SLIDR by Evaluation Run Table 4 provides the statistics for the actual distances between the crossing and trailing aircraft at \nSLIDR for each of the four evaluation runs. The TBFM system was set to deliver a super stream \nseparation of 8 NM at SLIDR. Table 4. Aircraft Separation Statistics at SLIDR Evaluation Run\nMean (NM) Standard Deviation (NM) 1 11.6 4.8\n2 13.4 7.9 xix 3 12.0 4.9\n4 12.5 5.1 RTA Flights Speed Profile Data4.6\nThere were two RTA flights flown by the pilots with the FMS simulator in each data collection \nrun. Controllers issued RTA clearances to pilots to meet times at the SLIDR extended metering \npoint. MITRE analyzed the aircraft speed profiles to assess if excessive speed adjustments \noccurred. Of the eight total FMS simulator flights, five crossed SLIDR flying an uninterrupted \nRTA, either with or without a Path Stretch maneuver. Of the other three flights, one was assigned \na GIM-S speed and two were canceled because of ATC spacing concerns. The summary of the \nFMS flights is presented in Table 5. Table 5. FMS RTA Flights Summary Completed RTAs Canceled RTAs RTA not Issued Total\n5 2 1 8 The six FMS simulator-based flights that completed an uninterrupted RTA to SLIDR only \nchanged their speed once, immediately after the RTA was engaged. They then flew a quasi-\nconstant speed (e.g., speed changes were within 0.002 Mach) to SLIDR. As shown in Figure 13, \nthe FMS for AAL346 adjusted its speed from Mach 0.786 to Mach 0.767 as soon as the RTA \nfunction was engaged. After two small speed changes, it continued to fly at Mach 0.766 until \ncrossing SLIDR. Figure 13. AAL346 FMS Flight in Evaluation Run #3 For the sample of six FMS RTA flights that completed an uninterrupted RTA, the mean delivery \nerror at SLIDR was 3.4 seconds with 11.1 seconds standard deviation, well within the desired \ntarget of 30 seconds. Across all runs, the FMS achieved this accuracy with a maximum speed \nadjustment of 0.0061 Mach2. xx 2 After the initial speed adjustment when the RTA was executed. Controller and Pilot Feedback4.7\nThe acceptability of combined Path Stretch and RTA clearances was evaluated by looking at both \nthe HITL simulation data, as summarized in Table 1, and through surveys and discussions with \nparticipants. Controller Feedback4.7.1\nController participants completed a survey at the end of the evaluation. Figure 14 provides the \naverage scores between the two participants. A high level of agreement to any question indicates \nthat the survey participant found the concept useful or operationally acceptable. \nThe survey included ten questions, abbreviated as Q1 through Q10. As can be seen in Figure 14, \nparticipants rated both Q2 (the straightforward ability to manage en route RTAs and assign \nintegrated TBFM/RTAs by voice) and Q5 (the straightforward and effective ability for \nconformance monitoring of en route RTAs and integrated TBFM/RTA clearances) the highest for \nthe survey. Conversely, participants rated Q1 (confidence of assigned RTA delivery to the en \nroute meter point at assigned STA with little or no intervention), Q8 (the proximity Closet Point \nof Approach (CPA) distance information usefulness for monitoring RTA), and Q9 (use of RTA \nmore straightforward, reliable, and less workload than conventional methods currently available, \nas neutral). Strongly Disagree\nNeutral Strongly Agree Average Likert Scale Controller Response Figure 14. Average Controller Scores Controllers Qualitative Results4.7.2\nMITRE also collected feedback from controllers in a series of debrief sessions. This section \nprovides a summary of the unscripted inputs received from HITL participants, with some follow-\non comments from the MITRE team. xxi Concept Discussion4.7.2.1\nParticipants liked the flexibility to use either RTA or GIM-S. The user interface made it easy for \ncontrollers to track the type of command that they issued and to track the aircrafts progress \ntowards meeting the STA. \nIt was also noted that TBFM uses forecasted wind data rather than real-time wind information. \nMITRE HITL staff stated that RTA may provide the most benefit in an inaccurate predictive or \nvariable wind environment over the use of GIM-S alone. Once the aircraft encounters winds \ndifferent than forecasted, the RTA FMS function would change the aircraft speed as necessary to \naccurately meet the assigned time. Or conversely, if the winds are erroneous in ground-\nautomation, the ETA calculation generated by the TBFM system which is used as an input to \nproduce the STA may result in an RTA clearance that is unachievable by the aircraft. Comments on the TBM-RTA Concept4.7.2.2\nParticipants indicated that the workload level experienced using voice communications to issue \nthe combined meet-time advisory options (i.e., Path Stretch, RTA, and GIM-S advisories) would \nbe cumbersome. However, it was stated that use of RTA has the potential to reduce existing \nvoice communication workload. Since a single RTA clearance in many cases will be sufficient \nbecause the FMS avionics can manage the speed changes necessary to meet the crossing time, \nthere should be fewer voice commands to pilots. It was also stated that use of Data \nCommunication for these clearance types would be a favorable application to mitigate overall \narrival management voice communications workload. \nParticipants also expressed some concern about RTA capable aircraft performance behavior, in \nparticular the speed profile executed to achieve the RTA (e.g., will the aircraft go slow and then \nspeed up?). However, evaluation results from the FMS simulators showed that once the FMS \nadjusted the speed to meet the RTA, only infrequent and small speed changes occurred afterward. \nIn future studies, especially if RTA is used in descent, analyses should be conducted to assess the \nspeed profile of flights issued RTA clearances to ensure ATC acceptability of RTA performance \nin that context. General TBM Comments 4.7.2.3\nOne participant expressed some concern about the current avionics standard of 30 seconds \nmeter point delivery accuracy in cruise. He stated that if one aircraft is 30 seconds late and the \nnext aircraft in arrival sequence is 30 seconds early, both within the avionics standard, an \naccuracy differential of 60 seconds, or about 8 miles at cruise altitudes, would exist. The concern \nis that if this routinely occurs, controllers will not use RTA. If it is found that 30 seconds \naccuracy is not acceptable, the avionics community may need to revisit the requirement. \nParticipants indicated that conforming to the Path Stretch and RTA advisories resulted in less-\nthan-optimal in-trail spacing of arrival aircraft transitioning from Sector 93 to Sector 39. \nParticipants stated that an occasional pair of flights with tight spacing would be manageable, but \nmultiple consecutive tight spacing pairs would not be operationally acceptable. An additional \ncontributing factor was the observed speeds of some RTA flights when crossing SLIDR (as the \nRTA operation was completed). Due to differences in altitude, large differences in Mach number \noccurred. For example, speeds of Mach .80, .74, and
.78 were observed for three subsequent \naircraft. \nParticipants noted that an unrealistically high traffic level was simulated to maximize the use of \nthe Path Stretch tool in conjunction with RTA. MITRE staff confirmed that excessive traffic xxii levels were used to push the limits of Sector 93 arrival management. Pilot Feedback4.8\nThere were two pilots controlling one flight each with the FMS simulator and two pseudo pilots \neach controlling multiple RTA flights in each of the HITL simulation runs. Q1 and Q2 of the \npilot survey were only applicable to the former. The rest, Q3 to Q5, were applicable to all the \npilots. Averaged scores for the FMS simulator and pseudo pilots are reported in Figure 15 and \nFigure 16, respectively. A high level of agreement to a question indicates that the survey \nparticipant found the concept useful or operationally acceptable. Strongly Disagree Disagree Neutral Agree Strongly Agree Average Likert Scale FMS Pilot Response Figure 15. Average FMS Pilot Scores As can be seen in Figure 15,the FMS FAA Certified ATPL pilots rated Q1 (the straightforward \nability to program the FMS for an en route RTA for TBFM extended metering) the highest \npossible score. They also rated high Q2 and Q3, related to the straightforward monitoring of RTA \noperation, both with a score of 4. Q4 (the assessment of the workload necessary to operate RTAs \nfor TBFM extended metering versus current practice) scored the lowest. Finally, they more than \nagreed with the assessment of the usefulness of RTA operation in Q5. xxiii Strongly Disagree Disagree Neutral Agree Strongly Agree Average Likert Scale Pseudo Pilot Response Figure 16. Average Pseudo Pilot Scores Figure 16 shows that the pseudo pilots scored Q3, Q4, and Q5 the same as the FMS pilots. \nReiterating the usefulness of RTAs for TBFM extended metering operations. Pilots Qualitative Results4.9\nPilots remarks and comments were collected in the final part of the survey. A summary of the \nremarks from the FMS pilots are presented below. Reported that he/she did not monitor the speed changes that the FMS was using to \nachieve the STA with the RTA function. He/she trusted the automation. Reported that using the RTA instead of a speed requires slightly more manipulation \non the FMS. Reported that a six-digit number for the STA was hard to hear, commenting that if the \nclearance was unexpected, this format could be confusing for pilots. Also \nacknowledged that this could be a personal issue and that could be mitigated once the \nRTAs become more commonly used. xxiv Summary and Conclusions5\nThe part-task HITL evaluation presented in this paper was focused on the use of integrated Path \nStretch and RTA clearances in the cruise extended metering environment. The low RTA \ncancellation rate and the positive feedback from the controller and pilot questionnaires collected \nshowed the operational feasibility of the TBM-RTA ConOps. Moreover, the higher delivery \naccuracy at the meter point achieved by the RTA flights demonstrated that, at least in cruise, the \nfunctionality can provide a benefit. Lastly, the relatively low speed adjustments implemented by \nthe FMS RTA to achieve the higher delivery accuracy allowed the controllers to monitor RTA \nflights with several minor improvements to the information already provided by the displays that \nthey currently use. \nThe HITL simulation operational scenarios were designed to put excess stress on the extended \nmetering operation to test the functional integration of the Path Stretch, RTA, and GIM-S meet-\ntime advisories. As a result, controllers were managing traffic that was workload-intensive at \ntimes. This caused the controller in sector 93 to occasionally intervene and issue speed and/or \nvector clearances to flights before handing off to sector 39. Controllers recognized that these \nspeeds and/or vectors were necessary because of the higher than normal traffic represented in the \nsimulation. \nAnother finding related to the higher than normal traffic during the evaluation is that, in a dense \ntraffic environment, even if aircraft meet their STA perfectly, there could be some separation \nissues after crossing the meter point. For example, if consecutive aircraft cross the meter point at \ndifferent speeds, even if perfectly separated at the meter point meeting their STA, post-crossing \nspacing can decrease to levels that are uncomfortable to the controllers. Therefore, the necessity \nto apply speed control to several aircraft by the receiving controller in sector 39 was observed \noccasionally during the HITL simulation. 6 xxv Next Steps7\nWhile the HITL simulation showed that the TBM-RTA concept is operationally feasible, \nadditional studies need to be conducted to assess the benefits of using RTA for en route extended \nmetering versus the use of GIM-S advisories. A key focus of future studies will be whether the \nhigher delivery accuracy achieved by RTA flights translates into benefits such as increased \nthroughput or reduced delays. \nThe HITL simulation also demonstrated the feasibility of the ConOps in extended metering in en \nroute cruise, but questions remain about the feasibility during the en route descent phase for \nmetering to the TRACON. Greater RTA performance uncertainty is expected when aircraft \naltitude changes occur, and the results of this HITL simulation cannot be directly extended to that \ntype of operation. Managing RTA flights that are metering and transitioning across multiple \nsectors should also be explored, as this was not studied in this HITL simulation. \nAnother important issue that needs to be validated is the use of more realistic wind forecast errors \nbetween the TBFM system and the FMS. MITRE expects the benefits of RTA over GIM-S to be \nhigher in actual operations where the wind prediction accuracy is lower than what was modeled \nfor the evaluation.\nA key next step is to study a more realistic depiction of arrival traffic flows. The HITL simulation \nconducted included higher than normal traffic levels operating in an arrival flow corridor which \ncreated some unexpected challenges, previously described. It would be desirable to simulate \ntraffic over a four cornerpost environment to allow TBFM to provide more balanced traffic \ndemand loading via the schedule. xxvi Acknowledgments8\nMITRE CAASD would like to express our thanks to Guillermo Sotelo, Kerry Capes, and Rob \nHunt from the Federal Aviation Administration (FAA) who provided valuable input to help guide \nthis research. The authors would also like to express our thanks to the other MITRE staff who \nsupported this research on our project team: Alain Oswald, Clark Britan, Mahesh Balakrishna, \nBill Bateman, Daniel Kirk and Elly Smith. xxvii References9\nSwenson, H., et al., Design and Operational Evaluation of the Traffic Management [1] Advisor at the Fort Worth Air Route Traffic Control Center, in 1st USA/Europe ATM \nResearch and Development Seminar, Saclay, France, 1997. Wynnyk, C., MacWilliams, P., Balakrishna, M., Becher, T., 2011 Trajectory Based [2]\nOperations Flight Trials, in 10th USA/Europe ATM Research and Development Seminar, \nChicago, IL, 2013. Klooster, J., Del Amo, A., Manzi, P., Controlled Time of Arrival Flight Trials, in 8th [3]\nUSA/Europe ATM Research and Development Seminar, Napa, CA, 2009. De Smedt, D., Bronsvoort, J., McDonlad, G., Controlled Time of Arrival Feasibility [4]\nAnalysis, in 10th USA/Europe ATM Research and Development Seminar, Chicago, IL, \n2013. Klooster, J., de Smedt, D., Controlled Time-of-Arrival Spacing Analysis, in 9th [5]\nUSA/Europe ATM Research and Development Seminar, Berlin, Germany, 2011. Sgorcea R., Enea, G., et. Al., Use of Flight Management System (FMS) Required Time [6]\nof Arrival (RTA) for Time Based Management (TBM): Concept of Operations, \nMTR170293V1, The MITRE Corporation, September 2017. (Unpublished) Lascara, B., Weitz, L., Monson, T., Mount, R., Measuring Performance of Initial Ground-[7]\nbased Interval Management Spacing (GIM-S) Operations,\" in 12th USA/Europe ATM \nResearch and Development Seminar, Seattle, WA, 2017. Celio, J., Concept of Use of Path Stretch Advisories, Revision 1, MTR150333R1, The [8]\nMITRE Corporation, 2017.\nRTCA NextGen Advisory Committee Initial Trajectory Based Operations Implementation [9]\nStrategy, Federal Aviation Administration, January 2018. xxviii AcronymsAppendix A Acronym Definition\nANSP Air Navigation Service Providers\nARTCC Air Route Traffic Control Center\nATA Actual Time of Arrival\nATC Air Traffic Control\nATPL Airline Transport Pilot Licence\nATM Air Traffic Management\nCAASD Center for Advanced Aviation System Development\nConOps Concept of Operations\nCMP Coupled Meter Point\nCPA Closest Point of Approach\nDSI Display System Interface\nDSS Decision Support System\nDST Decision Support Tools\nERAM En Route Automation Modernization\nETA Estimated Time of Arrival\nFAA Federal Aviation Administration\nFH Freeze Horizon\nFMS Flight Management System\nGE General Electric\nGIM-S Ground-based Interval Management-Spacing\nHITL Human in the Loop\nIDEA Integrated Demonstration and Experimentation for Aeronautics\nJEDI Joint En Route DSS Infrastructure\nMF Meter Fix\nMP Meter Point\nMRP Meter Reference Point\nNG Next Generation\nNM Nautical Mile\nPBN Performance Based Navigation\nPHX Phoenix Sky Harbor International Airport xxix PS Path Stretch\nRTA Required Time of Arrival\nSPD Speed\nSTA Scheduled Time of Arrival\nTBFM Time Based Flow Management\nTBM Time Based Management\nTRACON Terminal Radar Approach Control\nUFM Unified Flight Modeler\nXMP Extended Meter Point\nZAB Albuquerque ARTCC NOTICE\nThis is the copyright work of The MITRE Corporation, and was produced for the U. S. \nGovernment under Contract Number DTFAWA-10-C-00080, and is subject\nto Federal Aviation Administration Acquisition Management System Clause 3.5-13, Rights In \nData-General, Alt. III and Alt. IV (Oct. 1996). No other use other than that granted to the U. S. \nGovernment, or to those acting on behalf of the U. S. Government, under that Clause is \nauthorized without the express written permission of The MITRE Corporation. For further \ninformation, please contact The MITRE Corporation, Contracts Management Office, 7515 \nColshire Drive, McLean,
VA 22102-7539, (703) 983-6000. _top\n _GoBack\n _Toc505159428\n _Toc512861537\n _Toc505159429\n _Toc512861538\n _Ref504505633\n _Toc505159430\n _Toc512861539\n _Ref493944081\n _Ref493944053\n _Toc494272902\n _Toc494365960\n _Toc494369281\n _Toc494383262\n _Toc494448262\n _Toc494448317\n _Toc494448541\n _Toc494442479\n _Toc494449905\n _Toc505159412\n _Toc513193623\n _Ref503861724\n _Toc505159413\n _Toc513193624\n _Toc505159431\n _Toc512861540\n _Toc494272919\n _Toc494365981\n _Toc494369303\n _Ref494372866\n _Toc494383234\n _Toc494448283\n _Toc494448339\n _Toc494448563\n _Toc494442501\n _Toc497920726\n _Toc498515858\n _Toc498584759\n _Toc498588545\n _Toc498599154\n _Toc499131134\n _Ref503862575\n _Ref503867750\n _Toc505159432\n _Toc512861541\n _Toc494272921\n _Ref494279028\n _Ref494357367\n _Toc494365983\n _Toc494369305\n _Toc494383236\n _Toc494448285\n _Toc494448341\n _Toc494448565\n _Toc494442503\n _Toc497920728\n _Toc498515860\n _Toc498584761\n _Toc498588547\n _Toc498599156\n _Toc499131136\n _Toc505159433\n _Toc512861542\n _Ref503862270\n _Toc505159414\n _Toc513193625\n _Toc494272922\n _Toc494365984\n _Toc494369306\n _Toc494383237\n _Ref494394631\n _Toc494448286\n _Toc494448342\n _Toc494448566\n _Toc494442504\n _Toc497920729\n _Toc498515861\n _Toc498584762\n _Toc498588548\n _Toc498599157\n _Ref498924811\n _Toc499131137\n _Toc505159434\n _Toc512861543\n _Hlk513453917\n _Ref503862673\n _Toc505159415\n _Toc513193626\n _Hlk513453966\n _Ref503862733\n _Toc505159416\n _Toc513193627\n _Toc505159435\n _Toc512861544\n _Hlk513454221\n _Ref496093996\n _Toc505159417\n _Toc513193628\n _Hlk513454281\n _Toc494369308\n _Toc494383240\n _Toc494448289\n _Toc494448345\n _Toc494448569\n _Toc494442507\n _Toc497920732\n _Toc498515864\n _Toc498584765\n _Toc498588551\n _Toc498599160\n _Toc499131140\n _Toc505159436\n _Toc512861545\n _Hlk513454332\n _Ref503863043\n _Toc505159418\n _Toc513193629\n _Toc505159437\n _Toc512861546\n _Hlk513454428\n _Ref513209099\n _Toc513125397\n _Toc513193630\n _Ref505005575\n _Toc505159419\n _Toc505159438\n _Toc512861547\n _Hlk513454473\n _Toc494365990\n _Toc494369313\n _Toc494383244\n _Toc494448293\n _Toc494448349\n _Toc494448573\n _Toc494442511\n _Toc497920736\n _Toc498515868\n _Toc498584769\n _Toc498588555\n _Toc498599164\n _Toc499131144\n _Toc505159439\n _Toc512861548\n _Hlk513454571\n _Toc513125398\n _Toc513193631\n _Toc505159420\n _Ref503867859\n _Hlk513454602\n _Toc513125399\n _Toc513193632\n _Ref503868066\n _Toc505159421\n _Toc504987471\n _Toc494272928\n _Toc494365991\n _Toc494369314\n _Toc494383245\n _Toc494448294\n _Toc494448350\n _Toc494448574\n _Toc494442512\n _Ref497918401\n _Toc497920737\n _Toc498515869\n _Toc498584770\n _Toc498588556\n _Toc498599165\n _Toc499131145\n _Toc505159440\n _Toc512861549\n _Ref494273728\n _Toc494272899\n _Hlk513454694\n _Toc505159441\n _Toc512861550\n _Toc497920738\n _Toc498515870\n _Toc498584771\n _Toc498588557\n _Toc498599166\n _Toc499131146\n _Hlk513454722\n _Ref503932268\n _Toc512861583\n _Hlk494269685\n _Ref504029186\n _Toc512861584\n _Hlk513454876\n _Hlk513454913\n _Toc505159442\n _Toc512861551\n _Hlk513454951\n _Toc513125400\n _Toc513193633\n _Toc505159422\n _Ref503868404\n _Hlk513454971\n _Ref503868660\n _Toc512861585\n _Toc497920752\n _Toc498515872\n _Toc498584773\n _Toc498588559\n _Toc498599168\n _Toc499131148\n _Toc505159443\n _Toc512861552\n _Hlk513455127\n _Toc513125401\n _Toc513193634\n _Ref503869272\n _Toc505159423\n _Hlk513455180\n _Ref504490479\n _Ref503869389\n _Toc512861586\n _Toc494272933\n _Toc494366003\n _Toc494369326\n _Toc494383257\n _Toc494448306\n _Toc494448362\n _Toc494448586\n _Toc494442524\n _Toc497920751\n _Toc498515873\n _Toc498584774\n _Toc498588560\n _Toc498599169\n _Toc499131149\n _Toc505159444\n _Toc512861553\n _Hlk513455212\n _Ref504490533\n _Ref503869666\n _Toc512861587\n _Hlk513455258\n _Toc513125402\n _Toc513193635\n _Ref503869755\n _Toc505159424\n _Hlk513455302\n _Toc498515874\n _Toc498584775\n _Toc498588561\n _Toc498599170\n _Toc499131150\n _Toc505159445\n _Toc512861554\n _Hlk513455442\n _Toc494272930\n _Ref494273784\n _Toc494365993\n _Toc494369316\n _Toc494383247\n _Toc494448296\n _Toc494448352\n _Toc494448576\n _Toc494442514\n _Toc497920740\n _Toc498515875\n _Toc498584776\n _Toc498588562\n _Toc498599171\n _Toc499131151\n _Toc505159446\n _Toc512861555\n _Hlk513455458\n _Toc513125403\n _Toc513193636\n _Ref503932483\n _Toc505159425\n _Toc494272931\n _Ref494273786\n _Toc494365994\n _Toc494369317\n _Toc494383248\n _Toc494448297\n _Toc494448353\n _Toc494448577\n _Ref494449739\n _Toc494442515\n _Toc497920741\n _Toc498515876\n _Toc498584777\n _Toc498588563\n _Toc498599172\n _Toc499131152\n _Toc505159447\n _Toc512861556\n _Hlk513455482\n _Toc494365995\n _Toc494369318\n _Toc494383249\n _Toc494448298\n _Toc494448354\n _Toc494448578\n _Toc494442516\n _Toc497920742\n _Toc498584778\n _Toc498588564\n _Toc498599173\n _Toc499131153\n _Toc505159448\n _Toc512861557\n _Hlk513455499\n _Toc498584779\n _Toc498588565\n _Toc498599174\n _Toc499131154\n _Toc505159449\n _Toc512861558\n _Hlk513455604\n _Hlk513455576\n _Toc498584780\n _Toc498588566\n _Toc498599175\n _Toc499131155\n _Toc505159450\n _Toc512861559\n _Hlk513455644\n _Toc505159451\n _Toc512861560\n _Hlk513455688\n _Toc513125404\n _Toc513193637\n _Ref503940834\n _Toc505159426\n _Hlk513455712\n _Toc513125405\n _Toc513193638\n _Ref503940848\n _Toc505159427\n _Toc494365999\n _Toc494369322\n _Toc494383253\n _Toc494448302\n _Toc494448358\n _Toc494448582\n _Toc494442520\n _Toc497920747\n _Ref498012554\n _Toc498515878\n _Toc498584783\n _Toc498588569\n _Toc498599178\n _Toc499131158\n _Toc505159452\n _Toc512861561\n _Toc505159453\n _Toc512861562\n _Toc498584785\n _Toc498588571\n _Toc498599180\n _Toc499131160\n _Toc505159454\n _Toc512861563\n _Toc505159455\n _Toc512861564\n _Toc505159456\n _Toc512861565\n _Ref504036493\n _Ref495986283\n _Ref495344141\n _Ref504036307\n _Ref495986285\n _Ref495986286\n _Ref504039240\n _Ref495986328\n _Ref495986884\n _Ref495987598\n _Toc505159457\n _Toc512861566\n AcroWizard_Generated_Table ",
    "text": " Fleet Forecasting Tool Keeps U.S. Aviation System a Step Ahead MITRE is helping the Federal Aviation Administration predict how commercial aircraft fleets will grow \nand evolve in the future. The insights help the agency plan for the future of the National Airspace \nSystem. To keep the National Airspace System (NAS) running smoothly, the Federal Aviation Administration \nneeds good projections of air traffic growth and the evolving capabilities of commercial aircraft. That \nincludes anticipating how many flights airlines might schedule in a given year, what routes they would \nserve, how many passengers and how much cargo they would fly, and the types of aircraft they would \nuse. That information supports the work of multiple FAA offices. For instance, some FAA analysts use fleet \nforecasts to predict which airports might soon reach capacity and where congestion might be a problem \nin coming years. Others monitor and predict aviation emission levels, based on the number and mix of \naircraft traversing the nation's skies. Still others seek to understand when certain technologies aboard \naircraft will become common so that new, more efficient flight procedureswhich depend on those \ntechnologiescan be widely adopted in the NAS. For many years, the FAA contracted with an external vendor to provide the forecasts. But in recent years, \nthe agency decided it needed a more flexible capability than the static reports it had been using. The FAA \nasked MITRE to find an agile approach to exploring the agency's current and future needs, and to \ndevelop a capability that would meet them. Web-Based Tool Introduces Flexibility That led to the creation of MITRE's fleetForecaster. It is a web-based tool that both MITRE researchers \nand FAA analysts now use to forecast the nation's future commercial fleet inventory. \"There are two parts to the tool,\" says project leader Simon Tsao. \"One provides fleet forecasts for the \nentire NAS. That gives analysts a look at the expected U.S. air carrier fleet in some future year. The \nforecast extends out as far as 40 years.\" The second part of the tool provides a breakdown of that nationwide overview. \"It's at the airport level,\" \nTsao explains. \"For example, an analyst can use fleetForecaster to see what the expected mix of aircraft \ntypes would be for flights flying out of Washington Dulles International Airport in a given year.\" The FAA \nhas had access to the NAS-wide aspect of the web-based tool since 2016 and the airport-specific \ncapability since 2017. The tool provides a much more automated system for collecting and preparing the necessary datasets, \napplying algorithms and logic to that data to create the forecasts, and using those outputs in analyses. Automating a Manual Process \"Prior to fleetForecaster, creating the forecast was a very manual process,\" Tsao says. \"There was a lot to \ntrack and manage. It included information such as aircraft registration and flight data, airline press \nreleases on their plans to order, transfer, or retire aircraft, and Securities Exchange Commission filings \nwith data about airlines' contracts with manufacturers to receive deliveries of various aircraft. We still \nhave to do some of that data gathering, but it's a much more manageable and automated process.\" MITRE then stores all the data in a back-end server. \"That makes it a lot easier to manage than when it \nwas provided in different forms,\" he says. \"It's also more transparent. With the legacy forecast reports, \nthe sources of the data weren't tracked. In fleetForecaster, analysts can easily see what the various \ndatasets are. It's all captured on our servers.\" Enabling \"What-if\" Explorations Another of the tool's advantages over the manually created report is its flexibility. \"In the old product, \nyou got one forecast. Analysts couldn't really see or change the inputs in the forecast,\" Tsao says. \"With \nfleetForecaster, they can modify various parameters to see how that would affect forecast results.\" There are any number of \"what-if\" scenarios analysts can explore by altering the tool's forecast settings. \nFor example, fleetForecaster assumes a 25-year lifespan for passenger aircraft and a 45-year lifespan for \ncargo aircraft. \"But analysts can change those figures if they believe existing aircraft will be retired \nsooner than what's assumed in the tool. That could mean aircraft with more sophisticated technology \nmight enter the fleet sooner, which could affect projections of NAS capacity and efficiency.\" Similarly, if researchers in the FAA's Office of Environment and Energy want to see what would happen \nto their aviation emissions projections if a higher number of aircraft with a particular engine type enter \nthe fleet, or if a new type of aircraft were introduced, they could easily recreate a forecast scenario in \nfleetForecaster for their analysis. fleetForecaster is also supporting information sharing among the FAA's diverse analysts and offices. \n\"They all have access to a single web-based tool and a consistent dataset, so they have a shared \nunderstanding of what all analyses are based upon,\" Tsao says. \"That helps facilitate cross-agency \ncollaboration.\" by Marlis McCollum Approved for Public Release; Distribution Unlimited. Case Number 18-1656. _top\n _GoBack ",
    "text": " Quantum Cryptography and Side Channel Attacks Colin Lualdi, Stephen Pappas, Daniel Stack, and Brandon Rodenburg Abstract Quantum key distribution (QKD) promises a theoretically unbreakable cryptosystem by employing the probabilistic nature of quantum measurement over mutually unbiased bases, making it superior to classical cryptosystems threatened by the advent of quantum computing. However, it has been shown that QKD systems are vulnerable to side channel attacks due to engineering and technical imperfections in practical implementations. This article presents a general overview of quantum cryptography, beginning with a comparison of classical and quantum cryptography is threatened by quantum computing. A basic discussion of QKDs security characteristics and implementation details is given. An example side channel attack is introduced with the avalanche photodiode backflash attack. The authors provide a brief overview of their experiment to investigate this attack, and report results indicating the ability for this attack to, in principle, succeed. brodenburg@mitre.org The authors affiliation with The MITRE Corporation is provided for identification purposes only, and is not intended to convey or imply MITREs concurrence with, or support for, the positions, opinions or viewpoints expressed by the authors. Approved for Public Release; Distribution Unlimited. Case Number 18-0968 mailto:brodenburg@mitre.org 1 Introduction Quantum key distribution (QKD) promises a theoretically unbreakable cryp- tosystem by employing the probabilistic nature of quantum measurement over mutually unbiased bases. Its security lies in the impossibility of an eavesdropper to gain access to the quantum keys without revealing the eavesdroppers presence due to the destructive nature of quantum measure- ment, as measured by the quantum bit error rate (QBER) [1]. However, it has been shown that QKD systems possess security vulnerabilities due to engineering and technical imperfections in practical implementations. Side channel attacks exploiting various points of accidental information leakage have been described in the literature, with examples including the photon number splitting and faked states attacks [1, 2, 3]. Many of those systems employ avalanche photodiodes (APDs) as a part of the process of measuring photon states to create a secure key as described by QKD protocols like BB84 [1]. Avalanches of charge carriers following photodetection events in silicon and InGaAs APDs are known to emit sec- ondary photons as a consequence of carrier relaxation [4, 5]. These photons, or backflashes, may be coupled back into the quantum channel and detected by an eavesdropper who could potentially deduce the states of the origi- nal information-carrying photons measured by the legitimate QKD receiver without affecting the QBER and thus remain hidden [6, 7]. 2 Quantum Cryptography 2.1 The One-Time Pad Many encryption systems varying in complexity and security have been invented. However, in the context of quantum cryptography the one-time pad plays an important role. The principle behind this cryptosystem (also known as the Vernam cipher) is simple, yet it is extremely effective at securing information [9]. Suppose we have a system where we assign a numerical value to each letter in the alphabet: Letter A B C \n1\n 2\n(|H+ |V ) = 1\n 2\n(|0+ |1) |+ (1) |A \n1\n 2\n(|H |V ) = 1\n 2\n(|0 |1) | . (2) So, prior to creating each photon qubit, Alice chooses a random polarization basis (HV or AD). She records this information. Then, she creates the pho- ton with a random polarization state within that basis. She also records this polarization state and its associated bit value. Note that upon measurement |H and |D correspond to bit 0 and |V and |A correspond to bit 1. Thus, each photon that Alice creates has a random polarization state with a 25% probability of being |H, |V , |A, or |D. She then transmits the qubit to Bob via their optical fiber cable. 2. Bob receives the qubits from Alice and measures them Upon receiving the photons from Alice, Bob measures their polarization states to begin the process of creating a secret key. As follows from the 5 basic principles of quantum mechanics, the basis that Bob uses for his measurements will affect their outcome. For each photon that Bob receives, he randomly chooses either the HV or AD basis, and performs the measurement. He records his basis choices and measurement results in the form of random bits. 3. Alice and Bob compare results As the final step in the BB84 protocol, Alice and Bob indirectly compare their random bits to obtain a sifted key. Alice announces to Bob over an insecure classical channel her random basis choices while keeping secret her state choices. Bob looks at his basis choices, and tells Alice which photons had Alice and Bob choosing the same basis, and which had a basis mismatch. Bob communicates this information to Alice over the insecure classical channel, keeping secret his measurement outcomes. Alice and Bob then agree to keeping measurements when their measurement basis matched, and discarding all other measurements. This step is significant because in keeping only the photons for which Bob knows he used the same basis as Alice, he can be certain that the random bit resulting from his measurement is exactly the same random bit that Alice obtained when randomly choosing a polarization state prior to photon transmission, due to the nature of quantum measurement. So the BB84 protocol allows Alice and Bob to create two sets of sifted keys of random bits that they know are identical just by comparing basis choices so that their actual random bits remain secret. As a result, Alice and Bob now share a string of random bits that they can use as their secret key for the proved-secure one-time pad procedure as discussed earlier. Note that the one-time pad also works with strings of random bits [9, 12]. Suppose Alice uses an encoding system to convert her secret alphanumerical message to the binary string 10111001. The secret key that she shares with Bob might be 11001101. She performs bitwise modulo-2 sum (XOR) with her message and the secret key to encrypt it: 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 0 0 Upon receiving the encrypted message from Alice, Bob can perform another bitwise modulo-2 sum using the shared secret key to decrypt the message: 6 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 There are additional error correction and privacy amplification protocols that Alice and Bob can perform to increase the secrecy and accuracy of their secret key, at the expense of reducing the number of bits in the key. The majority of those protocols are classical, and take place after the transmission of information through the quantum channel [1]. Key distribution via QKD has been proved theoretically secure against all attacks due to the probabilistic nature of quantum measurement. Any attempts by an eavesdropper to secretly measure the quantum bits mid- transmission will irrevocably alter those quantum states such that Alice and Bob will be aware that their quantum bits have been tampered with by measuring the QBER. Even with a quantum computer an eavesdropper can- not non-destructively measure or clone quantum states due to the quantum no-cloning theorem [17]. 4 QKD Implementation In addition to the well-known BB84 protocol, researchers have developed a number of alternative protocols. Some of them are variations of BB84, with differences in procedures and states used [1]. For instance, the E91 protocol, introduced by Arthur Ekert in 1991, involves creating entangled pairs of photons (Einstein-Podolsky-Rosen states) at a central source and sending each photon to Alice and Bob for measurement [19]. Due to the variety of available QKD protocols and two-state quantum systems, there are countless possible approaches to implementing QKD. Each has its own unique design corresponding to the requirements of the protocol and the use case, and comes with its own strengths and weaknesses in terms of QBER tolerance thresholds, key generation rate, feasibility, and other factors. For instance, while in the previous chapter we considered a general polarization-based implementation of BB84 using optical fibers, it is also possible to implement BB84 using photon phase and frequency encoding [1]. Additionally, one is not restricted to the use of optical fibers for qubit transmission; free-space QKD where photons are transmitted kilometers through the atmosphere along a shared line of sight have been demonstrated [20]. Commericial QKD systems are currently available for purchase, with many field tests conducted in recent years proving their feasibility [22, 23]. 7 4.1 Exploiting Implementation Flaws In the ideal QKD implementation, guaranteed security against eavesdroppers relies on the assumption that only idealized equipment is used where every component functions precisely as expected. However, real-world implementa- tions tend to be far from ideal due to a variety of technical and engineering challenges. Such implementation flaws could significantly threaten the secu- rity of QKD as they offer side channel exploitation opportunities for Eve to increase her eavesdropping abilities without detection [1]. An example of a side channel attack is the backflash leakage attack, which exploits
the physical implementation of a typical BB84 fiber-based system with polarization encoding. In such a system, the quantum state of photons transmitted by Alice is typically measured by Bob by routing the photons through a series of beamsplitters (non-polarizing and polarizing) and additional optics such that a photon in one of the four polarization states used is ultimately detected by a photodetector (out of four total) that is associated with that polarization state. Hence, when Bob receives a signal from a photodetector associated with a certain polarization state, he knows that he has received a photon in that polarization state. Figure 1 shows a typical BB84 receiver that achieves this measurement of the photon state. It consists of two arms, each with two single photon detectors. Each arm is associated with one of the two BB84 bases (HV or AD), and is responsible for measuring photons in its basis. The 50-50 beamsplitter that connects the two arms performs the step of randomly choosing the basis for Bob by sending the incoming photons into either the HV or the AD arm with equal probabilities. If the photon travels straight through the first beamsplitter, it enters the HV arm and Bob is measuring in this basis. The measurement process begins when the photon passes through a polarizing beamsplitter that directs the photon according to its polarization. For example, an H polarized photon continues straight through and is detected by an avalanche photodiode (APD), a common type of photodetector. Thus, when Bob sees this specific APD fire, he knows that he has chosen the HV basis, and the result of his measurement was H (which can be translated to a bit value). Similarly, a V polarized photon gets deflected by the polarizing beamsplitter and is directed into the second APD in the HV arm, registering as a V measurement. Most commercial fiber-based QKD systems actually employ alternative encoding schemes due to the susceptibility of the polarization states to disturbances from birefringence and other environmental effects that are difficult to manage outside of the laboratory setting [22]. 8 Figure 1: Schematic of a typical BB84 receiver layout. Figure credit: Stephen Pappas, MITRE & Colin Lualdi. On the other hand, if the photon is directed into the second measurement arm by the first beamsplitter, then Bob is measuring in the AD basis. As the beamsplitters measure in the HV basis, Bob needs to first rotate the polarization of the incoming AD photon by /4 using a half-wave plate (HWP) so that a D photon becomes an H photon and an A photon becomes a V photon. The remainder of the measurement process is the same as in the HV arm except that when one of those APDs fires, Bob knows he is measuring in the AD basis and records an A measurement for one and a D for the other. Those APDs have a design flaw that could serve as a source of information leakage. First pointed out by Kurtsiefer et al., this attack relies on the curious fact that avalanche photodiodes are known to emit backflash photons upon photonic stimulation due to the physics of those detectors [6]. Their operating principle lies in the use of a semiconductor p-n junction. Prior to single photon detection, the reverse bias voltage of the p-n junction is raised to a breakdown voltage Vb. At this voltage, absorption by even a single photon is sufficient to create carriers in the conduction band of the diode, which can then trigger an avalanche process, creating a measurable current in the milliamp range indicating photon detection. Different semiconductor materials are used for photons of different wavelengths. Silicon (Si) APDs are most sensitive to wavelengths in the 400-1000 nm range (ideal for laboratory 9 experiments), while alternative semiconductor materials such as indium gallium arsenide are well suited for telecommunication wavelengths of 1300 nm or 1550 nm (ideal for long distance transmission). When photons strike the semiconductor material, they cause electron excitations, creating electron-hole pairs. The electrons function as charge carriers (i.e. hot carriers or free carriers) and multiply, causing the avalanche. Interestingly, a photoemission also occurs as a result of those avalanches. Explanations for those photoemissions are varied and include radiative electron-hole recombination and carrier energy relaxation (direct, phonon- assisted, or Bremsstrahlung) [24, 25]. Those secondary photons may be either absorbed in a quiescent region of the semiconductor, initiating new avalanches, or they may find their way out of the detector [4]. Photons that manage to escape the detector could potentially be a source of information leakage when APDs are used in a QKD implementation. Such backflash photons could couple with the optical fiber leading into the APDs, find their way through Bobs QKD receiver, and out into the quantum channel traveling in the opposite direction of the incident photons from Alice. An eavesdropper could then discreetly siphon off the backflash photons, leaving the original photons untouched. If those backflash photons carry meaningful information corresponding to the information carried by the original photons, Eve could potentially perform measurements on her backflash photons to gain information about the results of Bobs measurements and, in extension, the secret key. Since the creation of backflash photons is a random process, Alice and Bob have no knowledge of or control over photons that escape Bobs receiver. Thus, this attack allows Eve to obtain copies of the photons used by Alice and Bob without their knowledge, and thus leave the QBER unaffected. Consequently, this represents a dangerous potential QKD vulnerability. 5 Demonstration of Information Leakage from APD Backflashes We consider the hypothetical attack scenario shown in Figure 2. Alice and Bob are using a fiber-based BB84 QKD implementation with polarization encoding. It is assumed that Eve has full access to all classical communica- tions between Alice and Bob. We also propose that Eve is able to tap into the quantum channel, perhaps with the use of an optical circulator. This would allow all the photons sent by Alice to Bob to travel uninterrupted, but diverts to Eve the backflash photons traveling in the opposite direction. 10 Figure 2: Overview of a potential QKD attack exploiting APD backflash emission. Due to the design of the BB84 receiver (see Figure 1), all backflash photons acquire specific polarization information as they exit their originating APD and travel through a sequence of polarizing beamsplitters and half-wave plates. For instance, APD1, being parallel to its polarizing beamsplitter, is responsible for measuring H-polarized photons. Therefore, when backflash photons exit APD1, they return through the polarizing beamsplitter where onlyH light is transmitted, and photons of different polarizations are reflected and lost. Those H photons then reach the main beamsplitter, where half of them are transmitted through to the quantum channel and the other half are lost. A similar process occurs with the remaining APDs: backflashes from APD2 reach the quantum channel as V photons and APDs 3 and 4 also produce D and A-polarized backflashes, respectively, as they exit the polarizing beamsplitter and half-wave plate set to 45 degrees. It is important to emphasize that there is no direct coherence, classical or quantum, between the incident photons from Alice and the backflash photons. This is because the original photon is completely destroyed in the measurement process within the APDs. The resulting backflash creates a pulse of light that is created simply as a result of hot carrier relaxation. However, as those backflashes exit the BB84 receiver, the key polarization information is imprinted onto them by the various optical elements used. Additionally, a single QKD photon may create many backflash photons, allowing Eve to measure the polarization of the QKD signal with very high fidelity. 11 Figure 3: Schematic of the experiment setup used by the authors to investigate BB84 backflashes. 5.1 Experimental Apparatus Figure 3 provides an overview of the experimental setup. A function generator acts as a pulse generator and serves as the timekeeper for the entire apparatus by setting the reference time. It triggers a 850 nm pulsed diode laser. A variable attenuator significantly reduces the lasers power so that it generates faint pulses in an approximation of a single photon source. The resulting photons are then directed through a linear polarizer set to 45 degrees with respect to the fast and slow axes of the immediately following quarter wave plate. This transforms the incoming photons into circular polarization. This is necessary in order to ensure the balanced distribution of all incoming photons among the four BB84 detectors as polarized beamsplitters evenly split circularly polarized light. The photons then pass through a neutral density (ND) filter with an optical density of 3.0 rotated 20 degrees off the beam axis and then routed to the BB84 receiver (see Figure 1 for details). Each BB84 measurement port contains a Si APD for photodetection. Some of the secondary photons resulting from the avalanches within those APDs manage to escape into the BB84 receiver, becoming backflash photons. A portion of those photons then exit the BB84 receiver (purple beam in Figure 3) and find their way
back to the ND filter. The backflash photons reflect off the ND filter and coupled into a multimode optical fiber and detected by a silicon APD. To permit the investigation of polarization correlations between individual backflash signals and detection events in the 4-Channel APD (the originating 12 APD of the backflash), we rotate a linear polarizer in front of the fiber capture to scan through the linear polarization Hilbert space. Each of the five output signals from the five APDs used is routed to a timetagger device that records the exact times of all individual photodetection events. 5.2 Experimental Results Since we are interested in observing correlations between backflash polariza- tion and individual APDs in the 4-Channel APD, during the data-processing step we isolate backflash events associated with a particular APD. We achieve this by identifying all photodetection times from the backflash detecting APD that occur within a specific time window after the firing of one of the four APDs in the BB84 receiver since that backflash photon must have originated from that BB84 APD. Note that this approach does not handle the case where additional backflash events from other APDs happen to occur whether because of a pulse with multiple photons or spontaneous emission within the same time window and therefore are incorrectly attributed to this APD. However, we make the reasonable assumption that such peculiar events are rare and their effects will be masked by legitimate backflashes that occur much more frequently. Rotating the linear polarizer, we observe that the intensities of backflash events associated with each APD change as a function of the polarizer angle due to the hypothesized polarization dependence of the backflashes. Therefore, we are able to measure the maximum and minimum intensities of the backflashes from each APD. We calculate the fringe visibility =\nImax Imin Imax + Imin\n, (3) where Imax is the maximum observed intensity and Imin is the minimum observed intensity. We apply this concept to our backflash measurements to give a quantitative measure of our ability to measure a specific polarization in the backflash data. Figure 4 presents the visibility values for the five primary slices from each APD with = 0 indicating minimum visibility and = 1 indicating maximum visibility. With visibility values generally above 0.5, it is clear that we do have an ability to identify the polarization angles associated with maximum and minimum counts for each APD. Additionally, as APDs 1-2 and APDs 3-4 both correspond to two orthog- onal basis states, we expect a phase shift of /2 between the polarization 13 Figure 4: Visibility () values for APDs 1-4. As backflashes are not always generated at the same time after the photodetection, they are detected by the backflash-detecting APD over a small range of times. Hence the five time slices for each APD. 14 angles associated with maximum measured backflash intensities from each pair. We also expect to, with the AD basis being the HV basis rotated by /4, see a phase difference of /4 between cross-basis APD pairs. Figure 5 shows the estimated phase values of each slice from all four APDs, relative to each other. This figure clearly shows four distinct phases, with one for each APD. Figure 5: Phase values for each primary slice from APDs 1-4. The data shows a clear correlation between the backflashes from individual APDs and their polarization. It appears that, with the appropriate resources, a hypothetical eavesdropper would be able to exploit backflash polarization correlations to determine the originating APD, and therefore gain information regarding the result of the original BB84 measurement. This information leakage would not be detected by the legitimate communicators via the QBER, compromising QKD security. While our quantitative results offer us confidence in reaching our con- clusion, our non-ideal visibility, distinguishability, and phase values reveal 15 some flaws in our apparatus. This is partially attributed to issues such as backflash polarization distortion from the optics used, non-ideal beamsplit- ters, non-ideal circular polarization for the incoming photons from the BB84 source, varying detector efficiencies, and the fact that the HWP was not precisely calibrated. In order to evaluate the practicality of the backflash attack, one needs to quantify the rate of information leakage due to backflashes. To do this, however, one needs to first determine the backflash rate and compare it to the rate of incoming photons. As one may conclude from the discussions in [6, 4], this value is dependent on a complicated convolution of several functions and parameters, including the capture efficiencies and backflash amplitudes of the primary APDs, the efficiency for the backflash coupling back into the quantum channel, fiber attenuation effects, and the efficiency of the backflash-detecting APD. Characterizing each of those effects must be relegated to future work. While, without the backflash rate information, we cannot know with certainty, it may be the case that even if an eavesdropper, Eve, maximizes her detection efficiency with superior technology, the spectral and spatial filtering countermeasures described by Kurtsiefer et al. would reduce backflash levels such that Eve would gain very little information regarding the secret key. This information would then be reduced even further with privacy amplification procedures that the legitimate users perform to increase the security of their key. Furthermore, there are some emerging single-photon detection technologies that do not use avalanches in semiconductors, such as superconducting nanowire detectors [8] that may not exhibit backflash behavior. As we have discussed, quantum key distribution (QKD) promises a theoretically unbreakable cryptosystem by employing the probabilistic nature of quantum measurement over mutually unbiased bases. In ideal conditions the security of QKD is guaranteed, even against quantum computers. Thus, QKD is one possible replacement for classical cryptosystems threatened by quantum computing. However, we have also seen how non-ideal physical implementations of QKD systems render them vulnerable to various attacks that weaken their security, such as side channel attacks. We have considered the avalanche photodiode backflash side channel attack as an example. The results of the authors experiment investigating this attack indicate that, if not properly addressed, QKD security could be compromised. 16 References [1] N. Gisin, G. Ribordy, W. Tittel, and H. Zbinden, Quantum cryptogra- phy, Rev. Mod. Phys. 74(1), 145195 (2002). [2] G. Brassard, N. Ltkenhaus, T. Mor, and B. C. Sanders, Limitations on practical quantum cryptography, Phys. Rev. Lett. 85(6), 13301333 (2000). [3] I. Gerhardt, Q. Liu, A. Lamas-Linares, J. Skaar, C. Kurtsiefer, and V. Makarov, Full field implementation of a perfect eavesdropper on a quantum cryptography system, Nat. Commun. 2(1), 349 (2011). [4] A. Spinelli and A. L. Lacaita, Physics and numerical simulation of single photon avalanche diodes, IEEE Transactions on Electron Devices 44(11), 19311943 (1997). [5] F. Acerbi, A. Tosi and F. Zappa, Avalanche Current Waveform Esti- mated From Electroluminescence in InGaAs/InP SPADs, IEEE Pho- tonics Technology Letters 25(18), 17781780 (2013). [6] C. Kurtsiefer, P. Zarda, S. Mayer, and H. Weinfurter, The break- down flash of silicon avalanche photodiodesback door for eavesdropper attacks? J. Mod. Opt. 48(13), 20392047 (2001). [7] A. Meda, I. P. Degiovanni, A. Tosi, Z. Yuan, G. Brida, and M. Genovese, Quantifying backflash radiation to prevent zero-error attacks in quantum key distribution, Light: Science and Applications 6(6), (2017). [8] R. H. Hadfield, Single-photon detectors for optical quantum information applications, Nat. Photon. 3(12), 696705 (2009). [9] J. Katz and Y. Lindell, Introduction to Modern Cryptography, CRC Press, (2008). [10] C.K. Shannon, Communication theory of secrecy systems, The Bell System Technical Journal 28(4), 656715 (1949). [11] R. L. Rivest, A. Shamir, and L. Adleman, A Method for Obtaining Digital Signatures and Public-key Cryptosystems, Commun. ACM 21(2), 120126 (1978). [12] N. D. Mermin, Quantum Computer Science: An Introduction, Cambridge University Press (2007). 17 [13] A. Ekert and R. Jozsa, Quantum computation and Shors factoring algorithm, Rev. Mod. Phys. 68(3), 733753 (1996). [14] P. W. Shor, Algorithms for quantum computation: discrete logarithms and factoring, Proceedings 35th Annual Symposium on Foundations of Computer Science, 124134 (1994). [15] T.D. Ladd and F. Jelezko and R. Laflamme and Y. Nakamura and C. Monroe and J. L. O/Brien, Quantum computers, Nat. 464(7285), 4553 (2010). [16] C. H. Bennett and G. Brassard, Quantum cryptography: Public key distribution and coin tossing, Proceedings of IEEE International Con- ference on Computers, Systems and Signal Processing, Dec., 175179 (1984). [17] W. K. Wootters and W. H. Zurek, A single quantum cannot be cloned, Nat. 299(5886), 802803 (1982). [18] A. Houck, ELE 368: Introduction to Quantum Computing, Lecture on Quantum Key Distribution. [19] A. K. Ekert, Quantum cryptography based on Bells theorem, Phys. Rev. Lett. 67(6), 661663 (1991). [20] R. Ursin and F. Tiefenbacher and T. Schmitt-Manderbach and H. Weier and T. Scheidl and M. Lindenthal and B. Blauensteiner and T. Jen- newein and J. Perdigues and P. Trojek and B. Omer and M. Furst and M. Meyenburg and J. Rarity and Z. Sodnik and C. Barbieri and H. Wein- furter and A. Zeilinger, Entanglement-based quantum communication over 144 km, Nat. Phys. 3(7), 481486 (2007). [21] E. Gibney, Chinese satellite is one giant step for the quantum internet, Nat. News, Aug. (2016).
[22] H. Lo and M. Curty and K. Tamaki, Secure quantum key distribution, Nat. Photon 8(8), 595604 (2014). [23] D. Stucki and M. Legr and F. Buntschu and B. Clausen and N. Felber and N. Gisin and L. Henzen and P. Junod and G. Litzistorf and P. Mon- baron and L. Monat and J. B. Page and D. Perroud and G. Ribordy and A. Rochas and S. Robyr and J. Tavares and R. Thew and P. Trinkler and S. Ventura and R. Voirol and N. Walenta and H. Zbinden, Long-term 18 performance of the SwissQuantum quantum key distribution network in a field environment, New Journal of Physics 13(12) (2011). [24] R. Newman, Visible Light from a Silicon p-n Junction, Phys. Rev. 100(2), 700703 (1955). [25] S. Villa and A. L. Lacaita and A. Pacelli, Photon emission from hot electrons in silicon, Phys. Rev. B 52(15) 1099310999 (1995). 19 Introduction\n Quantum Cryptography\n The One-Time Pad\n Public Key Cryptography\n Impact of Quantum Computers on Classical Cryptography Quantum Key Distribution\n QKD Implementation\n Exploiting Implementation Flaws Demonstration of Information Leakage from APD Backflashes\n Experimental Apparatus\n Experimental Results ",
    "text": " 1 1. Systems Engineer, Lead\n2. Group Leader, Operations Research, Principal\n3. Data Analytics, Sr. \n4. This paper builds on work initially performed by MITRE in 2013. [1] Evaluating National Airspace System (NAS) Performance in \nContext Simon H. Heitin1, Wayne W. Cooper2, and Chih-Sheng Chou3 The MITRE Corporation, Mclean, VA, 22102, USA FAA analysts are faced with a problem of scale in knowing where to effectively spend \ntheir time and effort for post-operations analysis. They seek to identify areas for \nimprovement where performance is consistently below what is expected, and potential best \npractices where performance is consistently above what is expected. However, defining \nperformance expectations is challenging because performance metrics are very sensitive to \ncertain factors that are outside of the FAAs control (i.e., weather and demand). This study \nseeks to provide a statistical model for defining performance expectations that account for \nexogenous factors. It further defines statistical tests for detecting when performance \nexpectations are being consistently violated. The results could be deployed in automation to \nhelp FAA analysts detect performance issues quickly so that they can direct resources for \nin-depth analysis and solution development. Problem StatementI. \nThe Federal Aviation Administration (FAA) monitors National Airspace System (NAS) performance using a variety \nof metrics including airport departure delay, taxi-out time, and on-time performance. These metrics are published in \nAviation System Performance Metrics (ASPM) daily reports. FAA managers routinely use these reports to answer \nthree related questions: 1. Was performance at an airport on a specific day in line with conditions in the NAS on that day? \n2. Has performance at an airport changed over time?\n3. Did FAA Traffic Flow Management (TFM) actions on a specific day reduce the impact of system constraints? (E.g., did restrictions imposed on individual airport operations improve overall NAS system \nperformance?) This paper proposes a systematic approach for answering the first two questions4.[1] Obtaining meaningful \nanswers to these will, in turn, isolate specific areas of the NAS to which the third question should be focused to \nefficiently obtain an operationally meaningful answer. Airport performance on an individual day may be driven largely by that days weather or demand. The same is \ntrue for performance over months, seasons or years. Consequently, a direct comparison of current performance \nmetrics between a recent month and the corresponding month in another year may not meaningfully identify the \ntrend in performance. For example, the impact of weather in the most recent June may be significantly more severe \nthan that of the previous years June. Unless the metrics being used for the comparison account for this difference, \nthe resulting trend may largely be driven this weather input factor. A performance metric which explicitly accounts \nfor the impact of weather would enable a more meaningful comparison. More generally, current airport performance metrics fail to enable FAA managers to efficiently monitor airport \nperformance due to their failure to account for system conditions. System conditions include all factors that affect the \nbalance between flight demand and system capacity. These factors include: (1) forecasted weather (2) actual weather, 2 and (3) filed flight plans. Forecasted weather is the basis of the system capacity used by FAA managers to determine \nmost TFM actions, as these decisions must be made well in advance of a predicted problem. Actual weather \ndetermines the maximum system capacity that was ultimately achievable during operations. Filed flight plans are the \nbasis for determining the demand experienced during operations. These three factors are largely outside FAA control \nand are referred to in this study as exogenous factors. This study is limited to the second and third factors (actual \nweather and filed flight demand) but may be expanded in the future to include the first factor (forecasted weather). While current airport performance metrics include weather factors along with performance metrics, the \nrelationship between the two must be calculated by the analyst. For example, a severe thunderstorm may impact \nstandard arrival routes one hundred (100) nautical miles from an airport. An analyst may correctly determine that \nflight times for arrivals to that airport should increase due to the use of longer than normal routes to avoid these \nstorms. However, the analyst has no formal, repeatable method for estimating the magnitude of the increase in flight \ntimes attributable to the weather based on its severity. In addition, failure to incorporate the effect of weather in \ncalculating the metric means that automation cannot be fully utilized to identify locations and times justifying the \nexpenditure of limited analysis resources. The FAA actively monitors at least ten (10) metrics at the thirty (30) Core \nairports. This means that hundreds of performance metrics of potential interest to management can be monitored \ncontinuously for anomalies. The scale of this problem makes it difficult to systematically identify trends without \nautomation. Currently, a subjective decision must be made regarding which events/airports should be investigated \nmore closely by allocating limited analysis resources. The proposed process seeks to inform this decision reliably in \na way that may be implemented in automation. The goal of this study is to develop an automated process to inform the FAAs decision of how best to deploy \nlimited resources for post-operations analysis. It seeks to do this by providing a statistical methodology that identifies \nevents (time-periods and locations) where specific FAA performance metrics differed from what would be expected \nwhen accounting for the weather and demand. These anomalous events would be candidates for a further intensive \nand more detailed analysis to identify root causes. The results of these more targeted intensive analyses can be used \nto inform both future procedural improvements and identify best practices for TFM. AssumptionsII. \nDaily performance at a given airport is statistically independent of exogenous conditions on other days: normally, A. \nchanges to flight operations such as delays and cancellations are resolved by the end of the operational day, so \nthat normal operations can resume the following day, even after severe weather or high traffic volume. This is \nnot always the case: hurricanes and major snow events can disrupt normal operations for more than one day, but \nthese events are unusual. \nThe exogenous factors of demand and weather dominate the other factors under the control of the FAA. These B. \nfactors explain most of the statistical variation in the KPI, and as such provide a reasonable estimate of the \nnormal range of behavior when looking at the distribution of the regression model residual errors. The goal, \ndescribed later in this paper, of reaching a model R2 of 50% or more is one way of ensuring that this assumption \nis reasonable.\nVariation in a daily value for a performance metric can be represented as a linear function of the exogenous C. \nfactors that are used to describe it. This assumption allows the well-defined and understood statistical approach of \nlinear regression modeling to be used. [2] \nLong-term trends in relative system performance are measured with respect to a specific historical baseline D. \nperiod. The choice of this baseline period will affect results. If performance in baseline period #1 is better than in \nbaseline period #2, the relative performance of a more recent period may be different when measured against a \nmodel developed for period #1 than period #2. The analysis approach evaluates performance by airport and by day. The daily level of granularity was chosen \nfor analysis because operational days are generally independent (see assumption A above). At the beginning of the \nday, airlines and other users usually have their airframes in the correct location to achieve their planned schedule. As \nthe day progresses, there may be unforeseen disruptions, but there is generally enough time after the afternoon \ndemand peak to sort out the effects of those disruptions. Evaluation within a day would be a more challenging question because it would require accounting for the time- 3 5. The KPIs and names were developed for this paper and do not map directly to ASPM performance metrics. lag effect of weather and demand on each performance metric. It is expected that the chosen, daily level of \ngranularity is sufficient for informing the decision of where to deploy further analysis resources. Data SourcesIII. \nKey Performance indexes (KPIs) and exogenous factors were calculated using several FAA data sources. These data are stored in the following tables:\nIndividual ASPM flights [3]: This table records detailed flight attributes from ASPM, including:A. \n1) Origin and destination airport (O-D),\n2) Actual Out, Off, On, In (OOOI) event times (i.e., airport gate departure (Out), airport runway departure (Off), airport runway arrival (On) and airport gate arrival (In), \n3) Air carrier scheduled Out and In times, and \n4) Nominal taxi out and taxi-in times. Individual Traffic Flow Management System (TFMS) flights: This table records actual airborne time as well as B. \nthe flight track distance (MITRE-calculated) from origin to destination. The track distance is calculated as the \ndistance between each radar track location update (TZ message) for that flight in TFMS.\nASPM airport quarter-hour metrics [4]: this table collects quarter-hourly values of:C. The number of flights that intend to arrive/depart (ARRDEMAND, DEPDEMAND), 1) \n2) The counts of actual arrival
and departure throughput (i.e., ASPM arrivals and departures for efficiency computation (EFFARR, EFFDEP)),\n3) The scheduled count of arrivals and departures (SCHARR, SCHDEP), and \n4) The FAA recorded airport arrival rate (AAR) and departure rate (ADR). Hourly ASPM Weather Factors [5]: This table records these weather impact factors, which were calculated D. \nMETAR data based on ASPM weather factor methodology:\n1) Wind speed, \n2) Ceiling, \n3) Visibility,\n4) METAR-defined significant weather at the airport,\n5) Local thunderstorm conditions,\n6) En route thunderstorm conditions, and\n7) Scheduled operations. Based on various threshold values at each airport, the ASPM weather factors table provides one of four impact \nlevels, with both categorical and assigned numerical values (none = 0, minor = 1, moderate = 2, and severe \n= 3), on each weather factor, assigned for every hour. An overall daily impact value is also provided through \ncombining all weather attributes with ASPM-specified weights. [5] Because of the limited availability in TFMS of flight track updates outside the Continental US (CONUS), the \nflights used in this analysis were limited to origins and destinations in CONUS only. Key Performance Indicators and Exogenous FactorsIV. \nNAS Key Performance Indicators (KPI)A. In this study, eight KPIs were studied for eight study airports. KPIs were divided into two types: inbound \nmetrics, which focus on metrics for arrival flights to the study airport, and outbound metrics, which focus on metrics \nfor departures from the study airport. The KPIs5 were chosen to measure performance for different flight segments that are related to different \noperational areas. It was expected that FAA managers would want to be alerted to airports that exhibit performance \nanomalies across these different metrics within a given time-period, or within a single metric in multiple consecutive \ntime-periods. Figure 1 below shows the studied KPIs in green text. 4 Fig. 1 Conceptual diagram for deriving key performance index Inbound Flight Metrics: The inbound flight metrics are based on the arrival flights to the study airport. 1) \nInbound flight metrics include:\nDeparture Gate Delay (DGD): the daily average of the Actual Gate Out Time minus the Scheduled Gate Out \nTime for each flight. \nTaxi-Out Minutes above Baseline (TOM): the daily average of the Actual Runway Departure Time minus \nthe Actual Gate Out Time, minus the nominal Taxi-Out Time, for each flight. Nominal taxi-out times \nrepresent the estimated time for an aircraft under optimal operating conditions, when congestion, weather, \nor other delay factors are not significant. [3] \nTaxi-In minutes above Baseline (TIM): the daily average of the Actual Gate Arrival time minus the Actual \nRunway Arrival Time, minus the nominal Taxi-In Time, for each flight. Nominal taxi-in times represent the \nestimated time for an aircraft under optimal operating conditions, when congestion, weather, or other delay \nfactors are not significant. [3]\nAirborne minutes above Baseline (ATER): the daily average of the actual airborne time minus the first-filed \nEstimated Time En route (ETE), across all flights. The First Filed ETE represents the users intended \nairborne time, based on their initially filed flight plan information, as represented in TFMS\nBlock Minutes above Baseline (BMAB): The sum of the Taxi-Out Minutes above baseline, Airborne \nMinutes above baseline, and Taxi-in Minutes above baseline. \nFlown distance above Baseline (FDAB): the daily average difference of actual flown distance between the \norigin and destination for each flight and the baseline values for that origin and destination. The baseline \nvalue for each O-D is calculated as the average of the 5th and 15th percentiles of the (flown) track distances \nfor a three-year baseline period, based on TFMS flight track data. \nOutbound Flight metrics: The outbound flight metrics are based on departure flights from the study airport. 2) \nOutbound flight metrics include:\nOutbound Departure Gate Delay (OB_DGD): the average departure gate delay as calculated in the DGD \nmetric above, but here aggregated by departure instead of arrival airport. \nOutbound Taxi-out Minutes above Baseline (OB_TOM): the average taxi-out minutes as calculated in the \nTOM metric above, but here aggregated by departure instead of arrival airport. 5 Metrics are calculated as the portion of the value above a baseline or nominal value, so that values can be \ncompared across different airports. Also, distance flown and airborne time, which are different for flights for each O-\nD pair, can be aggregated up to the airport level only if the baseline values are subtracted first. Otherwise, the \naverage value for flown distance or airborne time on a specific day depends on the mix of short-haul and long-haul \nflights for that day. Exogenous FactorsB. \nSystem conditions include all the factors which change the balance between expected flight demand and expected system capacity. These factors include (1) forecasted weather, which affects forecast system capacity, (2) \nactual weather, which largely determines the actual system capacity achievable, and (3) filed flight demand. These \nthree factors are largely outside FAA control, so they are considered as exogenous factors when studying their \nimpact on the identified KPIs. Based on the data sources, the following metrics were derived with the intent of \nquantifying exogenous factors. \nDemand-Related Factors2) \nPrevailing arrival/departure demands are recorded in a quarter-hourly basis in the ASPM airport quarter- hour metrics table. They were aggregated into daily totals for daily arrival, departure and total demands in \nEquation (1), (2), and (3), respectively. These demand metrics reflect the number of flights which would be available demand at the airport to land \nor take off, if the corresponding flights were not delayed from their originally intended arrival or departure \ntime. As such they represent a virtual queue or unsatisfied arrival or departure demand. When a flight actually \narrives (lands) or departures (takes off), it is removed from this queue, which is updated every quarter-hour for \neach airport. New arrival demand are the flights entering this virtual queue in each quarter hour. This new \n(to the virtual queue) arrival demand in quarter-hour, New_ARRDEMANDt, is calculated from the existing \nASPM metrics in Equation (4), where ARRDEMANDt is the demand in the virtual arrival demand queue at the \nbeginning of quarter-hour t, and EFFARRt is the number of flights leaving the virtual queue (landing) during \nquarter hour t. A similar formula is used to calculate New_DEPDEMANDt in Equation (5). \nNew_ARRDEMANDt and New_DEPDEMANDt can be added together to reflect a new total demand, \nNew_ARRDEPDEMANDt in Equation (6). These three metrics were then aggregated into daily totals (i.e., \nDaily_New_ARRDEMAND, Daily_New_DEPDEMAND, and Daily_New_ARRDEPDEMAND). (4) (5) (6) Two more hourly demand indexes are used in this analysis: Hourly Excess Arrival Demand and Hourly \nWeighted AAR. The Hourly Excess Arrival Demand is measured by taking the difference between the arrival \ndemand (ARRDEMANDt) and the arrivals (actual landings) for efficiency calculation (Eff_Arrt) within each \nquarter-hour in Equation (7). These data were then aggregated into daily basis, denoted as Daily_EsArrD and \nDaily_WAAR. (1) (2) (3) 6 6. Cardinality | | is the number of elements meeting the logical condition in the set; in this case, the set includes all \nthe hourly values in one day. (7) With records of AAR per 15 minutes, the Hourly Schedule Weighted AAR (WAAR) is derived with \nscheduled arrival demand in Equation (8). (8) Additionally, the number of quarter-hours in a day for which the arrival demand exceeds that quarter-hours \nAAR, is referred to as A100, and it is expressed as the cardinality of arrival demand greater than the AAR in \nEquation (9)6. Likewise, the number of quarter-hours in a day for which the departure demand exceeds that \nquarter-hours ADR is referred to as D100 in Equation (10). These factors are also combined into a third \nexogenous factor: T100 = A100 + D100 in Equation (11). (9) (10)\n(11) Weather-Related Factors 3) \nAs discussed previously, the weather factor table provides six weather related impact levels: (1) wind speed (WSV), (2) ceiling (CV), (3) visibility (VV), (4) significant METAR airport weather (AWV), (5) near-by \nthunderstorms (NTSV) and (6) En route thunderstorm (ETSV), all on an hourly basis. An overall impact value \n(OV) is also calculated in ASPM using a formula weighting each of these six factors [5]. Since most flights fly at or close to a 3o glide slope on final approach, it is possible to convert the recorded \nceiling value into an equivalent visibility value. We then create a value which is the minimum of the recorded \nvisibility and ceiling value converted to an equivalent visibility for each hour, denoted as MINV. A daily (scheduled operation weighted) weather impact index (DWII) can be derived using Equation (12) \nfor each of these weather-related factors: (12) DWII is calculated for the six weather impact factors (WSV, CV, VV, AWV, NTSV and ETSV), as well as \nfor the OV and the MINV. Furthermore, the recorded values for scheduled operation in each hour was aggregated into daily totals \nusing Equation (13), denoted as Daily_SO. An overall weighted factor for each hour through multiplying the \nscheduled operation with its overall impact value (OV) is employed to derive a daily total weighted weather 7 factor in Equation (14), denoted as Daily_WF. (13) (14) Based on the available data, we collected 21 exogenous factors that may impact KPIs. However, not all of them \ncould be included in
statistical modeling due to correlation issues. Detail for correlation analysis among the \nexogenous factors would be presented in a later section. Analysis ApproachV. \nWe seek to profile the selected KPIs during a baseline period, explore how they are impacted by exogenous factors and apply such findings in predicting the normal range of performance during a treatment period, with \nstatistical modeling techniques. The purpose is to determine what days have performance outside this normal range, \nand to quantify such differences. Since weather and demand attributes are considered as exogenous factors for the \nstudied KPIs, multivariate linear regression models are employed to estimate/predict performances for the KPIs. \nComparing the modeled normal ranges with the actual values during the treatment period yields information about \ntimeframes when the KPIs are not in their normal performance range. This information can then be used to isolate \ndate ranges for each airport and KPI which should be delved into further using a more intensive detailed analysis \nwhich will uncover the reasons for under or over-performance. The normal or statistically expected range of performance for a KPI at a specific airport and day is defined in \nthis paper as the range of KPI values that fall between the 5th and 95th percentiles of the residual error terms of these \nregression models. In other words, given that the regression model correctly predicts the KPI value considering all \nthe exogenous explanatory factors (i.e., regressor values) for that day and airport, 90 percent of the time the actual \nvalue would be expected to fall into this predicted normal or statistically expected range. A five-step analysis approach is described in the following sections to achieve this goal. This process is depicted \nin Figure 2. Detailed descriptions of each step in the analysis approach follow. Fig. 2 Five-Step analysis procedure for NAS operation anomaly detection Step 1: Clean Data\nThis step includes two tasks: data cleansing and metric calculation. Data cleansing ensures data quality for analysis, and the extent of how to clean the data varied across the different data sources (tables). Data cleansing \ncreated a set of flights used throughout the analysis for all KPIs used for each airport. Data cleansing was performed \nas follows: Thresholds: the following thresholds applied for flights used to calculate each KPI: 1) \nAirborne time above baseline must be greater than -90 minutes\n(Outbound) Taxi-out time must be between 0 and 360 minutes\nTaxi-in time must be between 0 and 120 minutes\n(Outbound) Departure gate delay must be between -60 and 300 minutes \nFlown Distance Difference must be less than 1000 nm. 8 7. The results are de-identified due to potential sensitivities in reporting observed anomalies in published airport \nperformance data in this preliminary research without additional model validation and discussion with FAA \nsubject matter experts. 8. Data associated with May to October in 2016 were excluded due to the large daily variations in the percentage of \naircraft that reported OOOI event data during this period. 9. Data associated with December 2017 were removed from the analysis due to a gap in TFMS data in the MITRE \narchive during that period. Percent of Flights with Reported OOOI Data, or OOOI Ratio (Individual ASPM Flights Table): Only 2) \nflights which report OOOI can be used to calculate accurate taxi-out and taxi-in times. Thus, a day should \nonly be included in the analysis for a specific airport if it has an adequate percentage of flights with reported \nOOOI data. Based on initial data analysis, the 2% of dates with the lowest percentage of flights with reported \nOOOI data were excluded from the analysis, for both the baseline and treatment periods. \nCarrier: Sixteen major carriers had relatively large percentages (~50%+) of flights with reported OOOI data 3) \nin both the baseline and treatment periods. Given that, only these carriers are included in this analysis. Since \nsome carriers had high percentages only in the treatment period, due to input data changes in ASPM, this \nadditional filter was deemed to be warranted, so that both the historical and treatment period had essentially \nthe same mix of carriers. The analysis was performed for eight busy airports in the NAS7. They are denoted as A1 to A8 here after in this \npaper, and these airports make up 33% of total operations during CY2013 through 2017. The KPIs and exogenous factors as discussed previously were then derived with the cleaned set of data. Note \nthat the metrics were aggregated into daily basis at each airport. We collected data from May 1, 2013 to Nov. 30, \n2017 and joined data sets (tables) as needed to calculate the KPI and exogenous factors included in the analysis. \nFigure 3 depicts the performance of all KPIs at the airport A1 with the OOOI ratio. Note that the OOOI ratio is not \ngraphed with the ATER and FDAB, as the calculation of these two KPIs does not depend on OOOI data. Based on the work performed in this step, we defined the baseline period to be from May 1, 2013 to Apr. 30, \n2016 and the treatment period as from Oct. 1, 2016 to Nov. 30, 2017 8,9. 9 Fig. 3 Overview of KPIs trend at Airport A1 with OOOI ratio 10 Step 2: Develop Linear Regression Models\nLinear regression models were developed to formally characterize the relationship between exogenous factors and performance. Models were developed for each KPI-airport combination using the exogenous factors as potential \nregressors based on three years of data (between 5/1/2013 and 4/30/2016). Although there were 21 potential regressors collected during Step 1, only a subset of candidate regressors were \nselected for regression model development based on their correlation metrics: keeping the subset which eliminated \nthis cross-correlation (i.e., regressor multicollinearity) and which retained the regressors that were most correlated \nwith the KPI. Thus, correlation values for any pair of the regressors were inspected and low values were preferred in \nselecting the regressors. Figure 4 shows the correlation matrix among the chosen candidate regressors with correlation values between a \npair of regressors in the upper triangle of the matrix, and data plotting in the lower triangle. The six candidate \nregressors are: Wind Speed Impact (DWII_WSV) 4) \nMinimum Visibility Impact (DWII_MINV)5) \nNear-by Thunder Storm Impact (DWII_NTSV)6) \nEn route Thunder Storm Impact (DWII_ETSV)7) \nDaily Total unrolled demand (Daily_New_ARRDEPDEMAND), and 8) \nExcess Arrival Demand (Daily_EsArrD). 9) 11 \nFig. 4 Correlation matrix among selected regressors 12 This set of regressors results in a maximum correlation value of 0.43 for the DWII_NTSV and DWII_ETSV \nregressor pair. In addition to these six numerical regressors, seasonal factors were treated as categorical regressors in \nthe model with dummy variable (0/1) for spring, summer, fall and winter. Note that winter factor was excluded in \nthe model (or treated as constant term) as there are only three degrees of freedom for the four factors. Thus, nine \nregressors were employed for model development at each airport. Regression models were developed in two phases. The first phase considered all nine regressors, and the second \nphase considered only statistically significant regressors found in the prior result. The former regression models are \nreferred as Raw Regression (RR) model while the latter are called Significance Regression (SR) models hereafter. \nNote that Whites robust regression model techniques [6] were employed in these two phases when developing the \nRR and SR models. The rational for employing the Whites technique is that the heteroskedasticity is typically found \nin real data distribution. Heteroskedasticity occurs when the distribution of the regression model errors (residual \nerrors) is not uniform across the range of values of the regressor variables used to predict the modeled KPI. \nHeteroskedasticity can be detected with the Breusch-Pagan Test [7]. The differences of R2 values between RR and SR models (i.e., RR SR) for each airport and KPI are depicted in \nFigure 5 with the number denoting the significant regressor numbers in the SR model. For example, the largest \ndifference of the R square (R2) values between RR (0.167) and SR (0.137) model was found at airport A3 with KPI \nof TIM for 0.03. There were five significant regressors in its SR model. Fig. 5 Differences between RR and SR models for R2 values and significant regressor numbers R2 values of the SR models were further summarized with Box plots by KPI type and by Airport as depicted in \nFigure 6 and 7, respectively. For the SR models, it shows that the KPI of OB_DGD have highest average R2 value of \n0.7 across all airports while TIM shows lowest average goodness of fit (0.17). The best-fit model is observed at the \nA8 for its OB_DGD metric (R2 of 0.88) and the lowest is TIM at airport A4 (R2 of 0.07). 13 \nFig. 6 R2 distribution by KPI Fig. 7 R2 distribution by Airport 14 Step 3: Apply Models to Treatment Period for Daily Results\nThe expected performance range (EPR) is derived by integrating results of regression model and its residual bounds. Specifically, once a regression model for a KPI and an airport is built, its 5th and 95th percentiles of model \nresiduals were used to create a lower bound (LB) and
upper bound (UB), respectively of the expected performance. \nTogether with the estimates from the regression model, the EPR range is derived by Equation 15. EPR = {LB, UB}\n = {Model Estimate/Prediction + 5% Residual, Model Estimate/Prediction + 95% Residual} (15) The EPR is then used to compare the actual observation values during both baseline and treatment periods. \nBased on actual performance (observation) and the EPR values, each day is flagged as one of Below LB, Normal \n(i.e., within EPR), and Above UB. Since the range is built upon 5 and 95 percentile residual values of the \nregression models, the distribution of observation days for these groups would be 5%, 90% and 5%, respectively, \nduring the baseline period. Such distribution could be employed for testing the treatment period. Assuming that the \nregression model residual errors have the same distribution for both the baseline and treatment periods, the \ndistribution of days in the bottom 5%, mid-90% and top 5% ranges would remain the same, and any variations in the \ndistributions from the baseline would trigger further investigation for our study. Figure 8 and 9 show the \ndistributions during baseline and treatment periods, respectively. Fig. 8 Distribution for days fallen in Below LB, Normal and Above UB group during baseline period Fig. 9 Distribution for days fallen in Below LB, Normal and Above UB group during treatment period Additionally, the comparison of observation and EPR can be focused on daily basis at specific airports. Figure \n10 shows the observations on FDAB with its EPR from SR model at A1 for both baseline and treatment periods. Day \nA in the figure shows one example where performance is captured by the EPR prediction. Specifically, it was \nJanuary 22nd, 2017, during which severe impact from many weather factors were recorded during almost the entire 15 day at A1. Day B in the figure represents an example where the observed value was above the EPR prediction. This \nfigure also captures the cyclic pattern on FDAB performance due to seasonal effect. The shaded green area shows \nthose five months data in 2016 excluded in this study. A zoomed-in view for January 2017 is depicted in Figure 11. 16 TreatmentBaseline A B A1 Fig. 10 Daily plot for Observation and EPR performance of FDAB at A1 during baseline and treatment periods 17 Fig. 11 Daily plot for Observation and EPR performance of FDAB at A1 during Jan. 2017 Step 4: Identify Multi-Month Periods with Anomalous Performance\nThe first task in this step was to identify months that had a high number of days that were outside of the expected performance range. These are referred to herein as anomalous months.\nTo achieve this, data associated with the treatment period were inspected month by month for each KPI and airport. The theoretical 5% thresholds for Above UB and Below LB groups were employed in a Binominal Statistic \ntest. The null hypothesis (H0) was that a tested percentage of observations that were either Above UB or Below LB \nwithin a month was equal to or below 5%. The tested percentage was taken from the observations (Above UB or \nBelow LB) over the total number of days in a month. Given a tested percentage against the threshold level (5%), the \nBinomial Test returned a P-value indicating whether H0 should be rejected or accepted (cannot be rejected). In cases \nwhere more than 5% of the observation days during a month period were flagged as Above UB/Below LB, the \nalternative hypothesis (H1) was accepted (i.e., reject H0). This test was conducted for each of the eight KPIs and eight airports for each month in the treatment period, and \nthe result was the identification of anomalous months during the treatment period for either Above UB or Below LB \naccordingly. The results are shown in Figure 12, where the months Above UB and Below LB are denoted with red \nX and blue O, respectively. 18 Fig. 12 Binominal test result for KPI and Airport during treatment period 19 The second task in this step was to inspect the month-level results to identify consecutive periods with \nanomalous performance. This process was conducted for Above UB and Below LB groups separately with a \npreliminary threshold of consecutive three months (i.e., one season). There were 137 such anomalous periods \nidentified during the treatment period for all eight KPI across all eight airports. Note that the length for each \nanomalous period (in terms of number of months) varies for each KPI and airport. For example, we identified \nBMAB at A5 from May 2017 to Nov. 2017 (seven months) to be anomalous. During this period, more days were \nobserved above UB of BMAB EPR. On the other hand, we identified this KPI at A2 to have more observations \nbelow LB between Oct. 2016 and Feb. 2017. This finding will feed to next step in quantifying performance changes \nfor each anomalous period. Step 5: Identify Multi-Month Trends\nThe fifth step was to inspect the anomalous periods to determine whether the average value of the KPI (mean and median) were different between the baseline and treatment periods. This step was used to down-select to periods \nthat were aberrant in both the number of extreme values observed, and the general performance observed across the \nentire period. To do this, the following two statistic tests were conducted on the anomalous periods identified in step 4: \nMann-Whitney-Wilcoxon (MWW) Test: MWW test is a non-parametric statistic test for independent two 1.\ndata samples with a null hypothesis (H0) that they have identical population distribution. This test does not \nrely on an assumption of normal distribution of the population and can be used to quantify median \ndifferences for the two samples. The P-value, median shift and confidence interval of the tested two samples \nwas calculated for statistical inference. [8] \nStudent-T test: Student-T test is conducted with a null hypothesis of equal mean between two samples. 2.\nAlthough relying on assumptions of random, independent and normal distributed for both samples, the T-\ntest is wildly used and could be applied to infer mean differences on certain KPI at selected airport between \nthe baseline period and the anomalous period. The T-test gives results of P-value, 95% confidence interval \nof the mean difference using unpaired t-value formula as Equation 16 and degree of freedom as defined in \nEquation 17. [8] (16) (17) We exercise this step using the results from Step 4 and quantify drifts of the KPIs as shown in Figure 13. In this \nfigure, a highlighted red or green bar shows an anomalous period for at least three consecutive months (one season) \nwith statistically significant differences on both mean and median drifts from the baseline period (May 1, 2013 to \nMay 1, 2016). The red and green bars indicate Above UB and Below LB, respectively. 95% confidence intervals for \nthe mean differences are denoted in the figure. For example, at the A1, during Apr. and Jul. of 2017, the average \nFDAB is estimated to perform significantly above UB with a range from 7.5 to 13.5 miles. At A2, the average \nBMAB was significantly below LB from 1.8 to 3.2 minutes during Nov. 2016 and Feb. 2017. Moreover, A4 and A7 \ndo not observe any anomalous period with more than three months during the treatment period, and no significant \ndifferences of Above UB or Below LB are found at the eight airports during the same period on DGD and OB_DGD. 20 Fig. 13 Anomaly periods identified for KPI and Airport with significant mean differences against treatment period 21 Discussion of ResultsVI. \nThe performance of the models and the performance of the model results were inspected for consistency and alignment with expectations. Further work would be needed to formally validate the models, and this discussion \noffers a starting point. Three performance checks were performed, and they are enumerated below. A. Review overall model fits across airports and across metrics.\nBecause the choice of regressors was limited to variables that could be categorized as exogenous, an R2 of 0.5 or above was chosen as the threshold for an acceptable model fit. Table 1 below lists the R2 values for each model by \nKPI and airport. Acceptable fits are shown in green, and unacceptable fits are shown in orange or red. Table. 1 R2 Values for Each Linear Regression Model BMAB, DGD, and TOM had acceptable fits at each of the airports studied. DGD and TOM were two metrics \nthat had outbound aggregations as well. The difference between these two was that for the outbound metrics, both \nthe performance and the regressors were measured at the departure airport; for the original metrics, the performance \nwas measured at the departure airport, but the regressors were measured at the arrival airport. This indicates that \nweather and demand conditions at arrival airports are good explainers of performance for departures. This is sensible \ngiven that the airports studied were some of the busiest in the NAS, so conditions at those airports would be expected \nto have significant upstream effects. These upstream effects are likely due to the issuance of TMIs by the FAAs \nATCSCC during
times of actual or expected weather constraints. Those TMIs push delay to upstream facilities. [9] TIM had poor R2 performance at each of the airports studied. This is likely due to the effect of airport surface \ncongestion, which was not directly included in the regressors. The poor quality of TIM R2 performance did not have \na large impact on BMAB performance even though it is one of the components of block time. The other two components of BMAB, ATER and TOM, had R2 values that aligned well with those values for \nBMAB. It was expected that TOM would match BMAB well because much of the variation in block time comes \nfrom variation in predeparture operations. Once the flight is in the air, variation in flight time is limited. Comparing the fits for ATER and FDAB at each airport is a useful exercise for model verification because the \ntwo metrics are measured for the same portion of flight (i.e., from Off to In). ATER and FDAB had very similar \nR2 results at each airport studied. The largest difference between the performance of the two variables was at A8 \nwhere ATER was .37 and FDAB was .59. Further study would be needed to determine the underlying cause of this \ndifference at the airport. B. Review anomalous period results for each airport across metrics.\nAs mentioned above, two types of anomalous periods were identified in this analysis: periods where the adjusted performance was worse than expected, and periods where the adjusted performance was better than expected. One \ncheck for internal consistency was to show that, at a given airport, there were no overlapping periods that were \ndefined as underperforming under one KPI and overperforming under a different KPI. 22 C. Review consistency between FDAB and ATER results. \nThey should be roughly in agreement because they measure performance for the same segment of a flight (the Off to On segment). The results of the FDAB KPI and the ATER KPI were consistent, though not perfectly in \nalignment. Problematic periods identified using FDAB did not overlap with those identified using ATER (see Figure \nFig. 13 above); however, they were also not in conflict (i.e., periods of overperformance under one metric did not \noverlap with periods of underperformance with the other). VII. Conclusions and Next Steps\nIn conclusion, this analysis provides a promising approach for streamlining post-operations analysis. It achieves this through a formal method that accounts for weather and demand in evaluating performance across eight KPIs. It \nthen applies statistical tests to identify trends of over- or under-performance associated with different airports. The \nmodels that were developed passed several consistency checks, indicating readiness for further validation. There are two main recommendations for next steps aimed at improving the accuracy of the models and building \nvisualization tools to help users interpret the model results. The first recommendation is to adjust the models to \ninclude the impact of forecast weather as well as the impact of the actual weather (this study was limited to actual \nweather impacts). Traffic management decisions are usually made in advance based on forecasts of capacity and \ndemand changes, so forecast weather is a critical driver of performance. Further, metrics should be developed to explicitly reflect the accuracy of weather forecasts by comparing the \nforecasts to the observed weather. This comparison should also account for the lead time of multiple forecasts for \neach time-period (e.g., 8 hours ahead, 4 hours ahead, and 2 hours ahead). The importance of different lead times may \ndiffer for different airports due to the characteristics of its flights. Airports on the coasts must make TFM decisions 6-\n8 hours ahead of time to be able to significantly affect transcontinental arrivals. The second recommendation is to prototype user-facing visualizations that present the results in understandable \nand actionable ways. This would be the first step in developing a capability driven by these models to inform post-\noperations decision making. Such a capability would help quickly identify areas of under- or over-performance and \nallow the FAA to begin addressing problems (or identifying best practices) shortly after they arise. References [1] Cooper, W., Esmaeilzadeh, E., Flynn, B., and Schrader, P., Challenges in Developing an Aviation Operational \nPerformance Dashboard: Identification of Quantitative Performance Anomalies Using Statistical Limits, \nIntegrated Communications Navigation and Surveillance (ICNS) 2016. [2] Montgomery, E.P., Introduction to Linear Regression Analysis, 2nd edition, John Wiley & Sons, 1992.\n[3] FAA ASPM Flight Level Measures, http://aspmhelp.faa.gov/index.php/ASPM:Flight_Level, accessed October 2017.\n[4] FAA ASPM Airport Quarter Hour Data Dictionary, http://aspm.faa.gov/aspm/Dict_AirportQtr.pdf, accessed October 2017.\n[5] FAA ASPM Weather Factors Manual, http://aspmhelp.faa.gov/index.php/ASPM_Weather_Factors_Manual, accessed October 20, 2017.\n[6] White, H., A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity, Econometrica, Vol. 48, Issue 4 pp. 817-838, 1980. \n[7] Breusch, T., and Pagan, A., A Simple Test of Heteroskedasticity and Random Coefficient Variation. Econometrica Vol. 47, pp. 1287-1294, 1979.\n[8] Yau, C., R Tutorial with Bayesian Statistics Using OpenBUGS, r-tutor.com.\n[9] FAA, JO 7210.3AA Facility Operation and Administration, Federal Aviation Administration, Washington, DC, 2017. NOTICE http://aspmhelp.faa.gov/index.php/ASPM:Flight_Level\nhttp://aspm.faa.gov/aspm/Dict_AirportQtr.pdf 23 This work was produced for the U.S. Government under Contract DTFAWA-10-C-\n00080 and is subject to Federal Aviation Administration Acquisition Management \nSystem Clause 3.5-13, Rights In Data-General, Alt. III and Alt. IV (Oct. 1996). The contents of this document reflect the views of the author and The MITRE \nCorporation and do not necessarily reflect the views of the Federal Aviation \nAdministration (FAA) or the Department of Transportation (DOT). Neither the FAA \nnor the DOT makes any warranty or guarantee, expressed or implied, concerning \nthe content or accuracy of these views. 2018 The MITRE Corporation. All Rights Reserved. Approved for Public Release; Distribution Unlimited; Case Number: 18-1615 _top\n _Hlk512431216\n _Ref513029069\n _Ref513034621\n _Ref513035192\n _Ref512522984\n _Ref513034177\n _Ref512523062\n _Ref512523092\n _Ref512523178\n _Ref512523206\n _Ref512523249\n _Ref512523259\n _Ref512849732\n _Ref512868023\n _Hlk511050777\n _Ref512523349\n _Ref513033840\n _Ref512523359\n _Ref513033895\n _Ref512603853\n _Ref513035835\n _Ref513035828\n _Ref513033951\n _GoBack ",
    "text": " Microsoft Word IoT_Wintersim18_V12_04-16-18_ne.docx Proceedings of the 2018 Winter Simulation Conference \nM. Rabe, A.A. Juan, N. Mustafee, A. Skoogh, S. Jain, and B. Johansson, eds. TAMING COMPLEXITY AND RISK IN INTERNET OF THINGS (IOT) ECOSYSTEM \nUSING HYPERGRAPHS AND SYSTEM ENTITY STRUCTURE (SES) MODELING Saurabh Mittal \nSheila A. Cane Charles Schmidt \nJohn Tufarolo Richard B. Harris \nThe Homeland Security Systems Engineering and Development Institute (HSSEDI)TM Operated by The MITRE Corporation \n7515 Colshire Dr., \nMcLean, VA, USA {smittal, sheila, cmschmidt, tufarolo, rbharris}@mitre.org ABSTRACT The emerging Internet of Things (IoT) ecosystem is a phenomenon already in the process of deployment. \nVarious software/hardware system engineering stacks have mushroomed allowing new and legacy smart \ndevices to connect to the Internet while simultaneously lacking the notion of a system. Modeling an IoT \necosystem is a challenge due to fuzzy system boundaries as the same device may be employed in \nnumerous different contexts. This fuzzy boundary introduces risk in the overall IoT ecosystem. This paper \nexplores the definition and meaning of an IoT ecosystem and the complexity inherent within this system \nthat could have entirely unique characteristics from the convergence of Information Technology (IT) and \nOperational Technology (OT) components. It then presents an IoT ecosystems theoretical model using \nhypergraphs and System Entity Structure (SES) theory to propose an IoT-Inclusive-Systems model and an \nassociated risk evaluation framework. This theoretical model can provide a basis towards modeling IoT \necosystem as a whole to understand the new normal, a device-centric world view in an IoT-Inclusive-\nSystem. Keywords: Internet of Things, hypergraphs, system entity structure, complexity, risk management 1 INTRODUCTION The Internet of Things (IoT) is a relatively new and rapidly growing phenomenon. There is considerable \nand growing concern the rapid deployment of new, connected IoT capabilities will change the risk profile \nwithin and across many existing technology-driven and technology-enhanced environments. IoT, including \nits IT and OT components, introduces the possibility of greater physical consequences to vulnerabilities \nwithin an IoT system. The differences in the traditional risk perspectives of the IT and OT communities \ncould constrain a comprehensive evaluation of IoT risk when an approach that integrates these perspectives \nwould produce better results. Because of this rapidly changing environment, there is a need for a model or \nframework to be used to explore the larger question of whether systemic risks are increased given specific \nIoT deployments. While there is theoretical and practical modeling work being pursued from a technology \nperspective, there are no systematic models representing IoT systems along with their environment that \ncould contribute to a comprehensive risk assessment leading to more complete risk mitigation \napproaches. Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Mittal, Cane, Schmidt, Tufarolo and Harris Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 A theoretical model describing the IoT ecosystem is needed to provide methods to describe variations in \nIoT implementations, their relationship(s) to the environment, and associated risk implications. The purpose of this research is to develop an IoT theoretical model, and describe how such a model could \nbe used to perform risk assessments in IoT-centric systems. This paper reflects the foundational research \nbehind establishing this theoretical IoT model and related environment considerations, and is meant \nprimarily to provide the community (both academic and government) with a foundation which can be built \nupon to analyze the risk implications of these systems as they become pervasive. IoT modeling is a relatively new concept. The National Institute of Standards and Technology (NIST) \ndeveloped an IoT model conceptualizing five elements (Voas 2016): sensors, aggregators, communication \nchannel, external utility and decision triggers, to define the utility of devices constituting an IoT system. \nOther models (Huang and Li 2010) have also tended to focus on a small number of IoT aspects (e.g., cause-\neffect chaining, focus on connectivity and network topology, etc.) By contrast, the work presented here is an attempt to provide a unified model capable of capturing a broad \narray of factors impacting IoT systems. These include, but are not limited to, aspects of the devices \nthemselves, connectivity, connected services, policies, users, physical structures, and many more. This \npaper explores methods to allow all of these IoT system facets to be captured in a unified model in such a \nway as to support rigorous analysis methods. While the work presented here is limited to an initial IoT \necosystem theoretical model with the associated analytics yet to be developed, the authors believe the \npresented methods provide a promising path by which IoT systems can be understood with sufficient \ncontext and within their broader environment to support a more comprehensive framework for \nunderstanding IoT system risks. This paper describes the initial research results to develop a theoretical IoT model. Section 2 samples \nvarious IoT definitions and presents a device-centric world view. Section 3 presents an overview on \nhypergraphs, followed by SES theory in Section 4 that describes the pruning process as applicable to an \nSES model resulting in a Pruned Entity Structure (PES). Section 5 discusses the inherent complexity in \nIoT-Inclusive-System. Section 6 presents the IoT theoretical model. Section 7 discusses the integrated risk \nevaluation framework followed by conclusions and future work in Section 8. 2 IOT DEFINITION AND DEVICE-CENTRIC WORLD VIEW The IoT is a relatively recent and evolving phenomenon, sharing a concurrently evolving definition. When \nused as an acronym in itself, IoT signifies the entire IoT ecosystem. However, the usage of this acronym \nchanges with every definition. Most IoT definitions arise from the fundamental perspective anything \nconnected to the Internet becomes a part of an IoT (while neglecting to actually define IoT) (Cisco n.d.). \nMost definitions acknowledge two semantic elements: the Thing and the Internet. A Thing is defined \nas a physical device which is supplemented with a computing capability (on-board or remote), such that it \nbecomes smart, and has both software and hardware interfaces allowing it to connect to the Internet \n(Mckinsey n.d., CASAGRAS n.d., SIG 2013). Some IoT definitions include business processes, services, \napplications and infrastructure to support the various things (Haller n.d., CERP-IoT n.d.), while other \nresearch perspectives include virtual entities, virtual personalities, and all the miscellany of commerce and \nculture (Berge 1973), including real people (NIC n.d., Sundmaeker, Guillemin and Woelffle 2010, U. F. \nGroup 2011, Lee, et al. 2011, Domingue, Fensel and Traverso 2008). A particularly compelling IoT definition is provided by UK Future Strategy (U. F. Group 2011): An evolving convergent Internet of things and services available anywhere, anytime as part of an all-\npervasive omnipresent socioeconomic fabric, made up of converged services, shared data and an Mittal, Cane, Schmidt, Tufarolo and Harris advanced wireless and fixed infrastructure linking people and machines to provide advanced services \nto business and citizens. Consequently, every IoT system has a purpose: i.e., it serves a community/a group of users/people. \nFurthermore, any device that gets connected to the Internet without a purpose introduces unnecessary risk. \nWe define an IoT system as: A complex system consisting of a collection of interconnected smart devices that may span a single \nuser, a community, a region, a nation or across nations; provides services within an emerging or an \nexisting system; is distributed across the Internet; and incorporates inherent risk. Together, all the devices deployed to serve a purpose/use-case, with all the underlying infrastructure, \nconstitute an IoT ecosystem, largely called just an IoT. To fully model an IoT essentially requires modeling \nthe network and the things, as well as the various contexts in which these two are used. Figure 1 displays a device-\ncentric view of this IoT \ndefinition. The IoT-device \nparticipates in multiple \ncontexts, across multiple \nsectors/application-domains. \nEach ring represents an activity \nscope (e.g. local, near \nneighborhood, regional, state, \nnational and global reach). \nEach ring has a logical \nboundary representing the data \nexchange between different \nregions through the access \npoints. As you move out \ntowards the edges, the scope, \nscale and possible effect of IoT \nimplementation increases. Figure 1: Device Centric View of an IoT system Figure 1 presents two use-cases as applicable to two different sectors (for example, electricity and water \nsectors A and B respectively). It comprises of two use-cases/scenarios depicted as Walk 1 and Walk 2. \nWalk 1 is a user-oriented regional scenario using resources only in Sector A and operates up to a regional \nscale. Walk 2 utilizes the network and resources belonging to both Sector A and B and operates on a larger, \nglobal scale. 3 HYPERGRAPHS To understand the modeling approach, a fundamental understanding of mathematical Graph theory and SES \ntheory are essential. In simple terms, a graph or network is a collection of nodes and edges representing a \nproblem space. Nodes represent elements of interest, for example, people, places, activities or systems. \nEdges reflect the relationships between those nodes. A hypergraph is a graph in which an edge connects \nmore than two vertices (Berge 1973, Zhou, Huang and Schoelkopf 2006, Bretto 2013, Gallo, Longo and \nPallottino 1993) and is used to represent many-to-many relationships in a mathematical way. An edge in a \nhypergraph is called a hyperedge and connects more
than two nodes. Hypergraphs are very useful for \nmodeling social networks where entities can belong to more than one group. For example, families in \na Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Mittal, Cane, Schmidt, Tufarolo and Harris large community can be represented by a hypergraph (Newman 2010): One person can be in a family and \nin a community, and another person in the same community but in a different family. Almost all complex natural systems display many-to-many relationships characterizing them as non-linear \nand consequently, difficult to model. Hypergraph analysis shows the multiple ways a particular node or \ncomponent relates to other nodes. Hypergraphs, in a short span of two decades, have found applications in \nwide variety of scientific fields. Disciplines employing hypergraph analysis include molecular chemistry, \ntelecommunications, psychology, genetics, computer aided manufacturing, very large scale integrated \n(VLSI) circuits, hierarchical complex systems and various human activities (Bretto 2013). Lately, it has \nbeen applied to engineering information systems and social network analysis, where relationships are \nsupra-dyadic (i.e. involving more than two participants, e.g. a financial transaction involves buyer, seller \nand broker) and also in analyzing the partitioning and concurrent process design in a service-oriented \narchitecture within a Cloud environment (Molnar 2014). A hyperedge within a hypergraph is the easiest \nmethod to model multi-node relationships. Figure 2 contains an example of a hypergraph (Philippe Jgou a 2009). Overlaying a family example on \nthis graph, nodes X15, X16,, in hyperedge e7 (upper right corner) are members of a family, but they are also \nmembers of the hyperedge e5, which represents the community. Due to the IoT modeling problem complexity, and the preponderance of many-to-many relationships, we \nposit the IoT model is best represented by a hypergraph. Mathematically, hypergraphs are expressed using \nSet theory. However, this mathematical representation is not amenable for modeling purposes. There is a \ndearth of tools supporting formal hypergraph modeling. System Entity Structure (SES) theory based on Set \ntheory provides a means to model hypergraphs and thereby manage their inherent complexity. Figure 2: A Connected Hypergraph Figure 3: SES Application 4 SYSTEM ENTITY STRUCTURE (SES) HYPERGRAPH MODEL Hypergraph modeling is a complex endeavor with no rules to specify the structure. The SES theory (Zeigler \n1984, Zeigler and Zhang 1989, Zeigler, Praehofer and Kim 2000) is a formal ontology framework to capture \nsystem aspects and their properties. The underlying SES axioms provides the needed constraints to bring \nstructure to the modeling process these axioms can be found in (Zeigler 1984). A complete SES model \nformally describes a solution set containing all permutations and combinations available for modeling an \nactual system. Figure 3 conceptualizes the SES modeling process (Mittal and Martin 2013). It shows the \ncomplete solution set, represented by the large triangle, which represents the totality of a theoretical model. \nFor each instantiation of the model, the theoretical model is pruned to only those elements required for the \ninstance. Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Mittal, Cane, Schmidt, Tufarolo and Harris SES modeling semantics is constructed of the following elements: \n Entity (a physical entity or a concept represented as a label);\n Aspects (decomposition: is made up of): Denoted by a vertical bar ( | );\n Specializations (can be of type: is a type of): Denoted by a double vertical bar ( || );\n Multi-aspect (decomposition into similar type: is made up of many such): Denoted by a triple vertical bar ( ||| ). It also has a variable n, that specifies the number of entities in the relationship;\nand Variables (each entity has variables that have a range and value): Denoted by ~. This research suggests SES framework can be applied to model hypergraphs in support of IoT modeling. \nAs an example, consider the IoT-Inclusive System in Figure 4 represented as an SES. An IoT-Inclusive-\nSystem is a general system having IoT-specific elements. Figure 4 can be read as follows. The IoT-\nInclusive-System has two aspects; network aspect and physical aspect, labeled net-asp and phy-asp \nrespectively. These aspects are realized as the entities Network and Things. The Network entity has a \nconnectivity-asp aspect, which includes the entities Connections and Resources. Connections entity consists \nof many Connection entities. A Connection can be specialized using the connect-mode-spec into Wired or \nWireless entities. A Connection entity through the connect-protocol-aspect has a Communication Protocol. \nA Communication Protocol entity can be specialized using the protocol-spec into IP, Bluetooth, ZigBee or \n802.x entities. Things are comprised of many LogicalDevice entities. The multi-aspect Things and\nConnections contain millions of Things and millions of Connection entities. Together with all the choices, the \nIoT-Inclusive-System SES represent \nall the possible architectures at a \nvery high level of abstraction for a \ntechnology-only solution. From the \npermutation and combinations \nperspective, for example, assuming \nwe have 10 Things and 50 \nconnections between these 10 things \n(although a total of 100 connections \nare possible), there are about 4000 \nconfiguration options possible for \nIoT-Inclusive System (2 Connection \nx 4 Communication Protocol x 10 \nThings x 50 Connection). For \nbrevity, Resources entity is not \ndescribed in this example. Figure 4: Notional IoT Inclusive System 4.1 Pruned Entity Structure (PES) Hypergraph Model SES has been shown to work as an ontological framework and is typically used to lay out the design space \nfor complex information systems. Each configuration option in the design space may be applied to a specific \nuse-case and thereby specify the needed architecture (Zeigler and Hammonds 2007, Mittal and Martin \n2013). To systematically explore varying implementation options for specific use-cases (a.k.a. scenarios), \nthe complete SES model is pruned into only the essential elements relating to the scenario. The resulting \nSES is called a Pruned Entity Structure (PES). The SES allows coverage of all the semantic permutation \nand combinations available for articulating any particular system in a formal manner. The PES can be \ncontinuously pruned to reduce the available options to get closer to the problem-at-hand. Figure 5 shows Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 net-aspect connectivity-\naspect Connections Resources connection-mutiasp Connection connect-\nmode-spec Wireless Wired connect-\nprotocol-aspect Communication\nProtocol ~ range Network protocol-\nspec IP Bluetooth ZigBee 802.x phy-aspect ld-multi-aspect LogicalDevice Things IoT-Inclusive-System ~ n=millions ~ n=millions spec entity aspect multi-aspect ~ variable Is-made-of: Used for Decomposition (AND) Is-type-of: Used for options/choices (OR) Of-many-such: Used for many of same type (AND) A physical or virtual object A variable that has a range of values LEGEND Mittal, Cane, Schmidt, Tufarolo and Harris the pruning process. The resulting PES acts as a Reference Architecture, as it provides enough constraints \nto represent the particular domain within a family of architectures. Figure 5: PES generation through an iterative process (Mittal and Martin 2013) The IoT-Inclusive System design space shown in Figure 4, when pruned for a specific use, such as 10 \nThings and 50 Connections, yields the PES in Figure 6. Note the options have been reduced to actual \ncomponent numbers. Once we have the PES, various use-cases can be constructed allowing entity \nnavigation with the PES. An execution of a use-case involving entities in SES is called a Walk. This is \nanalogous to a Graph Theory walk as described in Section 2 for Figure 1. Figure 6 shows a walk with two \nLogicalDevices communicating over the Network. This walk is represented as a sequence of numbers on \nthe PES entities. As a PES still contains a lot of permutations, a walk in PES is a higher level of abstraction. \nAs the PES is continuously pruned (Figure 5), it eventually leads to a very specific implementation: an \narchitecture of the IoT-Inclusive System with explicit components. This transforms PES into a Component \nEntity Structure (CES) (Mittal and Martin 2013). To demonstrate the relationship between SES modeling \nand hypergraph models, a simple two-device IoT from the PES shown in Figure 6, is presented as a \nhypergraph in Figure 7. It identifies four hyperedges: e1 (purple), e2 (green), e3 (brown) and e4 (black), \nconnecting entities in the example IoT-Inclusive-system PES. Hyperedge e1 relates LogicalDevice-1, \nResource-System-Router, and Connection-Wired-1. Further, it also shows LogicalDevice-1 is a part of two \nhyperedges, e1 and e4. Figure 6 and 7 illustrate how an SES representation can be depicted as a hypergraph. \nDescribing the underlying mathematical transformation functions is outside the scope of this paper and will \nbe reported in future publications. 5 THE IOT COMPLEXITY Undesired functionality is a significant concern in highly complex systems. A device or system can exhibit \nundesired functionality either because such functionality was unintended (e.g., software vulnerabilities \nintroduced in development causing unexpected behavior), or because it was unplanned (e.g., functionality \nintentionally designed into the device, but unexpected by the end-user). Unfortunately, as has been \ndemonstrated in the IT world by security breaches and failures, such unexpected functionality is almost \nimpossible to eliminate. Both unintended and unused functionality results in undesired system behavior, \nand in highly complex systems can have cascading repercussions. IoT devices add a new type of operational complexity. Information technology systems, by definition, are \ninformation centric. When these systems display undesired functionality, it typically impacts
information. \nIoT systems, however, commonly fall under the term Operational Technology, and add a new dimension \nin that they have a physical component. They can often directly manipulate or respond to the physical world \nand/or directly respond to it. The result is a manifold increase in the possible consequences from undesired \nfunctionality. These now include, but are not limited to, impacts on physical property, availability of critical \nservices, availability of physical resources, potential impacts on the environment, and potential threats to \nhuman health and safety. Taming system computational complexity is a difficult and ongoing challenge. To do that, it is critical to \nhave a means to understand each system, its dependencies and interdependencies, and to understand how Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Mittal, Cane, Schmidt, Tufarolo and Harris failures of one component impacts aspects of the whole. With the rise of IoT and its corresponding expanded \nimpact pattern, an optimal mitigation strategy needs to encompass the new range of physical impacts as \nwell. Figure 6: PES for IoT-Inclusive System Figure 7: PES hypergraph with only two LogicalDevice and two Connection-Wired entities The following section presents an approach to modeling systems with IoT devices. This modeling approach \nprovides a way to apply rigor to the problem of tracing operational dependencies within such a system as a \nmeans to highlight potential vulnerability sources. By identifying the most likely cascading failure sources, \nand tracing the failure consequences to any eventual physical impact, one can determine how best to apply \nmitigations that avoid the most damaging cascades (Zimmerman and Restrepo 2009). While this model \ncannot predict the unpredictable (e.g., which systems will be attacked, or which will have a software \nvulnerability), it can help one understand the relationship between components and better clarify where risk \nmitigation strategies will be most effective. 6 IOT MODEL In order to model the IoT in its environment, we identify the following fourteen perspectives. Each \nperspective is necessary to understand the multi-dimensional nature of IoT. The perspectives are \nenumerated in Table 1. Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 net-aspect connectivity-\naspect Connections Resources connection-mutiasp Connection-Wired connect-\nprotocol-aspect Communication\nProtocol-IP ~ range Network phy-aspect ld-multi-aspect LogicalDevice Things IoT-Inclusive-System ~ n=50 ~ n=10 1,3 2\nUse-case: Two Logical Devices \ncommunicating over network Graph Walk (in sequence): \n1. Logical Device\n2. Network\n3. Logical Device The communication from the leaf \nnodes goes up the hierarchy until it \nfinds a common link to the parent of \nthe destination leaf. Mittal, Cane, Schmidt, Tufarolo and Harris Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Table 1: Fourteen IoT-Inclusive System Perspectives ID Perspective Description 1 Behavior Describes the overall macro IoT behavior as a whole. The behavior could be \nemergent (i.e. IoT resulted from devices just being connected to the Internet) or \nengineered (i.e. IoT resulted from following engineering practices). 2 Application \nDomain Identifies various environmental variables and properties that monitor the \nusefulness of a particular IoT solution and its application to a single or multiple \nsectors. It also describes the effect a particular IoT solution has on a sectorial basis. 3 Physical \nstructure Describes the logical structure of a Thing: a sensor, an actuator, an aggregator \nassembling multiple inputs for a single output, or more specifically, a computing \ndevice having variable computational power levels. 4 Services Describes various services a Thing consumes or provides to other components on \nthe Network. Essentially, IoT solves a business problem or creates opportunities \nto develop new business cases, eventually leading to formulation of new business \nprocesses. 5 Resources Describes resources, their management and supply-demand within an IoT system \ndeployment 6 Information Describes the knowledge structure as it is exchanged between resources, across \nnetwork and various Things. 7 Network Describes the network structure between two Things. The geographical distance \nand relative compatibility between two things may ultimately decide what kind of \nresources are invoked along the pathways. 8 Vulnerability Describes the vulnerability inherent in the IoT deployment across multiple \nperspectives. The vulnerabilities need to be specified at the intersection of various \nperspectives define in this list. Various scoring systems such as Common \nVulnerability Scoring System (CVSS) (First.org n.d.), Common Weakness \nScoring System (CWSS) (Coley 2014), etc. can be used to assess vulnerability \ninherent in an IoT deployment. 9 Organizations Describes various organizations having vested interest in a given IoT deployment. \nMultiple organizations may be involved in multiple IoT deployments requiring \nshared services, resources, information and applications 10 Security Describes security mechanisms and technologies 11 Privacy Describe privacy mechanisms and technologies 12 Analytics Describes the analytics required to ascertain the correct functioning of an IoT \ndeployment. These will involve both macro and micro levels so that the impact \nand influence of a Thing can be viewed in relation to a particular Application \ndomain or Sector as a whole. Eventually, such analytic frameworks will be used \nfor instrumentation and control at a critical infrastructure level. 13 Policy Describes the relationship between multiple perspective to specify and define \npolicies at the intersection of various perspectives. Mittal, Cane, Schmidt, Tufarolo and Harris Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 14 Users Describes the users involved in an IoT deployment. It may include the end-user, \nthe transient user (i.e., a user who indirectly uses an IoT as in third-party services, \ne.g., marketing services), and the organizations that use the applications within a\ntypical IoT deployment. The perspectives described in Table 1 portrays an abstract IoT-Inclusive system representation. Each \nperspective is modeled as an SES aspect. The SES model can help identify relationships between various \nIoT perspectives that need to be considered for an IoT deployed solution. These relationships are depicted \nby walks as described for Figure 6. Figure 8 provides a sample depiction of an IoT-Inclusive SES model. \nThis model exhibits the following options: Ignoring the multi-aspect numbers, we have: (2 Behaviors) x (4 LogicalDevice types) x (3 Services) \nx (2 Connection types) x (5 CommunicationProtocol types) x (2 Timeliness analytics types) x (6 \nComputingAnalytics types) x (4 ResourceItems types), resulting in 12000 IoT deployment \noptions/use-cases. This number does not even consider the combinations associated with entities: \nResource, DataElement, Domain, Capability, AttackEffects, and Orgs. One can easily imagine the \nincrease in permutations from thousands to millions of options. As stated earlier, each structural option enumerated in the above permutation can be realized as a valid \nsystem architecture. This exploration also involves constraints and scores attributable to each of the nodes \nthat may help in overall risk assessment. Conducting performance and risk analysis on each option shown \nin this high-level model would be resource intensive and cost-prohibitive. As more constraints are added \nby applying the pruning process, the IoT model moves closer to the specific IoT solution, and therefore, the \nrisk quantification should become more tractable, both visually and mathematically. Figure 8: IoT-Inclusive System Entity Structure (sample depiction) dom-multi-\naspect analytics-\nsystems-aspect IoT-Inclusive-System Behavior Domains Things Services Resources Information Network Vulnerability Security Analytics Policy Users* Privacy beh-aspect app-aspect phy-aspect serv-aspect res-aspect info-aspect net-aspect vul-aspect analytics-aspectsec-aspect pol-aspect Beh-spec Emergent Designed Domain* ld-multi-aspect LogicalDevice res-multi-aspect serv-multi-\naspect Service Resource* Timeliness Computing Infrastructure time-spec Data\nTimeliness Analysis\nTimeliness method-spec NeuralNetwork BigData DeepLearning SimpleStats TrendAnalysis PatternMatchers infra-spec Resource phy-structure-aspect Connection Information FormFactor Services mode-spec InputDevice OutputDevice AggregatingDevice ComputingDevice actuate-multiasp Actuators Sensing-multiasp Sensors aggregate-multiasp Aggregators indevice-spec outdevice-spec procdevice-spec Sensor Actuator Aggregator analytics-\nsystems-aspect connectivity-\naspect Connections Resources* connection-\nmutiasp Connection connect-\nmode-spec Wireless Wired connect-\nprotocol-aspect Communication\nProtocol ~ range analytics-aspectinfo-aspect computing-multiasp ComputingDevice protocol-spec IP Bluetooth ZigBee 802.x org-aspect Orgs* user-aspect DeviceService Telnet DNSQuery serv-spec pri-aspect Mittal, Cane, Schmidt, Tufarolo and Harris Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 The theoretical model brings forward fourteen perspectives in a foundational IoT-Inclusive-System. It \nshows how various entities constitute cross-references in different nodes, resulting in hyperedges that have \nentire graphs on either side of the hyperedge. Associating various vulnerability types and risk scores to each \nof the entities in the abstract model yields the needed abstraction level to understand the risk impact at a \nmacro level. Further specification of constraints helps us understand risk for a family of IoT-Inclusive-\nSystems. 7 INTEGRATED RISK EVALUATION FRAMEWORK IoT bridges IT, which is primarily concerned with data processes and OT, which is concerned with physical \nprocesses. Both IT and OT have mature and robust risk assessment and management methodologies. \nHowever, now that these communities are connected by IoT, differences in each communitys perspective \ncan skew or result in incomplete, risk assessments. Understanding the potential technical consequences \nassociated with a device or functional unit is only one, early piece in a procedure for understanding the \noperational risk associated with that device. To understand operational risk, technical consequences need \nto be turned into operational consequences, which are expressed in terms of their impact on the IoT-\ninclusive system as a whole. Doing this requires an understanding of the context in which a given technical \nconsequence occurs. This sort of context could be provided by associating the technical consequence with \nelements in a model of the IoT system, such as described in
the IoT-inclusive SES model. By using such a \nmodel, one can place a technical consequence in the context needed to understand what, if any, operational \nconsequence could result from that technical consequence. The concepts provided in previous sections can be combined into a theoretical risk evaluation framework. \nThe steps in this framework are as follows and shown in Figure 9. 1. IoT Theoretical Model A set of\nscenarios describing nominal use of\nan IoT system in the SES hypergraph\nframework. 2. Model Pruning The SES producing\nPES and/or CES hypergraphs. 3. Risk Framework The devices\nand/or functional units in the PES or\nCES are annotated with their at-\ntendant set of technical capabilities\nand nominal walks. The list of unde-\nsired behaviors are applied to the ca-\npabilities in these generated walks,\nleading to a set of potential technical\nconsequences. 4. Impacts By examining the gener-\nated technical consequences within\nthe context of the walks in which they\nappear, one can derive a set of opera-\ntional consequences associated with\nthese walks to be used directly as part\nof a risk assessment. Figure 9. Combined Risk Evaluation Framework Mittal, Cane, Schmidt, Tufarolo and Harris 8 CONCLUSIONS AND FUTURE WORK IoT modeling is a complex endeavor in itself as the model requires description across multiple perspectives. \nThis paper presented an IoT theoretical model in the form of a SES hypergraph model. This model includes \nboth IoT elements as well as the environment surrounding these elements. It presented a device-centric \nworld-view necessary to understand the expanded impact a device has on the larger technology-oriented \necosystem in different operational contexts. Having a hypergraph-based methodology is a suitable means \nto understand the dependencies and interdependencies between the model elements. Hypergraphs, in their \noriginal flavor, cannot be used for automated analysis due to the inherent computational and mathematical \ncomplexity. They have to be supported by various axioms that allow analysis on hypergraphs in a tractable \nmanner. The SES ontological framework provides the needed structured framework to construct \nhypergraphs in an iterative manner both visually and structurally. The pruning process facilitates the \nspecialization of a generalized hypergraph to a component-based architecture within the SES framework. \nWe discussed the IT and the OT aspects of IoT through the fourteen aspects of the conceptual IoT-Inclusive \nsystem. The proposed model provides a start towards a common set of terms describing the essential \nelements of the IoT and its environment, creating a better understanding of the overall picture. A significant \namount of work needs to be done before the theoretical framework described in this paper could be \npractically employed as part of an actual risk assessment. Future research could expand upon this work to develop a detailed risk calculation methodology, automated \npruning algorithms, and eventually automated risk assessment and mitigation strategies adaptable to \nvariations in IoT implementation from both static (design) and dynamic (implementation) perspectives. It \nshould be cautioned, however, that the path from the general model to automated risk assessment and \nmitigation strategies is not short. Benefits of this future research include a way to enable improved stability \nand resilience for IoT enterprises, and an understanding of potential paths to improved situational awareness \nthat can leverage industrial and commercial applications. ACKNOWLEDGEMENT The Homeland Security Act of 2002 (Section 305 of PL 107-296, as codified in 6 U.S.C. 185), herein \nreferred to as the Act, authorizes the Secretary of the Department of Homeland Security (DHS), acting \nthrough the Under Secretary for Science and Technology, to establish one or more federally funded \nresearch and development centers (FFRDCs) to provide independent analysis of homeland security \nissues. MITRE Corp. operates the Homeland Security Systems Engineering and Development Institute \n(HSSEDI) as an FFRDC for DHS under contract HSHQDC-14-D-00006. The HSSEDI FFRDC provides the government with the necessary systems engineering and development \nexpertise to conduct complex acquisition planning and development; concept exploration, \nexperimentation and evaluation; information technology, communications and cyber security processes, \nstandards, methodologies and protocols; systems architecture and integration; quality and performance \nreview, best practices and performance measures and metrics; and, independent test and evaluation \nactivities. The HSSEDI FFRDC also works with and supports other federal, state, local, tribal, public and \nprivate sector organizations that make up the homeland security enterprise. The HSSEDI FFRDCs \nresearch is undertaken by mutual consent with DHS and is organized as a set of discrete tasks. This \nreport presents the results of research and analysis conducted under: \nTask Order Number: 43161204, \nTask Title: HSHQDC-16-J-00526:Core Research Program, Internet of Things (IoT) Modeling \nTask Order Sponsor: Department of Homeland Security, National Protection and Programs Directorate \nPurpose statement: The purpose of this research was to develop an IoT theoretical model, and describe how such a \nmodel could be used to perform risk assessments in IoT-centric systems. The results presented in this report do not necessarily reflect official DHS opinion or policy. Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Mittal, Cane, Schmidt, Tufarolo and Harris REFERENCES Berge, C. 1973. Hypergraphs. North-Holland, Amsterdam: American Elsevier Pub. Co. \nBretto, A. 2013. Hypergraph Theory. Switzerland: Mathematical Engineering DOI:10.1007/978-3-319- 00080-0_2 Springer. \nCASAGRAS. n.d. \"RFID and the Inclusive Model for the Internet of Things.\" www.rfidglobal.eu. Accessed December 28, 2016. http://www.rfidglobal.eu/userfiles/documents/FinalReport.pdf. \nCERP-IoT. n.d. \"Internet of Things: Strategic Research Roadmap.\" www.grifs-project.eu. Accessed December 28, 2016. http://www.grifs-project.eu/data/File/CERP-IoT%20SRA_IoT_v11.pdf. \nCIO, DoD. 2013. The DoDAF ARchitecture Framework Version 2.02. DoD CIO. \nCisco. n.d. \"The Internet of Things How the Next Evolution of the Internet is Changing Everything.\" CISCO IBSG. Accessed December 28, 2016. \nhttp://www.cisco.com/web/about/ac79/docs/innov/IoT_IBSG_0411FINAL.pdf. Coley, S. 2014. Common Weakness Scoring System (CWSS). MITRE. \nhttps://cwe.mitre.org/cwss/cwss_v1.0.1.html. Domingue, J., D. Fensel, and P. Traverso. 2008. Future Internet FIS 2008: First Future Internet \nSymposium. Vienna, Austria: Springer. First.org. n.d. Common Vulnerability Scoring System v3.0: Specification Document. First.org. \nhttps://www.first.org/cvss/specification-document. Gallo, G., G. Longo, and S. Pallottino. 1993. \"Directed hypergraphs and applications.\" Discrete Applied \nMathematics (North-Holland, Elsevier Science Publishers) 42: 177-201. Group, The Open Architecture. n.d. TOGAF 9.1 Enterprise Edition. https://www.opengroup.org/togaf/. \nGroup, UK Future Internet Strategy. 2011. \"Future Internet Report.\" https://connect.innovateuk.org. May. Accessed December 28, 2016. \nhttps://connect.innovateuk.org/documents/ 595/Future+Internet+report.pdf. Haller, Stephen. n.d. \"Internet of Things: An Integral Part of the Future Internet.\" services.future-\ninternet.eu. Accessed December 28, 2016. http://services.future-\ninternet.eu/images/1/16/A4_Things_Haller.pdf. Huang Y. and G. Li. 2010. \"Descriptive Model for Internet of Things,\" in International Conference on \nIntelligent Control and Infomation Processing, Dalian, China, Lee, G.M., J. Park, N. Kong, and N. Crespi. 2011. IETF-The Internet of Things Concepts and Problem \nStatement. Internet Draft, IETF. Mckinsey. n.d. \"The Internet of Things.\" www.mckinseyquarterly.com. Accessed December 28, 2016. \nhttps://www.mckinseyquarterly.com/High_Tech/Hardware/The_Internet_of_Things_2538. Mittal, S., and J.L.R Martin. 2013. Netcentric System of Systems Engineering with DEVS Unified Process. \nBoca Raton, FL: CRC Press. Molnar, B. 2014. \"Applications of hypergraphs in informatics: a survey and opportunities for research.\" \nAnn. Univ. Sci. Budapest. Sect. Comput. 42: 261-282. Newman, M.E.J. 2010. Networks, An Introduction. Oxford: Oxford University Press. \nNIC, National Intelligence Council. n.d. \"Disruptive Technologies Global Trends 2025.\" www.fas.org. Accessed December 28, 2016. http://www.fas.org/irp/nic/disruptive.pdf. \nPhilippe Jgou a, Samba Ndojh Ndiaye. 2009. \"On the notion of cycles in hypergraphs.\" Discrete Mathematics 309 (23-24): 65356543. Accessed Jan 17, 2017. \nhttp://www.sciencedirect.com/science/article/pii/S 3446?np=y. SIG, IoT. 2013. Internet of Things (IoT) and Machine to Machine Communications (M2M)Challenges and \nopportunities: Final paper May 2013. Technology Strategy Board IoT Special Interest Group. Sundmaeker, H., P., Friess, P. Guillemin, and S. Woelffle. 2010. Vision and Challenges for Realizing the \nInternet of Things. European Research Project, Brussels: CERP-IoT. Voas, J. 2016. Network of 'Things'. NIST Special Publication 800-183. Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Mittal, Cane, Schmidt, Tufarolo and Harris Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 Zachman, J. n.d. A Concise Definition of Zachman Framework. Zachman International. \nhttps://www.zachman.com/about-the-zachman-framework. Zeigler, B.P. 1984. Multifaceted modeling and discrete event simulation. London, UK: Academic Press. \nZeigler, B.P., and G. Zhang. 1989. \"The system entity structure: knowledge representation for simulation modeling and design.\" In Artificial Intelligence, Simulation and Modeling, by L. Widman and N. \nNielseen K Loparo, 47-73. Hoboken, NJ: John Wiley. Zeigler, B.P., and P.E. Hammonds. 2007. Modeling and Simulation-based Data Engineering: Introducing \nPragmatics into Ontologies for Net-centric Information Exchange. Academic Press. Zeigler, B.P., H. Praehofer, and T.G. Kim. 2000. Theory of Modeling and Simulation: Integrating discrete \nevent and continuous complex dynamical systems. Academic Press. Zhou, D., J. Huang, and B. Schoelkopf. 2006. \"Learning with hypergraphs: Clustering,.\" Advances in \nNeural Information Processing Systems. Zimmerman, Rae, and Carlos E. Restrepo. 2009. \"Analyzing Cascading Effects within Infrastructure \nSectors for Consequence Reduction.\" IEEE International Conference on Technologies for Homeland \nSecurity. Waltham. \nhttp://research.create.usc.edu/cgi/viewcontent.cgi?article=1146&context=nonpublished_reports. AUTHOR BIOGRAPHIES SAURABH MITTAL is a lead systems engineer/scientist at Modeling, Simulation, Experimenation and \nAnalytics Tech Center, MITRE. He has over 15 years experience in modeling and simulation of \ncomplex systems and has co-authored 3 books and over 80 publications. He has M.S and Ph.D. in \nElectrical and Computer Engineering from the University of Arizona, Tucson. His email is \nsmittal@mitre.org. SHEILA A. CANE is Strategic Technical Advisor at MITRE. She has over 30 years' experience in system \nengineering, architecture analysis, and applications of queueing and graph theory. She holds a B.S. in \nApplied Mathematics from Buffalo State College, a M.S. in Industrial Engineering from SUNY \nBuffalo, and a D.B.A. in Information Systems
Management from Nova Southeastern University. Her \nemail is sheila@mitre.org. CHARLES SCHMIDT is a Group Lead at the MITRE corporation. He has over 17 years experience in \ncybersecurity, security automation and standards development. He holds a B.S. in Mathematics and \nComputer Science from Carleton College and an M.S. in Computer Science from the University of \nUtah. His email is cmschmidt@mitre.org. JOHN TUFAROLO is a principal engineer at the Modeling, Simulation, Experimenation and Analytics \n(MSEA) Technical Center, MITRE. He is a NTSA Certified Modeling and Simulation Professional \n(CMSP) and has more than 32 years of experience providing systems engineering project work, \nplanning, and leadership in complex distributed systems. His email is tufarolo@mitre.org. RICHARD B. HARRIS is a principal cybersecurity policy engineer for the Homeland Security Center, \nMITRE. He has over 14 years of experience in cybersecurity with the Department of Homeland \nSecurity and MITRE, and a perspective on complex risk environments that was seasoned by a 26 year \ncareer in the U.S. Marine Corps. His email is rbharris@mitre.org. Mittal, Cane, Schmidt, Tufarolo and Harris Approved for Public Release; Distribution Unlimited. Case Number 18-1212 / DHS reference number 17-J-00100-01 NOTICE This (software/technical data) was produced for the U. S. Government under Contract Number \nHSHQDC-14-D-00006, and is subject to Federal Acquisition Regulation Clause 52.227-14, Rights in \nDataGeneral. As prescribed in 27.409(b)(1), insert the following clause with any appropriate alternates: Rights in DataGeneral (Deviation May 2014). No other use other than that granted to the U. S. Government, or to those acting on behalf of the U. S. \nGovernment under that Clause is authorized without the express written permission of The MITRE Cor-\nporation. For further information, please contact The MITRE Corporation, Contracts Management Office, 7515 \nColshire Drive, McLean, VA 22102-7539, (703) 983-6000. ",
    "text": " Approved for Public Release; Distribution Unlimited: 18-1730. For Teamwork, an Innovative Space Inspires Collaboration Anywhere Cutting across both geographic and generational boundaries, MITREs \nCollaboration Spaces initiative empowers a diverse and far-flung workforce to \nspeak, brainstorm, and get on the same pagewithout having to be in the same \nroom. Some people conduct business the traditional wayin their offices at their companys headquarters. \nOthers work remotely. Seasoned veterans are used to conference rooms, where one person talks and \neveryone else listens. Meanwhile, twentysomethings who grew up in a more interactive world, think \nnothing of sneaking peeks at their laptops or wireless devices during meetings. Workforces are trying to reconcile these conflicting technological and demographic trends, but at MITRE, \nstriking the right balance is particularly important. In the words of MITREs Doug Phair, From what Ive \nobserved, external companies are seen as hired hands brought in to execute something. But were seen \nas part of the team. Were tied to our federal government sponsors at the ground level, at the very \nbeginning of projects, as a trusted adviser. That means we must foster an environment in which employees and our partners in the federal \ngovernment, industry, and academia can work together and share knowledge freely, no matter where \nthey are. Innovative ways to collaborate are nothing new at MITRE, but the Collaborative Spaces project \ntakes it to a new level. With Collaborative Spaces, teams don't just meetthey create. Collaborative Spaces was born from the premise of space to attract and retain folks, plus space to \nconnect MITRE together to do brainstorming and project war room-type stuff, says Phair, who led the \nMITRE team that developed Collaborative Spaces. That was the transformation we helped push over \nthe past few years. One Generation Learns from Another Building on the work of MITREs Enterprise Computing, Information, and Security Innovation Program \n(which provides funding to employees to explore ideas for innovative projects), Phair formed a team that \nexamined how MITRE could modernize its workspaceschanging them from briefing rooms to war \nrooms. Achieving that goal required thoughtful redesign. The team drew on a wide range of \nexpertisehuman resources, information technology, and corporate real estate. But the most valuable feedback of all may have come from the usability studies that involved \nemployeesincluding the next generation. One summer, Phair put up a time-lapse camera in the Collaborative Systems Lab, located on MITREs \nBedford, MA. campus. There were chairs, couches, movable tables, and whiteboards stacked in a corner \nof the lab. Phair told a group of 12 co-ops to make the space into whatever they wanted. The only \ncondition? They had to keep a journal and make an entry whenever they changed something. It was an educational experience all around. The co-ops quickly abandoned the desks in favor of the \ncouches. They moved the collaborative whiteboards out of the way because they were blocking the https://www.mitre.org/careers/working-at-mitre/employee-voices/a-technology-evangelist-brings-the-future-into-mitres\nhttps://www.mitre.org/publications/project-stories/a-new-tool-for-gaining-an-edge-in-high-tech-brainstorming\nhttps://www.mitre.org/careers/student-programs/co-ops-interns sunlight. And they bridged generational gaps when it came to practices like bringing laptops and \nchecking them during meetings. Im a Baby Boomer, and I tend to see people in a meeting with a laptop as not paying attention, Phair \nsays. But it has become clear that early career staff coming in see it as an efficiency. They were getting \nanswers before they left the meeting. Working together, with multiple generations in one space, was a \nlearning experience, and we got to understand each other. \"Its that compromise, that push-pull, that seems to make things work. Meanwhile, the construction of a new building on MITREs McLean, Va., campusa three-year project \ncompleted in 2016presented an opportunity to remake the workplace. The team took advantage of \nideas prototyped with the innovation project and included lessons learned for the co-op lab study. The building has neighborhoods\"groupings of workspaces supporting working relationships within \nand among groups of employeesthat includes spaces for collaboration, as well as spaces reserved for \nmobile workers. And the policies governing the way those spaces are used emphasizes flexibilityfor \nexample, by allowing employees to reserve collaboration rooms over a multi-day period, instead of one \nhour. Flexible Work Spaces to Suit Every Work Style The result is a group of rooms that use commercially available technology in innovative ways to \naccommodate just about anyones preferred work style. Things like size, seating capacity, and interactive \ntechnologies define spaces. For example, \"huddle rooms\" allow small groups to gather quickly and conduct businessand group \nmembers can call into the room if necessary. In a fully outfitted space called a \"project studio,\" they can \npivot from presentations to brainstorming sessions. Participants can easily adjust the furniture to bring it \nfrom table to standing height, making it easier to customize the brainstorming experience. Anyone can \nuse several writeable surfaces (tables and a wall) for jotting down ideas. And in a \"collaboration cove,\" people can gather around a table with dual monitors and share \ninformation and ideas with one another, including colleagues in remote locations. Participants can share \ninformation and switch whos presenting seamlessly, saving them the time and trouble of an email \nthread. We made sure that the space would meet all of those different needs, depending on what kind of work \ngroup was in there, says Lorin Petersen, a MITRE senior software engineer who served on the \nCollaborative Spaces design team. Maybe one group preferred to write everything down, while another \ngroup preferred to do something digital on a laptop. They found out they could do that all within that \nsame room. \"The goal is a project team working together in a unified space. Each team member can collaborate in \nthe way that best suits their work style. Safe and Secure CollaborationRegardless of Location What if you can't meet with your team in person? Collaborative Spaces use technology to loop in people \nwho cant physically make it to any of the rooms. An interactive projector powers a built-in virtual https://www.mitre.org/careers/student-programs/recent-graduates whiteboard you can connect to via laptops. Its touch-sensitive, so you can write on a projected image \nwith a pen or your finger. And even if you're not physically present, you're still in. Staff in different \nlocations can see everyone in the room, thanks to a 360-degree camera. You dont want to make it more difficult for people to get the work done,\" says Kristy Markin, a MITRE \nuser information and information architect who worked on the design. \"But everyone knows how to pick \nup a marker and go write on a whiteboard. Its a major advancement to have a projector thats precise \nenough to allow people to write on it in a way that felt natural to them and have somebody else \nremotely see that in real time.\" The technology behind the digital whiteboards is also more secure, thanks to MITREs inputand \nconfidence in our role as a trusted adviser. We performed security evaluations of the electronic \nwhiteboards in our Collaborative Systems Lab, discovered security vulnerabilities, and offered advice on \nhow best to address them. Weve helped industry think about security issues and drive improvements, Phair says. These boards \nwere never going to be used in a government installation until we did some of this work. For Phair, that exampleserving as a trusted partner and an early adapter and molder of new \nideasunderscores MITREs approach to building the workplace of the future. Were willing to pilot and try new things to keep the culture of collaboration, but also support the new \ndemographics of how we work and the distributive sense of our work. -- by Russell Woolard _top\n _GoBack ",
    "text": " Generation AI Nexus\nProject Story \nDistribution Unlimited. Case Number 18-2170. Preparing Generation AI for the Fourth Industrial Revolution The Fourth Industrial Revolution has already begun, but the U.S. faces a workforce shortfall of 250,000 data scientists. MITRE and leading technology companies are creating Generation AI Nexus to give students access to AI training, tools, and big data. Ready or not, the Fourth Industrial Revolution is already underway. In contrast to the First Industrial Revolution, which was powered by steam, the Fourthwhich fuses the physical, digital, and biological worldswill be fueled by big data and artificial intelligence (AI). There is ample evidence it has already begun, as is apparent to anyone who does a Google search, uses voice or facial recognition devices, or drives a car with near-autonomous safety controls. While some, like Teslas Elon Musk, have warned of the risks of AI, others see fundamental and positive changes ahead in security, healthcare, productivity, and more. Either way, most agree that the explosive growth of AI is inevitable. The Fourth Industrial Age will burn through massive amounts of data, with potentially hundreds of thousands of analysts employing AI tools to make sense of it all. However, as MITRE senior vice president Rich Byrne discussed at a panel during the National Geospatial-Intelligence Agencys (NGAs) GEOINT Symposium in April 2018, theres a big workforce challenge. In the past industrial revolutions, America led with technological advances and retrained the workforce and became a dominant power, he said. But while the U.S. should be making technical advances in AI and leading workforce reengineering of people skills, theres a lot more competition now. And were not going to succeed just based upon our past merits. According to McKinsey & Company, there will be a shortfall of up to 250,000 data scientists in the U.S. in a decade. Byrne says thats particularly troubling given how heavily China and other countries are investing in AI expertise. And even more ominously, Russian President Vladimir Putin says that the nation that leads in AI will be the ruler of the world.' Like other industrial revolutions, the Fourth will likely disrupt the U.S. workforce, particularly those with lower-skilled jobs. But one thing is clear: there are ample opportunities to those with AI expertise. Already, the shortage of AI analysts is quite apparent, with some PhDs earning $300,000-plus and https://www.mitre.org/publications/project-stories/dreaming-cgi-teaches-computers-to-see-better-than-humans\nhttps://www.washingtonpost.com/news/innovations/wp/2018/04/06/elon-musks-nightmarish-warning-ai-could-become-an-immortal-dictator-from-which-we-would-never-escape/?noredirect=on&utm_term=.f49c44b78e98\nhttps://www.mitre.org/capabilities/advanced-technologies/data-science-and-analytics\nhttp://geoint2018.com/\nhttp://geoint2018.com/\nhttps://www.mckinsey.com/featured-insights/digital-disruption/whats-now-and-next-in-analytics-ai-and-automation\nhttps://www.mckinsey.com/featured-insights/digital-disruption/whats-now-and-next-in-analytics-ai-and-automation\nhttp://www.sciencemag.org/news/2018/02/china-s-massive-investment-artificial-intelligence-has-insidious-downside\nhttp://www.sciencemag.org/news/2018/02/china-s-massive-investment-artificial-intelligence-has-insidious-downside\nhttp://www.sciencemag.org/news/2018/02/china-s-massive-investment-artificial-intelligence-has-insidious-downside\nhttps://www.theverge.com/2017/9/4/16251226/russia-ai-putin-rule-the-world Generation AI Nexus\nProject Story \nDistribution Unlimited. Case Number 18-2170. experienced teachers being recruited from academia for more lucrative pay.\nMITRE and Partners to Reach out to Students with Generation AI Nexus Byrne offered an idea for strengthening Americas AI skills by reaching out to university and high school students. He called them Generation AIthe generation that grew up knowing that the answer to most questions was a Google search away, that GPS made paper maps obsolete, and that Alexa was always listening. Yet, all too many members of this generation are also shying away from science, technology, engineering, and math careers. From school age through college, and into public service and work, we should give them the AI tools to reinvent themselvesso they can be the data analytics, machine-learning leaders of the world. As a company focused on solving problems for a safer world, MITRE is in a natural position to organize and align the needs and resources of U.S. academic, industry, and government stakeholders. Byrne explained that MITRE will develop a secure automated analytic framework through Symphony, complete with artificial and machine-learning tools. But Byrne points out that success will require the whole community. Those stakeholders will have plenty of heavy lifting to do to make this work. For example, academiaby integrating Generation AI Nexus into their curriculums. Industryby supplying seed money and cloud resources. And the governmentby providing data around crucial public service needs.\nAmbitious Goals for Standing up Generation AI Nexus Byrne has charged Jay Crossler, MITREs chief engineer for Learning Systems, and Michael Balazs, technology integrator, with standing up Generation AI Nexus. To achieve the initiatives ambitious goals, MITRE has already reached out to leading commercial internet companies and computer manufacturers about seeding the project with startup funds and providing free cloud computing time for students. Securing those agreements is a major step in itself, but beyond that, Crossler and Balazs outlined the following plan: Opening up MITREs Hackathons online. This is a quick way to begin reaching out to U.S. students. Traditionally MITREs hackathons have been on site. By working with partners that can donate the computing time, MITRE can offer students access to real data via Symphony through agreements with our sponsors. Well pose tough questions around cyber, health, https://www.nytimes.com/2017/10/22/technology/artificial-intelligence-experts-salaries.html\nhttps://www.mitre.org/capabilities/advanced-technologies/symphony-automated-secure-platform\nhttps://www.mitre.org/publications/project-stories/students-apply-ai-skills-to-pandemic-early-detection-and-response Generation AI Nexus\nProject Story \nDistribution Unlimited. Case Number 18-2170. and national security as challenges for students, says Crossler. For instance, Who can develop the best algorithm to find indicators of colon cancer in the next month?' Work with MITREs close academic partners to integrate Generation AI Nexus into the classroom. To begin, well work with those schools that are leading in AI and data science areas, Balazs says. But we think it also has tremendous potential for those in hard sciences as well, such as biomedical engineering, physics, chemistry, and more.\" He says that initially, they will start at the graduate level, then work down to undergraduate school and eventually to high school. Professors and students doing their own research. Crossler and Balazs envision the phase when students and professors apply the AI tools and data to their own projects. While we may offer prizes for challenges, it will be even more exciting when they develop and research topics of their own, Balazs says.\nA Preliminary Timeline According to Byrne, the target is to ultimately reach more than one million U.S. students through Generation AI Nexus, with the following preliminary timeline: Online hackathons by fall/winter 2018 Four universities will receive Symphony for free in summer 2019 and work Symphony into their curricula 40 universities planned for 2020 400 universities planned for 2024 Following that, Generation AI Nexus will reach out to high school and grade school students The Right Time to Launch Generation AI Nexus Ultimately, Balazs hopes to see every person entering the workforce with hands-on exposure to the transformational power of AI through Generation AI Nexus, just as the Hour of Code aims to do for programming. And while theres every evidence that the Fourth Industrial Revolution is already underway, its also clear we are in the early days. Crossler points out that this is a good time to be starting Generation AI Nexus. Were beginning the conversations with the different stakeholders nowand theyre excited. They see the potential just like we do. https://www.mitre.org/careers/academic-engagement\nhttps://hourofcode.com/us\nhttps://hourofcode.com/us\nhttps://hourofcode.com/us Generation AI Nexus\nProject Story \nDistribution Unlimited. Case Number 18-2170. I think once we model Generation AI Nexus in a few universities, it will grow exponentiallyright along with the Fourth Industrial Revolution. To learn more about the technology powering Generation AI Nexus, go to Symphony or contact symphony@mitre.org. Bill Eidson  https://www.mitre.org/capabilities/advanced-technologies/symphony-automated-secure-platform\nmailto:symphony@mitre.org _GoBack\n _top\n _GoBack\n _GoBack\n _GoBack ",
    "text": " Technology Futures James Thompson CoPI\nDavid Slater CoPI\nMainstreaming Complexity: Practical Decision-making in a Chaotic World\n| 1 |\n \nICCS  23 July 2018\nApproved for Public Release; \nDistribution Unlimited. Case Number 18-2452 What Is a Fractal?\nQualitative and Quantitative Definitions\nFractals vs. Multifractals\nAlgorithms for Multifractal Analysis\nFluctuation Analysis\nWavelets\nPractical ApplicationsOK, but so What?\nForecasting\nAnomaly Detection\nConclusions Next Steps Overview\n | 3 |\nFractals Objects That Do Not Simplify Under Magnification L-System:\nAngle 120\nAxiom F\nF > F+FFF+F \nThe Sierpinski Gasket\nThe Mandelbrot Set\nFractals are often created by simple iterative or recursive processes that lead to exceedingly complex objects\n The concept of a fractal is inherently related to dimension and measurement\nIn standard Euclidean geometry, as the measuring stick gets smaller (1/r), the quantity N(r) needed to cover the object grows according to the objects dimension and the measure of the object remains constant\n| 4 |\nBut, Mathematically, What Do You Mean Do Not Simplify? Euclidean Object\n1 x 1\nMeasuring stick .5 x .5\n.5 x .5\n.5 x .5\n.5 x .5 11.5 x 200km = 2300km\n28 x 100km = 2800km\n70 x 50km = 3500km\nSource: https://en.wikipedia.org/wiki/Coastline_paradox \nFor fractal objects this relationship fails for integer dimensions\nThe net effect is that as the scale of the measuring stick decreases, the measure of the object grows without bound\nTo measure such objects, a fractional dimension is required and that dimension becomes the more important number\n 1/r N(r)\n 1 1\n 2 4\n 4 16\n 8 64\n 16 256\n \n 1/r (1/r)2 Scale vs. Coverings\n 4 Standard Brownian Motion is a simple fractal with dimension H = 0.5 \nWhen treated as a time series this means the maximum and minimum are bounded by a cone proportional to time t raised to the power 0.5\nFractional Brownian Motion is also governed by a single value, but H is not restricted to 0.5\nValues of H closer to 0.0 produce rougher paths, while values closer to 1.0 give smoother values\nThus H statistically quantifies the sample path\n| 5 |\nTime Series and Other Plots Can Also Be Fractal (i.e., Statistically Self-similar Across Scales) Source: http://cs.mcgill.ca/~tredda/brownian.html Standard Brownian Motion In multifractals, the points exhibiting a single value H are scattered throughout the object\nIn between are points exhibiting different values of H\nAt different moments q the fluctuations scale according to the scaling function (tau(q))\nThe full spectrum of power laws and a relative measure of their prevalence is known as the multifractal spectrum\nThe multifractal spectrum statistically quantifies the sample path of a multifractal\n| 6 |\nMultifractals Generalization of Fractals, One Value H Is Not Enough Apple Stock Price Since IPO\nDays The multifractal spectrum is a relative measure of the number of fractal processes having the same smoothness (regularity)\nA measure of the (local) regularity is the Holder exponent : For small , or The number of fractal processes with regularity scales as:\n, or \nwhere is the multifractal spectrum\nAnd we can relate to the scaling function via the Legendre transform\n| 7 |\nThe Multifractal Spectrum Multifractal Spectrum: f(a) vs a\n Fluctuation or Wavelet Coefficients:\nMF-DFA (or DMA) methods generally use the variance parameter estimated from polynomial regression at different scales\nWavelet methods equate the wavelet coefficients to the scaling function, tau(q)\nBoth approaches rely on mathematical variations of the multifractal formalism that equates something we can compute empirically to the scaling function\n| 8 |\nAlgorithms for Extracting the Multifractal Spectrum A Multifractal Algorithm Taxonomy The data is iteratively segmented at different scales s\nPolynomial regression is applied to each segment\nThe sum of variance from the regression of each segment F(s) is proportional to the scaling function tau(q)\n| 9 |\nMultifractal Detrended Fluctuation Analysis (MF-DFA) The continuous wavelet transform W(s, t) is a generalized time-frequency method using scales s and time translations t\n| 10 |\nWavelets: A Brief Refresher Signal\nWavelet Transform\n 10 | 11 |\nWavelets and Multifractals\nIf we sum up all the W(s, t) values raised to the power q we get something we can relate to the scaling function The sum is performed over lines L(s) that connect local maxima of the wavelet transform W(s, t) Signal: Apple Stock Price\nWavelet Transform | 12 |\nPreliminary Results Accuracy of MF Spectrum Wavelet Leaders more often find a convex spectrum, but can vary wildly from one implementation to another\nMF-DFA methods appear to fail more often than good Wavelet Leaders implementations, but are perhaps more accurate in the runs that do not fail\n Preliminary results match theoretical predictions:\nMF-DFA computation time increases exponentially with length of the time series\nWavelet approaches vary depending on software implementation\nWavelet Leaders are fastest when implemented well\n| 13 |\nAlgorithm Comparison Preliminary Results Computation Time Accuracy, as width of confidence interval, improves with more data\nResults vary depending on software implementation\nWavelet Leaders is consistently better than other algorithms\n| 14 |\nAlgorithm Comparison Preliminary Results Accuracy of the Spectrum Peak The degree of multifractality is related to the width of the spectrum\nThis is proportional to the 2nd derivative of tau(q)\nNumerical estimations are prone to more error in general\nWavelet Leaders is again a consistently more accurate approach\n| 15 |\nAlgorithm Comparison Preliminary Results Accuracy of the Spectrum Width Securities, options, and currencies often exhibit heavy tails and infinite auto-correlation\nCalvet & Fisher construct a multifractal model that accurately mimics this complex behavior and allows for the construction of conditional probabilities of states over time\n| 16 |\nApplications: Forecasting and Large Deviations Calvet, Laurent, and Adlai Fisher. \"Forecasting multifractal volatility.\" Journal of econometrics 105.1 (2001): 27-58. Shekatkar et al recently published in Nature a method for distinguishing healthy hearts from those on the verge of heart-failure using multifractals\nThe comparison can be performed with short-time ECG recordings enabling rapid diagnosis and response to failing hearts\nShekatkar, Snehal M., et al. \"Detecting abnormality in heart dynamics from multifractal analysis of ECG signals.\" arXiv preprint arXiv:1705.00121 (2017).\n | 17 |\nApplications: Anomaly Detection Original\nForgery Multi-fractal Analysis\nNontraditional image processing techniques have been used to quantify and measure various artwork features for:\nForgery detection\nRestoration tracking\nDating Of particular interest is forgery detection based on texture analysis\nMultifractal analysis methods are ideally suited for this application\nThe picture on the left is an original Bruegel drawing while the picture on the right is an imitation\nThe corresponding spectra (peak and width) are discernibly different P. Abry, S. Jaffard, and H. Wendt, Bruegals Drawings Under the Multifractal Microscope, ICASSP 2012, pp. 3909-3912 (2012) \n On April Fools Day 2017, Reddit launched a social experiment in which they published a 1000x1000 canvas of pixels\nUsers could change a single pixel to one of 16 colors once every 5 to 20 minutes\nOver 27 hours, 1 million+ users placed about 16 million pixels\nUsers collaborated in groups and creating bots was encouraged\n| 18 |\nApplications: Reddit Place https://www.youtube.com/embed/EDGpTJ6Pea0\n 18 Reddit published a dataset of every pixel change over the entire experiment\nAs a test case for a large data set of images, we computed the Mulitfractal Spectrum for images every 90 seconds\nNote the apparent stability in both the peak and the width after about time 500-600\n| 19 |\nApplications: Reddit Place Fractals are ubiquitous in nature and in the data we collect, but they remain esoteric and thus poorly understood\nAlgorithms for extracting multifractal properties from data have improved in both speed and accuracy\nThese improvements mean that multifractal analysis is poised to enter mainstream decision-making\nA few practitioners are already employing multifractal analysis to great success\n| 20 |\nConclusions ",
    "text": " 1 Approved for Public Release: 17-3792.\nCopyright has been transferred to another party. Reuse is restricted. Contact the Contracts Management Office for guidance. On-Demand Assessment of Air Traffic Impact of Blocking \nAirspace Amal Srivastava, Tom St. Clair, Grant Pan\nThe MITRE Corporation 7515 Colshire Ave\nMcLean, VA, USA Abstract The Federal Aviation Administration often blocks strategically located airspace volumes to \nensure safety during a variety of operations that are potentially hazardous to aircraft, such \nas space launches. As the frequency of these operations increases, there is a growing need \nto deepen collaboration and transparency between stakeholders regarding the use of \nairspace. This collaboration can be supported by models and capabilities to quickly assess \nthe impact of airspace closures, up to 12 months into the future. This paper presents a \ntechnique to enable a what-if analysis capability coupled with a prediction model, \nwhereby changes in airspace dimension, location, and activation time are reflected \ninstantaneously as measures of projected impact. The technique can also be used for quick \npost-operations analysis using historical traffic data and to develop air traffic impact \nassessment capabilities accessible to a broad range of users outside of the air traffic \ndomain. This research has three key components: developing a model to predict air traffic \ndemand, modeling air traffic impact to the affected traffic, and reducing this information \ninto a data structure that can support on-demand analysis. The focus of this paper is on new \ntechniques to predict demand using a large set of historical track data and further encode \nthese projections to support the quick assessment of the impact of blocking various \nairspace volumes. Initial results show that the proposed data reduction scheme accurately \nrepresented the traffic crossing an airspace and resulted in data size reduction by over \n50%. The projection model performed well, the actual number of impacted flights were \nwithin the estimated range approximately 80% of the time. Finally, the responsiveness of \nthe web-based prototype developed to illustrate the concept demonstrated the models \nability to support an on-demand assessment of the air traffic impact of blocking airspace. 2018 Cambridge University Press. All rights reserved. 2 IntroductionI. Demand for airspace access has been on the rise due to an increasing number of new \nentrants such as space operators, unmanned aircraft systems (UAS), and balloon operators. \nTo manage operations that are potentially hazardous to aircraft, such as space launches in \nthe National Airspace System (NAS), the Federal Aviation Administration (FAA) may route \nair traffic around strategically located blocked airspace to ensure operational safety. As the \nfrequency of these activities increases, there is a growing need to increase collaboration \nand transparency among stakeholders regarding airspace usage. A primary need to support \nthis collaboration is the ability of all stakeholders to quickly assess the impact of planned \noperations far in advance of the event, up to 12 months into the future. Different \nstakeholders will have different uses for such a capability. A space operator may be able to \nadjust the plan of launch and reentry operations to have minimal impact to the NAS, and an \nFAA analyst may be able to quickly assess the impact of last-minute changes in the launch \ntime. In fact, a prediction model coupled with a what-if analysis capability, in which \nchanges in blocked airspace dimensions, location, and activation time are reflected \ninstantaneously as a measure of projected impact, could be a key enabler of collaborative \nand transparent airspace use among all stakeholders. This work has three key components: developing a model to predict air traffic impacted by \nblocking airspace volumes, modeling air traffic impact on the affected traffic, and reducing \nthis information to a data structure that can support on-demand analysis. The focus of this \npaper is on new techniques to predict demand from a large set of historical track data and \nfurther encode these projections into a data structure that can support the quick \nassessment using a what-if analysis paradigm. The organization of this paper is as follows: Section II explores background on existing \napproaches to predicting the air traffic impact of blocked airspace, Section III provides an \noverview of the approach, and Section IV discusses the data sources underpinning the \nimplemented algorithms and the scope of the study. Section V discusses the data reduction \nand encoding scheme, Section VI describes the traffic projection model, and Section VII \nsummarizes notes on the implementation of the model as a prototype. In conclusion, \nSection VIII points out the strengths and weakness of this approach and future work. In this paper, the terms aircraft hazard areas (AHAs) and Special Use Areas (SUAs) are \ncollectively referred to as blocked airspace; additionally, use of word the airspace \nimplies airspace volumes having lateral as well as vertical dimensions. II. Background The primary focus of the research presented in this paper is enabling a what-if analysis \ncapability that can provide immediate assessment of the impact of blocking airspace to a \nbroad class of users with little expertise in the air traffic domain. To the best knowledge of 3 1 DART is a product of AvMet, information at http://www.avmet.com/dart\n2 Fast-time simulation tool developed by National Aeronautics and Space Administration (NASA) Ames. 3 Fast-time simulation tool developed by The MITRE Center for Advanced Aviation System Development (CAASD). the authors, no published research addresses this requirement. Tools such as Dynamic \nAirspace Routing Tool (DART) 1can be used to assess the NAS impact of closing airspaces; \nhowever, to do that requires access to the tool, operator knowledge of the air traffic \ndomain, availability of data (such as traffic and weather), and setup time. The other component of the research is projecting the air traffic impact of blocking an \narbitrary airspace, which is a complex task, as it varies significantly depending on factors \nsuch as location, season, day of the week, time of day, and weather. In addition, the air \ntraffic management strategies to avoid hazard areas vary depending on area control centers \nand are not known in advance of the operation that requires blocking airspace. There are several publicly available demand forecasts. FAA publishes the Terminal Area \nForecast (TAF) for active airports in the National Plan of Integrated Airport Systems \n(NPIAS), which is considered the de facto official aviation forecast. It is developed from a \nseries of airport models that use trends in demographics to forecast changes in \nenplanement. Boeing publishes its latest assessment of the 20-year demand for world travel \nin its Current Market Outlook (Boeing, 2017), and Airbus provides its projection of 20-year \ndemand in its Global Market Forecast (Airbus, 2017). Finally, the Transportation Systems \nAnalysis Model (TSAM) (Jeff Viken, 2006; Jeff Viken, 2006) developed by Virginia Techs Air \nTransportation Systems Lab and NASA Langley can be used to project the passenger \ndemand for trips more than 100 miles selecting among three modes of transport: \nautomobile, airline, and on-demand services using very light jet aircraft. All these forecasts \nfocus on demand growth at the airports, not in the airspace in between; that is, they do not \nprovide a prediction of trajectories of fights between the origin and destination airports. \nThis makes them insufficient for modeling the impact of blocked airspace. \nOne approach to assessing the impact of a launch or reentry operation is to model the traffic \non the launch day based on available traffic and weather forecasts, and calculate the \nexpected delay by simulating the rerouting of the affected flights around the AHAs using \ntools such as Future ATM Concepts Evaluation Tool (FACET)2 and systemwideModeler 3. \nThis approach requires significant effort from a well-informed operator in setting up the \nsimulation to realistically model the planned operation conditions, making it unsuitable for \nuse in a what-if analysis capability that can be used by a broad range of users with no \nknowledge of the air traffic domain. Another approach used by Jessica Lee and Marie Kee (Kee, January, 2014) involves \nstatistical analysis on a specific SpaceX Falcon9 launch vehicle/Dragon capsule reentry \nvehicle operation to determine if the operation caused flights to experience significantly \nlonger flight distances, more fuel burned, and longer flight durations as compared to similar \nflights on other days. The paths of the flights on the launch day were compared to the \nsimilar flights on a set of five historical days to arrive at a range of distance and time \nimpacts of the launch. This approach may be used to develop prediction models of the \nlaunches with similar characteristics, such as the location and geometry of the hazard areas, 4 block time window, and the day of the week of the operation. However, its use as a general-\npurpose method to assess the impact of any blocked airspace is limited. Since this approach \nis derived from a comparison to actual impacts, a large number of historical impacted days would \nbe required before such an approach can be used to estimate behavior for future events. Also, the \nstudy required significant human effort and is not amenable to automation and producing \nresults in a short time. In related research, Srivastava (Amal Srivastava, 2015) projected the NAS impact of \nblocking airspace by measuring
the effect of delaying or routing flights around blocked \nairspace on a sample historical set of days similar to the proposed launch day traffic. This \napproach requires minimal air traffic domain knowledge however, analysis takes some \ntime (on the order of 20 minutes), making it unsuitable for use in a what-if analysis. \nMoreover, the model relies on selecting historical days close to the launch day and is \ntherefore useful only for assessing relatively near-term impacts. The approach presented in this paper combines insights gained from the earlier work to \ndevelop a model that predicts impact of blocking airspace on the NAS and encoding the \nresults in a data structure that can support interactive queries on blocking arbitrary \nairspace. III. Overview of the Approach The research objective presented in this paper is to enable a user to draw an airspace, \nanywhere on a map, indicate time window for which it is blocked, and instantaneously \nreceive metrics indicating the effect on airlines of blocking it. A user may move, reshape, or \nchange the closure times of the airspace, and the changes in impact are instantaneously \nreflected. In effect, it is envisioned that the geographical map is geo-coded with NAS \nimpact information, which is then used to provide a real-time assessment of the impact. One of the key requirements for achieving this vision is to develop a geo-coded data \nstructure to store aggregated projected or historical traffic data. The data structure referred \nto as route segment is used for this purpose; a route segment is a line segment between \ntwo known fixes or waypoints. Since traffic within the NAS changes from moment to \nmoment, it needs to be aggregated for a unit of time; for this model, the unit selected is one \nhour. The route segments carry bidirectional traffic density, aggregated hourly; thus, \ncreating a route segment density map over the geographical area of interest. The route \nsegment density map enables a what-if analysis paradigm, since the traffic density \ninformation in the route segments intersecting any arbitrary airspace can be used to assess \nthe impact instantaneously. To generate the route segments, the flown flight path is reverse-\nengineered into the known fixes and slotted to the hourly bins, depending on the time when \nthe flight was in the route segment. Once the data structure used to store projected (or historical) traffic density is designed, \nthe next step is developing the model for traffic projections. If reliable traffic forecasts were \navailable 12 months in advance, then they could have been the basis of projected NAS 5 4 Innovata is source of airline schedule data covering over 800 carriers worldwide. http://www.innovata-llc.com/ impact of blocked airspace. Unfortunately, that is not the case. Flight schedules databases, such \nas the one from Innovata 4, exist, but they do not contain information on general aviation \nand many business jet flights, which together form a significant portion (approximately 20 \npercent) of U.S. traffic. Moreover, the database only provides flight schedules between city \npairs, and not the expected path (trajectory) of the flights, which are required to model the \neffect of closed airspace on the NAS. Trajectories may be generated using flight schedules as \nan input to fast-time traffic simulation system such as DART; however, such an approach \nrequires operator knowledge of the air traffic domain, availability of other data (such as \nweather), and setup time, which makes it unsuitable for our purpose. In the absence of a traffic forecast, an approach that applies heuristic methods to project \ntraffic is used. The forecasting model is based on analysis of historical traffic trends \ncombined with known flight schedule patterns. Traffic flows at different locations for \nmultiple years are studied to uncover trends by aggregating the data at different levels \n(daily, weekly, and monthly). An important part of this research is to develop a prototype implementing the model and \ntesting the extent to which the goals of enabling a what-if analysis have been \naccomplished. Notes on implementation and the user interface are also part of this paper. To summarize, the key steps in the research to enable an on-demand assessment of air \ntraffic impact of blocking airspace are: Devise a data reduction and encoding scheme to enable a geo-spatial what-if analysis.\nDevelop an air traffic projection model. Model the NAS impact of blocked airspace. IV. Data Sources and Scope This research is relevant to locations worldwide; however, due to data and resource \nlimitations, it has been confined to airspace in the continental U.S. airspace only, specifically \nto a region bounded by Latitude 10N to 50N and Longitude 40W to 160W. Note that since \nthe key approach discussed in this paper relies on heuristic methods and historical traffic \npatterns, it would need to be adapted for use elsewhere, as these will vary from one region \nto another. The data source used to generate historical track data is Aircraft Situation Display to \nIndustry (ASDI) feed provided by the Traffic Flow Management System (TFMS) as a System \nWide Information Management (SWIM) service. The feed allows real-time air traffic data to \nbe disseminated to members of the aviation industry and includes aircraft scheduling, \nrouting, and positional information covering flights traversing the scope of this study. It \ndoes not contain the flights using Visual Flight Rules or military flights. 6 The actual flown track data is generated using the track position report (TZ) messages and \nis augmented by the oceanic messages (TO) for portions of track that are over the ocean in \nthe non-radar airspace. In the event a gap of more than 20 minutes is present between two \nnodes, an interpolated node is inserted, along with the great circle path, in the middle at the \nsame altitude as the prior one to ensure continuity in the track. The historical track data comprising all tracks from 2011 to 2016 is used in this study. V. Data Reduction and Encoding Scheme A key objective of this research is to achieve the ability to get instantaneous metrics on the \nNAS impact of blocking an arbitrary airspace, for any length of time. This requires that the \nhistorical and projected traffic information be stored in a geocode data structure, which \nwhen combined with blocked airspace coordinates and activation time is able to produce \nthe NAS impact metrics. There are readily available aggregated \nhistorical track data sets including number of \ndaily flights between city pairs. This data set \nwill not suffice as the flights between a city pair \nmay follow different paths. For example, Figure \n1 shows flight paths from New Yorks John F. \nKennedy Airports to Miami International \nAirport on March 3, 2017. A blocked airspace \nlocated at positions A, B, or C will impact a \ndifferent number of flights, as is evident from \nthe figure. The variation in the number of \nimpacted flights will rise for longer distance \nflights, as there may be more routes connecting \nthe origin and destination and a larger range of \nflight durations. It is apparent that the track data needs to be collected between points that are nearer and \ndo not have multiple paths between them. We use fixes and waypoints along tracks to \naggregate tracks. These are more closely spaced, with well-known points common to many \nflight paths. A flight track is split into several route segments, each bounded by a pair of \nnodes that are typically fixes and/or waypoints. An aircrafts flight plan can be a starting point to splitting a track, as it has the intended \nroute of a flight in terms of fixes and waypoints. In practice, however, the path deviates \nsignificantly from the flight plan. Analysis of track data from August 1, 2015, revealed that \n33 percent of flights deviated from the last filed flight plan by 25 nautical miles (NM) or \nmore. To address this, the actual flight track is snapped to the closest fixes and waypoints it \npasses over, in effect reverse engineering the flown flight plan. Since fixes and waypoints \nare generally not available over oceans, a grid of intersection points one degree apart Figure 1. Flight Paths from JFK to MIA on March 3, \n2017 7 (going north-south and east-west) is created to cover such locations. In addition, since the \nset of fixes and waypoints in use changes over a long period (six years used in this study), \nonly currently used fixes and waypoints are used to create route segments. After the tracks are split into route segments, the number of times each route segment is \ntraversed every hour is recorded as its traffic density; a collection of traffic density for all \nthe route segments make up a route segment density map. Finally, an algorithm to assess \ntraffic blocked by any arbitrary airspace projected over the route segment density map is \ndeveloped and tested. To summarize, the following are the steps to reduce and encode track data to support what-\nif analysis capability: Create a database of nodes of frequently used fixes, waypoints, and one-degree latitude and longitude grid points.\nAlign flight tracks to the nodes to infer the flown flight route and generate route segments.\nAggregate traversal of route segments by
all the flights on an hourly basis to generate route segment density map.\nDevelop an algorithm to assess traffic blocked by any arbitrary airspace projected over the route segment density map. These steps are described in detail in the subsequent sections. Generate Database of Nodes 8 The objective of this process is to generate a database of nodes that is granular enough to \ncapture prevailing air traffic patterns and contains usage frequency information. The \naeronautical navigation database (from sources such as National Flight Data Center) does \nnot contain usage frequency, which makes it inadequate for our purpose. To generate this \ndatabase, flight plans of flights from 2011 to 2015 were parsed to get the nodes (mostly \nfixes and waypoints) specified in the plans and their usage frequency. Airways and jetways \nwere expanded to the individual waypoints and fixes in the process. The nodes were further \nclassified on the frequency of use as high usage (97.5 percentile or higher), medium usage \n(90.0 97.4 percentile), low usage (75.0 89.9 percentile), and rarely used (below 75.0 \npercentile). This resulted in a large node's data set (see Figure 2 for a sample, which shows \nhigh (red), medium (blue) and low (yellow) usage count nodes). To account for low coverage in the oceanic areas due to the absence of fixes and waypoints, \na 1x1 degree grid was generated, and each intersecting point was stored as a synthetic \nnode. All the nodes, their locations, usage class, and type are stored in the database of \nnodes, which is later used to align flown tracks to the route segments. Infer Flown Flight Route The goal of this step is to infer the route that a flight flew, within a specified tolerance limit \non the allowed deviation from the actual path. To ensure that the inferred path is close to \nthe actual, we limited the maximum deviation between them to be less than 10 NM, and the \ndistance between two nodes on the flown plan to less than 150 NM. The first step of this process is to check if \nthe flight path generated using the filed flight \nplan (or amendments) is within the tolerance \nlimit of maximum deviation of 10 NM from \nthe actual path. The maximum deviation is \ncomputed as the maximum perpendicular \ndistance from the nodes on the actual flown \npath to the closest point on the inferred flown \nflight plan path (see Figure 3, in which the \nmaximum deviation is the perpendicular \ndistance of the inferred flight plan path from \nits flown path node A2). Results from this test indicated that the majority of flights deviated \nfrom the flight plan by more than 10 NM (for \nexample, analysis of flights on August 1, 2015, \nshowed 59 percent deviated more than 10 NM and 33 percent deviated more than 25 NM). \nTo address this, an algorithm that aligns the deviated section of the flight plan based path to \nthe flown path is developed. Steps in this algorithm are: Figure 3. Deviations of Flown Path Nodes from Inferred \nFlight Plan Path Figure 2. Nodes Bound by 25N-31N and 77W 81W 9 Start with the flight path generated using the filed flight plan.1.\nTraverse nodes in the flight plan path to identify the starting and ending nodes that 2.\ndeviate more than 10 NM from the actual path.\nLocate the points on the flown path that are closest to the identified deviated 3.\nstarting and ending node. Construct a corridor 10 NM across between starting and \nending points.\nSearch for nodes from the generated database of nodes within this corridor, starting 4.\nwith high usage ones. Repeat the search for medium, low, and synthetic nodes in that \norder. Stop the search when connecting nodes less than 150 NM apart are located. \nReplace the deviated nodes with the ones found in the corridor to get an aligned 5.\nflight path. \nRepeat steps 3 to 5 for other disconnected deviated sections.6. Figure 4 illustrates steps 3 to 5. Section F2-F4 \nof the flight plan path has deviated from the \nflown path. A corridor is created over the \nflown track between points corresponding to \nnodes F2 to F5 (corridor is shown in green). \nThe fixes and waypoints (nodes) within the \ncorridor are used to construct a path that is \nclosely aligned with the flow track (path \nshown in dash yellow lines). Generate Route Segment Density Map The flown flight plan track generated from the previous step connects origin to destination \nusing segments (also referred to as route segments) defined by the nodes in the database. \nIn this step, the number of traversals over every route segment is \naggregated on an hourly basis. Please note that since flights can \ntraverse a segment in both directions, a bidirectional usage count is \nkept. If the hour of the day changes while a flight is moving across \nthe segment, the hour span with most of the traversal time is \nchosen. Table 1 shows the top 20 busiest route segments in the \ncontinental United States on a sample day of January 4, 2015, \nbetween hours 15 and 16 UTC. Route segment IAH.BOTLL had 26 \naircraft traverse in the direction of node IAH to node BOTLL, \nreflecting high usage of this segment connecting the Houston \nInternational Airport (IAH) to the departure fix (BOTLL). Similarly, \nthere was a high number of arrivals using the fix APPLE into the \nLaGuardia Airport (LGA) in New York (route segment \nAPPLE.LGA). Additional metadata including a mix of different airlines, the \nproportion of international flights, and general aviation flights may Figure 4. Aligning Flight Plan Based Path to Flown \nPath Route Segment \nForward Count\nReverse Count\nIAH.BOTLL 26 0\nAPPLE.LGA 23 0\nDOSBE.IKICO 20 0\nCEDOX.DOSBE 19 5\nBOTLL.FLYZA 19 0\nJOHNS.FOSSE 19 0\nFOSSE.CEDOX 19 0\nIAH.SHAAK 19 0\nDVR.KONAN 19 0\nIKICO.CLT 19 0\nFRWAY.TUNNE 18 0\nFLCON.DIRTY 17 0\nHYDRR.PHX 17 0\nMCO.ORL 17 0\nSHAAK.BNDTO 17 0\nERLIN.ATL 16 0\nRMG.ERLIN 16 0\nFRNCH.SKARF 16 4\nDIRTY.ATL 16 0\nSKARF.TOMSN 16 0 Table 1. Sample Route \nSegments with \nBidirectional Usage \nCount 10 also be stored along with the route segment traffic density to provide supplementary \ninformation. Figure 5 visualizes the route segment density map for route segments with \nhourly usage of five or higher across the continental United States. Figure 5. U.S.-Wide Route Segments with Hourly Usage Count of Five or Higher Assess NAS Impact of Blocking Arbitrary Airspace The route segment density map enables instantaneous assessment of the impact of blocking \nan arbitrary airspace. This is accomplished by considering the bidirectional traffic density \nof the route segments impacted by the blocked airspace. For cases where the airspace is not \nblocked for the entire hour, the impact is assumed to be distributed linearly across the hour \nand is apportioned accordingly. To test the efficacy of the Route Segment Density map in assessing the impact of blocked \nairspace, five areas of airspace, distributed throughout the continental United States as \nshown in Figure 6, were used. The areas of airspace were placed in areas of relatively high \ntraffic and oriented across the direction of flow. 11 Figure 6. Test Areas of Airspace Placed across the Continental United States Table 2 below provides the coordinates and activation time (time during which the airspace \nwere blocked). Table 2: Test Airspaces Coordinates and Activation Times Airspace Coordinates Activation Times\nEast Airspace 3629N, 8018W 3600N, 8024W\n3554N, 7509W\n3630N, 8028W 1600 1800 UTC Florida Airspace 2505N, 8214W\n2505N, 7905W\n2440N, 7907W\n2440N, 8211W 1600 1800 UTC Center Airspace 4151N, 9936W\n4148N, 9855W\n3832N, 9849W\n3836N, 9931W 1600 1800 UTC North-West Airspace 4500N, 12500W\n4500N, 12000W\n4430N, 12000W 1600 1800 UTC 12 4430N, 12500W\nWest Airspace 3431N, 11514W 3431N, 11430W\n3111N, 11430W\n3111N, 11514W 1600 1800 UTC Using actually-flown tracks, the number of flights intersecting the five test airspace during \nthe time they were active were compared to the ones using the Route Segment Density map \nfor the entire year of 2016, resulting in a total of 366 comparisons. The results, depicted in \nFigure 7, show a close alignment between the actual number of impacted flights and the \nassessment made using the Route Segment Density map. 13 Figure 7. Actual Intersection vs. Based on Route Segment Density Map for the Test Airspace Areas In another analysis, the assessed impact number was correlated to the actual impact \nnumbers for all the areas of airspace. The results depicted in Table 3, show a strong \ncorrelation between the two. Table 3. Correlation between Actual Impacts and Those Based on Route Segment Density Map Airspace RSquare 14 East Airspace 0.983004\nFlorida Airspace 0.948678\nCenter Airspace 0.938896\nNorth-West Airspace 0.866413\nWest Airspace 0.948552 These results indicate that the Route Segment Density map is an efficient way to reduce \ntrack data to perform instantaneous impact assessment. While there is some loss in \naccuracy due to multiple steps involved in generating the Route Segment Density map, it is \nnot significant. An interesting observation from the results in Table 3 is that the data \nreduction for the North-West airspace introduced higher error (indicated by lower \ncorrelation). There may be multiple reasons for this, such lower conformance of flown path \n(compared to the filed flight plans) or less availability of available fixes to align the track to \nthe actual path. VI. Air Traffic Projection Model Air traffic expected to flow through an
airspace is influenced by several factors. These \ninclude the flight schedules; time of the day and seasonal pattern; effect of weather events \nsuch as thunderstorms, fog, low visibility conditions, wind speed, and direction; temporary \ncapacity constraints such as construction on a runway or problems with radars; special \nevents and military operations requiring closure of SUA; changes due to mechanical issues \nwith aircraft; avionics capabilities of the aircraft; and air traffic control techniques used by \nthe controllers. Most of these factors and their impact on the traffic flow are not known \nahead of time. Flight schedules are published in advance; however, they do not include \ngeneral aviation which makes up approximately 20 percent of U.S. traffic. Moreover, the \nschedule data does not contain the expected path (trajectories) of the flights, which is \nneeded for modeling the impact of blocked airspace. For the near-term future (four to eight \nhours), it is possible to predict flight trajectories based on the filed flight plans and the \navailable weather and wind forecast. However, in this research, we are targeting predicting \ntraffic for a relatively long-term time horizon (up to 12 months in future) at a high level of \ntime granularity (hourly), and for this, there are no clear predictors of the future traffic \npattern. The approach to predicting traffic used in this research applies heuristic methods to \nhistorical traffic patterns. Since traffic in the NAS is influenced by several factors that \ncannot be known in advance, projection estimates are produced as a range of likely low to \nlikely high values along with the mean, instead of a single value, which is unlikely to be \naccurate. The model essentially produces an estimate of the range of likely impact of \nblocking an airspace for the given length of time, based on historical traffic pattern at that \nlocation. The traffic predictions from this model are encoded in the Route Segment Density map data \nstructure described earlier, to enable what-if analysis for predicted impact. 15 To summarize, the steps involved in developing this model are:\nAnalyze the historical traffic of the continental U.S. airspace to uncover traffic patterns. Develop a traffic projection model based on the results of this analysis. Encode the projection model into the Route Segment Density map to enable its use in a what-if analysis paradigm. These steps are described in detail in the sections that follow. To assess the accuracy of the model, its results are compared to an alternate method of \nprojection. The track data from the years 2011 to 2015 is used to develop the model to \nproject for the year 2016. Analyze Historical Traffic Pattern in the Continental U.S. Airspace To analyze the historical traffic pattern in the continental United States, three areas of \nairspace are chosen at different locations, as shown in Figure 8. These areas of airspace \nspan approximately 100 NM and are oriented across the direction of traffic flow at that \nlocation, and together are considered to reflect the traffic pattern observed in the \ncontinental United States. Air traffic within a specific airspace within \nthe NAS changes from one moment to the \nnext, and needs to be aggregated by a time \nunit for analysis. This unit of aggregation is \na key factor to consider when uncovering \nhistorical air traffic patterns. For example, \naggregation could be daily (consider the \nhistorical behavior of all flights crossing an \nairspace during a day such as March 1, \n2016), monthly (consider the historical \nbehavior of all flights crossing the airspace \nduring a month, such as March 2016), and \nso on. The unit of aggregation should be \nsufficiently granular to capture the traffic \npattern without being noisy. Flights for the West Airspace (see Figure 8) aggregated daily over years 2010 to 2015 are \nshown in Figure 9. The chart below appears very noisy and not suitable to uncover traffic \npatterns. Figure 8. Airspaces Chosen to Proxy the U.S. Air Traffic \nPattern 16 Figure 9. Flights Aggregated Daily for West Airspace during the Years 2010 to 2015 When aggregated monthly (see Figure 10), the traffic plot appears flat with no pattern. Figure 10. Flights Aggregated Monthly for West Airspace during the Years 2010 to 2015 These results point to a need to consider a unit of aggregation between daily and monthly, \nthat is at a weekly level. The weekly numbers begin at the start of the year; for example, \nweek number 1 is the set of the first seven days of the year. Since a set of seven consecutive \ndays represents all the days of the week, weekly aggregation cancels the effect of day of \nweek variation and appears to be a good candidate. 17 Figures 11, 12, and 13 show the weekly traffic pattern for the three areas of airspace. The \ncharts reflect the seasonal traffic trends, especially pronounced in Florida (see Figure 12) \nand are not noisy. Based on these observations, weekly aggregation is chosen, as it is \ngranular enough for a pattern discovery without being too noisy. 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 Week Number 0 1000 2000 3000 4000 5000 6000 7000 N\num be\nr o f I\nnt er\nse ct\nin g \nFl ig\nht s Florida Airspace Weekly Flights Intersections Y2010 Y2011 Y2012 Y2013 Y2014 Y2015 Figure 12. Flights Aggregated Weekly for Florida Airspace during the Years 2010 to 2011 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 Week Number 0 500 1000 1500 2000 2500 3000 3500 N\num be\nr o f I\nnt er\nse ct\nin g \nFl ig\nht s West Airspace Weekly Intersecting Flights Y2010 Y2011 Y2012 Y2013 Y2014 Y2015 Figure 11. Flights Aggregated Weekly for West Airspace during the Years 2010 to 2011 18 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 Week Number 10000\n12000\n14000\n16000\n18000\n20000\n22000\n24000\n26000 N\num be\nr o f I\nnt er\nse ct\nin g \nFl ig\nht s North-East Airspace Weekly Flights Intersections 2010 2011 2012 2013 2014 2015 Figure 13. Flights Aggregated Weekly for North-East Airspace during the Years 2010 to 2011 The charts above also indicate that the traffic flowing through the selected areas of airspace \ndid not significantly change between years 2010 to 2015. A separate analysis revealed an \naverage yearly growth of 2.75 percent during this time. Based on the analysis above, and because air traffic tends to follow a weekly pattern, the \nprojection model uses week number and day of the week to correlate historical days to the \nday to be projected. To capture the past seasonal traffic trend, the model additionally \nselects same weekday from two weeks before and two weeks after the week of the day \nbeing predicted from the previous six years (see the shaded section in Figure 12), thus \nselecting 30 (5 days in each of past 6 years) historical days in total. The distribution of \ntraffic in the selected historical days is used to arrive at the mean and likely low and high \nvalues of projected impact. To summarize, steps to project for day Dp, at Hour Hp occurring in Week Number Wp in the \nyear Yp are: From the previous year (Yp -1), select five historical days from the week numbers Wp-2 a.\nto Wp+2, which are the same day of the week as Dp.\nRepeat the above steps for the previous five years (Yp-6) to (Yp-2), to get a total of 30 b.\nhistorical days.\nUse distribution of impact for these historical days to project the impact for Dp; 25 c.\npercentiles and 75 percentiles are used as the low and high bounds and mean as the \nimpact.\nHourly impact numbers are based on average impact during the Hour Hp for the 30 d.\nselected historical days.\nA multiplication factor of 1.0275 is applied to all metrics to reflect historical grown rate e.\nof 2.75 percent. For example, the traffic prediction for March 1, 2016, at Cape Canaveral (Tuesday occurring \nin week number 9) is based on the distribution of the traffic on Tuesdays during week \nnumbers 7, 8, 9, 10, and 11 for the years 2011 to 2015. 19 Predict Future Traffic During Holidays Holidays such as Christmas Day or Memorial Day change the air traffic pattern. Certain \nholidays, such as Memorial Day and Thanksgiving Day, fall on the same day of the week \nevery year, and historical traffic patterns can be readily applied to these. Others, such as \nJuly 4, may fall on a different day of the week every
year, and the traffic pattern in that year \nwill depend on a specific day, particularly in relation to the weekend. To uncover the \nholiday traffic pattern, the days relative to the holidays are compared for the years 2010 to \n2014. Figure 14 shows the percentage variance in traffic from a 60-day mean around \nThanksgiving Day for the Florida airspace. Days relative to Thanksgiving Day are labeled as \nT+/-<relative day>, for example T-1 means the day before Thanksgiving. \nFigure 14. Historical Traffic Patterns during Thanksgiving The figure shows that the Wednesday before and Sunday after Thanksgiving Day tend to be \nbusy, while day after Thanksgiving is light in traffic across all the years. Figure 15 shows the percentage variance in traffic from a 60-day mean around July 4 for the \nCape Canaveral site. The chart shows no specific trend, since July 4 may fall on a different \nday of the week each year, which in turn influences overall traffic trends (i.e., a Wednesday \nholiday may not produce increased demand whereas a Monday or Friday holiday may). 20 Figure 15. Historical Traffic Pattern during July 4 \nFor holidays, that fall on the same day of the week (such as the Thanksgiving Day), the \nmodel selects historical days that are same relative days compared to the holiday. For other \nholidays, no special processing is used. In this model, the holidays during which unusual traffic is anticipated are: Memorial Day Labor Day Thanksgiving Day Christmas Day Adapt Projection Model for Use in the Route Segment Density Map The projection model described above needs to be encoded in the Route Segment Density \nmap to support an on-demand projected impact assessment capability. The impact \nassessment model used to assess historical impacts described earlier can then be used to \nassess future impacts as well. In Section IV (Data Reduction and Encoding), bidirectional traffic traversing route segments \nis aggregated to generate a Route Segments Density map of the historical traffic. Route \nsegments can also be used to store the projected bidirectional traffic density to generate a \nProjected Route Segment Density map. The projected traffic density of a route segment can \nbe derived based on the projection model described above (i.e., by using the distribution of \nits usage across 30 historical days selected by the projection model). 21 One potential issue with this approach is that fixes \nand waypoints used by traffic in an area may change \n(or fixes can be renamed) over a period (six years is \nused for this research). This would result in a route \nsegment not appearing in all the past years, thus \nresulting in less than 30 days sample data to project \nfor that route segment. Table 4 shows historical \ndays that had the flight counts for the busiest 20 \nroute segments (shown earlier in Table 1). Analysis \nof route segments in the top 2.5 percentile (450 \nroute segments) in terms of usage showed an \naverage number of historical days to be 23.8, which \nis considered acceptable for this model. Section VIII \ndiscusses other approaches that can improve the \nmodel sample size. Since usage patterns of fixes and waypoints change \nover time, route segments used in the year prior to \nthe projected year are used to make the projections. To summarize, steps to project for day Dp, at Hour Hp occurring in Week Number Wp in the \nyear Yp are: Select the surrogate day Ds from the previous year (Yp -1) as one that is same day of the a.\nweek as Dp and in the Week number Wp.\nFor each route segment in the Route Segment Density map for day Ds, get the b.\ndistribution of the traffic density for historical days using the traffic projection model. \nFewer than 30 days may be selected, as discussed before.\nCompute the mean value, 25 percentile, and 75 percentile values as the range of c.\nprojected traffic density for that route segment.\nRepeat steps b and c for each hour of the day, to store it in the Projected Route Segment d.\nDensity map.\nThe Projected Route Segment Density map can be used to project traffic for any blocked e.\nairspace based on segments that intersect the airspace. The projection model encoded in the Route Segment Density map uses the distribution of \nroute segments in the previous years to generate mean, low, and high estimates of \npredicted impact. Using a value based on a large sample size reduces the effect of outliers in \nthe historical usage counts. Preliminary Results of Using the Projection Model and Discussion There is innate randomness in the traffic pattern in the NAS, which will limit the accuracy of \nany projection model to predict it. This model targets relatively long-term horizon of 12 \nmonths and at one-hour granularity, and is not expected to yield high-fidelity results. Route Segment \nForward Count\nReverse Count Historical Days Used\nIAH.BOTLL 26 0 5\nAPPLE.LGA 23 0 30\nDOSBE.IKICO 20 0 30\nBOTLL.FLYZA 19 0 5\nCEDOX.DOSBE 19 5 30\nDVR.KONAN 19 0 30\nFOSSE.CEDOX 19 0 30\nIAH.SHAAK 19 0 5\nIKICO.CLT 19 0 30\nJOHNS.FOSSE 19 0 30\nFRWAY.TUNNE 18 0 30\nFLCON.DIRTY 17 0 26\nHYDRR.PHX 17 0 21\nMCO.ORL 17 0 30\nSHAAK.BNDTO 17 0 5\nDIRTY.ATL 16 0 10\nERLIN.ATL 16 0 10\nFRNCH.SKARF 16 4 15\nRMG.ERLIN 16 0 26\nSKARF.TOMSN 16 0 15 Table 4. Frequency of Route Segment \nAppearing in 30 Historical Days Selected \nby the Projection Model 22 5 Projected National Rate of Enplanement as per FAAs TAF available at: \nhttps://www.faa.gov/data_research/aviation/taf/media/taf_summary_fy2014-2040.pdf Preprocessing and reducing data to make the model suitable for use in a what-if analysis \ncapability will further degrade its results. The approach used to assess the efficacy of this \nmodel is to compare its results with an alternate traffic projection model, as well as with \nobserved impacts based on actual flight paths. The model is developed using historical \ntraffic from the year 2011 to 2015, the tracks from 2016 are used to assess the results. The following comparisons are performed: Comparison to a projection model that uses TAF5 average (2.0 percent) growth applied to the previous years traffic as a proxy for the next year\nComparison of trends of the moving average of actual impacts to the moving averages of projected low and high values for the year\nPercentage of times the actual impact values fall within the predicted low to high range All the comparisons are performed on a set of test airspace areas listed in Table 2. Comparison with Projection Based on the Previous Year Traffic Model The truth data is first generated as the daily number of flight tracks intersecting the test \nareas of airspace (see Table 1) to arrive at a total of 365 data points (February 29 is \nignored) for the year 2016. These are termed Actual intersections. Next, the projection using the previous year traffic model is generated. This model projects \nby applying a growth factor to the prior year traffic. The daily traffic in the year 2015 is \nused to find the number of flights that will intersect the test areas of airspace. A growth \nfactor of 2.0 percent is applied to the result to arrive at 365 projections for the year 2016. \nThese projections are termed Prior-year based. The difference between actual and \nprojected value (actual minus projected) is a measure of error. Finally, the model is used to project demand for each day in 2016, where these projections \nare termed Model-based. The difference between actual and model projected values is a \nmeasure of error for the model; this is compared to observed error for the Prior-year based \nmodel, and results are shown in Table 5. Table 5. Comparison between Prior-Year Based and Model-Based Projection Accuracy Airspace Mean (Error) Std Dev (Error)\nModel Prior-Year Model Prior-Year East 3.48 -9.53 45.63 62.68\nFlorida -4.4 4.54 16.24 22.97\nCenter 0.90 13.89 36.09 41.03\nWest -1.76 4.28 18.12 20.83 23 North-West -8.53 8.90 9.78 14.97 The results show that the Model-based projections are consistently more accurate than the \nPrior-Year based projections, indicated by lower mean and standard deviation of error for \nall of the areas of airspace. Comparison of Trends of Actual vs Estimated Range Seven-day moving averages of actual intersections are plotted along with moving averages \nof low and high estimates of the model for all test areas of airspace in Figure 16. 1/1/20161/3/20161/5/20161/7/20161/9/2016 2/2/20162/4/20162/6/20162/8/2016 3/1/20163/3/20163/5/20163/7/20163/9/2016 4/2/20164/4/20164/6/20164/8/2016 5/2/20165/4/20165/6/20165/8/2016 6/1/20166/3/20166/5/20166/7/20166/9/2016 7/1/20167/3/20167/5/20167/7/20167/9/2016 8/2/20168/4/20168/6/20168/8/2016 9/1/20169/3/20169/5/20169/7/20169/9/2016 0 100 200 300 400 500 600 N\num be\nr O f I\nnt er\nse ct\nin g \nFl ig\nht s Actual (Moving Average) Low (Moving Average) High (Moving Average) East Airspace Actual vs Estimated Range 1/1/20161/3/20161/5/20161/7/20161/9/2016 2/2/20162/4/20162/6/20162/8/2016 3/1/20163/3/20163/5/20163/7/20163/9/2016 4/2/20164/4/20164/6/20164/8/2016 5/2/20165/4/20165/6/20165/8/2016 6/1/20166/3/20166/5/20166/7/20166/9/2016 7/1/20167/3/20167/5/20167/7/20167/9/2016 8/2/20168/4/20168/6/20168/8/2016 9/1/20169/3/20169/5/20169/7/20169/9/2016 0\n20\n40\n60\n80 100\n120\n140\n160\n180 N\num be\nr o f I\nnt er\nse ct\nin g \nFl ig\nht s Florida Airspace Actual vs Estimated Range Actual (Moving Average) Low (Moving Average) High (Moving Average) 24 1/2/20161/4/20161/6/20161/8/2016 2/1/20162/3/20162/5/20162/7/20162/9/2016 3/2/20163/4/20163/6/20163/8/2016 4/1/20164/3/20164/5/20164/7/20164/9/2016 5/1/20165/3/20165/5/20165/7/20165/9/2016 6/2/20166/4/20166/6/20166/8/2016 7/2/20167/4/20167/6/20167/8/2016 8/1/20168/3/20168/5/20168/7/20168/9/2016 9/2/20169/4/20169/6/20169/8/2016 0 50 100 150 200 250 300 350 N\num be\nr o f I\nnt er\nse ct\nin g \nFl ig\nht s\nCenter Airspace Actual vs Estimated Range Actual (Moving Average) Low (Moving Average) High (Moving Average) 1/1/20161/3/20161/5/20161/7/20161/9/2016 2/2/20162/4/20162/6/20162/8/2016 3/1/20163/3/20163/5/20163/7/20163/9/2016 4/2/20164/4/20164/6/20164/8/2016 5/2/20165/4/20165/6/20165/8/2016 6/1/20166/3/20166/5/20166/7/20166/9/2016 7/1/20167/3/20167/5/20167/7/20167/9/2016 8/2/20168/4/20168/6/20168/8/2016 9/1/20169/3/20169/5/20169/7/20169/9/2016 0 50 100 150 200 250 300 N\num be\nr o f F\nlig ht\n In te\nrs ec\ntio ns West Airspace Actual vs Estimate
Range Actual (Moving Average) Low (Moving Average) High (Moving Average) 1/2/20161/4/20161/6/20161/10/20161/12/20161/14/20161/18/20161/20/20161/22/20161/24/20161/26/20161/28/20161/30/20162/3/20162/5/20162/7/20162/9/20162/11/20162/13/20162/15/20162/17/20162/19/20162/21/20162/23/20162/25/20162/27/20163/1/20163/3/20163/7/20163/9/20163/12/20163/15/20163/17/20163/19/20163/21/20163/23/20163/25/20163/27/20163/29/20164/1/20164/3/20164/5/20164/8/20164/10/20164/13/20164/15/20164/17/20164/19/20164/21/20164/23/20164/27/20164/29/20165/1/20165/5/20165/7/20165/9/20165/13/20165/15/20165/17/20165/19/20165/21/20165/23/20165/26/20165/28/20166/1/20166/3/20166/5/20166/7/20166/9/20166/11/20166/14/20166/16/20166/19/20166/21/20166/24/20166/27/20166/30/20167/2/20167/4/20167/6/20167/8/20167/10/20167/12/20167/14/20167/16/20167/18/20167/20/20167/22/20167/24/20167/26/20167/28/20167/31/20168/2/20168/4/20168/6/20168/8/20168/10/20168/12/20168/14/20168/16/20168/18/20168/20/20168/22/20168/24/20168/26/20168/28/20168/30/20169/2/20169/4/20169/6/20169/8/20169/10/20169/12/20169/14/20169/16/20169/18/20169/20/20169/22/20169/24/20169/26/20169/28/20169/30/201610/2/201610/4/201610/6/201610/8/201610/10/201610/12/201610/14/201610/17/201610/19/201610/21/201610/23/201610/25/201610/27/201610/29/201610/31/201611/2/201611/4/201611/6/201611/8/201611/10/201611/12/201611/15/201611/17/201611/19/201611/21/201611/23/201611/26/201611/29/201612/1/201612/3/201612/6/201612/8/201612/11/201612/13/201612/15/201612/17/201612/20/201612/22/201612/26/201612/28/2016 0\n20\n40\n60\n80 100\n120\n140\n160\n180 N\num be\nr o f I\nnt er\nse ct\nin g \nFl ig\nht s North-West Airspace Actual vs Estimate Range Actual (Moving Average) Low (Moving Average) High (Moving Average) Figure 16. Actual Intersection vs. Projected Range for All Test Airspaces The charts show that estimated range values follow trends similar to actual impacts, and in 25 most cases the moving average of actual values falls within the estimated range. Accuracy of Estimated Range Table 6 shows the percentage of actual flight intersection falling in the projected range in \nthe 365 projections made for the year 2016. Table 6. Percentage of Actual Values Falling within the Estimated Range East Florida Center West North-West\nPercent in Range 81.4 82.4 79.7 96.7 88.5 The results in Table 6 show that the estimated range in most cases covers the actual flight \nintersections. Please note that this is effectively a sensitivity study future study is to evaluate the \nsensitivity of model performance to variations in constraint parameters. The test areas of \nairspace are approximately 200 NM in span and oriented perpendicular to the direction of \ntraffic. Projection of blocking airspaces of different size, shapes, and locations may produce \ndifferent results. Another variable is the activation time; changing it from the current value \nof two hours may result in different performance of the model. VII. Implementation An important goal of this research is to explore the feasibility of the model in providing \ninstantaneous impact assessment of arbitrarily defined airspace using a what-if analysis \nparadigm. To accomplish that, the projections were generated and encoded in advance in a \npreprocessing step, and a graphical user interface was developed to test the ability of the \nmodel to support what-if analysis. Preprocessing to Generate and Encode Projections The model required multiphase processing of daily flight tracks spanning five years and \ngenerating the resulting Route Segment Density maps. Steps such as inferring flown flight \nplans (see Section V) are very compute-intensive, as they require geo-spatial queries over a \nlarge database of nodes to align flight plan path to flown path. The team used a massively \nparallel high-performance computing cluster with 896 nodes and 1 TB of disk to process \nthe data and fine-tune the model. The Route Segment Density maps were stored in a geohash database to allow quick \nresponses to spatial queries and partitioning of the data to match user geographical view. \nThe size of Route Segment Density maps got reduced to approximately 45 percent of the \noriginal track data, reflecting a significant data reduction. 26 Graphical User Interface A graphical user interface was developed to illustrate the proposed concept and \ncapabilities. This interactive, web-based interface is a prototype environment that allows \nuser to conduct what-if analysis, composed of a web application that provides a front-end \nuser interface using an AngularJS interface and a back-end Java web service interface using \nSpring. Figure 17. Impact Assessor FAA View (left) and Space Operator View (right) The front-end user interface provides key functionality for the user to configure impact \nassessment parameters including date, hour, and name of the blocked airspace region. A \nuser can view traffic density for the selected time on the Route Segment Density map and \ncan draw airspace on the map. Two views shown are the FAA View and the Space \nOperator View to provide different perspectives of the same capability to two different \nstakeholders (see Figure 17). The FAA View provides flight-based metrics and airspace \nanalysis, whereas the Space Operator View is limited to display of color coded impact-\nlevels of a specific space launch or reentry operation. The back-end service handles requests from the interface using a REpresentational State \nTransfer (REST) web service, which provides a uniform interface to the prediction model \ncapable of rapid assessment of air traffic impact to blocked airspaces. This design decouples \nthe server and client and enables underlying components, including the prediction model, \nto be evolved independently of the service interface. The impact assessment data is provided from the web service as a comma separated values \n(CSV) file, which is reformatted and parsed for display. D3 is used in conjunction with \nLeaflet to provide both a geospatial mapping display and bar and pie charts displayed after \nexecuting an analysis. That enables a user to draw an airspace or load in predetermined \nhazard areas onto a map to instantaneously get metrics and visualize a Route Segment \nDensity map over the intersecting airspace at a user-designated time. Mapping overlays are \nexposed using Web Map Service (WMS)6 services, which include contextual charts including 27 6 WMS is OpenGIS standard, information at http://www.opengeospatial.org/standards/wms sectional, and en route low and high charts. The graphical user interface performed well and supported interactive impact analysis; \nmost queries were serviced within three seconds. VIII. Conclusions and Future Work The rising tempo of activities by new entrants such as space vehicle operators is putting \nincreasing demands on the national aviation airspace. As air navigation service providers \n(ANSPs) such as FAA seek to balance competing demands on the NAS safely and efficiently, \nthere is a need to research ways to increase transparency and collaboration in the use of \nairspace among all stakeholders. This research is aimed at developing models and \ntechniques to project, up to 12 months in advance, the impact of blocking any airspace. An \nexplicit goal of this research is to enable the projection model for use in a what-if analysis \nthat is accessible to a broad range of users with no prior knowledge of air traffic. Such a \ncapability will promote collaboration among all stakeholders and ANSPs. There are multiple \nchallenges in achieving these research goals. First and foremost are the innate uncertainties \nin factors affecting daily air traffic patterns and its lack of clear predictors. Another \nchallenge is enabling instantaneous response to the impact queries. In this paper, we present an approach that uses historical traffic patterns to project future \nNAS impact. We describe a data structure with encoded projection information to support \nwhat-if analysis capability. We assess the efficacy of the projection model as well as \nresponsiveness of the web-based prototype based on the model. The results on the efficacy \nof the data structure show that it is accurately able to represent the projected or historical \ntraffic flow crossing an arbitrary airspace. The initial results of the projection model show \ngood performance given the uncertainties of traffic pattern, the robustness of this \nperformance is an area of continued work. Finally, the performance of the web-based \nprototype has demonstrated the models ability to support what-if analysis of the impact \nof blocking airspaces. The projection model is based on the historical traffic pattern, and therefore planned future \nchanges in route structures will impact the accuracy of the model. Additionally, the model \ncannot be used to answer queries such as benefit of opening a special use airspace which \nhas historically been always closed. This research is ongoing, and other approaches to predict impact are being explored. For \nexample, instead of using route segments, a 10 NM grid might be used to capture historical \ntraffic patterns and to make projections. Doing so addresses the issue of changes in use of \nfixes and waypoints. Another avenue being considered is to use the flight schedules for \npredictions in the near-term range of three to four months. Enhancements to the \nfunctionality and features are also being researched. These include assessment of extra \ndistance and delay as an additional impact metrics, the ability to assess the impact of \nmultiple airspaces of the same time or of differing time windows, including altitude 28 attributes for an airspace (floor and ceiling), and extending the model to locations \nworldwide. Notice This is the copyright work of The MITRE Corporation and was produced for the U.S. \nGovernment under Contract DTFAWA-10-C-00080 and is subject to Federal Aviation \nAdministration Acquisition Management System Clause 3.5-13, Rights In Data-General, Alt. \nIII and Alt. IV (Oct. 1996). No other use other than that granted to the U. S. Government, or \nto those acting on behalf of the U. S. Government, under that Clause is authorized without \nthe express written permission of The MITRE Corporation. For further information, please \ncontact The MITRE Corporation, Contracts Management Office, 7515 Colshire Drive, \nMcLean, VA 22102-7539, (703) 983-6000. The contents of this document reflect the views of the author and The MITRE Corporation \nand do not necessarily reflect the views of the Federal Aviation Administration (FAA) or the \nDepartment of Transportation (DOT). Neither the FAA nor the DOT makes any warranty or \nguarantee, expressed or implied, concerning the content or accuracy of these views. Reference Airbus. (2017). Global Market Forecast http://www.aircraft.airbus.com/market/global-\nmarket-forecast-2017-2036/. Airbus. Amal Srivastava, T. J. (2015). Assesing Impact of Space Launch and Reentry Operations on \nthe National Airspace System (NAS) Using Historical Traffic Patterns. DASC. Prague. Boeing. (2017). Current Market Outlook, http://www.boeing.com/commercial/cmo. Boeing. Jeff Viken, S. D. (2006). NAS Demand Predictions, Transportation Systems Analysis. Hampton, \nVA: NASA Langley Research Center. Kee, J. Y. (January, 2014). SpaceX Falcon 9/Dragon Operations NAS Impact and Operational \nAnalysis. 29 Figure Captions\nFigure 1. Flight Paths from
JFK to MIA on March 3, 2017 \nAreas \n _Toc495408185\n _Toc495408187\n _Toc495408186\n _Toc495408188\n _Toc495408189\n _Toc495408190\n _Toc495408191\n _Toc495408192\n _Toc495408193\n _Toc495408194\n _Toc495408196\n _Toc495408195\n _Toc495408197\n _Toc495408198\n _Toc495408199\n _Toc495408200\n _Toc495408201\n _GoBack ",
    "text": " Approved for Public Release; Distribution Unlimited: 18-2490 Meet the MITRE Summer Interns at the NCCoE, Class of 2018! Some of MITREs summer interns took a break from their work for the National Cybersecurity \nFFRDC (NCF) to strike a pose for their class photo. As the nations first and only cybersecurity \nFederally Funded Research and Development Center, the NCF works across government and \nindustry to solve cybersecurity challenges that pose a serious risk to national security, public \nsafety, and economic prosperity. The interns are based at the NCFs principal work program, \nthe National Cybersecurity Center of Excellence (NCCoE) in Rockville, Maryland, which is \nsponsored by the National Institute of Standards and Technology (NIST). While some of the students are local, others hail from towns and cities from across the \ncountrysome from as far away as Florida, Mississippi, New York, and Illinois. All are pursuing \ngraduate and undergraduate degrees, enabling them to work alongside MITRE and NIST \nprofessional staff on a variety of challenging projects for the NCCoE, including Mitigating \nInternet of Things-Based Distributed Denial of Service attacks, Multifactor Authentication for e-\nCommerce, and mobile device security. This fall, most of the students will return to their respective campuses, while others will stay on \nat the NCCoE to continue work on their projects. Learn more about internships at MITRE by https://www.nccoe.nist.gov/\nhttps://www.nccoe.nist.gov/projects/building-blocks/mitigating-iot-based-ddos\nhttps://www.nccoe.nist.gov/projects/building-blocks/mitigating-iot-based-ddos\nhttps://www.nccoe.nist.gov/projects/building-blocks/mitigating-iot-based-ddos\nhttps://www.nccoe.nist.gov/projects/building-blocks/mitigating-iot-based-ddos\nhttps://www.nccoe.nist.gov/projects/use-cases/multifactor-authentication-ecommerce\nhttps://www.nccoe.nist.gov/projects/use-cases/multifactor-authentication-ecommerce\nhttps://www.nccoe.nist.gov/projects/building-blocks/mobile-device-security Approved for Public Release; Distribution Unlimited: 18-2490 visiting MITREs student programs page. Shown from left to right are Joshua Cobbins, Chelsea Deane, Michael Dundas, Ali Janlou, Charles \nJones, Trevon Williams, Tom Conroy, Bronwyn Hodges, Taylor Meckly, Mykah Rather, Skyler \nRakowski, Brandon Everhart, and Mike Garippo. (Photo taken by Devin Wynne.) https://www.mitre.org/careers/student-programs\nhttp://info.mitre.org/people/app/person/38268#Phonebook _top\n _GoBack ",
    "text": " Approved for Public Release; Distribution Unlimited: 18-2491.\n Building a New Kind of Math to Identify Critical Cyber Connections Teaser: One of the challenges of managing vulnerabilities of cyber networks is the number of \ninterdependent elements. MITRE researchers have developed a way to analyze these \nrelationships by identifying the \"known unknowns\" and quantifying their impact. Several years ago, the then-Secretary of Defense talked about the known knowns and known \nunknowns, which echoes what Confucius once wrote: To know what you know and what you \ndo not know. That is true knowledge. It sounds almost mystical. In fact, much scientific research is based on this concept of seeking information where you only \nhave a piece of the puzzle. Scientists develop hypotheses and then test them. Developing ways \nto capture the impact of what's known to be unknown is often a critical ingredient in this \nprocess. Especially if you don't want any unwelcome surprises. This is just as true in the evolving science of cybersecurity as in more traditional disciplines. For \nexample, many types of systems today rely on assets connected in cyberspace. They're \nincreasingly engineered by joining separate systems to provide capabilities and services. At \nMITRE, researchers are using techniques to identify critical components in a cyber network or \nmission. They must identify critical nodes to defend or attack in a cyber network, as well as \nquantify a systems resilience. Quantifying the Nature of Dependencies To contribute to this approach to cyber, Dr. Les Servi and his team developed within our \nindependent research program a set of methods to quantify the impact of known unknowns. \nThey call their newly developed tool the Robust Network Analysis (RNA). They built upon a body \nof knowledge called Functional Dependency Network Analysis (FDNA), first developed by MITRE \nchief engineer Paul Garvey many years ago to quantify the dependency between nodes. Servi, project lead for a larger cyber analytics research initiative, explains what the team's work \ninvolves. Lets say you have one task and sub-tasks and sub-sub tasks, he says. To do that \ntask, you have to do this one. To do this task, you have to do these four tasks. You must map \nthis all out and quantify the nature of the dependencies between the tasks, as well as quantify \nwhat is not known about these dependencies. Once the system is mapped, researchers can identify the critical nodes. Servi identifies some of \nthe questions you must answer. What are the nodes that you should attack if you want to hurt \nthis network? If you wanted to defend the network, which nodes should you fortify? Which \nnodes should you learn more about to better understand your vulnerability?\" For some systems, you can rank order the criticality of the nodes. For other systems, such https://www.mitre.org/research/overview\nhttps://www.mitre.org/research/overview\nhttps://www.mitre.org/research/overview\nhttps://www.mitre.org/research/overview Approved for Public Release; Distribution Unlimited: 18-2491.\n ordering is not meaningful, as the nodes most critical when faced with a highly capable \nadversary might be very different from the nodes when faced with a much less capable \nadversary. Building New Mathematics as a Hedge Against the Unknown FDNA is one approach to characterizing the dependencies between a task and its sub tasks,\" \nServi says. This is a time-consuming process requiring experts in the system of interest. \nFurthermore, even experts may not agree on the dependencies. To remedy this, Servis team \ndeveloped a way of using simulation results to complement the experts opinions. However, even with this approach, if you dont know dependencies precisely because it's too \ntime-consuming to get that precision, you have to figure out how to hedge against what's \nunknown,\" he explains. \"We designed an algorithm to identify the set of critical nodes in such \nsystems that helps practitioners hedge against what they know they dont know. He likens it to \nnavigating with a very bad map.\" This process, known as robust optimization, took existing methods in the academic literature \nand extended it to problems of interest to potential MITRE sponsors for mission network \nanalysis. Servi says robust optimization is a a cautious hedge. You know you don't know things, so you \nshould make decisions taking that into account. We joke that 'hope is a bad strategy for dealing \nwith the unknown.' In other words, you're moving a \"fragile decision\" to a \"robust decision.\" Optimization methods have been aiding our national security for decades. As early as World \nWar II, optimization methods assisted in locating German U-boats that were attacking \nmerchants ships. Servis teams goal is to use and build on modern optimization methods to \nassist in our current major challenge related to cyber networks. Robust Optimization in the Wider World Servi notes that MITREs robust optimization research isn't limited to cybersecurity and could \npotentially help many government programs. For example, it could benefit government \nacquisition a famously complex endeavor involving many moving parts and many unknowns. To spread the word about this work, the team has published papers in academic journals and \nspoken at universities, as well as the Boston chapter of INFORMS (the Institute for Operations \nResearch and the Management Sciences), which Servi currently runs. We're pushing the state of the art,\" he says. That's our job. However, we build prototype \nsoftware to quantify the impact of this work to illustrate how it can be used by government \nagencies. We want to build upon the intellectual property so we can make it available to a \nbroader audience. https://www.mitre.org/capabilities/acquisition-effectiveness/acquisition-initiatives/agile-acquisition\nhttps://www.mitre.org/capabilities/acquisition-effectiveness/acquisition-initiatives/agile-acquisition\nhttps://www.semanticscholar.org/paper/Deriving-Global-Criticality-Conditions-from-Local-Servi-Garvey/30a0506995fac1751e47f6c45ca53dc2cb3bd161\nhttp://annanagurney.blogspot.com/2018/03/fabulous-talk-by-informs-fellow-dr-les.html\nhttp://annanagurney.blogspot.com/2018/03/fabulous-talk-by-informs-fellow-dr-les.html\nhttp://annanagurney.blogspot.com/2018/03/fabulous-talk-by-informs-fellow-dr-les.html\nhttp://annanagurney.blogspot.com/2018/03/fabulous-talk-by-informs-fellow-dr-les.html\nhttp://annanagurney.blogspot.com/2018/03/fabulous-talk-by-informs-fellow-dr-les.html Approved for Public Release; Distribution Unlimited: 18-2491.\n The government may find this too risky to do alone, but that's okay. We're in the business of \nbridging between agencies and industry and taking risks though our research program, Servi \nsays. \"This is just one example of how MITRE invests in creating new capabilities to help make the \nworld a safer place, whether in the cyber realm or elsewhere. by Blair Gately _top\n _GoBack ",
    "text": " \nApproved for Public Release; Distribution Unlimited: 18-2758. AFCEA Honors MITRE Engineers for Groundbreaking Military Research\nTwo MITRE engineers have won international awards for their groundbreaking work in \ndeveloping new methods to help the military achieve its mission. Both honorees are based at \nMITREs Bedford, Massachusetts, campus. Dr. Chris Niessen has won the 2018 Meritorious Rising Star Award for Achievement in \nEngineering from the Armed Forces Communications & Electronics Association (AFCEA) for his \nbody of work, including creating a way to test complex military field radios in the lab rather than \nin the field. Dr. Ben Poole is a winner of the \"Forty Under Forty\" award for his accomplishments, including \nhis development of a detailed handbook to guide the government through the complex process \nof acquiring equipment that meets its technical specifications. The award is given to 40 \nengineers worldwide under the age of 40; awardees are evaluated by the Young AFCEAN \nAdvisory Council. Bringing the Real World into the Lab Niessen developed a method to test Army field radios by emulating real-life conditions in a \nlaboratory. It was relatively simple to test radios when they only had to communicate with one \nor two additional units, he says. But once the radios became more complex and had to \ncommunicate with a larger network, accurate testing became much more difficult. \"There wasn't any good way for the Army to try to buy these new modern radios and test \nthem, he says. \"You could strap it to a soldier's back, have him walk around in the field, get \ndata and spend forever trying to figure out how you got those results.\" In addition, a one-time test in the field wouldnt guarantee the same results in different \nconditions. Niessen found a way around that by developing an RF Emulatora device that \nrecreates a field environment under controlled conditions. With the emulator, the tester can \nreproduce those field conditions while the Army puts the radio through its paces. The RF Emulator, which Niessen developed several years ago with a team of MITRE engineers, \nwas so noveland so neededthat commercial electronics companies scrambled to create \nsimilar devices. Writing the \"Cookbook\" Poole credited a team of engineers from several disciplines across MITRE with helping him put \ntogether what he called a cookbook for an Air Force concept to increase program \nperformance of technically complex military acquisitions. \"Because of the complexity of the acquisition process, developing a handbook for it has to be, \nalmost by definition, a team sport,\" he says. \"There were a lot of folks at MITRE who made https://www.afcea.org/site/sites/default/files/files/All%20AFCEA%20International%20Award%20Winners%202018.pdf\nhttps://www.afcea.org/site/sites/default/files/files/All%20AFCEA%20International%20Award%20Winners%202018.pdf\nhttps://www.afcea.org/site/sites/default/files/files/All%20AFCEA%20International%20Award%20Winners%202018.pdf\nhttps://www.afcea.org/site/?CFID=1366cdbf-9921-4260-9e93-af676f015dbe&CFTOKEN=0\nhttps://www.afcea.org/site/40U40Winners\nhttps://www.afcea.org/site/YoungAFCEAN \nApproved for Public Release; Distribution Unlimited: 18-2758. significant contributions to what came to be known as the 'Owning the Technical Baseline \nCookbook.'\" \"I had a co-author, Dave Crawford, a cost-analysis expert at MITRE, and help from a whole team \nhere who have a lot of experience in a wide variety of acquisition activities,\" Poole says. Active in Local AFCEA Chapter \"I really appreciate the opportunity to be recognized along with a lot of other really impressive \npeople. AFCEA is a great organization we work with a lot at MITRE,\" Niessen says. Both he and \nPoole are members of the Lexington-Concord Chapter of AFCEA International. Niessen has been involved in MILCOM, AFCEA's international conference for military \ncommunications. He has helped recruit MITRE engineers to give talks on new technology at the \nevent. Niessen notes that MITRE has been the beneficiary of a fellowship program sponsored by the \nLexington-Concord chapter. The program is for Boston-area high school graduates interested in \npursuing a career in science, technology, engineering or math. The chapter awards the students \na scholarship and a 10-week paid internship. MITRE has hosted AFCEA interns for more than 50 \nyears. Some of them have gone on to become MITRE employees. \"Its an honor to have members like Chris and Ben on our team,\" says Lexington-Concord \nChapter President Pat Dagle. \"In addition to putting the power of engineering to work to \nimprove our nation's defense, they've done AFCEA proud.\" --By Tom Nutile https://events.afcea.org/MILCOM18/Public/enter.aspx\nhttps://www.mitre.org/careers/student-programs/student-voices/building-a-resume-one-summer-at-a-time _top\n _GoBack ",
    "text": " Russias Context for Cyber and \nInformation Issues: \nNine Thoughts for Consideration Author: Timothy Thomas May 2018 Sponsor: USEUCOM\nContract No.: W56KGU-17-C-0010\nProject No.: 0718S120 The views, opinions and/or findings \ncontained in this report are those of \nThe MITRE Corporation and should \nnot be construed as an official \ngovernment position, policy, or \ndecision, unless designated by other \ndocumentation. This technical data was produced for \nthe U.S. Government under Contract \nNo. W56KGU- 16-C-0010, and is \nsubject to the Rights in Technical Data-\nNoncommercial Items clause at DFARS \n (NOV 1995). Approved for Public \nRelease: Distribution \nUnlimited. Case Number 18-\n1941\n \nCorporation. \nAll rights reserved. Table of Contents 1 Introduction \nPutin Press Secretary Dmitri Peskov, referring to Kim Kardashians popularity, noted that a Twitter account able to reach millions of people can cause geopolitical chaos in just minutes. He \nstated: shes got no intelligence, no interior ministry, no defense ministry, no K.G.B. \nThis is the new reality: the global proliferation of the kinds of reach and influence \nthat were once reserved for the great powers and, more recently, great media \nconglomerates.1 Since the 1980s, Kremlin attitudes about the so-called information age have oscillated greatly. \nDuring the days of the Soviet Union, media outlets and TV, to include Xerox and fax machines, \nwere tightly controlled, since information was power. With the 1991 demise of the Soviet \nUnion, Russian analysts quickly understood that cyberspace offered information access to \nanyone with an Internet link. Seemingly unlimited data was available for free and individuals or \ngroups could link up with those of similar interests (pro- or anti-government, etc.) and become \ninfluential segments of society. Eventually Russias leadership became suspicious of information \nout of their control, and began visualizing the hand of foreign media agents everywhere to \ninfluence its citizens. Years later, that same leadership sees opportunities as well. The information age has become an \nera capable of internal control (via legislation) and external influence, since in the latter case it \nis possible to exploit populations in nations with open information systems and a democratic \nstyle. This is done through a host of tactics (fake photos, use of Internet trolls, one-sided \nreporting, etc.) that manipulate public opinion in tune with Russias interpretation of objective \nreality. Through media outlets such as Russia Today (RT) and Sputnik, Russia accesses both \ncompatriots located in other countries (in former Warsaw Pact nations or republics) and \nnumerous external media markets, which happily accept Russian rubles and offer Russian TV \npackages. The following discussion covers nine contemporary cyber/influence issues associated with \nRussias military and civilian use of the Internet and television propaganda. The purpose is to \noffer an expansive view of Russias approach to gain a strategic propaganda advantage or, if that \nis not attainable, equal information security in the years ahead. Topics covered include \ninformations impact on the initial period of war, the use of reflexive control, the ability to \nmanipulate presidential elections (in 2004!), information templates, centers of gravity, the \nmilitarys Intranet use, cyber troops, and Russias information infrastructure, among other \nissues. There are many surprising developments to which others could be added. 2 Vladimir Ryzhkov, The Kremlins War Propaganda, 25 March 2014, at http://www.the moscowtimes.com/opinion/article/the-\nkremlins-war-propaganda/496779.html\n3 Ibid. Cyber/Influence Issues2 Consideration One: Have Media Tactics Changed over Time?2.1\nHave Russian media tactics changed much since their intervention in Afghanistan in 1979? How \ndo they compare to those used in Ukraine? Vladimir Ryzhkov, a Russian State Duma Deputy from 1993 to 2007 and now a political analyst, \ndescribed in detail a conversation he had with a former KBG officers propaganda experience in \nAfghanistan from the 1980s, in which the officer outlined the Soviet principles of an information \ncampaign. The methods recalled by Ryzhkov from his KGB conversation are listed below,2 \nfollowed in parentheses by an example of a similar method used by Russia in Ukraine: It is necessary to convince the general population that the government is acting correctly \nand that the enemy is guilty of fomenting the crisis (Maidan protesters are to blame, the \nnew government is linked to fascists, extremists, the US, and the West, which are the \nreal aggressors). The Kremlin creates myths about the terrible persecutions of the Russian-speaking \npopulation (the spin doctors created a virtual reality that appeared to find the right \nbalance between truth and fiction, even though a human rights investigation by an \nindependent European human rights agency found no violations or persecutions of the \nRussian-speaking public in Crimea). The enemy must be demonized (Ukrainian Right Sector leader Dmitry Yarosh was used \nfor this. Moreover, the moderate forces were presented as neo-Nazis, and negative \nbackground information on Ukraines new leaders was brought to light). The authorities disguise their aggressive actions as humanitarian (Russia had a \nhumanitarian need to protect defenseless Russians in Crimea from the events that \ntranspired in Kiev). The Kremlin justifies its methods by citing alleged enemy actions (the US is trying to take \nover Ukraine, so we must defend our ancestral territories). Authorities must be presented as legal and legitimate (Crimeans have a right to self-\ndetermination). War propaganda depends on a totalitarian approach (domestically, Russia cracked down \non TV Rain and Lenta.ru for airing opposition points of view and earlier had silenced the \nmedia in Crimea once their forces intervened, pulling Black Sea TV, a local station that \nsupported the new government in Kiev, off the air ).3 Numerous other uses of cyber and information activities also took place in Ukraine. There was 4 Interfax-Ukraine News Agency, 29 May 2014, no author or title provided.\n5 Kateryna Peshko interview with Anatoliy Hrytsenko, Singular ImpressionNew Authorities Made Deal with Predecessors, \nGlavkom, 14 July 2014.\n6 Andrei Soldatov and Irina Borogan, The Red Web: The Struggle between Russias Digital Dictators and the New Online \nRevolutionaries, Public Affairs, New York, 2015, pp. 313-314.\n7 Iu. E. Kuleshov, B. B. Zhutdiev, and D. A. Fedorov, Information-Psychological Confrontation under Contemporary \nConditions: Theory and Practice, Vestnik Akademii Voennykh Nauk (The Journal of the Academy of Military Science), No. 1 \n2014, pp. 104-106.\n8 Ibid., pp. 106-109. an attempt to interfere in the Ukrainian elections4 and there has been an extensive information-\npsychological campaign on the battlefield via the manipulation of or warnings over the cell \nphone use of Ukrainian soldiers.5 Consideration Two: Russian Templates for Influence2.2\nAre there identifiable templates that Russia uses in their influence operations? Consideration one, above, offered one such template from the perspective of a KGB officer. \nAnother was discussed in the book The Red Web, where authors Andrei Soldatov and Irina \nBorogan developed a template through which to understand the Kremlins domestic approach \nto media control. They noted that Parliament produces a flow of repressive legislation that \nexploits cracks in previously published rules and regulations; hacktivists and trolls attack and \nharass liberals online, posing as someone other than a Kremlin supporter; Roskomnadzor \n[Russias Federal Service for the Supervision of Communications, Information Technology, and \nMass Media] is granted the power to censor and filter the Internet; Kremlin-affiliated oligarchs \nbankroll and take over media companies; specific manufacturers are selected to provide \nsurveillance equipment; and Putins paranoia of enemies ties these actions together, resulting in \nthreats and intimidation. Putins system is effective if people are certain the Kremlin is in \ncontrol. This dynamic is transformed when a crisis occurs and a message must be shared in real \ntime.6 In a 2014 article in the Journal of the Academy of Military Science, three authors from Belarus \ndescribed a different type of template, offering an opinion on what they termed the ongoing \ninformation-psychological confrontation. They believe the West was victorious in the \ninformation-psychological war (an economic and information war) in the early 1990s. They \ntermed this to be a new-generation war, since the confrontation rejected actual weapons. \nThey state that information-psychological warfare has now become an acknowledged form of \nmilitary art.7 This is an extremely important statement and one which Western analysts should \nseriously consider as to its meaning and expression. The authors then discussed the goals, trends, and information measures of such confrontations. \nFirst, they listed 13 ways to achieve the goals of information-psychological confrontation. \nSecond, they listed five trends that will determine the nature of information-psychological \nconfrontations in the next decade. Finally, when planning and implementing measures for \ninformation-psychological confrontations, they listed five principles that should guide actions.8 \nThe goals will be discussed further, along with trends. The authors note that the principal goals of an information-psychological confrontation are 9 Ibid., p. 106.\n10 The MH-17 shootdown refers to the destruction of Malaysian airline flight 17, destroyed by a missile allegedly launched by \nRussian troops in Eastern Ukraine; and the Sergey Skripal incident refers to the poisoning of a Russian defector to Great Britain, \nwho was poisoned along with his daughter. regime change, an increase in the time to make decisions, and the means to control people. These \ngoals are achieved via the following methods: changing the citizens moral values; creating a lack \nof spirituality; destroying traditions and cultivating a negative attitude toward cultural legacy; \nmanipulating the social consciousness; disorganizing systems and creating obstacles; \ndestabilizing political relations; exacerbating political struggles and provoking repression; \nreducing
information support; misinforming, undermining, and discrediting administrative \norgans; provoking social, political, national, and religious conflicts; mobilizing protests and \nstrikes; undermining authority; and damaging interests of a state.9 Trends that determine the nature of information-psychological confrontations are: shifting \naggression from the military-geographic domain to the information-psychological field; the role \nof television in initiating conflict; the influence of Western ideology on societys values; the \nabsence of direct invasion and destruction; and the irreversibility of the confrontations \nconsequences. The mass medias methods of manipulating TV were: blatant lies; concealing \nimportant information; immersion of information in a morass of garbage; replacement of \nterminology and use of unclear concepts and terms; introduction of taboos into certain sections \nof news; acknowledgement of the importance of images (use of well-known personalities with \nimpact); and transmitting negative information that is perceived as better than positive news by \nthe listener. While the source of this information is from a Belarus perspective and not a \nRussian one, it still offers insights into considerations of value and publishable in an important \njournal. One final template, used in both the MH-17 shootdown and the poisoning of Sergey Skripal,10 is \nthe methodology for confronting accusations of a true but damaging nature. When an event \nhappens, the initial response is to (1) deny guilt and involvement (2) immediately begin editing \nreality and creating evidence or the rationale of another sides involvement, to include \nenemy forces in the area of the attack (3) make pleas to involve Russia in the investigation (4) \nmake it appear that Russia is merely responding to attacks and (5) make conciliatory statements \nsuch as Russia is detached from unnecessary emotion. Meanwhile, Russian citizens are denied \naccess to much of the countervailing information. Consideration Three: Military Directorates for Cyber2.3\nWhat directorates guide the nations military cyber and information capabilities? In Moscow Defense Brief Number One of 2017, author Aleksey Ramm offered definitions, \nforces, and defense mechanisms of Russias cyber and information concepts. An information \noperation was defined as using specially prepared information against the adversarys armed \nforces, military or political leadership, or population to attain military, social, and political goals. \nA cyber operation was defined as attacking an adversarys information technical systems to \ndisrupt their operation or to steal or delete sensitive information. Goals have changed from \ndisrupting social networks to affecting the target audience of each. Ramm notes that the Main 11 Aleksey Ramm, Russian Information and Cyber Operations, Moscow Defense Brief, No. 1 2017, pp. 16-17.\n12 Mariya Latsinskaya, Aleksandr Braterskiy, and Ignat Kalinin, Russia Sent Troops onto the Internet: Shamanov Explained Why \nInformation Operations Troops are Necessary, Gazeta.ru, 22 February 2017.\n13 Ibid.\n14 Ibid. Intelligence Directorate of the General Staff oversees information operations. There are reasons \nto believe, he notes, that the 12th Directorate is in charge here. The General Staff Academy has a \ntraining course for senior officer in defensive measures against an adversarys information and \ncyber operations, as well as training on offensive operations by Russias own forces. Naturally \nthe Federal Security Service or FSB handles cyber operations for the government and its citizens. \nFinally, Ramm states that defensive measures for the military include a Military Internet, a \nprotected network with few interconnections. Thus, the concept, mentioned above in 2012, \nreappeared here in 2017. The Defense Ministry also has a Main Directorate for the Protection of \nState Secrets (also known as the 8th Directorate) and a Main Directorate for the Development of \nInformation and Telecommunication Technologies.11 In February 2017 Defense Minister Sergey Shoygu stated that information operation forces had \nbeen established in Russia. His comments led one to believe that these were psychological \noperation forces, since he said they were more effective than the old counterpropaganda \ndirectorate. He then added that propaganda must be smart, literate, and effective.12 A former \nChief of the USSRs KGB Analysis Directorate, Vladimir Rubanov, stated that Russias cyber \ntroops amount to 1,000 soldiers, and that information space is now as important as land, sea, \nand aerospace theaters of military operations.13 Alexander Perendzhiyev, an expert at the \nAssociation of Military-Political Scientists, stated that today victory is achieved in virtual space \nand not on the real-world battlefield. Further the report noted that: According to information on the Defense Ministry official website, there are several \nsubunits in the departments structure for now whose zone of responsibility can include \ninformation operations. Above all this is the Main (Intelligence) Directorate, the Main \nDirectorate for the Development of Information and Telecommunications Technologies \nunder the direction of Colonel Maksim Bets, as well as the Press Service and Information \nDirectorate headed by Major General Igor Konashenkov. The General Staff Eighth \nDirectorates 6th Scientific Company located in Krasnodar probably also plays a certain \npart.14 The article added that the Russian General Staff Academy is teaching a course on information \nconflict. Consideration Four: Cyber and the Initial Period of War2.4\nIs the Kaspersky anti-virus software part of Russias attempt to control the initial period of war \nthrough espionage or by implanting a capability (malware) in peacetime that could be released \non demand and cripple banking or infrastructure capabilities? From their own experiences, Russian leaders believe that the readiness of the Armed Forces to \nfight has had the greatest impact on the course and outcome of armed struggles. The ability to \nplant cyber and information means before such struggles occur has significantly increased the 15 S. G. Chekinov and S. A. Bogdanov, Initial Periods of War and their Influence on a Countrys Preparation for Future War, \nVoennaya Mysl (Military Thought), No. 11 2012, pp. 14-27.\n16 Paul Sonne, Russian Firm Was Long Seen as Threat, The Wall Street Journal, November 18-19, 2017, p. A2. importance of the concept of the initial period of war (IPW). Such means can serve key \ninformation links or corrupt entire systems, enabling victory before the first battle. The IPW was \nfirst defined in the 1920s. In 2012, it was defined as when warring states conduct military \noperations involving groups of their armed forces that are deployed before the start of war to \nachieve short-range strategic objectives or to create favorable conditions for committing their \nmain forces and continuing with more operations.15 Cyber implants are one of the most invasive tools that can be deployed forward through their \ninsertion into foreign systems in peacetime and remain capable long after insertion to achieve \nshort- or long-term objectives (either conducting reconnaissance or destroying systems when \nactivated). Due to such scientific advances, it appears that protecting critical infrastructure and \ncyber resources from cyber-attacks may even take precedence over other factors early in a \nconflict. Information technologies, precision weaponry, reconnaissance and electronic warfare \ntechnologies, and automated control procedures provoke new challenges and threats in the \nIPW for other nations. Many believe that the IPW will be decisive for the outcome of a war. A \nstate that is planning aggression will use peacetime or a period of threat to plant viruses, \ndisorganize systems of the country it wants to attack, and launch wide-scale targeted \ninformation operations and intense reconnaissance activity. Perhaps due to concern for the USs cyber security in the IPW, the US Federal Bureau of \nInvestigation (and earlier, the government of Ukraine) decided to no longer tolerate the use of \nKaspersky anti-virus solutions, a product sold in stores and advertised on prominent radio \nstations. Is it possible that the FBI feared Kasperskys ability to insert a virus or logic bomb into \ntheir critical information domain that would ensure Russia would have information superiority if \nan IPW between Russia and the US ever developed? A recent Wall Street Journal article noted \nthat the Kaspersky anti-virus has been on a Defense Department watch list of potential \nproblems since 2004. In 2013 the Defense Intelligence Agency issued a Pentagon-wide threat \nassessment about the company. US officials note that the firms products were used as a tool \nfor spying on systems in the US.16 What wasnt discussed was whether the products could also \nhave planted malware that can sit, wait, and be ordered on command to cause banking, \ninfrastructure, or other types of damage in times of stress. Consideration Five: Warning of Presidential Election Meddling2.5\nAre the 2017 charges against Russian meddling in elections worldwide the first time this \nthought has taken root, or were there earlier discussions relating to the topic? For the past two years, nearly every country in Europe has put their cyber forces on alert for \npossible interference from Russian hackers or cyber warriors. This is particularly true near \nelection time in these nations. Their warnings are based on finding active indicators of \nreconnaissance activities emanating from Russia. To think that all nations in Europe would just \nmake up such charges is inane. Meanwhile, Russia continues to reject any complicity in the face \nof overwhelming evidence. 17 Boris Rodionov, On the Waves of Energo-Information, Armeyskiy Sbornik (Army Journal), October 2004. While it is extremely hard to know just how widespread such discussions are in Russia and the \nlocus and extent of their cyber planning, there is at least one historical example worthy of \nmention. Writing in Armeyskiy Sbornik (Army Journal) in October 2004 author Boris Rodionov \ndiscussed
weapons of influence. In an eerie reference to problems associated with the 2016 US \nPresidential election and the elections in Europe, the article twice referenced influencing \nelections. One of those references read as follows: Today one can already predict the evolution of a weapons purpose; from weapons of \ndestruction to weapons of deterrence and then to weapons of influence. Using such \nweapons, it will be possible to exert long-range controlling effects on persons, and \nconsequently on the course and results of election campaigns, on the decision-making of \npresidents, prime ministers, and other high-ranking persons, and in this way to control \nthe entire world.17 Again, this article appeared in 2004! The article further stated that it was the use of information \ninfluence operations in the early 1990s that caused the USSR to cease to exist as a superpower. \nThis is a reference to the belief that the US had conducted some sort of information-\npsychological attack on the USSR that aided in the dissolution of the nation. Consideration Six: The Worries of Russian Cyber Planners2.6\nWhat is a major worry of Russian cyber planners? Russian information experts have been discussing digital/cyber issues for many years. Their \nefforts have included the drafting of a host of recommendations for consideration at the United \nNations for review and adoption, such as consideration for the definition of an information \nweapon over a decade ago. Several years later, during a 2010 Russian-sponsored conference in \nGarmisch Germany, a member of the Russian delegation was asked to rank order threats as he \nperceived them to Russia. Interestingly, escalation models were listed first. His concern clearly \nwas that a cyber exchange could mistakenly get out of control, especially due to the use by \nsome nations of surrogates or anonymous actors taking actions that responsible government \nofficials would never consider. The risk associated with such gambles was simply too high. \nSecond on the list of threats was the protection of civil infrastructures from attacks, which could \nresult in the collapse of key banking or service-oriented (gas, electric, etc.) organizations, \nresulting in chaos or confusion. Protection of critical infrastructure was listed as a priority \nconcern. Definitions were next, as it was felt the ability to define concepts such as cyber-attacks, \ncyber law, or other issues were key to keeping control over cyber-related issues and offering a \nvenue for not only discussion but a common understanding of threat issues. Of lesser concern \nto the individual was the threat of industrial espionage, most likely because Russian software \ndevelopers had become so adept and invasive in this area. For both Russia and the US, there are \nissues here that need to be discussed and settled. Peacetime is the place for the prevention of \nescalation models, not after escalation occurs. 18 Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in Information Space, \nMinisterstvo Oborny Rossiyskoy Federatsii (Defense Ministry of the Russian Federation), 2011, p. 5.\n19 Ibid.\n20 V. G. Kazakov and A. N. Kiriushin, All-Inclusive Command and Control of Combat Operations, Vestnik Akademii Voennykh \nNauk (The Journal of the Academy of Military Science), No. 4 2015, p. 39. To view an English version of the diagram in this \njournal, see Timothy Thomas, Kremlin Kontrol, 2017, Foreign Military Studies Office, TRADOC, pp. 195-196.\n21 See David E. Hoffman, The Dead Hand, Doubleday, 2009, pp. 150-154 for a worrisome discussion of the Perimeter project. Consideration Seven: Reflexive Control and Cyber2.7\nIs Russias concept of reflexive control operations a component of its information war concept? For at least the past 30 years, Russias military has employed a concept known as reflexive \ncontrol (RC). In its simplest form, it means making someone do something for themselves that \nthey are actually doing for you. A simple phishing attempt in cyberspace fits the definition \nperfectly, as the initiator of the attack gets a person to do something for themselves (open a file \nto see what is there based on misleading information in the e-mail), which allows a virus into \nthe system. The e-mails initiator thus accomplishes his or her goal, as the e-mail recipients \naction does your work. The use of analogies works the same way, as a person is led to believe \nbased on an analogy (the Russians, in 2014, made the claim that many Ukrainians involved in \nthe anti-government demonstrations in Kiev were Nazis) that he or she (a Russian) must fight \nthem, as the analogy draws on a Russians reflexive response to World War II recollections. In 2011, Russias military published a document known as the Conceptual Views Regarding the \nActivities of the Armed Forces of the Russian Federation in Information Space.18 The definition \nof information war discussed damage done to information systems, potential damage to the \nstability of society via brainwashing, and, at the end of the definition, stated that information \nwars confrontation was for forcing the state to make decisions in the interests of the \nconfronting party.19 Thus, when defining information war, the Russians included the RC \nconcept, although most Western readers of the definition would not spot it. In 2015, V. G. Kazakov and A. N. Kirishin wrote an article on RC for the Journal of the Academy \nof Military Science.20 They noted that the commander needs a special group (outside the Table \nof Organization and Equipment) with information-psychological qualifications to develop and \ntransmit the use of RC measures together with command control (readiness to execute \nassigned tasks) actions. This is done through the spreading of information packets on the \nbattlefield. An information packet could be a fake electronic warfare transmission that \ninfluences conditions. There was a diagram that accompanied this explanation, showing how \ncommand control and RC fit together to manipulate an enemys decision-making process. Consideration Eight: Is There a Cyber Dead Hand?2.8\nHas Russia developed a cyber dead hand like its nuclear dead hand concept in the past? \nDoes the military have an Intranet to ensure the security of military information as a different \ntype of backup system? In 1985, the Soviet Union tested and put on alert status a system known as Perimeter.21 It was \ndesigned to deliver a nuclear strike against the US if the latters nuclear weaponry destroyed the 22 David E. Hoffman, The Dead Hand, Doubleday, 2009, pp. 150-154.\n23 V. F. Samokhin, V. N. Lukyanchik, and A. N. Artyushenko, Prospects for a Military (Combat) Internet in the New Look \nRussian Armed Forces, Voennaya Mysl (Military Thought), No. 8 2011, pp. 57-60.\n24 Ibid.\n25 V. I. Kuznetsov, Yu. Ye. Donskov, and A. S. Korobeynikov, About the Question of the Role and Place of Cyberspace in \nModern Military Operations, Voennaya Mysl (Military Thought), No. 3 2014, pp. 14-16.\n26 Ibid. USSRs leaders and command systems before they could retaliate [or if an electronic warfare \nstrike took out the USSRs rocket force command and control capability]. The system consisted \nof missile launches from a secret bunker that could in reality throw down codes to ICBMs in \ncase the nations leadership was rendered helpless and unable to transmit codes to the Kazbek \nlaunch system. In times of tension, the system (and the officers in a bunker) might be activated in an advance \npreparation fashion. The Perimeter system would apparently be used not only if contact was \nlost with the leadership but if special sensors also indicated radioactivity, seismic shocks, and \natmospheric overpressure, all signs of a nuclear strike. In that sense the system was \nsemiautomatic, as its use still rested on people in the bunker making a final decision. An \nautomatic system was also contemplated (a Dead Hand) but apparently discarded, since it \nrelied solely on computers and took people out of the launch process.22 In 2011, in the journal Military Thought, it was reported that there were prospects for what was \ntermed a military (combat) Internet in the Russian Armed Forces. Information was viewed as a \ndecisive factor in achieving strategic and operational-tactical superiority over an adversary on \nthe battlefield. Information superiority enables speed and timely decision-making on the \nmodern battlefield. Improvements in the strategic control system through installing digital and \ntelecommunications equipment was designated as priority one for these reasons.23 It was noted \nthat many people writing on this subject tend to support development of a new Russian \nsegment, Intranet Russian Federation and that it could be protected against outside threats \nand have no risks of dependence on foreign assistance in technical problem fixing.24 Consideration Nine: Battlefield Influence Operations2.9\nHow has the military used cyberspace to influence the population and actions on the \nbattlefield? On the battlefield, operations in cyberspace have signaled Russias entrance into an entirely \nnew type of warfare. It is, according to experts, a combination of information and information \ninfrastructure designed and used on the battlefield to shape, generate, transform, transit, use, \nand store information in computers and computer networks. Cyberspace is essential for \noperations in any modern control system and is the most prioritized element of a battlespace in \nthe broadest sense. The authors of one article noted that the formation of cyberspace as a new \nrealm of combat operations called for a revision of ideas held about the forms and
methods of \ncombat actions and the content of command and control over tactical military formations.25 \nSome of the forms and methods were said to be cyber-warfare, cyber-engagement, cyber-\naction, and cyber-attack.26 27 Kh. I. Sayfetdinov, Information Confrontation in the Military Sphere, Voennaya Mysl (Military Thought), No. 7 2014, p. 38.\n28 Ibid., p. 39.\n29 Ibid., pp. 40-41.\n30 Ibid., p. 41.\n31 K. A. Trotsenko, Information Confrontation at the Operational-Tactical Level of Control, Voennaya Mysl (Military \nThought), No. 8 2016, p. 20.\n32 Ibid., p. 21. In 2014, Major General (retired) Kh. I. Sayfetdinov wrote on battlefield operations. He defined \ninformation warfare as the conscious employment of information to enable the user to achieve \nhis political, economic, military, or any other goals.27 The objective of such operations is to gain \nand hold information superiority over an adversary and to create favorable conditions for the \nArmed Forces. Operations must be conducted constantly, in peacetime and wartime.28 \nInformation operation tasks include monitoring information sources to detect, assess, and \npredict information-related threats to Russia; deceiving adversaries as to Russias plans and \nintentions; disorganizing the adversarys government and military command and control \ncapability; impairing the psychological stability of adversary forces; and maintaining the morale \nand psychological state of friendly forces.29 Subsystems of an information operations system \nwould include the ability to attack an adversarys technical information capabilities and protect \nfriendly systems from adversary attacks; software and hardware capabilities; reconnaissance, to \ninclude electronic reconnaissance capabilities; electronic warfare; and psychological warfare \nagainst an adversary, while protecting friendly forces from similar attacks by an adversary.30 In 2016, Colonel K. A. Trotsenko discussed operational-tactical control levels. Initially he \ndiscussed the basic structure and understanding of information confrontations in Russia. His \nexplanation contained the familiar division of information operations into information-technical \n(computers, electronics, etc.) and information-psychological (influencing the public and armed \nforces of an adversary). He added that this definition is strategic. At the tactical and operational \nlevels, the focus is more on organizing control and electronic warfare capabilities.31 Attaining a \ntactical goal can be determined by the degree of information superiority one has over an \nopponent and the time available to forestall adversary actions. He explains: Informational confrontation in preparing and conducting tactical actions is, \ntherefore, to imply a set of measures for organizing and effecting control, \nreconnaissance, electronic warfare, security, tactical camouflage, fire destruction \nof the adversary control systems, use of highly maneuverable units and certain \nkinds of maneuvers coordinated in terms of time, place, mission, and aimed at \nachieving superiority in controlling, deceiving, and forestalling the adversary in its \nactions.32 Conclusions3\nThis article was designed to show that Russias approach to cyber and information operations is \nthoughtful and innovative, focused on being covert and manipulative, and yet still repetitious \ndue to its use of specific concepts from Soviet days. Thoughtful in that it integrates new \ntechnologies, concepts, and approaches to cyber affairs as they develop; covert and \nmanipulative in the many ways it attempts to force its objective reality on other populations 33 V. I. Tsymbal, The Concept of Information Warfare, Presentation at a September 1995 conference in Moscow, Russia, p. 7. through reflexive control and other mass media methods; and repetitious in that many of the \ntechniques used earlier are still adaptable to current conditions as Russia continues to divide \ninformation warfare into information-technical and information-psychological aspects. This is a far cry from where Russia first started in the early 1990s. During a September 1995 \nconference in Moscow, for example, Russian information expert V. I. Tsymbal stated that the \nuse of information warfare forces against Russia would be considered a military phase of \nconflict, even if there was no loss of life. More ominously, he added: In studying the potential catastrophic consequences from an enemys use of \nstrategic IW systems on, for example, the economy or government controlwe \nmust unequivocally declare that in the case of their use against Russia, we \nreserve the right to conduct a first strike (nuclear) against the IW system and \nforces which are directing that weapon, and then also against the aggressor-\ngovernment.33 The warning was unambiguous. There apparently was a desire to use the conference to transmit \na message to the US leadership, if it hadnt made its way there earlier through other channels, \nthat the thought of an information warfare attack on Russias weak infrastructure would be an \nact of war leading to a devastating attack on the other side. Whether the conference message \nreflected actual operational plans or was used simply for deterrent purposes is not known. \nToday, since Russia has developed numerous information and cyber specialists, it is less likely \nthat Russia would answer a cyber-attack against its infrastructure with a nuclear strike. It would \nbe more likely that Russia would unleash its own powerful information strike against such an \nadversary. The analysis prompts a host of questions and suppositions about what Russias end goals might \nbe. Specifically, US attention should focus on Russias desire to achieve information superiority \nin the initial period of war; Russian attempts to manipulate objective reality to its benefit; the \ncontinued application of specific media tactics and reflexive control deception; and the various \ntemplates Russia is developing, either wittingly or unwittingly, to achieve their goals. For the \nU.S., these issues should become priority considerations. Understanding where Russia is \nheading, what techniques of persuasion they are using, and how they are shaping a future \npotential battlefield are all important considerations. There is also one other very important fact \nto keep in mind and that is for analysts to stop trying to mirror image U.S. thinking onto Russias \nway of conducting military affairs. Russia has its own priorities, concerns, and way of military \nthought. It is only through a conceptualization of Russias framework of military thought that its \nactions can be understood. Without that lens, analysts are likely to be led down some false \nroads. Russia will not go quietly into the night, as demonstrated by its addition of more military muscle \nand its persistence to worry incessantly about NATO. Russian activities, as a result, need to \ncontinue to be monitored closely. Some actions need to be confronted directly, either through \nnegotiations or through the development and implementation of new US security measures. A greater focus on the contours of Russian military thought would also be of the upmost \nimportance in trying to decipher where the nations leadership is taking them. _Toc293499070\n _Toc468868719\n _Toc468869305\n _Toc516035091\n _Toc516035092\n _Toc516035093\n _Toc516035094\n _Toc516035095\n _Toc516035096\n _Toc516035097\n _Toc516035098\n _Toc516035099\n _Toc516035100\n _Toc516035101\n _Toc516035102 ",
    "text": " Prepared for:\nDepartment of Homeland Security Dynamic Data Map Technical Report May 8, 2018 Authors: \nJason Veneman\nBrian Tivnan The Homeland Security Systems Engineering and Development Institute (HSSEDI)TM Operated by The MITRE Corporation Approved for Public Release; Distribution Unlimited.\nCase Number 18-1675 / DHS reference number 16-J-00184-08 This document is a product of the Homeland Security Systems Engineering and Development Institute (HSSEDI). i Homeland Security Systems Engineering & Development Institute\nThe Homeland Security Act of 2002 (Section 305 of PL 107-296, as codified in 6 U.S.C. 185), herein \nreferred to as the Act, authorizes the Secretary of the Department of Homeland Security (DHS), acting \nthrough the Under Secretary for Science and Technology, to establish one or more federally funded \nresearch and development centers (FFRDCs) to provide independent analysis of homeland security issues. \nMITRE Corp. operates the Homeland Security Systems Engineering and Development Institute (HSSEDI) \nas an FFRDC for DHS under contract HSHQDC-14-D-00006. The HSSEDI FFRDC provides the government with the necessary systems engineering and development \nexpertise to conduct complex acquisition planning and development; concept exploration, \nexperimentation and evaluation; information technology, communications and cyber security processes, \nstandards, methodologies and protocols; systems architecture and integration; quality and performance \nreview, best practices and performance measures and metrics; and, independent test and evaluation \nactivities. The HSSEDI FFRDC also works with and supports other federal, state, local, tribal, public and \nprivate sector organizations that make up the homeland security enterprise. The HSSEDI FFRDCs \nresearch is undertaken by mutual consent with DHS and is organized as a set of discrete tasks. This report \npresents the results of research and analysis conducted under: HSHQDC-16-J-00184\nNext Generation Cyber Infrastructure (NGCI) Apex Cyber Risk Metrics and Threat Model Assessment This HSSEDI task order is to enable DHS Science and Technology Directorate (S&T) to facilitate \nimprovement of cybersecurity within the Financial Services Sector (FSS). To support NGCI Apex use \ncases and provide a common frame of reference for community interaction to supplement institution-\nspecific threat models, HSSEDI developed an integrated suite of threat models identifying attacker \nmethods from the level of a single FSS institution up to FSS systems-of-systems, and a corresponding \ncyber wargaming framework linking technical and business views. HSSEDI assessed risk metrics and risk \nassessment frameworks, provided recommendations toward development of scalable cybersecurity risk \nmetrics to meet the needs of the NGCI Apex program, and developed representations depicting the \ninterdependencies and data flows within the FSS. The results presented in this report do not necessarily reflect official DHS opinion or policy. For more information about this publication contact: Homeland Security Systems Engineering & Development Institute The MITRE Corporation\n7515 Colshire Drive\nMcLean, VA 22102 Email: HSSEDI_info@mitre.org http://www.mitre.org/HSSEDI mailto:hssedi_info@mitre.org\nhttp://www.mitre.org/HSSEDI ii Abstract\nThe Homeland Security Systems Engineering and Development Institute (HSSEDI) assists the \nDepartment of Homeland Security (DHS) Science and Technology Directorate (S&T) in the \nexecution of the Next Generation Cyber Infrastructure (NGCI) Apex program. HSSEDI \ndeveloped a comprehensive data map of an essential subsector of the Financial Services Sector \n(FSS), namely the capital markets. This data map provides a foundational component for an \nextensive NGCI testing program. \nHSSEDI concludes this report with a set of three recommendations for the NGCI Apex program \nto enhance its representational testing environment: HSSEDI recommends that the NGCI Apex program expand this dynamic data map into \nan exhaustive depiction of workloads and time criticality for a small set of known market \nevents when the market infrastructure experienced particularly heavy workloads and \ndelays. HSSEDI recommends that the NGCI Apex program use these known market events and \nHSSEDIs Threat Model to inform detailed test scenarios for use in the representational \ntesting environment. HSSEDI recommends that the NGCI Apex program integrate this dynamic data map with \nHSSEDIs previous technical reports on Cybersecurity Risk Metrics Survey and the \nFinancial Systems Mapping to provide a comprehensive treatment of the systemic risk \nfacing the FSS. Key Words \nNext Generation Cyber Infrastructure (NGCI) Apex program1.\nCritical Infrastructures2.\nFinancial Services Sector (FSS)3.\nCapital Markets4.\nNational Market System (NMS)5. iii iv Table of Contents \n1 Project Overview \n2 Overview of the Capital Markets and Related Infrastructure \n2.2 Interdependence Across the Financial Services Sector \n3.1 Single Asset Analysis \n3.2 Multi-asset Analysis \n3.3 Bandwidth \n3.4 Infrastructure \n3.5 Dynamic Message Traffic \n3.6 Data Source \n3.7 Dynamic Data Behavior Impacts of High Traffic \nList of Acronyms \nFigure 1. Geographic location of the primary exchange data centers in New Jersey \nFigure 2. Interconnections between the exchanges \nFigure 3. Relationships and numbers of investors and exchanges \nFigure 4. Interdependence across the Financial Service Sector \nFigure 5. Apple stock price on August 11, 2015 \nFigure 6. Apple stock trades per second on August 11, 2015 \nFigure 7. Apple stock dollars traded per second on August 11, 2015 \nFigure 8. Apple stock cumulative dollars traded on August 11, 2015 \nFigure 9. Cumulative volume by exchange for AAPL shares \nFigure 10. Quote messages per second in seconds since midnight \nFigure 11. Frequency of observed message types \nFigure 12. Rates of messages for all tickers in a single day \nFigure 13. Visualization of messages passing between exchanges and to an observer \nFigure 14. Sequential frames from a video of market dynamics in action \nFigure 15. Number of SIP locks as a function of capacity \nFigure 16. Number of SIP crosses as a function of capacity \nTable 1. Top 10 trading days from January 2010 through February 2018 \nTable 2. Total notional value of trades January 2010 through February 2018 by date \nTable 3. Total trades from January 2010 through February 2018 at each exchange \n2 HSSEDI, \" Enhanced Cyber Threat Model for Financial Services Sector (FSS) Institutions,\" The MITRE Corporation, McLean, \nVA, March 2018.\n3 HSSEDI, \"Financial System Mapping (Final),\" The MITRE Corporation, McLean, VA, March 2018. Project Overview1\nThe Next Generation Cyber Infrastructure (NGCI) Apex Program seeks to accelerate the \nadoption of cyber technologies proven to be effective for mitigating information technology (IT) \nsecurity risk. Initially, the focal, critical infrastructure for the NGCI Program is the Financial \nServices Sector (FSS). The FSS is one of the most interdependent of the critical infrastructures, \ncomprised of intensely competing organizations which collectively hold the nations economic \nsecurity in their decision-making related to technology implementation. The goals of the NGCI \nprogram are to 1) increase financial sector-wide situational understanding of evolving IT security \nrisk and the technology associated with mitigating that risk; 2) improve the ability to understand \nand link compromises in the underlying cyber infrastructure to sub-sector operations; 3) enable \ngreater information flows between sub-sectors as well as across the entire sector; and 4) enable \nFSS institutions to detect and neutralize adversaries more quickly and effectively than is \ncurrently possible. To achieve these goals, the NGCI program requires an extensive testing \nprogram beyond testing at the level of individual institutions. \nTherefore, the NGCI Apex Program Management Office tasked the Homeland Security Systems \nEngineering and Development Institute (HSSEDI) to perform workload modeling which \ndescribes the data dynamics within and between systems to provide a basis for workloads in the \nrepresentational testing environment. As such, HSSEDI developed a comprehensive data map of \nthe capital markets subsector of the FSS, thereby providing a foundational component for an \nextensive testing program in support of the NGCI Apex program. Here, the term map conveys a \nguide to the mechanisms of the generation and flow of market activity data from one financial \ninstitution to another across an entire subsector of the FSS. The specific objective of this report is \nto identify and depict the scale and time criticality of essential business functions in a central \nsubsector of the FSS. To achieve this objective, HSSEDI performed extensive analyses on a \ndataset which is both authoritative and exhaustive. Because the capital markets subsector is often \nidentified as one of the most technologically advanced within the FSS, this report identifies \nworkloads that could appropriately serve as surrogates or upper bounds in the representational \ntesting environment. \nIn this way, this report complements the objectives of previous HSSEDI products for the NGCI \nprogram, namely the Cyber Risk Metrics Survey and Assessment, and Implementation Plan1, the \nEnhanced Cyber Threat Model for Financial Services Sector (FSS) Institutions2, and the \nFinancial System Mapping3. The objective of the cyber risk metrics survey and assessment task is \nto identify risk metrics and assessment frameworks that could be candidates to measure the \nsystemic impact of the NGCI Apex program on the FSS. The objective of the threat models \nsurvey and assessment task is to identify threat models and frameworks that could be candidates \nto inform systemic testing in the NGCI Apex program. Finally, the objective of the financial \nsystem mapping task is to identify and depict the intrinsically interdependent nature of the \nsubsectors which comprise the Financial Services Sector. ii Task Overview for the Dynamic Data Map 1.1\nThe purpose of the task is to develop a comprehensive data map of a subsector of the FSS, \nthereby providing a foundational component for an extensive testing program in support of the \nNGCI Apex program. This technical report describes and analyzes the data dynamics within and \nbetween financial systems to provide a basis for workloads in the representational testing \nenvironment. \nTo accomplish this task
and advance the objectives of the NGCI Apex program, HSSEDI: Performed workload modeling to describe the data dynamics within and between systems \nand institutions in order to provide a basis for workloads in the representational testing \nenvironment. Examples of this are: distributions (e.g., certain business processes, such as \nfront-end commercial banking, experience diurnal and weekly variance in traffic) and \nwhat-when-where (e.g., data in other processes have regulatory constraints; for instance, \nexchanges must immediately route marketable orders to other exchanges to ensure best \nprices). Developed a scalable approach to depict workloads in the representational testing \nenvironment from institution-specific systems and data flows (i.e., micro-prudential) to \nsub-sector and sector (i.e., macro-prudential) to inter-sector (e.g., energy and \ntelecommunications). Avoided information which might be institution-specific and therefore sensitive by using \nauthoritative and comprehensive data available to the NGCI Apex program. Developed and delivered this technical report which describes the development and \nimplementation of a Dynamic Data Map, to include quantitative metrics, to inform \nsubsequent testing. In the following sections, HSSEDI provides a general overview of the capital markets subsector \nand extensive analyses of this subsector. We conclude this report with a discussion of \nrecommendations for next steps for the NGCI Apex program. iii 4 https://www.youtube.com/watch?v=1ltjnbBaFok\n5 B. F. Tivnan, D. R. Dewhurst, C. Van Oort, J. H. Ring, T. J. Gray, B. F. Tivnan, P. S. Dodds, M. T. K. Koehler, M. McMahon, \nD. Slater, J. Veneman, and C. M. Danforth. (2018). Inefficiencies in the U.S. National Market System: Evidence from the Dow \n30. In Preparation. Overview of the Capital Markets and Related Infrastructure2\nIn this report, HSSEDI describes and analyzes the data dynamics within and between financial \nsystems, thereby providing a basis for workloads in the representational testing environment for \nthe NGCI Apex program. Initially, the focal subsector of the FSS is the capital markets, and \ninfrastructure of the capital markets which carries stock trading messages. This subsector of the \nFSS was chosen because of its high bandwidth, time-sensitive applications, and because it is \nempirically analyzable due to the existence of rich data. Unlike other subsectors, an empirical \nanalysis of the capital markets does not require the disclosure of supervisory data by regulatory \nbodies, nor the disclosure of sensitive, proprietary data from a financial institution. Instead, \nauthoritative sources make exhaustive datasets commercially available. Comprising all \ntransaction activity in the capital markets, the regulatory bodies use these same datasets. In \naddition, this subsector attracts wide interest from the public. The high throughput necessary to \nhandle stock trading ensures that systems designed to test this workload will be adaptable to other \nsectors of the financial system. Overview of the National Market System (NMS)2.1\nRegulations governing the capital markets define the National Market System (NMS), \ncolloquially known as the stock market, as all market centers where investors can buy and sell \nshares of publicly traded companies. To facilitate the efficient exchange of capital and shares in \nthe NMS, each market center is required to publish both the highest bid (i.e., the price at which \nan investor is willing to pay for a single share of a given stock) as well as how many shares the \ninvestor is willing to purchase at that price. In addition, each market center is also required to \npublish the lowest offer (i.e., the price at which an investor is willing to sell a single share of a \ngiven stock) as well as how many shares the investor is willing to sell at that price. \nAcross the entirety of the NMS, the highest bid and the lowest offer comprise what is known as \nthe National Best Bid and Offer (NBBO) and the difference between the highest bid and lowest \noffer is known as the spread. The NBBO reflects a distillation of the order flow across all the \nstock exchanges comprising the NMS. Figure 1 (taken from a video previously developed by \nHSSEDI4) provides a geographical depiction of the three major datacenters of the NMS, all of \nwhich happen to be located in northern New Jersey. The three major datacenters are: (1) \nMahwah, which contains the three exchanges comprising the New York Stock Exchange (NYSE) \nfamily of exchanges NYSE Arca, NYSE American (formerly NYSE MKT) and the NYSE \nitself; (2) Secaucus, which contains both the Chicago Stock Exchange (CHX) as well as the \nBetter Automated Trading System (BATS) family of exchanges consisting of Direct Edge A \n(EDGA), Direct Edge X (EDGX), BATS Z (BZX) and BATS Y (BYX); and (3) Carteret, which \ncontains the three exchanges comprising the National Association of Securities Dealers \nAutomated Quotations (NASDAQ) family of exchanges Philadelphia (NQ-Phil), Boston (NQ-\nBost) and NASDAQ itself. The newest public exchange, Investors Exchange (IEX), is located in \nWeehawken New Jersey (near Secaucus) and is shown in Figure 25. As depicted in Figure 2, the \ncommunications infrastructure connects the datacenters, both by dedicated, high-speed networks https://www.youtube.com/watch?v=1ltjnbBaFok iv 6 https://www.sec.gov/foia/docs/atslist.htm \n7 https://www.ici.org/pdf/2017_factbook.pdf known as Direct Feeds depicted in red and by the Security Information Processor (SIP) in blue \nwhich consolidates market data to determine and disseminate the NBBO. Figure 1. Geographic location of the primary exchange data centers in New Jersey Financial records flow both between the exchanges and to external parties such as traders and \nregulators. These external parties are represented by the Observer and Dark Pools in Figure 2. \nObservers may be physically located in the same data centers as the exchanges, known as co-\nlocation, or elsewhere. Dark pools, also known as alternative trading systems (ATSs), are closed \nexchanges where private parties, such as institutional investors, trade securities. Although the \ninternal information flow within an ATS is unknown, hence the name dark pool, they are \nrequired to report trades of publicly listed securities. Like observers, an ATS may be co-located \nwith existing exchanges or reside elsewhere. The number6 of registered ATSs is less than 100 in \ncomparison to the 11 listed exchanges. The number of entities acting in these exchanges is \napproximately 4,000 institutional investors and 95 million retail investors7 in the United States. \nThe notional relationships between investors and exchanges is depicted in Figure 3. https://www.sec.gov/foia/docs/atslist.htm\nhttps://www.ici.org/pdf/2017_factbook.pdf v Figure 2. Interconnections between the exchanges vi 8 HSSEDI, \"Financial System Mapping (Final),\" The MITRE Corporation, McLean, VA, 2018.\n9 Bookstaber, R., Paddrik, M., & Tivnan, B. (2017). An agent-based model for financial vulnerability. Journal of Economic \nInteraction and Coordination, 1-34.\n10 Bookstaber, R., & Kenett, D. Y. (2016). Looking deeper, seeing more: a multilayer map of the financial system. OFR Brief, \n16(06), page 7. Figure 3. Relationships and numbers of investors and exchanges Interdependence Across the Financial Services Sector2.2\nIn a prior report, HSSEDI described the interdependence intrinsic to the FSS8. In Figure 4, \nHSSEDI provides a graphical depiction of this interdependence, by tying in Figure 1 with the \nmaps from the aforementioned HSSEDI report. In Figure 4, Component C is a detailed \ndepiction of a Bank/Dealer9, a central element of the Financial Services Sector often serving as \nan intermediary in many financial services. The Trading Desk provides core functions of the \nBank/Dealer. Most notably, the Trading Desk executes securities trades in the National Market \nSystem, depicted as Component B in Figure 4. Component A of Figure 4 is the multi-layered \nmap of the financial system from the Department of the Treasury Office of Financial Research \n(OFR)10 that HSSEDI recommends to use to depict the interdependent nature of the financial \nsystem. For simplicity, Component A contains two Bank/Dealers while the National Market \nSystem is merely depicted as a single exchange in Component A. In this way, Figure 4 not only \ndepicts connectivity and information flows from individual financial instructions, to subsectors \nand sectors, but also illustrates the complementarity of this report with other HSSEDI technical \nreports, namely, the Financial Systems Mapping and the Enterprise Threat Model Technical vii 11 HSSEDI, Enterprise Threat Model Technical Report, The MITRE Corporation, McLean, VA, 2018. Report.11 Figure 4. Interdependence across the Financial Service Sector C Bank/Dealer B National Market System A Financial Service Sector Map viii Analysis3\nThe structure of the data flows of the financial institutions in the NMS can be a difficult topic to \nunderstand even for those immersed in it day-to-day. HSSEDI conducted its empirical analyses \nof authoritative data from U.S. stock markets, which illustrate the architecture of the system. The \nanalysis begins by breaking down the data associated with trading a single asset then moves to \nmulti-market, multi-asset analyses to get a system-wide view. This approach provides a layered \nview of activity in this system giving details of important considerations and constraints along \nthe way. Single Asset Analysis3.1\nThese examples will start with Apple stock (AAPL) which was the highest market capitalization \nasset traded on the day chosen for this analysis, August 11, 2015. This day is representative of a \ntypical trading day with no major news events triggering increased activity in the market. Figure \n5 shows the stock price of Apple over the course of a single day including both pre-market \n(04:00 to 09:30 hours or 0 to 19,800 seconds in the figures below) and after-hours trading (16:00 \nto 20:00 hours or 43,200 to 57,600 seconds in the figures below). Figure 5
is typical of the price \nchart most people see in news reports on the stock market. With data at the microsecond level, \neven in this typical view one starts to see some anomalous behavior with the spikes at around \n44,000 seconds. Those spikes are after-hours trades which, along with pre-market, are not usually \nshown when one looks at a stock on Yahoo Finance or similar sites. This begins to illustrate the \ncomplexity of considering data flows when looking at finance markets. Figure 5. Apple stock price on August 11, 2015 Dynamics become more complex when one considers the number of trades per second for a \nsingle stock, as seen in Figure 6. Here, one will notice the clear difference in activity during pre-\nmarket, regular market (09:30 16:00), and after-hours trading (16:00 20:00). ix Figure 6. Apple stock trades per second on August 11, 2015 To get a sense of how much capital is flowing across the NMS, a look into the number of dollars \ntraded per second in Figure 7 reveals some astounding numbers. Here one sees that at the highest \nspike $40 million in Apple stock is traded in one second. Figure 7. Apple stock dollars traded per second on August 11, 2015 To put things in perspective, the cumulative dollars traded, Figure 8, shows that theres a steady \nclimb to around $10 billion traded in a single day for this asset. At such a high rate, the spikes \nseen above $40 million traded in one second hardly register. x Figure 8. Apple stock cumulative dollars traded on August 11, 2015 Figure 9 shows how assets are traded at a high volume at the multiple exchanges that comprise \nthe NMS. The opening and closing hours differ per exchange and are the reason that some lines \nstart late or stop short. The start of regular trading at 09:30 (19,800 seconds since 04:00) is seen \nin Figure 9 as the sharp increase in volume at all markets at opening time. Figure 9. Cumulative volume by exchange for AAPL shares Multi-asset Analysis3.2\nThe analysis will now examine what is experienced in this sector by looking at the combined \ncharacteristics of all assets so get a broader picture of activity. Tying the dynamic fluctuations of \nmarket activity with communication networks and notions of bandwidth or capacity, it may be \nmore intuitive to think of trade volume and quote lots (a quote lot is typically 100 shares) in \nterms of messages, where a message represents an atomic unit of communication that describes a \nnumber of shares or lots for a particular asset (e.g., 8 shares of Apple). Since there are far more \nquote messages than there are trade messages (roughly 10 to 1), the following figures of quote \nmessages per day represent the high end of traffic on communication networks. In Figure 10, one \ncan again clearly see the opening and closing of regular trading hours. Figure 10 shows messages \nthat are recorded at each Tape or SIP of which there are three. The SIPs link the U.S. markets \nby processing and consolidating all protected bid/ask quotes and trades from every trading venue xi 12 https://www.ctaplan.com/index\n13 http://www.utpplan.com/overview\n14 http://www.ftserussell.com/index-series/index-resources/russell-reconstitution\n15 http://markets.cboe.com/us/equities/market_statistics/historical_market_volume/ into a single, easily consumed data feed.12 SIP A and B are operated by the Consolidated Tape \nAssociation and contain stocks listed on NYSE on SIP A and stocks listed on NYSE Arca, NYSE \nMKT, BATS and regional exchanges on SIP B. SIP C is operated by NASDAQ for NASDAQ \nlisted stocks.13 \nDuring regular trading hours there are very few times that less than 1,000 messages are seen per \nsecond while there are times when message traffic exceeds 100,000 messages per second. Similar \nto Figure 6, Figure 10 shows that the highest traffic occurs right after markets open or before they \nclose. Figure 10. Quote messages per second in seconds since midnight Several analyses were performed to determine the data profiles in the NMS. Dates for the \nanalysis were picked based on the number of trades on a date, notional dollar value of trades, and \nvolatility. A date, June 24, 2016, with features on the high-end of these criteria was chosen for \nadditional analysis. This date had the highest dollar value day of 2016 and the sixth highest in the \nlast eight years. The high activity seen on this date was due to a combination of the Russell \nindices rebalancing14 (a known periodic occurrence) with the results of Great Britains vote to \nleave the EU.\nThe following tables, based on an analysis of daily summary data15, provide visibility into the \nhigh activity days and exchanges. The top 10 high trade and notional value activity days are \nshown in Table 1 and Table 2. Table 3 shows the amount of trade activity by exchange since https://www.ctaplan.com/index\nhttp://www.utpplan.com/overview\nhttp://www.ftserussell.com/index-series/index-resources/russell-reconstitution\nhttp://markets.cboe.com/us/equities/market_statistics/historical_market_volume/ xii 2010. Since this tally only includes trades and trades are about 1/20th of all messages then it is \nestimated that NASDAQ processed approximately 260B messages from 2010 to February of \n2018.\nThe average day sees somewhat less than half the number of trades that are seen on the highest \nactivity days with a mean of 30,403,170 and a standard deviation of 7,765,933 trades. The \nminimum number of trades seen since 2010 is 7,556,055. Table 1. Top 10 trading days from January 2010 through February 2018 Date Number of trades 2011-08-08 74,671,169 2015-08-24 72,140,693 2011-08-09 70,402,718 2011-08-05 69,257,795 2011-08-10 67,424,274 2018-02-06 66,967,915 2010-05-07 66,174,403 2010-05-06 65,791,659 2018-02-09 63,584,408 2016-01-20 63,193,966 Table 2. Total notional value of trades January 2010 through February 2018 by date Date Notional value of trades ($) 2018-02-06 6.998334e+11\n2018-02-05 6.379111e+11\n2015-08-24 6.358204e+11\n2018-02-09 6.355986e+11\n2011-08-08 5.741051e+11\n2016-06-24 5.736876e+11\n2011-08-09 5.601463e+11\n2018-02-08 5.576612e+11\n2011-08-05 5.439415e+11\n2010-05-06 5.320244e+11 Table 3. Total trades from January 2010 through February 2018 at each exchange Date Market Participant NASDAQ (Q) 13,116,478,027 xiii NASDAQ \n(DQ) 12,330,177,635 NYSE Arca (P) 8,040,151,615 BATS BZX (Z) 5,972,705,249 NYSE (N) 5,424,407,590 EDGX (K) 3,655,105,299 BATS BYX \n(Y) 2,237,758,958 EDGA (J) 1,998,183,818 NASDAQ BX \n(B) 1,958,891,509 NYSE (DN) 1,608,910,746 At up to nearly $700 billion of trades passing between the exchanges on a high activity day we \ncan see the importance of reliable and secure communications connecting them. The notional \nvalue of trades is just part of the story though. From an engineering perspective, the rates of \nmessages passing between the exchanges is most important for the design of testing capabilities. \nThe messages that pass between exchanges are not just trade messages as tallied in Table 1. Far \nmore numerous are the quote messages that detail the price and number of shares a party is \nwilling to buy or sell. On the direct links between exchanges, quotes are referred to as add \nmessages. Prices change very often throughout a day and a party who submitted an add message \noften wants to cancel their quote when the parameters of it no longer suit their means. Canceling \nquotes is done through modify messages. As seen in Figure 11, messages break down to roughly \n49% add, 46% modify, and 4 % trade messages. The remainder of message types, at less than 1% \nof the total, will not be covered here. Frequency of observed message types add modify trade other Figure 11. Frequency of observed message types xiv 16 https://usa.visa.com/run-your-business/small-business-tools/retail.html \n17 https://blog.whatsapp.com/10000631/Connecting-One-Billion-Users-Every-Day\n18 Protocol developed by the Island Alternative Trading System\n19 https://www.batstrading.com/resources/membership/BATS_PITCH_Specification.pdf Rates of messages across all exchanges on a single day are shown in Figure 12. This figure \nshows the aggregated counts of all message types across all 8,000+ tickers on a single day. The \nmessages are counted in single second intervals from 04:00 in the morning to 20:00 at night. The \nregular trading day (9:30am 4:00pm ET) is clearly shown with the abrupt increase and decrease \nof activity. Message rates peak at 2,154,769/sec and average 117,919/sec during the trading day. \nIn all, this day saw 2,858,836,964 messages on the direct data feeds. Figure 12. Rates of messages for all tickers in a single day For comparison, the Visa payment network processes 150 million transactions per day and is \narchitected to handle a maximum of 24,000 transactions per second16. The messaging app \nWhatsApp handles 55 billion messages per day17. While WhatsApp handles more messages, they \nare at the other end of the spectrum from the time critical nature of payment networks and asset \ntrading. Bandwidth3.3\nTo convert message rates to bandwidth needs we can look at how the messages are formatted and \ntransmitted. Exchanges use different market data feed protocols with the primary ones being \nFinancial Information Exchange (FIX), ITCH18, and PITCH19. These protocols share similar \ncharacteristics in that for each message type they encode similar information. For add messages https://usa.visa.com/run-your-business/small-business-tools/retail.html\nhttps://blog.whatsapp.com/10000631/Connecting-One-Billion-Users-Every-Day xv 20 http://cdn.batstrading.com/resources/membership/BATS_Connectivity_Manual.pdf\n21 http://cdn.batstrading.com/resources/features/bats_exchange_Latency.pdf\n22 http://www.nasdaqtrader.com/content/Productsservices/trading/CoLo/ExpressConnectFS.pdf they encode the message type, unique message identification number, timestamp, order type, \nnumber of shares, stock identifier, and price. The importance of speed and quantity of messages \npushes these to be small with an ITCH add order comprising 40 bytes, cancel modify orders at 23 \nbytes, and trades at 44 bytes. Combining the different order types the bandwidth calculation that \nfollows will use 37.5 bytes per message for bandwidth calculations in congruence with the BATS \nexchange connection examples20. On
the high activity day shown in Figure 12 an observer would \nneed a connection with a minimum bandwidth of 646 Mbps (million bits per second) to intake \nthe direct feed data at the maximum message rate with no delay or packet loss in transmission. \nHowever, the 646 Mbps figure does not account for intra-second bursts which can reach as high \nas 2,700 Mbps from a single exchange10. Due to the high message rates, exchanges recommend \nmarket participants connect to their data feeds at rates of 1 Gbps or higher. The average rate \nobserved across all exchanges based on the data in Figure 12 is a factor of about 18 less than the \nmaximum rate. This observed average rate scaling factor is in line with the stated average rate \nscaling factor by BATS of 1921. Infrastructure3.4\nThe infrastructure that connects the exchanges is differentiated by bandwidth, latency, and price. \nConnections between the exchanges are offered in four main ways10: Virtual Private Network\nLow bandwidth, high latency, low priceo This runs through the public, internet backbone and is for applications which are not o\ntime-critical. Co-location\nHigh bandwidth, low latency, high priceo 1 Gbps and 10 Gbps connections for when the receiver is in the same facility as the o\nexchange. Extranet\nMedium bandwidth, medium latency, medium priceo Access exchange data through a third-party connection.o Private line Ethernet\nDirect point-to-point connection via fiber-optic or microwave/millimeter wave o\nantennas between exchanges or between an exchange and a participant\nFiber-optico High bandwidth, low latency, high price Microwave/millimeter wave wireless22o http://www.nasdaqtrader.com/content/Productsservices/trading/CoLo/ExpressConnectFS.pdf xvi 23 http://qnasdaqomx.com/WirelessConnectivity \n24 http://anova-tech.com/sample-page/map/\n25 In additional to this technical report, HSSEDI has also developed a visualization application to animate these dynamic flows. \nContact the NGCI Apex Program Management Office or HSSEDI for access to this visualization application. Medium bandwidth, very low latency, very high price These connections are not mutually exclusive for exchange data customers. A trading firm may \nbe co-located in an exchange and have with both fiber and wireless connections to other \nexchanges. While the wireless connections are considered supplemental23 to fiber-optic they \ncommand a premium price due to their speed. The speed difference for the wireless millimeter-\nwave connections can be significant with a Carteret to Secaucus, NJ latency of 153s compared \nto 93s on a fiber optic line24 40% faster. Dynamic Message Traffic3.5\nThe image in Figure 13 and Figure 14 shows freeze frames taken from a message visualization \napplication25 developed to explore the dynamics of financial data. They show individual trades \npassing between the exchanges to an observer at Carteret, NJ, one of the main exchange \nlocations. Each rectangle represents a trade with the width being proportional to the number of \nshares in that trade. \nFigure 13 depicts two stocks, Bank of America (BAC) in blue and AAPL in green. Trades of \nBAC are recorded by the SIP in Mahwah, the location of NYSE which is the listing exchange for \nBAC; while AAPL trades are sent to the SIP in Carteret, the location of NASDAQ which is the \nlisting exchange for AAPL. The trades shown in the image are from the first few hundred \nmicroseconds after the markets opened on February 5th, 2018, the day with the fourth highest \nvolume in the last eight years. The straight paths represent messages from exchanges to the \nrespective SIPs, while the circular paths represent messages that originated and terminated in the \nsame location. Each trade is represented by a rectangle with its width proportional to the size of \nthe trade (i.e., number of shares). The width of each path depicts the proportion of the number of \ntrades currently passing through that path. Trades begin their journey at the exchange executing \nthe trade and then move to their respective SIP location (i.e., listing exchange). The average time \nthis takes is approximately 500s. While this is just the activity of two tickers, it illustrates that \nall of the exchanges are producing trades and each link provides the necessary information for the \nimmediate action of market participants. Any delay due to capacity constraints or service issues \nwill therefore have an immediate impact on all subsequent activity. http://qnasdaqomx.com/WirelessConnectivity\nhttp://anova-tech.com/sample-page/map/ xvii Figure 13. Visualization of messages passing between exchanges and to an observer Figure 14 depicts some of the dynamics of this system, which has irregular bursts of market \nactivity and significant differences in speed. This figure is composed of a series of sequential \nframes taken from the message visualization application. The sequence goes from left to right \nthen top to bottom. In the first frame, top left, the market has just opened and trade messages for \nAAPL from the exchanges start being sent to the SIP in Carteret. As in the previous figure, the \nwidth of the rectangles represents the size of the trade. On the bottom of the second frame a large \ntrade appears originating and terminating in Carteret and covering the width of the frame. Most \nof the initial trades occurring away from Carteret reach Carteret by the 13th frame \napproximately 230s after the market opening. Beyond the short sequence of events captured in \nFigure 14, a dynamic depiction of the message flows via the visualization application shows \nbursts of activity and message hopping where one can see some messages pass others at \nsignificantly greater speeds on the same path a consideration for the development of the \nrepresentational testing environment. xviii 26 https://www.sec.gov/marketstructure/midas.html Figure 14. Sequential frames from a video of market dynamics in action Data Source3.6\nThe message level analyses in this report are derived from authoritative data from the same \nsource from which the Securities and Exchange Commission (SEC) gets their Market \nInformation Data Analytics System (MIDAS) data26. This data comprises both the direct from all \nthe exchanges as well as SIP data feeds for quote and trade messages. \nThe intake of the data occurs in NASDAQs co-location facility its datacenter in Carteret, New \nJersey. This co-location enables the data provider to add their own timestamp of when messages \nwere received when they ingest the market feeds. Timestamps from the exchanges and the data \nprovider are captured at the microsecond level. This additional timestamp provides further insight \ninto market dynamics from the position of a market participant. https://www.sec.gov/marketstructure/midas.html xix Dynamic Data Behavior Impacts of High Traffic3.7\nFigure 15 shows the number of times that a stock is apparently locked (i.e., a spread of 0) at the \nSIP. This also gives a preliminary indication that increasing message traffic for a given asset \nleads to more apparent locks in that asset. This suggests capacity and/or computational \nconstraints on processing incoming messages. Figure 15. Number of SIP locks as a function of capacity The SIP crosses in Figure 16 indicates that as the number of quote messages increases there is an \nincreasing number of apparent market crossings as seen at the SIP. In this figure, the price of the \nstock is given in the color chart to the right. Stocks that trade for less than one dollar (i.e., penny \nstocks, blue to blue-green in the figure) operate under different market rules and appear to follow \na different relationship between number of messages and crosses. xx Figure 16. Number of SIP crosses as a function of capacity xxi Conclusions and Recommendations4\nAs described in this technical report, HSSEDI developed a comprehensive, data map (i.e., a guide \nto the mechanisms of the generation and flow of market activity data from one financial \ninstitution to another across an entire subsector) of an essential subsector of the FSS, namely the \ncapital markets. This data map provides a foundational component for an extensive testing \nprogram in support of the NGCI Apex program. \nThis technical report describes several analyses of the data dynamics within and between the \nfinancial systems and infrastructure comprising the NMS. The analysis provides empirical \nsupport to the nature of background traffic present in a highly active, highly valued, and highly \nengineered sector of the financial system. Possible uses of this are for testing of red/blue \nexercises focused on the financial sector. The findings presented here show that data flows range \nfrom zero to millions of messages per second. Single messages, expressing transactions of \nhundreds of thousands of dollars, may only be valid for such short times that capacity and \ncomputational resources need to continually operate with high reliability. The analysis shows, \nand gives the boundaries of, data activity that fluctuates across several orders of magnitude for \nmany aspects of this system including day, time-of-day, asset, location, and message type. The \ndata map, with its boundaries and structure, may inform real-time determinations of normal and \nabnormal performance as well as ensure future FSS resiliency. Lastly, these analyses and the \nensuing data map may provide a basis for workloads in the representational testing environment \nfor the NGCI Apex Program.\nFinally, HSSEDI concludes this report with a set of three recommendations for the NGCI Apex \nprogram to enhance its representational testing environment. HSSEDI recommends that the NGCI Apex program expand this dynamic, data map into \nan exhaustive depiction of workloads and time criticality for a small set of known market \nevents (e.g., Flash Crash, Manic Monday and February 5th and 8th, 2018) when the \nNMS
infrastructure experienced particularly heavy workloads and delays. HSSEDI recommends that the NGCI Apex program use these market events and \nHSSEDIs Threat Model to inform detailed test scenarios for use in the representational \ntesting environment. HSSEDI recommends that the NGCI Apex program integrate this dynamic, data map \nwith HSSEDIs previous technical reports on Cybersecurity Risk Metrics Survey and the \nFinancial Systems Mapping to provide a more comprehensive treatment of the systemic \nrisk facing the FSS. xxii List of Acronyms \nAcronym Definition AAPL Apple Stock ATS Alternative Trading System BAC Bank of America Stock BATS Better Alternative Trading System BYX BATS Y Exchange BZX BATS Z Exchange CHX Chicago Stock Exchange DHS Department of Homeland Security EDGA Direct Edge A Exchange EDGX Direct Edge Exchange FFRDC Federally Funded Research and Development Center FIX Financial Information Exchange FSS Financial Services Sector HSSEDI Homeland Security Systems Engineering & Development Institute IEX The Investors Exchange IT Information Technology MIDAS Market Information Data Analytics System NASDAQ National Association of Securities Dealers Automated Quotations NBBO National Best Bid and Offer NGCI Next Generation Cyber Infrastructure NMS National Market System NQ-Bost NASDAQ Exchange Boston NQ-Phil NASDAQ Exchange Philadelphia NYSE New York Stock Exchange S&T Science and Technology Directorate xxiii SIP Security Information Processor _top\n _GoBack\n _Hlk512505773\n _Hlk512525564\n _Hlk512527351\n _Toc520809951\n _Hlk507572077\n _Hlk511132380\n _Toc458418744\n _Toc506884990\n _Toc520809952\n _Toc520809953\n _Hlk511131973\n _Toc520809954\n _Ref511144745\n _Toc520809966\n _Ref508206643\n _Toc520809967\n _Ref511056092\n _Toc520809968\n _Toc520809955\n _Ref511146316\n _Toc520809969\n _Toc520809956\n _Toc520809957\n _Ref508207135\n _Toc520809970\n _Ref508207255\n _Toc520809971\n _Ref508207284\n _Toc520809972\n _Ref508207438\n _Toc520809973\n _Ref508207505\n _Toc520809974\n _Toc520809958\n _Ref508207582\n _Toc520809975\n _Ref508290610\n _Ref508217307\n _Toc520809982\n _Ref508290615\n _Toc520809983\n _Ref508290655\n _Toc520809984\n _Ref508638799\n _Toc520809976\n _Ref508217091\n _Toc520809977\n _Toc508315137\n _Toc520809959\n _Ref508286059\n _Toc520809960\n _Toc520809961\n _Toc508315141\n _Toc508612111\n _Toc508612165\n _Toc508315142\n _Toc508315143\n _Hlk511152344\n _Hlk511152252\n _Ref508311245\n _Ref508217488\n _Toc520809978\n _Ref508612947\n _Toc520809979\n _Toc520809962\n _Toc520809963\n _Ref508217526\n _Toc520809980\n _Ref508217567\n _Toc520809981\n _Toc520809964\n _Toc520809965 ",
    "text": " Reducing GNSS Receiver Vulnerabilities \nJohn W. Betz, PhD \nThe MITRE Corporation Reports of problems with GPS appear with increasing frequency. As two of many examples: USA Today, on October 3, 2017, reported a Mysterious GPS glitch telling ships theyre parked at \nan airport, apparently due to intentional broadcast of spoofing signals. Some mobile devices in the exhibition hall at the September 2017 ION GNSS+ conference began \nreporting time in the year 2014, and locations in Europe. Because of the date change, these \ndevices suffered secondary problems with email and text messaging. The problem was caused \nwhen the devices received signals leaking from a GPS constellation simulator. All satellite-based navigation and timing (satnav) systems in the Global Navigation Satellite System \n(GNSS) consist of three segments: space segment (the constellation of satellites), ground segment \n(which monitors and controls the satellites and their signals), and user segment (the antennas, antenna \nelectronics, and receivers), as well as the signals broadcast from the satellites to the user equipment. In many cases, the reported problems are either caused by, or at least could be mitigated by, satnav \nuser equipment. Yet, like the USA Today headline quoted above, often the problem is blamed on the \nsatnav system, leaving the mistaken impression that there has been a flaw in the space or ground \nsegment, or in the signals. In these examples and many other cases, the space and ground segment and signals are correct, but \nimperfect user equipment is the vulnerability. For example: Regardless of what their inputs are, should maritime receivers on large maritime vessels report \nposition changes of tens of kilometers in a few seconds, altitude under water, and location on \nan airport runway? Should mobile devices report time travel from 2017 to 2014 and moving thousands of \nkilometers in a few seconds or minutes? Sometimes a satnav systems ground segment or space segment does malfunction, causing signals to \nprovide flawed or erroneous information. GPS experienced this situation in January 2016, when some \nsatellites broadcast an incorrect offset between system time and Universal Coordinated Time. This error \ndid not affect calculation of position or velocity, but did affect some timing receivers. Even in this case, \nhowever, since the erroneous broadcast did not conform to the GPS signal interface specification, \nreceivers could have detected and rejected the erroneous information. Yet some receivers were \naffected by it. When computer viruses and other malware appeared in the 1980s and 1990s, users did not discard their \nIBM PCs and Apple Macintoshes, reverting to typewriters and calculators or slide rules. Instead, virus \ndetection, firewalls, and other defenses were introduced. Software assurance practices reduced the \npresence of exploitable bugs and other vulnerabilities. Users adopted smarter practices in dealing with \nemails and using the Internet, while more diligently maintaining their software and hardware to address \nnewly found bugs and vulnerabilities. While threats have continued to evolve, so have defenses, \nallowing personal computers to become an integral part of todays society. Modern GNSS receivers are actually computers with specialized inputs and interfaces. Yet in many cases \nthey have been specified, developed, and tested as if they are mere radio receivers. Software assurance \npractices common in development and maintenance of other types of computers may not be rigorously \nemployed in development of GNSS receivers. Techniques that protect computers from malicious or \nfaulty inputs may be lacking in GNSS receivers, and handling of valid but rare conditions (such as GPS \nweek rollovers or insertion of leap seconds) may not be adequately implemented or tested. Absent are \nalgorithms that apply simple common sense to preclude many of the problems that are experienced, \nlike those in the Black Sea and at ION GNSS+ 2017. Signals from multiple satnav systems are available, \nbut not consistently used to crosscheck each other. Although low cost, low power, inertial sensors and \nprecision clocks exist, they may not be used to crosscheck computations and provide fallback capability. \nUsers may not be thorough or current in installing and maintaining hardware and software, and in \npracticing the same kind of cyber hygiene (such as updating passwords and blocking back doors) that \nthey practice with routers and firewalls. Its time for users to demand competent GNSS user equipment that is specified, developed, and tested \nto exhibit common sense, with receivers that respond appropriately (maintaining operation when \npossible, failing gracefully when necessary) to attacks, rare events, and even erroneous inputs. Its time \nfor manufacturers of GNSS chips and receivers to adopt practices and implement capabilities that enable \nuser equipment to operate appropriately in imperfect and threatened environments, rather than \nimplicitly trusting all inputs as valid and correct. Its time to employ the standards and compliance \nrequirements used for computers and computer software to GNSS receivers and their software. Perhaps \nits time for an organization to perform independent testing, evaluation, and rating of GNSS user \nequipment against various attacks and challenging conditions, just as the Insurance Institute for \nHighway Safety does for automobile crashworthiness in the United States. Cybersecurity for personal computers is never perfect, and defenses need to evolve to defend against \nnew attacks. Similarly, more competent and robust GNSS user equipment will never be perfect, and \nthere will need to be secure ways to upgrade user equipment as improvements become available. There \nwill be challenges in developing and sustaining competent GNSS user equipment, with new \nopportunities for organizations that can do this well. Even then, the result may not be perfect. But perfect may be the enemy of good enough. Every technology we use has vulnerabilities that can be \nsuccessfully attacked, given sufficient resources and skill. The objective is to raise the bar enough that \nsuccessful attacks causing significant consequences are difficult to carry out, and would expose the \nattacker to enough risk that most attacks are dissuaded. Lets work together so that competent GNSS user equipment is developed, employed, and maintained \nto address the challenges of today and tomorrow. Approved by MITRE for Public Release; Distribution Unlimited. Case Number 18-2925. ",
    "text": " 'Approved for Public Release; Distribution Unlimited. Case Number 18-2764'. My MITRE Journey: The Intern Edition (a Student Voices article for www.mitre.org) College is the time of your life where youre trying to figure out the great unknown. There's a lot of \nuncertainty in your life, such as: Where is the 10-page paper I wrote last night? How did I go from 100 \ndollars to 85 cents in a weekend? Most importantly, what is the next step in my life? College prepares you for the real world in many waysthrough academics, working with a diverse \ngroup of people, learning time managementand it instills a sense of independence. You need to \nexercise the knowledge gained in the classroom while seeking opportunities to learn off campus. Thats where internships come inits a chance to get professional experience in the field of your \nchoosing. Gaining this experience is challenging for most, including me. Internships are highly \ncompetitive these days, and they are increasingly hard to get as more students seek them out to build \ntheir resumes. When I started applying for internships this spring, I found myself stuck. At 21 years old, most people \ndont know what they want to do with their lives. Since many individuals in my generation are \nattempting to continue their education, internships are more competitive and require a lot more just to \nget into the maybe pile in the HR office. After receiving a few rejection letters, I came across a job posting for a Communication and Outreach \nInternship position for MITRE. This post looked promising and aligned with my professional goals. With my track record, I didnt think anything would happen after I applied, but I was wrong. I received an \ninterview and felt an immediate connection to the organizationthe kind you get when you know \nsomething is meant to beall joy and zero doubt. I was righta week later I received an offer. Maryland, here I come! My Work Experience \nI knew that the work I would be doing would be vital to the mission of the MITRE-operated National \nCybersecurity FFRDC (NCF), which is located in Rockville, Maryland. The NCF is the nations first and only \ncybersecurity federally funded research and development center. My job would support the National \nCybersecurity Center of Excellence (NCCoE)the NCFs principal work program sponsored by the \nNational Institute of Standards and Technology. Among other things, the NCCoE staff produces practice \nguides that organizations and industry can adapt to make the world safer against cyber-attacks. My first day at MITRE was one Ill never forget. The team welcomed me with open arms and support. \nThey told me they couldnt wait for me to join them and were eager to see the things I could offer. Now call me crazy, but its every college students dream to hear something like that. In my interview, I \nsaid I wanted my internship experience to be a real work experience. At that moment, I knew thats \nexactly what I was going to get. I had many challenges along the way. For starters, I considered myself a good writer until I wrote my first \ntechnical blog. I had no experience with that kind of writingtranslating information from a project into \nsomething everyone could understand. (I imagined my grandmother as my target audience.) Then, my \nnext assignmenta practice review guide reviewwas also very difficult. This experience helped me http://www.mitre.org\nhttps://www.mitre.org/centers/national-cybersecurity-ffrdc/who-we-are\nhttps://www.mitre.org/centers/national-cybersecurity-ffrdc/who-we-are\nhttps://www.mitre.org/centers/national-cybersecurity-ffrdc/who-we-are\nhttps://www.mitre.org/centers/national-cybersecurity-ffrdc/who-we-are\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.nccoe.nist.gov/\nhttps://www.nccoe.nist.gov/\nhttps://www.nccoe.nist.gov/\nhttps://www.nccoe.nist.gov/ 'Approved for Public Release; Distribution Unlimited. Case Number 18-2764'. realize that there are more ways to discover problems in documents than I had ever imagined. I completed every challenging assignment I received, thanks in part to the mentors I had along the way. \nThe team made sure that when I struggled, I had the resources and expertise I needed. My confidence \ngrew because they believed I could handle any task that came my way. I had the opportunity to \ncontribute to the same projects and tasks that the full-time professionals were working on. I wasnt a \ncoffee jockey and was treated like an equal. The End of the Road \nOverall, my experience as a MITRE intern leveled me above my peers. It was everything I could have \nasked for and more. I would encourage other students to apply for a MITRE internship. I can say with \nconfidence that the MITRE internship program is not only for science and engineering majorsits for \nanyone looking for self-developmenta real-world professional experience. On top of all that, I formed friendships with other NCCoE interns and staff that I hope will continue when \nI resume my studies in the fall. When people ask me what I did over the summer, I can say with \nconfidence that I did my part to solve problems for a safer world. And that would be the truth. by Joshua Cobbins (Editors note: Joshua Cobbins is an undergraduate at McKendree University, in Lebanon, \nIllinois. He is studying public relations. He wrote this story while interning at MITRE during the \nsummer of 2018.) Interested in becoming a MITRE intern? Check out our current Job Openings or read more about \nour Student Programs. https://www.mitre.org/careers/job-openings/\nhttps://www.mitre.org/careers/student-programs _top\n _GoBack\n _Hlk520368398 ",
    "text": " Approved for Public Release; Distribution Unlimited. Case Number 18-3121 1 A Passion for Law Leads to an Unexpected Career in Cybersecurity Nickyra Jackson When Nickyra Jackson was a teenager, she deeply respected her father's work as an engineerat \nNASA, no lessbut she had absolutely no interest becoming one herself. \"He took me to work with \nhim, and I liked how engineers problem-solved together. But my passion was for the law.\" Ultimately, Jackson studied criminology, pre-law, at the University of Maryland. Then, during an \ninternship in the Office of the Chief Information Officer at the U.S. Department of the Treasury \nheadquarters, she found her niche. \"It was a turning point for me, working both in technology and \npolicy. I was surrounded by engineers, policy, and security experts. I loved it.\" In the end, she veered from a dedicated legal career. Instead, she continued at the University of \nMaryland, receiving both a Master of Science in Information Systems Management and a Master of \nBusiness Administration. She became a systems engineer focusing on cybersecurity and privacy. After 10 years at MITRE, she still enjoys working with a pool of systems engineering, policy, and \ncybersecurity experts. \"You need people at the table from different disciplines to build a system that \nnot only satisfies a variety of requirements, but also works. Is it truly functional? Is it secure? How do \nyou test both and be sure?\" Protecting IT Systems on Land and at Sea Securing our military's cyber systems is a critical part of our defense system, and Jackson appreciates \nthe opportunity to work directly with our nation's warfighters. Collectively, she spent two years in \nHawaii working onsite at the United States Pacific Command and Pacific Air Forces, alongside \npersonnel from all military branches. \"One of the pleasures of working at MITRE is helping the \nwarfighters. I always give my very best but supporting them brings about an even greater sense of \npride and commitment. I ramp it up another notch. In Hawaii, Jackson assisted with testing and operationalizing a MITRE-developed tool called Cyber \nCommand System (CyCS) to provide situational awareness to command leaders about their critical \nassets, including their information technology. \"If a router or switch becomes degraded, CyCS will \nshow what kind of impact that might have on the mission. This particular project really hit home for \nme the importance of the work we do at MITREhow we make a difference and keep our nation \nsafe.\" More recently, Jackson has worked on a project for U.S. Army Central, where she led a continuous \nmonitoring task to develop a strategy and plan. The U.S. Army Central functions as Americas land \ndomain experts in the Middle East, Central Asia, and South Asiaproviding continuous oversight and \ncontrol of Army operations throughout the region. Jackson says, \"We ensure the right safeguards are \nimplemented so their network will remain secure and resilient, and the warfighters can accomplish \ntheir mission.\" In addition, Jackson has helped many government sponsors with systems security and privacy issues, \nincluding the Department of Health and Human Services (Centers for Medicare & Medicaid Services, https://www.mitre.org/capabilities/systems-engineering/overview\nhttps://www.mitre.org/capabilities/systems-engineering/overview\nhttps://www.mitre.org/capabilities/systems-engineering/overview\nhttps://www.mitre.org/capabilities/systems-engineering/overview\nhttps://www.mitre.org/capabilities/cybersecurity/overview?category=all\nhttps://www.mitre.org/capabilities/cybersecurity/overview?category=all\nhttps://www.mitre.org/research/technology-transfer/technology-licensing/cyber-command-system-cycs\nhttps://www.mitre.org/research/technology-transfer/technology-licensing/cyber-command-system-cycs\nhttps://www.mitre.org/research/technology-transfer/technology-licensing/cyber-command-system-cycs\nhttps://www.mitre.org/research/technology-transfer/technology-licensing/cyber-command-system-cycs\nhttps://www.mitre.org/research/technology-transfer/technology-licensing/cyber-command-system-cycs\nhttps://www.mitre.org/publications/technical-papers/january-2018-federal-ciso-summit-report\nhttps://www.mitre.org/publications/technical-papers/privacy-engineering-framework Approved for Public Release; Distribution Unlimited. Case Number 18-3121 2 National Institutes of Health, and Food and Drug Administration), the Department of Homeland \nSecurity (Office of Intelligence & Analysis, National Cyber Security Division, and U.S. Immigration and \nCustoms Enforcement), and the Department of the Treasury (Internal Revenue Service). Room to Grow, Room to Run \"MITRE has been very good to me,\" Jackson says. \"It offers what I look for in a career: meaningful \nwork, the opportunity to grow, and the sense that each new project is stretching me. That's what \nmotivates me. For people who want the same things, they'll find them at MITRE. \"Any time I get the opportunity, I talk to college students about working in STEM [science, \ntechnology, engineering, and mathematics.] Im proud to tell them about MITRE and the \nopportunities they'll find here.\" Jackson is also active in her church and in numerous community events, including a mentoring \nprogram for adolescent and teenage girls. She has been married for just over a year. In addition to \nloving music and her work, she graduated from running half marathons to the full Marine Corps \nMarathon. \"That was very rewardingand it felt good.\" Not surprisingly, Jackson is a strong believer in the value of perseverance and fortitude. \"I tell the \nyoung women that I mentor that you should always press forward for the things you're really \npassionate about. Be relentless in the pursuit of it, no matter how difficult it may be.\" by Bill Eidson https://www.mitre.org/careers/working-at-mitre\nhttps://www.mitre.org/careers/working-at-mitre\nhttps://www.mitre.org/careers/working-at-mitre/professional-development\nhttps://www.mitre.org/careers/student-programs\nhttps://www.mitre.org/careers/student-programs/student-voices/location-is-no-limitation-for-mitres-stem-summer-internships\nhttps://www.mitre.org/careers/student-programs/student-voices/location-is-no-limitation-for-mitres-stem-summer-internships\nhttps://www.mitre.org/careers/student-programs/student-voices/location-is-no-limitation-for-mitres-stem-summer-internships _top\n _GoBack ",
    "text": " Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3228 From The Game of Drones to Generation AI Nexus \nDr. Michael Balazs While finishing graduate school, Michael Balazs lived on the French/Swiss border for a year, working on \nthe Large Hadron Collider, the worlds largest and most powerful particle accelerator. For most people, \nthat would have been the highlight of their career. But Michael Balazs is not most people. Balazs has had quite a few high points while working at MITREincluding having one of his projects \nfeatured on an episode of National Geographics Breakthrough series, The Game of Drones. (Balazs \nappears at 1:24 minutes in this clip.) Along with other content about drones, the episode followed Balazs \nand his team as they ran MITREs Countering Unauthorized UAS Challenge. Balazs and his team conceived of the idea for the challenge during a conversation. They were just back \nfrom an early phase of teaching Special Forces troops to build their own small quadcopters. Each \nNibbler drone was produced by a 3-D printer and carried a smartphone to serve as \ncomputer/camera/GPS/communications. Afterwards, we were talking, and someone said, OK, were feeling pretty smart, but our adversaries are \nsmart, too. What if they turn the same techniques upon us? In a war zone you can shoot these drones down, but it would be too dangerous to do in a city, Balazs \nsays. And the likelihood of someone using small drones to deliver explosives is all too real. (For \nexample, in August 2018 there was an attempted drone attack upon the president of Venezuela.) We came up with the idea of hosting a challenge to help the government determine how well existing \ntechnology worked in capturing drones in flight. We went to the Quantico Marine Corps base in Virginia \nfor two weeks in 104-degree temperature, no cloud cover, and 100 percent humiditynot our best \nmove. We played the bad guys and flew four different scenarios of increasing complexity to replicate \nwhat our adversaries are likely to do. The finalists in the challenge used a variety of techniques, from jammers to flying nets. Its clear theres still a lot of work to do, says Balazs. And because MITRE is a nonprofit with a mission \nof making our world safer, we have continued working on this problem ourselves. I cant go into the \nparticulars, but weve made a lot of progress toward dealing with the drone technology we see ahead in \nthe next 5-10 years. Always trying to stay ahead of our adversaries, in 2017, Balazs and his team went to several Marine \ninstallations, including those in Kuwait, for what they called the surge phase of the Nibbler project. \nThe goal was to teach U.S. Marines to build and operate 72 quadcopter droneswithin 90 days. Not only \nwas the project a success, but they beat the deadline, finishing in 60 days. Generation AI Nexus Leads the Way Balazs explains that there are three typical scenarios where MITRE helps the government and the \nAmerican people. One, we tackle current hard problems that no one else can solve. Two, we come in \nwhere theres an important problem, but no profit motive for any commercial company to address it. \nAnd three, we look ahead for problems 5, 10, or even 20 years ahead, so we can figure out solutions in https://home.cern/topics/large-hadron-collider\nhttps://www.youtube.com/watch?v=SEaRWvKfDRw\nhttps://www.mitre.org/publications/project-stories/mitre-challenge-seeks-ideas-to-counter-unauthorized-unmanned-aircraft\nhttps://www.bloomberg.com/news/articles/2018-08-07/venezuela-attack-highlights-vulnerability-to-drone-assassins\nhttps://www.mitre.org/research/mitre-challenge-uas/uas-challenge-finalists\nhttps://www.marines.mil/News/Marines-TV/dvpsearch/Nibbler/#DVIDSVideoPlayer27131 Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3228 advance. In addition to applying that forward-looking mentality to drone technology, Balazs is also deeply involved \nin another major challengeAmericas workforce of the future. While helping run a hackathon about \nidentifying possible pandemics, he and Jay Crossler, MITREs chief engineer for Learning Systems, began \ntalking about a looming problem. According to McKinsey & Company, there will be a shortfall of up to 250,000 data scientists in the United \nStates. in a decade. This is particularly troubling given how heavily China and other countries are \ninvesting in artificial intelligence (AI) expertise. And even more ominously, Russian President Vladimir \nPutin says that the nation that leads in AI will be the ruler of the world. Balazs and Crossler discussed this with MITRE senior vice president Richard Byrne, and developed a plan \nto bring AI tools and data sets to students across the country. We believe if we give students secure \naccess to cutting-edge AI tools and data sets theyd normally never see, they wont just become engaged \nwith the technology. Theyll deliver real solutions. The concept is called Generation AI Nexus. Balazs is securing partnerships with government, academic \ninstitutions, and leading technology companies. Theyre very enthusiastic, says Balazs. Everyone Ive \ntalked with gets the value of the idea immediately and they want to be part of it. Balazs says MITRE will \nbegin Generation AI with a series of hackathons in the fall of 2018 to engage with students right away. \nWithin a year, I see tremendous growth. He says that in his experience, people at MITRE are driven by the mission. We do interesting work and \nfor the right reasons. You can have a conversation, come up with an idea thatll make a difference in the \nworldand then make it a reality. Thats the power of MITRE. by Bill Eidson Are you a good fit for MITRE, too? Explore our current Job Openings. https://www.mitre.org/careers/student-programs/student-voices/wanted-students-with-ai-skills-for-pandemic-early-detection\nhttps://www.mitre.org/careers/student-programs/student-voices/wanted-students-with-ai-skills-for-pandemic-early-detection\nhttps://www.mitre.org/careers/student-programs/student-voices/wanted-students-with-ai-skills-for-pandemic-early-detection\nhttps://www.mitre.org/careers/student-programs/student-voices/wanted-students-with-ai-skills-for-pandemic-early-detection\nhttps://www.mckinsey.com/featured-insights/digital-disruption/whats-now-and-next-in-analytics-ai-and-automation\nhttps://www.mckinsey.com/featured-insights/digital-disruption/whats-now-and-next-in-analytics-ai-and-automation\nhttps://www.mckinsey.com/featured-insights/digital-disruption/whats-now-and-next-in-analytics-ai-and-automation\nhttps://www.mckinsey.com/featured-insights/digital-disruption/whats-now-and-next-in-analytics-ai-and-automation\nhttp://www.sciencemag.org/news/2018/02/china-s-massive-investment-artificial-intelligence-has-insidious-downside\nhttp://www.sciencemag.org/news/2018/02/china-s-massive-investment-artificial-intelligence-has-insidious-downside\nhttp://www.sciencemag.org/news/2018/02/china-s-massive-investment-artificial-intelligence-has-insidious-downside\nhttps://www.theverge.com/2017/9/4/16251226/russia-ai-putin-rule-the-world\nhttps://www.theverge.com/2017/9/4/16251226/russia-ai-putin-rule-the-world\nhttps://www.mitre.org/about/leadership/executive/mr-richard-byrne\nhttps://www.mitre.org/publications/project-stories/preparing-generation-ai-for-the-fourth-industrial-revolution\nhttps://www.mitre.org/careers/job-openings _top\n _GoBack\n _Hlk523386200 ",
    "text": " In Singapore, a New Way of Analyzing Land Use Around Airports Land can be hard to come by in the prosperous island state of Singapore. MITRE is helping \nSingapore's Civil Aviation Authority decide if it can release land near Changi Airport for \ndevelopment without compromising the safety of air operations. Airports place development restrictions on surrounding land. That's not surprisingthey need obstacle-\nfree airspace for safety. But this creates a natural tension between airspace protection and economic \nexpansion. Add in the land limitations of an island-based country, such as Singapore, and competition for \nusable land becomes significant. Singapore is a global commerce, finance, and transport hub with a state-of-the-art airport, Changi, that \nserves as an aviation center for Southeast Asia. The country's territory consists of one main island and 62 \nislets. Land reclamation efforts have increased Singapore's area by more than 20 percent since it \nachieved independence in the 1960s, but acreage to build on remains a scarce resource. There are frequent requests from land use agencies for restrictions near the airports to be relaxed. The \nCivil Aviation Authority of Singapore (CAAS), in considering these requests, will ensure that safe \noperations are not compromised. An Imaginary Surface with Real Consequences CAAS safeguards airspace near Changi by applying Obstacle Limitation Surfaces (OLS). OLS are imaginary \nsurfaces that emanate from an airport. They define the volume of airspace that must be kept free from \nobstacles to allow for the safe operation of aircraft. OLS standards have existed fundamentally unchanged at airports around the world for decades. But \naircraft performance, navigation systems, and flight procedure capabilities continually evolve, which \nallows for much more precise arrival and departure paths. Flight tracking capabilities also continue to \nadvance. The evolution of all these capabilities creates new data that researchers can analyze to refine \nrequirements for protecting airspace. CAAS is willing to evaluate the OLS at Changi and consider adjusting them without compromising safety \nof air operations. This is where MITRE can help. The Right Data Helps Set the Boundaries CAAS sponsors MITRE's first research and development center outside of the United StatesMITRE Asia \nPacific Singapore (MAPS). Via this partnership, we're conducting a study to help CAAS determine if the \ncurrent OLS can be modified. \"First, we'll evaluate every aspect of every surface being considered,\" says Neal Westlund, MITRE's \nairport design and analysis group leader. \"Then we'll tell them which ones have the potential to be \nrelaxed and how much they could be relaxed. If CAAS decides its OLS can be modified, then our study will \nalso help them choose the safest and most effective modification strategy.\" During the study, MITRE developed an analytical framework that presents the performance parameters, http://www.changiairport.com/\nhttp://www.changiairport.com/\nhttp://www.changiairport.com/\nhttps://www.mitre.org/news/press-releases/mitre-partners-with-civil-aviation-authority-of-singapore-caas-to-support\nhttp://www.mitre-ap.sg/\nhttp://www.mitre-ap.sg/ safety factors, and logical arguments fundamental to the purpose of an OLS. The framework identifies \nwhat data to gather and which metrics to analyze. A New Framework with World-Wide Relevance Our OLS Assessment Framework offers a systematic, data-based approach to characterizing and updating \ncurrent boundaries. Theoretically, it could be used at any airport in the world. \n\"Many companies perform analyses of OLS,\" Westlund says. \"But we're developing a new method that \nsimplifies the comparison of obstacle surfaces to assess the feasibility of modernizing them. We're taking \nthis beyond just aviation expertise and adding modern technology capabilities in data-driven analyses \nusing GIS [Geographic Information Systems]. Our GIS expertise has allowed us to develop an enhanced, \nthree-dimensional analysis methodology, with three-dimensional visualizations.\" The International Civil Aviation Organization (ICAO), a specialized agency of the United Nations that \noversees international air travel, has called for a review of existing guidelines regarding OLS. Westlund \nhopes the framework will be useful in these efforts at other airports. As an operator of federally funded research and development centers, our sponsors and customers \nprovide us with trusted access to needed data. \"ICAO doesn't have access to the data to support the type \nof research we're doing,\" Westlund says. \"But data-driven analysis for aviation is MITRE's thing. We focus \non ways to take advantage of new technology while keeping safety the number-one priority.\" by Kathy Chamlee \nApproved for Public Release; Distribution Unlimited. Public Release Case Number 18-3393. https://www.mitre.org/centers/center-for-advanced-aviation-system-development/who-we-are\nhttps://www.mitre.org/capabilities/advanced-technologies/data-science-and-analytics\nhttps://www.mitre.org/centers/we-operate-ffrdcs\nhttps://www.mitre.org/publications/project-stories/government-and-industry-collaborate-to-improve-safety-through-data-sharing\nhttps://www.mitre.org/publications/project-stories/government-and-industry-collaborate-to-improve-safety-through-data-sharing\nhttps://www.mitre.org/publications/project-stories/government-and-industry-collaborate-to-improve-safety-through-data-sharing\nhttps://www.mitre.org/publications/project-stories/government-and-industry-collaborate-to-improve-safety-through-data-sharing\nhttps://www.mitre.org/publications/project-stories/government-and-industry-collaborate-to-improve-safety-through-data-sharing _top\n _Hlk510617069\n _Hlk510691065\n _GoBack ",
    "text": " Comparison of sUAS Safety Risk \nApproaches and Implementations Art Branch\nJeffrey Breunig\nJoyce Forman\nMichael Hadjimichael May 2018 MTR180191 MITRE TECHNICAL REPORT Center for Advanced Aviation System Development Sponsor: The Federal Aviation \nAdministration\nDept. No.: P124\nProject No.: 0216RB06-01\nOutcome No.: 6\nPBWP Reference: 6-4.A.1-1, \nRecommendations for sUAS Airworthiness \nApproval Approaches and Implementation Approved for Public Release; Distribution \nUnlimited. Public Release Case Number: \n18-3095. \nAll rights reserved. McLean, VA ii\n Approved By Tyler Smith Date\nDepartment Head\nNavigation and Unmanned Aircraft Systems Wallace N. Feerrar Date\nPortfolio Manager\nNavigation and Unmanned Aircraft Systems iii\n Executive Summary\nThe Federal Aviation Administration (FAA) requested that The MITRE Corporation (MITRE) \nstudy alternative risk assessment methodologies and provide recommendations going forward to \nsupport the analysis and approvals of small unmanned aircraft system (sUAS) applications and \nprovide the basis for risk-based decision making. This analysis includes detailed studies of two \nrisk assessment methodologies exemplifying two different approaches. The MITRE-developed \nSmall UAS Airworthiness Assessment Tool (sAAT) risk model, currently under development, is \na quantitative probabilistic model. The Joint Authorities for Rulemaking on Unmanned Systems \n(JARUS) Specific Operations Risk Assessment (SORA) methodology, also under development, \nwas selected to represent a knowledge-driven, qualitative risk assessment approach. Each model \nwas selected based on the maturity of the development efforts as representative of the approach \nto risk modeling.\nThe sAAT risk model, developed in collaboration with industry and academia, is designed to \ncalculate the risk of fatality per flight hour, based on aircraft characteristics, density of people \nexposed to the flight, reliability of the system, and aircraft kinetic energy (KE) in case of \ncollision with a person. The risk to the third-party is calculated based on published measurements \nand coefficients for the aforementioned quantities. The benefit of the sAAT model is an explicit \nalgorithm that can be validated and verified by other researchers. The sAAT ground risk model is \nundergoing testing and validation, and an air risk model is in development. The limitations of the \nsAAT model are primarily its narrow scope and limited set of input risk features. Complex or \nqualitative inputs, such as human error or onboard safety mitigations, are not included in the \ncurrent model implementation.\nIn contrast, the SORA methodology, developed by Working Group 6 of the Joint Authorities for \nRulemaking of Unmanned Systems (JARUS), is a rule-based, knowledge-driven system, whose \nrisk inference methods are based on variables, rules, and relationships derived from subject \nmatter experts. The SORA assessment results in a qualitative categorization of the operation into \none of six different Specific Assurance and Integrity Levels (SAIL). It then recommends \nobjectives to be met for each SAIL. The scope of risk factors being considered is broad and wide-\nranging. Compared to the sAAT risk model, the benefits of SORA are an expanded set of risk \nfactors, the ability to incorporate a large variety of risk factor types (quantitative and qualitative) \nand unmanned aircraft systems (UAS) community model development. Limitations of SORA \ninclude the subjectivity of model inputs and complexity of the process. \nThe goal of these models is to support an analysis that considers the combination of the aircraft \nand the intended mission, and provides an overall safety risk assessment of the operation from \nboth the air and ground perspective.\nThe assessment of alternatives was based on a set of evaluation criteria, such as the complexity, \nscope, input parameters, outputs/results, risk factors examined, and mitigation factors examined. \nBased on the evaluation that follows, it is recommended that the FAA: Come to agreement on standardized safety thresholds and acceptable levels of risk to 1.\nguide sUAS risk assessments.\nUse a holistic review process such as the SORA (once finalized) or the FAA safety 2.\nmanagement system (SMS) assessment processes for those operations in the higher risk \ncategories and/or with a required need for increased oversight.\nInvest in the development of semi-automated functions when the SORA methodology is 3. iv\n finalized and standardize the wide variety of inputs and integration of standardized safety \nthresholds. \nConsider using the sAAT model to identify the operations with the lowest risk. These 4.\noperations could be approved without further analysis. This may help streamline the \napproval process by reducing the number of applications that need more rigorous \nevaluation. \nConsider using the sAAT risk model to explore thresholds for acceptable levels of safety 5.\nby examining the most sensitive parameters. Perform research to refine model parameter \nvalues and integrate and expand industry operational data. v\n Acknowledgments\nThe authors would like to acknowledge the technical contributions of the following people: Brian Patterson for background and expertise on the JARUS SORA risk assessment \napproach. Shereef Sayed, Norm Fenlason, and Laurence Audenaerd for their expertise and support \non the MITRE Small UAS Airworthiness Tool (sAAT) risk model. Mike Noe for his subject matter expertise. vi\n Table of Contents\n1 Introduction \n1.2 Approach \n2.1 Risk Assessment Model Dimensions / Evaluation Criteria \n2.1.2 Input Data \n2.1.3 Outputs \n2.1.4 Strengths and Weakness of Quantitative Modeling \n2.2.1 Strengths and Weaknesses of Knowledge-Driven Assessment \n3.1 High-Level Comparison of SORA and sAAT \n3.2 Quantitative Modeling sAAT \n3.2.2 sAAT Ground-Risk Model Inputs \n3.2.3 sAAT Ground-Risk Model Outputs \n3-3. sAAT Output of Sensitivity Analysis \n3.2.4 sAAT Air-Risk Component \n3.2.5 Necessary Simplifying Assumptions for sAAT \n3.2.6 Similar and Related Quantitative Assessments \n3.3.1 Strengths and Weaknesses of the SORA Methodology \n3.3.2 SORA Ground-Risk Assessment \n3.3.3 SORA Air Collision Risk Assessment \n5 References/Bibliography \nAppendix A Abbreviations and Acronyms \n List of Figures\n3-1. sAAT Risk Probability Model \n3-2. sAAT Input of Kinetic Energy and Probability of Fatality \n3-3. sAAT Output of Sensitivity Analysis \n3-4. EASA UAS Risk Categories \n3-5. High-level View of the SORA Risk Assessment Approach \n3-6. SORA Air-Conflict Mitigation Process \nTable 3-1. Fundamental Differences Between SORA and sAAT \nTable 3-2. Vehicle Failure Rates by Weight Class \nTable 3-3. Air-SAIL Values Based on Assessed Air Risk Class \n Introduction1\nWith the rapid acceleration of small unmanned aircraft systems (sUAS) technology development \nand the ever-growing demand for sUAS operations in the National Airspace System (NAS), the \nFederal Aviation Administration (FAA) is seeking risk assessment methods to enable increased \nairspace access to avoid restrictive operational or technical waivers. The FAA desires an \nevaluation approach that is timely and efficient to calculate the key risk factors in sUAS \nmissions, and provide an actionable risk assessment in the form of an airworthiness approval. \nThe approach should: Determine if the mission achieves the required level of safety\nIndicate the highest risk contributors and, Identify the possible risk mitigations for excessive mission risk\nCurrent risk assessment methods assume worst-case conditions wherein an sUAS failure would \nalways achieve its maximum kinetic energy (KE) prior to impact and would always result in a \ncollision with a third-party (uninvolved) individual on the ground or possible mid-air collision \nwith a legacy manned aircraft. These worst-case assessments produce conservative risk estimates \nand limit the ability of the FAA to enable the growing demand for sUAS operations. Purpose1.1\nThe FAA requested that the MITRE Corporation (MITRE) evaluate alternative risk assessment \nmethodologies to provide a recommendation for approving sUAS applications and provide the \nbasis for risk-based decision making. This report contains an overview and comparison of two \ntypes of sUAS assessment methodologies, both of which are still in development: Joint Authorities for Rulemaking of Unmanned Systems (JARUS) Specific Operations \nRisk Assessment (SORA)\nMITRE-developed Small UAS Airworthiness Assessment Tool (sAAT) This document details the basic requirements of a risk assessment model and its inputs and \ndesired outcomes, as well as dimensions for comparisons. The purpose of this work is to inform \nthe FAA on alternative risk assessment approaches to streamline and improve the accuracy of the \nairworthiness assessment process. \nThe FAA typically certificates the airworthiness of the aircraft, certifies the qualification of the \ncrew, and grants operational approval for the operation. This document does not distinguish \nwhich part of this process would be assessing risk as these risk methods could be applied to either \nthe airworthiness of the aircraft or the safety of the operation. Approach1.2\nMITRE compared the JARUS SORA approach to identify the similarities and differences with \nthe sAAT risk model. The sAAT is a quantitative risk model that encompasses academic and \nindustry knowledge and research along with aircraft and mission parameters to develop \nprobabilistic risks of an sUAS collision with people on the ground (third-parties) which results in \na fatality. \nThe SORA approach was selected because of its standing with the international community. This ii\n qualitative approach uses a variety of non-numerical input and results in a risk assessment of \nrelative operations. It has been under development with participation by many nation states and \ncivil aviation authorities. \nThe detailed studies of the two methodologies were used to identify the strengths and weaknesses \nof each approach. Using a set of evaluation criteria, MITRE compared the similarities and \ndifferences of the two methodologies, which informed the set of recommendations. i\n Risk Assessment2\nRisk assessment is a systematic safety evaluation of a situation or activity. It involves the \nidentification of hazards or vulnerabilities, along with an assessment of their likelihoods and \nseverity. A formal model of a process or endeavor will expose and describe its hazards and \nconsequences. Application of such a model enables a consistent and comprehensive assessment \nof risk factors, as well as
a description of the effects of those risk factors. Such an assessment is \ncrucial for risk management; by enabling risk awareness, risk mitigation, and risk-based decision \nmaking. \nA variety of risk assessment methods exist, across many industries [1], [2]. These methods all \nhave the same basic steps in common: Determine what can go wrong1.\nDetermine how often this happens2.\nDetermine the extent of the consequences3.\nDetermine if the assessed risk is acceptable4. Methods to perform the risk assessment vary widely across industry domains. Furthermore, even \nwithin the same domain, the risk assessment can take different forms which may differ in \ndimension. A primary driver of model design is the desired output: Will risk be expressed as a \nnumerical value as a function of probability? Or will the risk be expressed as a qualitative term \nexpressed linguistically or as a relative index on a normalized rating scale? This first design \ndecision drives the selection of model expression (quantitative versus rule-based), and model \ninputs (quantitative versus qualitative data).\nRegardless of methodology, risk is the probability of an undesired outcome with the severity of \nthat outcome. Risk (R) is the Probability (P) of Severity (S) Risk Assessment Model Dimensions / Evaluation Criteria2.1\nIn evaluating risk modeling for airworthiness assessments, there are several dimensions along \nwhich comparisons may be made, as indicated in the following list. There is no order or \nweighting of these criteria. Nor are these criteria the only basis for the final recommendation. How is the risk model expressed? \nWhat kind of input data feeds the approach?\nWhat kind of output is produced? Additional metrics for model implementation evaluation include: Complexity of model\nIntended use (as designed)\nDecision support automation\nRisk areas covered Risk to pedestrians on the ground-\nRisk to other aircraft- ii\n Risk of penetration of sensitive/restricted areas-\nRisk due to human error (whether in planning, controlling, responding to -\nunforeseen/adverse conditions) Model Expression2.1.1\nModel expression refers to the formalism used to encode the risk computation. This may take the \nform of fault and event trees [3], [4], mathematical formulations [5], risk matrices [6], rule-based \napproach [7], or some combination of these and others [8]. Choice of representation is dependent \non intended use and available data. \nQuantitative models enable rapid exploration of input parameters. Trials (what-if tests) are easy \nand inexpensive to run, replicate, and quantify. Probabilistic distributions of input parameters can \nbe randomly sampled to explore the interactions among inputs, and results (e.g., most likely \noutput).\nQualitative models emphasize representation of a maximal set of risk factors. Presentation of \nnumerical input and output of a model may take various formats such as formulas, look-up tables, \nflow charts, and risk matrices. The rules which combine inputs are typically knowledge-driven, \nmeaning that they are derived from subject matter expert knowledge elicitation instead of \nformulas. Input Data2.1.2\nRisk models vary in their data requirements. Input data can range from precise quantification of \nrisk factor probabilities and probabilistic distributions to subjective assessments, expressed on a \nnumerical scale, or a descriptive term (such as low and high). For example, the probability of \na component failure may be expressed quantitatively as a point probability (e.g., 110-5) or as a \nprobabilistic function (e.g., a normal distribution around a mean value). A qualitative reliability \ninput may be expressed as very reliable.\nQuantitative models will depend on quantitative data to compute a quantitative output, while \nqualitative or non-numerical data can be used only by qualitative methods (e.g., rule-based \nmodels). Outputs2.1.3\nRisk model output is motivated by demands of the assessment problem and constrained by the \nmodeling methodology and input data. Methods which produce a quantitative expression of the \nseverity of a hazard, in conjunction with its probability of occurrence, are referred to as \nquantitative methods.\nInterpretation of a quantitative risk model output, probability of severity, is straightforward. For \nexample, probability of an adverse effect during a particular time period, such as probability of \nsUAS failures in one flight hour. Severity in this example relates sUAS failures to fatalities. \nQuantitative models can be validated over time based on actual event statistics, however, this is \nproblematic for rare events. As a substitute, the input probability of relatively more common \nadverse events can be refined (e.g., motor failure). The model algorithm, how output is calculated \nbased on input, can also be challenged and reevaluated by various researchers until a safe \nconsensus is achieved. \nQuantitative modeling can use both statistical and deterministic parameters to represent real iii\n world situations. These values can be presented in various formats such as graphs, equations, \ndiagrams, scatterplots, and tree diagrams. The model provides an abstraction that reduces a \nproblem to its essential characteristics. The model describes, in a quantifiable way, the impact of \nthe inputs on the output. Inputs represent parameters which can be determined, measured, or \ndescribed probabilistically and the output is similarly numerical or probabilistic. \nQuantitative risk assessment is sometimes also known as probabilistic risk assessment. The goal \nis to use quantitative data (measurable, comparable) to support an evaluation whose result is a \ncalculated expression of the severity of a hazard in conjunction with its probability of occurrence. \nThere are various understandings and definitions of risk. [2], [9]. \nProbabilistic risk assessment uses data to develop a probability distribution of risk. This enables \nthe evaluation of input data variability and uncertainty and its effect on the risk assessment. Strengths and Weakness of Quantitative Modeling2.1.4\nThe openly shared algorithm is the main strength of a quantitative approach to risk assessment. Increased model clarity: inputs and outputs are explicit\nComparability\nRepeatability\nAutomation, modeling and simulation A risk model which shares its algorithm description is clear and comprehensible in the sense that \nit specifies exactly how the inputs of the model are determined or measured. The formal \nexpression relating the input parameters to the output can be verified by other researchers. \nFor the same inputs, the model will always generate the same output. Because of this \nconsistency, it is easy to compare model outputs under different conditions. Changes in output \nare due only to changes in measurable input variables. Finally, a quantitative model with a clearly \ndefined range of determined or measured inputs is programmable and can be run automatically to \nsupport various modeling and simulation strategies, such as Monte Carlo methods.\nIn contrast, the weaknesses of quantitative modeling are: The quality of the output is only as good as the quality of the input\nNarrower scope of available features, since data is required to support probabilities\nIt may ignore some important qualitative (non-quantifiable) differences for simplicity\nIt may blur a desired distinction between high probability, low severity events, and low \nprobability, high severity events (which may have the same risk score) A qualitative feature must be given a scale of numeric values (e.g., 1= Strongly Agree, 5= \nStrongly Disagree). Not all qualitative features are amenable to this mapping, which can restrict \nthe inputs. As such, in situations where the process to be modeled is incompletely understood or \nspecified, model expressivity is lost and the model will be incomplete. Assumptions may be \nneeded to fill in the unquantifiable aspects. Reducing a complex process into a simple equation \nmay risk losing important distinctions. For example, events A and B may appear to have equal \nrisk, when the product of the high likelihood and low severity of event A may be equal to the low \nseverity and high likelihood of event B. iv\n Knowledge-Driven Risk Assessment2.2\nIn a knowledge-driven system, risk inference methods are based on variables, rules, and \nrelationships derived from subject matter experts. Although a qualitative process may be \nformalized and rigorous, it does not necessarily require a precise algorithm. The dominant feature \nof such models is that input data may be qualitative, reflecting inputs which are not measurable \nquantities, and output is qualitative. Output may be a risk classification, or relative risk index on \nsome scale (such as 1 to 10). Qualitative inference methods may include matrices relating \nlikelihood categories and severity categories to risk, such as the FAAs safety system \nmanagement (SMS) risk matrix [6]. Other methods include event and fault trees, rule-based \nsystems, and various combinations of such methods. Strengths and Weaknesses of Knowledge-Driven Assessment2.2.1\nThe risk value inference process is a logical and repeatable process, which can consider a very \nbroad range of risk and mitigation factors. For instance, in the SORA process, the guidance \nindicates that more than 100 inputs are required for the risk assessment. At least 40 of the \nrequisite inputs are quantifiable, measurable parameters, such as aircraft dimensions and mass. \nOther inputs are qualitative (e.g., high/medium/low) and free text (e.g., name of aircraft design \norganization). \nThe breadth of inputs required for SORA indicate the span of the risk assessment. If a system is \nmanufactured by a well-established company and undergoes regular maintenance and \nconfiguration management, the risk may be assessed to be less than for a new applicant.\nA knowledge-driven risk assessment is generally more labor-intensive and complex. There are a \nseries of required steps, most of which are manually derived. Although the model is a logical and \nrepeatable process, the complexity of input parameters entails a significant amount of subjectivity \nby the assessor. i\n Risk Modeling for Small UAS Airworthiness Assessment3\nModeling sUAS mission risk, in terms of
potential injuries, for airworthiness assessment requires \nconsideration of the following high-level risk factors: Operator capability/reliability\nAircraft capability/reliability\nDistribution of persons (potential sUAS strike victims)\nMitigating factors To create a risk model, the basic steps are:\nIdentify problem domain. For example: risk assessment of sUAS missions.1.\nDefine consequence and contributing factors. For example, the consequence is fatality, 2.\nmeasured as fatalities per flight hour. The contributing factors, or input variables, are \naircraft mass, mission operating altitude and speed, and population density in the mission \narea.\nBreak down the joint probability into component elements. For example, the probability 3.\nof a fatal strike is the product of the probability of aircraft failure, the probability of \nstriking a person upon failure, and the probability of a person-strike being fatal.\nDefine a metric for each of the model components and how each component probability 4.\nwill be obtained.\nDetermine the risk probability of severity by developing and validating an algorithm that 5.\ncombines these component probabilities into the desired joint probability. High-Level Comparison of SORA and sAAT3.1\nBoth the sAAT and SORA risk assessment models provide an estimate of risk due to operation of \nan sUAS mission over a population. However, the models take different approaches to input data, \nrepresentation of risk relationships, and output of results.\nThe SORA methodology is a generalized approach to risk assessment that provides a qualitative \nassessment of a proposed sUAS operation. SORA is a rule-based, knowledge-driven system, \nwhose risk inference methods are based on variables, rules, and relationships derived from \nsubject matter experts. The risk value inference process is driven by a series of look-up tables and \ncomparisons based on broad categories of inputs (e.g., Lethality is Low, Average, High). As a \nresult, it is wide-ranging in the risk factors that it considers, but qualitative and general in the \nassessment it can provide. SORA is a logical process to analyze a concept of operations and \nestablish an adequate level of confidence that it can be conducted with an acceptable level of risk \n[10].\nIn contrast, sAAT is a quantitative model designed to calculate a risk of fatality per flight hour. \nTo perform this calculation, the sAAT model uses a smaller set of quantifiable risk factors. \nRather than a rule-based approach, risk is calculated for the third-party ground risk.\nThe SORA and sAAT methodologies address different aspects of sUAS mission risk assessment. \nSORA is a methodology to assess the concept of operations and requirements to achieve a \nparticular level of safety, while sAAT is a model of specific mission risk. The SORA \nmethodology can inform the sAAT process by highlighting potential risk factors and their ii\n possible impact on specific mission risk.\nBoth models agree on the following: Assessing risk based on a combination of the intended aircraft and the desired mission \nprofile.\nConsidering fatalities to third parties on the ground and collisions to other aircraft. Classifies third party risk using some form of population density-\nClassifies midair collision risk based on manned air traffic (both methodologies are -\ncurrently drafting or developing air risk components) The general framework: The likelihood of fatalities is a function of likelihood of the UAS \nfailing (operation out of control), the likelihood of a person being struck by a failed UAS, \nand the likelihood of fatality based on impact velocity.\nThe ability to define common, general categories of operations, called mission profiles \nin sAAT, and standard scenarios in SORA.\nEstablishing UAS aircraft categories based on aircraft weight The fundamental differences between the methodologies are depicted in Table 3-1:\nTable 3-1. Fundamental Differences Between SORA and sAAT Evaluation Criteria SORA sAAT\nHow is the risk model expressed? Logic and inference process derived through subject matter expert \nprovided rules Computed Probability What kind of input data feeds the \napproach? Wide variety of qualitative and \nquantitative input parameters \n(aircraft, control station, processes, \nbackup procedures, mitigation \ncapabilities) Deterministic and probabilistic \ndata; geographic area of the \nmission; aircraft characteristics What kind of output is produced? Qualitative risk level (SAIL \ndefined in section 3.3.2) Quantified fatalities per flight hour; \nsensitivity analysis Expertise required to use model High; requires training; labor-\nintensive and judgement required Low; straightforward inputs and \noutputs Maturity of the model In development; most of the \nguidance is still in development; \nsome annexes are not available for \nreview In development, with operational \nprototype Intended use (as designed) Intended as an international risk \nassessment standard for UAS Intended to be a customizable \nmodel, based on specific \npopulations, sUAS operations, \nairspaces, and manned air traffic. Decision support automation None; manual process using look \nup tables and process flow diagrams Fully automated Risk Areas Covered\nRisk to pedestrians on the \nground Yes; population density is a Yes: Covers risk to pedestrians on \nthe ground using KE factors and iii\n generalized factor probable crash patterns;\nUses a 1 square kilometer \npedestrian density Risk to other aircraft Yes Yes\nRisk of penetration of \nsensitive/ restricted areas Yes No Risk due to human error Yes No\nScope of Mitigation factors Considers a wide variety of mitigations: Emergency response \nplan, parachute, shelter, technical \ncontainment, obstacle avoidance \ncapabilities Shelter factor for ground risk is the \nonly mitigation considered. \nMitigations are only added to the \nmodel when their effect can be \nquantified in a scientific, data-\nsupported way. Additional \nmitigation factors can be added as \ntheir value is quantified through \noperations and testing Quantitative Modeling sAAT3.2\nThe sAAT risk model is a quantitative model. It is designed to calculate a risk of fatality per \nflight hour, based on aircraft characteristics, density of people exposed to the flight, reliability of \nthe system, and KE if collision with a person is likely. To perform this calculation, the sAAT \nmodel uses a smaller set of risk factors where quantifiable data is available. sAAT currently \ncalculates the risk to the third-parties on the ground from data based on published measurements \nand coefficients. An air-risk model to determine the risk of a mid-air collision is in development.\nThe sAAT allows different types of users, such as regulators, safety analysts, and operators to \nexplore and analyze the risk of various operational scenarios. Assessing relative risk of Standard Mission Profiles: The sAAT risk model was \ndeveloped to be an analytical tool for assessing the relative risk of various mission profile \nand aircraft combinations. The user interface enables the analyst to look at combinations \nof aircraft and mission profiles to determine the rate of fatality per flight hour. The sAAT \nmodel constants, as well as parameters for the standard mission profiles and aircraft \nprofiles, are configurable items in the implementation to enable what-if types of \nstudies. For each run, the analyst can modify any of the default parameters for the \nstandard operational mission and generic aircraft type. \nEvaluating risk associated with waiver applications: Proposed commercial sUAS \nmissions often require a waiver application to allow for currently prohibited missions. \nThe model can support the evaluation of these applications. Both the applicant and the \nregulator (e.g., the FAA) can use the sAAT model to assess the risk of a proposed \noperation, based on the actual aircraft characteristics and location of the mission. The user \nenters either a flight path or a geospatially referenced shape of the area (such as a circle or \nrectangle). The sAAT uses this information to retrieve the specific population densities \nfor the area of operation. The user enters specific aircraft and operational information, and \nthe sAAT computes the overall level of risk. The assessment may be used as part of an \nSMS approach with various levels of risk acceptability based on the combination of \nmission profile and aircraft type. As the risk of the sUAS operation increases, the higher \nthe approval requirements may be needed. \nInforming sUAS performance standards and policy: With its quantitative analytical iv\n capabilities, the model can provide data to determine operational thresholds and \nacceptable levels of safety. For instance, it may be possible to identify when increased \nfailure rates still achieve target safety levels, such as in low pedestrian density regions. \nThis model can provide decision support for the development of policies, procedures and \nregulations. Risk is characterized by the probability of a fatal strike and the severity of that strike [11]. As the \nmodel only considers one level of severity (fatal), the model simplifies to a discussion of \nprobability only the probability of a fatal sUAS strike on a person.\nIf we assume that probabilities of these components are both independent and Gaussian, then the \ncomponent probabilities can be simply multiplied. One can imagine situations in which these \nevents are not independent and risk for those situations would need to be derived differently. In \naddition,, although the distribution of many of these components are not Gaussian, we can \npostulate a Gaussian over-bound that conservatively encloses that risk and allows this simplified \nmodel to proceed. 3-1. sAAT Risk Probability Model The risk equation components are depicted in Figure 3-1. where the component probabilities of the sAAT model are the following: Probability that the aircraft fails to maintain flight ( currently uses a set of failure rates based on the weight class of the aircraft as o v\n depicted in Table 3-2 due to a lack of operational data on sUAS failure rates. Table 3-2. Vehicle Failure Rates by Weight Class Weight
Category Failure Rate per Flight Hour\nMicro ( 0.55 lbs.) 1E-2 Mini (0.56 4.4 lbs.) 1E-3\nLimited (4.5 20.9 lbs.) 1E-4 Bantam (21 55lbs.) 1E-5 Number of pedestrians exposed to aircraft flight operations () density of exposed population is the mean density of people per square o kilometer within the area of operation. The sAAT uses the average population density by square unit area for operations that cover areas with different population densities. Shelter factor ( shelter factor is the proportion of the population density that is exposed to the o vi\n sUAS operation. A shelter factor of one assumes a worst-case scenario where the population is entirely un-sheltered, conversely, a shelter factor of zero assumes the entirety of the population is sheltered. Probability of the failed aircraft being on a collision course with pedestrian ( is currently defined as where is the calculated horizontal distance from the o point of failure. Probability of the person not avoiding the collision ( currently assumes a unit of one due to the lack of data on what effect onboard o mitigations may provide in avoiding a ground collision with a third-party, or, the \npossibility of reactions by third-parties to avoid a potential collision threat. The value \nindicates the worst-case scenario with no effect from onboard mitigations, and no \nthird-party reaction on the ground. Probability of collision with person resulting in a fatality ( is currently determined by the terminal KE of the aircraft, the impact angle, the o vii\n velocity equation, and the drag equation. Strengths and Weaknesses of the sAAT 3.2.1\nStrengths of the sAAT model include: Consistency: Due to sAAT being a quantitative model, a given set of input parameters \nwill consistently output the same answer providing repeatability.\nModular Architecture: Given the incipient environment of UAS data, the sAAT is built \nwith the ability to change input data quickly should research provide an improved input \nparameter.\nBuilding on Best Practices: The sAAT incorporates work validated by academia and \nindustry. Weaknesses of the sAAT model include: Data Requirements Limit Features: sAAT is a relatively inflexible model unless further \ndevelopment is made to incorporate additional risks such as human error, aircraft \npenetration rates, effects of weather, impact severity, etc. Limited to Current Data: Being an inflexible model, accuracy of the sAAT is subject to \naccuracy of the underlying data. Due to a lack of published research; principal data such \nas aircraft reliability, minimum crash energies resulting in a fatality, and mission profiles \nare posited until conclusive studies or data are provided or collected. sAAT Ground-Risk Model Inputs3.2.2\nThe sAAT model allows the user to select standard mission profiles, aircraft characteristics, and \nselected computational variables, such as the level of energy determined to be fatal, for the risk \nanalysis calculations. The basic input to the sAAT are the parameters defining the mission area \nand the aircraft characteristics. The aircraft and mission parameters are captured either in the \nform of general-purpose mission profiles, or as mission-specific values defined by the user. The \nrequired aircraft information includes gross-takeoff-weight, cross-sectional area of the aircraft, \nmaximum aircraft speed, and maximum aircraft operating altitude. Additionally, the user enters \nthe aircraft type, as either multirotor (e.g. a quadcopter), hybrid, or fixed-wing. Operational \ninformation includes the expected operating speed and altitude. The sAAT uses global maximum \nspeed and altitude values if operation specific values are not otherwise specified as an input \nThe required information for the designated mission area includes the size, shape, geographic \nlocation, and associated population densities for the region of operation. The region of operation \nis a set of geodetic latitude and longitude points provided by the user that define either the \nboundary of operation or the path of operation. Boundaries of operation can be a user defined \ncircle, rectangle, or non-self-intersecting polygon. Paths of operation are a series of user-defined \nwaypoints consisting of at least two points.\nThe density of the population within the route of flight is a significant operational risk factor \nwithin the mission profiles. Higher population density leads to a proportionally higher \noperational risk. The sAAT uses a pedestrian density model, which is based on LandScan viii\n Global Population Database developed by the U.S. Department of Energys Oak Ridge National \nLaboratory [11]. sAAT Ground-Risk Model Outputs3.2.3\nThe sAAT defines risk as the probability of fatality to a third-party. A third party is defined as a \nmember of the public that is not a participant in the sUAS flight activity and is involuntarily \nexposed to an aircraft accident [12]. It is the bystander that happens to be near the planned area of \noperation of the sUAS. \nThe sAAT model interface produces two outputs: (1) a graphical depiction of the risk value; and \n(2) the sensitivity analysis of risk factors. In combination, these three outputs can aid the analyst \nin determining if the risk assessment meets the acceptable safety levels. Additionally, the sAAT \nmodel provides the user with outputs that identify the probability of an impact to a third party, \nand the probability of the impact being fatal. The sensitivity analysis identifies the variables that \nhad the most significant impact on driving the level of risk. 3-2. sAAT Input of Kinetic Energy and Probability of Fatality As illustrated in Figure 3-2, the input graph relates the PoF (%) to the estimated impact KE \n(Joules). The dark line that indicates 50% probability represents the upper threshold of acceptable \nrisk. In this example, the PoF (risk) is 91.2% for an estimated KE at impact of 165.5 Joules. The \ngraph indicates, in this notional example, that the computed risk level is above the 50% \nthreshold.\nThe model identifies the parameters that have the highest sensitivity in driving the overall level \nof risk. This allows for the near real-time assessment of risk and helps support the determination \nof the acceptable risk level of sUAS operations. The sensitivity analysis output, as notionally \nshown in Figure 3-3, indicates which factors contribute the most to the risk. The risk factors and \ntheir associated rankings vary depending on the input data of the proposed sUAS operation. \nFactors are listed in rank order. Positive values on the right side of the y-axis contribute to higher \nrisk. Negative values, measured towards the left of the y-axis contribute to reducing the risk. In ix\n this example, the risk can be reduced the most by reducing the greatest contributors: population \ndensity and the weight of the aircraft. NOTE: this is just a notional output to demonstrate the \nconcept as shown in Figure 3-2. Flying faster would NOT reduce risk. 3-3. sAAT Output of Sensitivity Analysis sAAT Air-Risk Component3.2.4\nAlthough sAAT does not currently include an air risk component, it is intended that an air risk \ncomponent will be added, using the following Modified Endoh methodology [16].\nThe Air Risk model provides the localized risk analysis based on manned aircraft flight data, \nwhich is derived from MITREs Global Flight Informatics (MGFI) database of manned traffic \nunder radar and surveillance coverage. It provides the probability of a Mid-Air Collision Risk, \nand has been successfully demonstrated with the FAA Pathfinder and UAS Test Site Programs, \nand the Navys Triton program.\nAir risk occurs when an operator loses control of the sUAS, and the aircraft achieves unsafe \nproximity to an aircraft (an encounter). Once an encounter occurs, a calculation is made to \ndetermine the probability of a near mid-air collision, defined as the situation when the sUAS and \na manned aircraft occupy the same 3-dimensional space.\nTypically, the risk calculation will also include a measure of event severity. To calculate the \nseverity component of an air risk, it is necessary to understand the conditional probability of \nfatality, given that a collision has occurred. However, research to determine this probability is not \nyet sufficient to determine the consequences of such a collision.\nThis methodology uses historical manned aircraft track data to determine a volumetric collision \nrisk, that is, the probability of collision of an sUAS with a manned aircraft, moving in a volume \nof airspace defined by time of data, altitude, latitude, and longitude. It does not consider the \ncharacteristics of the sUAS. Necessary Simplifying Assumptions for sAAT 3.2.5\nCalculating risk in a quantitative model requires data supporting all the above probabilities. \nWhen exact probabilities are not available, assumptions must be made about these values, so that \nthe result may be calculated. x\n For example, the probability that the operator loses control of the aircraft, , is dependent on many factors, such as model, age, and weather. The sAAT model uses a mean time between failure derived from industry-wide operations as a value to represent the entirety of aircraft \nreliability [17]. Clearly there is a range of possible probabilities due to the variety of factors, but \nfor purposes of computational simplicity, sAAT assumes a single point estimate for this \nparameter.\nTo speed computation (and development), probabilistic distributions are replaced by point \nestimates in the current version of sAAT.\nAlso, some risk components are ignored, as they are not easily quantified: Operator skill\nWeather conditions during mission\nVisual obstruction during Line of Sight Operations\nMechanical mitigations Similar and Related Quantitative Assessments 3.2.6\nThe basic equation, expressing risk as a function of failure rate, and
exposed population is \ncommon to many quantitative models; for example, Melnyk et al. [5], and Weibel et al. [18]. \nWork has been done to understand the consequences of sUAS impact on a person, work was \ndone by Campolettano et al. [19] and the FAAs center of excellence for UAS research [20]. Knowledge-Driven Risk Assessment Approach SORA3.3\nJARUS is a group of experts from over 50 countries, representing international aviation \nregulation authorities, industry, regional authorities, as well the European Aviation Safety \nAgency (EASA), the European Organisation for the Safety of Air Navigation \n(EUROCONTROL), and the FAA. JARUS members collaborate to recommend a single set of \ntechnical, safety and operational requirements for the certification and safe integration of UAS \ninto airspace and at airports. xi\n 3-4. EASA UAS Risk Categories xii\n JARUS is developing the SORA for evaluating the risk for operating a UAS within the \nSpecific category. The Specific category is one of three EASA UAS categories (Open, \nSpecific, and Certified), as depicted in Figure 3-4 [21]. The Specific category (unlike the Open \nand Certified categories) requires a waiver or authorization, which involves a hazard and risk \nassessment. The Open category is for sUAS flying visual line of sight (VLOS) operations \nbelow 120m (400 feet above ground level). The Certified aircraft are the larger \ncommercial/military UAS that have undergone type certifications and have regular safety \nmaintenance. Both Open and Certified have well-defined operational constraints to mitigate \nrisks. \nThe SORA is a tailoring guide that allows the regulator to determine appropriate risk mitigations \nfor reducing the risk to an acceptable level. Per the introduction to the SORA overview \ndocument, the methodology should not be used as a checklist nor be expected to provide \nanswers to all the challenges [10]. The SORA methodology may be applied where the \ntraditional approach to aircraft certification (approving the design, issuing an airworthiness \napproval and type certificate) may not be appropriate due to an operator/applicants desire to \noperate a UAS in a limited or restricted manner [10].\nThe SORA methodology is a rule-based, knowledge-driven system, whose risk inference \nmethods are based on variables, rules, and relationships derived from subject matter experts. The \nSORA methodology provides a qualitative assessment of a proposed UAS operation. It can be \napplied to UAS aircraft of any weight class (e.g., not limited to sUAS, whose weight is under 55 \nlbs.). SORA is a logical process to analyze the risk of a proposed UAS mission concept to \ndetermine if the operation can be approved by the regulator.\nThe risk value inference process is driven by a series of look-up tables and comparisons based on \nbroad categories of inputs (e.g., Lethality is either Low, Average, or High). The scope of risk \nfactors being considered is broad and wide-ranging. It includes aircraft operational and physical \ncharacteristics, crew training, manufacturer maturity, system component reliability, mitigation \nfactors, and backup operational procedures to name a few. The SORA methodology is a logical \nprocess to analyze a concept of operations and establish an adequate level of confidence that it \ncan be conducted with an acceptable level of risk. The SORA methodology is a logical process to \nanalyze a concept of operations and establish an adequate level of confidence that it can be \nconducted with an acceptable level of risk [10]. Strengths and Weaknesses of the SORA Methodology3.3.1\nStrengths of the SORA methodology include: Broad range of factors considered: The SORA methodology examines several different \naspects of risk and considers a wide range risk factors and mitigation factors. Considers proximity to restricted/sensitive airspace: Risk is increased if the planned \noperation is near restricted/sensitive airspace, an airport, and over critical infrastructure. Considers both strategic and tactical mitigations: Strategic mitigations are those \nprocesses in place, such as training, maintenance, and configuration management. SORA \nassumes less risk for established operational procedures and pre-programmed aircraft \nresponse due to loss of control. Tactical mitigations include the ability of the aircraft to \navoid obstacles and other aircraft (i.e. collision avoidance capabilities) during active flight. Weaknesses of the SORA methodology include: xiii\n Lack of consistent guidance: Updates to the SORA methodology are currently underway. \nFor instance, the SORA methodology has been used by civil aviation authorities (CAAs) \nworldwide, including the FAA with the approval of beyond visual line of sight (BVLOS) \noperations by Xcel Energy. However, the guidance from accompanying Annexes are either \nmissing or still being drafted. It is uncertain when the methodology will be finalized. \nWithout all the Annexes, the SORA methodology, as described, cannot be conducted fully. \nIn addition, the current Annexes are not completely aligned or consistent with each other, \nwhich adds difficulty to conducting the risk assessment. Complex: The SORA approach is highly-detailed and may be laborious for assessing \nsUAS applications or unscheduled UAS operations. The level of detail and analytical rigor \nof the SORA approach may be better suited for larger UAS flying scheduled operations \n(e.g., Part 121) in controlled airspace and near restricted air space. In addition to the main guidance publication, the SORA documentation includes specific \ninformation and guidance in the form of ten Annexes, which are the following: Annex A: Input Guidelines for collecting and presenting system and operation \ninformation for a Specific UAS operation.\nAnnex B: Harm Barriers\nAnnex C: Strategic Mitigations\nAnnex D: Tactical Mitigations\nAnnex E: Threat Barriers\nAnnex F: Ground Risk Model \nAnnex G: Air Risk Model\nAnnex H: Unmanned Traffic Management (UTM) Implication for SORA\nAnnex I: Glossary of Terms\nAnnex J: Standard Scenario Template SORA Ground-Risk Assessment3.3.2\nThe SORA methodology is a tiered (hierarchical) model, that assimilates a prescribed set of \ndecomposed risk and mitigation factors in a standardized manner. \nThe first tier assimilates risk in the following areas: Harm Identification (fatalities, damage)1.\nHazard Identification (aircraft-centric, for instance the UAS operation out of control)2.\nThreats (outside of the aircraft, adverse operating conditions, issues with external 3.\nsupporting systems, collision course, etc.)\nAircraft Mitigations (referred to as Harm Barriers)4.\nOperational Mitigations (referred to as Threat Barriers)5. The SORA methodology introduces the concept of Specific Assurance and Integrity Levels \n(SAIL), which represent the level of confidence that a specific operation will stay under control \n[10]. SAILs include factors, such as crew training, manufacturer of the aircraft, and complexity \nof the proposed UAS operation. The SAIL determines what constraints and mitigations are \nrequired. It outlines which safety objectives must be complied with and identifies the types of xiv\n evidence required to indicate that the objectives have been satisfied. There are six SAILs, where \nSAIL I is the lowest risk level and SAIL VI indicates operations with highest intrinsic risk. \nThe grade of SAIL is determined through identification of Threats and Harms, along with \nprevention mechanisms (Threat Barriers) and mitigation mechanisms (Harm Barriers). For \ninstance, the lack of crew training may increase the likelihood of a fatality to a person on the \nground. A Harm Barrier would be a well-designed training program for all crew. The Threats are \nexternal forces on the aircraft, such inclement operating conditions and issues or failures of \nexternal systems, such as communication links. Figure 3-5 depicts a high-level view of the risk \nassessment approach SORA employs. 3-5. High-level View of the SORA Risk Assessment Approach The SORA assessment methodology includes several detailed Annexes. The reader can refer to \nAnnex F, Ground Risk Model, for more information about the ground risk assessment. However, \nAnnex F is not currently available for public distribution. SORA Air Collision Risk Assessment3.3.3\nThe air risk assessment portion of the SORA methodology spans Annexes C, D, and G. Annex C, \nStrategic Mitigation Collision Risk Assessment, and Annex D, Tactical Mitigation Collision Risk \nAssessment, are currently in draft and are expected to be released upon the next revision of \nSORA. Annex C is expected to provide guidance on how an operator may implement and \ndemonstrate assignment of encounter categories, assess the air risk class, provide concepts for the \nimplementation of strategic mitigations, and assess the SAIL. Annex D is expected to provide \nguidance on detect-and-avoid (DAA) and assignment of tactical mitigation requirements. \nSimilar to the ground-risk assessment, the SORA air collision risk component results in an Air-\nSAIL (Air-SAIL I through Air-SAIL IV). There are several steps for determining the level of air \ncollision risk, as follows: Determination of Airspace Encounter Category (AEC) category: The AEC is a 1.\nqualitative classification of the rate at which a UAS would encounter a manned aircraft in xv\n typical civil airspace. SORA categorizes airspace into one of 12 collision risk categories \n[22]. These categories are characterized by altitude, controlled versus uncontrolled \nairspace, airport versus non-airport environments, airspace over urban versus rural \nenvironments, and lastly atypical versus typical airspace.\nAssignment of Initial Air-Risk Class (ARC): The ARC is a qualitative classification of 2.\nthe rate at which a UAS would encounter a manned aircraft in typical civil airspace, \nwhich is based on the likely number of other aircraft in a given airspace. There are four \ncategories (i.e., no risk, low, moderate, and high risk) for the ARC determination. The \nARC represents the collision risk for the airspace defined in the AEC, before mitigations \nare applied [22]. \nApplication of Strategic Mitigations to reduce the initial ARC (optional): If the ARC 3.\nis too high, the operator can identify
mitigations can be applied to reduce the ARC level \n[22]. There can be strategic mitigation and tactical mitigations, as depicted in Figure 3-6. 3-6. SORA Air-Conflict Mitigation Process Assignment of SAIL from Air Collision Risk: Using a look up table, the Air-SAIL is 4.\nmapped directly from the final (i.e., mitigated) ARC level, as indicated in Table 3-2. xvi\n Table 3-3. Air-SAIL Values Based on Assessed Air Risk Class Final ARC Air-SAIL\nARC 4 SAIL VI\nARC 3 SAIL IV\nARC 2 SAIL II\nARC 1 SAIL I Determination of Uncontained Integrity Level: Depending on the ARC level, further 5.\nassessment is made on based on the intended proximity to adjacent airspaces with higher \nAEC levels. Uncontained integrity levels needed for the phases of flight or flight \nsegments that are adjacent to sensitive/restricted airspaces [22]. The definition of \nadjacent is subjective.\nTactical Mitigation Performance Requirement (TMPR) and Robustness Levels: 6.\nThese indicates the level of the aircrafts ability to avoid collisions with obstacles (See \nand avoid capabilities) and to avoid conflicts with other aircraft (conflict detection \ncapabilities). Flights operating with visual line of sight do not need to meet TMPR \nrobustness levels; whereas BVLOS operations need to meet the TMPR and robustness \nlevels [22]. The TMPR and robustness levels are used as the basis of requirements of the \noperator to meet for approval. The SORA guidance provides Annexes that give more specific information for each of these \nsteps for determining the AIR-SAIL. Refer to ANNEX G, the Air Risk Model, for more detailed \ninformation. 4 i\n Conclusions and Recommendations5\nIn summary, quantitative risk modeling methods require all model components to be numerically \nquantified and their output to be a numerical value which reflects a physical quantity. In contrast, \nqualitative models allow both quantitative and qualitative inputs. Risk may be calculated by a \ncombination of methods, including numerical equations, inference rules (if-then), lookup tables \n(SMS matrices), and many other methods [23]. The principal differences are the explicit \nalgorithm of a quantitative probabilistic model versus the flexibility and broader subjective inputs \nand qualitative output of a qualitative model. Model precision is based on the completeness and \ncomprehensiveness of the input variables, as well as the quality, timeliness, and utility of the data \nthat is used for the inputs. \nBased on the evaluation that follows, it is recommended that the FAA: Come to agreement on standardized safety thresholds and acceptable levels of risk to 1.\nguide sUAS risk assessments.\nUse a holistic review process such as the SORA (once finalized) or the FAA SMS 2.\nassessment processes for those operations in the higher risk categories and/or with a \nrequired need for increased oversight.\nInvest in the development of semi-automated functions when the SORA methodology is 3.\nfinalized and standardize the wide variety of inputs and integration of standardized safety \nthresholds. \nConsider using the sAAT model to identify the operations with the lowest risk. These 4.\noperations could be approved without further analysis. This may help streamline the \napproval process by reducing the number of applications that need more rigorous \nevaluation. \nConsider using the sAAT risk model to explore thresholds for acceptable levels of safety 5.\nby examining the most sensitive parameters. Perform research to refine model parameter \nvalues and integrate and expand industry operational data. i\n References/Bibliography6\n[1] T. Aven, \"Risk Assessment and Risk Management: Review of Recent Advances on Their Foundation,\" European Journal of Operational Research, vol. 253, no. 1, pp. 1-13, 2016. \n[2] M. Rausand, Risk Assessment: Theory, Methods, and Applications, John Wiley & Sons, 2011. \n[3] R. E. Barlow et al., \"Reliability and Fault Tree Analysis: Theoretical and Applied Aspects of System Reliability and Safety Assessment: Papers,\" in Society for Industrial and Applied \nMathematics, Berkeley, 1975. [4] R. Farret et al., \"Design of Fault Trees as a Practical Method for Risk Analsysi of CCS: \nApplication to the Different Life Stages of Deep Aquifer Storage, Combining Long-Term \nand Short-Term Issues,\" Energy Procedia, vol. 4, pp. 4193-4198, 2011. [5] R. Melnyk et al., \"A Third-Party Casualty Risk Model for Unmanned Aircraft System \nOperations,\" Reliability Engineering & System Safety, vol. 124, pp. 105-116, 2014. [6] FAA, Order 8040.4B Safety Risk Management Policy, Effective date 02 May 2017. \n[7] M. Hadjimichael, \"A Fuzzy Expert System for Aviation Risk Assessment,\" Expert Systems with Applications, vol. 36, no. 3, pp. 6512-6519, 2009. \n[8] T. Bedford and R. Cooke, Probablistic Risk Analysis: Foundations and Methods, Cambridge: Cambridge University Press, 2001. \n[9] A. McNeil, R. Frey and P. Embrechts, Quantitative Risk Management: Concepts, Techniques and Tools Revised Edition, Princeton and Oxford: Princeton University Press, \n2015. [10] Joint Authorities for Rulemaking of Unmanned Systems, JARUS guidelines on Specific \nOperations Risk Assessment, 1.0 ed., 2017. [11] J. Breunig et al., \"Modeling Risk-Based Approach for Small Unmanned Aircraft Systems,\" \nin AIAA Aviation Forum, Atlanta, 2018. [12] R. Aalmoes et al., \"A conceptual third party risk model for personal an unmanned aerial \nvehicles,\" in International Conference on Unmanned Aircraft Systems, Denver, 2015. [13] Range Commanders Council, \"Common Risk Criteria for National Test Ranges: Inert \nDebris,\" 2000. [14] Range Commanders Council, \"Range Safety Criteria for Unmanned Air Vehicles,\" 2001.\n[15] P. W. Janser et al., \"Lethality of Unprotected Persons due to Debris and Fragments,\" 1982.\n[16] N. Fenlason, \"Modified Endoh Method for Calculating Airborne Unmitigated Collision Rates,\" The MITRE Corporation, McLean, 2017.\n[17] J. Moore, \"Guessing When Your Drone Will Die,\" AOPA, 5 March 2018. \n[18] R. Weibel and R. J. Hansman, \"Safety Considerations for Operation of Different Classes of UAVs in the NAS,\" in AIAA 3rd \"Unmanned Unlimited\" Technical Conference, Workshop \nand Exhibit, 2004. [19] E. T. Compolettano et al., \"Ranges of Injury Risk Associated with Impact from Unmanned \nAircraft Systems,\" Annals of Biomedical Engineering, vol. 45, no. 12, pp. 2733-2741, 2017. [20] D. Arterburn et al., \"FAA UAS Center of Excellence Task AF: UAS Ground Collision \nSeverity Evaluation Revision 2,\" 2017. [21] W. Ryan, \"Industry Based Compliance Challenges,\" in FAA UAS Symposium, Baltimore, \n2018. [22] Joint Authorities for Rulemaking of Unmanned Systems, JARUS guidelines on Specific ii\n Operations Risk Assessment, 1.1 Draft ed., 2018. \n[23] J. Condor et al, \"A Comparative Analysis of Risk Assessment Methodologies fo rthe Geologic Storage of Carbon Dioxide,\" Energy Procedia, vol. 4, pp. 4036-4043, 2011. \n[24] EASA, Notice of Proposed Amendment 2017-05 (A), 2017. i\n Abbreviations and AcronymsAppendix A AEC Airspace Encounter Category\nARC Air-Risk Class\nBVLOS Beyond Visual Line of Sight\nCAA Civil Aviation Authorities\nCFR Code of Federal Regulations\nDAA Detect-and-Avoid\nEASA European Aviation Safety Agency\nEUROCONTROL European Organisation for the Safety of Air Navigation\nFAA Federal Aviation Administration\nFt Feet\nJARUS Joint Authorities for Rulemaking of Unmanned Systems\nKE Kinetic Energy\nMGFI MITREs Global Flight Informatics\nMITRE The MITRE Corporation\nNAS National Airspace System\nPoF Probability of Fatality\nsAAT Small Unmanned Aircraft System Airworthiness Assessment Tool\nSAIL Specific Assurance and Integrity Level\nSMS Safety Management System\nSORA Specific Operations Risk Assessment\nsUAS Small Unmanned Aircraft System\nTMPR Tactical Mitigation Performance Requirement\nUAS Unmanned Aircraft System\nUTM Unmanned Traffic Management\nVLOS Visual Line of Sight NOTICE This work was produced for the U.S. Government under Contract DTFAWA-10-C-\n00080 and is subject to Federal Aviation Administration Acquisition Management \nSystem Clause 3.5-13, Rights In Data-General, Alt. III and Alt. IV (Oct. 1996). The contents of this document reflect the views of the author and The MITRE \nCorporation and do not necessarily reflect the views of the Federal Aviation \nAdministration (FAA) or the Department of Transportation (DOT). Neither the FAA \nnor the DOT makes any warranty or guarantee, expressed or implied, concerning \nthe content or accuracy of these views. 2018 The MITRE Corporation. All Rights Reserved. _Toc214668640\n _Toc214701175\n _Toc515517896\n _Hlk512418823\n _Toc513014315\n _Toc513067171\n _Toc513206867\n _Toc515517897\n _Toc512679845\n _Toc513014318\n _Toc513067172\n _Toc513206868\n _Toc515517898\n _Toc515517899\n _Toc515003314\n _Toc513014320\n _Toc513067174\n _Toc513206870\n _Toc515517900\n _Toc513014321\n _Toc513067175\n _Toc513206871\n _Toc515517901\n _Toc513014322\n _Toc513067176\n _Toc513206872\n _Toc515517902\n _Toc513014323\n _Toc513067177\n _Toc513206873\n _Toc515517903\n _Toc513014325\n _Toc513067179\n _Toc513206875\n _Toc515517904\n _Toc513014327\n _Toc513067180\n _Toc513206876\n _Toc515517905\n _Toc513014328\n _Toc513067181\n _Toc513206877\n _Toc515517906\n _Toc513014330\n _Toc513067182\n _Toc513206878\n _Toc515517907\n _Hlk515458075\n _Toc513014331\n _Toc513067183\n _Toc513206879\n _Toc515517908\n _Toc513118522\n _Toc515517930\n _Toc513014332\n _Toc513067188\n _Toc513206880\n _Toc515517909\n _Toc513118515\n _Toc515517924\n _Toc515517931\n _Toc513118501\n _Toc513014334\n _Toc513067189\n _Toc513206881\n _Toc515517910\n _Toc513014336\n _Toc513014337\n _Toc513067190\n _Toc513206882\n _Toc515517911\n _Toc513014339\n _Toc513067191\n _Toc513206883\n _Toc515517912\n _Toc515517925\n _Toc513067192\n _Toc513206884\n _Toc515517913\n _Toc515517926\n _Toc515517914\n _Toc513014341\n _Toc513067193\n _Toc513206885\n _Toc515517915\n _Toc513014342\n _Toc513067194\n _Toc513206886\n _Toc515517916\n _Toc515517917\n _Toc513014345\n _Toc513067196\n _Toc513206888\n _Toc515517918\n _Toc513014346\n _Toc513067197\n _Toc513014347\n _Toc513206889\n _Toc515517919\n _Toc513014348\n _Toc513118520\n _Toc515517928\n _Toc513206890\n _Toc515517920\n _Hlk509232743\n _Hlk499710939\n _Hlk509836804\n _Hlk513530627\n _Hlk509229816\n _Hlk509232838\n _Hlk513463383\n _Toc515517929\n _Toc513118523\n _Toc515517932\n _Hlk501799332\n _Hlk509837609\n _Hlk509232867\n _Toc513014350\n _Toc513067199\n _Toc513067200\n _Toc513067201\n _Toc513014351\n _Toc513067202\n _Toc513206891\n _Toc515517921\n _Hlk514827284\n _Toc293499079\n _Toc515517922\n _Toc515517923\n _GoBack ",
    "text": " 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3379' Engineer Embraces Design Thinking as a Framework for Problem-Solving\nAwais Sheikh was the first member of his family to grow up in America. Experiencing a culture in the \noutside world that was very different from the culture inside his home, he sought out ways to embrace \nthe best of both cultures. This skill proved valuable in his engineering career as he began exploring \nhuman-centered design as a complement to classical systems engineering. \"My stories and experience, as well as listening to other people's stories, makes me a better engineer,\" \nSheikh says. \"The more we understand people and their experiences, the better equipped we are to \naddress the complex issues facing our country.\" Awais recent focus has been exploring business innovation methods to apply within MITRE and at \nsponsor agencies, including lean startup and design thinking. \"Design thinking\" is an approach that \nhelps us better understand people's stories, Sheikh says. He describes design thinking as \"living in a \nproblem domain for a while, exploring the problem from the user's experience, and understanding \nwhat their needs are.\" \"It's a holistic and responsive approach that helps us solve the kinds of the kinds of complex problems \nthat MITRE tackles for our government sponsors.\" Bringing Award-Winning Skills to MITRE Sheikh's early experiences primed him to look for ways to combine design thinking alongside traditional \nsystems engineering. After earning a degree in business information technology from Virginia Tech, he \nworked for various management and information technology consulting firms. During this time, he \ngained valuable experience in technology management and applying agile methods to government \nprojects. While working full-time, Sheikh also returned to Virginia Tech and earned an MBA. Armed with his new \ndegree and his earlier successes applying agile methods and design thinking to government projects, \nSheikh joined MITRE in 2012. He wasn't the first in his family to take that step30 years earlier his \nfather joined MITRE. \"The fact that my father worked at MITRE didn't sway my decision to join the company,\" Sheikh says. \n\"But over the years, my father talked about how MITRE differs from for-profit companies by working in \nthe public interest. I wanted to be part of that mission.\" Design Thinking Achieves Innovative Outcomes \"Design thinking involves observing the problem and its effects in context,\" Sheikh says. \"Then you start \nbrainstorming, conceptualizing, developing, and rapidly prototyping possible solutions.\" Among other projects, Sheikh led a team in MITREs first empirical study of applying design thinking in a \nfederal context. \"The government wanted formal research to confirm the benefits of using design \nthinking and turned to MITRE because of our expertise and objectivity,\" he says. \"We developed \nresearch and methodology for empirically demonstrating the outcomes of a design-thinking approach.\" His team's work has been featured at conferences and in journals, including the 2018 Academy of \nManagement Annual Conference. https://www.mitre.org/capabilities/acquisition-effectiveness/acquisition-initiatives/agile-acquisition\nhttps://www.mitre.org/publications/project-stories/applying-design-thinking-to-boost-federal-agency-problem-solving\nhttps://www.mitre.org/publications/project-stories/applying-design-thinking-to-boost-federal-agency-problem-solving\nhttps://www.mitre.org/publications/project-stories/applying-design-thinking-to-boost-federal-agency-problem-solving\nhttps://journals.aom.org/doi/10.5465/AMBPP.2018.74\nhttps://journals.aom.org/doi/10.5465/AMBPP.2018.74\nhttps://journals.aom.org/doi/10.5465/AMBPP.2018.74\nhttps://journals.aom.org/doi/10.5465/AMBPP.2018.74\nhttps://journals.aom.org/doi/10.5465/AMBPP.2018.74\nhttps://journals.aom.org/doi/10.5465/AMBPP.2018.74 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3379' While at MITRE, Sheikh and his colleagues have applied design thinking methods for various internal \nefforts and sponsor projects. In one, they took a \"big picture\" view and employed design thinking to \nanalyze the current tools, the actual users of these tools, and the problems end users want these tools \nto solve. As a result, MITRE developed a large-scale modernization solution that will result in faster, \nmore efficient services, such as issuing identity and travel credentials. Empowering Early Career Professionals Serving as the business innovation capability lead at MITRE, Sheikh advocates design thinking as a \nframework for problem solving. \"Design thinking enables MITRE and our government sponsors to \napproach old, stubborn problems in new ways and find long-term, sustainable solutions.\" Sheikh is also passionate about mentoring early career researchers at MITRE. He serves as a role model \nby speaking with new hires and junior staff about innovation in an engineering context. His achievements, both technical and professional, have not gone unnoticed. Sheikh was recently \nnominated for a 2019 Becoming Everything You Are (BEYA) award, which promotes diversity by \nrecognizing engineers of color who have made achievements and accomplishments in science, \ntechnology, engineering, and math (STEM). --by Lisa Pacitto https://www.mitre.org/careers/working-at-mitre/professional-development\nhttps://intouch.ccgmag.com/page/beya_stem_conf2\nhttps://intouch.ccgmag.com/page/beya_stem_conf2\nhttps://intouch.ccgmag.com/page/beya_stem_conf2\nhttps://intouch.ccgmag.com/page/beya_stem_conf2\nhttps://intouch.ccgmag.com/page/beya_stem_conf2 _top\n _GoBack ",
    "text": " Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3584\n _GoBack\n _top\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack\n _GoBack ",
    "text": " Mission Dependency Analysis with Physical Network Relationships Les Servi, Kael Stilp MITRE Corporation Mclean, VA October 15, 2018 Abstract The combination of functional and physical relationships is a natural means to identify the key areas a network is most vulnerable in an at- tack. Towards that end this paper examines four variations of the general combinatoric decision making problem of identifying the physical nodes of a computer network to enter, the physical nodes to traverse and then the functional nodes to attack to most impact the networks mission all subject to a budget constraint. The paper also introduces a new model to begin to lay the groundwork for computing the trade-offs between observ- ing an adversarys traffic vs. diminishing an adversarys functionality. To capture this scenario, this paper proposes interlocking a Prize Collecting Steiner Tree problem with Functional Analysis. The paper ends with nu- merical experiments which illustrate by example, the size and complexity of networks each of the four variations are achievable using the methods described. This work is meant to provide initial support for future defense analysis evaluating attack strategies relying on imperfect information, and incorporating network properties into Functional Analysis. c Approved for Public Release; Distribution Unlimited. Case Number 17-3756 1 1 Introduction Modeling cyber security attack metrics with a functional network is a practiced and natural means to capture complex relationships towards overall operability. However, physical realities can easily be missed with this modeling technique. This paper proposes a broad means to improving functional analysis through the inclusion of decisions support from physical network models. Functional rela- tionships determine the quality of an overall system given many pieces, and can be used to identify nodes of greatest impact to an attacker. Physical relation- ships express the realities of any attack, that an attack is a strategy occurring over real world connections where there may be the ability to share costs among many attacks, and since attacks are part of a larger system, may adversely im- pact other goals on a network. This papers examines four variations of this variety: (P1) A network with physical nodes which can be attacked and a very simple mission objective. (P2) A network with no physical nodes but functional nodes whose leafs, when attacked, impact the mission objective in specified but more complicated ways. (P3) A network with both physical and functional nodes which combines the best elements of problem (P1) and problem (P2). (P4) A network with both physical and functional nodes as is in (P3) but also with nodes which have the ability to observe traffic. The problems (P1)-(P3) are used to explore the initial computational com- plexity of such a problems as (P3). This work is precursor to analysis defensive network design analysis and providing a tool for evaluating impartial informa- tion attacking methods. The problem (P4) is introduced to explore how network properties feed into functional analysis, and not just what nodes are attacked. As a generic description, systems working towards a common function can be said to have a mission, where the combined elements of the system have an overall capability of effectiveness at accomplishing that function. The quality of this capability to accomplish the desired function can be called the Measure of Effectiveness (MOE), a continuous rating between 0 and 1, where 0 is no function and 1 is fully functional. The inputs that can be changed, or in this paper, attacked, are called the leaf nodes, denoted i L. The premise is that the nodes i L have a effectiveness value ei which propagate through a function system to find the MOE. There are many ways in which the MOE can be defined, any calculable func- tion given inputs could suffice. For general use in this paper, given decisions w [0,1]|w| the MOE can be measured by w : moe(w) [0,1]. The func- tion moename() can be any suitable function with the given description name. For this paper w represents the leaf nodes attacked within a functional system, and the computations are run with an existing implementation of Functional 2 Network Dependency Analysis (FDNA) [3, 4, 5, 6, 16]. Functional system with parameterized inputs helps identify critical leaf nodes, i.e. if leaf nodes are attack which ones have the greatest impact to the MOE. Other functional net- works, such as BLARE, Crown Jewel, RiskMap, and SODA, can easily supplant FDNA in the analysis. Functional systems use parameters to model the relationship between child and parent nodes, to calculate the operability of nodes from the leaf nodes up to the root node. These parameters may be thought of as judgments on the relationships between nodes. If these parameters are either not accurate, or changed, it may impact any analysis. This uncertainty can be explored through robust optimization techniques that explore the worst case modifications of these parameters [9]. This paper will take advantage of existing uncertainty work on FDNA trees to get these considerations without additional effort. This paper extends functional networks by accounting for more complex restrictions on the decisions that can be made. In particular, the focus is on incorporating physical realities of computer network attacks into decision tree analysis. Instead of each leaf node of the functional network having a set cost, attacks will occur over a new physical network where leaf nodes of the functional network double as physical nodes. This will allow attacks to share attacking resources for multiple attacks, simultaneously. This is an implementation of Prize Collecting Steiner Tree (PCST) to an objective value using more complex functions. The expansion of functional networks is done by adding in a physical layer. Steiner Tree networks are well studied and come in a wide variety [12]. Most variations of the problem have fairly straight forward objective functions, but a very broad class of objectives is being proposed in this paper. In some ways, Prize Collecting Steiner Tree (PCST) objectives, which involves finding a min- imum cost subtree with costs for including edges and a profits for connecting specified sets of nodes, is close to the base problem in this paper [13]. There are some variations with more complex objective functions. Buy at Bulk k-Steiner Tree is a problem that incorporates a distance measure between node pairs into the objective [14]. In communication networks, evaluating the quality of edges can be additional constraints to a problem such as in Quality of Service Mul- ticast Tree Problem. [15] This paper contributes a general functional analysis structure as an objective to the Steiner Class of problems and loosely uses PCST to define a variation with a budget for opening arcs and a desirable prize for reaching non-Steiner nodes. The sets of problems which will be discussed in this paper will start from base problems (P1) and (P2), then combine them. This paper keeps an FDNA MOE obfuscated with moeopr(w) for the purpose of describing expansions of the problem and emphasizing this is not restricted to FDNA. This function measures the operability of a network, which an attacker wants to minimize. A formal description of FDNA can be found in Appendix A. Finally, the addition of complimentary second objective to the attacker is added to reference further work, which is described in the appendix. 3 (P1) Physical Attack Attackers start from outside a protected network or networks, and spend budget to traverse arcs and compromise successive nodes, trying to min- imize the average operability of important nodes. The attacker is tar- geting a specific set of important nodes, but the resource costs to make the attacks is determined by actual network artifacts, such as strength of firewalls, etc. Finding weaker points of traversal and taking advantage of already compromised paths can be advantageous to the attacker. This can be used as a simple measure of effectiveness of attacks or placing network traffic observers. (P2) Functional Attack The attacker makes decisions to compromise the leaf nodes of a functional network, indicated by w, to minimize the mission, moeopr(w), while not exceeding a cost budget. The cost to attack is determined independently for every leaf node, and the sum cost of attacking each leaf node must be within the resource budget. Each of the leaf nodes of a network are represented by high and low operability values and a cost to attack. Each attack reduces the operability of a leaf node from the high value to the low value, and the budget is used to minimize the MOE by selecting the appropriate leaf nodes to attack. (P3) Functional Physical Attack Combine (P1) and (P2), by replacing the simple MOE of (P1) with the more diverse computation of (P2). (P4) Functional Physical Attack with Observation This is (P3) with two additional considerations. First a second objective is trying to maximize moeobs(m), where m represents the indicator of net- work traffic being observed in the modified, attacked network. Traffic is observed by in place observers the attacker already controls. The second change is that the attacker must now choose whether to disable a
com- promised node or not, where in the previous problems there was never a reason to not disable a compromised node. Not disabling a node may benefit the attacker by routing more network traffic through an observer. The key to unlocking (P3) is to generalize (P1) to use a Functional Analysis objective function instead of a summation of prizes collected. For the sake of this paper, Physical Attack can be thought of as having many outside nodes the attacker has free access to, and an internal network with L where prizes, or a Functional generalization, is present. From the accessible outside node, the attacker may spend budget to traverse arcs and compromise new nodes, from which additional arcs may be traversed to compromise additional nodes. 1.1 Illustrative Example To illustrate the problems and their differences, Figure 1 shows an example of a network an instance of each problem. For each problem in this instance, the 4 cost to attack across each arc is 1, the budget is 2, and every functional parent is equal to the average operabilities of its children. The operability of the leaf nodes is as follows: 103.0 is 1; 104.0 is .2; and 105.0 is .6. When attacked, each of these is reduced to operability 0. There is also an observer on node 2.0, and the attacker wishes to observe traffic from node 105.0 to node 103.0. If the traffic is observed, moeobs(m) = 1, otherwise moeobs(m) = 0. (P1) When implementing Physical Attack there is no associated functional net- work and the problem is trying to minimize the average operability of the leaf nodes. The best attack collects as much operability as is possible. The optimal solution, shown in Figure 1, thus attacks node 103.0, which has an operability of 1, more than half the total operability on the leaf nodes. This overestimates the value of node 103.0 due to not calculating MOE with an functional network. (P2) Functional Attack replaces the physical network with the minimal cost for attacking each node in the physical network. Thus, node 103.0 costs 2 to attack, node 104.0 costs 2 to attack, and node 105.0 costs 1 to attack, which with a budget of 2 means exactly one leaf node can be attacked. Figure 1 show the optimal solution, which is now to attack node 105.0, but this misses that by attacking node 105.0, node 104.0 would no longer cost 2 to attack. (P3) Functional Physical Attack rectifies the mistakes made by Steiner Attack and Functional Attack. It does not over value node 103.0, and it recognizes that 104.0 costs less to attack after node 105.0 has been attacked. Figure 1 shows the optimal solution to Steiner Attack, where once node 105.0 has been attacked, the attack can continue to also attack node 104.0. However, this attack eliminates node 105.0, which the attacker wished to observe. (P4) Functional Physical Attack with Observation has a multi objective func- tion and thus has many opimal solutions along a Pareto curve. The solu- tion shown in Figure 1 is one such optimal solution, where moeobs(m) > 0. If the attacker wants to observe the traffic, a new optimal solution is shown in Figure 1. The traffic originates from node 105.0 and terminates at node 103.0. In the unattacked network, the shortest path is 105.0, 104.0, 103.0, so the traffic is not observed by the observer placed at node 2.0. However, in the optimal attack, node 102.0 is disabled, so the new shortest path is 105.0, 3.0, 2.0, 103.0, which is observed at node 2.0. The attacker chooses to not disable node 2.0, even though it has compromised it. 2 Analysis The proposed underneath network will be D = (N,A), a directed network, where the parameters w for moeopr(w) and/or the parameters m for moeobs(m) can be determined, and a super node set n0 N0 N represents the origin of 5 (a) Base instance (b) Physical Attack opti- mal solution (c) Functional Attack op- timal solution (d) Functional Physical Attack optimal solution (e) Functional Physical Attack with Observation Pareto optimal solution. Figure 1: Illustrative examples, where white nodes are functional, gray nodes are leaf nodes, and charcoal nodes are physical. The attack is represented as bold edges and node outlines, with the attack originating from the Outside. Where necessary, network traffic is indicated by a dashed lines and an observer is indicated by a dashed gray outline 6 all attacks. The arcs A represent the physical connections that an attack can occur over. This can be generalized to the nodes or both nodes and arcs, but for this paper, the assumption is made that attacking is done to nodes over arcs. This models that where at attack occurs from impacts the cost. The proposed definition of an attack is that it an attacking path to node nj N is the sequence of nodes n0, n1, n2, . . . , nk1, nk, where k = j, (ni1, ni) A. The node nj 6 N0 will be said to be compromised if it is on any attacking path. There are some assumptions made regarding how attacking paths are made. The first assumption is that attacks are not cumulative, a node attacked twice is compromised once. Therefore, each leaf node need only be attacked by a single attacking path. The second assumption is that once a node is compromised, an attack can be made on any incident node. Any compromised node may be disabled freely by the attacker. In problem (P4) it may be advantageous to compromise a node but not disable it as a means of routing network traffic advantageously. The following data is shared by the problems. SET CONDITION DESCRIPTION N Set of underneath nodes N0 N0 N Super node set representing external attack origins L L N,N0 L = Leaf nodes A Set of arcs attacks can occur over PARAMETER CONDITION DESCRIPTION ca a A Cost to attack via an arc vn n L Value of disabling a node b Budget for attacks VARIABLE CONDITION DESCRIPTION wi i L, wi [0, 1] Indicator of attack of a leaf node pa a A, pa [0, 1] Indicator of an attack via an arc uk,a k L, a A, uk,a [0.1] Attack path indicator for each leaf node 2.1 Physical Attack The Physical Attack base model is the underneath physical network, and attacks are coordinated attacking paths from outside the network which may share attack costs by following overlapping paths to separate leaf nodes. With no functional dependency, the objective of minimizing the average operability of each leaf node is the assumed objective, which is the equivalent of the standard maximizing the sum of operability disabled in PCST. The variable v is used for this purpose, as a prize. The initial attack formulation uses a multi commodity single path formula- tion. That is, for every node that is attacked, a path must be identified using a single unit of flow from N0 to the node. When leaf nodes are relatively sparse or 7 the network is relatively small this is a reasonable formulation. In these cases it keeps columns down and avoids Big M coefficients on binaries. Different formulations may, certainly, be more appropriate for different instances. min vT(1w)|L|1 (1) s.t. cTp b (2)\n (n0,j)A:n0N0 uk,(n0,j) wk = 0 k L (3) (i,k)A uk,(i,k) wk = 0 k L (4) (j,i)A uk,(j,i) \n (i,j)A uk,(i,j) = 0 k L,i N : i 6 N0, i 6= k (5) uk,a pa 0 k L,a A (6) p,u,v,w B (7) The model will find an attacking path from some node in the super node set N0 to each leaf node that is disabled. For each path that is chosen all of the arcs must be used for an attack. Note that optimality guarantees a node would never need to be attacked multiple times, so this formulation does not need to handle allowing a path to use an arc to access a node attacked from elsewhere. The path trying to find a second route to the already attacked node could just use the already established attack path. Constraints 2 restricts the attacks to be within budget. Constraints 6 states that any arc on an attacking path must have been paid for by the attacker. Constraints 3,4,5 mandate an attacking path from the origin node to each leaf node k that has wk = 1. These constraints do not enforce a simple loop. Any loops add cost to Constraint 6 but serve no advantage to the objective. Optimality thus allows the assumption that each attack path is a simple path. Post processing of any solution can ignore loops with no negative practical impact. 2.2 Functional Attack For a reference starting point for functional attacks, the Functional Attack model is where each leaf node l to a functional decision tree has a cost cl\nto attack. The sum of these costs must be no more than the budget and the MOE is minimized. The coefficient c can be thought
of as an arc from an undefined source node, such as n0, to each node in L. min moeopr(w) (8) s.t. cTw b (9) w {0, 1}|L| (10) 8 This model uses a knapsack constraint on attacking nodes, where the value of the knapsack is determined by the functional system. This paper uses a robust formulation of FDNA for computational purposes. 2.3 Functional Physical Attack The Functional Physical Attack expansion of the Functional Attack problem adds the Steiner network from Physical Attack. Here, the leaf nodes are iden- tified as physical nodes as well as functional nodes. Attacks are coordinated paths from outside the network to leaf nodes. These attack may share attack costs by following overlapping paths to separate leaf nodes, and the effectiveness is measure by the interlocked functional system. This problem is closely related to Prize Collecting Steiner Tree problems, except that rather than a simple prize the evaluation is on a functional tree. min moeopr(w) (11) s.t. cTp b (12)\n (n0,j)A:n0N0 uk,(n0,j) wk = 0 k L (13) (i,k)A uk,(i,k) wk = 0 k L (14) (j,i)A uk,(j,i) \n (i,j)A uk,(i,j) = 0 k L,i N : i 6 N0, i 6= k (15) uk,a pa 0 k L,a A (16) p,u,v,w B (17) Note that similar to the Physical Attack, in an optimal solution there is no need for any node to be attacked more than once, and loops can be post- processed out with no practical negative impact. Constraint 12 restricts that attacks the overall budget Constraint 16 states that any arc on an attacking path must have been paid for by the attacker.. Constraints 13,14,15 mandate an attacking path from the origin node to each leaf node k that has wk = 1. 2.4 Functional Physical Attack with Observation (P4) is evaluating how network traffic patterns are impacted by the compro- mising of nodes, which may be utilized to reroute traffic to cross preplaced observers in the network. This is a challenging model to formulate due to un- certainty of existing network patterns, but the use of robust FDNA networks to evaluate success can aid in taking a simplified formulation and hedging against uncertainty. 9 The details to formulating (P4) are left for Appendix B. In order to formulate (P4), a (P3) model is used as a top layer, and the attacking decisions create a modified auxiliary network where shortest path models and their duals are simultaneously solved to track successful observation of network communication. The point of (P4) for this paper is to demonstrate how properties of net- works should contribute to the functional systems and not just what nodes are attacked. Functional systems are designed to simplify decision logic, but if value of properties of a network have large impact they should be considered in as direct a manner as possible. Showing (P4) without computation accomplishes that, and Appendix B shows a more thought out initial idea on capturing net- work properties into the existing decision logic. 3 Numerical Examples The goal of running experiments in this paper is to demonstrate potential ele- ments of importance for if implementing (P3). Demonstration 1. The individual difficulty of solving the functional and phys- ical networks of (P3) has a compounding impact on the difficulty of solving their combined network. Demonstration 2. Adding physical networks in (P3) may introduce situations where budgets have sudden changes in marginal payoff. Demonstration 3. The percentage of nodes that are leaf nodes likely represents a higher difficulty to solve. All of the experiments are run with a vanilla Gurobi solver, with the physical network built into an existing FDNA tool. The experiments clearly showed that Gurobi could struggle to find both good bounds as well as good solutions, and as problems scaled up The difficulty increased super linearly as one would expect. 3.1 Method For all comparisons in this paper each instance will have multiple runs across a variety of budgets, and the results will be scaled to a uniform measure. It is assumed the same input instance is used with varied budgets. To describe the varied input, and how long it runs, the notation IP (r, s) [lb, ub, s] will be used to represent a run with budget r and terminating either at optimality, and objective output values satisfying lb = ub, or with terminating in s seconds with lb < ub representing the best determined lower bound and the best found solution value for an upper bound. The symbol will be used to indicate a term or inequality being ignored. Require: StepSize, T imeLimit [\n.\n,MinMOE, ] IP (,) [,MaxMOE, ] IP (0,) [,MaxBudget, ] min(r) : IP (r, 2 TimeLimit) >= [,MaxMOE, ] 10 Figure 2: Sample chart of a series of runs on an instance. Total 0 Step 0 while Step <= 1 do [lb, ub, s] IP (Step MaxBudget, T imeLimit) B max( lbMinMOE\nMaxMOEMinMOE , 0) V ubMinMOE\nMaxMOEMinMOE T s\nT imeLimit OutputStep [B, V, T ] Total Total + VB+T\n2 b 1\nStepSize + 1c Step Step+ StepSize end while Ensure: Output, Total For a range of budget values the relative computation time and the relative range of the attainable mission value were computed. Many experiments were conducted with different step sizes and with a Time limit and four parameters were computed. Specifically, we computed B, V, T and Total where B could be interpreted as the value of the bound relative to the minimum MOE and maximum MOE of interest. V cab be interpreted as the relative value of the best found solution relative to the minimum MOE and maximum MOE of interest. T can be interpreted as the time used to find the solution relative to the time limit, If optimality is not found, the value is 1. Total is an aggregation of B, V, and T to roughly interpret the difficulty of an experiment. A Total of 0 solved to optimality in 0 second on every run. A Total of 1 meant no run did better than a bound of the best case MOE and a solution of the worst case MOE. An example of how each of these experimental runs is displayed is shown in Figure 2. Both axis are on a scale from 0 to 1. The gray fill is a representation of Total, so a larger gray bar means the experiment was more difficult. The columns represent each run for the experiment. The line graph tracks T and the bars track B and V. If B and V are equal, optimality was found and it will be a flat line. If B and V are different then the line graph will be at 1 and a box representative of the optimality gap connects B and V. 3.2 Experiments The first experiment is meant to demonstrate Hypothesis 1 and 2. The function and physical networks are given three structures each, None, Simple, Complex. The None structure will help demonstrate (P1) and (P2), indicating the associ- 11 Figure 3: The rising cost of structure complexity on both physical and functional networks, run using 600 seconds each at 5% steps. ated network was not used. The Simple structures can be interpreted as being individually simpler to solve than the Complex structures, which were indi- vidually more difficult to solve. In particular, the physical Complex simulates a non-traditional cluster network with abundant connections. The functional Complex is based on an NP-Hard set cover problem. All of these structures are in the vicinity of 200 nodes, except Complex functional, which is around 140 nodes. Each network is given the same set of leaf nodes, so that any pair of functional and physical networks can be paired for a full model. Figure ?? shows the results of combining all 9 possible instances. P0 is labeled, and is the well known Knapsack problem. P1 is created when there is a physical network paired with None from the functional network. P2 is created when None is used from the physical networks with any functional network. P3 is created when neither None is used. Demonstration 1 is supported by observing how the rows show greater complexity as rows are lower, while columns more to the right show greater complexity. Particularly note the quadrant of (P3) instances. When the two Simple networks are interlocked, the resulting (P3) is also simple, but when the two Complex networks are interlocked, there is a significant increase the difficulty of the experiment. Demonstration 2 is supported by observing the Simple functional row. Interlocked with None physical there is clear diminishing returns, but interlocked with the Simple physical the returns plateau then take sharp dips. This is representative of valuable nodes being more expensive to reach with an attack. The second experiment is meant to demonstrate hypothesis 3. Both the 12 Figure 4: The complexity by percentage of leaf nodes to total nodes, using 600 second runs on the first row, 1200 second runs on the second row, and 1800 second runs on the third row. functional and physical networks are built in
similar topological manners in an effort to make the comparison more similar. Moreover, a physical (or functional) network of smaller size than a larger physical network, is strictly a subgraph of the larger. In all instances, the number of Non-Leaf Physical Nodes is equal to the number of Non-Leaf Functional Nodes. Figure 4 shows the results over runs between 5% and 95% of the nodes being Leaf nodes. Hypothesis 3 is supported by observing how the gray boxes form a hill like structure across each row. 4 Conclusion This work extends the viewpoint of functional analysis to incorporate physical realities through the interlocking of two different modeling approaches. Four problems are introduced and explored on instances with hundreds of nodes. The first three capture how to combine the two different models into one holistic model. For these three models, computational experiments demonstrate the relationship between the difficulty of the holistic model to the difficulties of the individual components. The fourth model demonstrates how network properties, such as the links used for network traffic, can contribute as inputs to functional analysis. These ideas are precursors to future work exploring imperfect information for attacks, whole system defensive network design. The work on observation opens many questions on how to successfully implement network properties into 13 functional analysis within a decision support tool context. References [1] Watters, J., Morrisey, S., Bodeau, D., and Powers, S., The Risk-to-Mission Assessment Process (RiskMap): A Sensitivity Analysis ad an Extension to Treat Confidentiality Issue, The MITRE Corporation. Dartmouth, NH : The Institute for Information Infrastructure Protection. Pub Rel 09-2994, p 25-26, 2009. [2] Hastings, G., Montella, L., and Watters, J., MITRE Crown Jewel Analy- sis Process, MITRE Corporation MITRE Technical Report MTR090088. 2009. [3] Garvey, P. and Pinto, C., Introduction to Functional Dependency Network Analysis, Proceedings from the Second International Sympo- sium on Engineering Systems, Massachusetts Institute of Technology, http://esd.mit.edu/symp09/day3.html, 2009. [4] Garvey, P. and Pinto, C. Advanced Risk Analysis in Engineering Enter- prise Systems. Chapman- Hall/CRC-Press, Taylor & Francis Group (UK), Boca Raton, London, New York, ISBN 0. 2012. [5] Garvey, P., Pinto, C., and Santos, J., Modelling and Measuring the Op- erability of Interdependent Systems and Systems of Systems: Advances in Methods and Applications, International Journal of System of Systems Engineering, Vol. 5, Issue 1. 2014. [6] Servi, L., and Garvey, P., Deriving Global Criticality Conditions from Local Dependencies, to appear in Systems Engineering, 2017. [7] Browning, T., Applying the design structure matrix to system decom- position and integration problems: a review and new directions, IEEE Transactions on Engineering Management, Vol. 48, Issue 3, p. 292-306. 2001. [8] Browning T., Design structure matrix extensions and innovations: a sur- vey and new opportunities. IEEE Transactions on Engineering Manage- ment, Vol. 63, Issue 1, p. 27-52. 2016. [9] Frezza, D., and Servi, L. Two Stage Generalized Robust Optimization Submitted to Operations Research 2017. [10] Guariniello, C., and DeLaurentis, D., Supporting Design via the System Operational Dependency Methodology,Research in Engineering Design, Vol. 28, p. 53-69, 2016. 14 [11] Reliability Information Analysis Center, Data and Analysis Center for Soft- ware, 2005. Topic 6.6.2 Fault Tree Analysis (FTA) In System Reliability Toolkit. [12] M. Hauptmann, M. Karpinski (eds.), A Compendium on Steiner Tree Prob- lems, 2013. [13] Ljubic, Ivana, Weiskircher, Ren, Pferschy, Ulrich, Klau, Gunnar, Ljubi C, Ivana, Mutzel, Petra, Fischetti, Matteo. (2004). Solving the Prize- Collecting Steiner Tree Problem. [14] M.T. Hajiaghayi, G. Kortsarz, and M. Salavatipour. Approximating Buy- at-Bulk and Shallow-light k-Steiner trees. Approximation, Randomiza- tion, and Combinatorial Optimization. Algorithms and Techniques, pages 152163, 2006. [15] Du, D.,Hu, X. Steiner Tree Problems in Computer Communication Net- works. World Scientific Publishing, 2008. [16] Mason, E and Servi, L and Frezza, D Critical Node Analysis and System Identification using a Discrete, General Framework for Dependency Map- ping, Submitted 2017. A FDNA Functional networks which takes inputs and calculates a series of dependencies to determine the overall MOE of a system. For this paper, existing code for robust FDNA is expanded upon, but the ideas present are not exclusive to FDNA. Each node in a FDNA tree is said to have an operability level between 0 and 100, where the operability of the root node is the MOE. The operability of children in a FDNA tree, an value determining weighted average, and a limitation on the scalar difference between each child and its parent, determine the operability of each parent node. SET CONDITION DESCRIPTION F Set of FDNA nodes L L F Leaf nodes J J = F\\L Set of children for each node PARAMETER CONDITION DESCRIPTION ij i F, j J (i) Weighted multiplier ij i F, j J (i) Weighted scalar b Budget for attacks VARIABLE CONDITION DESCRIPTION Pi i F Operability of node i 15 The essential Equation 18 is used to calculate a parent operability once the operability of each node is known. For this paper, binary indicator variables w on the leaf nodes determine if a leaf node has either a High or Low operability level, which are taken as input. The Mixed Integer Program formulations to either minimize or maximize are based on this equation. Pi = min 100\n1 |J (i)| jJ (i) (100 Pj)ij , min\njJ (i) [Pj + ij ] (18) Robust can be thought of as a way of assuming mistakes are made within a model. A value will determine how many parameters were wrong, then additional inputs can be used to determine how far off a parameter may be. Solving for the robustness will require the solutions to account for worst case parameter mistakes, thus preventing mistakes letting a solution looking being too good to be true. Two values and can be independently input to the problem to explore how the MOE is impacted based on how inaccurate the parameters may have been. See ?? for a detailed explanation on implementing robustness into FDNA. This paper will use the and to show those FDNA ideas extend to Problem 1 and Problem 1 for free. B Functional Physical Attack with Observation The key to unlocking these problem 1 is evaluating how network traffic patterns are impacted by the compromising of nodes, which may be utilized to reroute traffic to cross preplaced observers in the network. This is a challenging model to formulate due to uncertainty of existing network patterns, but the use of robust FDNA networks to evaluate success can aid in taking a simplified formulation and hedging against uncertainty. B.1 Formulation If attacks are thought of as severely limiting the functionality of a physical node, there may be additional consequences not fully captured by only measuring the overall functionality through a decision tree calculation. An attacked may have the ability to observe network traffic at certain places within the physical network, so destroying the capability of a node may simultaneously limit their ability to gather information. This section will expand the Steiner Attack problem with a second objective which maximizes the ability to observe network traffic. The initial assumption will be that there are existing nodes in N\\N0 which have observers on them, and the defender is unaware of their existence. The second assumption will be that network traffic occurs between any pair of nodes, and must not travel through the outside network represented by N0. The third assumption is that network traffic is uncapacitated. The fourth assumption is that communication 16 between two nodes will always take the resulting shortest path within the net- work, and, for the sake of being conservative, network paths of equal length are lexicographically shorter if they are not incident with an observer than if they are. The third and fourth assumptions are the most pressing to expand upon. The problem lies in a nuance about network flows and determining how a network should prioritize routing traffic at nodes that meet capacity. With shortest path, a lexicographic preference towards traffic not being monitored implies all shortest paths must have a monitor for the attacker to successfully monitor traffic. However, if flow, any designed in preferences for routing traffic could cause unintelligently biased solution preferences. Some work needs to be done to make it work. Even the more extreme requiring of a cut consisting of observers between a sender and receiver to claim traffic is observed does not work, as if the cut is a bottleneck for traffic the model must determine what traffic is sent though. Even more of a reason to make the third and fourth assumptions is the question of how much information is known. To incorporate capacities, there must be a realistic notion of all traffic within the system. The existing monitors may provide some of this information, but not likely all of it. Furthermore, with capacities the model must know the routing mechanisms in place within the network. The unlikelihood of a reasonable model of these attributes complicates trying to measure the network traffic. For now, with no capacity, the initial model for observers can use shortest path, and the imperfect information can be reflected by utilizing robust optimization of uncertain
value of network traffic presumed to be observed under shortest path. This is a shortfall, and must be addressed in future research. The first definition of an attack with observers will use the following data. SET CONDITION DESCRIPTION N Set of underneath nodes N0 N0 N Super node set representing external attack origins L L N,N0 L = Leaf nodes A Set of arcs attacks can occur over NM NM N Nodes containing observers of value to the attacker AM AM (N\\N0) (N\\N0) Set of node pairs (s, t) with valued traffic The physical network contains NM and AM , defining the observers and the pairs of nodes between which observing their traffic is desirable. The assumption will be that traffic for (s, t) AM will travel along the shortest path from s to t, using only nodes that have not been attacked. If that path is incident with a node in NM , the traffic (s, t) will be considered observed. PARAMETER CONDITION DESCRIPTION ca a A Cost to attack via an arc b Budget for attacks 17 VARIABLE CONDITION DESCRIPTION wi i N\\N0, wi [0, 1] Indicator of disabling of a node pa a A, pa [0, 1] Indicator of an attack via an arc ui,a i N/baclaN, Attack path indicator for each node a A, ui,a [0.1] m(s,t) (s, t) AM ,m(s,t) [0.1] Indicator traffic is monitored g(s,t),a (s, t) AM , a A, g(s,t),a 0 Shortest path flow x(s,t),i (s, t) AM , i N\\N0 Shortest path dual values The assumption will be that attacks may choose to disable any node it attacks, or leave them functioning. Attacks could be modeled with Big M flow constraints, in this case, since any node may be attacked. However, the shortest path calculations would be expected to dominate the order of the size of the problem, this model will stick with the Steiner formulation. A Big M coefficient would be at the head of the binary decision dependencies and could cause pseudo randomness in traditional means of finding solutions. Shortest path calculations pose an issue, since shortest path must be en- forced while the objective functions run counter to the network adhering to the condition. As such, each shortest path will be modeled with both the primal and dual versions for enforcement. Before getting to the model, some discussion is required regarding the pri- mal/dual formulations of shortest path. Using the defined parameters and for some s, t N\\N0, and a vector h {1.0.1}\n|N\\N0|, where hs = 1, ht = 1 and hi = 0 otherwise, the primal formulation of the shortest path from s to t is min 1Tg (19) s.t.\n (j,i)A,j 6N0 g(j,i) \n (i,j)A,j 6N0 g(i,j) = hi i N\\N0 g 0 The variable g can be assumed to be binary. The resulting dual problem is max xt xs (20) xj xi 1 i, j N\\N0 : (i, j) A (21) A primary problem in implementing shortest path as a way to model network traffic is that attacked nodes need to be removed form the internal formulation. Moreover, the resulting problem could be infeasible. Both cases must be han- dled. The case that the resulting problem becomes infeasible First, consider the new shortest path formulation when nodes V = {i N\\{N0 {s, t}} : wi = 1} are removed. The resulting primal formulation is 18 min 1Tg (22) s.t.\n (j,i)A,j 6{N0V } g(j,i) \n (i,j)A,j 6{N0V } g(i,j) = hi i N\\{N0 V } g(i,j) 0 (i, j) A : i, j N\\{N0 V } To convert model 19 to model 22 using w as a variable, the constraints g(i,j) + wi 1 i, j N\\N0 : (i, j) A g(i,j) + wj 1 i, j N\\N0 : (i, j) A can be applied and note that on deleted constraints on associated attacked nodes trivially equal 0. The modified dual is max xt xs (23) xj xi 1 i, j N\\{N0 V } : (i, j) A To convert model 20 to model 23 using w as a variable, the constraints on attacked nodes need to be removed. The constraints can be modified by adding a Big M reduction xj xi |N\\N0|(wi + wj) 1 i, j N\\N0 : (i, j) A where it is known the longest shortest path is limited by the nodes in N\\N0. These modifications leave the case where the resulting shortest path is in- feasible, either due to s or t being attacked or s and t having a cut set being attacked. One workaround, used here, is to modify h using m(s,t). The premise is that shortest path will only be calculated if m(s,t) = 1, that is the network traffic passes through an observer. If the s, t pair is cut or the shortest path is not incident with an observer, m(s,t) will be forced to 0 and make the primal/dual trivial with 0 solutions. These modifications can be made by setting hs = m(s,t) ht = m(s,t) and then requiring that some observer be incident to the path with (i,j)A:i,jN\\N0,iNM or jNM g(i,j) m(s,t) 0 and then requiring primal/dual equality with 1Tg (xt xs) = 0 19 . These shortest path models must be done for each (s, t) AM . The proposed overall model will additionally trim some unnecessary variables out which are always 0 due to optimality conditions. The assumption made on the model that any monitored path is lexicograph- ically longer than an unmonitored path of the same length is not explicitly modeled. Perturbations on the primal/dual of the shortest path sub-models easily achieve this. The proposed model following combines the Steiner Attack formulation with a new functional decision tree objective and the discussed shortest path sub models for each (s, t) AM . 20 min moeopr(w),moeobs(m) (24) s.t. cTp b (25)\n (n0,j)A:n0N0 uk,(n0,j) wk = 0 k N\\N0 (26)\n (i,k)A uk,(i,k) wk = 0 k N\\N0 (27)\n (j,i)A uk,(j,i) \n (i,j)A uk,(i,j) = 0 k N\\N0,i N : i 6 N0, i 6= k (28) uk,a pa 0 k N\\N0,a A (29)\n (s,j)A,j 6N0 g(s,t),(s,j) m(s,t) = 0 (s, t) AM (30)\n (i,t)A,i6N0 g(s,t),(i,t) m(s,t) = 0 (s, t) AM (31)\n (j,i)A,j 6N0 g(s,t),(j,i) \n (i,j)A,j 6N0 g(s,t),(i,j) = 0 (s, t) AM ,i N\\{N0 {s, t}} (32)\n (i,j)A:i,jN\\N0,iNM or jNM g(s,t),(i,j) m(s,t) 0 (s, t) AM (33) g(s,t),(i,j) + wi 1 (s, t) AM ,i, j N\\N0 : (i, j) A (34) g(s,t),(i,j) + wj 1 (s, t) AM ,i, j N\\N0 : (i, j) A (35) x(s,t),j x(s,t),i |N\\N0|(vi + vj) 1 (s, t) AM ,i, j N\\N0 : (i, j) A (36) 1Tg(s,t) (x(s,t),t x(s,t),s) = 0 (s, t) AM\n(37) p {0, 1}|A| (38) u {0, 1}|N\\N0||A| (39) v {0, 1}|N\\N0| (40) m {0, 1}|AM | (41) g 0 (42) 21 The objective function now has two functional decision trees. Constraints 25,26,27,28,29 are from Steiner Attack. Constraints 30,31,32 are similar path constraints, requiring traffic that is observed have a flow of one from the sender to the receiver. Constraint 33 requires observed traffic be incident with some observer. Constraints 34,35 prohibits network traffic from using a disabled node. Constraints 36,37 form the duals for the shortest paths, enforcing that shortest paths are simple, shortest paths. Constraint 37 has a Big M coefficient to trivialize constraints that should not be in the dual due nodes being disabled. 22 ",
    "text": " APPROVED FOR PUBLIC RELEASE; DISTRIBUTION UNLIMITED. \nPUBLIC RELEASE CASE NUMBER 18-3508 MITRE TECHNICAL REPORT: MTR180617 LinkBioMan: Delivering Actionable Context to \nMultimodal Video Understanding October 2018 Dr. Monica Carley-Spencer\nAdithya Dattatri\nHoward Huang\nChongeun Lee\nBenjamin M. Skerritt-Davis\nAmanda C. Vu\nMatthew R. Walmer\nMarc S. Zebrowitz The views, opinions and/or findings contained in this report are those of \nThe MITRE Corporation and should not be construed as an official \nGovernment position, policy, or decision, unless designated by other \ndocumentation. 2018 The MITRE Corporation. All Rights Reserved. Corporate Headquarters\nMcLean, Virginia ii iii Abstract\nSince most multimedia context extraction models deal with benign, simple and often trivial \ncontexts, there is a need for a decision framework capable of processing complex topics and \nextracting an actionable context that can aid in public area safety and in post-event investigation \nfor law enforcement or national/international security. The framework should be able to process \nmultiple data streams, combining lower-level sensory inferences into a human-level interpretation \nof events. In this paper, we introduce Linking Soft Biometrics to Semantic Description of an Event \n(LinkBioMan), a multimodal near-real-time decision framework capable of producing \nactionable context, a preliminary interpretation of events and automated alerting. With the \nYouTube2Text dataset, LinkBioMan's Captioner achieves a maximum METEOR score of 0.3183 \nand a maximum CIDEr score of 0.7061, which is in line with the performance of other video \ncaptioners. We also demonstrate the effectiveness of LinkBioMan's context classification module, \nContextNet, which outperforms NISTs 2015 TRECVid evaluation team scores for the Semantic \nIndexing challenge. LinkBioMans ContextNet achieves a mean Average Precision (mAP) score \nof 0.325 (0.379 using a subset of TRECVid data with audio) in relevant categories, compared with \nthe TRECVid 2015 teams' maximum mAP score of 0.273 in the same categories. Ablative tests on \nContextNet demonstrate the critical contribution of raw visual features and show that motion and \naudio boost performance in certain categories of semantic concepts depending on the nature of the \ncontext. LinkBioMans multimodal fusion strategy at the decision level allows it to process \ncomplex, multimodal data streams to generate an understanding of scenes ranging from everyday \nevents to life-threating emergencies. iv v Table of Contents \n1 INTRODUCTION \n3.2 YOUTUBE2TEXT DATASET \n3.3 TRECVID EVALUATION DATASET \n4.2 CONTEXTNET \n4.3 LINKBIOMAN CAPTIONER \n5.2 ALERT: CONTEXTNET ON THE LBM DATASET \n5.3 CONTEXT CLASSIFIER: CONTEXTNET, RANDOM FORESTS ON THE TRECVID EVALUATION DATASET \n5.4 ABLATION: CONTEXTNET \n5.5 CAPTIONER: ON THE LBM DATASET \n5.6 CAPTIONER: ON THE YOUTUBE2TEXT DATASET \nAppendix B Dataset Details \nB.2 All Data (Minus Unreadable Clips) \nB.3 Clips with Audio \nAppendix D Acronyms and Abbreviations \nFIGURE 1: LINKBIOMAN DECISION FRAMEWORK \nFIGURE 2: SAMPLE FRAMES OF LBM DATASET VIDEO CLIPS \nFIGURE 3: LINKBIOMAN DESIGN \nFIGURE 4: AUDIO PROCESSING \nFIGURE 5: CONTEXTNET DESIGN \nFIGURE 6: SHOW AND TELL CAPTIONER VS. LINKBIOMAN CAPTIONER (FIRST VERSION) \nFIGURE 7: SHOW AND TELL CAPTIONER VS. LINKBIOMAN CAPTIONER (SECOND VERSION) \nFIGURE 8: AVERAGE PRECISION AND MEAN AVERAGE PRECISION: CONTEXTNET VERSUS RANDOM FORESTS \nFIGURE 9: AP FOR CONTEXTNET VERSUS AP FOR RANDOM FOREST VERSUS INFAP FOR TRECVID TEAMS ON THE TRECVID EVALUATION DATASET \nFIGURE 10: CONSTRUCTIVE ABLATIVE TESTS OF CONTEXTNET WITH THE LBM DATASET \nFIGURE 11: CORRUPTIVE ABLATIVE TESTS OF CONTEXTNET WITH THE LBM DATASET \nTABLE 1: NUMBER OF POSITIVE AND NEGATIVE INSTANCES FOR THE TRECVID DATA \nTABLE 2: LINKBIOMAN MODULES \nTABLE 3: COMPARISON OF CONTEXTNET (CN), RANDOM FORESTS (RF) AND BEST TRECVID TEAM ON THE TRECVID EVALUATION DATASET \nTABLE 4: CAPTIONER PERFORMANCE ON THE LBM DATASET \nTABLE 5: CAPTIONER PERFORMANCE ON THE YOUTUBE2TEXT DATASET AND YOUTUBE2TEXT CLIPS WITH AUDIO \nA surge of compact and affordable multimedia recording devices has enabled virtually anyone to \ngenerate images, audio recordings and videos anywhere and anytime. This media has usages \nranging from personal memorabilia, to more critical matters, such as, real-time monitoring for \nphysical property, surveillance for border protection, public area safety and post-event \ninvestigations for law enforcement or national/international security. However, the amount of data \nproduced by such everyday sensors has far surpassed the available human resources needed to \nprocess, analyze and formulate a timely response. For example, a command center with dozens of \nscreens playing surveillance video feeds would need to staff a designated operator for each \nindividual monitor, and even for trained operators, the effectiveness would be limited by their \nability to maintain the required level of alertness, especially when a majority of the content is \nbenign/unactionable. Such limitations call for an automated assistive system that can not only \nprocess the data at the low sensory level (e.g., object detection), but also derive the global semantic \ncontext from the sensory output. Many analytics tools exist that can detect, classify, query, \ndescribe, summarize or even supply answers to asked questions (e.g., visual Q&A), but their \ncontexts are limited to the low sensory levels (e.g., whether the image contains a car), rather than \nthe actual meaning of the scene. Even those with soft or hard attention mechanisms are limited to \nthe prominent foreground objects and fall short in connecting to unattended entities, thus not \ndelivering the actual context of the scene [1][3]. \nIn this paper, we propose Linking Soft Biometrics to Semantic Description of an Event, \nLinkBioMan a multimodal near-real-time decision framework capable of producing actionable \ncontext. It ingests uncontrolled collections of video1 (with or without audio) from a variety of \nmobile or fixed sensors and generates a preliminary interpretation of events (What is happening?) \nand automated alerting (Is something happening that demands an immediate response?). The \nsystem is currently trained in the domain of peoples behaviors and activities in public gathering \nplaces (e.g., riots, demonstrations, sporting events, concerts, parades) and public transportation \nareas (e.g., seaports, airports, train stations), and can be expanded to interpret concepts in other \ndomains. It is an assistive, automated framework that continually incorporates human feedback to \nimprove its accuracy. Video \nBuffer Captioner Alert Contexts Video Scene \nDetection Video Scene \nSegmentation Video Entity \nDetection Video Entity \nClassification Soft \nBiometrics ContextNet Video Entity \nTracking Caption Two Streams \nSpatial TVNet \nOptical \nFlow Two Streams\nCombined Two Streams \nMotion Audio \nBuffer Audio \nFeature Extraction\nAudio Entity Classification Input OutputDecision Framework Figure 1: LinkBioMan Decision Framework \nThe diagram shows a hierarchical module structure of LinkBioMan decision framework. The gray modules \nrepresent data streams as input to subsequent modules. The modules that are different hues of green and blue \n(e.g., TVNet Optical Flow, Two Streams Spatial, Audio Feature Extraction) are primary modules extracting low-\nlevel features from the source data stream. The apricot modules (e.g., Two Streams Combined) are secondary \nmodules that fuse the low-level features from primary modules for semantic features, which are more easily \ninterpreted by human beings. The orange modules produce output to be displayed on the user interface. See \nTable 2 for further details on modules. The biggest differentiator between LinkBioMan and existing video analytics is that it is \ndesigned to derive the semantic context from a video scene beyond the low sensory level and \nrender a near-real-time alert, hereafter referred to as actionable context. Our goal was to develop a \nsystem that can detect, classify and connect objects, people, activities and environments to provide \na relevant, meaningful and actionable interpretation of multimodal sensor feeds. LinkBioMan \nachieves this goal by using a modular approach, as shown in Figure 1, allowing maximum \nflexibility to accommodate diverse types of sensors, domains and goals. For example, if the \ndomain is port security and the goal is to detect vessels and to alert when they approach a port \nfrom a particular direction, then some of the processing modules would not be necessary, such as \nSoft Biometrics or Two Streams Combined. This modularity makes the LinkBioMans decision \nframework flexible and customizable to allow for tackling a wide variety of use cases. In this \npaper, we quantitatively demonstrate how each module contributes to deriving the overall \nsemantic context present in the input feed.\nThe LinkBioMan Captioner is a video captioner that augments the image captioning tool from ii Show and Tell [4], [5], henceforth called Show and Tell Captioner, allowing fusion with \nadditional sensor feeds and semantic contexts from other domains. We were able to achieve a \nmaximum METEOR [6] score of 0.3183 and a maximum CIDEr [7] score of 0.7061 on the \nYouTube2Text dataset, putting our system in line with or exceeding the performance of other \nvideo captioners. ContextNet is used to successfully demonstrate LinkBioMans capability of \nclassifying contexts, with a mean Average Precision (mAP) score of 0.325 on relevant topics from \nthe TRECVid 2015 evaluation [8], in comparison to the maximum mAP score of 0.273 from the \nTRECVid performer teams in the same categories. The contribution of LinkBioMan is as follows. A modular near-real-time (alert) decision framework that accommodates different \nmodalities of sensory inputs and is trainable for various domain concepts Deriving semantic context and alert (actionable context) from the fusion of audio and \nvideo from uncontrolled data in domains of interest Demonstrating the quantitative impact of each low-level sensory module to the \nclassification of the actionable context Related Work2\nContext can represent a variety of concepts as categorized in [9]. Studies [10][14] have shown \nthat leveraging context can enhance the performance of their image analytics goals. [15][18] \nexplore and apply semantic context
to better their video scene analysis. Some image and video \ncaptioners also attempt to include semantic context [2], [19][21]. In this paper, we extend the \ntraditional semantic context to actionable context, where a preliminary interpretation of events \n(What is happening?) through semantic captioning and alerting (Is something happening that \ndemands an immediate response?) can be automatically generated for a timely response to an \nobserved event from a video scene. To increase the accuracy of such context detection, we believe \nthat it is key to exploit the multiple modalities present in the sensor feed. Leveraging and fusing \nmultiple modalities in signal processing has been previously explored [3], [15], [16], [22][30], \n[62]. However, with the possible exception of [26], which fuses audio and video to detect violent \nscenes in movies, most of the fusion deals with benign, simple and often trivial contexts. Our goal \nis to develop a decision framework capable of processing complex topics and extracting an \nactionable context to aid in public area safety and in post-event investigation for law enforcement \nor national/international security. Datasets3\nPublicly available, well annotated multimedia datasets that include video and audio recordings of \nthe activities of interest are scarce. To get started, we assembled an initial dataset reflecting the \nactivities of highest relevance to LinkBioMan and annotated and labeled the data ourselves as \nexplained in Section 3.1. Recognizing the need to expand our data corpus, we continued to search \nfor external sets of annotated data and were able to acquire two datasets: the Youtube2Text iii 2 http://www.youtube.com\n3 http://webscope.sandbox.yahoo.com Dataset, described in Section 3.2, which was used for evaluating LinkBioMans video captioner \nperformance and compared against existing video captioners, and the TRECVid Evaluation \nDataset, described in Section 3.3, which was used to compare LinkBioMans ContextNet \nperformance with the TRECVid performer teams video context models in selected topics relevant \nto LinkBioMan. LinkBioMan (LBM) Dataset3.1\nFor system development testing and training ContextNet and the LinkBioMan Captioner we \nassembled our own dataset consisting of 4404 short video clips extracted from 2541 source \nvideos; each clip is 2 seconds in duration, totaling 84.7 minutes of video. We used freely available \nvideo recordings from a variety of uncontrolled sources, including mobile sensors and surveillance \ncameras, rather than from orchestrated data collections. This dataset henceforth referred to as the \nLBM Dataset includes a mixture of videos, both with and without audio, downloaded from \nYouTube2 under the Creative Commons licenses in combination with videos from existing video \ndatasets: WWW Crowd Dataset [31], YFCC100M Dataset3 [32], Violent Scenes Dataset [33] and \nViolent-Flows Database [34]. Source videos encompass a wide range of real-world scenes, as well \nas scenes from sporting events and films. These videos were recorded on a variety of devices \nranging from personal cell phones to professional film equipment. \nBecause selected videos did not come with captioning, we annotated the clips and generated \nground truth labels. First, a basic motion-based keyframe extractor [36] was used to identify \nportions of each video where activity was occurring. Next, these portions were segmented into 2-\nsecond clips to create the corpus. Using a simple interface we created in-house, annotators \n(MITRE staff including some of our team members) reviewed each 2-second clip and provided: \n(1) a brief (ideally one sentence) description of the activity that they saw and heard in the clip, (2) \nan indication of which modality carried the most relevant information (audio/visual/both) and (3) a \nbinary alert/no alert determination to indicate whether an unusual activity meriting attention \noccurred in the clip. Each clip was annotated for its own content, not the content of preceding or \nsubsequent clips. The descriptions provided by the annotators adhered to a general style of \nactor/object followed by action, object and then a prepositional phrase containing key contextual \ninformation. Guidance was provided to annotators in the form of the following examples: OBJECT ACTION OBJECT ENVIRONMENT Policemen are pushing the people publicly protesting against NATO\nA man is fighting a man in front of a store at the mall\nA policeman has pinned down a man on the ground in front of a store at the mall\nA man is throwing bottles to the store window on the street\nPeople are standing on top of a car that is turned upside down\nA man started a fire near a car on the street iv The annotations were reviewed, and any typos corrected before labeling occurred. Annotators \nwere not constrained to a set dictionary but did exhibit overall self-consistency across annotations \nand in the case of multi-way annotation, annotators were unanimous in identifying the key activity \ncontent. While the initial batch of the LBM Dataset was annotated five-ways (i.e., five annotators \nwith each clip), more recent portions were annotated one-way due to time constraints. Figure 2 \nshows frames from two different video clips, along with the associated annotations, in the format \nof <caption>|<modality>|<alert>. Figure 2: Sample Frames of LBM Dataset Video Clips\nGround truth labels (i.e., semantic context) were derived exclusively from the annotations. Each \nclips annotations were searched for descriptive terms of the activities sought. For example, the \npresence of words including smash, bash, shatter, break and/or destroy in annotations would \nindicate that destructive behavior is evident in the clip. In the case of five-way annotations of the \nsame clips, synonymous terms that different annotators used to describe the same actions, objects \nand actors were added to the list of keywords associated with an activity label. A general rule was \nthat if one or more annotators identified an activity, then the clip was labeled as positive for that \nactivity, although in every instance there was unanimous agreement on the presence of an activity. \nThe semantic context labels included in this dataset cover a range of topics and may pertain to the \nvisual surroundings (e.g. Airport, Train Station), human actors (e.g. Crowd, Fighting, Running), \nnon-human actors (e.g. Benign Boating, Dangerous Boating), or auditory cues (e.g. Screaming, \nShooting). YouTube2Text Dataset3.2\nWe selected YouTube2Text or Microsoft Video Description Corpus (MSVD) [37] to compare \nLinkBioMans Captioner performance with other captioners that published their performance on \nthe YouTube2Text Dataset. The official YouTube2Text Dataset is comprised of 1970 clips \nwithout audio, with multiple descriptions per video. Annotation of the dataset was crowd-sourced \nvia Amazons Mechanical Turk. The clips contain a wide variety of scenes and actions performed \nby both humans and animals, ranging from cooking to playing to riding a bike. Each clip averages \nabout 41 reference captions, and the average clip length is approximately 9.6 seconds. While the \nofficial YouTube2Text Dataset contains descriptions in multiple languages, we used only the v English descriptions. Although the official YouTube2Text Dataset does not contain audio, it is \ndistributed with uniform resource locators (URLs) to the original video clips that contain \naudio, some of which have been dubbed with music. For additional experiments, we followed \n[3] in downloading and extracting clips from the original video clips via the included URLs. \nFor our experiments, we used both the official YouTube2Text Dataset without audio and the \nYouTube2Text clips with audio. TRECVid Evaluation Dataset3.3\nWe decided to leverage the outcomes from the National Institute of Standards and Technology \n(NIST) TRECVid evaluations [38] to compare the ContextNets performance with other video \ncontext models. We selected the TRECVid 2015 Semantic Indexing (SI) Task evaluation [8]. \nPublicly-available NIST-generated annotations were downloaded from the following datasets: \nIACC.1A, IACC.1B, IACC.1C and IACC.2C [39]. Of the 30 topics for which NIST created \nground truth labels, only seven topics were deemed relevant to the usage scenarios envisioned for \nLinkBioMan. This resulted in a downsized set chosen for experimentation: Boat_Ship, \nCheering, Dancing, Demonstration_Or_Protest, Explosion_Fire, Running and Throwing. Table 1 \nprovides detailed breakdowns of the positive and negative instances for these topics. Table 1: Number of Positive and Negative Instances for the TRECVid Data Topic Number of Positive Clips Number of Negative Clips \nCClipsClipClipsBoat_Ship 950 13,963 Cheering 484 14,192\nDancing 705 14,576\nDemonstration_Or_Protest \nPorotest 643 13,395\nExplosion_Fire 899 16,116\nRunning 637 14,677\nThrowing 272 16,363 Some videos were excluded due to encoding errors that prevented processing. In addition, a large \nportion of the videos did not contain audio, rendering the audio modules unusable. Therefore, \nmultiple models were trained, some containing audio features and some not (see Appendix B for \nfurther details on the training datasets used). Design Overview4\nLinkBioMan consists of five main components: (1) the decision framework which contains the \nmodules functioning as the analytic powerhouse of the system, (2) the scheduler which acts as a \nstreaming platform, orchestrating information passing and cueing for the decision framework, (3) \na user feedback loop which is integrated into the systems user interface, producing data that can \nlater be aggregated and used to improve module performance, (4) a database for module result \nstorage and retrieval and (5) the video handler which transcodes input video streams for vi processing by the modules. With the ContextNet module generating (semantic) context and alert \nevery 3 seconds and LinkBioMan Captioner module running every 5 seconds based upon \nprocessed input from all associated modules for ContextNet and LinkBioMan Captioner, the \nLinkBioMan system can process videos in near-real-time. A sample 10-second clip was \nprocessed at 30 frames per second (fps) using the above parameters in 10.006 seconds, which
is \napproximately 0.9994x real-time. Note that the run time does not include module training time, \nmodule load time or system startup time. Figure 3 shows an overview of the LinkBioMan \nsystem. Refer to Figure 1 for a more detailed view of the decision framework (B in Figure 3). Decision Framework\nAlert Caption Video/Audio \nBuffer Database Scheduler Module Cues\nt(i+1) HISTORY\nModule Results t(0i-1) CURRENT\nModule Results t(i)\nPre-trained Models\n(CNNs, SVMs, etc.) ALL\nModule Results t(0i) Contexts User \nFeedback B C D E Video \nHandler A Figure 3: LinkBioMan Design \n(A) The video handler transcodes the input video stream. (B) The decision framework then ingests the input \nframes and audio buffers, producing results which are saved to (C) the database. (D) The scheduler ensures that \nthe results from the decision framework are generated at the user-specified rates and synchronized across the \nframework by controlling the video stream to each of the modules. (E) At run time, users can provide feedback \non the decision framework output (alert, context and caption) for future module fine-tuning. At system startup, the scheduler dynamically builds the decision framework based on the user-\nspecified system configuration, assigning separate worker processes to each module. Once \ninitialization is complete, the video handler transcodes the input video stream and passes the \ntranscoded frames and audio buffers to the scheduler. The scheduler then brokers and \nsynchronizes the data streams for the modules, each of which typically processes the data at \ndifferent rates. Any data queries or stores to the database are also handled by the scheduler, which \nacts as the mediator among the decision framework, the database and the individual decision \nframework modules.\nThe decision framework itself is highly modular and houses the analytical capabilities of the vii system. Individual modules are categorized as either primary or secondary depending on their \ninput. The input of primary modules is limited to the source data stream, while secondary modules \nmay receive input from the data stream and other modules. This leads to a hierarchical module \nstructure where modules further up-stream tend to extract low-level features from the data and \ndown-stream modules work to fuse these low-level features in meaningful ways, ultimately \nteasing out higher-level semantic concepts that can be used to alert, provide context to, or describe \na scene to an operator. The modules, for the most part, rely on pre-trained deep neural network \nmodels, the details of which are described in Table 2. These modules extract information ranging \nfrom raw features which are interpretable to a machine (i.e. a vector of floats) to more semantic \nfeatures such as entities (i.e. detected objects or attributes of objects in a frame) that are more \neasily interpreted by human beings. \nIn one of the system user interfaces, there is also an option for users to provide feedback on the \nsystem performance. The feedback is automatically recorded in the system database and can be \nextracted later by developers to fine-tune the models. Table 2: LinkBioMan Modules\nThe table includes information on the input, output, and general description of each of the modules in the \nLinkBioMan decision framework, which is graphically displayed in Figure 1. The right-most column of the \ntable, titled Pre-Trained, indicates if the decision framework module is using a pre-trained model. If the \ndecision framework module is not using a pre-trained model, then the model has been either fine-tuned or \ntrained from scratch on an external dataset, as noted in the Description column. Module Description Input Output Pre-Trained\nVideo Entity \nClassification Performs image recognition, assigning class \nprobabilities for the entire image. Using the \nframework from [40] and trained on \nImageNet [41]. Video buffer Image classification \nprobabilities, raw Inception \nfeatures Yes Video Entity \nDetection Identifies multiple objects in an image \nusing the application programing interface \n(API) from [42], assigning a bounding box \nand a class label for each object detected. \nUsing the framework from [43] and trained \non Open Images [44]. Video buffer List of detected objects, \naggregated object \nprobabilities Yes Video Scene \nSegmentation Assigns labels to every pixel in the image, \nresulting in masks for each region of the \nimage. Using the framework from [12] and \ntrained on [11]. Optimized framework for \nspeed. Video buffer Scene areas, normalized by \ntotal image area and \naggregated object/scene \nprobabilities No Video Scene \nDetection Classifies the scene into one of 365 scene \ntypes. Using the framework from [45] and \nthe training set from [46]. Video buffer Scene classification \nprobabilities Yes TVNet Optical Generates optical flow using a new Video buffer Optical flow frames Yes viii Flow alternative flow-computing deep net from \n[47]. Two Streams \nSpatial Spatial branch of a Two-Stream video \nprocessing architecture for human activity \nrecognition as described by [48], [49] and \nimplemented in [50]. The spatial branch \nprocesses visual information in the form of \nRGB video frames. Network pre-trained on \nthe UCF101 dataset provided by [51]. Video buffer Human activity \nclassification scores, raw \nResNet Features Yes Two Streams \nMotion Motion branch of a Two-Stream video \nprocessing architecture, which takes in \nmotion information in the form of stacked \noptical flow frames. Pre-trained network \nprovided by [50]. TVNet \nOptical Flow Human activity \nclassification scores, raw \nResnet features Yes Two Streams \nCombined Module to fuse outputs of the Two-Stream \nbranches using temporal aggregation \nbased on [49]. Two Streams \nSpatial/ \nMotion Human activity \nclassification scores Yes Audio Entity \nClassification Detects 73 audio events spanning human \nactivities, transportation, machinery, and \nweather events. Uses [52], [53]. Audio \nfeatures Audio entity probabilities No Audio Feature \nExtraction Extracts feature embeddings from 1-\nsecond windows of acoustic waveform. \nUses [52], [54]. Audio buffer Audio feature embeddings Yes Video Entity \nTracking Tracks objects through a video scene by \nusing a combination of temporal tracking \nand a color-based appearance model. Uses \nKernelized Correlation Filters (KCF) [55]. Video buffer, \nvideo entity \ndetection List of tracked objects Yes Soft Biometrics Classifies individuals identified by video \nentity detection modules using the \nDeepMAR neural network [56] pretrained \non the pedestrian attributes dataset [57]. \nOutputs soft biometric descriptions of each \ndetected person. Video buffer, \nvideo entity \ndetection Human soft biometric \nclassification scores No Context and Alert: \nContextNet Fusion module that combines inputs from \nmany modules to predict probabilities for \nalert and high-level semantic contexts. \nContextNet is based on a framework for \ntransfer-learning with multi-label problems \n[58]. Multiple \nmodules (see \nFigure 1) Probabilities for semantic \ncontexts and alert No Context: Random \nForest Context \nActivity Classifier Individual models trained to classify \nsemantic contexts using video and audio \nentities. Implemented with [53]. Video entity, \naudio entity Class labels, probabilities \nfor semantic contexts No ix Captioner Fusion module that combines inputs from \nother modules to generate a natural \nlanguage description of a given scene. \nBased on Googles Show and Tell caption \nframework, TensorFlow implementation \n[4], [5], [59]. Multiple \nmodules (see \nFigure 1) Semantic scene \ndescriptions listed by net \nconfidence scores No Audio Feature Extraction and Audio Entity Classification 4.1\nFigure 4 depicts audio processing for Audio Feature Extraction and Audio Entity Classification. \nThe incoming audio stream is decoded from the MPEG-4 (MP4) file, converted to mono, down-\nsampled to 8 kilohertz (kHZ) (if necessary) and added to a circular buffer. All audio processing \nuses a 1-second analysis window, which is typical for non-speech audio event detection [52]. \nWhen audio processing is initiated by the Scheduler, the Audio Buffer sends a 1-second audio \nframe to the Audio Feature Extraction module, that converts the acoustic waveform into feature \nvectors.\nTwo feature sets are calculated from the acoustic waveform: VGGish embeddings and cortical \nfeatures. These two feature sets capture different information from the acoustic waveform, with \nthe former engineered using deep learning and the latter designed after the responses from cortical \nneurons in the brain. We incorporate both feature sets as shown in Figure 4. Figure 4: Audio Processing \n(A) Audio is extracted from the input video, pre-processed, and stored in a 1-second circular buffer. (B) Two \nfeature sets, VGGish and cortical, are extracted from the audio waveform and sent, along with audio entity \nprobabilities, to later stages of processing in the LinkBioMan Decision Framework (Refer to Figure 1). The VGGish embeddings are provided by Google [52], so named because their architecture is \ninspired by comparable features in the visual domain known as VGG. These features are learned x by a Convolutional Neural Network (CNN) trained on a large corpus of audio to capture the \nvariability present in real-world sound events. The result is a 128-feature vector for 1-second of \naudio. The cortical features are spectro-temporal features based on the receptive fields of cortical \nneurons measured in ferret [60]. These features (described in detail in [54]) are calculated by first \ncomputing the cochleagram, a time-frequency representation (similar to a spectrogram) that \nincorporates non-linearities present in the mammalian cochlea and auditory periphery. The \ncochleagram is then filtered using a large bank of two-dimensional Gabor filters spanning different \ntemporal and spectral modulations. The resulting representation is a 7680-dimensional feature \nvector.\nThe VGGish embeddings are sent to the Audio Entity Classification module; VGGish features \nwere selected in lieu of cortical features after comparison of cross-validation performance. This \nmodule is composed of a support vector machine (SVM) that outputs the probability that each of \n73 audio entities is
present in the 1-second audio window. The SVM was trained on a subset of the \nAudioset database [52], [61]; classes span many types of audio events occurring in public spaces, \nsuch as, transportation and vehicles (e.g., aircraft, police siren, car horn), explosions (e.g., \nfireworks, gunshot), weather sounds (e.g., rain, thunder, wind) and human activities (e.g., speech, \nclapping, walking, shouting, laughter). Audio entity probabilities and labels from the Audio Entity \nClassification module, along with both VGGish and cortical features, become inputs to \nContextNet and the LinkBioMan Captioner, which incorporate these features with those from \nother modules to derive higher-level contextual information. ContextNet4.2\nThe ContextNet module is a fully connected network that is used to perform feature fusion on the \noutputs of many primary and secondary modules. The ContextNet produces probabilities for alert \nand semantic contexts. Alert probabilities are generated for experiments performed on the LBM \nDataset only because it is the only dataset with Alert annotations. Figure 5 shows the ContextNet \ndesign. The network architecture includes a dropout layer with the drop probability of 0.2 directly \nafter the feature input layer. Using the dropout layer encourages ContextNet to explore \nredundancies across the input feature space provided by different modules and not to overly rely \non a small subset of the inputs. Following the dropout layer is a fully connected hidden layer with \n1024 units and a Rectified Linear Unit (ReLU) activation function. The fully connected hidden \nlayer is followed by another dropout layer with a 0.1 drop probability. This second dropout layer is \nlastly followed by a fully connected layer for the output logits and a sigmoid activation function \nproducing the final probabilities. We performed tests with additional hidden layers but found that \nthey did not provide better performance on any of the datasets tested. L2 regularization was \napplied to all weights. In both the LBM Dataset and the TRECVid Evaluation Dataset, most labels \nhad a severe imbalance of positive and negative examples. To address this and create an unbiased \nestimator, inverse-frequency weighting was used for each labels loss function. In all experiments, \nContextNet was trained using TensorFlows Adam Optimizer for 2000 training steps, with a batch \nsize of 100 random samples per step. xi Figure 5: ContextNet Design The ContextNet design shows that input modules can be easily swapped out for experimentation. Dropout \nlayers are included only during training. The logits layer is sent through a sigmoid activation function to \ngenerate the output probabilities. LinkBioMan Captioner4.3\nThe LinkBioMan Captioner model modifies the Show and Tell Captioners [5] CNN-Long Short \nTerm Memory (LSTM) layers to incorporate LinkBioMans multimodal features. The motivation \nfor the modification is based on results from [3], [20], which demonstrated that incorporating \nadditional information from multiple modalities (image, motion, audio) as well as semantic \ninferences from other classifiers improved the overall captioner accuracy. The Show and Tell \nCaptioner uses an encoder-decoder framework, where an (Inception v3) CNN is used to extract \nsalient features from an image to encode, followed by a LSTM decoding the extracted features \ninto a natural language representation. In comparison, the LinkBioMan Captioner (first version) \nuses the extracted features from LinkBioMans primary and secondary modules plus their \ninference scores, concatenates them with the image features from the pre-trained CNN of the \nShow and Tell Captioner and run them through the LSTM decoder. Figure 6 shows the \ncomparison between the Show and Tell Captioner and LinkBioMans Captioner (first version). \nNote that the LSTM vector sizes and the combined CNN-LinkBioMan vector sizes are \nproportional to the number of features that can be extracted from the LinkBioMan modules. As the \ncombined CNN-LinkBioMan features are large and sparse, incorporating them directly into the \nLSTM would drastically expand its cell size, risking overfitting. Therefore, only the LinkBioMan \ninference scores that are more compact and summarize the detected entities extracted from each \nLinkBioMan module are included in the combined CNN-LinkBioMan vector. The combined xii CNN-LinkBioMan vector is then fed into the LSTM of an expanded cell size. The LSTM decoder \nis pre-trained on the original MSCOCO caption dataset [63] before being fine-tuned on our \ncustomized LBM Dataset, using the following training parameters: sparse softmax cross entropy \nloss, stochastic gradient descent with a learning rate of 2.0, decay rate of x0.5 per 8.0 epochs and \nan LSTM dropout rate of 0.3. The result is a captioner that processes and translates the multimodal \nfusion of video, audio, two streams (temporal, motion) and soft biometrics in less than 2 seconds. Inception v3\nCNN Image Encoder LSTM Language \nDecoder Embedding Layer Combined LinkBioMan \nFeature Vector Audio \nEncoder Attribute \nEncoder Context \nEncoder Combined CNN-\nLinkBioMan Features Vector size:\n2048 Vector size:\n512 Vector size:\n*1014 Vector size:\n*1526 Cell size:\n*1526 Vector size:\n*Varies for each CNN Inception v3\nCNN Image Encoder LSTM Language \nDecoder Embedding Layer Vector size:\n2048 Vector size:\n512 Cell size:\n512 Show and Tell Captioner LinkBioMan Captioner (First Version) LinkBioMan Multimodal Encoders Figure 6: Show and Tell Captioner vs. LinkBioMan Captioner (First Version) \nThe diagram shows an overview of the original Show and Tell Captioner model compared with the \nLinkBioMan Captioner (first version) model based off the Show and Tell Captioner [5]. The LinkBioMan \nCaptioner (first version) uses LinkBioMans multimodal features and inference scores, that are concatenated \nwith the pre-trained Show and Tell Captioners (Inception v3) CNN features before being fed into the LSTM. \n*The LSTM cell size increases to support the combined CNN-LinkBioMan features (exact dimensions depend \non LinkBioMan feature vector size: for an LinkBioMan vector size of 1014, the LSTM cell size expands from \n512 to 1526). Preliminary experiments showed that the LinkBioMan Captioner (first version) model with \nconcatenation did outperform the original Show and Tell Captioner in BLEU [64], ROUGE-L \n[65] and METEOR [6] metrics (see Section 5.5 for details), but also suggested it may run the risk \nof overfitting. This is partly due to our LBM Dataset being limited in size and the LSTM cell size \nbeing expanded to incorporate the LinkBioMan features, resulting in a more complex LSTM \ntrained with a more limited dataset than in the Show and Tell Captioners training scenario. To \nresolve this issue, modifications to the LinkBioMan Captioner (first version) were made. First, the \nfeatures extracted from each LinkBioMan module are concatenated and then fed through an \nembedding layer. This embedding layer, consisting of a fully connected layer with a reduced cell \nsize, is trained to compress and reduce the sparsity of the LinkBioMan features. Afterwards the \nembedded features are then combined with the Show and Tell Captioners CNN features via \nelement-wise summation before being fed into the LSTM, allowing the system to learn joint xiii relationships between the LinkBioMan features and the Show and Tell Captioners CNN features. \nThis change allows us to preserve the original dimensions of the LSTM, further reducing the risk \nof overfitting during the fine-tuning of the LSTM. Figure 7 shows the second version of \nLinkBioMan Captioner. The LSTM cell size and the size of the input vector to the LSTM remain \nthe same as those in the Show and Tell Captioner. Inception v3\nCNN Image Encoder LSTM Language \nDecoder Embedding Layer Inception v3\nCNN Image Encoder LSTM Language \nDecoder Embedding Layer Embedding Layer CNN \nAudio Encoder CNN \nAttribute \nEncoder CNN \nContext \nEncoder LinkBioMan Multimodal Encoders Vector size:\n2048 Vector size:\n512 Cell size:\n512 Vector size:\n2048 Combined LinkBioMan Feature Vector Vector size:\n512 Vector size:\n1014 Vector size:\n512 Cell size:\n512 Vector size:\n512 Element-wise Sum Show and Tell Captioner LinkBioMan Captioner (Second Version) Figure 7: Show and Tell Captioner vs. LinkBioMan Captioner (Second Version) \nThe diagram shows an overview of the original Show and Tell Captioner model compared with the \nLinkBioMan Captioner (second version) model based off the Show and Tell Captioner [5]. The LinkBioMan \nCaptioner (second version) first compresses LinkBioMan features in an embedding layer before combining with \nthe Show Tell Captioners CNN features via summation. The resulting feature vector size and LSTM cell size \nremain the same as those in the Show and Tell Captioner [5]. Experiments and Analysis5\nTo assess the efficacy of the LinkBioMan system, we conducted several experiments, which are \ndetailed in the following subsections. Section 5.1 compares two approaches to classifying \n(semantic) contexts using the LBM Dataset: ContextNet and Random Forests. Section 5.2 \ndescribes the performance of LinkBioMans Alert with ContextNet. Section 5.3 compares the \nperformance of ContextNet and Random Forests on the TRECVid Evaluation Dataset with the \nreported results of the TRECVid performer teams. Section 5.4 conducts ablative tests with the \nContextNet module to measure the contributions of each of its input modules. Sections 5.5 and 5.6 \nmeasure the performance of the LinkBioMan Captioner using the LBM Dataset and the \nYouTube2Text Dataset, respectively. Context Classifier: ContextNet Versus Random Forests5.1\nUsing the LBM Dataset, we compared the performance of ContextNet against more traditional xiv random forests (ensemble of decision tree classifiers) for classifying contexts. For Random \nForests, we trained separate forests for each context and alert using scikit-learns Random Forest \nClassifier but found that its weight-based balancing system was unable to handle the high \npositive/negative imbalance for some of our contexts. For this reason, it was necessary to train \neach forest on a randomly sampled, balanced subset of the data. In this experiment, each
forest \nwas made up of 10 sub-forests, each with 10 trees, giving 100 trees total. Each sub-forest was \ntrained on a different balanced subset of the training data, to increase the total amount of data that \nthe forest is exposed to, while still keeping the outputs unbiased. Figure 8 shows the results. ALERTairportbenign boatingboatingboisterous crowdclimbing/jumpingcrowddancingdangerous boatingdemonstration/protestdestructiveemergency responsefightinginjurymarchingparadingpolice standoffrunningscreamingshootingtraffic-vehiculartrain stationmAP\n0 0.2 0.4 0.6 0.8 1 Av\ner ag\ne Pr\nec isi\non (A\nP) 0 0.5 1 1.5 2 m\nea n \nAv er\nag e \nPr ec\nisi on\n (m AP\n)Comparison of ContextNet and Random Forest Classifiers ContextNet Random Forest Classifiers Placeholder Figure 8: Average Precision and Mean Average Precision: ContextNet Versus Random \nForests The graph shows Average Precision (AP) scores for both ContextNet and Random Forests in the indivual \ncontexts of the LBM Dataset, along with Alert. The mean Average Precision (mAP) is also displayed on the far \nright. We found that there was a wide range of difficulty for the various contexts, with boating being \none of the easiest to detect, and destructive being one of the hardest to detect. The hardest \ncontexts to detect were typically ones with a very limited number of positive examples in the \ntraining set, and we believe performance in these categories would be significantly improved by \nobtaining additional training examples. Of the 22 labels (including Alert), ContextNet achieved a \nhigher AP score in 13 labels with a 3% higher overall mAP score than Random Forests. \nContextNet and Random Forests were approximately tied in 5 labels and Random Forests \nperformed better in only 4 labels. In these 4 labels, Random Forests had significantly higher AP \nscores than ContextNet, the most notable of which was a rare context benign boating. One \npossible explanation for this result is the simpler way that decision trees handle features. Decision xv trees always split along a feature dimension, thus, if there are a few simple but effective scene \nfeatures that can instantly distinguish a context (rather than a more complex interaction among \nfeatures), then the forests may do a better job than ContextNet in selecting these features and \nignoring noise from irrelevant features. This is especially likely for contexts with few positive \nexamples. For example, the Video Entity Detection module can detect boats, cars, buses and other \nvehicles, which could be instantly useful to identify benign boating or traffic-vehicular. \nAdditionally, there are audio entities for screaming that would be directly useful to identifying the \nscreaming context. These features are available for ContextNet to use too; however, with few \npositive training examples, it is harder to train ContextNet because it is a more complex model \nthan Random Forests. The results also suggest that ContextNet is better at detecting more complex \nand nuanced contexts, such as injury, destructive and most importantly Alert. These are \nmore abstract concepts that require more complex fusion from multiple domains to detect. \nContextNet is capable of combining features in this way, while Random Forests is limited to \nsplitting along one feature at a time. Alert: ContextNet on the LBM Dataset5.2\nIn this section, we give special attention to the performance of the Alert of ContextNet. \nMechanically speaking, the Alert label is handled identically to any other context, but for the \nLinkBioMan system as a whole, it has a special importance because of the systems overall aim \nat generating near-real-time alerts for complex real-world situations. Alert is also unique because it \nis extremely open-ended in its definition. The other context labels generated by ContextNet \nrepresent fairly concrete concepts such as airport, crowd, screaming or fighting. Such \nlabels can have a broad range of characteristics, but they are all still much more specific than \nAlert which could represent many different scenarios, such as, riots, injuries, fires, car accidents, \nrobberies, floods, and more. For this reason, ContextNets understanding of alert-ability is highly \ndependent on the data on which it is trained and on the annotations provided by human annotators. When trained with all possible input modules, ContextNet achieved 81.5% accuracy at detecting \nalert-able situations. However, because the LBM Dataset has a highly unbalanced number of \npositive and negative examples for most labels, accuracy is not a good metric for measuring \nperformance. Instead, the preferred metric is AP, for which ContextNet achieved a score of 0.567. \nFor perspective, the expected AP of a fully random system on a large data pool can be \napproximated as the ratio of true positive examples to total documents [66]. In this case, the testing \nsegment of our LBM Dataset had 214 clips annotated as alert-able out of the 1094 clips total, \ngiving an expected AP of only 0.196. Thus, the performance of ContextNet in detecting alert-able \nsituations far exceeds random chance. We can also examine the true positive rate (TPR) and false \npositive rate (FPR) for Alerts when using a fixed threshold to convert alert probability scores into a \nbinary decision. In this case we will use the simple threshold of 0.5. At this threshold, ContextNet \nhas a 0.678 TPR and a 0.151 FPR. While these results are far from ideal, they are promising given \nthe domain complexity, the open-endedness of what the system is expected to detect, and the \nmany challenging factors included in the LBM Dataset, such as, poor image quality, wide \nvariability in viewing angles, moving cameras, and missing sound. xvi Context Classifier: ContextNet, Random Forests on the TRECVid 5.3\nEvaluation Dataset NIST made available the numerical scores for the TRECVid 2015 SI Task, which we used to \ncompare with our context classifier performance of both ContextNet and Random Forests. These \ntests are performed on seven topics described in Section 3.3. Note that for TRECVid 2015, NIST \nused inferred Average Precision (infAP) [67] to estimate precision from their rank-ordered search \nand retrieval results based on random sampling theory. This infAP metric gives results that closely \napproximate standard AP, and thus, it should provide a fair comparison with our results, which are \nmeasured in AP. Table 3 presents the infAP scores and mAP score for the best performing \nTRECVid team, alongside the AP and mAP scores for ContextNet and Random Forests. Figure 9 \npresents the scores of all TRECVid teams as well as those of ContextNet and Random Forests on \nthe seven topics. Both approaches (ContextNet and Random Forests) outperform many of the \nTRECVid performing teams scores. Table 3: Comparison of ContextNet (CN), Random Forests (RF) \nand Best TRECVid Team on the TRECVid Evaluation Dataset The table compares the AP of ContextNet and Random Forests when applied to seven of the NIST-annotated \ntopics on the TRECVid 2015 dataset. The mAP scores across all 7 topics are displayed in the bottom row of the \ntable. The three colored columns indicate three different testing configurations, which are elaborated in more \ndetail in the paragraphs below the table. The scores of Best TRECVid Team are reported as Inferred Average \nPrecision (infAP), which approximates AP. Average Precision (AP) All Data\nAll Data (No Audio Used) \nClips with Audio TRECVid Topic Best \nTRECVid Team CN CN RF CN RF Boat Ship 0.569 0.626 0.608 0.529 0.684 0.604 Cheering 0.229 0.205 0.235 0.097 0.245 0.409 Dancing 0.072 0.175 0.168 0.166 0.234 0.170 Demonstration or Protest 0.397 0.513 0.435 0.423 0.618 0.237 Explosion Fire 0.135 0.308 0.315 0.272 0.379 0.261 Running 0.280 0.241 0.185 0.299 0.259 0.400 Throwing 0.226 0.204 0.235 0.096 0.235 0.100 mAP 0.273 0.325 0.312 0.269 0.379 0.312 We performed experiments in three distinct configurations, which are highlighted in different xvii colors in Table 3. In the first configuration, All Data, we used all the clips minus the few that \ncould not be processed due to technical issues (see Section 3.3 for details). For this configuration, \nwe compared only ContextNets results to the best TRECVid performing teams results because, \nunlike the experiments comparing ContextNet and Random Forests using the LBM Dataset, \nwe did not attempt to accommodate data of varying feature vector length for the random \nforest implementation (i.e., training and testing ContextNet and Random Forests with the \nsame clips of missing audio and with audio). In three of the seven topics tested, we achieved \nhigher individual topic AP scores than any other TRECVid performing teams (see Figure 9), and \nwe achieved a 0.325 mAP score, far surpassing the best TRECVid performing teams score of \n0.273. These results are very promising, but they lead to two questions which we addressed with \nthe other two configurations: First, considering that audio is missing in many clips, will \nContextNet perform better if the audio features are just completely removed? Second, if we restrict \nthe dataset down to only the clips with audio, will that make the problem easier and will \nContextNet and Random Forests have better performance? Note that because many clips lack audio, we used zero-padding to replace the missing inputs to \nContextNet. This partially missing data could have adverse effects on ContextNet and even lead to \nworse performance than if audio was completely ignored. The second configuration, All Data \n(No Audio Used), was used to answer the first question posed above. In All Data (No Audio \nUsed), we used all the clips, but simply ignored all
audio features. In this configuration we were \nable to compare ContextNet with Random Forests and found that ContextNet achieved higher AP \nscores in six out of seven topics. Our results also showed that removing audio led to a 1.3% \ndecrease in the mAP score for ContextNet, showing that overall, audio is helping even though it is \npartially missing. Note that there were some topics that had actually improved AP scores once the \naudio was removed, such as Cheering, a topic that has clear connections to audio. This suggests \nthat for more audio-centric topics, the partially missing audio is a larger hinderance than help. It \nalso suggests that there are consistent visual indicators for Cheering that ContextNet can learn to \nuse instead of audio features and that these visual indicators give more stable performance than the \npartially missing audio features. In the next configuration Clips with Audio we saw that when \naudio was consistently present, ContextNet performed better in Cheering, supporting the theory \nthat the partially missing audio is to blame. In the final configuration Clips with Audio, we performed training and testing on only the subset \nof video clips containing audio. The goal of Clips with Audio was to answer the second question \nposed above; how well ContextNet and Random Forests could perform when audio was \nconsistently available for all clips. We found that again ContextNet outperformed Random Forests \nin all but two topics: Cheering and Running. It is interesting to note that Random Forests \nachieved a significantly higher AP score on each of these two topics than any other system when \nrunning on this subset of the data. In the previous section we theorized that, because of their \nsimple splitting rules, Random Forests may excel in limited data situations when there is a small \nnumber of very reliable features that can instantly distinguish the context. This theory may explain \nthe result as well if there are certain audio features that instantly distinguish the Cheering and xviii Running topics. Both ContextNet and Random Forests had a significantly higher mAP score \nwhen training and testing in Clips with Audio than in All Data (No Audio Used), achieving \nmAP scores of 0.379 and 0.312, respectively. This shows that the consistent presence of audio \nmakes the prediction of topics much easier. Note that because these experiments were done on a \ndifferent subset of the TRECVid Evaluation Dataset, they may not provide an apples-to-\napples comparison with the other results. For this reason, these results are marked with a \ndifferent shape in Figure 9. We believe the results above show that ContextNet is more able to handle complex topics/contexts \nthan Random Forests or TRECVid 2015 performing teams. Considering the All Data \nconfiguration, ContextNet was able to greatly outperform any TRECVid 2015 performing teams \nmethod for the complex topics, such as, Demonstration_Or_Protest and Explosion_Fire. \nThese topics are more demanding than simple object or activity recognition topics like \nBoat_Ship or Running, as they require a complex fusion of features to detect. Furthermore, \nboth topics saw even further improvement when testing on the Clips with Audio configuration, \nshowing that ContextNet can very effectively fuse audio into its decisions. Figure 9: AP for ContextNet Versus AP for Random Forest Versus infAP for TRECVid \nTeams on the TRECVid Evaluation Dataset The diagram compares individual topic AP performance for ContextNet, Random Forests, and 86 other \nTRECVid 2015 participating teams methods on seven of the NIST-annotated TRECVid 2015 topics. \nNote that the scores reported for the 86 other methods were reported as infAP which approximates AP. \nAlso note that the data points marked with diamonds were trained and tested only on clips including \naudio; therefore, they may not provide an exact apples-to-apples comparison with the other data points. xix Ablation: ContextNet5.4\nWe performed a series of ablative tests with the ContextNet module to measure the contributions \nof each of its input modules. In these ablative tests, we gradually removed or corrupted parts of the \ninputs of ContextNet, starting with individual modules and then moving on to groups of modules. \nThe results are reported as mAP scores across all labels, including Alert. A fixed 75-25 Training-\nTesting split was used in all experiments. Note that some clips in the LBM Dataset are sourced \nfrom the same original video, meaning that the two samples are not independent. We took extra \ncaution to ensure that clips from the same video were not spread between the training and testing \nset. Additionally, some context labels in the LBM Dataset were very rare, having fewer than 50 \npositive examples total. For this reason, we were careful to select a split that had a somewhat \nbalanced distribution of positive instances of all labels in both the training and testing sets.\nIn the first ablative experiment, we tested the performance of ContextNet when it was given inputs \nfrom only a subset of the modules at both training and testing time. We will refer to these as \nConstructive Ablative Tests as the modules are ablated before model construction. For \nconsistency, the architecture and training protocol of ContextNet was kept constant regardless of \nthe number of input features. We tested with individual modules and with groupings of modules, \nsuch as RGB Video Only, Optical Flow Only, Audio Only, Semantic Features Only, and Non-\nSemantic Features Only. The last two categories are a comparison between features with known \nhuman-readable semantic labels (e.g. the logits of a CNN) and raw deeply-learned features, \nrespectively. These deeply learned features are taken from the last fully connected layer directly \nbefore the final output layer of a deep network. These feature vectors are much larger in size \n(typically 2048) and may contain more general-purpose feature information than the semantically-\nloaded output layers. The Semantic Features are: Video Scene Detection, Video Scene \nSegmentation, Video Entity Classification, Video Entity Detection, Soft Biometrics, Two Streams \nSpatial, Two Streams Motion, Two Streams Combined and Audio Entity. The Non-Semantic \nFeatures are: Raw Inception Features, Two Streams (TS) Spatial Raw ResNet Features, TS \nMotion Raw ResNet Features, Audio Feature VGGish and Audio Feature Cortical. Note that the \nRaw Inception Features are extracted as part of the Video Entity Classification module. Figure 10 \nshows the results. xx ALLRGB Video OnlyOptical Flow OnlyAudio onlyRGB Video + Optical FlowRGB Video + AudioOptical Flow + AudioSemantic Features OnlyNon-Semantic Features OnlyVideo Scene DetectionVideo Scene SegmentationVideo Entity ClassificationVideo Entity DetectionSoft BiometricsRaw Inception FeaturesTwo Streams SpatialTwo Streams MotionTwo Streams CombinedTS Spatial Raw ResNet FeaturesTS Motion Raw ResNet FeaturesAudio EntityAudio Feature VggishAudio Feature Cortical Modules Included 0 0.1 0.2 0.3 0.4 0.5 0.6 m\nAP Constructive Ablative Tests mAP Scores Figure 10: Constructive Ablative Tests of ContextNet with the LBM Dataset \nThe graph shows results for our Constructive Ablative Tests with ContextNet on the LBM Dataset. In these \ntests, only a subset of the possible input features to ContextNet were given both at training and testing time. The \nscores reported are mAP scores across all contexts and Alert. The x-axis states which modules or group of \nmodules were included in the test. The color coding of bars represents the following: Orange = All Modules \nIncluded, Blue = Group of Modules Included, Green = Single Module Included. Refer to Table 2 for further \ndetails on the individual modules. The highest mAP score was achieved when all modules were included; however, some module \nsubsets nearly matched this performance. When using RGB Video Only, the system achieved a \nmAP score almost equal to the performance with all modules. This reflects human intuition about \nthe reliance on vision. For example, even just a single still image of a protest would be sufficient \nfor a human to recognize the demonstration/protest context. However, when using RGB Video \nOnly, ContextNet had a much lower AP score in contexts that relied on auditory information (e.g. \nscreaming) or motion information (e.g. running). The Non-Semantic Features also gave nearly \nequal mAP, and a significantly higher score than the Semantic Features, showing that the raw \ndeeply learned features may provide more information for ContextNet to use. This is further \nsupported by the fact that the Raw Inception Features and Two Stream Spatial Raw ResNet \nFeatures both achieved the highest mAP scores in isolation.\nThere are some cases where adding more features led to a degradation of performance. For xxi example, the set of RGB Video + Optical Flow performed worse than RGB Video Only. This \nsuggests that, despite the counter-measures taken, ContextNet is still susceptible to some \noverfitting when increasing the size of the feature input space. More features make distances in \nhigher-dimensional spaces become more similar, increasing the demand for a precise decision \nboundary and making good classifications more difficult. We can see that among the three main \ngroups of information (RGB video, optical flow, and audio), the most useful one by far is the RGB \nvideo. After RGB video, the optical flow channel provides the second most information. Finally, \nusing audio alone yields the lowest scores, however this is to be expected, as many videos in the \ndataset include either no audio or super-imposed audio that is not relevant to the original scene.\nThe second ablative tests were Corruptive
Ablative Tests, where the model is given all module \ninputs at training time, but at testing time some of the module inputs are corrupted. The corruption \nmechanism that we chose was the scrambling of the input features of each module separately. This \nmethod was chosen because simply zeroing the feature values would mean different things for \ndifferent modules. For Video Entity Detection, zeroing all features would simply mean that no \nobjects are detected; however, for something more abstract like the Raw Inception Features, the \nimpact of zeroing is not so clear. Additionally, corruption by scrambling preserves the distribution \nof values for each modules feature vector. Once again, we performed corruptions of individual \nmodules and groups of modules. Figure 11 shows the results. NONEAll RGB VideoAll Optical FlowAll AudioAll RGB Video + OpticalAll RGB Video + AudioAll Optical Flow + AudioAll Semantic FeaturesAll Non-Semantic FeaturesVideo Scene DetectionVideo Scene SegmentationVideo Entity ClassificationVideo Entity DetectionSoft BiometricsRaw Inception FeaturesTwo Streams SpatialTwo Streams MotionTwo Streams CombinedTS Spatial Raw ResNet FeaturesTS Motion Raw ResNet FeaturesAudio EntityAudio Feature VggishAudio Feature Cortical Modules Corrupted 0 0.1 0.2 0.3 0.4 0.5 0.6 m\nAP Corruption Ablative Tests mAP Scores xxii Figure 11: Corruptive Ablative Tests of ContextNet with the LBM Dataset \nThe graph shows results for our Corruption Ablative Tests with ContextNet on the LBM Dataset. In these tests, \nall possible input features to ContextNet were given at training time, but at testing time, a subset of module \nfeature vectors was corrupted through random scrambling. The scores reported are the mAP scores across all \ncontexts, including Alert. The x-axis states which modules or group of modules were corrupted in the test. The \ncolor coding of bars represents the following: Orange = No Modules Corrupted, Blue = Group of Modules \nCorrupted, Green = Single Module Corrupted. See Table 2 for further details on individual modules. The significance of high and low mAP scores is swapped between the Constructive Ablative Tests \nand the Corruptive Ablative Tests. In the Constructive Ablative Tests, if a module or a group of \nmodules was very useful, then we saw high mAP scores for it. In the Corruptive Ablative Tests, if \na module or a group of modules is important, we expect to see a large drop in the mAP scores \nwhen those modules are corrupted. Thus, the importance of a module or a group of modules can \nbe measured by how far the mAP score drops when that module or group of modules is corrupted. \nHowever, an exact inverse correlation is not expected due to the redundancy among the modules. \nSome modules that had high mAP scores in the Constructive Ablative Tests may not necessarily \nlead to a significant mAP-score-drop in the Corruptive Ablative Tests, as ContextNet is focusing \non other modules that cover the same area.\nFrom the results, we can see that for many individual modules, corruption leads to little or no \nchange in the mAP scores. This could mean that either (1) ContextNet is not attending to these \nfeatures at all because it is focusing on other modules that cover the same area, or (2) the \nredundancy of features is providing a degree of robustness, and thus, corruption of one redundant \nmodule can be tolerated. For example, Two Streams Spatial and Two Streams Motion are \nredundantly covered by Two Streams Combined and somewhat redundantly covered by the raw \nTwo Streams ResNet features. Meanwhile, the Soft Biometrics module led to a significant drop in \nperformance when corrupted, even though Soft Biometrics was one of the weakest modules in \nisolation in the Constructive Ablative Tests. This may be because the Soft Biometrics modules \nfeatures provide unique semantic information not covered by any other module, and thus, when \nthat unique information is corrupted, it causes a significant drop in performance.\nFurthermore, we can see that unsurprisingly corrupting All RGB Video, led to a much larger drop \nin performance than corrupting Soft Biometrics. Our previous ablative experiment showed that in \nisolation, RGB Video Only can perform almost as well as the full set. Therefore, it is not \nsurprising that of the All RGB Video, All Optical Flow and All Audio, corrupting All RGB Video \nled to the biggest drop in the mAP scores. However, this raises the question: Is ContextNet \nactually using the optical flow and audio features in a meaningful way? If so, then corrupting them \nshould lead to a deterioration in performance. In this test we can see that corrupting All Optical \nFlow or All Audio does lead to a drop in performance. This is true both when corrupting them \nindividually or along with All RGB Video. This shows that even when all modules are provided, \nboth optical flow and audio are still used by ContextNet for useful supplemental information. \nFinally, it is interesting to see that corrupting All Semantic Features produces a similar drop in \nperformance as corrupting All Non-Semantic Features. The previous experiment suggested that xxiii the non-semantic features carried more information than the semantic features; however, in this \ntest, corrupting each set has a similar impact. Captioner: On the LBM Dataset5.5\nFor valid comparisons of LinkBioMan Captioner performance, we ran an identical round of \ntraining and testing on the following captioner models: The Show and Tell Captioner, the \nLinkBioMan Captioner (first version), henceforth referred to as concat LinkBioMan and the \nLinkBioMan Captioner (second version), henceforth referred to as embed & add LinkBioMan. \nAll captioners were first pre-trained on the MSCOCO dataset [63], before being fine-tuned on the \nLBM Dataset. In the cases where we were evaluating LinkBioMan Captioner performance on the \nYouTube2Text Dataset (Section 5.6), we follow a similar training scheme; pre-training on the \nMSCOCO dataset before fine-tuning on the YouTube2Text Dataset.\nNote that the size of the LBM Dataset is very small relative to the MSCOCO dataset; therefore, we \ntook several precautions to combat overfitting. We performed fine-tuning for a variable number of \nsteps, from only 50k all the way to a full 1 million. Additionally, the decaying learning rate \ninitialized during MSCOCO training was preserved and lowered further during training on the \nLinkBioMan dataset. Table 4 shows the captioner test results; the Model column describes the \ncaptioner model used and the number in parentheses is the number of training steps fine-tuned on \nthe LBM Dataset.\nAs previously mentioned, our primary goal for the LinkBioMan Captioner is to develop a system \ncapable of recognizing scene semantic context and producing scene descriptions based on multiple \nmodalities. This requires training a captioner that can not only recognize the individual details \nbehind each modality, but also fuse the information from each modality into a contextual \nunderstanding that aligns with human judgment contained in the ground truth annotations. To \nassess this alignment, we evaluated the trained captioners on the testing partition of the LBM \nDataset, using the BLEU [64], ROUGE-L [65], and METEOR [6] metrics. BLEU uses n-gram \nmatching that rewards captioner results if more n-grams in the result (words, phrases) match with \nthose in the ground truth. This favors shorter sentences that are precise, capturing only patterns \nexisting in the annotations. ROUGE-L uses longest-common-subsequence matching that rewards \ncaptioner results if a larger fraction of the ground truth is encountered. This favors descriptive \nsentences that recall more complete fragments of the ground truth. BLEU and METEOR run the \nrisk of respectively favoring overly short or overly long caption statements, which is why pairing \nthem together gives a more balanced assessment of the overall alignment with the ground truth \ncaptions. Finally, the METEOR metric, advertised as being more correlated with human \njudgment, uses a harmonic-mean combination of unigram-precision and unigram-recall \naugmented by word stem and synonym matching between reference and candidate words. Thus, \nphrases that are generated by the captioner and match the reference in meaning and context (but \nnot necessarily verbatim) are better rewarded under METEOR. The combination of all three \nmetrics allows us to perform a balanced assessment of the captioner in terms of precision, recall, \nand context regarding human-level semantic scene understanding. xxiv Table 4: Captioner Performance on the LBM Dataset Model BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEO\nR ROUGE-L Show and Tell (0k) 0.1397 0.0493 0.0200 0.0091 0.0557 0.1418\nShow and Tell (50k) 0.2072 0.1281 0.0934 0.0727 0.0924 0.2221\nShow and Tell (500k) 0.2198 0.1342 0.0950 0.0722 0.0984 0.2244\nShow and Tell (1M) 0.2227 0.1366 0.0974 0.0745 0.0993 0.2263\nconcat LinkBioMan \n(50k) 0.2244 0.1404 0.1006 0.0767 0.1000 0.2304\nconcat LinkBioMan \n(500k) 0.2355 0.1484 0.1081 0.0848 0.1051 0.2411\nconcat LinkBioMan \n(1M) 0.2364 0.1488 0.1082 0.0848 0.1058 0.2424\nembed & add \nLinkBioMan (50k) 0.2365 0.1520 0.1128 0.0892 0.1095 0.2558\nembed & add \nLinkBioMan (500k) 0.2570 0.1700 0.1282 0.1019 0.1206 0.2708\nembed & add \nLinkBioMan (1M) 0.2574 0.1692 0.1270 0.1011 0.1197 0.2706 The results in Table 4 show LinkBioMan Captioner models outperform the Show and Tell \nCaptioner in all metrics. This is likely because the LinkBioMan features contain information about \naudio and temporal stream that would be unavailable to the Show and Tell Captioner. Of the two \nLinkBioMan Captioner models, embed & add LinkBioMan gave a better performance than concat \nLinkBioMan. One possible explanation for this is that the act of concatenating the LinkBioMan \nfeatures expands the cell size of the
LSTM, which can lead to overfitting. Additionally, \nembedding the LinkBioMan features on top of the Show and Tell Captioners CNN feature \nembedding space learned on the MSCOCO dataset may allow the model to better learn \nrelationships between them.\nIt should be noted that the scores achieved in Table 4 are lower than the values typically seen on \nother datasets such as the MSCOCO dataset. This is likely because of the small size of the LBM \nDataset, which has only 4404 video clips and 1 reference caption per clip. Because most metrics \nare designed to compare a candidate caption against a group of references, they will tend to give \nlower scores when only one ground truth reference is provided. We also observed that all \ncaptioners that were fine-tuned on the LBM Dataset had a strong tendency to produce captions \nidentical to ones in the training set. Depending on the model and the number of fine-tuning steps, \n92-99% of captions generated came from the training dataset. This phenomenon of captioning by \nexemplar was also observed in the original Show and Tell paper [5] where roughly 80% of their \ntop captions generated came directly from the training dataset. The authors of that paper attributed \nit to the relatively small size of their training datasets. Given that the LBM Dataset is even smaller, xxv this increased tendency to use training captions as exemplars is to be expected. Captioner: On the YouTube2Text Dataset5.6\nWe trained and tested the Show and Tell Captioner, concat LinkBioMan and embed & add \nLinkBioMan on the two configurations of YouTube2Text Dataset: the official \nYouTube2Text Dataset and YouTube2Text clips with audio. The official YouTube2Text \nDataset contains 1970 video clips without audio. We split the dataset into 1300 training clips, with \nthe remaining 670 clips used for testing. Due to the relatively small size of the official \nYouTube2Text Dataset, we again pre-trained our models on the MSCOCO dataset and then fine-\ntuned the model on the YouTube2Text Dataset. Similar to the captioner training on the LBM \nDataset, we maintained the same decaying learning rate between the pre-training and fine-tuning \nsessions. Additionally, we experimented with 500k and then with 1 million fine-tuning training \niterations on the YouTube2Text Dataset. We uniformly sampled clips at a rate of 1 frame per 2 \nseconds for both training and testing. As each clip in the YouTube2Text Dataset contains multiple \nreference captions, we chose to assign all captions to all clips for training. In total, our training \ndataset consisted of 343,980 frame-caption pairs. Although the official YouTube2Text Dataset does not contain audio, it is distributed with \nURLs to the original video clips that contain audio. Therefore, we followed [3] in \ndownloading the YouTube2Text clips with audio to perform additional experiments. Because \nsome clips were no longer available, we were able to download 1,620 of the 1,970, which \namounts to approximately 82% of the official YouTube2Text Dataset size. Despite the \nreduced dataset size, the proportion of the remaining subsets of the training and testing data \nroughly matched the proportion of training and testing data in the official YouTube2Text \nDataset, and thus, there was no need for redistribution between our training and testing \ndatasets. As noted below, our models trained on the official YouTube2Text Dataset for 500k \niterations performed better on almost all metrics than those trained on 1 million iterations. \nTherefore, we chose to train captioner models on the YouTube2Text clips with audio for 500k \niterations only, following the same training and evaluation procedure as done on the official \nYouTube2Text Dataset. We also trained the Show and Tell Captioner model on the \nYouTube2Text clips with audio; however, note that the Show and Tell Captioner does not \nhandle audio features. For experiments, we normalized the captions by converting all generated words to lower-case \nand removing any quotation marks from the produced captions. As both concat LinkBioMan \nand embed & add LinkBioMan are based upon the Show and Tell Captioner [5], each model \ngenerates one caption per sample, resulting in multiple captions per clip. To determine the \nfinal caption to be used, we summed up the predicted confidence produced by the model for \neach unique caption and chose the caption with the largest accumulated confidence. If \nmultiple captions had the same accumulated confidence, then we would arbitrarily choose \none caption at random (although this never happened in practice during our experiment). This \ncaption voting scheme provides a balance in weight between the caption frequency and the xxvi confidence per caption. Because the model tends to copy reference captions from training, \nmany clips had multiple verbatim duplicate captions. This behavior is not unexpected as \npreviously explained in Section 5.5. To compare the LinkBioMan Captioner performance with other video captioners \nperformance on the YouTube2Text Dataset, we used the BLEU [64], METEOR [6] and \nCIDEr metrics [7]. CIDEr is a text evaluation metric that compares generated captions to an \nestimated consensus, constructed through weighted n-grams from the ground truth captions. \nIt replaces ROGUE due to a more thoroughly defined ground truth consensus (multiple \nground truth captions per video) compared to the LBM Dataset (limited consensus due to 1 \nground truth caption per video). [3] uses an encoder-decoder architecture fusing auditory, \nvisual and motion information via an attention model that inputs feedback from the decoder \nnetwork. [68] uses a recurrent model with multiple encoding rates and learns temporal \nfeatures using a loss that incorporates the reconstruction of sequences both forward and \nbackwards in time. [69] encodes local temporal video structure using a 3D-CNN as encoder \nand uses an attention mechanism to select a subset of frames in order to exploit the global \nstructure. [19] uses a Semantic Compositional Network, which weighs the decoder with tag-\ndependent weight matrices and thus encodes semantic concepts. [70] uses two LSTMS, one \nstacked onto the other, to map a sequence of video frames to a sequence of words that form \npredicted caption. Table 5 displays our performance on the Youtube2Text Dataset with other video captioners \nperformance. The last nine rows (in orange and green) contain results from our experiments. \nIn the Model column, the numbers in parentheses correspond to the number of training \nsteps fine-tuned on the official YouTube2Text Dataset. We found that both concat \nLinkBioMan and embed & add LinkBioMan performed worse on the YouTube2Text clips \nwith audio than on the official YouTube2Text Dataset. This is likely due to audio dubbing \ncontained in some videos that are unrelated to the content, as investigated by [3]. Note that \nthe Show and Tell Captioner did not use the audio features when trained on the \nYouTube2Text clips with audio, and thus did not suffer or rather saw a slight increase in its \nperformance because the YouTube2Text clips with audio is approximately 82% of the \nofficial YouTube2Text Dataset. We note that embed & add LinkBioMan performs better than \nthe concat LinkBioMan for all metrics used in our evaluation. This is similar to our results on \nthe LBM Dataset, perhaps for the same reasons discussed in Section 5.5. Additionally, both \nconcat LinkBioMan and embed & add LinkBioMan performed better than the Show and Tell \nCaptioner for all metrics on the official YouTube2Text Dataset. Furthermore, both the concat \nLinkBioMan and embed & add LinkBioMan performed better for almost all metrics when \ntrained on 500k iterations compared to 1 million iterations, possibly because the networks \nwere beginning to overfit to the training dataset when trained with a larger number of training \niterations. It is interesting to note that embed & add LinkBioMan (500k) achieved higher \nBLEU-4, METEOR, and CIDEr scores than [69] and a higher CIDEr score than [3] without \nthe use of an explicit attention mechanism. Embed & add LinkBioMan (500k) also achieved xxvii a higher METEOR score than [70], suggesting that the embed & add layer might be more \neffective than the additional LSTM layer. xxviii Table 5: Captioner Performance on the YouTube2Text Dataset and YouTube2Text Clips with Audio The last three rows (green) pertain to LinkBioMan Captioner models (concat, embed & add) on the YouTube2Text clips with audio \nand the six rows above (orange) on the official YouTube2Text Dataset, with the best score underlined. All other rows display results of \nvideo captioner models using the official YouTube2Text Dataset, except Attention Fusion (AV). The LinkBioMan Captioner results are \nbetter without audio because the audio dubbing contained in some clips is unrelated to the content, as investigated by [3]. Model BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEO\nR CIDEr Attention Fusion (V) [3] - 0.524 0.320 0.404 Attention Fusion (AV) [3] - 0.539 0.322 0.400 mGRU + pre-train GoogLeNet Features [68] 0.808 0.695 0.600 0.495 0.334 0.755 mGRU + pre-train ResNet-200 Features [68] 0.825 0.722 0.633 0.538 0.345 0.812 Enc-Dec + Local + Global [69] - 0.419 0.296 0.517 SCN-LSTM Ensemble of 5 [19] - 0.511 0.335 0.777 S2VT + RGB (VGG) + Flow (AlexNet) [70] - - 0.298  Show and Tell (500k) [5] 0.775 0.594 0.490 0.388 0.300 0.585 Show and Tell (1M) [5] 0.773 0.589 0.486 0.384 0.297 0.585 concat LinkBioMan (500k) 0.784 0.610 0.504 0.400 0.305 0.638 concat LinkBioMan (1M) 0.780 0.606 0.500 0.397 0.304 0.647 embed
& add LinkBioMan (500k) 0.799 0.634 0.532 0.433 0.318 0.706 embed & add LinkBioMan (1M) 0.795 0.627 0.525 0.425 0.315 0.698 Show and Tell (500K) [5] on clips with audio 0.780 0.601 0.499 0.397 0.298 0.588 concat LinkBioMan on clips with audio (500k) 0.768 0.584 0.479 0.382 0.295 0.598 The last three rows (green) pertain to LinkBioMan Captioner models (concat, embed & add) on the \nYouTube2Text clips with audio and the six rows above (orange) on the official YouTube2Text Dataset, \nwith the best score underlined. All other rows display results of video captioner models using the official \nYouTube2Text Dataset, except Attention Fusion (AV). The LinkBioMan Captioner results are better \nwithout audio because the audio dubbing contained in some clips is unrelated to the content, as \ninvestigated by [3]. xxx embed & add LinkBioMan on clips with audio (500k) 0.792 0.622 0.521 0.421 0.309 0.638 Conclusion6\nLinkBioMan is a multimodal near-real-time decision framework capable of producing \nactionable context, a preliminary interpretation of events and automated alerting. With the \nYouTube2Text Dataset, the LinkBioMan Captioner was able to achieve a maximum METEOR \nscore of 0.318 and a maximum CIDEr score of 0.706, which is in line with the performance of \nother video captioners and our highest score exceeding two of the other video captioners \nconsidered. Additionally, we have demonstrated the effectiveness of the LinkBioMan's context \nmodule, ContextNet, which achieved a mAP score of 0.325 (and 0.379 with TRECVid clips with \naudio), in relevant categories, outperforming the TRECVid 2015 teams' maximum mAP score of \n0.273 in the same categories. Ablative tests on ContextNet demonstrated the critical contribution \nof raw visual features but motion and audio features have also been shown to boost certain \ncategories of semantic concepts depending on the nature of the context. These test results are \npromising but more tests could be done, such as, measuring the speed/accuracy trade-off of the \nvarious module inputs for ContextNet and the user feedback loop to be considered for the \nproduction environment. We hope that LinkBioMan can be relevant to use cases from the \nDepartment of Homeland Security, the Department of Defense, law enforcement agencies and the \nIntel Community. For future study, we would like to include additional modalities (e.g., text, \ngeotags) and incorporate unsupervised learning to overcome limitations in training data. ReferencesAppendix A\n[1] K. Xu et al., Show, attend and tell: Neural image caption generation with visual attention, in International conference on machine learning, 2015, pp. 20482057.\n[2] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, Image captioning with semantic attention, in Proceedings of the IEEE conference on computer vision and pattern \nrecognition, 2016, pp. 46514659. [3] C. Hori et al., Attention-based multimodal fusion for video description, in Computer \nVision (ICCV), 2017 IEEE International Conference on, 2017, pp. 42034212. [4] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, Show and tell: A neural image \ncaption generator, in Proceedings of the IEEE conference on computer vision and \npattern recognition, 2015, pp. 31563164. [5] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, Show and tell: Lessons learned from \nthe 2015 MSCOCO image captioning challenge, IEEE Trans. Pattern Anal. Mach. \nIntell., vol. 39, no. 4, pp. 652663, 2017. [6] A. Lavie and M. J. Denkowski, The Meteor metric for automatic evaluation of \nmachine translation, Mach. Transl., vol. 23, no. 23, pp. 105115, Sep. 2009. [7] R. Vedantam, C. Lawrence Zitnick, and D. Parikh, Cider: Consensus-based image \ndescription evaluation, in Proceedings of the IEEE conference on computer vision \nand pattern recognition, 2015, pp. 45664575. [8] P. Overretired et al., TRECVID 2015-An overview of the goals, tasks, data, \nevaluation mechanisms, and metrics, 2016. [9] S. K. Divvala, D. Hoiem, J. H. Hays, A. A. Efros, and M. Hebert, An empirical study \nof context in object detection, in Computer Vision and Pattern Recognition, 2009. \nCVPR 2009. IEEE Conference on, 2009, pp. 12711278. [10] J. Wang, X. Zhu, S. Gong, and W. Li, Attribute recognition by joint recurrent \nlearning of context and correlation, 2017. [11] B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and A. Torralba, Semantic \nunderstanding of scenes through the ADE20K dataset, arXiv Prepr. \narXiv1608.05442, 2016. [12] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, Deeplab: \nSemantic image segmentation with deep convolutional nets, atrous convolution, and \nfully connected crfs, IEEE Trans. Pattern Anal. Mach. Intell., vol. 40, no. 4, pp. \n834848, 2018. [13] L. Yang, K. D. Tang, J. Yang, and L.-J. Li, Dense saptioning with joint inference and \nvisual context, in CVPR, 2017, pp. 19781987. [14] R. Mottaghi et al., The role of context for object detection and semantic segmentation \nin the wild, in Proceedings of the IEEE Conference on Computer Vision and Pattern \nRecognition, 2014, pp. 891898. [15] M. R. Naphade and T. S. Huang, Detecting semantic concepts using context and \naudiovisual features, in event, 2001, p. 92. [16] G. T. Papadopoulos, V. Mezaris, I. Kompatsiaris, and M. G. Strintzis, Combining \nmultimodal and temporal contextual information for semantic video analysis, in \nImage Processing (ICIP), 2009 16th IEEE International Conference on, 2009, pp. \n43254328. [17] M. Bertini, A. Del Bimbo, and G. Serra, Learning ontology rules for semantic video \nannotation, in Proceedings of the 2nd ACM workshop on Multimedia semantics, \n2008, pp. 18. [18] L. Ballan, M. Bertini, A. Del Bimbo, L. Seidenari, and G. Serra, Event detection and \nrecognition for semantic annotation of video, Multimed. Tools Appl., vol. 51, no. 1, \npp. 279302, 2011. [19] Z. Gan et al., Semantic compositional networks for visual captioning, in \nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition, \n2017, vol. 2. [20] Y. Pan, T. Yao, H. Li, and T. Mei, Video captioning with transferred semantic \nattributes, in CVPR, 2017, vol. 2, p. 3. [21] R. Socher, A. Karpathy, Q. V Le, C. D. Manning, and A. Y. Ng, Grounded \ncompositional semantics for finding and describing images with sentences, Trans. \nAssoc. Comput. Linguist., vol. 2, no. 1, pp. 207218, 2014. [22] J. Mao, W. Xu, Y. Yang, J. Wang, Z. Huang, and A. Yuille, Deep captioning with \nmultimodal recurrent neural networks (m-rnn), arXiv Prepr. arXiv1412.6632, 2014. [23] S. Venugopalan, L. A. Hendricks, M. Rohrbach, R. J. Mooney, T. Darrell, and K. \nSaenko, Captioning images with diverse objects, in CVPR, 2017, vol. 3, p. 8. [24] J. W. Fisher III, T. Darrell, W. T. Freeman, and P. A. Viola, Learning joint statistical \nmodels for audio-visual fusion and segregation, in Advances in neural information \nprocessing systems, 2001, pp. 772778. [25] J. Wagner, F. Lingenfelser, T. Baur, I. Damian, F. Kistler, and E. Andr, The social \nsignal interpretation (SSI) framework: multimodal signal processing and recognition in \nreal-time, in Proceedings of the 21st ACM international conference on Multimedia, \n2013, pp. 831834. [26] T. Perperis et al., Multimodal and ontology-based fusion approaches of audio and \nvisual processing for violence detection in movies, Expert Syst. Appl., vol. 38, no. 11, \npp. 1410214116, 2011. xxxiii [27] P. K. Atrey, M. A. Hossain, A. El Saddik, and M. S. Kankanhalli, Multimodal fusion \nfor multimedia analysis: a survey, Multimed. Syst., vol. 16, no. 6, pp. 345379, 2010. [28] L. Pang and C.-W. Ngo, Mutlimodal learning with deep boltzmann machine for \nemotion prediction in user generated videos, in Proceedings of the 5th ACM on \nInternational Conference on Multimedia Retrieval, 2015, pp. 619622. [29] Y. Gwon, W. Campbell, K. Brady, D. Sturim, M. Cha, and H. T. Kung, Multimodal \nsparse coding for event detection, arXiv Prepr. arXiv1605.05212, 2016. [30] Q. Jin, J. Liang, and X. Lin, Generating Natural Video Descriptions via Multimodal \nProcessing., in Interspeech, 2016, pp. 570574. [31] J. Shao, C. C. Loy, K. Kang, and X. Wang, Crowded scene understanding by deeply \nlearned volumetric slices, in IEEE Transactions on circuits and systems for video \ntechnologiy, VOL. 27, NO. 3, 2017. [32] B. Thomee et al., YFCC100M: The new data in multimedia research, \narXiv:1503.01817. [33] C.-H. Demarty, C. Penet, M. Soleymani, and G. Gravier, VSD, a public dataset for \nthe detection of violent scenes in movies: design, annotation, analysis and evaluation, \nMultimed. Tools Appl., vol. 74, no. 17, pp. 73797404, Sep. 2015. [34] T. Hassner, Y. Itcher, and O. Kliper-Gross, Violent Flows: Real-Time Detection of \nViolent Crowd Behavior. [35] S. Ali and M. Shah, A Lagrangian Particle Dynamics Approach for Crowd Flow \nSimulation and Stability Analysis, Proc. IEEE Comput. Soc. Conf. Comput. Vis. \nPattern Recognit., 2007. [36] B. Castellano, PySceneDetect v0.3.4. 2017.\n[37] D. L. Chen and W. B. Dolan, Collecting highly parallel data for paraphrase evaluation, in Proceedings of the 49th Annual Meeting of the Association for \nComputational Linguistics: Human Language Technologies-Volume 1, 2011, pp. \n190200. [38] A. F. Smeaton, P. Over, and W. Kraaij, Evaluation campaigns and TRECVid, in \nProceedings of the 8th ACM international workshop on Multimedia information \nretrieval, 2006, pp. 321330. [39] NIST, TRECVID data availability by year and task. [Online]. Available: \nhttps://www-nlpir.nist.gov/projects/trecvid/past.data.table.html. [40] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, Rethinking the \ninception architecture for computer vision, in Proceedings of the IEEE conference on \ncomputer vision and pattern recognition, 2016, pp. 28182826. xxxiv [41] O. Russakovsky et al., Imagenet large scale visual
recognition challenge, Int. J. \nComput. Vis., vol. 115, no. 3, pp. 211252, 2015. [42] J. Huang et al., Speed/accuracy trade-offs for modern convolutional object detectors, \nin IEEE CVPR, 2017, vol. 4. [43] S. Ren, K. He, R. Girshick, and J. Sun, Faster R-CNN: Towards real-time object \ndetection with region proposal networks, IEEE Trans. Pattern Anal. Mach. Intell., \nvol. 39, no. 6, pp. 11371149, Jun. 2017. [44] D. P. Papadopoulos, J. R. R. Uijlings, F. Keller, and V. Ferrari, We dont need no \nbounding-boxes: Training object class detectors using only human verification, Feb. \n2016. [45] C. Szegedy et al., Going deeper with convolutions, in Proceedings of the IEEE \nconference on computer vision and pattern recognition, 2015, pp. 19. [46] B. Zhou, A. Khosla, A. Lapedriza, A. Torralba, and A. Oliva, Places: An image \ndatabase for deep scene understanding, arXiv Prepr. arXiv1610.02055, 2016. [47] L. Fan, W. Huang, C. Gan, S. Ermon, B. Gong, and J. Huang, End-to-end learning of \nmotion representation for video understanding, Apr. 2018. [48] K. Simonyan and A. Zisserman, Two-stream convolutional networks for action \nrecognition in videos, in Advances in neural information processing systems, 2014, \npp. 568576. [49] L. Wang et al., Temporal segment networks: Towards good practices for deep action \nrecognition, in European Conference on Computer Vision, 2016, pp. 2036. [50] J. Huang, two-stream-action-recognition. [Online]. Available: \nhttps://github.com/jeffreyhuang1/two-stream-action-recognition. [51] K. Soomro, A. R. Zamir, and M. Shah, UCF101: A Dataset of 101 Human Actions \nClasses From Videos in The Wild, Dec. 2012. [52] S. Hershey et al., CNN architectures for large-scale audio classification, in \nAcoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International \nConference on, 2017, pp. 131135. [53] F. Pedregosa et al., Scikit-learn: Machine learning in Python, J. Mach. Learn. Res., \nvol. 12, no. Oct, pp. 28252830, 2011. [54] N. Mesgarani, M. Slaney, and S. A. Shamma, Discrimination of speech from \nnonspeech based on multiscale spectro-temporal modulations, IEEE Trans. Audio. \nSpeech. Lang. Processing, vol. 14, no. 3, pp. 920930, 2006. [55] J. F. Henriques, R. Caseiro, P. Martins, and J. Batista, High-speed tracking with \nkernelized correlation filters, IEEE Trans. Pattern Anal. Mach. Intell., vol. 37, no. 3, \npp. 583596, 2015. xxxv [56] D. Li, X. Chen, and K. Huang, Multi-attribute learning for pedestrian attribute \nrecognition in surveillance scenarios, in 2015 3rd IAPR Asian Conference on Pattern \nRecognition (ACPR), 2015, pp. 111115. [57] Y. DENG, P. Luo, C. C. Loy, and X. Tang, Pedestrian attribute recognition at far \ndistance, in Proceedings of the ACM International Conference on Multimedia MM \n14, 2014, pp. 789792. [58] R. Bartyzal, Multi-label image classification with Inception net. [Online]. Available: \nhttps://towardsdatascience.com/multi-label-image-classification-with-inception-net-\ncbb2ee538e30. [59] C. Shallue, tensorflow/models/research/im2txt/, 2018. [Online]. Available: \nhttps://github.com/tensorflow/models/tree/master/research/im2txt. [Accessed: 13-Mar-\n2018]. [60] D. A. Depireux, J. Z. Simon, D. J. Klein, and S. A. Shamma, Spectro-temporal \nresponse field characterization with dynamic ripples in ferret primary auditory cortex, \nJ. Neurophysiol., vol. 85, no. 3, pp. 12201234, 2001. [61] J. F. Gemmeke et al., Audio Set: An ontology and human-labeled dataset for audio \nevents. 2017. [62] C. Liu, C. Wang, F. Sun, and Y. Rui, Image2Text: a multimodal image captioner, in \nProceedings of the 2016 ACM on Multimedia Conference, 2016, pp. 746748. [63] T.-Y. Lin et al., Microsoft COCO: Common objects in context, in European \nconference on computer vision, 2014, pp. 740755. [64] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, BLEU: a method for automatic \nevaluation of machine translation, in Proceedings of the 40th annual meeting on \nassociation for computational linguistics, 2002, pp. 311318. [65] C.-Y. Lin, ROUGE: A Package for Automatic Evaluation of Summaries.\n[66] Y. Bestgen, Exact expected average precision of the random baseline for system evaluation, Prague Bull. Math. Linguist., vol. 103, no. 1, 2015.\n[67] E. Yilmaz and J. A. Aslam, Inferred AP: Estimating Average Precision with Incomplete Judgments.\n[68] L. Zhu, Z. Xu, and Y. Yang, Bidirectional multirate reconstruction for temporal modeling in videos, Nov. 2016.\n[69] L. Yao et al., Describing videos by exploiting temporal structure, pp. 45074515, 2015.\n[70] S. Venugopalan, M. Rohrbach, J. Donahue, R. Mooney, T. Darrell, and K. Saenko, Sequence to sequence video to text. pp. 45344542, 2015. xxxvi Dataset DetailsAppendix B\nDetails on TRECVid DatasetB.1 IACC 1A (TV2010): sin.30.qrels.tv10.gz\nIACC 1B (TV2011): features.qrels.tv11.gz, featureL.qrels.tv11.gz\nIACC 1C (TV2012): featuresF.qrels.tv12.gz\nIACC 2C (TV2015): feature.qrels.7z All Data (Minus Unreadable Clips)B.2\nActivity # of Positive Clips # of Negative Clips Boat_Ship 777 12875 Cheering 464 13283 Dancing 674 13791 Demonstration_Or_Protest 617 12484 Explosion Fire 873 15052 Running 597 13689 Throwing 249 15341 Clips with AudioB.3\nActivity # of Positive Clips (with audio)\n# of Negative Clips \n(with audio) Boat_Ship 449 6023 Cheering 236 5244 Dancing 429 5404 Demonstration_Or_Protest 364 4966 Explosion Fire 402 5194 Running 347 5797 Throwing 164 6846 xxxvii Computing ResourcesAppendix C\nLBM currently runs on an AWS EC2 P3.2xlarge instance, which is powered by 1 NVIDIA Tesla \nV100 GPU with 16 GB memory, and 8 CPUs with 61 GB memory. xxxviii Acronyms and Abbreviations Appendix D\nAP Average Precision\nAPI Application Programming Interface\nAWS Amazon Web Services\nBLEU Bilingual Evaluation Understudy \nCIDEr Consensus-based Image Description Evaluation\nCN Context Net\nCNN Convolutional Neural Network\nCPU Central Processing Unit\nEC2 Elastic Compute Cloud\nFPR False Positive Rate\nGB Gigabyte(s)\nGPU Graphics Processing Unit\ninfAP Inferred Average Precision\nKCF Kernelized Correlation Filters\nkHz Kilohertz\nLSTM Long Short-Term Memory\nmAP Mean Average Precision\nMETEOR Metric for Evaluation of Translation with Explicit Ordering\nMP4 MPEG-4\nMPEG Moving Picture Experts Group\nMSCOCO Microsoft Common Objects in Context\nMSVD Microsoft Video Description Corpus\nNIST National Institute of Standards and Technology\nReLU Rectified Linear Unit\nRF Random Forest\nROUGE Recall-Oriented Understudy for Gisting Evaluation\nSI Semantic Indexing\nSVM Support Vector Machine\nTPR True Positive Rate\nTRECVid Text Retrieval Conference, Video Retrieval Evaluation\nURL Uniform Resource Locator\nVGG Visual Geometry Group xxxix _GoBack\n _Toc54497488\n _Toc54498619\n _Toc63138695\n _Toc63140075\n _Toc63140209\n _Toc64785106\n _Toc82931581\n _Toc64785108\n _Toc64785109\n _Toc527228703\n _Ref524298790\n _Toc527228728\n _Hlk524087513\n _Toc527228704\n _Toc527228705\n _Hlk525806175\n _Ref524249803\n _Ref526791386\n _Ref526792895\n _Toc527228706\n _Ref524280580\n _Toc527228729\n _Ref524250115\n _Toc527228707\n _Ref524250173\n _Toc527228708\n _Ref524378213\n _Toc527228739\n _Toc527228709\n _Ref524371084\n _Toc527228730\n _Ref524282220\n _Ref526077575\n _Toc527228740\n _Toc527228710\n _Ref524372509\n _Toc527228731\n _Toc527228711\n _Ref524290922\n _Toc527228732\n _Ref526113393\n _Toc527228712\n _Ref524291160\n _Toc527228733\n _Ref524292365\n _Toc527228734\n _Toc527228713\n _Ref524238192\n _Toc527228714\n _Ref524372658\n _Toc527228735\n _Ref524458157\n _Toc527228715\n _Ref524238214\n _Ref524458265\n _Toc527228716\n _Hlk524648775\n _Ref524354480\n _Toc527228741\n _Hlk524351818\n _Ref524212648\n _Toc527228736\n _Ref524238624\n _Toc527228717\n _Ref527295480\n _Ref524296009\n _Toc527228737\n _Ref524372777\n _Toc527228738\n _Ref524239212\n _Toc527228718\n _Ref524296947\n _Toc527228742\n _Ref524239223\n _Ref526100130\n _Toc527228719\n _Hlk525934634\n _Ref524378429\n _Toc527228743\n _Toc527228720\n _Toc64785115\n _Toc82932113\n _Toc82932667\n _Toc527228721\n _Hlk524694777\n _Ref525839500\n _Toc527228722\n _Toc527228723\n _Ref524958100\n _Toc527228724\n _Toc527228725\n _Toc527228726\n _Toc527228727 ",
    "text": " Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 1 Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 2 Table of Contents\nLAN Insights into APM Adoption \nAlliance to Modernize Healthcare (CAMH) Federally Funded Research and Development Center, which is operated by the MITRE \nCorporation.\n2 Category 3B: Fee-for-service-based shared-risk, Procedure based bundled/episode payments, and Population-based payments \nthat are NOT condition specific. LAN Insights into APM Adoption At its inception in 2015, the Healthcare Payment Learning and Action Network (LAN)1 has adopted the \ngoal of transitioning 30% of U.S. healthcare payments to alternative payment models (APMs) by 2016 \nand 50% by 2018. The LAN believes that moving to value-based payment is necessary to improve the \nquality, efficiency, and overall value of the American healthcare system. In October 2018, the LAN \nreleased the annual results of its APM Measurement Effort, which demonstrates that almost 34% of \nhealthcare payments in 2017 were made through alternative payment models that is, shared-savings, \nshared-risk, bundled payments, or population-based payments. Given the growing interest in alternative \npayment models with downside risk, such as shared risk, bundled payments, and population-based \npayments, the LAN refined its measurement survey to capture greater detail of these models. The \nsurvey data found that 12.5% of all health care spending surveyed was in downside risk models in 2017. \nThe measurement results also found that 90% of responding payers expect APM activity to increase and \nnearly half (48%) of payers identified subcategory 3B2 as the APM subcategory to be most impacted. \nFurthermore, the enhanced survey examines how four different lines of business commercial, \nMedicaid, Medicare Advantage, and Medicare FFS are making progress toward the LAN goals, and \nreports findings at the payment or subcategory level within the four categories of the LANs Refreshed \nAPM Framework. The following insights explore APM progress at the aggregate level and by line of \nbusiness, as well as lessons learned from three years of measurement. Aggregated Results \nThe LANs annual APM Measurement Effort has captured payments made in calendar years (CY) 2015, \n2016, and 2017. To accomplish this, the LAN invited health plans and states from across the nation to \nreport payments made to providers according to the Refreshed LAN APM Framework. At a high level, the \ncategories and payment methods within the categories include, but are not limited to: Category 1: Traditional fee-for-service or other legacy payments not linked to quality\nCategory 2: Foundational payments like care coordination fees or pay-for-performance \nCategory 3: Shared-savings, shared-risk, bundled payments\nCategory 4: Population-based payments and integrated finance and delivery systems Figure 1 below depicts the categories and subcategories described in the Refreshed LAN APM \nFramework http://hcp-lan.org/workproducts/apm-refresh-whitepaper-final.pdf\nhttp://hcp-lan.org/workproducts/apm-refresh-whitepaper-final.pdf Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 4 3 Category 4 payments are not necessarily appropriate for all providers and markets. The LAN does not expect or intend that all \npayments will ever be in Category 4. \n4 The term Managed FFS Medicaid states refers to states that pay providers directly, rather than operate through Medicaid \nManaged Care Organizations. Such states typically invest in payment models geared toward improving care quality and delivery \nfor Medicaid beneficiaries. Figure 1: LAN APM Refreshed Framework3 The LAN collaborated with Americas Health Insurance Plans (AHIP) and Blue Cross Blue Shield \nAssociation (BCBSA) to gather representative data on the types of payments health plans with \ncommercial, Medicaid, and Medicare Advantage business made to healthcare providers in 2017. The LAN \nalso collaborated with the Center for Medicare & Medicaid Services (CMS) to collect this data from \nMedicare FFS. In addition, the Association for Community Affiliated Plans (ACAP),the Alliance of \nCommunity Health Plans (ACHP), and the National Association of Medicaid Directors encouraged their \nmember plans or managed FFS Medicaid states4 to participate in the LAN effort. For more information \nregarding the methods used and processes followed for the 2018 measurement effort, please see the \n2018 APM Methodology Report. https://www.ahip.org/\nhttps://www.bcbs.com/\nhttps://www.bcbs.com/\nhttps://www.cms.gov/\nhttps://www.cms.gov/\nhttps://www.cms.gov/\nhttps://www.communityplans.net/\nhttp://www.achp.org/\nhttp://www.achp.org/ Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 5 5 Berchick, E. R., Hood, E., and Barnett, J.C., Current Population Reports, P60-264, Health Insurance Coverage in the United Interpreting the Aggregated Results In comparing the results of this years survey to the prior two years (Figure 2), adoption of Category 3 \nand 4 APMs increased 5 percentage points (or a 17% increase), bringing total APM spending to \napproximately $385.5 billion nationally. While payment models in Categories 3 and 4 are the LANs \nprimary focus, it is also important to note the changes in Categories 1 and 2. Since the first year of APM \nmeasurement by the LAN, payments made through Category 1 (payments with no link to quality) have \ndecreased by 34%. Category 2 payments also decreased between last years and this years \nmeasurement, from 28% to 25%. While it is not possible from the LANs data collection process to track \nwhere these payments go year-to-year, payments in Categories 3 and 4 collectively have increased at a \nsteady pace from 23% in the first year of measurement to 34% in this years effort. It is unlikely that \npayments in Category 1 with no link to quality moved directly to Categories 3 or 4; rather, Category 1 \npayments likely moved to Category 2, and payments previously made in Category 2 are now being \ncaptured in Categories 3 and 4. Figure 2: LAN APM Measurement Effort Results: \nComparison between 2015, 2016, and 2017 Payments: 62% 15% 23% 43% 28% 29% 41% 25% 34% CATEGORY 1 CATEGORY 2 CATEGORY 3&4 2015 2016 2017 Figure 2 compares data from CY 2015, CY 2016, and CY 2017. In 2015, data was \ncollected from 70 plans and 2 managed FFS Medicaid states, which represented 198.9 million lives or 67% of the U.S. covered population. In 2016, the data was collected \nfrom 78 plans, 3 managed FFS Medicaid states, and Medicare FFS. This represented 245.4 million lives or 84% of the U.S covered population. In 2017, the data was \ncollected from 61 plans, 3 states, and Medicare FFS, representing 226.3 million lives or 77% of the U.S. covered population.5 Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 6 States: 2017, U.S. Government Printing Office, Washington, DC, 2018. 6 3A and 3B percentages represent data from 61 health plans, 3 states, and FFS Medicare. 7 CMS.gov Medicare Shared-savings Program Fast Facts, January 2018,\n https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/sharedsavingsprogram/Downloads/SSP-2018-Fast-\nFacts.pdf 8Muhlestein, D., Saunders R., Richards, R., McClellan, M., Recent Progress In The Value Journey: Growth Of ACOs And Value-\nBased Payment Models In 2018. Health Affairs. August 14, 2018. \nhttps://www.healthaffairs.org/do/10.1377/hblog2 68/full/ Changes in Category 1: \nThe decrease in payments in Category 1 appears to be driven by Medicare FFS and by health plans \nconsistently reporting that they continue to negotiate contracts that compensate providers using some \ntype of quality measurement. Tying some payment to quality is a move away from paying purely on fee-\nfor-service without any link to quality. Additionally, based on the responses to the informational \nquestions, 90% of health plans believe that APM adoption will increase in the next 24 months, signaling a \ncommitment to move away from Category 1. When Medicare FFS dollars are removed from Category 1, \nwe see that Category 1 payments rise to 57%. Changes in Category 2 4: \nDespite over 50% of Medicare FFS payments in Category 2, Category 2 payments decreased modestly \nfrom the last measurement effort to 25%. If we remove Medicare FFSs dollars from Category 2, \npayments in this category drop sharply to 12%, roughly in half. This is not to say that the other market \nsegments are using pay-for-performance less as a contracting strategy; rather, two dynamics are likely in \nplay. First, pay-for-performance is generally the first step for providers before they move to contracts \nthat involve more complex gainsharing, like shared-savings, captured in 3A. Subcategory 3A6 has a \nsignificant proportion of APM activity (19.4%, the majority of which is the shared-savings payment \nmodel), so it is possible that the training wheels of historic pay-for-performance contracts are being \nreplaced with shared-savings contracts. Second, more providers are taking on shared-savings \narrangements as part of the accountable care organization (ACO) movement, and pay-for-performance \ndollars might be added to these contracts. There were 480 ACOs participating in Medicare Shared \nSavings Program (MSSP) in 2017, with 9 million assigned beneficiaries. Of these ACOs, 82%, or 460, were \nin Track 1 (non-risk based).7 Meanwhile, there were approximately 700 commercial ACO contracts in \n2017, and slightly more than 90 ACO contracts in the Medicaid sector.8 Anecdotally, it is known that \nsome shared-savings arrangements have a pay-for-performance bonus layered on top. It is difficult to determine whether Category 3 or Category 4 is driving the overall increase in these \ncategories because previous years results reported aggregated total dollars in Categories 3 and 4 \ncombined; however, this year, we examined Category 3 and Category 4 separately. Based on 2017 data, \naggregated results indicate that subcategory 3A has the most APM dollars of these two categories, at \n21.1%, while 3B has the second-most APM dollars flowing through it at 8.7%. Subcategories 4A, 4B, and \n4C combined had 3.8%. Given the preponderance of Category 3 payments in 2017, it
is reasonable to \nconclude that the growth in Category 3 is driving the increase in the combined Categories 3 and 4. In a similar vein, the aggregated results at the subcategory level indicate that upside risk APMs in https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/sharedsavingsprogram/Downloads/SSP-2018-Fast-Facts.pdf\nhttps://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/sharedsavingsprogram/Downloads/SSP-2018-Fast-Facts.pdf\nhttps://www.healthaffairs.org/do/10.1377/hblog2 68/full/ Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 7 9 United States Department of Health and Human Services, Centers for Medicare and Medicaid Services. (2017). Fast Facts: All \nMedicare Shared-savings Program Accountable Care Organizations. Available at: https://www.cms.gov/Medicare/Medicare-Fee-\nfor-Service-Payment/sharedsavingsprogram/Downloads/All-Starts-MSSP-ACO.pdf \n10 Healthcare Payment Learning & Action Network Measuring Progress: Adoption of Alternative Payment Models in \nCommercial, Medicaid, Medicare Advantage, and Fee-for-Service Medicare Programs. October 25,2016\nhttps://hcp-lan.org/workproducts/apm-measurement-final.pdf 11 United States Department of Health and Human Services, Press Office. HHS reaches goal of tying 30 percent of Medicare \npayments to quality ahead of schedule. March 3, 2016. https://www.hhs.gov/about/news/2016/03/03/hhs-reaches-goal-tying-\n30-percent-medicare-payments-quality-ahead-schedule.html subcategory 3A at 21.1% are the most dominant APM type by almost 9 percentage points a significant \nmargin given that subcategory 3B and all of Category 4 combined equal 12.5%. In 2017, 1% of MSSP ACOs (six total) were in Track 2 (two-sided risk), 8% (36) were in Track 3 (two-sided \nrisk), and 9% (45) were in the ACO Investment Model (AIM), a CMMI Initiative, which is a subset of MSSP \nACOs.9 Over time, the expectation is that payments in 3A will convert to 3B, indicating ACO contracts \nmaturing from shared-savings in the early years to shared-risk in the later years of the contract. This \ntransition might occur earlier as conditions for participating in MSSP change. CMS has issued a proposed \nrule that encourages all ACOs in the program to participate in shared-risk arrangements (categorized as \n3B). As noted previously, Medicare FFS has had a significant impact on the reduction in Category 1 and the \nincrease (or relative stability) of Category 2. The impact Medicare FFS has on combined APM Categories \n3 and 4, however, is less dramatic. The combined Categories 3 and 4 is 34% with Medicare FFS, while \nwithout Medicare FFS, the combined Categories 3 and 4 is 31%. Line of Business Results New to the 2018 Measurement Effort is the examination of APM activity by the four lines of business \n(LOB) commercial, Medicaid, Medicare Advantage (MA), and Medicare FFS using the lookback \nmethodology. While there are methodological and sampling differences that do not allow for a direct \ncomparison, the LAN does have a frame of reference for LOB information the 2016 Point-in-Time data. Line of Business Comparison: 2016 Point-in-Time The LAN previously reported line of business APM adoption in 2016 using a point-in-time methodology \nthat captured data from 40 health plans and two states. These data showed that Medicare Advantage \nhad the most payments in Categories 3 and 4 (41%), followed by commercial (22%), and then Medicaid \n(18%).10 Medicare FFS reported its 2016 point-in-time metrics data at 31%.11 Line of Business Comparison: 2017 Lookback All lines of business fall in the same order in terms of APM adoption in the 2017 lookback data reported \nby the 2018 Measurement Effort as they did in the point-in-time data: Medicare Advantage still has the \nmost in Categories 3 and 4 (49.5%), Medicare FFS has 38.3%, the commercial market has 28.3%, and \nMedicaid is at 25%. Figure 4 compares 2016 point-in-time data to 2017 lookback data. Table 1: 2016 Point-in-Time Data Compared to 2017 Lookback Data https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/sharedsavingsprogram/Downloads/All-Starts-MSSP-ACO.pdf\nhttps://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/sharedsavingsprogram/Downloads/All-Starts-MSSP-ACO.pdf\nhttps://hcp-lan.org/workproducts/apm-measurement-final.pdf\nhttps://www.cms.gov/newsroom/press-releases/cms-proposes-pathways-success-overhaul-medicares-aco-program\nhttps://www.cms.gov/newsroom/press-releases/cms-proposes-pathways-success-overhaul-medicares-aco-program Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 8 12 2016 Point-in-Time data in the Medicare Advantage, commercial, and Medicaid lines of business is based on data from 40 \nhealth plans and 2 states, which is a smaller dataset than the 2017 Lookback dataset (61 health plans, 3 states). (in order of highest APM Categories 3 & 4 to lowest) 2016 Point-in-Time \nCategories 3&4 Combined12 2017 Lookback\n Categories 3&4 Combined Medicare Advantage 41% 49.5%\nMedicare FFS 31% 38.3%\nCommercial 22% 28.3%\nMedicaid 18% 25% Category Comparison by Line of Business Figure 5 shows each line of business and how much spending is each category. Medicaid has the most in \nCategory 1 (67.8%), Medicare FFS has the most in Category 2 (51.2%), and Medicare Advantage has the \nmost in APM Categories 3 and 4 (39.2% and 10.3%). Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 9 13 See Methodology and Results Report for details. Figure 4: Line of Business/Category Comparison 56.5 15.2 26.6 1.7 67.8 7.2 20.8 4.2 48 2.5 39.2 10.310.5 51.2 33.8 4.5 CATEGORY 1 CATEGORY 2 CATEGORY 3 CATEGORY 4 Commercial Medicaid Medicare Advantage Medicare FFS Note: total covered lives 13 and total healthcare spending in each line of business \nvaries. The following section examines each market segments individual data and identifies notable \ncomparisons to other lines of business and comparisons to the aggregate data without Medicare FFS. Commercial Over half of the commercial markets dollars (56.5%) flow through Category 1, fee-for-service payments \nwith no link to quality. This is almost 38% higher than this years aggregate result (41%). The commercial \nmarket, however, has fewer dollars in Category 2 (15.2%), which is 39% lower than the aggregate (25%). \nAs stated previously, Medicare FFS has a significant impact on the aggregate data in Categories 1 and 2. If \nwe examine the commercial market data without Medicare FFS data, the story looks different. Without \nMedicare FFS, the aggregated dollars in Category 1 is 56.7% and 12.1% in Category 2. Both aggregate \nfigures without Medicare FFS are more closely aligned with the commercial market data. In exploring Categories 3 and 4, the commercial market has 26.6% of dollars in Category 3 and 1.7% in \nCategory 4, for a total of 28.3% in combined Categories 3 and 4, which is a noteworthy increase over the \n2016 Point-in-Time commercial data from Table 1 (22%). However, the commercial market is lower in \nboth categories relative to the aggregate (30% in Category 3 and 4% in Category 4), but the differential is \nnot nearly as stark as the difference in Categories 1 and 2. Within Categories 3 and 4, the data show that \nthe commercial market has the greatest proportion of spending in Category 3A APMs with shared- Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 10 14 Muhlestein, D., and McClellan, M., Accountable Care Organizations in 2016: Private and Public Sector Growth And \nDispersion. Health Affairs. April 21, 2016. https://www.healthaffairs.org/do/10.1377/hblog2 64/full/\n15 Muhlestein, D., Saunders R., Richards, R., McClellan, M., Recent Progress In The Value Journey: Growth Of ACOs And Value-\nBased Payment Models In 2018. Health Affairs. August 14, 2018. \nhttps://www.healthaffairs.org/do/10.1377/hblog2 68/full/ savings (18.4%) and has the least amount in Category 4 (1.7%) A possible explanation for spending in 3A \nmight be attributed to a concerted effort by commercial health plans to contract with accountable care \norganizations (ACOs). In 2016, approximately 28.3 million people were covered by an accountable care \narrangement 17.2 million of whom were covered under commercial contracts.14 Given the volume of \ncommercial lives in ACO arrangements, it is reasonable to conclude that there is a corresponding \nsignificant level of payments and financial investment in payment models that support ACOs, such as \nshared-savings. Most contracts between health plans and ACOs start in shared-savings arrangements \n(3A) before moving to shared-risk arrangements (3B) or Category 4 models. The data do not provide \ninsights as to why the commercial market has the least amount of payments in Category 4 as compared \nto the other market segments. To many who watch commercial market trends, it is not unusual for the commercial markets results to \ngenerally be between the Medicare Advantage market and the Medicaid market. Unlike health plans in \nthe Medicare Advantage and Medicaid line of business, health plans in the commercial market are not \nfinanced publicly and uniformly but rather in a fragmented manner with an assorted array for payers \nincluding: self-funded employers, fully-insured employers, and even individual consumers through the \nexchange business. Given that researchers link high APM adoption in Medicare Advantage to its \ncapitated financing model that rewards quality achievement, it is reasonable to conclude that the lack of \ncapitated financing to commercial payers may explain the lower levels of APM adoption in the \ncommercial market. Additionally, the commercial market typically follows Medicare Advantage on certain payment \ninnovations, such as shared-savings, once Medicare Advantage efforts are proven successful. Medicaid To the extent reported, health plans and states serving the Medicaid market have approximately 68% of \npayments in Category 1, which is the most of the four market segments. Current Medicaid payments \nmade through legacy payments is above the aggregate view from the first measurement year, which was \n62%. When examining APM Categories 3 and 4, Medicaid shows the least activity of the four market segments \nat 25%, and is lower than the aggregated results of 32%. Medicaid Categories 3 and 4 results are also \nlower than the aggregate results from last years result (29%). On the surface, however, the Medicaid \ndata does not trail far behind the commercial results in Categories 3 and 4, which is 28.3%. Also notable \nis that Medicaid has more dollars in Category 4 (4.2%) than the commercial market (1.7%). Challenges of designing an APM in Medicaid and assessing results include:
Demonstration projects with shared-savings and other APM models expiring without renewal, a \ntrend that researchers point to as shrinking the number of ACO contracts in Medicaid in 201715 \nLegislative and regulatory issues that state Medicaid agencies may have to navigate to https://www.healthaffairs.org/do/10.1377/hblog2 68/full/ Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 11 16 Matulis. R. and Lloyd, J., The History, Evolution, and Future of Medicaid Accountable Care Organizations. Center for \nHealthcare Strategies, February 2018. https://www.chcs.org/media/ACO-Policy-Paper_022718.pdf\n17 Bynum, J.P.W., Austin, A., Carmichael, D., and Meara. E., High-Cost Dual-Eligibles Service Use Demonstrates Need For \nSupportive And Palliative Models Of Care Health Affairs. July 2017. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5633373/ \n18 Moffit, R., Numerof, R.E., and Buseman, C.M., Let the Market Compete: Learning From Medicare Advantage To Move Toward \nValue-Based Care Health Affairs. January 2018 https://www.healthaffairs.org/do/10.1377/hblog2 98/full/ implement certain APM models\nRapid increase in the number of Medicaid-covered lives in states that have expanded eligibility \npotentially constraining internal resources \nUncertainty at the federal level, given attempts to repeal the Affordable Care Act may have \ndeterred investments in this area \nHigh turnover rate and limited staffing resources within state Medicaid agencies16 may represent \na barrier to adoption and a barrier to measurement Perhaps for this final reason, the 2018 APM Measurement Effort achieved a lower level of \nrepresentativeness in the Medicaid market than the other lines of business, potentially driven by payers \nand Managed FFS states pursuing Categories 3 and 4 models not having the time or resources to respond \nto the Measurement survey. It should also be noted that adults with dual eligibility for Medicaid and \nMedicaid coverage were excluded from reporting for the Medicaid sector. Because these patients often \nrepresent a disproportionate level of spending,17 and to the extent that these beneficiaries are attributed \nto providers in APM contracts, spending on their behalf would not be captured in the Medicaid line of \nbusiness data of this effort. Medicare Advantage The Medicare Advantage market has just under half of its payment flowing through Category 1 (48%). \nLike the commercial and Medicaid markets, this is higher than the aggregate of 41%. If we look at the \nMedicare Advantage results in Category 1 against the aggregate without Medicare FFSs data, Medicare \nAdvantage is less than the aggregate by 15% and also has less in Category 1 than the commercial and \nMedicaid markets. Conversely, Medicare Advantage has the most dollars in APMs Categories 3 and 4 (39.2% and 10.3%, \nrespectively). We can break down these categories further, which may provide further insights. Of the \n39.2% in Category 3, 25.3% is attributed to subcategory 3A, which includes shared-savings, and 13.9% is \nattributed to subcategory 3B, which includes shared-risk. Medicare Advantage has 10.3% in Category 4, \nand 9% of this is in subcategory 4B, comprehensive population-based payments. Researchers attribute the APM innovation in the Medicare Advantage market to its financing structure, \nin which plans are paid a monthly, capitated rate derived using each enrollees age, location, and health \nstatus. If plans reduce costs while maintaining or improving quality, they can keep savings, receive \nbonuses, and increase their enrollment of beneficiaries. Given that plans are financed through a value-\nbased arrangement with the federal government, it is logical that the plans themselves would apply this \nsame approach to how they pay providers.18 https://www.chcs.org/media/ACO-Policy-Paper_022718.pdf\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5633373/\nhttps://www.healthaffairs.org/do/10.1377/hblog2 98/full/ Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 12 19 The Value Modifier Program was in effect in 2017 and will sunset in 2018. The Quality Payment Program will incorporate \naspects of the Value Modifier Program. \n20 See Methodology and Results report for a complete list of questions and results. Medicare FFS One of the most interesting data points of this years Measurement Effort comes from Medicare FFS. \nMedicare FFS has only 10.5% of its payments in legacy payments, or Category 1. Medicare FFSs \npayments in Category 1 are 74% less than this years aggregate (41%) across all payers. While Medicare FFS has the least amount of payments in Category 1, it has the most amount of \npayments in Category 2 (51%). This is significantly higher than any other market segment and higher than \nthe aggregate from the previous three measurement surveys (15%, 28%, and 24% respectively). These large Medicare FFS differences in Categories 1 and 2, in comparison to the rest of the market \nsegments, are largely explained by CMSs long-standing effort to link Medicare FFS payments to \nhealthcare quality through a range of nationwide value-based purchasing programs. For example, the \nHospital Readmissions Reduction Program lowers payments to Inpatient Prospective Payment System \n(IPPS) hospitals with too many readmissions and the Value Modifier Program19, which determines the \namount of Medicare payments to physicians based on their performance on quality and cost measures \ncontributed to Category 2 spending. The Quality Payment Program is a more recent example of CMSs \ncommitment to link Medicare FFS to quality and encourage physicians to participate in APMs that have \nsome level of risk. When examining Categories 3 and 4, Medicare FFS results are not as stark. Medicare FFS has 34% in \nCategory 3 and 4.5% in Category 4, or 38.5% combined. These figures align with results from the \nMedicare Advantage market segment and are higher than the commercial market segment. Payers Perspectives on the Future of APM Adoption For the first time, the LAN Measurement Effort added semi-qualitative informational questions20 to the \nMeasurement survey in order to better understand payers perspectives on APM adoption. The survey \nquestions are structured such that the first set of questions explores where payers believe healthcare \npayment is headed, the second set explores how payers think APM adoption will impact the healthcare \nmarketplace, and the final section allows payers to identify the top facilitators and barriers to APM \nadoption. The intention of the informational questions is to provide insight and guidance to stakeholders \non where to focus future initiatives that are intended to improve healthcare value. When asked about the future of APM adoption, 90% of payers indicated that APM activity will increase, \nwhile zero payers surveyed indicated that APM activity will decrease. This result shows clear agreement \namong payers that the industry intends to continue development and implementation of APMs. In \nresponding to a follow-up question regarding which APM subcategory will be most impacted, nearly half \n(48%) of payers identified subcategory 3B (fee-for-service-based shared-risk, procedure based \nbundled/episode payments, and population-based payments that are NOT condition specific). \nSubcategory 3B is the only APM subcategory outside of Category 4 that places providers at risk for their \nperformance. Its selection as the APM to be most impacted by future APM adoption reflects a likely shift \nto two-sided risk arrangements. Additionally, 25% of payers identified subcategory 3A (Traditional https://www.cms.gov/Medicare/Quality-Initiatives-Patient-Assessment-Instruments/Value-Based-Programs/Value-Based-Programs.html\nhttps://www.cms.gov/Medicare/Quality-Initiatives-Patient-Assessment-Instruments/Value-Based-Programs/HRRP/Hospital-Readmission-Reduction-Program.html\nhttps://www.cms.gov/Medicare/Quality-Initiatives-Patient-Assessment-Instruments/Value-Based-Programs/VMP/Value-Modifier-VM-or-PVBM.html\nhttps://www.cms.gov/Medicare/Quality-Payment-Program/Quality-Payment-Program.html Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 13 shared-savings, Utilization-based shared-savings) as the APM most impacted by future activity. As \npreviously discussed in this paper, it is likely that growth in 3A, which represents 21.1% of total dollars \nacross all lines of business, drove the growth in Category 3 and 4 payments captured by the 2018 \nMeasurement Effort. Future studies reporting at the subcategory level will allow for a more definitive \ntrend comparison of APM growth. Payers responded that APM activity will result in better quality of care, more affordable care, and \nimproved care coordination. While they felt that payment reform may drive further consolidation \namong healthcare providers, they did not expect higher unit prices as a consequence. Together, these \nimpressions offer an optimistic view of the impact of APMs on healthcare value. Its important to note \nthat these results reflect payers perspectives, specifically those of the 70 health plans and 3 FFS \nMedicaid states who participated in the Measurement Effort. The same questions could produce \ncontrasting results when surveying different stakeholder groups. Given that APM activity has only \nrecently proliferated across the United States (as recently as 2015, Category 1 made up 62% of \npayments), only time and rigorous evaluation can validate these payer expectations. The payer-identified barriers and facilitators to APM adoption represent actionable steps for \nstakeholders who are interested in seeing further APM adoption. Respondents were asked to select up \nto three choices from a list of nine options, including the option of writing out their own answer; the \nbarriers and the facilitators questions each employed the same response options. Two of the options \nability to operationalize and willingness to take on financial risk- did not specify the stakeholder \ngroup involved in these choices as barriers and/or facilitators, leaving the LAN and readers to interpret \nthe results within the larger context of the healthcare marketplace and the LAN Measurement Effort as a \nwhole. Because insurers are risk-bearing entities by nature, one can infer that the willingness to take on \nfinancial risk refers to provider willingness. This interpretation is reinforced by the result that \nsubcategory 3B, which is characterized by its incorporation of financial risk for providers, will be most \nimpacted by future APM activity. The identification of ability to operationalize as a top barrier also \nrequires interpretation, as APM adoption represents approaches to provider payment that may push the \noperational limits of all stakeholders. In this case, it is
more difficult to determine whose ability to \noperationalize is in question. For example, one participating payer responded Access to electronic \nmedical record (EMR) data and interoperability of systems as a top barrier. Interoperability of systems \ncan represent a challenge to providers, payers, and potentially other stakeholders, and may require \nsignificant multi-stakeholder collaboration and potentially regulatory guidance to chart a path forward. Identifying top facilitators provides insights for potential future strategies. The fact that payers selected \npayer interest/readiness as the top facilitator to APM adoption speaks to the point that payers are \nbroadly supportive of payment reform. The identification of purchaser interest/readiness as the \nsecond top facilitator showcases the vital role purchasers play in promoting the use of APMs. Finally, \nthere was a tie in the number of payers who identified provider interest/readiness and government \ninfluence as top facilitators. Taken together, the identification of these top facilitators provides an \nencouraging outlook to the future of APM adoption, as it appears that the four major stakeholder groups \npayers, purchasers, providers, and the government all have potential to facilitate APM adoption. Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 14 Lessons Learned The LANs goal is to accelerate the adoption of APMs to create a healthcare system that results in higher \nquality care that is both innovative and affordable. Tracking how quickly, or in what ways, the nations \nhealthcare payments are changing is no easy task. While there is much more to uncover, over the last \nthree years of measurement the LAN discovered many things. Value in Alignment First, there is clear value in alignment. The LAN developed standard definitions, frequently asked \nquestions, and methodological approaches to help health plans classify and report data. Myriad \nvariations in health plan programs means, however, that classifying payments into single categories \n(when they almost never exist in isolation) is complex, and requires a high-touch, interactive approach to \nensure the classifications are appropriate as data is collected. In addition, plans are frequently asked for \nsimilar data from different entities, so the more the LAN proactively discusses and standardizes \ndefinitions and data requests of health plans, the lower the burden for health plans to participate in \nmeasurement efforts. Working to align with partners such as AHIP, BCBSA, and others in advance of the \nmeasurement effort helped address these issues and minimize variation in interpretations and \napproaches. Value in Benchmarking Health plans of all sizes are interested to learn where they stand in the movement toward APMs and \nhow they compare to the market. Some health plan APM strategies are dictated by market conditions, \nothers by factors such as data system limitations or provider readiness. Having conducted many \ninteractions with individual health plans and states, a common theme that the LAN uncovered is that \nplans are eager to analyze their own business using the APM Framework as a guide, and they find \ninternal value from participating in a measurement effort. Individual data analysis assists health plans \nand states with their own strategic planning based on the unique situations of their markets, which can \nlead to innovations designed to improve care quality and affordability. Value in Customization Healthcare is local, and each market is unique, which means some health plans and states may take \nmore aggressive approaches than others in the move toward APMs; other health plans and states may \nfeel they have fewer opportunities to experiment. The LAN learned that direct comparisons between \nhealth plans and across states or geographies are inappropriate because each plan and state deals with a \nunique set of market dynamics related to supply and demand, urban and rural environments, provider or \nplan readiness, and more. Still, there is value in understanding the facilitators and barriers to adoption of \nAPMs in the different market segments. This years effort shows the differences in APM adoption even \nmore acutely by line of business commercial, Medicaid, Medicare Advantage, and Medicare FFS \nwhich can lead to greater insight into the similarities and differences in payment activity between them. Value in the Common Framework State Medicaid agencies from eight states use the LAN Framework to define the level and type of APMs \nin their states Medicaid programs.21 State-level APM measurement is taking place in both the Medicaid Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 15 21 Davis, H.E., and Boozang, P.M., Leveraging Medicaid Managed Care to Advance Value-Based Payment Manatt on Health: \nMedicaid Edition , May 2018 https://www.manatt.com/Insights/Newsletters/Manatt-on-Health-Medicaid-Edition/Leveraging-\nMedicaid-Managed-Care-to-Advance-Value and commercial sectors. States, specifically state regulators, are likely to have unique needs and desired \noutcomes, and the LAN APM Framework provides a consistent foundation to measure state-specific \nimplementation of APMs. The LAN looks forward to working with more states in future measurement \nefforts and collaborating on how the APM Framework can help track state-specific APM adoption goals. Looking Forward The LAN APM Measurement Efforts demonstrate the significant progress health plans and states have \nmade in moving to APMs as a means to improve quality and contain costs. The LAN encourages health plans, states, and other stakeholders to contribute to our national \nunderstanding of APM adoption by collaborating in future LAN APM Measurement Efforts. It is through \nthe collective efforts of the public and private sector that momentum continues to build around APM \nadoption and experimentation to improve healthcare quality and affordability for all Americans. To learn more about the LANs APM Measurement Efforts, please visit the LAN website. https://www.manatt.com/Insights/Newsletters/Manatt-on-Health-Medicaid-Edition/Leveraging-Medicaid-Managed-Care-to-Advance-Value\nhttps://www.manatt.com/Insights/Newsletters/Manatt-on-Health-Medicaid-Edition/Leveraging-Medicaid-Managed-Care-to-Advance-Value\nhttps://hcp-lan.org/groups/apm-fpt-work-products/apm-report/ Approved for Public Release. Distribution Unlimited. PRS Case: 18-3770 16 NOTICE This (software/technical data) was produced for the U. S. Government under Contract \nNumber HHSM-500-2012-00008I, and is subject to Federal Acquisition Regulation \nClause 52.227-14, Rights in Data-General. No other use other than that granted to the U. S. Government, or to those acting on \nbehalf of the U. S. Government under that Clause is authorized without the express \nwritten permission of The MITRE Corporation. For further information, please contact The MITRE Corporation, Contracts Management \nOffice, 7515 Colshire Drive, McLean, VA 22102-7539, (703) 983-6000. 2018 The MITRE Corporation. _top\n _Toc525917215\n _Toc525917216\n _Toc525917217\n _Toc525917218\n _Toc525917219\n _Toc525917220\n _GoBack\n _Toc525917221\n _Toc525917222\n _Toc525917223\n _Toc525917224\n _Hlk527629396\n _Hlk527629440\n _Toc525917226\n _Toc525917227 ",
    "text": " National Cybersecurity FFRDC Self-Assessment and Annual Review 1The MITRE Corporation Symposium on the Federal \nWorkforce for the 21st Century\nOctober 2018 Report NOTICE This report was produced for the U. S. Government under Contract Number TIRNO-99-D-00005, and is subject to Federal Acquisition Regulation Clause 52.227-14, Rights in DataGeneral, Alt. II, III and IV (DEC 2007) [Reference 27.409(a)]. No other use other than that granted to the U. S. Government, or to those acting on behalf of the U. S. Government under that Clause is authorized without the express written permission of The MITRE Corporation. For further information, please contact The MITRE Corporation, Contracts Management Office, 7515 Colshire Drive, McLean, VA 22102-7539, (703) 983-6000. Report Symposium on the Federal Workforce for the 21st Century Approved for Public Release. 18-3746. Distribution unlimited. 1The MITRE Corporation CONTENTS\nINTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3 BACKGROUND AND PURPOSE . . . . . . . . . . . . . . . . . . . . . . . . . .4\nThe Presidents Management Agenda: mission, service, stewardship . . . . . . . . . 4 The Federal Workforce Symposium: sharing experiences from the \nprivate and public sectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 The changing nature of work: mission, service, stewardship in the digital age . . . 6 About this report . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 WHAT WE LEARNED . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .8\nChallenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Opportunities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 RECOMMENDATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nIncrease use of partnerships for talent exchange programs . . . . . . . . . . . . . . 17 Expand use of critical hiring authorities . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 Use data science to develop evidence-based HR strategies . . . . . . . . . . . . . . 19 Expand use of apprenticeships and development partnerships . . . . . . . . . . . 20 Build training and reskilling into technology procurements . . . . . . . . . . . . . . . 21 Collaborate with labor organizations on an initiative with clear \noutcomes and shared interests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 Establish a talent marketplace to increase mobility opportunities . . . . . . . . . 23 Develop managers to provide ongoing, effective, feedback and coaching . . . . . 24 Explore approaches for aligning compensation with value and performance . . . 25 Continuing the conversation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Alignment of recommendations with CAP Goal 3 subgoals . . . . . . . . . . . . . . 26 CONCLUSION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 APPENDIX: PARTICIPATING ORGANIZATIONS . . . . . . . . . . . . . . . . 28 Report Symposium on the Federal Workforce for the 21st Century2 3The MITRE Corporation INTRODUCTION \nOn September 12, 2018, the Office of Management and Budget (OMB), \ntogether with The MITRE Corporation, convened more than 150 \nexperts and leaders from across the country for a full-day symposium \non strategies for improving the federal workforce in support of the \nPresidents Management Agenda (PMA) on modernizing the federal \ngovernment The objectives of the symposium were to share leading \nworkforce development and management practices from the private \nand public sectors and identify next steps the federal government \nmight take to address cross-agency people and workforce challenges \nUltimately, the goal was to energize momentum around the PMA to \ndrive progress and fuel the governments future workforce Participants came from all sectors, including the private and public \nsector, academia, and nonprofits, and represented a cross-section \nof functional areas such as human resources (HR), operations, \ninformation technology, and change management OMBs goal was \nto get a perspective from both inside and outside the Beltway The \ndays activities included presentations and panel discussions to share \nexperiences, followed by in-depth roundtables with diverse teams of \nparticipants, to begin applying learnings to government use cases MITREs role was that of an independent third party with knowledge \nof the government Our expertise is in systems thinking and the \ninterrelationship between technology and people The MITRE team \nfor this effort brought expertise in human and organizational systems, \nwith experience researching and designing actionable strategies \nthat consider the human aspects of any system or transformational \ninitiative We applied our expertise to understand the input from the \nparticipants; synthesize it into a form that OMB can review, use to \nconsider next steps, and engage stakeholders; and represent the voices \nand perspectives of the participants This report is intended to provide our perspective on the key take-\naways from the discussions of that day; identify the challenges and \nopportunities that emerged from those discussions; and provide a set \nof recommended practices and actions for the government to consider, \naligned with the intent and vision of the workforce strategies in the PMA Report Symposium on the Federal Workforce for the 21st Century The Presidents Management \nAgenda: mission, service, \nstewardship In early 2018, the Presidents Management \nCouncil and the Executive Office of the President \nreleased the PMA to lay out a long-term vision for \nmodernizing the Federal Government in key areas \nthat will improve the ability of agencies to deliver \nmission outcomes, provide excellent service, and \neffectively steward taxpayer dollars on behalf of \nthe American people. The direction presented in the PMA follows a \nsystems-thinking approach, identifying a closely \nrelated set of strategies and actions to address \nthe challenges around these three central themes These challenges are not newaging \ntechnology infrastructure, disconnected and \ndifficult-to-access data, and a long-standing \ncivil service model that does not reflect modern \nrealities or adequately serve federal workers and \ntheir organizations The goal of the PMA is to \naddress these challenges in an integrated manner, \nrecognizing the interrelationships among them As the PMA describes \nthe challenges facing \ngovernment and the \nfederal workforce, \nit presents a vision \nfor addressing the \ncritical transformation \ndrivers: modernizing information technology, \nmaking data accessible to improve delivery to the \npublic while creating greater accountability for \nresults, and aligning and repositioning the federal \nworkforce to the changing nature of work and \nrapidly evolving expectations from the public \nThe PMA includes Cross-Agency Priority (CAP) \ngoals that focus on specific, targeted changes \nand associated actions aligned with each of these drivers For CAP Goal 3, Developing a Workforce \nfor the 21st Century, this includes three subgoals: Actively Manage the Workforce through \nimproved employee performance management \nand engagement Develop Agile Operations that support \nretraining and redeploying human capital \nresources Acquire Top Talent using simple and strategic \nhiring approaches and practices Advancing the vision in the PMA requires devel-\nopment of strategies and actions that the govern-\nment can take to simultaneously drive measurable \nresults and enable greater employee satisfaction \nTo that end, OMB recognizes the need to engage \nothers outside the federal government to better \nunderstand the practices they use to drive change, \ntheir insights on the changing nature of work, and \nhow their workforce
strategies should address the \nevolving needs of the federal workforce 4 BACKGROUND AND PURPOSE Mission, service, \nand stewardship \nrequire commitment, \nskill, and sustainable \nengagement 5The MITRE Corporation The Federal Workforce \nSymposium: sharing \nexperiences from the private \nand public sectors The long-term goals defined in the PMA, \nincluding the workforce goal, require sustained \npartnership with others outside the federal \ngovernment By engaging with the private sector, \nthe government can understand how they are \naddressing the workforce implications of digital transformation and leverage relevant practices \nBy partnering with academia and non-profits, the \ngovernment can research, test, and learn new \napproaches and determine how best to adopt or \napply them By collaborating with employees and \ntheir representatives in labor organizations, the \ngovernment can address both the needs of those \npeople and the agency missions they serve These \nare a few of the persistent actions that the federal \ngovernment should commit to going forward \nRecognition of these imperatives is what launched \nthis effort and the Federal Workforce Symposium To that end, OMB and MITRE, assisted by our \nprivate sector partner McKinsey and Company, \nidentified and invited participants from private This is the focus today: to go beyond the idea stage and talk to concrete actions This \nis your opportunity to make \nsome recommendations to the \nfederal government sector organizations in the technology and \nservices sectors; academia, professional \nservices; public-interest nonprofits; labor, federal \ngovernment, and state and local government \norganizations (See Appendix for a complete list of \nparticipating organizations ) Session participants \nrepresented a breadth and depth of experiences \nand responsibilities for human capital strategy, \noperations, training, performance management \nand compensation, technology, talent \nmanagement, succession planning, civil service \nlaw, and change management through people To ensure the greatest degree of candor and \nopenness, the working sessions followed Chatham \nHouse Rule, with comments and inputs captured \non a nonattribution basis Participants were highly \nengaged and produced abundant insights for the \ngovernment to consider Report Symposium on the Federal Workforce for the 21st Century The changing nature of work: \nmission, service, stewardship \nin the digital age This diverse group came together with \na common interest in supporting a federal \ngovernment that delivers mission, service, and \nstewardship Group members all shared the same \nmacrochallenge: embracing digital transformation \nand the way it is changing the nature of work, \nexpectations, and experiences for the workforce \nThis point was emphasized throughout the \nsymposium by the various panels in the morning \nand afternoon working sessions The pace of change and adoption of digital \ntechnology has accelerated; research and \nstudy show this will only continue A point made \nby some speakers and panelists was that the \ndigital transformation is changing the nature of \nwork, and organizations face a choice between \nbeing disrupted or disruptive 1 This is the \nchoice between allowing technology-driven \ntransformation to impact organizations and people \nin adverse ways (e g , reductions in jobs) or using it as an opportunity to redefine the work and \ncreate new possibilities for skill and job growth, \nand new ways for employees to contribute to \nmission, service, and stewardship As many of the \npanelists pointed out, this transformation is driving \nprivate sector organizations and governments to \nmodernize information technology, democratize \ndata, and enable the workforce by rethinking the \nrelationship between people and their work and \nfocusing more on the employee experience To arrive at a potential set of specific actions \nthe government should consider taking, the \ndiscussion at the symposium was framed around \nfour topics: the relationship between technology \nand people; the need for upskilling and reskilling \nto position people to adapt to and grow with the \nchanging nature of work; rethinking performance \nmanagement and all its aspects, including \ncompensation; and needed reforms to modernize \nthe civil service One common practice emerged: \nleading organizations align business and people \nstrategies so that they consider all the things \nthat employees value (instead of adhering to the \ntraditional view that monetary compensation is the Adapted from: Willis Towers Watson, 2018 Our current reality: we must disrupt or be disrupted. The MITRE Corporation primary motivator) The key to retaining satisfied, \nproductive, engaged employees is the quality of \nthe employee experience, and experience shows \nthat engaged employees deliver results As OMB makes decisions about actions and \npractices to advance the PMA goals, it should \nensure that they are both business-driven and \npeople-driven; that those actions and practices \nfocus on a common sense of purpose and mission; \nand that they engage employees, stakeholders, \nand other related parties in that shared purpose \nand mission About this report\nThis report captures the ideas around which there was the greatest convergence among \nparticipants; it does not include every idea or \nrecommendation raised during the September \n12 session We applied our judgment and insight \nto highlight potential actions the government \ncould consider that (1) represent the collective \npoint of view, (2) were new to the federal \ngovernment but had precedent and a degree \nof successful practice in other organizations, \nor (3) were backed up by existing third-party \nresearch and evidence Our objective is to provide \nrecommendations that could yield substantial \nimprovement opportunities Participants may \nnot have all agreed on specific actions, but they \ngenerally agreed that action was required Based \non our analysis of participants input and our own \nstudy of the relationship between transformation \nand workforce management, we also developed \na framework that OMB might consider using to \norganize and focus future discussions (See Figure \n1 in What We Learned) Technology is the enabler, but its the humansits uswho \nare most important 7 8 \n WHAT WE LEARNED \nSymposium participants recognized the broad scope of federal workforce development as a \ntopic for discussion and problem-solving; their \ndiscussions converged around the three core \nchallenges we have highlighted in this section. \nWhile this convergence does not encompass \nall of the governments workforce challenges, \nwe believe the three noted below are among \nthe most fundamental and significant for OMB \nand its partners and stakeholders to achieve its \ngoals. Successfully addressing these challenges \nwould improve mission delivery, enable more \neffective and efficient service, and strengthen the \nstewardship of public funds. Challenges \nAligning workforce strategies to keep \npace with the changing nature of work Human resource functions support organizations \nand their mission. Yet, across all sectors, HR faces \na recurring challenge: balancing continuity, consis-\ntency, and repeatable processes with the agility to \nanticipate and adapt their workforce planning and \ndevelopment strategies to changing environments \nand requirements. This is a significant challenge \nfor the federal government, given the scope and \ncomplexity of its work, its large and diversely skilled \nworkforce, and the ever-increasing volume and \nvelocity of technological advancements. The rapidly \nincreasing accessibility of new technology, meth-\nods, and data change the nature of work, who does \nit, and what skills and tools are required. An agile workforce strategy relies on access to \ndatathe right dataand the ability to continually \nanalyze that data to inform near-real-time work-\nforce decisions. Data about emerging conditions, \ndemand, and other needs that will affect workload \nwill alter the nature of the work. This environ-\nmental and operational data must be analyzed \nin conjunction with workforce-specific data. At There are a lot of levels and \ndimensions to this problem . \nWe spend so much time \nreacting versus being more \nproactive . We dont take the \ntime to envision the future \nand share that future . Report Symposium on the Federal Workforce for the 21st Century 9The MITRE Corporation present, some of the data required to do this type \nof critical workforce planning is not collected, \nsynthesized, or shared at an agency- or govern-\nment-wide level Symposium participants noted that without data \non the distribution of current workforce skills, \nleaders can not make evidence-based decisions \nFor example, data could inform shifting resources \nto deploy the right skills to address emerging \nneeds, where to apply training investments, and \nwhich incentives are most valued by employees \nNor does the current workforce strategy allow \nfor operational agility (i e , some degree of excess \ncapacity), which also inhibits effective resource \nrealignment, mobilization, and redeployment when \nthere is a surge in the need for critical skills Sustaining sufficient investment to \nattract talent and develop skills for \ndigital transformation and mission Most participants, regardless of sector, said \nthat their organizations faced the challenge of \ncompeting for people with skills that are in high-\ndemand (e g , cybersecurity, data science) They \nobserved that these sought-after employees have \nmany employment options and will make choices \nabout where to work based on their perceptions of \nwhat they will learn, what they can contribute, and \nhow their employer will value their contributions Participants also acknowledged this is a significant \nchallenge for the government Many professionals \nhave expectations they perceive as inconsistent \nwith what the government offers in terms of \ncareer experiences, professional development, \nwork environment, and rewards Todays early- and \nmid-career professionals seek less hierarchy, the \nopportunity to have multiple experiences with \nthe same employer, and the freedom to apply \ntheir skills to diverse, meaningful challenges \nConstraints on upward and lateral career mobility \nextend the perception that government service \nis less desirable than employment in the private \nsector As one
participant observed, we are not \ngood at incentivizing people to move around, and \nwe do not make it easy from a mobility standpoint Symposium participants discussed a specific \nchallenge related to learning and development: re-\nskilling Despite their deep institutional knowledge, \ndedicated government employees may face evolv-\ning mission or organizational requirements that \nhave changed their work and necessitated new \nskills Many of these reskilling opportunities have \nsignificant technology components Participants \nnoted that employees (in any organization, not just \nin government) may view technology as a threat to \ntheir job rather than an enabler of their work and \ntheir agencys mission Finally, budget constraints \nsometimes lead to reskilling efforts that do not \nsupport the necessary time or degree of training \nrequired for employees to master new skills Updating laws and policies to meet \ncurrent needs Many of the participants said that some \nexisting laws and policies create particularly \ncritical challenges for the government The Merit \nSystem Principles of fair and open competition, \nWere not harnessing \nthe data 10 Report Symposium on the Federal Workforce for the 21st Century fair and equitable treatment, and protection \nagainst personal favoritism are intended to create \na level playing field and open opportunities for all \nHowever, the process for posting and competing \njobs in the government can be frustrating to \nmanagers when they feel they have identified a \nquality candidate and want to move quickly The process of developing candidates and building \ntalent pipelines can also be cumbersome to \nmanagers, given that career ladders are often \ndesigned in advance of the competitive process \nIn contrast, commercial companies may identify \nhigh potentials (or HiPos) for their leadership \npotential and nurture their careers with focused \ndevelopment opportunities as they ascend through \nmanagement ranks One example of a federal \nprogram focused on building leadership success is \nthe Internal Revenue Services (IRS) XD (Executive \nDevelopment Program) Through this program, the \nListen to the people doing \nthe work IRS successfully applies intentional succession \nand development principles in line with its private \nsector peers while still following federal laws and \npolicies But this is not a consistent practice across \nthe federal government Some symposium participants raised the \nchallenge of balancing the important goals \nof Veterans Preference with other objectives \nunderlying the Merit System, such as fair and \nopen competition and new opportunities This \ngenerated much dialogue among participants, \nwho discussed whether the preference and the \nopportunity it creates is a one-time preference \nto facilitate initial government employment or \na long-term commitment that applies to any \nopportunity pursued once inside the government \nSome participants pointed to a proposal by the \nDepartment of Defense in 2016 that would allow \nVeterans Preference to be an option only for \ninitial entry into government 2 While symposium \nparticipants agreed on the need to explore \npotential options to restructure the statute, \nthey also emphasized that any options needed \nto continue to honor our veterans and identify \nadditional approaches for helping veterans \nqualify for jobs and be positioned for growth and \ndevelopment opportunities The September 2018 \nNational Academy of Public Administration (NAPA) \nNo Time to Wait, Part 2 report3 provides additional \nperspective on this topic and is consistent with \nsymposium participants suggestions The third aspect of this challenge relates to \nperformance management, specifically how federal \nmanagers address below-par performers In the \nOPM Federal Employee Viewpoint Survey (FEVS), \nonly 42% of respondents felt that steps were \ntaken in their organizations to address below-par \nperformers This result is consistent across past \nsurveys One contributing factor, which is not \nunique to the federal government, is the challenge \nof helping supervisors learn how to coach and \ndevelop a struggling employee while maintaining \nthe productivity and morale of the whole work unit 11The MITRE Corporation Opportunities \nAs participants shared their experiences, insights, and recommendations for address-\ning the challenges facing the government, \nsome clear themes emerged In synthe-\nsizing the results from the symposium, \nwe developed the framework in Fig-\nure 1 to organize captured ideas and \nrecommendations, and to provide \nto OMB a model that might prove \nuseful for future research, engage-\nment, and action planning The \nopportunities composing this \nframework reflect key ideas raised \nby participants The final section \nof this report, Recommendations, \npresents those specific practices or \nactions that MITRE believes the gov-\nernment should explore further, in align-\nment with these opportunities Figure 1. Opportunity Framework and seeking training that is self-enriching versus \nrelated to job requirements They have set up or \nare participating in Talent Marketplaces to provide \nmore options for employees 4 They have revised \nperformance management and compensation to \npay for value, not simply performance And they \nnot only encourage mobility but also build mobility \ninto their organizational models and career paths \nto improve the employee experience Amazon Web Services (AWS) provides another \nexample of a high-performing company focused \non the employee experience AWS uses tools \nlike the Connection Survey to continuously pulse \nemployee satisfaction and engagement, as well \nas decision models that allow for disagreement \nbut focus on getting commitment to deliver the \noutcome All of these examples focus on under-\nstanding, respecting, and leveraging the strengths, \nexperiences, and motivations of their people People Shared by symposium speakers and \nparticipants was the perspective \nthat leading organizations today \nput people at the center of their \nstrategies and focus on enhancing the employee experience and employee value \nFor many organizations in many sectors, this is a shift from traditional organizational strategies \nand practices While some might argue that it \nis always about the people, many examples \nwere shared that demonstrate that leading \norganizations are doing more to understand \nwhat motivates and engages people, as well as \ndeveloping workforce strategies and programs \nto align organizational needs and the value \nproposition for each employee Professional services organizations such as \nAccenture, Deloitte, McKinsey, and the Boston \nConsulting Group (BCG), all symposium attendees, \nhave shifted their models to provide more control \nto employees in setting their career paths, \nlooking for and acting on growth opportunities, 12 Report Symposium on the Federal Workforce for the 21st Century In our framework, we place people at the center \nbecause a people-driven strategy recognizes \npeople for the skills and value they bring to the \norganization, aligns incentives to what they value, \nsupports ongoing growth and development, \ncreates new opportunities, enables people to \ndefine and manage their own career paths, and \nfosters a sense of mission and purpose behind \nroles and work A people-centric approach is \nconsistent with all leading practices and leading \norganizations regardless of their sector 5 Engagement Reflecting on their leadership \nexperience, industry experts \nand executives attending the \nsymposium emphasized that \nemployee engagement is essential to any change effort that impacts the workforce \nOrganizations cannot merely inform employees \nof impending changes; leaders and managers \nshould communicate early and often, listen to the \npeople who do the work, and invite employees \nto be actively involved in designing the solution \nTo illustrate this type of active involvement, one \nparticipant shared the example of employee-driven \nproduct development in a technology organization 6 Participants acknowledged that this is a challenge \nin all types of organizations Engaging employees \nrequires commitment and consistency, but \nresearch shows it also decreases resistance, \nincreases commitment, and directly contributes \nto the success of, for example, technology \nimplementations 7 Symposium participants noted that having a clear \nand compelling mission is a significant strength for \nthe government Many employees join the govern-\nment for the mission, and, as reported in the 2017 \nFEVS, most federal employees take the values \nof mission, service, and stewardship seriously \nThey are dedicated and proud to serve Similarly, \ngovernment employees are willing to put in extra \neffort to get a job done In the 2017 FEVS results, \n95% of respondents reported believing that they \nThe most important partnership that can be developed and nurtured is [between] management \nand employees are doing important and valuable work, as opposed \nto 83% of their private sector peers (per Partner-\nship for Public Service and Mercer/Sirota) 8 That most government workers believe their work \nhas purpose is a strong foundation on which to \nbuild greater engagement and partnership This \nis particularly important within the context of \nlabor and management As related at the sym-\nposium, the experience at the Portsmouth Naval \nShipyard demonstrates that building productive, \nsustainable working relationships is possible when \nall parties focus on common values and goals In \nthis example, collaboration between labor and \nmanagement built trust, provided a foundation \nfor decision-making, and helped those involved 13The MITRE Corporation navigate through the disagreements and challeng-\nes that inevitably arose In this case, transparent \ncommunication and active engagement resulted \nin measurable performance gains for the shipyard Learning and development In the public and private sectors, \nemployees perceptions of learning \nand career growth opportunities \n(or lack thereof) have emerged \nas a major retention factor, along with the conventional wisdom of satisfaction \nwith pay and immediate supervisor 9 As one \nparticipant noted, Career opportunitiesthe \nability to progress in ones careeris one of the \nmain drivers of employee satisfaction and a key \nissue for maintaining a satisfied and productive \nworkforce As such, symposium attendees across \nall sectors reported using a variety of strategies \nto increase retention of valued
staff, including \noffering growth and development opportunities, \nsustaining investments in lifetime learning, and \nexpanding nonmonetary incentives that create a \nmore positive employee experience One specific learning and growth opportunity \ndiscussed at the session was increased workforce \nmobility Agency leaders at the symposium ad-\nvocated sharing talent, with lateral transfers and \nThe most recent Federal Employee Viewpoint Survey reports that 91% of the federal workforce \nbelieves the work I do is \nimportant. rotations among agencies, and between the public \nand private sector, to help employees grow their \ncompetencies by providing diverse and challeng-\ning work experiences This practice also helps \nagencies expand their own capabilities for critical \ntechnical skills (e g , cybersecurity, healthcare, \nenergy, data science/analytics) Public sector attendees noted challenges associ-\nated with implementing mobility strategies, includ-\ning managers desire to keep high performers in \ntheir organizations Participants indicated this is \nin part because traditional Title 5 position man-\nagement constrains how managers can backfill \npositions In addition, positions that become va-\ncant require managers to deal with the challenges \nassociated with developing a new position based \non standards, structuring positions into career lad-\nders, and competing vacant positions The oppor-\ntunity is thus to encourage, train, and incentivize \nsupervisors to develop their employees and allow \nthem the mobility to grow their career Additional development opportunities discussed \nby participants include modeling joint duty, \ntemporary, inter- and intra-departmental \nassignments (already common practice in \nDepartment of Defense and intelligence \ncommunities); partnering with community colleges \nfor low-cost training opportunities; supporting \napprenticeships and on-the-job training; and \nestablishing academies to train on special skills \nthat are difficult to acquire, highly sought after, and \nrapidly changing (e g , artificial intelligence, data \nscience, cybersecurity) Report Symposium on the Federal Workforce for the 21st Century14 From 2017 Federal Employee \nViewpoint Survey: of respondents said they \nare satisfied they have \nopportunities to get a better \njob in their organizations %35 Performance management In a growing trend, private sector \norganizations have shifted from \nfocusing on a formal, annual rating \nor ranking process to an iterative \ncoaching and feedback process that is more informal and frequent Companies \nsuch as Accenture, Deloitte, McKinsey, and BCG \nhave moved to this model of ongoing coaching \nand feedback as a way of increasing engagement \nwhile also providing performance feedback This \nis quickly becoming the norm in the private sector, \nespecially in those organizations that employ \nknowledge workers In a Harvard Business Review \n(HBR) article about Deloittes new performance \nmanagement approach, the writer notes, Weve \narrived at a very different and much simpler \ndesign for managing peoples performance Its \nhallmarks are speed, agility, one-size-fits-one, \nand constant learning 10 Exploring this approach in the federal sector rep- resents an opportunity to address an area where \nthe federal government scores are lower than \nprivate sector comparisons in the Federal Employ-\nee Viewpoint Survey (FEVS), and where the lowest \nresults are in the performance-based rewards and \nadvancement categories As the results suggest, \nfewer than half of federal employees are satisfied with the relationship between pay, promotions, \nawards, and their performance Symposium participants from private sector \nand state government, as well as MITRE, not-\ned they have already begun to train managers to \noffer frequent, informal feedback and guidance \nto meet employees expectations and measure \nmanagers ability to do so successfully Millennials \nexpect more feedback from their managersat \nleast monthly 11 As a result, these companies have \nreduced their reliance on rating scales and rank-\ning employees in typical bell curves and relative \nrankings Beyond assessing employees job and \nactivities, managers assess staff on their individual \nvalue to the organization based on their skills and \nthe results or outcomes they deliver Symposium participants whose organizations are \nimplementing this newer approach indicate that \nit appears to be creating more engagement and \nstrengthening relationships between manager \nand employees They said that balancing frequent \ncoaching with performance feedback helps their \nstaff respond and adjust throughout the annual \nperformance cycle That said, successful imple-\nmentation requires training and incentivizing man-\nagers to embrace this new approach to working \nwith their staff while evaluating their own perfor-\nmance for this responsibility Partnerships During the symposium, discussions \nprobed how the private sector and \nsome states have partnered with \ncommunity colleges and universities \nto develop curricula focused on building skills for specific occupational needs 12 \n An engaged workforce is the most powerful workforce that you can possibly have Report Symposium on the Federal Workforce for the 21st Century 15The MITRE Corporation of respondents felt that \npay is based on how well \nthey perform their jobs of respondents indicated \nthey feel promotions in \ntheir work unit are based \non merit 47% \nof respondents believe \nthat awards in their work \nunit are based on how well \nthey perform their jobs 31%35% The federal government has similar options \nBy focusing first on potential human capital \nshortages or specific talent gaps, the government \ncan then determine which educational platforms \nor institutions might offer the most viable \npartnership opportunities As many private sector \norganizations are struggling with similar skill gap \nshortages, opportunities exist to work in tandem \nParticipants discussed options such as building \napprenticeship or credentialing programs that \nfocus on specific areas (e g , cybersecurity) Partnerships can also increase opportunities for \nemployees to gain and learn from new experiences \nSymposium participants discussed the need to \nincrease opportunities for government employees \nto work outside the federal government; gain \nexperience, knowledge, and skills; and then return \nto apply their new knowledge and skills to their \ngovernment work This type of exchange creates \nthe mobility and diverse experiences that early- \nand mid-career professionals seek It enables \nemployees to develop skills and expertise in areas \noutside their comfort zones and exposes them to \nother organizational methodologies and cultures Participants also referenced models that allowed \nfor private sector and non-governmental organiza-\ntions to be involved in filling government roles and \ndeveloping government employees Programs such \nas the U S Digital Service and authorities such as \nthe Intergovernmental Personnel Act (IPA)13 and \nthe Critical Hiring Authority, for example, allow \nthe government to recruit top technologists for \nterm-limited tours of duty The IRS closed several centers, and \neach of those centers had between \n3,000 and 5,000 employees Most \nof the people at the centers were \ndoing data entry When the centers \nwere closed, the data transcription \nfunction was no longer needed But \nrather than let the employees go, the \nIRS prepared for the transition by \nproviding training to the impacted \nemployees The goal was to prepare \nthe people for the future and the \nchanging nature of work 16 Report Symposium on the Federal Workforce for the 21st Century Technology and data Participants discussed the value of \nharnessing available data to inform \ndecision-making around strategic \ninvestments and talent management \nsolutions that address workforce needs, trends, and gaps Indeed, dynamic work \nconditions are forcing changes For example, the \npractice of using static position descriptions to \nhire entry-level employees is evolving as managers now realize that an employees skills must adapt in \ntandem with the job requirements, particularly for \njobs reliant on technology Moving forward, effort \nshould be made to transition to more dynamic \nmethods of data capture, which could inform \nthose position descriptions and therefore drive \ncompensation and selection Leveraging data to identify emerging trends that \nmay affect government operations and service \ndelivery allows agencies to plan for anticipated \nchanges in workflow and staffing For example, the \ndata from existing human capital systems (e g , po-\nsitions, occupations, career levels, competencies) \ncan be compared with emerging work needs The \nresults enable valuable discussions about how an individual employees career path and an organi-\nzations workforce planning needs might fruitfully \nintersect For example, representatives from the \nprivate sector described the importance of data \nscience to drive agile workforce strategies such as \nwhere to apply training investments, who may be \nat risk of leaving, which skills are needed where, \nand which incentives and rewards will provide the \ngreatest value to employees Symposium participants emphasized that \ntechnology should be an enabler of people, not \nthe other way around: We need to make the \ntechnology work for us Analyzing data related \nto workloads alongside metrics for capturing \nthe demand for government services will allow \nagencies to accurately assess the impact of \nautomation Assessment is essential to planning \nfor and capturing shifts as they happenas \npositions change to reflect increased reliance on \ntechnology in the delivery of these services As an \nexample, artificial intelligence may enable a change \nin process so that technology will replace routine \nwork that does not require human judgment 17The MITRE Corporation RECOMMENDATIONS \nThroughout the symposium, participants shared accounts of their activities, decisions, \nand experiences, all of which touched on the \nopportunities discussed previously While the \nconversations surfaced many ideas, some of the \nsuggestions stood out because of their potential \nfor transformational impact for the federal \ngovernment, and because they had: demonstrable impact in local or state govern-\nment or in the private or nonprofit sectors viability as determined by academic and \napplied research results potential to be scaled widely across the \ngovernment applicability to multiple challenges and \nopportunities relevance to the Presidents Management \nAgenda For the purposes of this report, we have \nhighlighted nine
recommendations for further \nreview and consideration based on the \ndiscussions and supporting data Evaluation \nand implementation of these recommendations \nrequires a distinct set of considerations and \nactions Some are designed to take advantage of \nexisting policies, tools, authorities and data, while \nothers are more substantial in their effort, more \nfundamental in their potential for impact, and may \nrequire legislative actions or policy change: 1 Increase use of partnerships for talent \nexchange programs 2 Expand use of critical hiring authorities 3 Use data science to develop evidence-based \nHR strategies 4 Expand use of apprenticeships and \ndevelopment partnerships 5 Build training and reskilling into technology \nprocurements 6 Collaborate with labor organizations on an initia-\ntive with clear outcomes and shared interests 7 Establish a talent marketplace to increase \nmobility opportunities 8 Develop managers to provide ongoing, effec-\ntive, feedback and coaching 9 Explore approaches for aligning compensation \nwith value and performance Increase use of partnerships \nfor talent exchange programs Purpose and practice: Talent exchange \nprograms in professional and academic organiza-\ntions have long been a tool to support individual \ngrowth and development, as well as organizational \ngrowth When structured to both fulfill the staff-\ning need and help develop the capabilities of the \nreceiving organization and its employees, these \narrangements can have significant benefits The government has several programs already \nauthorized that agencies could use to a greater \ndegree to acquire talent and experts, who then \ncan contribute and teach others At the same time, \nsuch programs could enable employees to do a \nrotation in the private sector or at an academic \ninstitution to round out their experiences and \nperspectives The Intergovernmental Personnel Act (IPA) \nprogram is a tool used by government agencies to \nbring in ideas from state and local governments, \ncolleges and universities, Indian tribal governments, \nfederally funded research and development \ncenters, and other eligible organizations The \nScience and Technology Policy Institute14 describes \nthis type of exchange as a triple win for the \ndestination organization, the participant, and the \nhome organization Nonetheless, IPAs are not \nused as frequently as they might be given the \nrestrictions put upon them, which are designed \nto avoid personal and organizational conflicts of \ninterest and legal issues (e g financial disclosure \nand post-exchange compensation) Report Symposium on the Federal Workforce for the 21st Century An authority that agencies may use to acquire pri-\nvate sector expertise is the Experts and Consul-\ntants authority under 5 U S C 3109 (U S Code) \nAppointments under 5 U S C 3109 allow tempo-\nrary hiring of experts and consultants to provide \nprofessional or technical expertise that does not \nexist or is not readily available at the agency Re-\nquirements for the program include ensuring that \nappointments are temporary or intermittent 15 As \nof March 2018, 2,841 employees are on expert and \nconsultant appointments across the government, \nbased on numbers from OPMs FedScope 16 Actions:\nConsider using IPAs and expert appointments more \nbroadly to augment existing skill sets and fill critical \nroles for which the necessary level of expertise is \ndifficult to find in the federal government Explore the possibility of expanding IPA-approved \norganizations to include private sector employers, \nwho could rotate into the government to introduce \nadditional perspectives and approaches Broaden use of IPAs to nontechnology roles, to in-\nclude human capital professionals Considerations: The government should re-examine the legal \nand ethical issues related to IPAs, such as \ngovernment ethics restrictions (5 C F R 2635 \n[Code of Federal Regulations]), Post-Exchange \nRestrictions 18 U S C 207; 5 C F R 2641, and \norganizationalas well as otherconflicts of \ninterest These arrangements carry risks in terms of \nthe potential for losing talent and intellectual \nproperty; this is one reason some organiza-\ntions are cautious about these relationships \nThe government should develop strategies to \nmitigate these risks These arrangements will require resources \nto support program and stakeholder \nmanagement 18 Expand use of critical hiring \nauthorities Purpose and practice: It may be possi-\nble to expand the use of critical hiring authorities \n(e g , Critical Position Pay Authority)17 to address \nidentified gaps in knowledge, skills, and abilities in \nmission-critical positions In addition to using the current authority more \nbroadly, OPM and Congress have the authority \nto approve related Streamlined Critical Pay \nAuthorities to meet special needs and to allow \nadditional flexibility for an agency or agencies \nIn the past, streamlined authorities have been \ngranted to the National Aeronautics and Space \nAdministration (NASA) and the IRS to recruit from \nthe private sector For example, the streamlined \nauthority granted to the IRS gave the Secretary of \nthe Treasury the authority to set compensation \nand appoint individuals to positions designated \nas critical and requiring skills and competencies \nnot otherwise available These individuals served \non one-time renewable four-year contracts \n(four-year base, four-year renewal for eight years \nmaximum), during which time they were also \nexpected to develop the organizational capability \nand existing talent to fill the specific technical or \nfunctional need Actions:\nConsider wider use of the existing Critical Position \nPay Authority across government to recruit more \ncandidates for skills such as cybersecurity, data sci-\nence, healthcare, and other high-demand skill areas 18 Explore and evaluate granting targeted or stream-\nlined authority to agencies or groups of agencies \nwith significant needs, priorities, or critical deficien-\ncies in key skill areas 19The MITRE Corporation Considerations: The existing Critical Position Pay Authority \nhas a cap of 800 positions that may be \ncovered government-wide at any one time, \nand limits the number of active authorizations \nIn exploring the possible broader use of this \ntool, these caps should be adjusted to meet \ngovernment needs These positions should be carefully identified \nand scoped to be clearly distinguishable from \nexisting positions on the standard federal pay \nscale If not carefully executed, this can create \nreal or perceived pay inequities and other \nchallenges for the current workforce Use data science to develop \nevidence-based HR strategies Purpose and practice: The government \nalready uses data science to support mission \nstrategies and operational decisions It can \nextend this practice to workforce strategies \nand operations as well by using data to baseline \nand project skillset needs to inform hiring and \ndevelopment strategies Using data to understand \nfuture demands and trends inside the organization \ncan help agencies anticipate skills requirements, \nidentify where to invest training for both reskilling \nand ongoing development, learn where mobility \nopportunities exist, and determine which hiring \nstrategies to develop The government has a great deal of data about \nthe workforce and the business environment \nPrivate sector symposium participants described \ntheir practice of using that data as a strategic \ntool to understand the past and present and \nanticipate the future possibilities We believe \nthis leading practice holds great potential for the \ngovernment Agencies can use their projections to \nalign budget requests with staffing needs, despite \nthe challenges associated with government \nfunding These efforts can then be integrated with \ndata metrics that evaluate the quantity and quality \nof government services and products Dont gather data until you \ndecide which decision it \nwill inform, otherwise youll \nget lost and be subject to \nconfirmation bias \n Actions:\nDevelop data-driven workforce planning strategies \nthat analyze the needs of shifting, in-demand skill \nsets, relative to the existing talent, within and across \nagencies Leverage benchmark data inside and outside the \ngovernment to build forecasting models for employee \nworkload projections Conduct an objective assessment of what data is \navailable and whether data can support strategic \ndecisions around reskilling and redeployment of the \nworkforce, or additional data is required Engage the governments Chief Statistician to help \ndefine a path forward and form a cross-agency com-\nmunity of people-analytics professionals Establish the designated people-analytics role within \nthe 200 occupational series or increase the staffing \nlevels of industrial organizational psychologists that \nreport to agency Chief Human Capital Officer (CHCO) \nRequired skills include HR analytics, data visualiza-\ntion, and storytelling, to help government leaders \nmake informed decisions about their workforce Considerations: Data accuracy, currency, and reliability impact \nthe ability to make meaningful data-driven \ndecisions Data standardization and integrated \nsystems are also necessary to enable this vision Achieving the right balance of HR, managers, \nand staff requires job analysis to identify \nchanging competency models Data informs effective \ndecision-making around \nhuman capital Report Symposium on the Federal Workforce for the 21st Century20 Expand use of apprenticeships \nand development partnerships Purpose and practice: Companies are \nusing apprenticeship programs to build or reskill \ntalent in critical jobs that call for hard-to-acquire \nskill sets (e g , cybersecurity) or emerging skills \nareas for which competition is fierce across the \ngovernment and private sector The government \nhas the option to explore solutions such as \napprenticeships to build talent pipelines and reskill \nemployees Emerging technology apprenticeship \nprograms, for example, leverage models once \ndeveloped for trades Such employer-driven \nprograms allow organizations to grow their own \ntalent with on-the-job-training, formalized \nmentorship, and projects that groom employees to \ndevelop demonstrably desirable skills Google has \nfollowed a similar approach to reskill local workers \nto work in their new Lenoir Data Center Googles \npartnerships with academia and the private sector \nenable curriculum development relevant to the \napprenticeship 19 These apprenticeship programs aim to increase an \napprentices skill level and wages The U S De-\npartment of
Labor (DOL) points to the practice as \na proven solution for businesses and agencies to \nrecruit, train, and retain highly skilled workers Reg-\nistered Apprentice, the DOL program, offers a quick \nstart toolkit to help organizations establish viable \nefforts, reporting that approximately 400,000 \napprentices participate in 20,000 such programs \neach year Possible partners for these programs \ninclude labor organizations, local K-12 programs, \neconomic development agencies, community col-\nleges, state apprenticeship agencies, community \norganizations, and nonprofits and foundations 20 The University of Maryland, Baltimore County \n(UMBC) program is another example Originally \ndeveloped for the Department of Defense and \nthe Department of Homeland Security (DHS) the \nUMBC 10-year vetted course in cybersecurity \nleads to a career as a certified cybersecurity \noperator analyst 21 At the state level, Californias \nformal nontraditional apprenticeships and \npartnerships with the community college system \nprovide evening classes, enabling a mutually \nbeneficial relationship for both recruiting and \ncurriculum development 22 Actions\nPartner with the private sector and academia to \nestablish agreements with community colleges and \nonline learning institutes Prioritize the development of training and apprentice-\nship programs that focus on cybersecurity or other \nin-demand skills and difficult-to-fill positions Leverage established apprenticeship programs, (e g , \nthe Department of Labors Registered Apprentice \nprogram) as well as private sector and academic \nengagement to increase opportunities for veterans \nwho want to transition from the military or develop \nnew skills Considerations: Agencies must balance identifying early talent \nwith the need to have a competitive process \nthat encourages a broad range of applicants \nand provides opportunities that are consistent \nwith Merit Systems Principles Veteran advocacy groups could be helpful \npartners in identifying candidates for \napprenticeship programs Cybersecurity apprenticeship programs such as the one forged by the \ngovernor of Maryland, Maryland Department of Labor, and University of \nMaryland Baltimore County allow participants to earn semester credits \ntoward degree programs, while also receiving the on-the-job training \nand classroom instruction in a traditional apprenticeship 21The MITRE Corporation Build training and reskilling \ninto technology procurements Purpose and practice: Integrating reskilling \nand upskilling requirements into government \nprocurements for technology and services can help \nprepare employees for the impact of the change \nTraining and reskilling can help employees develop \nthe knowledge, skills, and abilities required to \nunderstand and use the technology and adjust to \nthe changing nature of their work It is a common \npractice to include user training in purchases for \nsoftware or new systems, and that is sufficient \nwhen the primary change impacting the employee \nis the transition from one tool to another But the \nmore significant challenge arises when the solution \nbeing acquired fundamentally changes the work \nand the way that work is performed Movement to digital platforms, wider use of \nrobotics and artificial intelligence, continual \nsoftware updates in Cloud environments, and \nthe large volumes of available data are just a \nfew drivers of growing complexity in the work \nenvironment While automation can increase \nproductivity and reduce the need for some \nforms of manual work, it also introduces new \nrequirements, new complexities, and new data into \nthe work itself To address this, some organizations \nare including in their technology procurements the \nrequirement that solution providers or separate \norganizations offer training on the work, not just \nthe product Doing so can accomplish several \nthings, including: developing an understanding of the new way \nof working and interacting with the system and \nwith others creating awareness of new possibilitiesthe \nhigher-value activities that the employee \ncan now perform because of the change \nto what they do (e g automating data \ncollection, cataloguing, or other largely \nroutine or administrative functions creates \nthe opportunity to focus on more analytics, \ndecision-making, or knowledge work) establishing early adopters within the \nworkforce These individuals can serve as \ncoaches and advocates, increasing employee \nengagement and understanding during \nacquisition processes that might otherwise \ncause concerns about job security Actions\nExplore the impact of this practice on key modern-\nization initiatives Work with a solution provider to define the type of \nadditional training needed to reskill or upskill the \nworkforce impacted by a specific modernization \nsolution Consider coupling this approach with the moderniza-\ntion Centers of Excellence (COE) effort This will cre-\nate a reference model that could be used to provide \nguidance to the acquisition community to incorporate \nrelevant language into procurements Consider this as a potential initiative on which to col-\nlaborate with labor Considerations: Success would require that functional subject \nmatter experts (SMEs) be made available by \nthe supplier In some cases, the supplier may \nhave only the technology expertise Therefore \nthe government should consider how to get \nthis additional work training if not available \nthrough the supplier itself This may affect the cost of these \nprocurements The government should \nconsider how to include the opportunity \ncost and the cost of other alternatives \n(e g , government-provided reskilling) in the \nevaluation of these procurements 22 Report Symposium on the Federal Workforce for the 21st Century expertise to design and develop an internal, \nemployee questionnaire Specific to the Census \nemployee experience, the survey aimed to help \nimplement policies, practices, and procedures \nto improve the Bureau and was created by a \ncross-directorate work group of managers and \nemployees with a focus on actionable results \nThe results helped guide the implementation of \nappropriate and realistic activities, policies, and \nprocedures to reach goals outlined in the U S \nCensus Bureau Business Plan for Change Actions:\nIdentify an initiative with shared interest and goals on \nwhich to collaborate Explore reskilling initiatives as opportunities to col-\nlaborate, given the benefits to both labor and man-\nagemente g , managers want to obtain hard-to-fill \nknowledge, skills, and abilities, and labor wants to \nprovide developmental opportunities that result in \nhigher salaries or continued employment Begin collaborative projects with a shared under-\nstanding of the agency and employee needs and \nmutually beneficial priorities, especially those that \nleverage in-house expertise Collaborate with labor \norganizations on an initiative \nwith clear outcomes and \nshared interests Purpose and practice: Symposium \nparticipants were optimistic about opportunities \nfor more collaborative conversations between \nlabor organizations and management Participants \nrecommended three essential practices: \nembracing a cooperative labor-management \nleadership model for the initiative, developing \nadvocates among the early adopters to support \ncommunication and build trust, and allowing \nparticipants to shape the effort to ensure that it is \npractical, while encouraging their commitment and \nbuy-in One exemplar discussed was the voluntary \nPortsmouth Shipyard Renewal of Shipyard \nValues and Pride (RSVP) program, which utilized \nmechanisms for sharing ideas and concerns \ntransparently, and for solving problems together The U S Census Bureau is another example of \nhow management and labor collaborate to engage \nemployees on proactive solutions For example, \nthe Census Organizational Climate Survey (OCS) \nharnessed the Bureaus internal survey statistical 23The MITRE Corporation Considerations: A baseline level of mutual trust and open \ncommunication is an essential starting point \nfor working on shared goals Participation in such programs should be \nvoluntary Establish a talent marketplace \nto increase mobility \nopportunities Purpose and practice: Trends suggest \nthat todays professionals value flexible career \npaths, lateral moves to allow for diverse job \nexperiences, and opportunities for lifelong \nlearning While employees frequently cite their \ndedication to mission, they also frequently \ncriticize federal agencies for providing insufficient \nopportunities for personal development and \ncareer advancement To address these perceptions, the government \nshould consider using a cross-governmental talent \nmarketplace; USAJOBS may be a foundation on \nwhich to build this more robust tool A marketplace \napproach would serve four purposes: better align \ntalent with work demands, enable greater mobility \nand visibility for career planning for employees, \nprovide transparent developmental rotation \nopportunities, and capture the evolving skills \nof government employees 23 The transparency \nand wide range of options provided via a talent \nmarketplace would allow government employees to \nactively participate in shaping their career paths The government currently has programs that \nenable rotations as part of leadership development \nprograms such as the Presidential Management \nFellows Program (PMF), agency Senior Executive \nServices Candidate Development Programs (SES \nCDP), and Presidents Management Council (PMC) \nInteragency Rotation Program These opportunities \nshould be leveraged more across all agencies An example of a large agency that is providing a \nbroad range of rotations to a large workforce is DHS DHS introduced a Joint Duty Program that \nprovides one-year detail assignments across \nits agencies (e g , U S Coast Guard, Federal \nEmergency Management Agency) Smaller \nagencies without the breadth of DHS would \nbenefit from connecting with other agencies to \nfoster career growth, and a talent marketplace can provide that connecting point Actions:\nExplore the viability of USAJOBS as the platform on \nwhich to build a talent marketplace, while also ad-\ndressing concerns about user experience, specifically \nease of searchability and clarity of the vacancy 24 Utilize the talent marketplace not simply as a \njob-posting system, but more broadly as a talent-\ninventory portal that allows employees to constantly \nupdate their skills, competencies, training, technical \ncredentials, and development goals Considerations: A critical success factor will be to create an \neffective funding strategy for developmental \nrotations; under current policy, the home \nmanager is often constrained by continuing to \nsupport the salary of the detailed employee \nwhile struggling to maintain resources for \nongoing operations in the home office This \ncan be a
disincentive for managers to support \nthe mobility of their staff A talent marketplace approach could \npotentially be leveraged for building talent \npools for critical, hard-to-fill positions The government will require substantial \nresources to develop a fully integrated, robust, \nand user-friendly talent marketplace 24 Report Symposium on the Federal Workforce for the 21st Century Develop managers to provide \nongoing, effective, feedback \nand coaching Purpose and practice: According to HBR, \norganizations need competent management just \nas much as they need analytical brilliance and \nshould invest in strengthening management \nthroughout the organization 25 In government, the \nsupervisor life cycleselection, orientation, devel-\nopment, performance, evaluation, and rewards\nneeds reform The GAO report Federal Workforce: \nInappropriate Use of Experts and Consultants at \nSelected Civilian Agencies notes that federal su-\npervisors sometimes lack effective skills, such as \nthe ability to identify, communicate, and help ad-\ndress employee performance issues 26 Addressing \nthese needs would benefit from a comprehensive \napproach to selecting and developing managers to \nensure a complement of engaged supervisors Agencies are required to train supervisors within \none year of initial appointment and follow up at \nleast every three years; nonetheless, a recent \nOPM survey showed the training results to be \ninconsistent across agencies The requirement \nincludes training on the supervisory skills that \nrelate to mentoring employees, improving \nemployee performance, conducting appraisals, \nand identifying unacceptable performance Only \n84% of agencies self-reported compliance with \nthe curriculum requirements for new supervisors, \nand only 63% responded that ongoing supervisory \ntraining requirements were covered 27 Adjusting performance management practices \nrequires that supervisors change their own be-\nhaviors first According to Alan Colquitt, author \nof Next Generation Performance Management, \nemployees of companies that have encouraged \nongoing feedback have reported dissatisfaction; \nthis is because more feedback does not necessar-\nily translate into better feedback 28 Organizations \nneed to train leaders and employees on how to \ngive and receive feedback, and to shift from judg-\ning to developmental feedback Compared with the private sector, government employees have a \nlower perception of their supervisors feedback \nFEVS data positive responses to the statement \nMy supervisor provides me with constructive \nsuggestions to improve my job performance as \n14% lower in government than in the private sector \nThe combination of clear expectations, frequent \nfeedback, training, and coaching may help improve \nperformance or build the evidence necessary to \nremove employees with below-par performance Actions:\nDevelop supervision competency models to include \nboth technical and management skills, as opposed to \npromoting based on technical competence alone To inform hiring decisions, use job analyses to doc-\nument that competencies fundamental for manage-\nment are present in the assessment Incorporate \nassessment instruments that evaluate a candidates \nmanagement-related competencies (e g , oral com-\nmunication, team building, and coaching) throughout \nthe selection process Use assessment tools such as \nrole-playing exercises and panel interviews to assess \nthese skills Establish an onboarding and probationary period for \nnewly selected and trained supervisors to assess \ntheir effectiveness in a people-management role Build leadership positions into the organizational \nstructure and ensure that employees are given the \nopportunity to lead projects or tasks Provide adequate training and support for supervisors \nto help build skills and encourage acceptance of a \ncoaching culture Allow sufficient time for supervisors to perform their \nsupervisory duties outside of their technical respon-\nsibilities and for employees to participate in discus-\nsions For example, MITRE allocates a budget for both \nsupervisors and employees to conduct conversations \nthat relate to performance outside of their usual proj-\nect work These conversations cover the employees \ncareer goals, training requests, and opportunities For \nthe government, such a shift may require a signifi-\ncant budget commitment, not easily acquired in the \ncurrent environment Considerations: The government should consider expanding the \nnumber of nonsupervisory senior leader (SL) \nand senior technical (ST) positions, of which \nthere are currently 1,283 (as of March 2018) 29 25The MITRE Corporation Career paths could also be developed for \nthose employees who are highly skilled \ntechnically and want to advance but are \nnot interested or skilled to serve in people-\nmanagement positions, with a potential goal \nof SL or ST positions Explore approaches for \naligning compensation with \nvalue and performance Purpose and practice: Private sector \napproaches to performance management suggest \nreduced emphasis on past ratings Instead \nthey favor ongoing feedback and performance \nmeasurement and compensation that is clearly \ntied to both performance (e g , results) and value \n(e g , skills and behaviors) Participants discussed \nperformance management systems that aligned \nemployee compensation with the roles, results, \nand behaviors that the employee had exhibited \nduring the previous performance cycle The \nprivate sector focuses on compensation aligned \nto the individual person and what that person \nhas achieved during the rating cycle as opposed \nto a ranking and rating system that compares \nindividuals to peers We recognize that this practice is fundamentally \ndifferent from the civil service rules in Title 5, \nwhich require agencies to structure compensation \nbased on the general schedule (GS) pay levels \ndescribed in 5 U S C Parts 51 and 53 (i e those \nassociated with the work performed in the \nposition) Paying employees based on position \nis the current standard because it allows for \nthe execution of Merit Systems Principles that \nrequire equal pay for equal work However, the \ncurrent system does not recognize individual \nemployees for their achievements beyond the \ninitial qualification standard for the position \n(e g , employees are not recognized for earning \nadditional degrees) The result is that while pay \nmay be relatively equal based on the position, \nperformance is not equal at an individual level \nThe goal of equal pay for equal work is an important principle; adding some differentiation \nbased on performance results and value can \nfurther strengthen the federal performance and \ncompensation system and help the government be \nviewed as a preferred employer for top talent This particularly complex and challenging oppor-\ntunity requires careful and close collaboration with \nemployees and labor organizations It does repre-\nsent a significant trend outside government, and \nthe government should explore how it might be \napplied in the federal workplace Actions:\nExplore compensation approaches that effectively \nbalance the importance of recognizing employees for \nindividual accomplishments, skills, and educational \nadvancement, with the importance of paying for the \nposition in a way that appropriately compensates \nequal pay for equal work Review the assessment and validation process that is \nused in government person-driven systems (e g , the mil-\nitary model in Title 10 and the Foreign Service in Title 22) Examine state models for hiring, promotion, and \nperformance management transformations (e g , Tennessee) 30 Considerations: This practice is fundamentally different from \nthe approach that the federal government has \ntraditionally taken in setting compensation \non GS pay levels described in 5 U S C Parts \n51 and 53, which are executed in the position \nclassification standards The government pay system dictates the \ntype of positions that are governed at each \nlevel on the GS schedule in the U S Code \nApplying Title 22 or Title 10 principles to \nthe Title 5 system, which is position driven, \nrepresents a monumental change that would \nrequire significant resources to legally defend \npromotion decisions An essential component of the effectiveness of \nthis change will be the previous recommenda-\ntion to develop managers to provide ongoing, \neffective feedback and coaching to their staff 26 Report Symposium on the Federal Workforce for the 21st Century Continuing the conversation\nAs OMB continues to take action to execute the workforce strategies in the PMA, there is \ngreat opportunity to build upon the engagement \nthat occurred at the symposium We recommend \nconvening a series of smaller events with cross-\nsector, topic-based groups periodically during the \nyear, to work on issues and problems or to focus on \nspecific recommendations We also recommend \nholding an annual Federal Workforce Symposium \nThe annual event can be both a culmination of the \nprevious years efforts, as well as an opportunity to \nestablish new focus areas for the coming year The data we gathered from symposium partic-\nipants and presenters validates that there is no \nlack of good ideas within and outside the federal \ngovernment Further, some of these ideas have \nbeen implemented not just in the private sec- tor, but also within government, in many cases as \ndemonstration projects or pilots As OMB chooses \nto test and implement any of these recommenda-\ntions, it should explore why demonstration proj-\nects have been minimally effective in generating \nlessons learned that other organizations can adapt \nin subsequent efforts Alignment of \nrecommendations with CAP \nGoal 3 subgoals \nAs the government reviews and prioritizes these \nrecommendations, we recommend considering \nhow the recommendations and specific, associat-\ned actions may support the CAP Goal 3 subgoals \nreferenced in the first section of this report Table \n1 provides a notional look at how the recommen-\ndations align to those subgoals CAP GOAL 3, WORKFORCE FOR THE 21ST CENTURYSUBGOALS Symposium Report Recommendations Actively Manage the \nWorkforce Improve Performance \nManagement & Engagement Develop Agile \nOperations Reskill & Redeploy \nHuman Capital Resources Acquire Top \nTalent Simple & Strategic \nHiring Increase use of partnerships for talent \nexchange programs Expand use of critical hiring authorities \nUse data science to develop evidence- \nbased HR strategies \nExpand use of apprenticeships and \ndevelopment partnerships \nBuild training and reskilling into \ntechnology
procurements \nCollaborate with labor organizations on an \ninitiative with clear outcomes and shared \ninterests Establish a talent marketplace to increase \nmobility opportunities \nDevelop managers to provide ongoing, \neffective, feedback and coaching \nExplore approaches for aligning \ncompensation with value and performance Table 1. Recommendations and CAP Goal 3 SubGoal alignment 27The MITRE Corporation CONCLUSION \nThe collective dialog, observations, and recommendations emerging from the Federal Workforce Symposium on September 12, 2018 represent an important step \nforward in advancing the goals in the PMA and creating broader public-private \ncooperation to address federal workforce challenges Stakeholders from across the \npublic and private sectors shared a common understanding of the challenges and \nopportunities facing all organizations today, and the federal workforce specifically \nWhile acknowledging obvious differences in their respective environments, common \nthemes did emerge, such as the need to harness the digital transformation so that \nit serves government and business workforce management and the importance of \npeople-driven strategies to successful transformation A key objective of the symposium was to cultivate new partnerships to help address \nthe governments challenges From the energy in the room and the feedback we \nreceived, we feel that the symposium succeeded in laying this foundation The key \nis now for OMB to take advantage of these new relationships and the openness and \ninterest that participants brought to the table Continue to build on that momentum \nby consistently engaging those who were there to get feedback on emerging \nstrategies and actions Reach out to those who could not attend to share what \noccurred and to bring them into future discussions And, finally, engage the federal \nlabor organizations in collaborative discussions focused on shared interests Looking \nahead, it is of vital importance to recognize that listening and learning about what \ncan and should be done should continue to come from voices inside and outside \nof the federal government As the symposium participants consider the outcomes \nof an event they created together, we recommend embracing the people-centered \nprocesses that enabled a full dayand a full futureof innovation on behalf of their \nmissions, their organizations, and their people As described in the PMA and in the discussions at the symposium, the commitment \nto change is long-term, and the partnerships the government needs to help solve \nproblems should be equally enduring The federal governments partners are ready \nand interested in advancing together As one participant said about the symposium \nattendees after the session: We should not let each of us go our separate ways, \ntaking action based on our individual perceptions without some reliance on that \ndiverse aggregate. I believe we need to move forward together. 28 Report Symposium on the Federal Workforce for the 21st Century A M Fadida Consulting Accenture ACT-IAC Administrative Conference of the United States Amazon American University Association for Talent Development Association of Government Accountants A-Z Consultant Services Bipartisan Policy Center Booz Allen Hamilton Boston Consulting Group CPS HR Consulting Definitive Logic Deloitte Consulting U S Department of Agriculture U S Department of Commerce U S Department of Defense U S Department of Education U S Department of Homeland Security U S Department of Housing and Urban Development U S Department of Justice U S Department of the Treasury Domestic Policy Council Eagle Hill Consulting Ernst & Young ETW Fannie Mae Federal Permitting Improvement Steering Council Federal Railroad Administration FedFusion General Services Administration George Mason University Mercatus Center George Washington University Georgetown University Government Matters Greater Washington Partnership Guidehouse Guild Education Harvard University Hemsley Fraser The Heritage Foundation HP Inc HumRRO IBEW IBM Center for the Business of Government ICF International, Inc Information Technology Industry Council Insight Venture Partners KSG Strategic Consulting Learning Tree International Markle Foundation McKinsey & Company Mercer Merit Network, Inc (Michigan) Micron Technology Microsoft Montville and Company, LLC National Academy of Public Administration National Institutes of Health National Nuclear Security Administration National Oceanic and Atmospheric Administration National Science Foundation NIC Federal Northrop Grumman U S Office of Management and Budget U S Office of Personnel Management Oracle Partnership for Public Service Professional Services Council Pymetrics Senior Executives Association Skillsoft Syracuse University Maxwell School of Citizenship \nand Public Affairs TVM Consulting University of Maryland Robert H Smith School of \nBusiness University of Phoenix University of South Florida The Volcker Alliance Willis Towers Watson APPENDIX: PARTICIPATING \nORGANIZATIONS 29The MITRE Corporation Endnotes\n1 Willis Towers Watson, 2018 2 https://www govexec com/management/2016/06/senate-moves-change-vets-preference-federal-hiring/129118/ 3 National Academy of Public Administration (NAPA), White Paper No Time to Wait, Part 2: Building a Public \nService for the 21st Century, September 2018 4 McKinsey Quarterly, Making a market in talent, May 2006 5 Corporate Executive Board (CEB), CEB Corporate Executive Leadership Council, Open Source Change: Making \nChange Management Work, 2016 6 Government Accountability Office (GAO), Federal Workforce: Additional Analysis and Sharing of Promising \nPractices Could Improve Employee Engagement and Performance, July 2015 Available: https://www gao gov/\nassets/680/671396 pdf 7 U S Merit Systems Protection Board, The Power of Federal Employee Engagement, 2008 8 FEVS, Partnership for Public Service Available: http://bestplacestowork org/BPTW/analysis/ 9 Career opportunities impact on retention: Glassdoor, February 2017, Why Do Workers Quit? The Factors that \nPredict Employee Turnover 10 Harvard Business Review, Reinventing Performance Management, April 2015 11 Harvard Business Review, Millennials Want to Be Coached at Work February 27, 2015 12 Greater Washington Partnership Report, Partnering to Strengthen Tech Talent in the National Capital Region, \nDecember 2017 13 U S Digital Service Available: https://www usds gov/mission 14 S V Howieson et al , Science & Technology Policy Institute, Federal Personnel Exchange Mechanisms, \nNovember 2013 Available: https://www google com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=9&-\ncad=rja&uact=8&ved=2ahUKEwjKqf_N793dAhUwrlkKHT2nC6YQFjAIegQIBRAC&url=https%3A%2F%2F-\nwww ida org%2Fidamedia%2FCorporate%2FFiles%2FPublications%2FSTPIPubs%2FD-4906 \npdf&usg=AOvVaw0BfwRF9h9ecxYg20oKX9SJ 15 GAO, Federal Workforce: Inappropriate Use of Experts and Consultants at Selected Civilian Agencies, July 1991 \nAvailable: https://www gao gov/assets/220/214696 pdf 16 OPM Available: https://www fedscope opm gov/ 17 U S C 5377 and 5 CFR part 535 18 Chief Human Capital Officers Council, Critical Position Pay Authority Available:\n https://chcoc gov/content/critical-position-pay-authority 19 Google Data Centers, Economic Impact and Community Benefit, April 2018 Available: https://static googleus-\nercontent com/media/www google com/en//about/datacenters/usstory/full-report/full-report pdfChief Human \nCapital Officers Council, Critical Position Pay Authority Available: \nhttps://chcoc gov/content/critical-position-pay-authority 20 A Quick-Start Toolkit: Building Registered Apprenticeship Programs Available: http://www nd gov/veterans/files/\nresource/apprenticeship_toolkit%20(2) pdf 21 Office of Governor Larry Hogan, Governor Larry Hogan, UMBC Training Centers Announce \nNew Cyber Apprenticeship Program Available: http://governor maryland gov/2018/05/31/\ngovernor-larry-hogan-umbc-training-centers-announce-new-cyber-apprenticeship-program/ 22 State of California Department of Industrial Relations, Find an apprenticeship program Available: \nhttps://www dir ca gov/databases/das/aigstart asp 23 McKinsey Quarterly, Making a market in talent, May 2006 24 J Davidson, Washington Post, Will update fix main problems with USAJOBS, the federal jobs board? Available: \nhttps://www washingtonpost com/news/powerpost/wp/2016/02/28/will-update-fix-main-problems-with-usa-\njobs-the-federal-jobs-board/?noredirect=on&utm_term= cd5a97c620e3 25 Harvard Business Review, Vol 95, Issue 5, Why do we undervalue competent management? Neither great leader-\nship nor brilliant strategy matters without operational excellence, pp 120-127, September/October 2017 https://www.govexec.com/management/2016/06/senate-moves-change-vets-preference-federal-hiring/129118\nhttps://www.gao.gov/assets/680/671396.pdf\nhttps://www.gao.gov/assets/680/671396.pdf\nhttp://bestplacestowork.org/BPTW/analysis/\nhttps://www.glassdoor.com/research/studies/why-do-workers-quit/\nhttps://www.glassdoor.com/research/studies/why-do-workers-quit/\nhttps://www.glassdoor.com/research/studies/why-do-workers-quit/\n http://retentionconsortium.org \nhttps://www.usds.gov/mission\nhttps://www.usds.gov/mission\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=9&cad=rja&uact=8&ved=2ahUKEwjKqf_N793dAhUwrlkKHT2nC6YQFjAIegQIBRAC&url=https%3A%2F%2Fwww.ida.org%2Fidamedia%2FCorporate%2FFiles%2FPublications%2FSTPIPubs%2FD-4906.pdf&usg=AOvVaw0BfwRF9h9ecxYg20\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=9&cad=rja&uact=8&ved=2ahUKEwjKqf_N793dAhUwrlkKHT2nC6YQFjAIegQIBRAC&url=https%3A%2F%2Fwww.ida.org%2Fidamedia%2FCorporate%2FFiles%2FPublications%2FSTPIPubs%2FD-4906.pdf&usg=AOvVaw0BfwRF9h9ecxYg20\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=9&cad=rja&uact=8&ved=2ahUKEwjKqf_N793dAhUwrlkKHT2nC6YQFjAIegQIBRAC&url=https%3A%2F%2Fwww.ida.org%2Fidamedia%2FCorporate%2FFiles%2FPublications%2FSTPIPubs%2FD-4906.pdf&usg=AOvVaw0BfwRF9h9ecxYg20\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=9&cad=rja&uact=8&ved=2ahUKEwjKqf_N793dAhUwrlkKHT2nC6YQFjAIegQIBRAC&url=https%3A%2F%2Fwww.ida.org%2Fidamedia%2FCorporate%2FFiles%2FPublications%2FSTPIPubs%2FD-4906.pdf&usg=AOvVaw0BfwRF9h9ecxYg20\nhttps://www.gao.gov/assets/220/214696.pdf \nhttps://www.gao.gov/assets/220/214696.pdf\nhttps://www.fedscope.opm.gov/\nhttps://www.fedscope.opm.gov/ \nhttps://chcoc.gov/content/critical-position-pay-authority\nhttps://static.googleusercontent.com/media/www.google.com/en//about/datacenters/usstory/full-report/full-report.pdf\nhttps://static.googleusercontent.com/media/www.google.com/en//about/datacenters/usstory/full-report/full-report.pdf\nhttps://chcoc.gov/content/critical-position-pay-authority\nhttps://chcoc.gov/content/critical-position-pay-authority \nhttp://www.nd.gov/veterans/files/resource/apprenticeship_toolkit%20(2).pdf\nhttp://www.nd.gov/veterans/files/resource/apprenticeship_toolkit%20(2).pdf\nhttp://governor.maryland.gov/2018/05/31/governor-larry-hogan-umbc-training-centers-announce-new-cyber-apprenticeship-program/\nhttp://governor.maryland.gov/2018/05/31/governor-larry-hogan-umbc-training-centers-announce-new-cyber-apprenticeship-program/\nhttps://www.dir.ca.gov/databases/das/aigstart.asp\nhttps://www.dir.ca.gov/databases/das/aigstart.asp \nhttp://governor.maryland.gov/2018/05/31/governor-larry-hogan-umbc-training-centers-announce-new-cyber-apprenticeship-program/\nhttps://www.washingtonpost.com/news/powerpost/wp/2016/02/28/will-update-fix-main-problems-with-usajobs-the-federal-jobs-board/?noredirect=on&utm_term=.cd5a97c620e3\nhttps://www.washingtonpost.com/news/powerpost/wp/2016/02/28/will-update-fix-main-problems-with-usajobs-the-federal-jobs-board/?noredirect=on&utm_term=.cd5a97c620e3 30 Report Symposium on the Federal Workforce for the 21st Century 26 GAO, Federal Workforce: Improved Supervision and Better Use of Probationary Periods Are Needed to Address \nSubstandard Employee Performance Available: https://www gao gov/assets/670/668339 pdf 27 FEDweek, OPM Finds Training of Supervisors to Be Inconsistent, July 5, 2018 Available: \nhttps://www fedweek com/issue-briefs/opm-finds-training-of-supervisors-to-be-inconsistent/ 28 Alan Colquitt, Generation Performance Management 29 Alan Colquitt, Generation Performance Management OPM Available: https://www fedscope opm gov/ 30 Government Executive Agencies Could Learn a Lot From Tennessees Shift to Pay for Performance, 2017 \nAvailable: https://bit ly/2RWov1l Photo Credits\nCover Photo credit: National Institute of Standards and Technology, \nPhoto credit: Nuclear Regulatory Commission, Courtesy of Wolf Creek Nuclear Operating Corp \nPhoto credit: U S Department of Agriculture (USDA) \nPhoto credit: National Institute of Standards and Technology \nPhoto credit: Senior Executives Association \nPhoto credit: United States Department of Agriculture \nPhoto credit: United States Department of Agriculture, Anson Eaglin \nPhoto credit: U S Department of Energy, Savannah River Site \nPhoto credit: Department of Energy, Lynn Freeny \nPhoto credit: U S Marine Corps, Lance Cpl Tojyea G Matally \nPhoto credit: National Institute of Standards and Technology, \nPhoto credit: U S Department of Agriculture, Anson Eaglin \nPhoto credit: National Institute of Standards and Technology \nPhoto credit: U S NAVY https://www.gao.gov/assets/670/668339.pdf \nhttps://www.gao.gov/assets/670/668339.pdf \nhttps://www.fedweek.com/issue-briefs/opm-finds-training-of-supervisors-to-be-inconsistent/\nhttps://bit.ly/2RWov1l 31The MITRE Corporation MITRE is a non-profit company chartered in \nthe public interest to address issues of national \nimportance From MITREs unique vantage \npoint working across federal, state, and local \ngovernments, as well as industry and academia, \nwe work in the public interest to discover new \npossibilities, create unexpected opportunities, and \nlead by pioneering together for public good Our \nmission-driven teams are dedicated to solving \nproblems for a safer world Today, MITREs work and \nindependent research tackle challenges that impact \nthe safety, stability, security, and well-being of our \nnation through its operation of federally funded \nresearch and development centers (FFRDCs) as well \nas participation in public-private partnerships 32 Report Symposium on the Federal Workforce for the 21st CenturyMITREwww mitre org Introduction \n Background and Purpose \n The Presidents Management Agenda: mission, service, stewardship\n The Federal Workforce Symposium: sharing experiences from the private and public sectors\n The changing nature of work: mission, service, stewardship in the digital age\n About this report What We Learned \n Challenges \n Opportunities Recommendations \n Increase use of partnerships for talent exchange programs\n
Expand use of critical hiring authorities\n Use data science to develop evidence-based HR strategies\n Expand use of apprenticeships and development partnerships \n Build training and reskilling into technology procurements \n Collaborate with labor organizations on an initiative with clear outcomes and shared interests\n Establish a talent marketplace to increase mobility opportunities \n Develop managers to provide ongoing, effective, feedback and coaching\n Explore approaches for aligning compensation with value and performance\n Continuing the conversation\n Alignment of recommendations with CAP Goal 3 subgoals Conclusion \n Appendix: Participating Organizations ",
    "text": " Authors \nEdward Y. Hua, PhD \nDouglas Flournoy Contributors\nSaurabh Mittal, PhD\nAnthony Rood\nJacob Richkus September 2018 An Exploratory \nStudy on Interfacing the Simulation \nTraining Exercise Platform (STEP) with \nOperational \nSimulators The views, opinions and/or findings contained \nin this report are those of The MITRE \nCorporation and should not be construed as an \nofficial government position, policy, or decision, \nunless designated by other documentation. \nRESERVED. Approved for Public Release; \nDistribution Unlimited. 18-3705 Document No: MTR-T842-B-3067\nMcLean, VA Abstract\nThis report introduces the Simulation Training Exercise Platform (STEP) technology. One of its core capabilities is mapping the effect-impact relationship between the cyber and \noperational domains within a simulation environment. With this technology we aim to \naddress the problem of understanding precisely how effects in one domain could propagate \nto the other and manifest into certain impact in a complex simulation environment. STEP \ncould bring benefits to a broad range of sponsors, both military and civilian, who are \nentrusted with mission-critical responsibilities through analyzing simulation data. We also \nidentify three technical hurdles that could affect sponsor acceptance of STEP and lay out a \ntransition path to the relevant sponsors. Executive Summary\nWe introduce the Simulation Training Exercise Platform (STEP), a technology developed by the Carnegie Mellon Universitys (CMU) Software Engineering Institute (SEI). As a cyber \nsimulator that can be interfaced with a mature operational simulator, one of its core \ncapabilities is to trace the effect-impact relationship between the cyber and operational \ndomains in the simulation environment. STEP has gained traction within the DOD, where it \nis being applied in several DOD-sponsored cyber exercises. A long-standing problem in the Modeling & Simulation (M&S) community is the lack of \nability to trace and study how effects from one domain would propagate to result in an \nimpact in the other domain. Failure to do so makes it difficult to diagnose the root cause of \nan adverse impact in the simulation space. In addition, DOD simulations have not kept up \nwith the current reality of more blended missions on the battlefield, which could leave \ndecision makers ill-prepared for real-life crises. Sponsors, such as the Army Research Lab (ARL) and the Federal Aviation \nAdministration (FAA), have expressed strong interest in adopting STEP in their respective \nsimulation environments. However, there are some technical hurdles that need to be \naddressed before STEP could find acceptance among a diverse group of sponsors. These \ninclude properly evaluating the effectiveness, versatility, and scalability of STEP. The applicability of STEP to the Army and FAA sponsors requires a well-defined \ntransition path based on studying their respective operational simulators and \ncontextualizing STEP within these two domains. v Table of Contents Abstract \nExecutive Summary \nTable of Contents \nList of Figures \n1. Introduction to Simulation Training Exercise Platform \n2. Current State-of-the-Art \n2.2 Latest STEP Enhancements \n3.1 Sponsor Engagement \n3.2 Benefits to Sponsors \n3.3 Sponsor Acceptance \n5. Transition Paths \n6. Conclusions \nAbbreviations & Acronyms \nFigure 1. Illustration of how STEP realizes CKEI between the cyber and operational \ndomains \nFigure 2. Cross-domain interactions in the simulation space \nIn a simulation environment comprising a cyber domain and an operational domain, the progression of a simulation run is driven by the myriad interactions between the domains. Such \ninteractions are typically initiated by some effect in one domain, which then propagates to the \nother domain and results in an impact in the target domain, as observed by the simulation \noperator governing the simulation. The Simulation Training Exercise Platform (STEP) is a cyber simulator that provides training \nin various cybersecurity fields, such as Information Assurance (IA), incident response, and \ncomputer forensics. First developed at Carnegie Mellon Universitys (CMU) Software \nEngineering Institute (SEI) in 2003, STEP has undergone periodic and incremental upgrades. \nOver the last 15 years of evolutionary development, it has now reached a high level of maturity \nand stability. One of the key features of STEP is its ability to accurately map out the cross-\ndomain effect-impact relationship; this is achieved through an SEI-defined Application Program \nInterface (API) called Cyber-Kinetic Effects Integration (CKEI) [2]. STEP traces the inter-domain effect-impact relationship by re-creating the domain space \nwhere the impact would be manifested. Figure 1 illustrates this approach, using STEP interfaced \nwith the Army OneSAF simulator as an example. In the operational simulation domain where \nOneSAF operates, on identifying a target, the Forward Observer (FIS) sends a report to the \nBattalion (BN), which then relays the information to the Brigade (BDE). BDE issues the Call For \nFires (CFF) order, sends it to BN, which forwards this message to the Battery. The Battery then \nassigns the actual firing to the particular Gun, which executes the CFF order to fire on the \ntarget. Figure 1. Illustration of how STEP realizes CKEI between the cyber and operational domains. In the cyber domain, STEP creates a virtual copy of each physical device, as well as the ii networking that connects these devices, that participates in the CFF order propagation \nthroughout the echelon. The states of these virtual nodes at any given time closely mirror those \nof their counterparts in the operational domain. Each physical node that receives the CFF \nmessage routes it to the next intended recipient via its virtual counterpart, which then forwards \nit to the virtual counterpart of the intended recipient, who then passes it to the recipient in the \noperational domain. If the nodes in the operational domain (OneSAF) are compromised on the \ncyber side, the virtual nodes in STEP update their state and any associated communications \nmessage accordingly. Current State-of-the-Art2.\nAt the present, STEP is primarily being tested by the DOD, specifically the Army. SEI continues to expand its capability set with new features and enhancements to support ever-\nincreasingly complex simulation scenarios. Pairing STEP with Operational Simulators2.1\nAccording to SEI, there are currently two methods of pairing STEP with a mature operational simulator. In the first method, SEI provides an external interface to link STEP with the \noperational simulator at the customers site. When a simulation scenario is set up, the customer \nworks closely with SEI to define the detailed requirements on the effects to be introduced into \nthe cyber domain. SEI is then responsible for configuring STEP and implementing these effects. \nThis work is transparent to the customer, who continues to focus on setting up the operational \ndomain for the scenario. The Army is currently testing STEP with two of its simulators, OneSAF \nand VBS3, via this external-interfacing approach. In the second method, the customer receives a copy of the STEP software from SEI and \ninstalls it at their site. The customer is responsible for configuring the STEP and interfacing it \nwith its operational simulator. To help them do this, the STEP package includes a suite of \ntutorial videos that train operators how to set up and configure the desired effects. STEP has \nbeen used in several DOD-organized exercises such as Cyber Flag and Cyber Guard. Both methods have been tested in DOD-sponsored exercises. Latest STEP Enhancements2.2\nThrough periodic cycles of development, SEI is constantly expanding STEPs feature set to support cyber training in more complex and diverse simulation environments. The aim is to \nmake STEP more agile and modular. Some of the most recent enhancements added to STEP \nfollow. These features are all optional and their absence from STEP does not affect our study of \neffect-impact relationship mapping. TopoMojo: The current STEP contains a rich set of features that may not all be \napplicable to a particular customers needs. The set could also create the problem of \ninflexibility in installation and deployment. In response, TopoMojo was developed as the \nlightweight version of STEP. It retains the key features of STEP, such as CKEI, while \nremoving others. iii WELLE-D: This is a tool that simulates wireless communications. It can be used to model \nOpen Systems Interconnect (OSI) Layer-2 (MAC-layer) wireless links. \nSCADASIM: This feature allows the cyber operator to manipulate SCADA systems \n(power, lighting, security cameras, etc.) during a simulation run. It contains several \ncomponents, such as Human-Machine Interface (HMI) and a Historian that archives the \nlog files. \nGHOSTS: This application tracks the real-time status (e.g., health check) of all server \nactivities during a simulation run. It uses a PostgreSQL database to archive all data \npertaining to activities in the simulation space. Data visualization is achieved through the \nuse of a GUI, which includes a number of more commonly used performance metrics. \nThe user can also write his/her own PostgreSQL script to extract relevant data from the \ndatabase for more in-depth analysis. \nGreyBox: This is a tool that runs on a Virtual Machine (VM) to model the entire Internet (\nInternet in a box). One use case of GreyBox is to study a Local Area Network (LAN) in \nthe context of global Internet. The LAN can be seen as one entity, and the rest of the \nInternet another entity; the two are connected via a gateway. \nCartographer: This feature is used to validate the network deployed prior to simulation \ncommencement. It is intended to minimize human mistakes when manually entering \nhundreds of IP addresses for a large simulation scenario. Once launched, Cartographer \ncan identify errors in the
IP address space in a matter of minutes. This tool can be used \nto check for errors from OSI Layer 3 (IP) up to OSI Layer 7 (Application). Applicability to Sponsors3.\nDue to the high volume and complexity of cross-domain interactions, mapping a relationship between the effect in one domain and its impact in the other is a daunting challenge (Figure 2). \nFailure to accurately capture this effect-to-impact play makes it difficult to investigate the root \ncause of an adverse impact. Furthermore, current DOD simulation environments are unable to \nkeep up with detailed cross-domain interplay on the battlefield, where cyber operators and \nkinetic operators work alongside each other in increasingly blended missions. The lack of \nrealism representing blended missions in the simulation space makes the decision makers ill \nprepared to manage real-life crises. iv \nFigure 2. Cross-domain interactions in the simulation space. Sponsor Engagement3.1\nIn this project, we have engaged with three sponsorsthe Army, the FAA, and the Air Forceto gauge their interest in STEP and identify suitable operational simulators for study. The Point-of-Contact (POC) for Army Research Lab (ARL) Survivability Lethality Analysis \nDirectorate (SLAD), who came across a proof-of-concept demonstration of STEP integrated with \nthe OneSAF simulator, expressed a desire to pursue further study of this technology. The Aviation Cybersecurity group in support of all FAA simulation activities had been \nconducting their own investigation of effect-impact interactions. On learning of STEP, they were \ninterested in a collaborative study to see how its benefits aligned with the sponsor interests. We also exchanged communication with the Computing Infrastructure and IT Service \nManagement group, which supports Air Force simulations using the AFSIM simulator. Because \nintegrating STEP with AFSIM would require that STEP be embedded to become part of the \nAFSIM, this did not fit our original design in which we would maintain two separate domains. \nConsequently, we decided not to pursue collaboration with them at the present time. Benefits to Sponsors3.2\nSTEP can bring a host of benefits to various sponsors, both military and civilian. It provides a robust platform to evaluate the strengths and weaknesses of new tools and capabilities prior to \nprocurement. It allows stakeholders to design and execute more realistic simulation \nexperiments showing how a cyber component would allow or prohibit information exchange \nbetween operational facilities. Furthermore, it gives simulation operators a means to investigate \ncyber threats as rigorously as other threats that could negatively impact the mission outcome. For the Army sponsor, STEP could be used to examine, the impacts of cyber effects on the \ngathered intelligence on the battlefield (whether it is legitimate or compromised) to assist \ncommanders in making more informed decisions. It could also enhance training to study how \ncyber effects could maximize operational impact before being applied to real-life missions. v Finally, it would enhance training for cyber operators, reflecting the reality of more blended \nmissions. For the FAA sponsor, STEP would enhance the effectiveness and realism of cybersecurity \nexercises for the FAA and its aviation sector partners; this in turn would increase the value of \nsuch exercises to the stakeholders. It could also improve the effectiveness of air traffic \noperational incident response during a suspected/confirmed cybersecurity incident. Sponsor Acceptance3.3\nThe Army was the earliest adopter of STEP in several of its simulation exercises. They have shown a strong interest in continuing study on STEP and making it an integral part of its \nsimulation environment. The FAA sponsor was recently introduced to the capabilities of STEP. It has expressed \nwillingness to partner with us and further explore the potential benefits it may bring to the FAA \nand its aviation-industry partners. The Integration Experimentation and Demonstration for \nAeronautics (IDEA) lab hosts a sophisticated simulation apparatus that could be interfaced with \nSTEP. We expect to produce tangible results in the near future to demonstrate its applicability \nto this sponsor. Furthermore, we plan to invite other sponsors to participate in this study, which would \nallow us to explore the versatility of STEP. Technical Hurdles4.\nSTEP promises to bring many benefits. Yet to reach a larger group of sponsors, we need to address the following three considerations that could impede its wider acceptance.\nFirst, there currently is no systematic approach to evaluating the accuracy of STEP in tracing an effect-to-impact relationship. The high volume and complexity of cross-domain interactions \nin the simulation space could lead to a certain effect manifesting into unintended impacts, as \nwell as impacts of higher orders. How to quantify the impact that deviates from the expected \noutcome, and how to identify higher-order impacts that may be considered negligible, requires \nfuture study and research. Second, the question remains unanswered as to the versatility of interfacing STEP with a \nbroad range of operational simulators. STEP was designed to be compatible with any mature \noperational simulator. To the best of our knowledge, currently STEP has only participated in \ncyber simulations and exercises with the Army and remains untested by other services and \nagencies. It would be necessary to collaborate with multiple sponsors and interface STEP with \ntheir respective simulators to validate its versatility. Third, the scalability of adopting STEP in a simulation scenario should not be ignored. STEP \nrealizes the CKEI by creating a virtual copy of the domain where the impacts are manifested (as \nshown in Figure 1). The virtual copy includes each device and networking connection that is \ninvolved in manifesting the impacts [3]. As the simulation scenario grows in size and complexity, \nmore computing resources are needed to generate and sustain this virtualization, potentially at \nthe expense of other aspects of the simulation. A careful examination of the scalability of the \nuse case with a STEP deployment would help define a more robust scope of the simulation in \nwhich the capabilities of STEP could be fully and accurately realized. vi Transition Paths5.\nWe have identified two transition paths to move forward with our STEP study with the Army and FAA sponsors:\nFor the Army sponsor, interface STEP with OneSAF and develop use cases that \nexamine the impacts that system-level cyber vulnerabilities may have on warfighting \nmissions. \nFor the FAA sponsor, leverage the IDEA lab to develop use cases that demonstrate \nthe impact of some operational effects on the underlying communications network \nduring air traffic control operations. Conclusions6.\nThis report introduced STEP, a cyber-domain training technology developed at the CMU SEI that can trace inter-domain effect-impact relationships within the simulation environment. We \nevaluated the feasibility of deploying STEP with two operational simulators utilized by two \nsponsors: ARL and FAA, one military and one civilian. In our findings, STEP could bring benefits \nto either sponsor by assisting users to make critical decisions based on high-fidelity, simulation-\nbased analysis. As an initial step, STEP does provide mechanisms to identify and define cross-\ndomain effects and impacts. However, its potential use in an exhaustive simulation exercise \nneeds further evaluation. STEPs versatility and accuracy for mapping out the effect-impact \nrelationship may depend on how it would handle the scalability of the simulation space. Both \nArmy and FAA sponsors are interested in further collaborative study to evaluate STEP in realistic \nscenarios. Acknowledgements The authors gratefully acknowledge the contributions made by Rotem Guttman (Carnegie \nMellon University/Software Engineering Institute/CERT). References\nDaiello, C., Hancock, K., Surdu, J., and Lacks, D., Cyber Effects within a Kinetic Model, 1.\nInterservice/Industry, Training, Simulation, and Education Conference (I/ITSEC), No. 17181, \nNov. 2017.\nGuttman, R., Combined Arms Cyber-Kinetic Operator Training, SEI Blog, March 2017.2.\nHua, E., and Guttman, R. Personal Communication, 2018.3. Abbreviations & Acronyms API Application Program Interface ARL Army Research Laboratory vii BDE Brigade BN Battalion CERT Computer Emergency Response Team CFF Call For Fires CKEI Cyber-Kinetic Effects Integration CMU Carnegie Mellon University DOD Department of Defense FAA Federal Aviation Administration FIS Forward Observer HMI Human-Machine Interface IDEA Integration Demonstration & Experimentation for Aeronautics LAN Local Area Network M&S Modeling and Simulation MESA Modeling Environment for Service Oriented Architecture Analysis OSI Open Systems Interconnection POC Point-of-Contact SCADA Supervisory Control and Data Acquisition SEI Software Engineering Institute SLAD Survivability & Lethality Analysis Directorate STEP Simulation Training Exercise Platform VM Virtual Machine _GoBack\n _Toc525979042\n _Toc528138516\n _Toc525979043\n _Toc528138517\n _Toc525983247\n _Toc528138518\n _Toc525983248\n _Toc528138519\n _Ref524090665\n _Toc525979044\n _Toc528138520\n _Ref526066312\n _Toc527529042\n _Toc525983151\n _Toc525983250\n _Toc525979045\n _Toc528138521\n _Toc525983153\n _Toc525983252\n _Toc528138522\n _Toc525979047\n _Toc528138523\n _Toc525983156\n _Toc525983255\n _Toc525979048\n _Toc528138524\n _Ref525981443\n _Toc527529043\n _Toc525983158\n _Toc525983257\n _Toc525979049\n _Toc528138525\n _Toc525983160\n _Toc525983259\n _Toc525979050\n _Toc528138526\n _Hlk524513431\n _Toc525979051\n _Toc528138527\n _Toc525979052\n _Toc528138528\n _Toc528138529\n _Toc525979053\n _Toc528138530\n _Toc525979054\n _Toc525979055\n _Toc528138531\n _Ref524159578\n _Ref524183684\n _Toc525979056\n _Toc528138532 ",
    "text": " Interns Develop Software Tool for Air Operations (a Student Voices article) When college students Ryan Vinh and Akhil Jacobs came to MITRE for a summer internship, they got a \nchallenging assignmenthelp develop software for improving air tasking orders (ATO) for a military \nsponsor. ATOs organize air operations in a military environment to maximize efficiency and effectiveness \nwhile minimizing the dangers of having multiple types of air operations occurring in the same airspace. \nTo accomplish this work, Vinh and Jacobs worked with MITREs Derek Lax. This project started shortly before Vinh and Jacobs began their summer internships. MITRE staff working \nfor the sponsor suggested developing a software tool to automate the compilation of filtered ATO \nreports while also reducing the chances of inadvertently releasing sensitive information. The current \nmethod of modifying these daily reports was manually intensive and time consuming. Lax, Vinh, and Jacobs took on the challenge of developing a prototype for automating these processes. \nLax led the overall software development effort. Vinh, a junior at Princeton majoring in computer \nscience, and Jacobs, a junior at Rensselaer Polytechnic Institute majoring in computer systems \nengineering and computer science, wrote much of the code. Time Spent Becomes Time Saved Working together, the three-person team developed the prototype for an automated tool that reads the \ndaily reports and parses themand does it in a fraction of the time, eliminating human error. What \ntook roughly 30 minutesassuming everything went well, which it didnt alwayswas reduced to \nbetween one and two minutes using the new tool, Lax says. Once they had a prototype done, Vinh and Jacobs helped present their findings to the sponsor. The team \nstayed in constant contact with the military end-user throughout the development period. This steady \nstream of user feedback afforded them valuable insight to adjust an existing feature or add a new \nfeature using an Agile development methodology. In addition, software bugs were addressed during \ndevelopment. The entire effort took approximately three months. Another aspect of this project was to use this tool development as an exemplar of the Continuous \nIntegration/Continuous Delivery toolchain used in MITREs Networked Experimentation, Research, and \nVirtualization Environment (NERVE). The team introduced the prototype into the environment and \nsuccessfully demonstrated how code changes could be easily introduced, tested and made ready for end-\nuser inspection. Making a Difference The hard work of Lax, Vinh, and Jacobs paid off. With additional help from the sponsor, the tool received \n\"Authority to Operate with conditions\" and as of mid-June 2018 is being used in day-to-day operations. Both Vinh and Jacobs are ecstatic about the hands-on experience they received during their internships \nat MITRE. It really felt like I was making a difference in the real world, Jacobs says. Adds Vinh: I never \nthought I would actually work on a project with so much impact and visibility. I never expected to help \ncreate something this summer that could be deployed to actual warfighters, let alone something that we \nwould present to high-ranking officers! They were both extremely bright and quick to learn, Lax says of the two. They quickly adapted to the https://www.mitre.org/publications/project-stories/it-takes-nerve-to-bring-isolated-labs-people-together new tools. It was a pleasure to work with them. by Tom Nutile If these or any of our many intern opportunities interest you, check out our current Job Openings or read \nmore about our Student Programs. Approved for Public Release; Distribution Unlimited 18-1531 https://www.mitre.org/careers/job-openings/\nhttps://www.mitre.org/careers/student-programs/student-voices _top\n _Hlk497296269\n _Hlk496613984\n _GoBack ",
    "text": " PowerPoint Presentation ICS Cyber Risk Management Workshop Government of the Republic of Ghana\nOctober 23-26, 2018 Accra, Ghana Otis Alexander\nLead Cybersecurity Engineer Cedric Carter\nSenior Cyber Systems Engineer Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-3595 | 2 | Agenda Understanding the ICS Landscape Threats to ICS ICS Security Guidelines ICS Security Considerations Assessing Risks to ICS Cyber Risk Management Framework Exemplar U.S. DOE ONG-C2M2 References | 3 | Understanding the ICS Landscape | 4 | Understanding the ICS Landscape Industrial Control System (ICS) is a general term that encompasses several \ntypes of control systems including: Supervisory Control and Data Acquisition (SCADA) systems Distributed Control Systems (DCS) Other control system configurations such as skid-mounted Programmable \nLogic Controllers (PLC) ICS are specialized Information Systems that physically interact with the \nphysical environment Many ICS are components are considered to be Critical Infrastructure ICS is considered to be Cyber Enabled devices | 5 | Where are Industrial Control Systems (ICS) located? Hydro Power Manufacturing Oil & Gas Water Treatment Navy Ships Power Systems ICS found in Critical Infrastructure | 6 | ICS DCS (Distributed Control System) Tightly integrated control system solution, typically provided by one vendor SCADA (Supervisory Control and Data Acquisition) Front End software used to Integrate multiple independent Programmable Logic \nControllers (PLCs) into one system, providing equivalent capability of a DCS SIS (Safety Instrumented Systems) Independent control system for safety and protection ICS includes DCS, SCADA, & SIS HMI (Human Machine Interface) Displays Typical Control Center for ICS | 7 | DCS Examples Electric Power Generation Manufacturing Refineries DCS is a integrated control system solution | 8 | SCADA Examples SCADA systems are used in the electricity sector, oil and gas pipelines, water utilities, transportation networks and other applications requiring remote monitoring and control. Source: automationghana SCADA environments are remotely operated | 9 | SIS Examples Safety instrumented systems consist of an engineered set of hardware and software controls which are especially used on critical process systems SIS are independently operated for safety means | 10 | ICS Characteristics Real-Time Control of Devices (i.e., actuators, breakers, valves) Gathers and Displays Data from Local/Remote Sensors Alerts for Alarms and Events Includes Hardware, Software, & Communication Components ICS Receives Sensor Inputs & Controls Physical Things Software\n(Control Logic) End \nDevice(s) Sensor(s)\nActionInput Actuators, \nBreakers, \nValves, Pumps, \nMotors, etc. Temperature, \nPressure, \nFlow, \nPosition, etc. Operator \nInterface Status, Alarms, \nHuman Input, \netc. | 11 | ICS Uniqueness IT ICS Security Objective (Focus)\nConfidentiality\nIntegrity Availability\nIntegrity Life Time Expectancy & Refresh rate 3 5 Years 10 20 Years + Patch Deployments/ Software & Anti-Virus \nUpdates Regularly Scheduled, Some Pre-Testing, Reboots Thorough Testing (Slow and Vendor Must Also Test), No Reboots Message Format Varies Well Defined Content Components & Software Standard, Familiar to IT Personnel\nCustom Built, Unfamiliar to IT Personnel, Trust Needed within Zones & \nLevels Networks Large, Change Often, Uses DHCP\nSmall, Many, Do Not Change Often, Static Addressing, Different \nProprietary Protocols, Deterministic, Traffic Content Known, Zones, & \nLevels Time Outages and Delays are Mostly Acceptable\nOutages and Delays are Normally Unacceptable, Functions are Time \nDependent Performance\nNon-Real-time, Response must be reliable, Hight throughput \ndemanded, High delay, variation is accepted Real-time, Response is time critical, Modest throughput accepted, \nHigh delay, variation is a concern Reliability Requirements\nScheduled operation, Occasional failures tolerated, Beta \ntesting in the field acceptable Continuous operation, Outages intolerable, Thorough testing expected Risk Management\nData integrity paramount, Risk impact is loss of data, loss of \nbusiness operations, Recover by reboot Human safety paramount, Risk Impact is loss of life, Equipment or \nproduct, Environmental damage, Fault tolerance essential ICS is Different than IT | 12 | Adversaries are Increasingly Targeting ICS Legacy ICS connected to the Internet & NOT Prepared to Detect Attacks | 13 | Ukraine Power Grid (Substations)\nICS Cyber Attack Source: SANS.org Phishing Emails BlackEnergy3 \n(Malware Installed) VPN & Credential Theft Network & Host Discovery Power \nOutages Malicious Firmware \nDevelopment SCADA Hijack (HMI/Client) Breaker Open Commands UPS Modification Firmware Upload KillDisk Overwrites Business Network Intrusion ICS Attack Stage 1: Stage 2: | 14 | Cyber Security Challenges Many Possible Pathways into ICS Connected to the \nInternet, IT Systems, \nVendors Different Protocols \n(DNP3, Modbus, \nProfibus, OPC, \nDeviceNet, etc) IT Security \nSolutions/Controls \nare not suitable for \nICS Patch Deployment, \nRemediation, \nResponse | 15 | Threats to ICS | 16 | Threats to ICS Since ICS devices and networks were not originally designed to be resilient to \ncyber enabled attacks, they are vulnerable ICS systems are remotely operated for ease of utilization and have little to no \ndefenses towards local or network based cyber attacks Many operational ICS use legacy and outdated protocols that have no security \nfeatures embedded (attack on ICS confidentially, availability, and integrity) Additionally, physical security can be under utilized and costly for critical \ninfrastructure operators | 17 | Crash Override Industroyer \nOverview Scanned and mapped ICS environment using a variety of recon protocols Improved the attacks probability of success Issued commands to remote terminal units (RTUs) over ICS protocols. Created conditions where individual utilities were island from infected \nparties, and decreased the reliability of the grid Denied service to local serial COM ports on Windows devices Prevented communications with field equipment over serial Exploited Siemens relay denial-of-service (DoS) vulnerability Lead to a shutdown of the relay Included a wiper module in the platform Rendered Windows systems unavailable Crash is known for its strategic attack stance on ICS | 18 | Crash Override Industroyer\nEnterprise effects Part I Enterprise Persistence (Modified Existing Service; Redundant Access) Overwrote and altered existing services for malware to start at boot restart Adversary could select service of choice and direct it for malware Privilege Escalation (Legitimate Account, Windows Registry Weakness) Used valid account for authentication with local proxy before malware installation Once adversary obtained permissions, upgraded the installed malware with permissions Defense Evasion (Obfuscation, File Deletion) Replaced notepad with trojanized version to gain administrative privileges Once malware executed, it cleared Windows registries keys, files, and processes Discovery (File, System time, System Services) Used port scanner for recon and network mapping Enumerated all Windows network and local services\n | 19 | Crash Override Industroyer\nEnterprise effects Part II Enterprise Execution (Module Load, Service, Script) Used timed threaded process to attempt to load malware payload (depended on \nversion) defrasvc service loads module DLL malware library Malware issues commands to execute shell authenticated user commands (start | stop \nservice of choice) Exfiltration (Data Gathering) Metadata and other data about ICS was transferred and used by malware Command and Control (C2) Main backdoor (RAT) was used to control components of the malware that was \nconnected to the ICS remote services via HTTPS | 20 | Crash Override Industroyer\nICS effects Part I ICS Defense and Operator Evasion (File Deletion, Masquerading) Malware modified ICS Windows configuration files for targeting the ABB PCM600 Used the IEC 104 to kill main process on ICS hosts and masqueraded new processes Discovery (File, Directory, and Network Enumeration) Used ICS mapping tools (IEC 61850, IEC 61870, OPC DA, etc) to enumerate for recon Execution (101, 104, 61850, OPC DA via Payloads) Killed the main process via IEC 104 transmission and sent payloads to ICS devices If target devices respond, the 61850 payload sent request packet Used 61850 module to enumerate the objects discovered in pervious step and sent \nrequest to control Disruption (Exploit Vulnerability, Spoofing) Exploited CVE 2015-5374 causing relay to be an unresponsive state, used spoofing to \nsend control messages https://ics-cert.us-cert.gov/advisories/ICSA-15-202-01 | 21 | TRISIS/TRITON/HATMAN \nOverview Malware was identified and detected before any cyber physical/digital \ndamage could be executed Actual analysis impacts were conjectured by analyst Used the SIS to shut down process (Triger a false positive) Downtime and financial loss Reprogrammed SIS to allow an unsafe state Increased risk of physical consequences due loss of SIS functionality Reprogrammed the SIS to allow for unsafe state while using the DCS to \ncreate an unsafe state or hazard Coordinate both systems to fail in tandem, causing a potentially dangerous \nstate for personnel and equipment TRITON is known for its possible strategic attack effects on ICS | 22 | TRISIS/TRITON/HATMAN\nICS effects ICS Disruption & Destruction (I/O Image Modification) Able to add malware to the execution table of the controller If controller failed, TRITON would attempt to return controller to an operable state If the controller did not recover, TRITON would overwrite the malware to cover it tracks Execution (Module Load) trilog.exe loaded libraries from libraries.zip that contained libraries for controlling the \nTriconex controllers Defense and Operator Evasion (Masquerading) The malware names the main program as trilog.exe to impersonate the Triconex\nsoftware for analyzing SIS logs | 23 | ATT&CK Model MITREs Adversarial Tactics, Techniques, and Common Knowledge \n(ATT&CK) is a curated knowledge base and model for cyber adversary \nbehavior, reflecting the various phases of an adversarys lifecycle and the \nplatforms they are known to target. ATT&CK is useful for understanding security risk against known adversary \nbehavior, for planning security improvements, and verifying defenses work as \nexpected. For more information: https://attack.mitre.org/wiki/Main_Page https://attack.mitre.org/wiki/Main_Page | 24 | Biancos Pyramid of Pain Source: David Bianco https://detect-respond.blogspot.com/2013/03/the-pyramid-of-pain.html | 25 |
Breaking Apart the ATT&CK Model Persistence\n Privilege Escalation\n Defense Evasion\n Credential Access\n Discovery\n Lateral Movement\n Execution\n Collection\n Exfiltration\n Command and Control Adversary Tactics Whats in ATT&CK? Tactics High level, time-agnostic adversary tactical goals Techniques Methods that adversaries use to achieve tactical goals Groups Threat actors, including techniques and software they use Software Built-in utilities and custom malware, linked to techniques Full framework at attack.mitre.org ATT&CK Recon Weaponize Deliver Exploit Control Execute Maintain Traditional Defense | 26 | Bringing Everything Together with ATT&CK Threat Intelligence Detection \nand Hunting Measuring \nDefenses Security Engineering Security Operations Center Hunt, and know what to hunt for Tune defenses to detect techniques Develop analytics targeted to high-impact threats Adversary Emulation Communicate results using a common language Emulate known threats Cyber Threat Intelligence Ingest and share behaviors for situational awareness Identify and map changing threat landscape Prioritize techniques based on adversary profile and \nuse Security Engineering Informing strategic decisions for best threat coverage Work with all stakeholders to deploy defenses | 27 | ATT&CK Coverage Matrix (Example) Persistence Privilege Escalation Defense Evasion Credential Access Discovery Lateral Movement Execution Collection Exfiltration Command and Control DLL Search Order Hijacking Brute Force Account Discovery Windows Remote Management Automated Collection Automated Exfiltration Commonly Used Port Legitimate Credentials\nCredential Dumping Application Window \nDiscovery Third-party Software Clipboard Data Data Compressed Communication Through \nRemovable MediaAccessibility Features Binary Padding Application Deployment Software Command-Line Data Staged Data Encrypted AppInit DLLs Code Signing\nCredential Manipulation File and Directory Discovery Execution through API Data from Local System Data Transfer Size Limits Custom Command and \nControl ProtocolLocal Port Monitor Component Firmware Exploitation of Vulnerability\nGraphical User Interface Data from Network Shared Drive\nExfiltration Over Alternative ProtocolNew Service DLL Side-Loading Credentials in Files Local Network Configuration \nDiscovery InstallUtil Custom Cryptographic \nProtocolPath Interception Disabling Security Tools Input Capture Logon Scripts PowerShell Data from Removable Media Exfiltration Over Command \nand Control Channel Scheduled Task File Deletion Network Sniffing Local Network Connections \nDiscovery Pass the Hash Process Hollowing Data Obfuscation File System Permissions Weakness\nFile System Logical Offsets Two-Factor Authentication Interception Pass the Ticket Regsvcs/Regasm Email Collection Fallback Channels Service Registry Permissions Weakness Network Service Scanning Remote Desktop Protocol Regsvr32 Input Capture Exfiltration Over Other \nNetwork Medium Multi-Stage Channels Web Shell Indicator Blocking \nPeripheral Device Discovery Remote File Copy Rundll32 Screen Capture\nMultiband Communication Basic Input/Output System\nExploitation of Vulnerability Remote Services Scheduled Task Audio Capture Exfiltration Over Physical MediumBypass User Account Control Permission Groups \nDiscovery Replication Through \nRemovable Media Scripting Video Capture Multilayer Encryption Bootkit DLL Injection Service Execution Scheduled Transfer Peer Connections Change Default File \nAssociation Component Object Model Hijacking Process Discovery Shared Webroot Windows Management \nInstrumentation Remote File Copy Indicator Removal from \nTools Query Registry Taint Shared Content Standard Application Layer \nProtocolComponent Firmware Remote System Discovery Windows Admin Shares MSBuild Hypervisor\nIndicator Removal on Host Security Software Discovery Execution through Module \nLoad Standard Cryptographic Protocol\nLogon Scripts Modify Existing Service InstallUtil System Information \nDiscovery Standard Non-Application \nLayer ProtocolRedundant Access Masquerading Registry Run Keys / Start \nFolder Modify Registry System Owner/User \nDiscovery Uncommonly Used Port NTFS Extended Attributes Web Service Security Support Provider Obfuscated Files or \nInformation System Service Discovery Data Encoding Shortcut Modification System Time Discovery Windows Management \nInstrumentation Event Subscription Process Hollowing Redundant Access Regsvcs/Regasm Winlogon Helper DLL Regsvr32 Netsh Helper DLL Rootkit Authentication Package Rundll32 External Remote Services Scripting Software Packing Timestomp MSBuild Network Share Removal Install Root Certificate Legend High Confidence of Detection\nModerate Confidence of Detection Low Confidence of Detection | 28 | ATT&CK for ICS: Why Different Models?\nPart I Adversary motivations are different Gaining access, accomplishing an objective depends on target and what the \nobjective is Enterprise and cyber physical differences Different phases in the lifecycle mean different choices Pre/post compromise differences Technologies are different How an adversary interacts with systems depends on that system Enterprise systems and embedded devices differences Very different ways of defending them Platform dependencies Data collection Mitigation tradeoffs | 29 | ATT&CK for ICS: Why Different Models?\nPart II ATT&CK for ICS focuses on adversaries who have a primary goal of the \nfollowing: disrupting an industrial control process destroying property or causing temporary permanent harm or death to humans by attacking industrial control \nsystems Operators of ICSs work to keep the system in a safe, working state 24/7 and \nare a key target for adversaries While the primary source of data comes from publicly available cyber incident \nreports, credible attacks published by academia and the broad ICS community \nare also used to augment ATT&CK for ICS content where appropriate | 30 | ICS Architecture ICS ATT&CK focus | 31 | ICS ATT&CK Model Persistence Privilege Escalation Defense Evasion Operator Evasion Credential Access Discovery Lateral Movement Execution Command and Control Disruption Destruction Valid Accounts Rootkit Network Sniffing Exploitation of Vulnerability Connection Proxy Module Firmware Module Firmware Exploitation of Vulnerability File Deletion Block Serial Comm Port Brute Force Device Information Default Credentials Scripting Commonly Used Port Spoof Command Message External Remote Service Modify Event Log Modify I/O Image Default Credentials Control Process Valid Accounts Graphical User Interface Block Command Message Modify Control Logic Alternate Modes of Operation Modify Reporting Settings Exploitation of Vulnerability Role Identification External Remote Service Command-Line Interface Modify I/O Image Modify System Settings Masquerading Modify Reporting Message Credential Dumping Location Identification Man in the Middle Modify System Settings Exploitation of Vulnerability Memory Residence Block Reporting Message\nNetwork Connection Enumeration\nModify Control Logic Modify Reporting Settings Firmware Spoof Reporting Message Serial Connection Enumeration Modify Reporting Message Modify Tag I/O Module Enumeration Block Reporting Message Modify Control Logic Network Enumeration Spoof Reporting Message Modify Physical Device Display Network Service Discovery Modify Tag Modify HMI/Historian \nReporting Modify Control Logic Modify Parameter Device Shutdown Modify Parameter Firmware Modify Command Message Block Serial Comm Port Modify System Settings Alternate Modes of Operation Operator Evasion\nHow can we fool the operator into thinking everything is OK\nHow can we fool the operator to take the wrong action Disruption (Physical)\nHow can we stop the process\nHow can we degrade the process Destruction (Physical)\nHow can we destroy equipment\nHow can we cause catastrophic failure | 32 | CrashOverride\nATT&CK for ICS Decomposition Persistence Privilege Escalation Defense Evasion Operator Evasion Credential Access Discovery Lateral Movement Execution Command and Control Disruption Destruction Valid Accounts Rootkit Network Sniffing Exploitation of Vulnerability Connection Proxy Module Firmware Module Firmware Exploitation of Vulnerability File Deletion Block Serial Comm Port Brute Force Device Information Default Credentials Scripting Commonly Used Port Spoof Command Message External Remote Service Modify Event Log Modify I/O Image Default Credentials Control Process Valid Accounts Graphical User Interface Block Command Message Modify Control Logic Alternate Modes of Operation Modify Reporting Settings Exploitation of Vulnerability Role Identification External Remote Service Command-Line Interface Modify I/O Image Modify System Settings Masquerading Modify Reporting Message Credential Dumping Location Identification Man in the Middle Modify System Settings Exploitation of Vulnerability Memory Residence Block Reporting Message\nNetwork Connection Enumeration\nModify Control Logic Man in the Middle Modify Reporting Settings Firmware Spoof Reporting Message Serial Connection Enumeration Modify Reporting Message Modify Tag I/O Module Enumeration Block Reporting Message Modify Control Logic Network Enumeration Spoof Reporting Message Modify Physical Device Display Network Service Discovery Modify Tag Modify HMI/Historian \nReporting Modify Control Logic Modify Parameter Device Shutdown Modify Parameter Firmware Modify Command Message Block Serial Comm Port Modify System Settings Alternate Modes of Operation | 33 | TRISIS/TRITON/HATMAN\nATT&CK for ICS Decomposition Persistence Privilege Escalation Defense Evasion Operator Evasion Credential Access Discovery Lateral Movement Execution Command and Control Disruption Destruction Valid Accounts Rootkit Network Sniffing Exploitation of Vulnerability Connection Proxy Module Firmware Module Firmware Exploitation of Vulnerability File Deletion Block Serial Comm Port Brute Force Device Information Default Credentials Scripting Commonly Used Port Spoof Command Message External Remote Service Modify Event Log Modify I/O Image Default Credentials Control Process Valid Accounts Graphical User Interface Block Command Message Modify Control Logic Alternate Modes of Operation Modify Reporting Settings Exploitation of Vulnerability Role Identification External Remote Service Command-Line Interface Modify I/O Image Modify System Settings Masquerading Modify Reporting Message Credential Dumping Location Identification Man in the Middle Modify System Settings Exploitation of Vulnerability Memory Residence Block Reporting Message\nNetwork Connection Enumeration\nModify Control Logic Modify Reporting Settings Firmware Spoof Reporting Message Serial Connection Enumeration Modify Reporting Message Modify Tag I/O Module Enumeration Block Reporting Message Modify Control Logic Network Enumeration Spoof Reporting Message Modify Physical Device Display Network Service Discovery Modify Tag Modify HMI/Historian \nReporting Modify Control Logic Modify Parameter Device Shutdown Modify Parameter Firmware Modify Command Message Block Serial Comm Port Modify System Settings Alternate Modes of Operation | 34 | Lessons Learned ICS were not designed to be resilient against cyber enabled attacks Adversaries are targeting common ICS vulnerabilities Unsecured protocols and networks Replay, spoofing, DoS (Denial of Service) Poor utilization of physical security for safety Little to no validation/integrity through packet transmission Crash Override Industroyer and TRISIS/TRITON/HATMAN are well \nknown examples of strategic ICS attacks We can use ICS ATT&CK modeling to: Learn and understand adversarial behavior (Analysis) Map cyber enabled ICS attacks vectors Develop defensive strategies to decrease cyber impact | 35 | ICS Security Guidelines | 36 | ICS Security Guidelines and Best Practices\nOverview Part I The overall goal of
ICS security standards and best practices is to improve the \noverall security of the data, networks, and critical infrastructure. ICS security standards: Defines both functional and assurance requirements Cover a broad range of granularity Addresses the users need, but also is practical since cost and technological \nlimitation need to be considered ICS security best practices: Are the foundation of technical security standards. Recognizes the people who develop, integrate, evaluate, configure, \nmaintain, and use the technology are critical for safeguarding the critical \ninfrastructure Can be used to conduct in-house security assessments\n | 37 | ICS Security Guidelines and Best Practices\nOverview Part II Things to consider: There are many classification systems and organizations that develop technical \nsecurity standards, it is important to adopt a standard that fits your \norganizations needs Organizations should adopt standards and best practices to reduce risk and \nminimize cost, damage, risk in lieu of an impactful event Standards and best practices help develop ICS defense-in-depth strategies Adopted ICS Standards & Best Practices Organizations: ANSI: American National Standards Institute ISA: International Society of Automation IEC: International Electrotechnical Commission NIST: National Institute of Standards and Technology ICS-CERT: Industrial Control Systems Cyber Emergency Response Team\n | 38 | ANSI/ISA 62443-3-3 Provides detailed technical control system requirements (SRs) associated with \nthe seven foundational requirements (FRs) described in ISA-62443-1-1 \n(99.01.01) Defines guidance for ICS system security requirements and security levels The SR normative language states that the control system shall provide \ncapability to to support some support some specific security requirement. | 39 | ANSI/ISA 62443-4-2 Provides the cybersecurity technical requirements for components that make \nsup an Industrial Automation and Control System (IACS). The standard provides security capabilities that enable a component to mitigate \nthreats for a given security level (without compensating remediation strategies) 62443-4-2 simplifies the procurement and integration processes for the various \nnetwork enabled devices that make up an ICS/SCADA environment | 40 | NIST 800-82 Special Publication rev II NIST 800-82 SP rev II is a best practice guidance document on how to secure \nICS, SCADA, DCS, systems, while addressing the following: Overview of ICS System topologies Threats Vulnerabilities Performance Reliability Safety Requirements Provides recommended security countermeasures to associated risks | 41 | ICS-CERT Recommended Practices ICS-CERT recommended practices (RP) provides state of the art Defense-in-\nDepth strategies for security ICS networks and infrastructure The RPs are catered towards organizations that are: In the process of developing defense and mitigation strategies Learning to prepare for ongoing and emerging ICS cyber issues, \nvulnerabilities, and mitigation strategies The ICS-CERT team works with control system subject matter experts (SMEs) to \nensure the RPs are publicly available and have been vetted The documents include, but not limited to: Updating Antivirus in an Industrial Control System Good Practice Guide for Firewall Deployment on \nSCADA and Process Control Networks Improving ICS Cybersecurity with Defense-in-Depth \nStrategies Cross-Site Scripting Creating Cyber Forensics Plans for Control Systems Patch Management for Control Systems Developing an Industrial Control Systems \nCybersecurity Incident Response Plan Securing Control System Modems\nRemote Access for Industrial Control Systems | 42 | Lessons Learned There are many entities, boards, and sectors that have ICS security \nstandards and best practices It is important to identify your organizations security needs before \nadopting to a ICS security standard and/or best practice Identify Pros and Cons of each ICS security standard and/or best \npractice Organizations could also utilize ICS security standards and best practices \nfor risk management and in-house security assessments | 43 | ICS Security Considerations | 44 | ICS Security Considerations\nOverview As more ICS network enabled functionality, innovation, and optimization \ntechniques increases, so will the adversarial threat and attack vectors Organizations should not rely on adversaries to expose their ICS risks and \nassociated vulnerabilities due to: Health and safety concerns Time and cost for remediation Reputation and Reliability concerns Physical and digital damage Organizations should adopt vetted security considerations and continuously \nupdate due to international cyber threat | 45 | Cybersecurity Culture Cyber security is currently an ongoing dynamic culture The idea is to make cyber security an integral part of the organizations life The culture encompasses: Knowledge How much information/data do you know about your system? Beliefs What cyber security strategies are you adopting towards? Attitudes Do you care about X,Y,Z vulnerabilities, threats, and risks? Values What entities are impactful? How should we defend and secure them? knowledge beliefs attitudes values | 46 | ICS Asset Configuration/Management\nPart I Configuration Management (CM) is policies and procedures for controlling \nmodifications to hardware, firmware, software, and documentation to ensure \nthe information system is protected against improper modifications prior to, \nduring, and after system implementation Lack of CM can lead to unmanageable and highly vulnerable inventory of \nhardware, firmware, and software Before CM strategies are in place, the organization should categorize ICS \nsystems and network assets (NIST SP 800-83 rev II {Section 4.5.1}) this \nincludes: Focusing on systems rather than just devices (PLCs, DCS, SCADA, HMIs, \nshould be considered) Assets that use routable protocols or dial-up services should be documented Reviewing asset list annually (addition and removal) | 47 | ICS Asset Configuration/Management\nPart II Configuration management policies and procedures are used to control \nmodifications to hardware, firmware, software, and documentation Ensure that the ICS system is protected against improper modifications prior \nto, during, and after system implementation. The security controls that fall within the NIST SP 800-53 CM family provide \npolicy and procedures for establishing baseline controls for information \nsystems. Controls are also specified for maintaining, monitoring, and documenting\nconfiguration control changes. A formal change management program should be established to insure that all \nmodifications to an ICS network meet the same security requirements as the \noriginal components identified in the asset evaluation, associated risk \nassessment, and mitigation plans | 48 | ICS Asset Configuration/Management\nPart III Supplemental Guidance: NIST SP 800-70: Provides guidance on configuration settings for IT products NIST SP 800-100: Provides guidance on information security governance and planning NIST SP 800-128: Provides guidance on implementation of a security-focused configuration management \nprogram | 49 | ICS Architecture When designing a network architecture for an ICS deployment, it is usually \nrecommended to separate the ICS network from the corporate network (NIST \nSP 800-83 rev II {Section 5}) The nature of network traffic on these two networks is different: Internet \naccess, FTP, email, and remote access will typically be permitted on the \ncorporate network but should not be allowed on the ICS network If ICS network traffic is carried on the corporate network, it could be intercepted \nor be subjected adversarial based attacks or recon Items that should be considered when designing a hardened ICS architecture \nare the following: Network Segmentation and Segregation Boundary Protection (Physical Security) Firewalls | 50 | ICS Security Controls It is often difficult or infeasible to apply security controls todays ICS because of \nthe following: Use of a combination of legacy systems Planned life span of 20-30 years Hybrid of legacy systems (augmented with newer hardware and software\nthat are interconnected to other systems) The NIST SP 800-53 controls are organized into 18 families; each family \ncontains security controls related to the general security topic of the family. Security controls may involve aspects of policy, oversight, supervision, \nmanual processes, actions by individuals, or automated mechanisms \nimplemented by information systems/devices | 51 | ICS Monitoring Legacy and modern ICS devices are usually supplied with physical and \nvirtual interfaces that can be tapped for situational awareness Monitoring on a real-time basis where feasible is a great factor for incident \nresponse, analysis, and knowing the health state of the ICS environment There are many techniques for monitoring ICS environments. The following are \nsome items to consider: Tap physical and virtual network socket sensors Log authentication attempts/denial Monitor inflow/outflow packet transaction anomalies Use Intrusion Detection Systems (IDS) Use Intrusion Prevention Systems (IPS) | 52 | ICS Network Access Control Proper firewall and network configuration rules should be in place and \nconsistently maintained and monitored to decrease the risk of network based \ncyber attacks ICS network access control can be achieved by: Leverage ICS architecture to separate and protect network zones Encryption of communication and logical isolation Control and filtering of traffic Supported authentication tactics for leverage ICS equipment | 53 | ICS HMI and Workstation Security Typically this strategy involves hardening the various Human Machine \nInterfaces (HMIs), Open Platform Communications (OPCs), and other remote \nclients used to connect and configure the ICS devices The various remote devices need to be: Locked Down by utilizing the functionality provided by the Operating \nSystem (OS). If there is weak security functionality in place, consider other \nupdated supported tools. Tested to ensure the security changes still allow for communications to the \nICS devices Verified to confirm no serious security holes (vulnerabilities) are left open by \nthe hardening process | 54 | Supply Chain A supply chain attack is an intentional malicious action (insertion, substitution, \nor modification) taken to covertly exploit a vulnerability in the ICS development \nlifecycle The Information and Communications Technology (ICT) supply chain is defined \nin NIST 800- 161 as a linked set of resources and processes between
\nacquirers, integrators, and suppliers that begins with the design of ICT \nproducts and services and extends through development, sourcing, \nmanufacturing, handling, and delivery of ICT products and services to the \nacquirer. Proper vetting and personnel authentication strategies should be in place for all \nentities involved in the ICS development lifecycle | 55 | User Access Controls Performing the authentication and authorization of users in the ICS \nenvironment presents a challenge. Managing these users accounts can be \nproblematic as employees are added, removed, and as their roles change Authentication and authorization can be performed either in a distributed or \ncentralized approach using Kerberos, RADIUS, TACACS+ Distributed Approach: Every system performs these steps on their own. Each system is \nresponsible for storing its own set of user accounts, credentials, and roles \nand performing the identification and authentication of the user. Centralized Approach Utilizes some central authentication system (e.g., Microsoft Active Directory, \nLightweight Directory Access Protocol (LDAP) to store all accounts and \nmanage the authentication and authorization of all individuals and systems. | 56 | Intrusion Detection and Response Intrusion detection and response is a defensive resilience strategy set to \nensure ICS equipment and HMIs are operable during and after cyber-enabled \nattacks This strategy enforces ICS incident response teams and analyst to automate \nresponse and remediation techniques per cyber attack The strategy encompasses: Detect identify the presence of an abnormal event Mitigate after successful attack, control infected system and return back to \nnormal state Learn learn from successful attack, and automate prevention strategies | 57 | Lessons Learned\nPart I Since ICS environments encompass various entities, proper asset \nmanagement should be considered ICS devices and networks should not be installed on the organizations \ncorporate network Security controls may involve aspects of policy, oversight, supervision, \nmanual processes, actions by individuals, or automated mechanisms \nimplemented by information systems/devices Monitoring on a real-time basis where feasible is a great factor for \nincident response, analysis, and knowing the health state of the ICS \nenvironment Firewall and network configuration rules should be in place and \nconsistently maintained and monitored | 58 | Lessons Learned\nPart II All remote machines used to connect to the ICS devices should be \nhardened to support the Defensive-in-Depth strategy Supply chain attacks are impactful and all personnel involved in the ICS \ndevelopment lifecycle should be authenticated and verified Authentication and authorization can be performed either in a distributed \nor centralized approach Intrusion detection and response is a defensive resilience strategy set to \nensure ICS equipment and HMIs are operable during and after cyber-\nenabled attacks | 59 | Assessing Risks to ICS | 60 | Assessing Risks to ICS\nPart I Organizations need to manage: Financial risk, risk of equipment failure, personnel safety risk, etc. Safety assessments are well established Risk Management NIST Special Publication 800-39, Managing Information Security Risk: \nOrganization, Mission and Information System View NIST Special Publication 800-37 Revision 1, Guide for Applying the Risk \nManagement Framework to Federal Information Systems: A Security Life Cycle Approach | 61 | Assessing Risks to ICS\nPart II National Institute of Standards and Technology, NIST Special Publication 800-82, source URL: \nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf | 62 | Assessing Risks to ICS\nPart III Framing Developing a framework for the risk management decisions to \nbe made Safety How do safety requirements interact with information security How conflicts between safety requirements good security practice reconciled Availability of services ICS part of critical infrastructure where continuous and reliable operations is \na requirement ICS with strict requirements for availability or for recovery Physical operating environment Specific environmental requirements ICS tied to their physical environment | 63 | Assessing Risks to ICS\nPart IV Assessing risk Identify threats and vulnerabilities that are likely to cause \nharm if an adverse event arising from them occurs ICS-CERT Sharing of device vulnerabilities, incidents, and mitigation \nmeasure. Information sharing organizations Responding Consistent organizational-wide response to identification \nof risk Risk responses may be constrained in ICS by system requirements, \npotential adverse impact on operations, or regulatory compliance regimes Monitoring Monitor risk on an on-going basis Implement a risk management strategy Monitor changes in the environment that may affect risk calculations Monitor the effectiveness and efficiency of risk reduction activities\n | 64 | ICS Considerations\nPart I Safety Information security risk assessment must identify and communicate \nidentified risks that could have safety implications and vice versa. Potential Physical Impacts An evaluation of the potential physical impacts should include all parts of an \nICS, beginning with evaluating the potential impacts on the set of sensor and \nactuators. Physical Disruption Potential effects to the physical process performed by the ICS under \nconsideration, as well as other systems Cascading impacts into other related ICS processes should be considered \nas well | 65 | ICS Considerations\nPart II Non-digital Aspects ICS often have non-digital control mechanisms that can prevent the ICS \nfrom operating outside of a safe boundary Analog mechanisms can be used to observe the physical system state to \nprovide operators with reliable data if digital readings are unavailable or \ncorrupted Safety Systems Impact of the implemented security controls on the safety system should be \nevaluated to determine that they do not negatively impact the system Impact to Connected Systems ICS may be interconnected with other systems, such that failures in one \nsystem or process can easily cascade to other systems either within or \nexternal to the organization | 66 | Risk Management Framework Tasks National Institute of Standards and Technology, NIST Special Publication 800-82, source URL: \nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf | 67 | Simple Example The SCADA system contains both real-time sensor data and routine \nadministrative information. The management at the power plant \ndetermines that SC sensor data = {(confidentiality, NA), (integrity, HIGH), (availability, \nHIGH)}, SC administrative information = {(confidentiality, LOW), (integrity, LOW), \n(availability, LOW)}. SC SCADA system = {(confidentiality, LOW), (integrity, HIGH), (availability, \nHIGH)} Considering the potential impact of a security breach due to the \nunauthorized disclosure of system-level information or processing \nfunctions SC SCADA system = {(confidentiality, MODERATE), (integrity, HIGH), \n(availability, HIGH)} | 68 | ICS Impact Levels Product Produced Non-hazardous materials or \nproducts Non-ingested consumer \nproducts Some hazardous products \nor steps during production High amount of proprietary \ninformation Critical infrastructure (e.g., \nelectricity) Hazardous materials \nIngested products Industry Examples Plastic injection molding \nWarehouse applications Automotive metal \nindustries Pulp and paper \nSemiconductors Utilities\n Petrochemical\n Food and beverage\n Pharmaceutical Security Concerns Protection against minor \ninjuries Ensuring uptime Protection against \nmoderate injuries Ensuring uptime\n Capital investment Protection against major \ninjuries/loss of life Ensuring uptime\n Capital investment\n Trade secrets\n Ensuring basic social services\n Regulatory compliance National Institute of Standards and Technology, NIST Special Publication 800-82, source URL: \nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf | 69 | Overlays Overlay A fully specified set of security controls, control enhancements, \nand supplemental guidance derived from the application of tailoring \nguidance to security control baselines described in NIST SP 800-53. Address the need for developing community-wide and specialized sets of \nsecurity controls for information systems and organizations | 70 | Key Security Controls\nPart I Role-based Access Control (RBAC) Legacy ICS systems or specialized ICS equipment may require development \nof specialized interface software. Web Servers Some products, such as PLCs and other control devices, are available with \nembedded Web, FTP, and email servers to make them easier to configure \nremotely and allow them to generate email notifications and reports when \ncertain conditions occur. Virtual Local Area Network (VLAN) VLANs have been effectively deployed in ICS networks, with each \nautomation cell assigned to a single VLAN to limit unnecessary traffic \nflooding and allow network devices on the same VLAN to span multiple \nswitches | 71 | Key Security Controls\nPart II Wireless Prior to installation, a wireless survey should be performed to determine \nantenna location and strength to minimize exposure of the wireless network Configuration Management A formal change management program should be established and \nprocedures used to insure that all modifications to an ICS network meet the \nsame security requirements Virtual Private Network (VPN) VPN devices used to protect control systems should be thoroughly tested to \nverify that the VPN technology is compatible with the application | 72 | Key Security Controls\nPart III Intrusion Detection and Prevention IDS and IPS vendors are beginning to develop and incorporate attack \nsignatures for various ICS protocols such as Modbus, DNP3, and ICCP An effective IDS deployment typically involves both host-based and network-\nbased IDS Patch Management Applying patches to OS components creates another situation where \nsignificant care should be exercised in the ICS environment. Patches should \nbe adequately tested to determine the acceptability of side effects | 73 | Lesson Learned Organizations need to consider financial, equipment failure, and \npersonnel safety risks within ICS environments NIST SP 800-37 and 800-39 are great resources to consider for managing \nrisks Overlays are a fully specified set of security controls, control \nenhancements, and supplemental guidance derived from the application \nof tailoring guidance to security control baselines described in NIST SP \n800-53 Manageable security controls can decrease the security risk within an ICS \nenvironment | 74 | Cyber Risk Management Framework Exemplar\nU.S. DOE ONG-C2M2 Overview The Department of Energy (DOE) developed the Oil and Natural Gas \nSubsector Cybersecurity Capability Maturity
Model (ONG-C2M2) Derives from the Electricity Subsector Cybersecurity Capability Maturity \nModel (ES-C2M2) The purpose of the ONG-C2M2 is to address only the implementation and \nmanagement of cybersecurity practices associated with information technology \n(IT) and operational technology (OT) and the environments in which they \noperate. Intended Audience: Decision Makers Leaders Practitioners Facilitators\n | 75 | Core Concepts\nMaturity Models Part I A maturity model is a set of characteristics, attributes, indicators, or patterns \nthat represent capability and progression in a particular discipline Model content typically exemplifies best practices and may incorporate \nstandards or other codes of practice of the discipline A maturity model thus provides a benchmark against which an \norganization can evaluate the current level of capability for its \nimprovement. This includes: Practices Processes Methods Set goals priorities | 76 | Core Concepts\nMaturity Models Part II To measure progression, maturity models typically have levels along a scale \nONG-C2M2 uses a scale of maturity indicator levels (MILs) 03 If an organization demonstrates these attributes, it has achieved both that level \nand the capabilities that the level represents Having measurable transition states between the levels enables an \norganization to use the scale to: Define its current state Determine its future, more mature state Identify the capabilities it must attain to reach that future state | 77 | Model Architecture\nOverview The model arises from a combination of the following: Existing cybersecurity standards Frameworks, programs Initiatives The model provides flexible guidance to help organizations develop and \nimprove their cybersecurity capabilities The model is organized into 10 domains. Each domain is a logical grouping of \ncybersecurity practices | 78 | Model Architecture\nDomains Part I Each of the models domains contains a structured set of cybersecurity \npractices Each set of practices represents the activities an organization can perform to \nestablish and mature capability in the domain For each domain, \nthe model provides \na purpose statement \nand introduce its \npractices Source Oil and Natural Gas Subsector Cybersecurity Capability Maturity Model Version 1.1 | 79 | Model Architecture\nDomains Part II The domains include: Risk Management Asset, Change, and Configuration Management Identity and Access Management Threat and Vulnerability Management Situational Awareness Information Sharing and Communications Event and Incident Response, Continuity of Operations (Ops) Supply Chain and External Dependencies Management Workforce Management Cybersecurity Program Management | 80 | Maturity Indicator Levels (MILs)\nOverview The model defines four maturity indicator levels, MIL0 through MIL3, which \napply independently to each domain in the model The MILs define a dual progression of maturity: an approach progression and \nan institutionalization progression Example of Approach Progression in the Cyber Program Management Domain Source Oil and Natural Gas Subsector Cybersecurity Capability Maturity Model Version 1.1 | 81 | Maturity Indicator Levels (MILs)\nPart I MIL0 The model contains no practices for MIL0. Performance at MIL0 simply \nmeans that MIL1 in a given domain has not been achieved MIL1 Contains a set of initial practices MIL2 Contains a set of developed practices which contain the following: Practices are documented Stakeholders of the practice are identified and involved Adequate resources are provided to support the process (people, funding, and tools) Standards and/or guidelines have been identified to guide the implementation of the \npractices | 82 | Maturity Indicator Levels (MILs)\nPart II MIL3 The activities in a domain have been further institutionalized and are now \nbeing managed. Management practices support this progression Activities are guided by policies (or other organizational directives) and governance Policies include compliance requirements for specified standards and/or guidelines Activities are periodically reviewed to ensure they conform to policy Responsibility and authority for performing the practices are assigned to personnel Personnel performing the practices have adequate skills and knowledge | 83 | Using ONG-C2M2\nOverview ONG-C2M2 is meant to be used by an organization for the following: Evaluate its cybersecurity capabilities consistently Communicate its capability levels in meaningful terms Inform the prioritization of its cybersecurity investments Source Oil and Natural Gas Subsector Cybersecurity Capability Maturity Model Version 1.1 | 84 | Using ONG-C2M2\nPerform an Evaluation Organizations should select the appropriate personnel to evaluate the function \nin scope against the model practices Personnel selected to participate in the evaluation should include people who \ncould provide useful information on the organizations performance of \ncybersecurity practices in the model Upon completion of the evaluation, a scoring report is generated that shows \nmaturity indicator level results for each domain The report should be reviewed with the evaluation workshop participants, and \nany discrepancies or questions should be addressed | 85 | Using ONG-C2M2\nAnalyze Identified Gaps The scoring report from the evaluation will identify gaps in the performance of \nmodel practices Determine whether these gaps are meaningful and important for the \norganization to address The organization should determine the level of practice performance and MIL \nachievement for each domain that best enables it to meet its business \nobjectives and cybersecurity strategy | 86 | Using ONG-C2M2\nPrioritize and Plan The organization should prioritize the actions needed to fully implement the \npractices that enable achievement of the desired capability in specific domains The prioritization should be done using criteria such as: how gaps affect organizational objectives the importance of the business objective supported by the domain the cost of implementing the necessary practices the availability of resources to implement the practices A cost-benefit analysis for gaps and activities can inform the prioritization of the \nactions needed | 87 | Using ONG-C2M2\nImplement Plans and Reevaluate Model evaluations are particularly useful in tracking implementations and \nshould be conducted periodically to ensure that desired progress is achieved Reevaluations should also be considered in response to major changes in the \nbusiness, technology, market, or threat environments to ensure that the \ncurrent profile matches the organizations desired state Source Oil and Natural Gas Subsector Cybersecurity Capability Maturity Model Version 1.1 | 88 | References The MITRE Corporation, Adversarial Tactics, Techniques & Common Knowledge (ATT&CK), source URL: https://attack.mitre.org/wiki/Main_Page The MITRE Corporation, ICS Adversarial Tactics, Techniques & Common Knowledge ATT&CK, source URL: https://www.acsac.org/2017/workshops/icss/Otis-\nAlexander-ICS,%20Adversarial%20Tactics,%20Techniques.pdf Process & Plant Automation LTD, source URL: http://www.automationghana.com/ FireEye, Attackers Deploy New ICS Attack Framework TRITON and Cause Operational Disruption to Critical Infrastructure, source URL:\nhttps://www.fireeye.com/blog/threat-research/2017/12/attackers-deploy-new-ics-attack-framework-triton.html FireEye, Sandworm Team and the Ukrainian Power Authority Attacks, source URL: https://www.fireeye.com/blog/threat-research/2016/01/ukraine-and-\nsandworm-team.html ISA, ANSI/ISA-62443-3-3 (99.03.03)-2013 Security for industrial automation and control systems Part 3-3: System security requirements and security levels, \nsource URL: https://www.isa.org/store/ansi/isa-62443-3-3- -security-for-industrial-automation-and-control-systems-part-3-3-system-security-\nrequirements-and-security-levels/116785 ISA, ANSI/ISA-62443-4-2-2018, Security for industrial automation and control systems, Part 4-2: Technical security requirements for IACS components, source \nURL: https://www.isa.org/store/ansi/isa-62443-4-2-2018,-security-for-industrial-automation-and-control-systems,-part-4-2-technical-security-requirements-for-\niacs-components/62991116 National Institute of Standards and Technology, NIST Special Publication 800-82, source URL: \nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf Department of Homeland Security ICS-CERT, Recommended Practices, https://ics-cert.us-cert.gov/Recommended-Practices Security Matters, A four step guide to secure your ICS Network Using ISA/99/IEC 62443, source URL: https://www.secmatters.com/blog/a-four-step-guide-to-\nsecure-your-ics-network-using-isa-99iec-62443 Department of Energy, OIL AND NATURAL GAS SUBSECTOR CYBERSECURITY CAPABILITY MATURITY MODEL (ONG-C2M2) , source URL: \nhttps://www.energy.gov/sites/prod/files/2014/03/f13/ONG-C2M2-v1-1_cor.pdf https://attack.mitre.org/wiki/Main_Page\nhttps://www.acsac.org/2017/workshops/icss/Otis-Alexander-ICS, Adversarial Tactics, Techniques.pdf\nhttp://www.automationghana.com/\nhttps://www.fireeye.com/blog/threat-research/2017/12/attackers-deploy-new-ics-attack-framework-triton.html\nhttps://www.fireeye.com/blog/threat-research/2016/01/ukraine-and-sandworm-team.html\nhttps://www.isa.org/store/ansi/isa-62443-3-3- -security-for-industrial-automation-and-control-systems-part-3-3-system-security-requirements-and-security-levels/116785\nhttps://www.isa.org/store/ansi/isa-62443-4-2-2018,-security-for-industrial-automation-and-control-systems,-part-4-2-technical-security-requirements-for-iacs-components/62991116\nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf\nhttps://ics-cert.us-cert.gov/Recommended-Practices\nhttps://www.secmatters.com/blog/a-four-step-guide-to-secure-your-ics-network-using-isa-99iec-62443\nhttps://www.energy.gov/sites/prod/files/2014/03/f13/ONG-C2M2-v1-1_cor.pdf ",
    "text": " UP JORS software Latex paper template version 0.1 Software paper for submission to the Journal of Open Research Software To complete this template, please replace the blue text with your own. The paper has three main sections: (1) Overview; (2) Availability; (3) Reuse potential. Please submit the completed paper to: editor.jors@ubiquitypress.com (1) Overview Title Transplant2Mongo: A Python module to manage and store Organ Procurement and Transplantation Network (OPTN) data in MongoDB 1 Paper Authors 1. Harvey, Christine 2. Weigel, Robert PhD Paper Author Roles and Affiliations 1. Lead High Performance and Analytical Computing Engineer, The MITRE Cor- poration and PhD Student, George Mason University 2. Professor, George Mason University Abstract The transplant2mongo Python module allows users to transform Standard Trans- plant Analysis and Research (STAR) data files from the Organ Procurement and Transplantation Network (OPTN) into a MongoDB schema [1,2] . The STAR data are a collection of tab-separated files with inter-related records that is not designed for complex query. Any researcher planning to use data from an OPTN STAR files can use transplant2mongo to convert the information into a MongoDB docu- ment for analysis using open-source tools. The source code for transplant2mongo is available on GitHub at https://github.com/ceharvs/transplant2mongo and includes sample data files for initial testing and data query. Keywords Python; OPTN; UNOS; organ transplant; health care; analysis; MongoDB Introduction The Organ Procurement and Transplantation Network (OPTN) keeps a record of all organ donations, transplants, and waiting list registrations since 1987 in the United States [1]. This complex data set can be used to review, query, and ana- lyze the US organ donation system over time and across various factors. The total 1Approved for Public Release; Distribution Unlimited. Case Number 18-0298. c MITRE Corporation is provided for identification purposes only and is not intended to convey or imply MITREs concurrence with, or support for, the positions, opinions, or viewpoints expressed by the author. https://github.com/ceharvs/transplant2mongo UP JORS software Latex paper template version 0.1 database is around 9GB and contains records on hundreds of thousands of donors and over a million patients [2]. The transplant2mongo software translates data from OPTN Standard Transplant Analysis and Research (STAR) files into a Mon- goDB database. OTPN STAR files are designed to be analyzed and processed in either SPSS or SAS, according to the OPTN [2], which are both proprietary tools. This software was developed to allow researchers to use open-source software to manage the dataset and perform an analysis. transplant2mongo transforms the raw tab-separated value (TSV) STAR files into documents stored in a MongoDB database. Translating the data allows any user without specialized software to ex- plore and perform analysis on this complex and interconnected dataset. Due to the sensitive nature of STAR file data, the development of these tools was completed in a secure lab environment at The MITRE Corporation and the code repository does not include any STAR files. Using Python to complete the data transformation and MongoDB as a final repository for the data allows users to make use of only open-source tools. Python and the included modules read in the data from the STAR TSV files and convert it to MongoDB documents . Special consid- eration was made to process the data and remove erroneous symbols and characters that are not compatible with MongoDB. The resulting MongoDB has been used to perform analysis of the OPTN dataset and the results of the analysis will be considered in a future publication. Implementation and architecture This software was developed on a CentOS machine using Python 2.7 and MongoDB 2.6 in a secure lab environment, suitable for the sensitive data files. This tool was developed and tested using OPTN STAR file data from June 2014 and March 2015. The general file configuration of OPTN STAR files can be seen in Figure 1. Users of this tool may not have the complete UNOS STAR files, and may only have certain subsets of this information. In this case, the Makefile can be edited so that only a subset of the STAR files are processed. As shown in Figure 1, the TSV files are all stored in the highlighted, Delimited Text Files folder. All data processed with the tool should be contained in this folder. This folder contains a sub-folder for each of the data types: Deceased Donor, Intestine, Kidney Pancreas Kidney-Pancreas, Liver, Living Donor, and Thoracic. The Kidney Pancreas Kidney-Pancreas sub-folder contains in- formation on all patients and transplant recipients for kidney and pancreas, and combined kidney/pancreas transplants. The Thoracic folder includes data on both heart and lung transplant patients. The deceased donor and living donor fold- ers contain details on all organ donors, while the other folders provide data on all patients registered to the waiting list and those who received a transplant. Each of these major groups are represented as collections in the database with the patient or donor information as documents and the sub-folders as sub-documents. UP JORS software Latex paper template version 0.1 Figure 1: Structure of the OPTN STAR files. MongoDB was chosen as the database due to the NoSQL format, allowing multiple patient fields to be combined into a single document with multiple sub-documents. Many of the fields have changed over the years and many of the patient fields are missing information, making this data suitable for NoSQL storage. Alternatively, a SQL database system could be used. With a structured database implementation the number of columns would be very large and there would be many NULL fields in the database. A Makefile is used to build the database from the contents of the Delimited Text Files folder. The Makefile has targets for cleaning, processing, and importing the data into a specified MongoDB database. A linked directory using a symbolic link is used to avoid unnecessary parsing of spaces in the file names. Users need to specify their database location and name in the Makefile before execution. The default interface is localhost and database name is organ data. Users also need to define their components, which specifies the STAR files that the researcher has access to from UNOS. These values are selected from the following list: deceased, living, intestine, kidpan, liver, and thoracic. Data are copied from the original location and file structures are flattened to establish a simple structure for parsing. UP JORS software Latex paper template version 0.1 Once the data is in place, another Python script is run to generate JSON and add the documents into a MongoDB database. For the base files, the main donor or organ data files, the add patients.py script is run to generate major documents in the appropriate tables. For files that contain sub-document information such as follow-up visits or medications, the supplemental data.py script adds this infor- mation as a sub-document to the main patient or donor document. This script uses a unique identifier, such as DONOR ID, TRR ID CODE, or WL ID CODE, to match the supplemental data file entry with a unique record for the donor or organ type. Once a match is found, the supplemental data is added to the document in the database. The TSV files, having the extension .DAT, only contain data and do not include column names, therefore columns are determined by the .htm files corresponding to each .DAT files. Data are cleaned before insertion into the database. The cleaning process is han- dled in the Python scripts add patients.py and supplemental data.py, which use the clean string function. These scripts remove extraneous values such as extra commas, quotations, and new lines. The scripts also create Python datetime objects from potential date strings and convert strings to integers when possible. The scripts do not assume a particular data type for any column. The database contains many different columns and the typing is automatically determined by Python and MongoDB. All data is originally imported as a string. The Python scripts check if the data is a date or an integer, and if not, the data are kept as strings. Following execution of each of the import scripts, follow-up scripts are run to add age bins to all age fields of the data for fast and simple aggregation of the data. Quality control The scripts have been tested on two distinct UNOS STAR file data sets from 2014 and 2015. Each script prints out the number of lines in the file and then the number of patient documents successfully imported into the database. With the two testing sets, the line count results match the imported entry counts in all scenarios with the exception of a particular data file where a new line is hidden with quotation marks and the reported file length is one more than the imported record count. The data were manually confirmed in this situation and manual spot checks of all the data were performed. The Github repository includes sample data that can be used for testing the instal- lation. These data contain no real patient information and were generated by the developers of the software. The
Makefile is set up by default to run on this sample data set with the localhost MongoDB database by following the directions pro- vided in the README. Users can test if the implementation works properly with the test database.py script. Full instructions are in the README file and this script can be run to UP JORS software Latex paper template version 0.1 perform spot-checks on the sample data and the full database to ensure the import has completed properly. (2) Availability Operating system All operating systems should be compatible. Programming languages MongoDB version 2.6 or higher Python 2.7 Python packages: pymongo, csv, datetime, argparse, codecs, pandas, and subprocess Additional versions could be compatible, these are the verified requirements. Additional system requirements None. Dependencies The data import package in the GitHub repository is necessary for installation. Users need to obtain UNOS STAR files directly from the OPTN. This data contains private health data and can only be obtained through the OPTN via a request. List of contributors Christine Harvey was the lead developer on this project with support from Dr. Robert Weigel. Software location: Code repository Name: GitHub Persistent identifier: https://github.com/ceharvs/transplant2mongo Licence: GNU GENERAL PUBLIC LICENSE Version 3, 29 June 2007 Date published: 15/02/17 Language English (3) Reuse potential This tool is available for re-use by anyone working with UNOS STAR files, perform- ing research on the Organ Transplant system. This tool provides a reproducible, open source alternative to working with the data quickly and efficiently. This allows researchers to use modern machine learning and research tools to analyze data. The software has a high potential for extension. This tool is currently written in Python 2.7 and could be upgraded to Python3. The software could also be extended to use alternative databases. There is no official support for this software, but those with questions or interested in collaboration can contact Christine Harvey at ceharvey@mitre.org or via GitHub. https://github.com/ceharvs/transplant2mongo UP JORS software Latex paper template version 0.1 Acknowledgements The data reported here have been supplied by the United Network for Organ Sharing as the contractor for the Organ Procurement and Transplantation Network. The interpretation and reporting of these data are the responsibility of the author(s) and in no way should be seen as an official policy of or interpretation by the OPTN or the U.S. Government. The authors would also like the thank the Early Career Research Program and the Innovation Area Lead, Rob Case for supporting this research. Funding statement The software referenced herein is copyright of The MITRE Corporation and the result of MITREs Early Career Research program and work done in the Compu- tational Science and Informatics program at George Mason University. Competing interests The authors declare that they have no competing interests. References [1] Organ Procurement and Transplantation Network, 2015. OPTN Website. Avail- able at: http://optn.transplant.hrsa.gov/ [Accessed May 8, 2015]. [2] Organ Procurement and Transplantation Network, 2017. Standard Transplant Analysis and Research (STAR) Dataset Files. Available at: https://optn.transplant. hrsa.gov/data/request-data/ [Accessed September 27, 2017]. [3] Transplant2Mongo, 2017. https://github.com/ceharvs/transplant2mongo Copyright Notice Authors who publish with this journal agree to the following terms: Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a Creative Commons Attribution License that allows others to share the work with an acknowledgment of the works authorship and initial publication in this journal. Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journals published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgment of its initial publication in this journal. By submitting this paper you agree to the terms of this Copyright Notice, which will apply to this submission if and when it is published by this journal. http://optn.transplant.hrsa.gov/\nhttps://optn.transplant.hrsa.gov/data/request-data/\nhttps://optn.transplant.hrsa.gov/data/request-data/\nhttps://github.com/ceharvs/transplant2mongo\nhttp://creativecommons.org/licenses/by/3.0/ ",
    "text": " Copyright \nApproved for Public Release; Distribution Unlimited. Public Release Case Number 18-3908 HEADLINE Pop Open MITRE's Toolkit to Discover Pathways to Innovative \nThinking \nTEASER [255 characters or fewer, including spaces] What if you could use tools to build not just products, but community? That's the goal of the MITRE \nInnovation Toolkit, which spurs collaboration and creativity with a human-centered focus. Federal \nagencies are adopting it to improve problem solving. Over the years, innovation has largely been viewed in the context of product and technology \nadvancesfrom the wheel and the engine, to the internet and the smart phone. In other words, its \nusually a thing. But what if our perspective on innovation were more well, innovative? What if innovation is just as \nrelevant to a process as it is to a product or service? A multi-disciplinary team from MITRE believes that's \nnot only possible, but something that should be available to everyone. The team has developed the MITRE Innovation Toolkit, a collection of methods and techniques that \npromote creative thinking and problem solving. The tools offer low-cost, high-impact pathways for \nhelping everyone think and work more like innovators. The type of innovation we're hoping to inspire is more about collaboration and less about technology,\" \nsays systems engineer Dan Ward, who develops tools for the toolkit and leads hands-on workshops in \ntheir use. \"We arent just looking for innovative ways to write code, but for innovative ways to work \ntogether. We want to help people save time and money, while increasing their impact. The idea for an innovation toolkit packed with different approaches and methods isnt new. The market \nis full of them. In fact, when Team Toolkit began investigating the space, they found approximately 300 \ntools exist to promote innovation. But on closer inspection, they found nothing that was tailored for \nMITRE and our sponsors. For one thing, brainstorming was continually equated with the act of innovating, when it should really \nbe viewed as just one of many elements in the process, Ward says. One of the most crucial elements of \ninnovation is focusing on the user. Human-centered design is really the key, says Rachel Gregorio, one of the human factors engineers on \nthe team, which also includes Aileen Laughlin, Stephanie Medicke, Kaylee White, Niall White, and Jessica \nYu. To innovate, you have to put the user at the center of the problem to understand their goals and \npain points. What problem are you trying to solve? What job do users need to get done? At that \nintersection, novelty and impact meet. MITRE to Pentagon: \"Let's Keep This Going\" After months of testing, the team narrowed the list of existing tools down from 300 to just 24making \nconsiderable enhancements to each tool along the way and developing user-friendly ways to describe https://itk.mitre.org/our-toolkit/\nhttps://www.mitre.org/publications/project-stories/applying-design-thinking-to-boost-federal-agency-problem-solving Copyright \nApproved for Public Release; Distribution Unlimited. Public Release Case Number 18-3908 each method. They organized the tools into distinct categories (Frame Problem, Evaluate Options, \nUnderstand Users, Develop Plan, Generate Ideas, Reduce Complexity). That way, toolkit users can easily \nselect the most appropriate paths for their objectives. Each exercise can be easily downloaded and followed. In most cases, a facilitator (whether from the \noutside or designated from a team) walks participants through the process, using templates to capture \ninformation. The output varies. Participants may create a visual document through which they can better \nunderstand the user or engage in a conversation that creates a shared awareness of the situation. \nResults may include a written document that help set goals or possibly even 3D renderings that assist in \nprototyping. In January 2018, the team began field testing the kit within MITRE. Team Toolkit held three workshops to \ntrain staff in using them on internally funded research projects through our MITRE Innovation Program. Sponsor-facing projects came next. In August, a Pentagon sponsor used six of the tools to help with \ntechnology problem solving, organizational design and dynamics, and teambuilding and consensus. The \nprincipal sponsor has already asked for another toolkit training session, noting the work's importance. Team Toolkit has led several training sessions with personnel at Hanscom Air Force Base in \nMassachusetts and at Langley Air Force Base in Virginia. Early into the development process, the team \nconducted a \"journey mapping\" exercise for people who work in vehicle sourcing at Langley. Journey \nmapping is a way to visualize a users experience with a product or service to help create shared \nawareness and identify opportunities for improvement. Participants identified several bottlenecks in the vehicle sourcing process and determined areas where \nprocess changes and automation could provide some relief. Failure Is an OptionAs Long as You Learn from It The team also led a Hanscom group through a premortem exercise, which is a technique for framing a \nproblem by imagining a future in which the project has completely failed. By envisioning failure, \nparticipants can have a better understanding of what constitutes success. The premortem tool has also worked well at MITRE. In August, Ward led a premortem session for an \ninternal team of software developers who create custom applications to improve employee productivity. Ive never seen people talk so honestly at work,\" says Matt Merrill, who leads the software group. \n\"There was something about the process and about the way that Dan led it that helped everyone let \ntheir guard down. One thing we talked about was how we need to admit when something has failed so \nwe can learn from it. That led to a big push for us to have ways to measure our progress, so we really will \nknow when something isnt working.\" The group has already begun documenting guiding principles and procedures so theyre all working \ntowards the same software development goals and standards. I want to run the same exercise for another project that Im doing, Merrill says. I would definitely \nrecommend a premortem to any group that's having trouble developing a plan. Merrill believes he could now lead the exercise himself, after seeing Ward in action. And that's exactly \nwhat the toolkit developers hope will happen. https://www.mitre.org/research/overview Copyright \nApproved for Public Release; Distribution Unlimited. Public Release Case Number 18-3908 Even the Team Toolkit members got into the premortem act, to put their ideas to the test. They held \ntheir own premortem discussion to exploreyou guessed itpotential failure. What if no one used the \ntools? What if the team began to fall apart? In other words, what if their hard work didn't work out? These dire musings generated concrete insights. The team realized that they needed to incorporate \nbetter metrics to understand exactly which tools are used. They also realized that success will depend on \nthe relationships they build and maintain with a broader community, which led to a new focus on \ncustomer relations management. We ended up with a paper print-out with all this amazing information, Ward says. But the most \nmeaningful artifact produced was the conversationthe shared awareness of the experience and our \nvision. That continues to make a difference as we move ahead. Building a Community of Innovators So far, demand for the innovation toolkit is growing steadily both within MITRE and with our sponsors, \nlargely due to word of mouth. We have really focused on making the tools easy to use and grasp. Everything is on our website, \nincluding templates that you can download, Gregorio says. That way, the tools can be available to \nanyone who wants to use them, and we can do our part in democratizing innovation. The members of Team Toolkit are working to create a future in which so many people are using the \ntoolkit that an entire community forms around the concept. We want to mentor, coach, and encourage people to use it, Ward says. We want them to dive in and \njoin the conversation, let us know what is working and what isnt, and make it an interactive experience. --By Twig Mowatt Learn more about the MITRE Innovation Toolkit and how it can help jumpstart your organization's \ncreative and problem-solving processes. https://itk.mitre.org/our-toolkit/\nhttps://itk.mitre.org/ _top\n _GoBack ",
    "text": " Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-4079 [Title] Designing New Ways to Test and Protect Vehicle Computer Systems (a Student Voices interview with MaryAnn VanValkenburg) How is MITRE making the computers in your car more secure? Intern MaryAnn VanValkenburg can tell \nyouby testing and verifying the security of the system components embedded in the vehicle. VanValkenburg, a senior at Worcester Polytechnic Institute (WPI), spent five months at MITRE designing \na way to test embedded security systems. She had the best of both worldsa 2018 summer internship \nworking with other interns and then another seven weeks in the fall completing her Major Qualifying \nProject (MQP) for her college degree. Mitigating Cyber Risks in Embedded Systems Embedded systems security is an emerging disciplineespecially on college campusesbut one MITRE \nhas been leading for years. Because embedded systems are computers built into larger, more complex \nmechanical systems, the cybersecurity of an embedded system relies on the security strength of each of \nits components. That's why MITRE is researching new protocols to ensure the computers embedded in \nvehicles are secure and resilientand help keep everyone on the road safer. \"This summer my team worked on designing a computer program that makes it easier to test the \nembedded systems inside vehicles,\" VanValkenburg says. It's an area continually being expanded as \nmore and more cars are sold with computer-aided systems such as automatic parking and lane departure \nnotifications. \"Our goal was to make an easy-to-use and device-agnostic program that can verify the security of the \ncomputer systems inside cars, planes, power plant control systems, and other machines that have \nembedded systems.\" She created a messaging protocol that enables synchronized testing across multiple \nsystems by simply plugging the testing devices together. \"The protocol I designed allows you to test multiple systems [several cars] at the same time. Because the \nsystems were linked you could test multiple functions such as how a cars lane assist technology would \nrespond when another car tried to merge into that lane.\" The potential uses extend far beyond cars. \"You could also use this protocol to test a challenge-response \ninteraction between two planes that are physically separate but operating within the same \nenvironment,\" she adds. Partnering with Academia MITRE and WPI have a long history of collaboration that includes the opportunity for students to \ncomplete their MQPs on our Bedford, Massachusetts, campus. The students work on MITRE-sponsored \ndesign projects over a seven-week period, from late summer into fall. In VanValkenburg's case, the MQP \ngave her the opportunity to take her summer project to the next level. \"Basically, my MQP project extended the existing embedded testing framework I contributed to during \nmy internship with the goal of making it more flexible,\" she says. \"Imagine that you have a bunch of little \nblack boxes that can talk to each other. You connect one to your computer and one to your car so that \nyou can run code on your car from your computer. This summer, I helped build the concept of the little \nblack boxes. https://kde.mitre.org/blog/2018/07/16/consolidating-embedded-systems-security-through-education-competition-and-business/\nhttps://www.mitre.org/capabilities/cybersecurity/overview?category=all\nhttps://www.mitre.org/capabilities/cybersecurity/overview?category=all\nhttps://www.mitre.org/capabilities/cybersecurity/resiliency\nhttps://www.mitre.org/publications/project-stories/mitre-wpi-collaboratory-brings-a-new-way-of-learning-to-campus\nhttps://www.mitre.org/careers/academic-engagement Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-4079 \"This fall I it took one step further and wrote the language the black boxes can use to talk to each other.\" Intern Competitions are a Valuable Part of the Experience MITRE takes great pride in running a robust internship program that gives students the ability to learn \nand grow. Our interns can participate in contests such as our annual hackathon and embedded Capture-\nthe-Flag (eCTF) competition. They can attend networking events, lunchtime seminars, early career \nprograms, and technical exchange meetings. They can even partner with full-time staff in mentoring \nrelationships that often continue after they return to school. VanValkenburg can attest to many intern opportunities. She wrote code all night during the hackathon in \nJuly. She showcased her work at the Student Expo and participated in a fox hunt (radio transmitter \nlocating competition) run by MITRE's Dan Sinkiewicz. She felt fortunate to be able to work with Nick \nBrown, her MITRE mentor, as well as to participate in some mentoring of younger interns herself. \"It's been a great experience.\" by Kay M. Upham Are you a student who is a good fit for MITRE, too? Explore our current Job Openings and be sure to \nfollow us on Twitter. https://www.mitre.org/careers/student-programs/student-voices/smack-is-back-competition-fuels-intern-innovations\nhttps://kde.mitre.org/blog/2018/07/31/ectf/\nhttps://kde.mitre.org/blog/2018/07/31/ectf/\nhttps://www.mitre.org/careers/student-programs/student-voices/college-interns-thrive-under-mitre-mentorship\nhttps://www.mitre.org/careers/job-openings\nhttps://twitter.com/MITREonCampus _top\n _Hlk529362038\n _GoBack ",
    "text": " FMS Flight Plan Route Sharing Via Datalink FMS Flight Plan Route Sharing by \nDatalink Michael Cramer \nStephen Dabrowski \nKarl A. Meyer \nDavid Stauffer \nAugust 31, 2018 MP180483 MIT R E P R O D U C T Sponsor: The Federal Aviation Administration Dept. No.: P113 Project No.: 0218BB03-RD \nOutcome No.: 3 PBWP Reference: 3-4.1-2, FMS Flight Plan Route Sharing by Datalink NOTICE This work was produced for the U.S. Government under Contract DTFAWA- 10-C-00080 and is subject to Federal Aviation Administration Acquisition Management System Clause 3.5-13, Rights In Data-General, Alt. III and Alt. IV (Oct. 1996). The contents of this document reflect the views of the author and The MITRE Corporation and do not necessarily reflect the views of the Federal Aviation Administration (FAA) or the Department of Transportation (DOT). Neither the FAA nor the DOT makes any warranty or guarantee, expressed or implied, concerning the content or accuracy of these views. All rights reserved. McLean, VA Center for Advanced Aviation System Development Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-4046 ii Abstract \nIn Fiscal Year (FY) 2018, the Federal Aviation Administration (FAA) tasked the MITRE CAASD Corporations Center for Advanced Aviation System Development (MITRE CAASD) with industry collaboration to develop a framework for collecting, storing, and analyzing Flight Management System (FMS) planned route information via Aircraft Communication Addressing and Reporting System (ACARS) datalink. This work is part of a broader activity MITRE CAASD is supporting to track Performance-Based Navigation (PBN) implementation and use in the National Airspace System (NAS). MITRE CAASD explored mutually agreeable methods with Delta Air Lines to collect and archive FMS route downlink messages to provide evidence of the flown approach procedure. MITRE CAASD and Delta Air Lines worked together to ensure that route information could be exchanged with no equipment changes or flight crew involvement. Further, coordination with Delta Air Lines ensured the collection scheme minimized impact to their operations. This work sought to refine approach procedure identification by leveraging existing datalink methods and airline initiated active flight plan downlink requests. Analysis of initial data samples demonstrated MITRE CAASDs ability to extract and identify approach procedure information and correlate with other operational datasets to perform analysis and confirm the flown approach procedure. The methodology for collecting and analyzing downlinked flight data is outlined in this document, as well as recommendations for future airline outreach efforts and evolution of the framework. One finding of this research is the importance of timely flight plan downlink reports. If the downlink message is received too early, the planned approach may be inaccurate due to flight plan changes between the downlink time and execution of the approach. If the flight plan datalink message is collected too late (e.g., at touchdown), the executed approach may be cleared from the FMS reports. MITRE CAASD achieved the goal of proving the support value of targeted downlinks to improve MITRE CAASDs PBN analytics. Expansion of this datalink effort to examine other available data sets may offer opportunities in the future to support safety studies and validation and operational analysis of Next Generation Air Transportation System (NextGen) concepts such as Trajectory-Based Operations (TBO). iii Acknowledgments \nThe authors would like to acknowledge Mahesh Balakrishna, Clark Britan, and David Gouldey from MITRE CAASD for their contributions and assistance in this work. Thanks is also due to the Delta Air Lines for agreeing to provide downlink data and its staff for being willing to meet and participate in the initial data collection efforts, specifically Mike Manatrizio for his technical expertise and execution of data transfers to MITRE CAASD. We would also like to thank Delta Air Lines Captains Mark Bradley and Brian Swain for their support, guidance, and corporate advocacy that made the collection of operational data possible. In addition, we would like to thank to General Electric Aviation FMS and datalink experts Cindy Martini and Joachim Hochwarth for their insights on their FMS product lines and operational details. Finally, the authors would like to thank Kristal Archer for help in preparing and formatting this document. v Table of Contents \n Introduction \nFigure 3-1. Downlink Messages by Aircraft Type \nTable A-1. Flight History and Intent Data Content \nThe Federal Aviation Administration (FAA) faces major challenges in meeting future demand for airport and airspace resources. While meeting demand, the FAA must also balance its goals to protect the environment, reduce traffic delays, and improve operational safety. The FAA is addressing these issues through the Next Generation Air Transportation System (NextGen), which relies heavily on Performance Based Navigation (PBN) procedures and optimized airspace design to enhance system safety, access, capacity, efficiency, and environmental benefits. National Airspace System (NAS) stakeholders have also been requesting PBN procedures to be implemented more expeditiously to reap benefits sooner. To this end, the FAA has implemented thousands of PBN en route, departure, arrival, and approach procedures throughout the NAS. PBN, referring to any combination of area navigation (RNAV) and Required Navigation Performance (RNP), is a system using modern navigation technology that permits aircraft to fly more direct routes and conform very well to the planned path. Translating this ability of flying more direct and less dispersed routes into operationally beneficial procedures is complex and dependent upon many factors. The advanced navigational technology needed for some PBN procedures and the complexity in developing PBN procedures brings significant costs to both the FAA as well as the users. NAS stakeholders therefore are keen on tracking the current state of PBN in the NAS. To address the need to track PBN use in the NAS, the FAA tasked the MITRE CAASD Corporations Center for Advanced Aviation System Development (MITRE CAASD) to develop automated capabilities to derive and report on metrics to help characterize PBN operations in the NAS. The resulting Performance-Based Navigation (PBN) Analysis System derives various metrics through a combination of trajectory-based Threaded Track Flight Story (TTFS) data, aircraft intent (filed/amended flight plans) from Traffic Flow Management System (TFMS), and aircraft equipage data. Determining procedure usage via these data sources is a complex process, requiring advanced algorithms, data fusion, and extensive quality assurance measures [1]. 1.1 Motivation for Research There are significant challenges and limitations associated with tracking procedure conformance and usage through radar track and flight plan data. Approach procedures present a particular challenge in that the approach procedure clearances are not entered into the flight plan. Therefore, with the existing PBN Analysis System framework, approach procedure usage determination would need to rely solely on radar track data. However, overlays and common waypoints may exist between a conventional and a PBN approach procedure, or vectors to Instrument Landing System (ILS) approaches may be similar to defined PBN paths. Further, aircraft flying straight-in approaches without a downwind leg often follow a very similar trajectory regardless of approach type, making it difficult to determine usage based solely on track points. As such, the PBN Analysis System currently only determines approach usage for Required Navigational Performance (RNP) approaches that contain a Radius-to-Fix (RF) leg, representing only ~1% of Instrument Flight Rules (IFR) arrivals in the NAS. These RF legs provide a unique procedure geometry to other approach types, which can be monitored for conformance. 2-2 In order to identify usage of approaches other than RNP approaches with RF turns, MITRE CAASD is exploring the use of other types of data, including Air Traffic Control (ATC) voice communications, and aircraft downlinked intent. Downlink data may not be scalable to a NAS- wide level due to the need for operator involvement in setting up the downlink capability and availability on only certain aircraft types. However, even limited data is useful to evaluate approach utilization, and validate approach-related metrics derived from ATC-pilot voice communications and trajectory-based analysis. In Fiscal Year (FY) 2018, the FAA tasked MITRE CAASD with industry collaboration to develop a framework for collecting, storing, and analyzing FMS planned route information via datalink. This work seeks to improve approach procedure identification by leveraging existing datalink methods and airline initiated active flight plan downlink requests. Data analysis of initial data samples was pursued to demonstrate the ability to correlate downlinks with other flight trajectory analysis to confirm flown approach procedures. The legal, logistics, and processing methodology to collect and analyze downlinked flight data are defined, as well as recommendations for future airline outreach efforts and data integration. Obtaining Aircraft Information via Datalink \nAircraft provisioned with Aircraft Communication Addressing and Reporting System (ACARS) flight and communication management avionics enable airline operation centers (AOCs) to collect flight data for monitoring the companys day-to-day operations. This ACARS capability offers a variety of standard and customizable messages to manage aircraft flight planning and execution. Airline agreements to access existing operation reports have proven to be a viable source for MITRE CAASD research data [2] but can be limited by the airlines established data processes. What is available depends on what chosen subset of ACARS messages operators have deployed in their fleet. The following sections discuss current and potential ACARS message options based on coordination meetings with
Delta Air Lines prior to beginning data collection. Those meetings highlighted their internal ACARS processes and ramifications associated with MITRE CAASDs approach to using that data. This initial effort allowed MITRE CAASD to both address practical data collection issues and ensure protection and appropriate use of proprietary operational data. 2.1 Data Collection Framework Because Airbus and Boeing have implemented relatively common ACARS feature sets, the collection of data across a large proportion of an airlines fleet is assured. For Delta Air Lines, the agreement for this study focused on collecting data from their Boeing 757 and 767 aircraft. MITRE CAASD has previous experience with ACARS data requests that are compatible with those aircraft models [3, 4]. There are two main mechanisms for generating an ACARS downlink: the ACARS report can be generated from AOC uplinked requests or by an automated reporting option within the aircraft avionics. Pilot initiated reports can also be downlinked, but were not considered for this work to reduce complexity and avoid flight deck involvement in the collection activity. 2-3 Previous route identification efforts [3, 4] revealed that flight plan reports collected well before the end of the flight may differ from what was actually flown. As such, selecting viable report trigger points is critical to minimizing the errors introduced by late flight plan changes. For this effort, MITRE CAASD and Delta Air Lines chose to employ existing AOC uplinked report requests to begin collection and allow for data intake and processing maturation. MITRE CAASD explored alternative message content and the possibility to add new AOC requests (triggers), but those actions would likely require airline data processing changes and thus were tabled for the initial collection effort. Potential use of automated (triggered) data reports was also discussed in the Delta Air Lines coordination meetings. Report automation is often activated in the onboard ACARS avionics and monitored by airlines ground systems to streamline the collection of routine aircraft operations. Because this method involves changing both aircraft configuration and the groundside data processing, flexibility in adjusting the trigger location is limited. Therefore, fully automated triggers were not used in this research study. Both of these report generation options require airlines to disclose their data collection processes, potentially revealing proprietary or competition sensitive processes. While ACARS may be standard, downlinked data generation is airline specific and involves the entire range of airline business and human resource practices (e.g., pilots, flight operations, avionics maintenance, information technology, and corporate leadership). Discovery of what ACARS messages are available and collected or could be collected requires negotiation and legal agreements to adapt airline processes in response to MITRE CAASDs data requirements. Given an airline agreement to share ACARS data, the collection process is relatively straight forward. ACARS reports are in a compact but defined character format that can be easily exchanged as text files. For this initial effort, Delta Air Lines periodically e-mailed these files. Other potential data collection schemes include MITRE CAASD establishing a ACARS network connection and tapping the airlines data stream directly. Alternatively, wired delivery of the airline data directly to a MITRE CAASD repository is possible. MITRE CAASD could also pursue formal data management options to restrict access and protect airline data. 2.2 FMS Route Downlink Message General Guidelines During discussions with Delta Air Lines technical experts, a set of collection guidelines were compiled and can be re-used for future discussions with other airline data collection participants. While a variety of ACARS message content is available, obtaining that data may require detailed coordination with individual airlines. A summary of collection guidelines generated during meetings with Delta Air Lines is summarized below. Downlink requests should be transparent to pilots Delta Air Lines indicated a \npreference for methods that have no impact on normal pilot responsibilities or cockpit activities. Onboard FMS systems offer pilot initiated ACARS status reports; however, MITRE CAASDs data collection was designed to avoid flight deck involvement. Ensure downlink requests are acceptable to airline standard reporting processes the use \nof REQFPN,RP (request flight plan, active route report) was currently in routine use by Delta Air Lines. Changing the request to REQPOS,RP (request position, active route report) adds current aircraft position and time tag to the active route response. While that 2-4 data is helpful for MITRE CAASDs follow-on processing, the Position (POS) request was unacceptable to Delta Air Lines as those requests would interfere with one of their primary report automation processes. Downlink content must be compatible with airline and pilot labor relations agreements \nmay involve both airline corporate and Air Line Pilots Association (ALPA) approvals of the collection and intended use of the data. Additional ground based triggering (uplink requests) of reports must be compatible with \nairline operation processes new ground request (triggers) must be negotiated and integrated with airline operations. Airborne based triggering (avionics automation) of reports requires fleet avionics updates \nand associated maintenance even simple requests may be expensive to implement and can be highly dependent on airline fleet mix and their ACARS configuration. Flexibility with data transfer (text or other formats) must consider both MITRE \nCAASD and airline time, hands-on, and infrastructure costs. 2.2.1 Delta Air Lines Agreement Details MITRE CAASD and Delta Air Lines entered into a non-disclosure agreement (NDA) which protects the data that Delta Air Lines shares with MITRE CAASD. It allows MITRE CAASD to receive, analyze, and aggregate the downlinked flight plan data into relevant statistics which can then be publicly shared. The NDA does not allow public sharing of any identifiable data (e.g., by flight number and date of the downlink). Delta Air Lines will periodically collect all the downlinked data in a text file, which will be initially emailed to MITRE CAASD. Once the expansion to the full fleet mix of aircraft continues, this data transmission process may be automated through electronic file transfers (FTP) or a MITRE CAASD Aeronautical Radio, Incorporated (ARINC) connection. 2.3 ACARS Messaging and Avionics Support While aircraft avionics can differ, the ACARS capability resides in a combination of communication management unit (CMU) and flight management system (FMS) features (or interfaced avionics units) that establish and support the air-to-ground datalink connection. Attachment 7 of the ARINC 702A Flight Management Computer System Characteristics [5] describes the ACARS uplink and downlink formats and syntax defined and built from Imbedded Message Identifiers (IMI) and Imbedded Element Identifiers (IEI). These identifiers are generally managed by the Airlines Electronic Engineering Committee (AEEC) to be standard across the industry, but operator customizations can be created for internal use. The ARINC 702A document acknowledges the creative expansion of these identifiers and when found to have value, encourages standardization with the note users are requested to advise the AEEC staff as need arises. Typically, onboard systems employ configuration files for ACARS features to allow operators the ability to restrict or expand flight information streams. Reasons to restrict ACARS features includes the per-bit cost of message content exchanges and the airlines groundside data intake and retention policies. While a number of report downlink request combinations can be created, there is no guarantee that an airlines ACARS customization will support those requests. 2-5 2.3.1 ACARS Messages Initial Collection Effort Early work with airlines and a small ACARS sample from the Delta Air Lines data collection are discussed in Appendix A. Aside from providing details of the downlinked data content, Appendix A contrasts Delta Air Lines data with MITRE CAASDs 737 FMS Test Bench ACARS reports and provides examples of other available ACARS downlinks. MITRE CAASDs Test Bench leverages desktop FMS trainer capabilities to provide simulation of FMS behavior; the Test Bench has been used for various studies, including Metroplex procedure design activities and trials of NextGen TBO and electronic flight bag capabilities. Examination of Delta Air Lines downlink data revealed that their uplink requests are tailored by aircraft type. Subtle differences between MITRE CAASDs Test Bench results and the Delta Air Lines downlinks indicates message customization and aircraft variation exists, but can be ignored by MITRE CAASD for these initial approach usage analysis efforts. Given those downlink variations, it is important to have a clear understanding of any operator- specific ACARS behavior. In future efforts, the downlink content and format employed for Delta Air Lines data intake and processing designs may need case-by-case adaptation to each airlines downlink content. 2.3.2 Potential for ACARS Trigger and Report Customization Previous data analysis efforts have indicated that flight plan reports collected well before the end of the flight may differ from what was actually flown. The ability to eliminate that source of error involves selecting suitable report trigger points. Those collection triggers can either be implemented as ground uplinks or leverage on-board avionics features. To customize ground side automation, the airline must agree to make changes to their uplink delivery (manual or automated) processes. For airborne automation, the avionics (generally the FMS holding the flight plans) must be altered using program option selections to define airline specified messaging. Two examples that customize ACARS implementations use Boeings Adaptable Datalink Databases (ADDB) or Airbus Aircraft Modifiable Information (AMI) files, which
are loaded into onboard avionics. There are significant airline costs to create and deploy customizations because they effectively change the aircrafts avionics and could potentially disrupt ground side data processing. Typically these loads simply activate existing FMS features with little effort. For a higher level of customization, operators can build their own message content that will respond to special request codes not claimed by current ARINC 702A definitions. Conversations with General Electrics Boeing 737 FMS experts and research into the Thales/Smiths Airbus FMS reveals internal FMS capabilities (e.g., airborne triggering mechanisms) that can be enabled by airline customers. These ready-to-use customizations may hold immediate value for continued research into ACARS downlink data processing. Built-in airborne triggers (e.g., time to destination) could easily ensure accurate flight plan reports are collected. For the GE system, the customizable downlink capabilities include: automated triggers (report an aircraft event, such as those described below), transactional (downlink responses to AOC or ATC uplinks), and FMS-CDU activity (status, errors, or faults). Along with the ability to enable or disable these report downlinks, the GE system also allows operators to customize what information messages will be downlinked. As Airbus and Boeing 2-6 define common features on their aircraft avionics, those same GE/Thales features are likely to be present in Honeywell or other suppler avionics offering similar report capability. Particularly useful are the automated event triggers for the GE 737 FMS that include: Five time-to-destination triggers When flight plan modification is executed (EXEC key-in) Estimated Time of Arrival (ETA) change Destination airport change Destination runway change In-Air (speed and strut switch) Cruise level entry FMS wind setting/experienced Modifying these triggers was discussed with Delta Air Lines, but determined to be out of scope for the initial data collection effort given potential complexity of these modifications. Revisiting these options with Delta Air Lines, or use of ACARS customization during discussions with other airlines, is recommended for future efforts. An airline fleet with more airframe uniformity (e.g., Alaska Airlines or Southwest Airlines, who predominantly use Boeing 737 aircraft) may allow the airline to be less at risk of disruption when modifying datalink behavior. Conversations with Alaskas ACARS focal indicated they perform frequent ADDB updates. 2.4 Data Collection Considerations The following data collection considerations are intended to better match data needs to an airlines specific ACARS configuration and operating procedures. An ideal case is an airlines willingness to freely change their ACARS data operations to match the project needs. As that is unlikely without significant resource investment, coordination meetings need to identify project data needs, and balance with the airlines ability and willingness to meet those needs. The considerations are: Communicate and verify project use cases of ACARS data with airline Identify airline data sensitivity and agreements, data processing impacts, data protection \nrequirements Determine current ACARS usage, operating procedures of airline, current and potential \nACARS trigger mechanisms, and aircraft type variations Verify available ACARS data content matches project needs If necessary, determine airline willingness to modify or add ACARS transmissions or \noperating procedures Define data transfer and archiving methodology, such as e-mail/FTP transfers between \nparties or direct ACARS access 2.4.1 Delta Air Lines Collection Details This study required an approach procedure identifier already present in Delta Air Lines ACARS collection scheme. Delta Air Lines datalink process was not significantly modified MITRE CAASD received samples from their standard ongoing AOC downlink monitoring activities. MITRE CAASD and Delta Air Lines Airlines agreed to use Delta Air Lines existing in-range 3-7 AOC report trigger for the initial collection activity. The Delta Air Lines in-range downlink is crew initiated as a step in their arrival briefing, so the timing of this downlink can vary. Once the in-range downlink is received by the AOC, a request for the current flight plan is automatically uplinked; the downlink of the approach procedure message is also automated. Requirements for enhanced downlink trigger mechanisms that isolate the approach phase of flight or capture all flight plan changes were not specifically addressed with this work. As mentioned in Section 2.3.2, automated FMS trigger points could easily reduce planned vs. flown errors on approach procedure identification by using a plan modification or time to destination downlink triggers. Making that a hard requirement would have increased costs to Delta Air Lines and increased the time needed to complete this initial data analysis effort. The value of altering an airlines ACARS data requests and specific trigger points must be acceptable to airline participants. 2.5 Other Uses of Downlink Data This document has a narrow focus of leveraging the REQFPN,RP (request, flight plan, active route) message to derive approach procedure utilization data. Customizing and expanding on the downlink messages and the ability to set the downlink triggers could allow for the use of ACARS in many other areas of research including: Safety studies (vertical performance assessment, procedure blunders, discrepancy in \napproach clearance versus flown procedure) Operational concepts validation (e.g., Time of Arrival Control, Interval Management) Trajectory Modeling Applications (e.g., comparing ground automation trajectories to \nFMS trajectories) Validation of algorithms (e.g. SID/STAR usage algorithms, ATC-pilot voice \ncommunications) The above uses of the data will require greater operator involvement and buy-in. MITRE CAASD continues to develop relationships with various operator and will look to expand data collection as needed to support FAA research activities. Downlink Data Analysis \nMITRE CAASD conducted an initial analysis with the Delta Air Lines downlink data to verify applicability to the approach utilization use case. The following sections show these analysis results, highlighting the scope, features, and accuracy of downlink data received, planned instrument approach trends, and the utility of downlink data for several use cases. Further, the data analysis results highlight some limitations of the in-range call as the primary trigger mechanism. Delta Air Lines provided MITRE CAASD downlink data for most days in May-July 2018 for its B757 and B767 fleets. MITRE CAASD ingested these downlink messages, and fused the messages to published procedure data within Digital Terminal Procedures Publication (d-TPP) and flight trajectory data from System-Wide Information Management Flight data Publication Service (SFDPS), and produced data visualizations and analysis results. 3-8 3.1 Completeness of Downlink Data Delta Air Lines agreed to test the trigger mechanism and initial data sharing for its B757 and B767 fleet. Figure 3-1 confirms that the vast majority of downlink messages received from Delta Air Lines are within the B757 and B767 fleet. Outliers are described more in Section 3.3. \nFigure 3-1. Downlink Messages by Aircraft Type \nFigure 3-2. Daily Downlink Data Availability (May-June 2018) 3-9 Figure 3-2 shows daily downlink data coverage for the Delta Air Lines B757 and B767 fleet arriving in the CONUS; some days in May, late June and early July 2018 were not included in the downlink data sent from Delta Air Lines to MITRE CAASD. Figure 3-3 compares the number of flights for which a downlink message was received to the number of arrivals at each airport. Excluding days for which no downlink data was transferred from Delta Air Lines to MITRE CAASD, this ratio ranges from 75 to 85% of Delta Air Lines B757 and 767 flights across top Continental US (CONUS) airports; note, downlink data is not available for arrivals to non-CONUS airports with the current data sharing architecture. \nFigure 3-3. Flights with Downlink Messages vs. Arrival Counts While the data does not represent all Delta Air Lines operations, there is sufficient data to conduct proof-of-concept data analyses. However, if this downlink data were to be used for broader studies that required full coverage, MITRE CAASD would need to work with the airlines to ensure downlinks are delivered more consistently. 3.2 Approach Procedure Analyses The initial use case for the downlink data is evaluation of approach utilization across the NAS to help the FAA achieve PBN transition goals and related benefits. Figure 3-4 below shows the frequency of respective approach types loaded into the FMS at downlink time for the Delta Air Lines B757 and B767 fleet. The approach type in the FMS route plan is usually Instrument Landing System (ILS), with RNAV (GPS) and RNAV (RNP) approaches also being planned. 3-10 \nFigure 3-4. Planned Approach Type in FMS at Downlink Time Figure 3-5 shows this approach breakdown at an airport level. This type of breakdown has not been possible to create via the trajectory-based analysis in the PBN Analysis System. Most airports utilize ILS as the primary approach, but those that also rely on RNAV procedures include John F Kennedy International Airport (KJFK), Orlando International Airport (KMCO), San Francisco International Airport (KSFO), Southwest Florida International Airport (KRSW), Fort Lauderdale-Hollywood International Airport (KFLL), San Diego International Airport (KSAN), and Louis Armstrong New Orleans International Airport (KMSY). It is important to note that these results reflect the approach loaded in the FMS at downlink time, which may not be the ultimately executed approach type. Section 3.4 expands on the importance of downlink timing on accuracy of the approach, along with data that highlights limitations with the downlink trigger mechanism used in this study. 3-11 \nFigure 3-5. Planned Approach Type in
FMS by Airport 3.2.1 Visual Approach Identification While a planned instrument approach procedure usage will be entered in the FMS and in the downlink message, a planned visual approach is never entered into the FMS. Generally an instrument approach is still entered as a backup an ILS approach at most runways. By analyzing the downlinked approach procedure with respect to trajectory data and associated metrics within MITRE CAASDs Threaded Track Flight Story (TTFS), it is possible to estimate whether an ILS is actually being flown vs. a visual approach. Length of the flown downwind leg and descending flight path angle are both computed in the TTFS system and were used to separate likely visual approaches from likely instrument approaches. Figure 3-6 demonstrates this process at Hartsfield-Jackson Atlanta International Airport (KATL), with likely ILS approaches (as per the plan in downlink) in red, likely visual approaches in blue, and unknown in gray. Likely visual approaches accounted for 52% of the flight tracks evaluated, while 31% are unknown, and 16% are likely ILS approaches. Given the prevalence of Visual Meteorological Conditions (VMC), an extension of this analysis to all airports would likely put visual approaches as the most used in Figure 3-4. 3-12 \nFigure 3-6 Identifying Visual Approaches at KATL Runway 26R 3.2.2 Special Procedure Usage The Flight Standards Flight Technologies and Procedures Division (AFS-400) is responsible for approving use of special, non-public procedures, including both operator- and FAA-designed approaches. A robust FMS downlink architecture would enable more routine monitoring and analysis of special approach procedure utilization, which could benefit the airlines by providing a more analytic justification for evolving procedure design criteria. The FAA would benefit from monitoring performance on special procedures; successful implementation of a special procedure with non-standard criteria may help justify evolution of criteria. Additionally, special procedure utilization and performance data could support FAA annual or biannual review, which is often required for conditional waivers and special procedure approvals. Figure 3-7 shows the planned approaches in FMS downlink data for KJFK arrivals. The majority of arrivals on Runway 13L are planned for the RNAV (RNP) special approach. 3-13 Figure 3-7: KJFK Planned Approach Type in FMS at Downlink Time, by Runway. MITRE CAASD has deployed a capability in the AFS Data Analytics Prototype for AFS-400 to analyze usage patterns for RNP approach procedures with Radius-to-Fix (RF) legs. The AFS Data Analytics Prototype capabilities enable analysis of fused operational usage metrics (e.g., arrival procedure usage), aircraft performance metrics (e.g., climb gradient distributions, final approach deviations), and weather conditions at various points of interest in the National Airspace System (NAS). The RNP approach usage capability has been subsequently tailored to monitor usage of several special RNP procedures, including the special RNP approach for Runway 13L (shown in Figure 3-8). \nFigure 3-8: JFK 13L Special RNAV (RNP) Procedure Usage Delta Air Lines Downlink Samples. Figure 3-9 shows sample Delta Air Lines track data in 2017 that was detected by conformance algorithms as using the JFK 13L RNP approach. The charts show the conformance trend over 3-14 time and the conforming aircraft types. MITRE CAASD is now able to use Delta Air Lines downlink data to validate the track data conformance monitoring algorithm, though data lag prevented the analysis from being possible prior to publication. \nFigure 3-9: AFS Data Analytics Prototype: JFK 13L Special RNAV (RNP) Conformance Monitoring More importantly, for special approaches that do not have distinct lateral or vertical paths from published approaches, downlink data would enable measuring usage and conformance. This would enable reporting metrics similar to the one in Figure 3-9 for all approach procedures. 3.3 Downlink Timing Analyses This section describes the timing of the downlink with respect to arrival time, and explores reasons that the downlink route may not reflect the ultimately executed flight plan. If the in- range downlink trigger is too early, the downlink information could be inaccurate due to a Flight Plan route change prior to execution of the approach. The pilot may not have yet checked, via Automatic Terminal Information Service (ATIS) or communication with Air Traffic Control, for available and unavailable approaches at the airport. ATC also may clear for a different arrival runway or approach type than originally planned based on changing traffic features or weather conditions. 3.3.1 Time/Altitude at Downlink Figure 3-10 shows the time from arrival and flight altitude distributions for downlink messages received from Delta Air Lines. The distributions are fairly wide, but centered in the vicinity of typical Top of Descent (TOD) points, when the aircraft is still in en route airspace and 40 minutes from the arrival airport. The location of downlinks received for JFK arrivals is shown in Figure 3-11 and also highlights the significant variation in distance from airport. As discussed in Section 2.4, there are no timing requirements on the in-range downlink call generally the crew will perform this action when convenient, during the arrival briefing. Follow-on work may include working with Delta Air Lines and other airlines to improve the automated trigger mechanism by sending the message closer to arrival. For example, one possibility is to trigger the message downlink when the landing gear or flaps are lowered on final approach. At this point, flights are established on the approach and only a go around or an abnormal event would cause the flight to deviate from what is programmed in the FMS. 3-15 \nFigure 3-10. Time from Arrival and Altitude at Downlink Time 3-16 \nFigure 3-11. Locations of KJFK Arrivals at Downlink Time, by Runway 3.3.2 Runway/Route Changes in Downlinks Figure 3-12 shows the frequency of flights with multiple downlink messages in the dataset 8% of the flights have more than one downlink. Only 1.1% have a runway or approach procedure change, and most of these are runway changes only 0.3% of flights in the downlink sample had a change in approach procedure without a change in planned arrival runway. As such, using the downlink data provided by Delta Air Lines could result in procedure usage assignment errors as clearances change post-downlink. Note, the trigger mechanism used by Delta Air Lines does not 3-17 automate a downlink upon planned route change, so these percentages likely underestimate the actual frequency of planned runway or approach changes. Improvements to the trigger mechanism, such as making the trigger later in the flight path, could reduce the number of runway and procedure changes after the downlink. \nFigure 3-12. Frequency of Multiple Downlink Messages and Route Changes Figure 3-13 shows the top ten most common changes in approach procedures in the downlink dataset. Arrivals to KJFK 22L switched from ILS to VOR/DME approaches twelve times in the sample dataset. The other most common approach changes were due to a change in the planned arrival runway. \nFigure 3-13. Most Frequent Planned Approach Procedure Changes 3-18 3.4 TTFS Analysis of Flights with Downlinks In order to better characterize accuracy of the intent information within downlinks, the Delta Air Lines downlink dataset was fused to available TTFS trajectory data and associated metrics. TTFS is a analytic product which fuses all available surveillance sources for a given aircraft to provide a single trajectory and associated flight performance metrics. TTFS enables higher fidelity analysis for safety, aircraft performance, criteria and standards, benefits, and operational performance reporting. This section reinforces the limitations of the in-range call as a trigger mechanism for downlink, specifically the inability to track planned runway and approach changes that occur well after TOD. 3.4.1 Downlink Time compared to TOD TOD is estimated via trajectory analysis algorithmically in the TTFS data process [6]. Flights in the downlink data were joined to TTFS flights based on flight metadata (e.g., callsign). Figure 3-14 shows a comparison of TOD time to the time of latest downlink for a given flight. The wide distribution indicates that the in-range call varies significantly with respect to TOD, and often comes prior to TOD. 3-19 Figure 3-14. TOD Time Compared to Downlink Time 3.4.2 Runway Changes After Downlinks With flight plan route messages often downlinked prior to TOD, the next analysis evaluated whether this significantly impacts accuracy of the planned runway and approach in the downlink messages. For this analysis, we compared arrival runway assignments in TTFS, algorithmically determined based on trajectory alignment to arrival runways just before touchdown, to the planned arrival runways in Delta Air Lines downlink messages. Figure 3-15 shows the top airports in the downlink dataset, with flight counts for which the runway assignment in TTFS matched the planned runway in downlink message (blue) and flight counts for which the runway assignment did not match the downlink message (red). The larger airports have a substantial proportion of flights that landed on a different runway than the in-range downlink indicated, including KATL, where approximately 40% of flights landed on a different runway than was planned in the downlink. 3-20 \nFigure 3-15. Runway Changes (based on trajectories) After Downlink Message Figure 3-16 shows the most frequent differences between the planned runway in downlink message and the trajectory-based runway assignment. Flights landing on a parallel
runway from the planned runway at the in-range call is very common at the larger airports, though the downlink usually reflects an accurate runway configuration. \nFigure 3-16. Most Frequent Differences between Downlink Runway and Arrival Runway 5-21 These results confirm that the in-range trigger is not sufficient for obtaining accurate runway and approach information for all flights, which impacts the accuracy of approach utilization data presented in Section 3.2. Future efforts should focus on alternative trigger mechanisms, including triggers a specified distance/time from arrival, or automated triggers for any flight plan route change. Airline Feedback on Collection \nDelta Air Lines made several observations that are consistent with the original research motivation for tracking approach utilization via downlink: There is a unique value to gathering and analyzing data on which procedures are being flown following PBN implementations. The return on PBN investments needs to be measured and the results will inform future implementation throughout the NAS. The downlink framework provides definitive data that will help the FAA and industry evaluate whether PBN capabilities are bearing fruit or being utilized appropriately across the NAS. With better information on which approaches are being utilized, the FAA can better allocate resources to increase safety and operational use of procedures, and develop new procedures and technologies that will be beneficial. ATC may also benefit from an increased understanding of approach utilization trends and coordination with operators and the FAA on a strategy going forward. Local operators can leverage the same data to measure their respective fleets participation rates in locations where specific PBN procedures are available (e.g., did we fly the RNAV RNP AR procedures in locations where our company policy advises us to, for safety and performance related reasons). Operators can also use this data to determine if and where they may need to address training or procedural deficiencies to increase the likelihood crews will fly these procedures. Delta Air Lines has been engaging ATC and internally with their Training and Standards group to increase usage of PBN procedures at KATL. The downlink data may be useful for evaluating progress in PBN procedure usage as a result of this engagement. Recommended Next Steps \nThis report used a sample of downlink data, periodically emailed to MITRE CAASD from Delta Air Lines, to demonstrate the ability to extract and analyze planned instrument approaches and illustrate other potential uses of the data. However, for continued research this methodology presents two challenges. First, an expansion to additional aircraft types and operators will increase data volume and necessitate a transition from e-mail delivery to an automated data capture and processing system. Further, during flight operations, pilots commonly make flight plan changes to respond to emerging airspace and air traffic control conditions (e.g. runway changes). The ability to adjust collection content and timing offers a potential increase in the quality, types of data, and analyses that can be performed. Ideally, a running log of flight plan changes would be available for every flight, but available downlink content and collection timing is airline-specific. Data sharing agreements must balance analysis needs and the feasibility of airline participation in collecting and sharing the downlink data. Recommended improvements to downlink collection activities for future efforts include: 5-22 Adjust trigger mechanism to improve context of data collected need to be addressed Airline operations agreements to request data at more times of interest (e.g., a \ndownlink when ~5 miles from the destination airport would increase the likelihood the approach procedure in downlink is correct, or triggering the downlink when the landing gear or flaps are lowered) Airline activation of internal FMS triggers (e.g., the plan modification trigger \nwould ensure up-to-date FMS plans are collected) Explore downlink content or acceptable modifications to help identify control modes \nover the various phases of flight (e.g., the aircrafts ability to downlink LNAV, VNAV, or ILS coupled autopilot guidance would separate FMS and hand-flown approach segments). The archive of downlinked messages can leverage various data management tools to \naddress airline agreements (e.g., access, redaction and retention policies) Increase awareness of downlink flight data, processing schemes, and analysis steps for \nother FAA and industry stakeholders. Documentation of downlink capabilities is available, but often highlights downlink functionality for research concepts, rather than for facilitating operational data analysis. Explore the research potential for other ACARS downlink capabilities by surveying and \ndocumenting common airline downlinks that may be applicable for future studies. Knowing what data is available, and common customizations increases awareness of existing data sources and how and where that information could be obtained. If appropriate, integrate downlink data with TTFS and PBN Analytics for data intake and \nfollow-on processing. The analyses in this report used downlink data fused to trajectory data sources. Expansion of data volume with additional airlines would likely make it practical and cost effective to automate these data fusion efforts and leverage established data management methods. 6-23 References [1] J. Timberlake, S. Chase, O. Eldridge and K. Meyer, \"Performance-Based Navigation Analytics Quality Assurance, Capability Enhancemnets, and Stakeholder Engagement,\" MP170504, The MITRE Corporation, McLean VA, August 2017. [2] C. Wynnyk and D. Gouldey, \"2011 Seattle Required Time of Arrival (RTA) Flight Trials Analysis Report,\" MP120061, The MITRE Corporation, McLean, VA, April 2012. [3] D. Gouldey and Cramer, Mike, \"E-mail Discussions, 2016 American Airlines data collection,\" 2018. [4] R. Sgorcea, \"Viability of Aircraft Communication Addressing and Reporting System (ACARS) to support Mid-Term RTA Concepts,\" MP120211, The MITRE Corporation, McLean, VA, April 2012. [5] ARINC, \"Advanced Flight Management Computer System Arinc Characteristic 702A-1,\" Annapolis, MD, January 2000. [6] Performance Based Navigation (PBN) Dashboard Updates and Level-off Metrics, Attachment to F073-L16-024, The MITRE Corporation, McLean VA, August 2016. A-1 Appendix A ACARS Datalink Samples \nThis section describes early message format examination with American Airlines route (containing procedure data) downlinks as well as an examination of the Delta Air Lines downlinks collected for this work. The Delta Air Lines downlinks are compared to results generated by MITRE CAASDs GE 737 FMS Test Bench, which was also used to examine other potential ACARS message requests for procedure identification and other NAS research activities. A.1 Early Uplink Request Efforts American Airlines Airbus A319 and Boeing 737 Early efforts with American Airlines and the ACARS AOC IEI request RP failed on the GE-737 and Thales/Smiths(GE) A319 ACARS avionics. Airbus Sample: \nQU QXSXMXS \n.TULCVAA 102143 \n_FMD \nAN N9002U/FI AA0231/MA 001I A319-115 \n- REQFPN,RP.FN44CD \nQU TULCVAA \n.QXSXMXS 102143 \n_FML \nFI AA0231/AN N9002U \nDT QXS MIA7 102143 F61A \n- REJREQ,214323,001,,001,C2EB - FAILED (no capability for RP request) 737 Sample: \nQU DDLXCXA \n.TULCVAA 102131 \n_FMD \nAN N835NN/FI AA2519/GL PLS \n- REQFPN,RP.FN44CD QU TULYVAA \n.DDLXCXA 102131 \n_FML \nFI AA2519/AN N835NN 737-800 \nDT DDL PLS 102131 F26A \n- REJREQ,213113,1,,F6C2,14968 - FAILED (no capability for RP request) The MITRE CAASD suggestion to replace the ACARS AOC request RP with the RI element identifier resolved the problem with the GE-737 and Thales/Smiths(GE) A319 ACARS avionics. \nQU DDLXCXA \n.TULCVAA 062020 \n[1]FMD \nAN N968AN/FI AA2389/GL DFW \n- REQFPN,RI.FN686E 737 Change: \nQU TULYVAA \n.DDLXCXA 062020 \n[1]FML A-2 FI AA2389/AN N968AN 737-800 \nDT DDL DFW 062020 F46A \n- FPN/RI:DA:KDFW:AA:KSNA:CR:DFWSNA30:R:18L(20R):D:WSTEX1.CIKAN:F:CIKAN..EWM..BXK.J212\n.CULTS..JOLAR:A:KEFFR3.JOLAR:F:VECTOR..DISCO..BONKE:AP:ILS 20R/FNAAL23896167 Airbus Change: \nQU DDLXCXA \n.TULCVAA 062024 \n[1]FMD \nAN N5007E/FI AA0231/GL MIAV \n- REQFPN,RI.FN686E \nQU TULYVAA \n.DDLXCXA 062024 \n[1]FML \nFI AA231/AN N5007E A319-115 \nDT DDL MIAV 062024 F66A \n- RESREQ/AK,1158AF6 \nQU TULYVAA \n.DDLXCXA 062024 \n[1]FML \nFI AA231/AN N5007E \nDT DDL MIAV 062024 F67A \n- FPN/FNAAL231/RP:DA:KMIA:AA:MMMY:CR:MIAMTY11:R:08R..DHP,N25480W080209.A509.MARCI..KR\n66S,N26000W082000..CIGAR,N27296W084470.Q102.BLVNS..CRP,N27542W097267..MFE,N26104W09814\n4..REX,N26006W098139BC7A (truncated) For the Airbus RI request the RP response is due to an Airline customization, the RP and RI response content is identical. This example shows the effect of tailoring downlink requests based on airline customizations of ACARS behaviors. Delta Air Lines use of the RP request for the samples collected in this study would produce no response from the 737 FMS. Because there is evidence Delta Air Lines tailors their downlink requests by aircraft type it is likely they use the RI request for that aircraft model. A.1.1 Delta Air Lines Airline Data Samples With the Delta Air Lines dataset the in-range AOC RP request was used and a small a sample of a transferred file is shown in Figure A-1. Agreements were to sample Delta Air Lines Boeing 757 and 767 Delta Air Lines operations, however, examination of these records showed Delta Air Lines ACARS data included other fleet aircraft (B717, A350). MITRE CAASDs data intake and processing can cross reference identify tail numbers to identify and categorize by aircraft type if necessary. \nFigure A-1. Delta Air Lines Collection Sample A-3 Separating Delta Air Lines header information and examining an ACARS report line from the first line of the sample above reveals the Approach Procedure detail this work needed. Figure A-2. Expanded Delta Air Lines ACARS Report Line Sample Figure A-2 expands the reports original ACARS route report by placing each of the ACARS IMI/IEI directives (FPN, TS, RP, and FN) on a separate line. The content in the IEI responses are expanded below. /TS requested Time Stamp response. This time tag directly corresponds to the Delta \nAir Lines header and confirms the report header can be used for records not explicitly containing a
time stamp request. /RP requested Active Route response. This content is further expanded: \no :DA: departure airport KGSP (Greenville Spartanburg SC) \no :AA: arrival airport KATL (Atlanta GA) \no :R: departure runway 04 \no :A: arrival procedure OZZZI1.DGESS (STAR and transition) \no :AP: approach procedure ILS 08L.LARII (procedure and transition) \no (-) arrival runway (08L) /FN requested Flight Number response. Delta Air Lines Flight DAL The (redacted) tail number of this aircraft included in the header information identified this report was generated by a Delta Air Lines Boeing 717. Inferred from this particular report is the AOC uplink request for this report (and other 717s) is likely REQFPN,TS.RP.FN. Examination of Delta Air Lines reports revealed their uplink requests appear to be tailored by aircraft type. For the small sample of reports in Figure A-1 the uplink request (REQFPN,RP) associated with both a Boeing 767 and 757s is different than that used for an Airbus A330 (REQFPN,FN.RP). As the Active Route (RP) request holds the desired message this aircraft variation can be ignored for MITRE CAASDs approach identification efforts. Ensuring MITRE CAASDs awareness of uplink request message variations is a useful discussion item during the airline agreement process. Airline uplink request tailoring may have unexpected impacts on data collection content and subsequent processing. A.1.2 General Electric 737 FMS Test Bed ACARS Reports To confirm the initial Delta Air Lines ACARS data set, MITRE CAASD executed similar request on the GE 737 FMS Test Bench with a known departure SID and the same Delta Air Lines STAR arrival and approach procedures. The uplink request /RP was replaced with a GE FMS /RI variation that produces identical content. The GE response shown in Figure A-3 A-4 matches the Delta Air Lines content but does contain some format differences along with the GE FMS departure information. These subtle ACARS variations must be accommodated in the data collection and processing steps. \nFigure A-3. GE Test Bench Results using Delta Air Lines Flight Plan Sample /TS requested Time Stamp /RI requested Active Route response expanded: \no :DA: departure airport KGSP \no :AA: arrival airport KATL \no :R: departure runway 04 and \no (-) arrival runway identity (08L) \no :D: departure procedure BIMMER1.ACERB (SID, transition) \no :A: arrival procedure OZZZI1.DGESS (STAR, transition) \no :F: flight plan segments (departure, arrival, missed approach hold) \no :AP: approach procedure ILS 08L.LARII (procedure and transition) FN requested Flight Number response matched the programmed A.1.2.1 GE 737 FMS Test Bed ACARS Variation (POS) Position Report To further examine potential ACARS report variations the MITRE CAASDs GE 737 FMS Test Bench was programmed with a sample flight plan with departure, en route, and arrival elements and flown. Figure A-4 represents the two Control Display Unit (CDU) flight plan LEGS pages containing the flight plan departure legs. A-5 \nFigure A-4. FMS Flight Plan LEGS pages with lateral waypoints and vertical constraints Replacing the ACARS the Flight Plan IMI request (FPN) with a Position Request (POS) is a relatively to simple change that will add the exact time and position of the response report downlink (REQPOS,RP request, position report, active plan). Figure A-5 shows both the ARINC 702A-1 standard definitions of the report and inflight POS response from the GE FMS. While the bulk of the downlinked message matches the ARINC standard definitions the GE FMS shows entries that have been customized. \nFigure A-5. ARINC 702A format and GE FMS POSition Report Addressing these report anomalies to understand the airlines ACARS behaviors is necessary for MITRE CAASD to correctly interpret the report data. Regardless, the latitude, longitude, altitude and Greenwich GMT of the POS response clearly identifies the location and time this report was generated. Embedding that time and location as part of the report records can help manage analysis tasks as the data contains self-identifying content. As mentioned in Section 2.2, Delta Note: (right) ARINC 702A-1 format and (left) and POS header (blue text) and GE FMS output (black) A-6 Air Lines coordination meetings indicated their data operations reserved the POS report for dedicated purposes. Access or use of the POS request message was not acceptable for this initial MITRE CAASD effort. The use of position reports may not be a problem for future airline data collection agreements. Recognizing these data processing implementation details implies MITRE CAASDs data analysis must be able to compensate for airline collection agreements. The existing FPN format used for Delta Air Lines data intake designs may need, or benefit from adaptation for other airlines content. A.1.2.2 Other ACARS Downlink Content Not considered for this work but defined in the ACARS feature set are the Flight Plan History IEI (FH) and the Intent Data List (IDL) downlinks. When the FMS is programmed to respond to these requests the resulting information provides detailed internal FMS prediction and trajectory data shown in Table A-1. Table A-1. Flight History and Intent Data Content Figure A-6 shows both the Flight History and Intent Data List reported by the GE 737 FMS software. The columns with data headings for the Flight History correspond directly to the FMS CDU page information displayed to the pilots. There were no winds for this sample and altitudes are in 10s of feet (196 represents1960 feet). The Flight Plan History is derived from the state data used for by the FMS for its internal predictions. By downlinking that time, fuel, and wind information the ground side trajectory predictions may be improved. Use of the ETA values could be fed to scheduling algorithms for metering, RTA estimates, or interval management. Any use of this data must accommodate the fact that FMS predictions are dynamic so these values will vary as the flight progresses. The Flight Plan History reports fuel information (for aircraft weight estimates) is very useful for performance predictions but airlines may restrict access to that fuel use data. Airline data agreements regarding Flight History reports must consider competition sensitive data. Flight History Content \n(predictions at waypoint) Intent Data Content ETA ETA Waypoint Name Waypoint Latitude Longitude Speed Altitude Altitude Fuel Temperature Waypoint Type (Lateral, Vertical) Wind Speed Lateral Turn Direction Wind Direction Lateral Turn Radius Airspeed Vertical T/C, T/D, Cross, Transition Procedure Indicator . Track to Next Waypoint . Distance to Next Waypoint A-7 In comparison the IDL report provides FMS trajectory data and with definitions in the ARINC 702A-1 characteristics could be used to recreate the three-dimensional version of the predicted flight path. Another potentially useful aspect of the IDL report is the identification of (RNP) RF legs in the flight plan. These points correspond to the CDU pages entries for ZONOK (370) and ZETEK (340) that indicate RF arc transitions at 3.7 and 3.4 nm respectively. \nFigure A-6. ACARS Flight History (left) and Intent Data List (right) B-1 Appendix B Abbreviations and Acronyms ACARS Aircraft Communications Addressing and Reporting System ADDB Adaptable Datalink Databases ADS-C Automatic Dependent Surveillance Contract AEEC Airlines Electronic Engineering Committee ALPA Air Line Pilots Association AMI Aircraft Modifiable Information AOC airline operation centers ARINC Aeronautical Radio, Incorporated ASIAS Aviation Safety Information Analysis and Sharing ATC Air Traffic Control ATIS Automatic Terminal Information Service CAASD Center for Advanced Aviation System Development CDA Connected Data Architecture CDU Control Display Unit COTS Commercial Off-the-Shelf d-TPP Digital Terminal Procedures Publication EFVS enhanced flight vision system ERAM En Route Automation Modernization ETA Estimated Time of Arrival EXEC Execute FMS flight plan modification FAA Federal Aviation Administration FH Flight History (IEI) FMS Flight Management System FPN Flight Plan IMI FTP file transfer protocol GBAS Ground Based Augmentation System GE General Electric GLS GBAS Landing System GPS Global Positioning System B-2 HITL human-in-the-loop IDL Intent Data List IEI Imbedded Element Identifiers IFR Instrument Flight Rules ILS Instrument Landing System IM Interval Management IMI Imbedded Message Identifiers LNAV Lateral Navigation NAS National Airspace System NDA non-disclosure agreement NM Nautical Miles PBN Performance-Based Navigation POS Position Report IMI REQ Request Report IMI RF Radius to Fix leg RNAV area navigation RNP Required Navigation Performance RTA Required Time of Arrival SFDPS System-Wide Information Management Flight data Publication Service SID Standard Instrument Departure SWIM System Wide Information Management TBFM Time Based Flow Management TF Track to Fix Leg TOAC time of arrival control TOD Top of Descent TTFS Threaded Track and Flight Story VMC Visual Meteorological Conditions VNAV Vertical Navigation VOR/DME VHF omnidirectional range / Distance Measurement Equipment Disclaimer \nThe contents of this material reflect the views of the author and/or the Director of the Center for Advanced Aviation System Development (CAASD), and do not necessarily reflect the views of the Federal Aviation Administration (FAA) or the Department of Transportation (DOT). Neither the FAA nor the DOT makes any warranty or guarantee, or promise, expressed or implied, concerning the content or accuracy of the views expressed herein. This is the copyright work of The MITRE Corporation and was produced for the U.S. Government under Contract Number DTFAWA-10-C-00080 and is subject to Federal Aviation Administration Acquisition Management System Clause 3.5-13, Rights in Data-General, Alt. III and Alt. IV (Oct. 1996). No other use other than
that granted to the U.S. Government, or to those acting on behalf of the U.S. Government, under that Clause is authorized without the express written permission of The MITRE Corporation. For further information, please contact The MITRE Corporation, Contract Office, 7515 Colshire Drive, McLean, VA 22102 (703) 983-6000. publish or reproduce this document, or to allow others to do so, for Government Purposes Only. ",
    "text": " PowerPoint Presentation Overview | # | \nJoint Concept of Operations Refinement\nand Spiral Development\nCensus Operations\nTax Refund Fraud\nASW\nStrategic TCT\nElectronic Warfare\nTactical Logistics\nCUAS Operations\nUAS Ops\nBorder Security\nEmergency Management\nSpecial Ops\nCyber Warfare\nAdvanced Weapons\nJoint Surface Warfare (JSuW)\nJoint Time Sensitive Targeting\nISR Management\nSmall Combatant Joint Command Ctr\nJoint Chemical/Bio Security\nBMD NSEL* and Simulation Experiments\n(SIMEXs)\n**OSD-sponsored National Security Experimentation Lab (NSEL) | # | Simulation, Experimentation and Analytics Lab (SEAL): \nNew Home for NSEL and the SIMEXs\nLarge scale motorized, reconfigurable data wall allows for replicating different operating environments. SEAL Unclassified \nComputing \nClassified \nComputing All computing for the SEAL is extrinsic to lab, leveraging a Multi-Level Security KVM \nto allow for easy transition between unclassified and classified NSEL computing environments | # | Simulated Systems\nReal World\nSimulated Platforms\nSimulated Sensors/Weapons Target Nomination ID & Fusion\nTarget\nDevelopment\nISR Management Platform Tasking\nPlatform Tasking\nNSEL and Simulation Experiments (SIMEXs) | # | \nLevels of Experimentation\nExercise and Training Monte Carlo Simulations\nSimulated C4ISR Systems/Weapons/Operators\nTTXs/Wargames\nWhite-carded C4ISR Systems and Weapons/Real Operators Field Events\nReal Operational \nenvironment and C4ISR\nSystems/weapons/Operators\nSIMEXs\nSimulated sensors/weapons and real C4I Systems/Operators Increasing Operational \nFidelity/Cost Agile Development\nTTP/Technology\nPolicy/Strategy\nStatistical\nPredictions | # | \nNSEL and the SIMEXs provide an environment for agile development of CONOPS/TTP and technologies in various tactical scenarios. SIMEXs are distinct from Monte Carlo simulations in that they operate in real-time and included tactical operators using real C4I systems to conduct various time-sensitive crisis-action missions. SIMEXs also differ from table top exercises or wargames because their stimuli are data represented in C4I systems instead of white cards or moderated scenario injects. Further, SIMEXs participants are normally tactical operators and not policy-level decision-makers. Live exercises are conducted in the field (usually with real C4I, sensors and weapons); however these events are normally highly structured and are used for training. There is usually little room in a field event for CONOPS or technology development.\n5 COCOM Industry\nLabs Government\nLabs (MCTSSA) NSEL DREN/SDREN\nEmploy SDREN/DREN for Distributed SIM/C4I | # | SIMEX Sponsorship and Themes\nFY01-03\nFY04-6\nFY07-09\nFY10-12\nFY13-15 Chem/Bio Defense, C/BMD, EMRG, LASER, UDOP, Advanced Sensors, NSW, UAS Ops, ISR Mgt, NSW and Cyber Navy TST, Army, Air Force, Navy and Joint TST, SOCOM SRC, COP, Advanced sensors/weapons OSD AT&L/Joint Staff Autonomous/Netted Weapons and Sensors, SPECOPS, Irregular Warfare, MDA, COP/CTP ISR Mgt 62 SIMEXs Conducted Joint TST, MDT, Advanced Sensors/Weapons, MDA, COP/CTP, NSW/SSGN Ops DHS S&T/CBP/Commerce AFRL/ESC\nPEO U&W/A/C4I and ONR\nPEO-Subs JSuW JCTD\nMCSC\nDTRA/MDA\nNORTHCOM/STRATCOM\nUAS Ops, Strategic TCT, ASW, Border Security, DSCA, ASuW, Census, LASER, AOC WS\nDASD EC&P FY16-18 ARCENT/AFCENT Treasury\nUSW, Tax Refund Fraud, LASER, CUAS Ops, EW. Tactical Log, IFT Army RCO/PM MC | # | \n7\nAlthough all services were represented in the Joint TST SIMEXs, only three services continued to sponsor SIMEXs after 2005.\nA consistent sponsor of the SIMEX program was the Navyincluding programs within PEO U&W, A and C4I. In addition, multiple Departments of ONR sponsored SIMEXs on various C4ISR and weapon themes. The PEO Subs sponsored three SIMEXs examined SSGN battle management. The Air Force (ESC and AFRL) sponsored SIMEXs examining AOC WS 10-2, ISR management as well as a User Defined Operational Picture (UDOP). MARCORSYSM (MCSC) sponsored multiple SIMEXs examining the impact of C2PC on various Naval and Marine Corps missions. Joint sponsors of SIMEXs included the Joint Surface Warfare JCTD, NORTHCOM and STRATCOM. NORTHCOM was interested in UAS operations in the National Air Space as well as Defense support to Border Security and Civil Authorities. The STRATCOM theme was Strategic Time-critical targeting. MDA and DTRA sponsored SIMEX events that examined advanced sensors for missile defense and Chem/Bio defense. Non DOD sponsors include DHS S&T, CBP and the Census Bureau. The DHS S&T SIMEX focused on Bio-Security and , the CBP SIMEXs on Border Security technologies and the Census SIMEX on 2020 Census Re-engineering. 4 Months 2 weeks 4 weeks Final Planning Conference (FPC)\nInitial Planning Conference (IPC)\nConcept Exploration\nExperiment Design\nExperiment Integration & Test\nExperiment Execution\nExperiment Analysis The MITRE SIMEX Schedule: Activities/Output | # | \nThe SIMEX process is normally 5-6 months. The process begins with concept development and an Initial Planning Conference during which the sponsors and stakeholders define SIMEX objectives and the scenarios. Thereafter, the SIMEX team refines the scenario and CONOPS and develops and tests the simulation/C4I infrastructure. While the integration and testing is ongoing, the data collection lead will build the Data Collection and Analysis Plan (DCAP) that delineates essential data collection to support the SIMEX Objectives. The SIMEX itself is executed over two weeks. The first week includes operator training on the new SIMEX CONOPS and technology. The second week will include 8-10 three-hour scenarios during which the operators execute the SIMEX and evolve CONOPS/TT&P (and possibly technology) in accordance with the experiment objectives. In parallel, the data collection team will be executing the DCAP and producing incremental After Action Reviews (AARs). In approximately a month after the SIMEX, the data collection team will produce a Briefing and Final Report on the SIMEX results. \n8 SIMEX Director \nManages planning & execution\nof individual SIMEXs Technical Director \nManages technical\nintegration & testing Data Collection/Analysis Lead \nDevelops/executes data collection & analysis plan & authors reports CONOPS/Scenario Lead \nDevelops scenarios\n& simulation architecture Development Lead\nDevelops and integrates\nnew SIMEX software Portfolio Manager\nManages project staff & coordinates NSEL sponsorship\nSIMEX Team | # | Monday\nRun 1\nIn-briefs;\nCONOPS Briefs Tuesday\nRun 3\nRun 2 Wednesday\nRun 5\nRun 4 Thursday\nRun 7\nRun 6 Friday\nRun 9\nAAR\nRun 8\n0830-0900: In-brief\n0900-1200: Morning Run\n1200-1300: Break for lunch\n1300-1500: Afternoon Run \n1500-1600: Hot Wash\nDaily Schedule AM PM\nSample SIMEX Week * | # | \nMeaningful statistical analysis requires full pair-wise comparison of each variable with all other variables\nRun matrix complexity increases with the number of variables and the number of values tested for each variable\nThe limited number of runs available\nin a SIMEX necessitates choosing\nvery few variables to test. \nHidden variables can complicate the analysis and must be taken into account Analysis Overview How Many Variables? | # | \nThe independent variance of each factor contributes to the total variance measured.\nANOVA helps us differentiate between what is the result of normal variation and what is an actual effect.\nWe isolate the effects by turning each factor OFF and ON in every combination. \nWe test if changes observed are greater than what we would expect given each factors variance.\nWe assume there will be no impact and reject H0 if there is an impact (i.e. rejection means we found something interesting).\nSIMEX Approach: Analysis of Variance\n(ANOVA)\n| 12 |\nNull Hypothesis H0: Factor X will have no impact on system performance Box-Whisker plots are a satellite view of the datas distribution | # | \n SIM Oct Nov Dec Jan Feb Mar Apr May Jun Jul Aug Sep Oct\n 1 IPC S&C I&T DR EX Rep \n 2 IPC S&C I&T DR EX Rep \n 3 IPC S&C I&T DR EX Rep \n 4 IPC S&C I&T DR EX Rep \n 5 IPC S&C I&T DR EX Rep \n 6 IPC S&C I&T DR EX Rep \n 7 IPC S&C I&T DR EX Rep \n 8 IPC S&C I&T DR EX Rep Legend:\nInitial Planning Conference (IPC)\nScenario & CONOPS (S&C)\nIntegration &Testing (I&T)\nDry Runs (DR)\nSIMEX Execution (EX)\nSIMEX Reporting and Analysis (Rep) SIMEX Waterfall | # | \nSIMEX 19-X Sample Schedule (Slot 3) May\nApril\nMarch\nFebruary\nJanuary\nDecember\nPreliminary SIMEX\nPlanning\nBeginning in December\nInitial Planning\nConference\nDecember 13-14\nCONOPS/Scenario\nDevelopment\nDecember-January\nSIM/C4I Development/\nIntegration\nJanuary-February\nFinal Planning\nConference\nMarch 7\nDistributed\nIntegration/Testing\nMarch-April\nSIMEX Operator\nTraining\nApril 8-12\nSIMEX\nExecution\nApril 15-19 \nSIMEX\nHighlight Reel\nMay 3\nSIMEX\nFinal Report/AAR\nMay 31 | # | \nParticipate in Planning Conferences Provide C3/sensor/weapon technical parameters\nas able Review Proposed C4ISR Environment Provide Operators\nfor the SIMEX\n(Red and Blue Cells) Review Post-SIMEX Briefing/Report Evolve CONOPS and TTP Guide Scenario Development Tailor results to influence CONOPS/TTP and Acquisition SIMEX Sponsor Responsibilities | # | 15 CONOPS Development Data Analysis/pair-wise comparison Application Evolution \nSIMEX Outcomes/Products The SIMEX Experience SIMEX Process | # | \nFour products generally derive from the six-month SIMEX process (depicted in slide 2): CONOPS evolution which begins in the early months of SIMEX planning and then crystalizes in SIMEX execution;\nApplication development and integration which occurs in the later months of the SIMEX process and then intensifies during SIMEX execution;\nThe sponsor, stakeholder and operator experience of the SIMEX which highlights in real-time key issues and insights. This experience is usually documented in the SIMEX highlight reel delivered two weeks after the SIMEX; and\nThe analytical products (Final Report and Companion Briefing) compile observations and statistics related to the SIMEX objectives and experimental variablesusually delivered 6 weeks after SIMEX execution. 16 MITRE SIMEXs: A Differentiating Capability\nAn even playing field to industry and Government for distributed experimentation\n A state-of-the-art venue for strategic/tactical experimentation for sponsors A cost-effective mechanism for risk reduction events leading up to live demonstrations and exercises\nAn environment for emulating current and future C4I, Sensor and Weapon systems in realistic scenarios | # | 17 MITRE is a not-for-profit organization whose sole focus is to operate federally funded research and development centers, or FFRDCs. Independent and objective, we take on some of our nationsand the worldsmost critical challenges and provide innovative, practical solutions.\nLearn and share more about MITRE, FFRDCs,\nand our unique value at www.mitre.org | # | ",
    "text": " \nCase number 18-4444. Title: Interns Break Down Barriers for the deaf/Deaf and Hard of Hearing Teaser: About 10 percent of Americans are deaf/Deaf or hard of hearing. This past summer, a \ndedicated group of MITRE interns boosted the Federal Communications Commission's mission to \nimprove access to the technology that lets people connect across multiple devices. Calling a friend. Joining a work conference call. Refilling a prescription by phone. Most of us use mobile \ndevices and apps to communicate daily without a second thought. However, if youre part of the 37.5 million members of the deaf/Deaf or hard of hearing communities in \nthe U.S., you need a way to see the conversation. That could mean signing with an American Sign \nLanguage (ASL)-to-English interpreter via video relay or having a discussion facilitated by captions. But how is communication delivered accurately, quickly, and reliably between people who are hearing \nand people who are deaf/Deaf or experience hearing loss? Is communication across multiple devices and \nplatforms practical? And is the technology compatible? During the summer of 2018, nine MITRE internssix of them members of the deaf/Deaf or hard of \nhearing communitiesput several technologies to the test. The goal: Create an optimal user experience. \nThey ran and re-ran baseline tests in our Federal Communications Commission (FCC)-sponsored National \nTest Lab (NTL) in McLean, Va., or in our NTL-Rochester, N.Y., lab. This summers testing and validation \nwas part of an ongoing, growing effort as more interns from the community lend their time, talent, and \nconsumer experience to dismantle barriers to communication. The FCC funds the Telecommunications Relay Service, or TRS, to ensure that people who are deaf/Deaf, \nhard of hearing, deaf/blind, or speech-disabled have full access to advanced communications services \nand equipment free of charge. The service was launched in the 1970s. Since the passage of the \nAmericans With Disabilities Act in 1990, fees from telecommunications and Voice over Internet Protocol \nproviders have funded the TRS. Despite the clear need for the TRS, the FCC has just 1,688 employees and few engineers. So, four years \nago, the agency requested MITREs systems engineering expertise to help modernize and improve TRS's \noptions. The CMS Alliance to Modernize Healthcare took on the challenge. Making the FCCs services more reliable and accessible isnt just the right thing to do, it also translates \ninto making the world saferMITREs mission from the start. Think of conveying a doctors advice or \nmaking a 911 call. In both cases, accuracy can be a matter of life or death. And for members of the \ndeaf/Deaf or hard of hearing communitieseveryday communication should be quick and easy. A Day in the Life in the NTL Against a backdrop of 75-plus desktop phones, monitors, PCs, smartphones, spreadsheets, and cameras, \ninterns, in the NTL, test video relay service (VRS) providers software and hardware performance against \ncertain measures. (There are five VRS providers nationally.) The interns also test Internet Protocol \nCaptioned Telephone Services (IP CTS), which allow individuals with some residual hearing to speak \ndirectly to the other individual over the internet, using both voice and captions. For VRS testing, the internsunder the mentorship and guidance of Dr. Chern Lioulooked at time \ndelays, pixilation, and video mail (vs. voicemail) delivery. For IP CTS testing, the interns measured text \naccuracy and delay in captions appearing on the screen. Through repeated, rigorous testing, they created https://www.nidcd.nih.gov/health/statistics/quick-statistics-hearing\nhttps://www.nidcd.nih.gov/health/statistics/quick-statistics-hearing\nhttps://www.nidcd.nih.gov/health/statistics/quick-statistics-hearing\nhttps://www.mitre.org/careers/student-programs/student-voices/intern-project-amplifies-benefits-for-hard-of-hearing\nhttps://www.fcc.gov/consumers/guides/telecommunications-relay-service-trs\nhttps://www.mitre.org/publications/project-stories/better-telecom-technology-helps-an-underserved-community-reach-out\nhttps://www.mitre.org/publications/project-stories/better-telecom-technology-helps-an-underserved-community-reach-out\nhttps://www.mitre.org/news/press-releases/mitre-wins-five-year-contract-recompete-to-operate-cms-alliance-to-modernize\nhttps://www.mitre.org/news/press-releases/mitre-wins-five-year-contract-recompete-to-operate-cms-alliance-to-modernize\nhttps://www.fcc.gov/consumers/guides/internet-protocol-ip-captioned-telephone-service\nhttps://www.fcc.gov/consumers/guides/internet-protocol-ip-captioned-telephone-service \nCase number 18-4444. objective snapshots of how the technology works on various devices. This testing is aimed at improving \nusers routine communications. I never knew there was more than one providerI only used one, says Jaric Sloan, a fourth-year \nstudent at Rochester Institute of Technology (RIT)-National Technical Institute for the Deaf studying \ncomputer engineering technology. I used an Excel matrix to validate and report different results. We \ncolor coded results. Yellow meant video mail failed. Red meant it failed to connect, or the quality wasn't \ngood. Green meant it all worked great. In addition to gaining technical experience, the interns also benefitted from the opportunity to immerse \nthemselves in MITREs culture. Mustafa Hussein, a senior studying information technology at Gallaudet \nUniversity in Washington, DC, says, Ive worked for a big commercial corporation. It was all about \nprofits, a time is money mentality. The expectations are very high at MITRE, but its more focused on \ncollaboration. I learned lessons from this internship about leadership, teamwork, business culture, and \npublic ethics. Pop-up Conversations and Proper Text Captioning Spontaneous conversations came up in the lab setting, and Abbie Castillo was always ready to take part. \nCastillo, a Gallaudet student pursuing a bachelors degree in interpreting, was MITREs first ASL \ninterpreter intern. I stayed on the lookout for pop-up conversations between a Deaf client and a hearing person, says \nCastillo, who is hearing. When youre interpreting, youre constantly analyzing, tuning into the clients \npreferred signing style, and making sure what you translate is conceptually accurate. Its a lot. For long \nmeetings, Id interpret for 20 minutes, then my mentorthe projects full-time, in-house \ninterpretertook the next 20 minutes. We went back and forth. Minnie Buenaventura, a systems engineering intern (on her second summer at MITRE) and a Gallaudet \nalumna, tested the overall production quality of IP CTS on a desktop phone, Android, and other \nplatforms. She looked for time lapses before words appear on the screen and for missing or incorrect \nwords. Its like individualized captioning of live television programming, which is never perfect (unlike \nprerecorded programs' high level of accuracy). I really enjoyed testing all of the different providers, says Buenaventura, who is Deaf. I see errors, like \nthe name 'Jim' might come across as 'Jen.' Or 'Reston' [a town in Virginia] might come across as 'Russia.' Buenaventuras mentor, Evan Saltz, a former intern and now a MITRE subcontractor on the FCC project, \nassisted her with the IP CTS testing process he helped develop. Saltzs mentor, Jim Malloy, taught him \nwhy text captioning must be accurate. Consider the consequences if a caller speaks with a doctor and says, I am not allergic to penicillin, and \nthe doctor repeats the callers words, You are not allergic to penicillin, but the captions show, you are \nallergic to penicillin Saltz says. The patient might not get what they need. \"Its important to empower the deaf/Deaf and hard of hearing communities and educate vendors and \nothers about the issues unique to both communities. A Winning ACE for ASL-Fluent Customers Through the FCC work, MITRE brings together deaf/Deaf and hard of hearing community \nstakeholdersthe TRS users, government, vendors, and academiato improve and modernize services https://www.ntid.rit.edu/\nhttps://www.ntid.rit.edu/\nhttps://www.ntid.rit.edu/\nhttps://www.ntid.rit.edu/\nhttps://www.gallaudet.edu/\nhttps://www.gallaudet.edu/ \nCase number 18-4444. and realize cost savings of up to $17 million annually, according to the FCC Contracting Officer \nRepresentative. To make direct video calls more efficient, for example, MITRE created a now-operational, open-source \nprototype called Accessible Communications for Everyone Direct, or ACE Direct. The technology supports \nthe notion of an ASL-fluent customer service representative in a call center supporting Deaf ASL-using \ncustomers. On the vendor side, collaboration helps all parties. The service providers have come to appreciate \nMITREs feedback and findings, says Yus Johnson, MITRE systems engineer. Theyre getting a lot of \ntesting at no cost, and we report agnostically to help make the service better overall. This work is really disruptivein a positive way, says Jeff Rogers, who leads MITREs FCC work with \nReeta Singh and Dwight Handon. Were enhancing the quality of service delivery to the Deaf and hard of \nhearing communities, which are so often discriminated against. And with the energy and enthusiasm of \nthese students, were accelerating our ability to deliver impact at four times the speed. by Karina Wright Sidebar with intern names MITREs 2018 Federal Communications Commission Project Interns\nMinnie BuenaventuraRecent Gallaudet graduate with two bachelors degrees; most recent in Information Systems. Abbie CastilloSophomore at Gallaudet University. Major: Interpreting Sar GregorczykSenior at Virginia Tech, graduating December 2018. Major: \nComputer Science; Minors: Mathematics and Linguistics Mustafa HusseinRising senior at Gallaudet University. Major: Information \nTechnology Sean PaskeyGallaudet University. Major: Information Technology Priyanka SantiagoSophomore entering Columbia University. Major: \nComputer Science Jaric SloanFourth year student at Rochester Institute of Technology. \nMajor: Computer engineering Technology Mike TotaJunior at Gallaudet University. Major: Information Technology Andre WebsterRochester Institute of Technology. Major: Electrical \nEngineering https://github.com/mitrefccace/acedirect-public _top\n _GoBack\n _Hlk531866204 ",
    "text": " Copyright \nApproved for Public Release; Distribution Unlimited. Public Release Case Number 18-4487 Fighting Polio in Africa, Thanks to MITRE's Civic Leave Program As a group leader in the International Operations Department, Melissa Utzinger travels the globe helping \nforeign governments overcome engineering issues. Her typical challenge involves providing rigorous \nengineering analysis to inform key decision making of partner nations and the U.S. Their goal: to develop \nan integrated, cohesive system that gets the job done. But recently, she was overseas to tackle a much \ndifferent challengehow to administer a polio vaccine to a child under five years old. I was a little nervous about it because I dont have a medical background, but fortunately it was drops \nand not an injection, she says. And I brought boxes of raisins and gave one to every kid after they got \ntwo drops under their tongue. Pretty soon, the adults were encouraging more kids to do it, so they could \nget raisins too. Utzinger joined a humanitarian mission sponsored by Rotary International in Benin, a tiny sliver of a \ncountry on the border of Nigeria in West Africa. Rotary is a founding partner of the Global Polio \nEradication Initiative, which has immunized more than 2.5 billion children against the disease in 122 \ncountries. And despite Utzinger's busy work schedule, MITRE not only supported her desire to help others, but also \nprovided paid time off through our civic leave program. Working for the Health of Childrenand Trees Using her 40 hours of paid volunteer service time, Utzinger flew into the capital city of Cotonou on \nOctober 2 and spent part of the next week vaccinating the people most vulnerable to this deadly \ninfectious disease. By the end of her stay, the Rotary volunteers had provided inoculations to more than \n200 children. The volunteers met in the mornings at a health center where local mothers and children were already \nlined up to receive the vaccinations. People got so dressed up to come, she says. You could tell it was \nan important event for them. In the afternoons, Utzinger and her teammates went door-to-door in the neighboring slums. Each person \nhad a distinct job: locate eligible children, maintain a wearable freezer compartment to keep the \nvaccines cold, administer the vaccines, and place a mark on each childs left pinky to identify those who \nreceived inoculations. Team members made their way through the streets, leaving chalk marks on each house to indicate how \nmany children lived in each one and how many had been inoculated. If they missed any children the first \ntime around, the team stopped in again on the way home to try and find them. As part of the mission, Rotary International gave each participant a day away from the inoculation work \nto pursue other volunteer work. Utzinger opted to spend her day planting trees outside the city. She \nplanted a variety of fast-growing saplings, some for firewood and some with medicinal purposes, such as \npain relief. Copyright \nApproved for Public Release; Distribution Unlimited. Public Release Case Number 18-4487 Back in her office in Bedford, Massachusetts, Utzinger has been working on a project to help a partner \nnation integrate their missile defense capabilities into its overall defense architecture while enhancing \ncoalition, U.S., and regional security capabilities. But the lessons from Benin are never far from her mind. The experience really gave me a better perspective on life here, she says. You realize how fortunate \nwe are here to have something as basic as clean running waterand you realize how important it is to \nreach out and help other people. What Is MITRE's Civic Leave Program? The civic leave program offers MITRE employees up to 40 hours of paid time each year for volunteering \non civic and community projects. It's been around for decades and is extremely popular, says Sue \nStapleton, who runs the program. In 2018, about 1,300 employees applied for it. The projects include international work, such as providing public health education on HIV in India and \nconstructing orphanages in the Dominican Republic. Closer to home, the program covers work in \nfoodbanks, STEM mentoring and outreach, hurricane relief, and work with veterans and senior citizens. \nRequests must be approved by the appropriate manager. The civic leave program really underscores how important working in the public good is here at MITRE, \nStapleton says. As a company, our commitment doesnt end with the work day. We really want to \nsupport our employees in giving back to their communities in their personal lives as well. --by Twig Mowatt PHOTO: _top\n _Hlk531610489\n _GoBack ",
    "text": " Semi-Supervised Methods for Explainable Legal Prediction Semi-Supervised Methods for Explainable Legal Prediction Branting\nPfaff\nWeiss\nBrown The MITRE Corporation McLean, VA, USA {lbranting,mpfaff,bweiss}@mitre.org Pfeifer\nThe MITRE Corporation Ann Arbor, MI, USA cpfeifer@mitre.org Chakraborty\nFerro\nYeh The MITRE Corporation Bedford, MA, USA {achakraborty,lferro,asy}@mitre.org ABSTRACT Legal decision-support systems have the potential to improve ac- cess to justice, administrative efficiency, and judicial consistency, but broad adoption of such systems is contingent on development of technologies with low knowledge-engineering, validation, and maintenance costs. This paper describes two approaches to an important form of legal decision supportexplainable outcome predictionthat obviate both annotation of an entire decision cor- pus and manual processing of new cases. The first approach, which uses an Attention Network for prediction and attention weights to highlight salient case text, was shown to be capable of predict- ing decisions, but attention-weight-based text highlighting did not demonstrably improve human decision speed or accuracy in an evaluation with 61 human subjects. The second approach, termed SCALE (Semi-supervised Case Annotation for Legal Explanations), exploits structural and semantic regularities in case corpora to iden- tify textual patterns with predictable relationships to case decisions. ACM Reference Format: Branting, Pfaff, Weiss, Brown, Pfeifer, Chakraborty, Ferro, and Yeh. 2019. Semi-Supervised Methods for Explainable Legal Prediction. In Proceedings of ICAIL (ICAIL19). ACM, New York, NY, USA, 9 pages. https://doi.org/10. 1145/nnnnnnn.nnnnnnn 1 INTRODUCTION Recent advances in Artificial Intelligence (AI) and Human Language Technology (HLT) have created new opportunities to automate rou- tine aspects of case management and adjudication, freeing human experts to focus on aspects of these tasks that most require human judgment and knowledge. An important application of this technol- ogy is decision support for routine administrative decision-making and adjudication. Globally, benefits adjudications, resolution of commercial conflicts, criminal defense, and other forms of access to justice are often impeded by the opacity of legal processes, short- ages of affordable legal assistance, and growing case backlogs [18]. Effective decision-support systems could potentially improve access Permission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org. ICAIL19, June 2019, Montreal, QB, CA \nACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn to justice for significant numbers of citizens by improving trans- parency, compensating for lack of affordable human legal assistance, and speeding case decisions. A particularly simple but useful form of decision support is explainable legal decision prediction. For example, benefits appli- cants could make better-informed decisions if they knew (1) the likelihood of success of an application and (2) the strengths or weaknesses of their application, i.e., the reasons for the predicted likelihood. Similarly, adjudicators and decision processes could be more productive and consistent if the strengths or weaknesses of each application could be automatically identified and presented along with the application itself. Inherent in explainable outcome prediction systems is a trade-off between explanation quality and development effort. At one extreme, purely machine-learning-based systems typically have little or no explanatory capability but require relatively little development ef- fort. At the other extreme, systems with case facts expressed in man- ually engineered features and legal rules expressed in executable logic may be capable of generating explanations with considerable fidelity to human explanations but require prohibitively high levels of development effort for application at scale. A key requirement for explainable decision predictions systems is therefore optimizing the trade-off between explanation quality and development effort, that is, identifying approaches that can produce useful and comprehensible predictions but forwhich the en- gineering effort is low enough to permit development, verification, and maintenance at scale. A particularly important requirement for large-scale adoption is the ability to accept free text rather than manually-engineered features as input. This paper describes two approaches to explainable legal deci- sion prediction that operate on textual inputs. Each system was prototyped on a collection of 16,092 World Intellectual Property Organization (WIPO) domain name dispute cases. The first system, NFE (No Feature Engineering), uses an Atten- tion Network [26] for prediction and highlights salient case text based on attention weights for decision support. NFE was evaluated as a decision aide for attorney and non-attorney subjects to predict the case decisions. While the case decisions themselves were found to be predictable using this approach, attention-weight-based text highlighting was not shown to improve decision speed or accu- racy. This negative result motivated a second approach, termed SCALE (Semi-supervised Case Annotation for Legal Explanations), in which the justification structure of a representative set of cases is annotated, and tags for factual and legal findings are propagated https://doi.org/10.1145/nnnnnnn.nnnnnnn\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn ICAIL19, June 2019, Montreal, QB, CA Branting, Pfaff, Weiss, Brown, Pfeifer, Chakraborty, Ferro, and Yeh Figure 1: Paradigms of explainable decision prediction. to sentences in unannotated cases that share a high degree of simi- larity to the annotated sentences in a semantic embedding space. This approach exploits the structural and semantic regularities in case corpora to identify fact patterns with predictable relationships to case decisions. The remainder of this paper is structured as follows. Section 2 discusses the inherent trade-off between explanation quality and development effort. A minimalist approach to feature engineering, NFE, is discussed in Section 3, and Section 4 discusses a semi- supervised approach, SCALE, motivated by the negative results of the evaluation of NFE. The annotation scheme is described in Sec- tion 7, and Section 6 discusses how annotations of a representative set of cases are mapped onto similar sentences from other cases in semantic embedding space for use in prediction and decision support. The paper concludes with related and future work. 2 THE TRADE-OFF BETWEEN EXPLANATION QUALITY AND DEVELOPMENT EFFORT Until the recent rise in popularity of legal applications of data sci- ence and deep learning, the primary focus of research in the AI and law community was on computational models of argumentation [8]. These models typically operated on manually engineered rep- resentations of case facts and produced argument trees or other formal justifications for legal conclusions [25]. Even when the ob- jective was simply prediction, rather than justification, case features were typically assigned to each case manually [19] [2]. In general, the only circumstance under which manual representation of the facts of each new case was obviated was when the user interface queried users for the value of each feature [28] [23] or when pre- diction was based on factors unrelated to the merits of the case, such as the attorneys, judge, cause of action, etc., [31]. When the features closely corresponded to users conception of relevant case facts, this approach was workable. However, this approach often requires a significant knowledge-engineering effort to identify a cognitively-plausible feature set [1]. Advances in machine learning and corpus-based techniques have made outcome prediction increasingly feasible, even in the absence of domain-specific features. Several projects have demonstrated the feasibility of predicting case outcomes from unprocessed text, using either deep learning techniques or applying symbolic ma- chine learning techniques to n-grams or other domain-independent lexical or linguistic text features, provided that there are sufficient training examples [3] [12] [30]. However, such systems have very limited inherent explanatory capability. Reducing the opacity of the machine learning algorithms that perform best for many purposes neural network models, often referred to as Deep Learningis the focus of very active current research, such as the DARPA Explain- able AI (XAI) program [17]. However, there has been little XAI work directed at the particular forms of explanation characteristic of legal discourse.1 Legal justifications and explanations differ from typical XAI applications in that they must make explicit reference to authoritative legal sources to be persuasive. One way to characterize the dependence of explanation qual- ity on prior engineering effort is by identifying the knowledge- engineering artifacts intermediary between the textual expression of the facts of a case and the output (e.g., a prediction with some degree of explanation or justification). Figure 1 sets forth a notional division of explainable prediction systems. In this figure, the term feature is intended to mean a fact pattern of potential legal rele- vance,2 whereas a legal predicate is a term or concept occurring as an antecedent or consequent a legal rule or norm. Paradigm 1 is a pure machine-learning approach requiring no knowledge engineering other than construction of an output-labeled corpus and producing little explanation beyond the prediction itself and the internal model weights associated with that prediction (e.g., attention weights on input subtexts). At the opposite extreme, Paradigm 7 can generate hybrid case-based and rule-based argu- mentation but requires manually engineered feature, issue, and rule sets and execution-time representation of new cases in terms of that feature set [24] [11]. The objective of the research described in this paper is to de- velop techniques for
explainable prediction that can provide prac- tical tools for improving the efficiency of administrative decision processes without imposing excessive knowledge-engineering, val- idation, and maintenance costs on agencies. Minimizing up-front engineering costs is important because the factors motivating agen- cies to consider decision-support systemsdecision backlogs re- sulting from insufficient resourcestend to preclude solutions that require extensive development efforts. The domains of particular interest to us include disability benefit claims, immigration petitions, landlord-tenant disputes, and attor- ney misconduct complaints. The high volumes of cases of these types mean both that large training sets are available and that agen- cies have an incentive to consider technologies to improve decision processes. However, because of the sensitivity of most of these data sets, we have found it convenient to perform initial research on an open-source data set consisting of 16,092 World Intellectual Property Organization (WIPO) domain name dispute decisions.3 WIPO cases have only two possible decisions: granting or deny- ing the request to transfer a domain name to the Complainant. WIPO cases are consistently segmented into seven sections: Parties, Domain Name, History, Background, Contentions, Findings, and Decision. The Findings section typically consists of four subsections, 1See [33] for a recent exception to this generalization.\n2The factors of [4] are examples of features in this sense.\n3http://www.wipo.int/amc/en/domains/decisionsx/index-gtld.html. http://www.wipo.int/amc/en/domains/decisionsx/index-gtld.html Semi-Supervised Methods for Explainable Legal Prediction ICAIL19, June 2019, Montreal, QB, CA one for each of the three requirements that Complainants must establish to prevail (issues): confusability, no legitimate rights or interests, and bad faith, plus an additional issuereverse name highjackingthat we do not address. We formed a case-decision corpus in which the facts of each instance consist of the concatena- tion of the first 5 sections, and the decision is transferred or not transferred. This dataset has a roughly 10-to-1 class skew in favor of transferred. In addition, we formed a separate corpus for each of the three issues, for a total of 4 datasets used in the experiments below. The next section describes development and evaluation of the NFE, most minimalist approach approach to explainable decision prediction. 3 A NO-FEATURE-ENGINEERING PARADIGM The No Feature Engineering (NFE) approach (Paradigm 1) treats legal prediction as a problem of classifying texts that represent case descriptions into decision categories. This approach may be appropriate when there is a corpus of previous case-text/decision pairsas is typically the case in administrative or judicial forums and decisions can be viewed as unstructured categories, such as granting or denying a particular benefit or form of relief.4 Prototyp- ical domains fitting this description involve routine administrative decisions, such as applications for permits, licenses, or benefits, each of which characterized by relatively circumscribed and pre- dictable fact patterns and a limited range of permissible outcomes. Cases in trial or appellate courts of general jurisdiction are gener- ally ill-suited to this approach because of the wide variety of both facts giving rise to cases and types of decisions. This shallow approach to decision prediction is not appropriate for completely autonomous processes. Denial of benefits by an automated process, no matter how accurate, raises significant due- process issues, and in any event prediction accuracy is limited in this paradigm by the absence of explicit modeling of legal rules or issues. However, even an imperfect prediction can be useful in high-volume forums for (1) triage, e.g., granting benefits without further processing in extremely clear cases and routing cases to particular decision makers based on apparent complexity, and (2) decision support. 3.1 Explanation in No-Feature-Engineering Systems Since the NFE approach lacks explicit legal concepts, our approach to decision support focuses on identifying the portions of case text that are most predictive of the decision. Our hypothesis is that a decision maker may benefit from having the predictive text identified even in cases in which the decision disagrees with the models prediction. This hypothesis is based on the observation that one of the challenges of decision making is sifting through irrelevant portions of the case record to locate the most important facts. One approach to predictive-text identification would be to pro- duce a case summary that includes only the most relevant portion 4Cases in which decisions consist of numerical awards can be modeled as regres-\nsion problems. For simplicity, we confine the discussion in this paper to categorical classification. Figure 2: Screenshot of human evaluation of the case facts. This might approximate the actions of a law clerk or other administrative assistant. However, many decision makers may prefer to see the text selected asmost relevant in its original tex- tual context. Consistent with this approach, we experimented with various approaches to highlighting important portions of the case text, including pairwise mutual information and logistic-regression model weights. However, attention-network weights [7] have the advantage over these methods in that the weights are specific to each individual case rather than global for the entire corpus. In the evaluation below, we therefore focused on attention-weight-based highlighting. 3.2 Evaluation of Attention-Based Highlighting for Decision Support Prior work had not established whether simply highlighting the most important portion of a case description based on attention weights can provide significant decision support. We therefore performed an evaluation using using an attention network trained on the WIPO cases described above. A total of 61 participants were recruited for the study: 34 with legal experience and 27 without legal experience, but none familiar with the WIPO domain. Participants were randomly assigned to 1 of 4 conditions: Control: Case text only Highlighting: Case text plus highlighting Precedents: Case text plus positive and negative precedents Highlighting and Precedents: Case text plus highlighting and positive and negative precedents Each participant was asked to decide the issue of No Rights or Legitimate Interests (NRLI) in two separate cases and to provide a justification for each prediction. In addition, they were asked to complete a survey to collect demographics and opinions about the ICAIL19, June 2019, Montreal, QB, CA Branting, Pfaff, Weiss, Brown, Pfeifer, Chakraborty, Ferro, and Yeh experience of the tasks and usability of the interface. Participants were encouraged to complete the study within an hour. The screenshot in Figure 2 shows the interface as it was pre- sented to participants in the condition with both highlighting and precedents. All participants saw the Current Case (1) for which they were to predict the NRLI decision. Participants in conditions that included the positive and negative precedents were shown in the Prior Case pane (2) to the right of the Current Case. Partici- pants were able to toggle between two prior cases, one in which the Complainant won, and one in which the Complainant lost on the NRLI issue. For participants in conditions including highlighting, certain passages of text were highlighting in yellow, as prompted by the yellow bar above the cases (3). At any time, participants could refer back to the NRLI criteria (4). Finally, participants made their prediction (NRLI is true or false) and wrote a justification for that prediction (5). Four dependent variables were assessed for each trial: Correctness: Participant prediction (NRLI is true or false) compared to actual case outcome. Task Duration: Amount of time to evaluate case, timed from when the case is first presented until the participant submits the prediction with justification. Task Difficulty: Measured with Single Ease Question [27] and eight items selected from the Multiple Resources Ques- tionnaire [10]. User Satisfaction: Measured with System Usability Scale [13]. More participants decided Case 1 correctly (48) than incorrectly (13). However, participants with legal experience were significantly more likely to decide Case 1 correctly (30 out of 34, or 88.2 %) than those without legal experience (18 out of 27, 66.67%), 2 (1, N=61)\n= 4.18, p = .04. Highlighting had no effect on correctness. Participants were significantly more likely to get Case 1 correct with precedents (25 out of 27, or 92.6%) than without precedents (23 out of 34, or 67.6%), 2 (1, N=61) = 5.58, p = .02. More participants decided\nCase 2 incorrectly (53) than correctly (8). In Case 2, there were no statistically significant differences between those with and without legal experience and there were no significant effects of either highlighting or precedents on correctness. Participants with legal experience spent more time on the task for both cases. The observation that participants were more likely to correctly decide Case 1 with precedents, even though it took them signif- icantly more time to decide than without precedents, suggests that precedents contribute important information to the decision- making process even in a domain, like WIPO, without stare decisis. Overall, however, this study did not find statistically significant evidence that providing outcome-relevant case comparison features leads to improved decision making. An important proviso to these conclusions is that some partici- pants comments indicate that they mistakenly believed that their goal was to predict the outcome of the entire casewhether the domain name should be transferredrather than simply the NRLI issue, a confounding factor not evident in the pilot conducted in advance of the main study. This illustrates that non-experts can find deciding even simple administrative issues very challenging and that the design of decision-support
systems for such users (e.g., Figure 3: Annotation, clustering, and tag mapping. Figure 4: Inducing a model for each feature from facts and contentions. citizens not represented by attorneys familiar with the domain) requires extensive usability analysis. Another proviso is that this study doesnt rule out the possibility that highlighting produced by a different predictive model might be more useful for decision support. Perhaps the most illuminating comments by participants were that they had difficulty understanding the connection between the highlighted text and the issue that they were supposed to decide. These comments, and the overall results of study, indicate that use- ful decision support should help the user understand the connection between relevant portions of the case record and the issues of the case. 4 SCALE: SEMI-SUPERVISED CASE ANNOTATION FOR LEGAL EXPLANATIONS The results of the evaluation of NFE suggest that an effective deci- sion support system for prediction explanations must identify not just relevant case text, but fact patterns and issues that connect the text to the predicted outcome. To achieve this capability in Semi-Supervised Methods for Explainable Legal Prediction ICAIL19, June 2019, Montreal, QB, CA Figure 5: Inducing and applying feature-to-issue models. the WIPO domain without individually annotating every case, we have developed a novel approach based on exploiting regularities in opinion structures. This approach is based on several observations about the consistency of language across separate cases and within different sections of the same case. First, we observe that the relatively stereotyped language of administrative case decisions means that statements with similar legal effect in different cases tend to be close to each other in semantic-embedding space [22]. Thus, annotation tags applied to a subset of cases can bemapped to an entire corpus, with accuracy and completeness that depends on the consistency of the case language within the corpus, the typicality of the annotated cases, and the threshold for semantic similarity. Second, most factual-finding or legal-ruling sentences correspond semantically to one or more sentences in the contentions section. This is a manifestation of the inherent property of cases that findings and rulings resolve contentions by parties. Third, the polarity of each finding and rule, that is, which party it supports, depends on sentences in the facts section. Thus, machine-learning techniques developed to predict the overall outcome of the case can be applied as well to predict the polarity of individual findings and rulings. Finally, in many administrative domains the Findings or Decision sections of cases are subdivided into predictable subsections, each resolving one of the elements (issues) that a Complainant must establish. In WIPO cases, there are 4 subsections. Considering each subsection separately permits the overall decision to be broken into separate steps, improving the comprehensibility. Our key hypothesis is that these document regularities can be exploited to project annotations on a representative set of decisions onto the entire corpus, and that the resulting semi-automated cor- pus can be exploited to identify the case features (1) to predict the issues on which the decision will turn and the decision itself, (2) to justify a prediction in terms of the features of the particular case, and (3) to identify prior cases whose facts and contentions are most relevant to a given case. As shown in Figure 3, Step 1 of the SCALE procedure consists of manual annotation of the Findings section of a representative set of cases. All sentences in the corpus in close proximity to a tagged sentence in the semantic-embedding space are identified Figure 6: Analysis of a new case. UDNDRP repre- sents Section 4 of the Uniform Domain Name Dispute Resolution Policy (https://www.icann.org/resources/pages/ policy-2012-02-25-en). in Step 2, and in Step 3 the corresponding tags themselves are mapped to all similar sentences from the Findings section of some case. The result of these steps is an annotation of the Findings section of every case in the corpus. These mapped annotations will almost certainly be less accurate than manual annotations; the actual accuracy will depend on the details of both the original annotation and the clustering itself. However, we hypothesize that the mapped annotations are accurate enough for prediction, triage, and decision support. Figure 4 shows the next step, inducing a separate model for each feature from the case description, i.e., the Facts and Contentions. In Step 5, shown in Figure 5, feature-to-issue models are induced for each of the high-level issues. Finally, Figure 6 illustrates how the prediction for a new case proceeds by predicting features from Facts and Contentions, predicting issue-decisions based on features, and finally predicting the transfer decision based on the issues. The SCALE approach differs from NFE in it that involves reason- ing about case features induced from the case description which can be used to explain and justify a prediction. Our initial imple- mentation involves annotation of 16,092 WIPO decisions. 5 ANNOTATION A key goal of SCALE is a methodology that permits development of explainable legal prediction systems by agencies that lack the resources to engineer domain-specific feature sets, a process that requires both extensive expertise in the particular legal domain and experience in feature engineering. Instead, SCALE requires only the linguistic skills necessary to annotate the decision portion of representative cases, a much simpler process. Our annotation schema for WIPO decisions consists of three lay- ers: Argument Elements, Issues, and Factors (sub-issues).5 Tags are applied to clauses and sentences, as opposed to shorter units such as noun phrases, in order to identify the complete linguistic propo- sition corresponding to the annotation label. The MITRE Annota- tion Toolkit (MAT) is used to perform the annotation (http://mat- annotation.sourceforge.net/). 5We are also currently exploring a fourth layer, Evidence, which captures the evidence\ncited in support of the Factor or Issue. As this exploration is still underway and the Evidence tag set continues to expand, it will not be discussed further here. https://www.icann.org/resources/pages/policy-2012-02-25-en\nhttps://www.icann.org/resources/pages/policy-2012-02-25-en ICAIL19, June 2019, Montreal, QB, CA Branting, Pfaff, Weiss, Brown, Pfeifer, Chakraborty, Ferro, and Yeh 5.1 Argument Elements Although our approach to predictive-text identification is to lever- age the Factual Findings and Legal Findings, the annotation schema is designed to capture the full range of argument elements present. These argument elements are as follows: (1) Policy (2) Contention (3) Factual Finding (4) Legal Finding (5) Case Rule (6) Decision We have found that with these six argument elements, the major- ity of sentences within the \"Discussion and Findings\" and \"Decision\" sections of WIPO cases can be assigned an argument element label. These argument elements are not specific to WIPO decisions, and should have utility in other domains. 5.2 Issues Each Argument Element tag is assigned an Issue. The Issue tags include the three required elements that the complainant must establish in order to prevail in a WIPO case. These issues are docu- mented in the Uniform Domain Name Dispute Resolution Policy, paragraph 46, and form the backbone of every decision: (i) ICS: Domain name is Identical or Confusingly Similar to a trademark or service mark in which the complainant has rights (ii) NRLI: Respondent No Rights or Legitimate Interests in respect of the domain name. (iii) Bad Faith: Domain name has been registered and is being used in Bad Faith. For element (ii), NRLI, although the dispute is typically ap- proached from the point of view of the complainant demonstrating that the respondent has NRLI, it is very often the case that the panel considers the rights or legitimate interests of the complainant and/or the respondent. In that case, RLI is available as an Issue tag. In addition, the domain name resolution procedure allows for situations in which the complainant abuses the process by filing the complaint in bad faith (CIBF).7 The schema thus consists of five Issue tags, plus an Other cate- gory: ICS NRLI RLI BadFaith CIBF OTHER 5.3 Factors In our annotation scheme Factors are the elements which we hy- pothesize will prove most useful for explainable legal prediction. 6https://www.icann.org/resources/pages/policy-2012-02-25-en#4.\n7See 15(e) of the Rules for Uniform Domain Name Dispute Resolution Policy for CIBF, https://www.icann.org/resources/pages/udrp-rules-2015-03-11-en Figure 7: Four text spans annotated with factual and legal- findings features. The factors and corresponding tags are specific to the WIPO issues. For ICS, the ICANN policy does not explicitly identify specific fac- tors that will be considered by the panel, so our tag set for ICS is derived from factors commonly observed in the data, such as CownsTM (Complainant owns Trademark) and TMentire (Trade- mark is contained in its entirety within the Domain Name). For NRLI/RLI, the policy establishes three factors, and for Bad Faith, four factors. Each of these has a corresponding tag. For example, under NRLI there is PriorBizUse from 4(c)(i) of the policy (Bona fide business use of Domain Name or demonstrable preparations to do so, prior to notice of the dispute) and under BadFaith there is Confusion4CommGain from 4(b)(iv) of the policy For commercial gain from confusion with complainants mark). The tag set also includes labels for other common factors observed in the data, such as PrimaFacieEst (Prima Facie Case Established). For CIBF, two factor tags are available:
RDNH (Reverse Domain NameHijacking) and Harass (complaint brought primarily to harass DN holder). Each level of annotation also has an \"Other\" option to be used when none of the predefined tags is appropriate, and there is a free-form Comment field which the annotator can use to capture ad hoc labels and enter notes. 5.4 Attributes A Citation attribute is used to capture the paragraph citation of Policy and Case Rule argument elements. A polarity attribute is used to capture positive/negative values for issues and factors. Figure 7 shows four typical annotations. We anticipate that this annotated data set will be made available to researchers in 2019. 6 MAPPING ANNOTATIONS FOR PREDICTION AND EXPLANATION Linguistic annotation is an expensive and arduous task, but neces- sary to train and evaluate analytics. From a small set of 23 annotated documents, we are able to project the annotations to similar sen- tences throughout the entire corpus of documents. This projection is accomplished through the use of word and sentence embeddings to find text that is semantically similar to the annotated text. The projection method is as follows. https://www.icann.org/resources/pages/policy-2012-02-25-en#4\nhttps://www.icann.org/resources/pages/udrp-rules-2015-03-11-en Semi-Supervised Methods for Explainable Legal Prediction ICAIL19, June 2019, Montreal, QB, CA First, word embeddings are trained on the tokenized corpus using FastText[9]. This yields a vector per token which captures the semantics of the word through the surrounding context. Next, these word embeddings are used to compute sentence embeddings by averaging the vectors of the words in each sentence for each of the 2.64 million sentences in our corpus. Semantically similar sentences are close to each other in semantic-embedding space. A notable limitation of this approach is sentences that are lexicallhy very similar but have opposite meaning end up very close in this embedding space. An example is simple negation via \"not\", for example \"the panel finds that it was properly constituted\" and \"the panel finds that it was not properly constituted\" differ by a single word but have completely different meanings. The sentences are then clustered into 512 clusters by their embeddings. The clusters establish neighborhoods of similar sentences. Once the word embeddings have been trained, embeddings for the annotation spans of text can be trained. The same method used to compute sentence embeddings is used to compute embeddings of the annotation spans. While the annotation spans are not strictly sentences, the sentence embedding method can be used to compute embeddings of arbitrary spans of text. Once the word embeddings, corpus sentence embeddings, an- notation span embeddings and clusters have been computed the tags can be projected. For each annotation label of interest for the specific experiment, we retrieve the top 10,000 sentences in the corpus ranked by cosine similarity to the annotated spans. Then, the annotation label is projected to each cluster associated with each retrieved sentence. For these prediction tasks, we do not use the words of the sen- tences. Instead, we use the cluster label of each sentence in the document. The sentences are selected according to task-specific cri- teria. XGBoost[16], an efficient implementation of gradient boosted machines, is used in all prediction tasks in this work. These are preliminary results, and we continue to iterate to improve the out- comes. As the transfer decision labels are highly skewed, 91% transfer (14,591 cases), 9% nontransfer (1,407 cases), we do not create a dedicated test set. Instead, we opt for 10 random test/train splits and report the average area under the curve (AUC), and per class precision, recall and F1 score aggregated over the 10 trials. 6.1 Predicting Decisions from Mapped Tags The accuracy of mapped tags as predictive features depends on both the annotation conventions and the details of the clustering. An initial evaluation of adequacy and correctness of these initial two steps can performed by determining the predictive accuracy of the mapped tags. If the tags are capturing the actual decision, then a high degree of accuracy should be achievable by training a model that predicts overall case decisions, or decisions for individual is- sues, from the mapped tags. This experiment used the tag projection method described in section 6, and retrieve sentences based on all annotation types. This method selected 1.8M sentences out of the total corpus of 2.6M. Predicting overall case outcome with the annotated data gave strong results with an average AUC of 80.8% and a standard devi- ation of 0.01. The transfer class, the majority class in this dataset, earned a 91.9% F1 (97.3% precision and 87.1% recall). The non- transfer class was lower with a 48.2% F1 (35.7% precision, 74.5% recall). This experiment indicates that tags mapped from a modest set of 23 annotated cases (0.14 percent of the entire corpus) are sufficient to express the decisions in the Findings section. 6.2 Predicting Decisions from Factual Findings Tags The next experiment involved restricting the prediction to just those tags that represent factual findings. The purpose of this ex- periment is to determine whether the factual findings are sufficient to determine the outcome of individual issues and of the case as a whole. This is important because the factual findings may be predictable from the case text, e.g., in the case of WIPO, all the sections preceding the panels discussion and findings. This experiment used the tag projection method described in section 6, and retrieved sentences only of factual finding annotation types. This method selected 1.3M sentences out of the total corpus of 2.6M sentences. Predicting overall case outcome with the annotated data gave strong results with an average AUC of 89.6% and a standard devia- tion of 0.008. The transfer class, the majority class in this dataset, earned a 94.3% F1 (98.8% precision, 90.2% recall). The non-transfer class was lower with a 61.2% F1 (46.7% precision, 89% recall). 6.3 Predicting Findings from Case Text In our next experiment, we measured our ability to predict tags in the Findings section from the case text, i.e., the first 5 sections of cases. We selected 3 findings: Identical or Confusingly Similar (ICS)- Complainant owns trademark, No Rights or Legitimate Interest (NRLI)-prima facie, and Bad Faith-disrupt business. These were the most frequently occurring findings in our corpus. To create the training data for this experiment, we used the tag projection method described in section 6. The projected sentence annotations were then interpreted as labels for a binary document classification task. Each finding label is skewed towards the negative class. The ICS label distribution is 75.8% negative and 24.2% positive, NRLI is 80.3% negative and 19.7% positive, finally bad faith label distribution is 74.2% negative and 25.8% positive. The prediction accuracy is similar for all labels. Over 10 trials, bad faith and NRLI earned an average AUC of 63.5% and 62.9% respectively, while ICS was a bit lower with 60.1% AUC. Examining the per class precision, recall and F1 metrics, bad faith had the strongest result with 79.8% F1 for the negative class (81.5% precision, 78.2% recall) and 46.3% F1 for the positive class (43.9% precision, 48.9% recall). ICS and NRLI had similar results. ICS had 79.5% F1, for the negative class (80.9% precision, 78.2% recall) and 40.2% F1 for the positive class (38.3% precision, 42.3% recall). Results for NRLI prediction are 78.1% for the negative class (86.5% precision, 71.1% recall) and 40.1% F1 for the positive class (31.7% precision, 54.6% recall). This section has described a methodology for inducing case features for decision prediction by exploiting regularities in case corpora. The use of these features for justification and explana- tion is beyond the scope of this paper. However, over 30 years of ICAIL19, June 2019, Montreal, QB, CA Branting, Pfaff, Weiss, Brown, Pfeifer, Chakraborty, Ferro, and Yeh scholarship has been directed at techniques, including case-based reasoning (CBR), dialectical argumentation, and rule-based justifi- cation, for justification, explanation, and argumentation in cases represented in terms of outcome-relevant features. The SCALE approach is agnostic as to which of these techniques should be ap- plied. The key research contribution of this work is enabling these techniques to apply to cases represented as text without requiring manual feature processing. 7 RELATEDWORK Several previous projects have addressed SCALEs goal of extracting factors from case texts for use in prediction or for other purposes. Ashley et al. 2009 [6] extracted CATO factors [5] from squibs, a form of case summary, using text classification [14] then predicted case outcomes by applying a machine learning algorithm, Issue-Based Prediction [15], to cases represented using those factors. SCALE differs from this approach in two important respects. First, SCALE uses features that arise from a linguists annotations of the Deci- sion portions of a representative sample of cases, whereas CATO factors were engineered and refined by multiple experts over a period of many years. Moreover, SCALE extracts factors from unre- stricted free text from cases, unlike [6], which processed only squibs, which were produced by experts. Accordingly, SCALE has both much less onerous feature development and broader applicability. Features defined and extracted by SCALEs much more highly au- tomated approach are almost certain to be less precise than CATO factors. However,
SCALE makes system development for new do- mains tractable in a manner that previous, more labor-intensive approaches are not. Other approaches to automated features ex- traction from free text include efforts for automated annotation described in [32], event detection for indexing as described in[21], and identifying cited facts and principles in legal text [29]. The argumentation-mining community has produced a num- ber of efforts addressing the task of identifying argumentation units from free text (see generally [20]). However, despite their central role in legal argumentation and justification, case features, including factors, are not argument units per se. Accordingly these techniques are not directly applicable to the task of identifying relevant case features. 8 CONCLUSIONS AND FUTUREWORK Computational techniques for explainable legal problem solving have existed for many years, but broad adoption of these techniques has been impeded by their requirement for manual case represen- tation. The rise of large-scale text analytics and machine learning promised a way to finesse this obstacle, but the limited explanatory capability to these approaches has limited their adoption in law where, for deep institutional reasons, decisions must be justified in terms of authoritative legal sources. This paper has described two approaches to exploiting the scala- bility of machine learning while retaining explanatory capability. An evaluation of the first approach, NFE, failed to establish signifi- cant improvement in decision accuracy from decision support in the form of highlighting of case text based on attention weights. This experiment doesnt conclusively establish that this approach cant be made to work, but it suggests the limits of explanation and justification based purely on text without explicit reference to legally-relevant concepts. This negative result motivated a second approach, SCALE (Semi-supervised Case Annotation for Legal Ex- planations), that exploits structural and semantic regularities in case corpora to identify textual patterns corresponding to annotations in a subset of cases. This approach obviates manual representation of any but a representative set of cases while at the same time enabling all of the more traditional techniques for explanation and justification. Our evaluation of SCALE used the statement of facts and con- tentions in each case as a proxy for actual case records, which may be both more complete and less orderly than the panels own summary. We anticipate applying the SCALE methodology to an administrative agency starting in the next few months, which will provide a more realistic evaluation of its ability to scale to actual agency decision making. This work was undertaken in the hope of developing a method- ology equally applicable to routine administrative adjudications in agencies throughout the world. We hope that it will provide a model for how to apply contemporary computational linguistics techniques to homogeneous case corpora to produce explainable decision prediction systems with a minimum of manual case anno- tation. ACKNOWLEDGMENTS The MITRE Corporation is a not-for-profit company, chartered in the public interest, that operates multiple federally funded research and development centers. This document is approved for Public Release; Distribution Unlimited. Case Number 18-4558. MITRE Corporation. All rights reserved. REFERENCES\n[1] Al-Abdulkarim, L., Atkinson, K., Bench-Capon, T.J.M., Whittle, S., Williams, R., Wolfenden, C.: Noise induced hearing loss: An application of the angelic\nmethodology. In: Legal Knowledge and Information Systems JURIX 2017: The\nThirtieth Annual Conference, Luxembourg, 13-15 December 2017. pp. 7988\n(2017) [2] Alarie, B., Niblett, A., Yoon, A.: Using Machine Learning to Pre-\ndict Outcomes in Tax Law (December 15 2017), available at SSRN:\nhttps://ssrn.com/abstract=2855977 or http://dx.doi.org/10.2139/ssrn.2855977 [3] Aletras, N., Tsarapatsanis, D., Preotiuc-Pietro, D., Lampos, V.: Predicting judicial\ndecisions of the European Court of Human Rights: a natural language processing\nperspective. PeerJ CompSci (October 24 2016), https://peerj.com/articles/cs-93/ [4] Aleven, V., Ashley, K.: Evaluating a learning environment for case-based ar-\ngumentation skills. In: Proceedings of the Sixth International Conference on\nArtificial Intelligence and Law. pp. 170179. ACM Press, University of Melbourne,\nMelbourne, Australia (June 30July 3, 1997) [5] Aleven, V.A.W.M.M.: Teaching Case-based Argumentation Through a Model and\nExamples. Ph.D. thesis, University of Pittsburgh, Pittsburgh, PA, USA (1997),\naAI9821228 [6] Ashley, K.D., Brninghaus, S.: Automatically classifying case texts and predicting\noutcomes. Artif. Intell. Law 17(2), 125165 (Jun 2009) [7] Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning\nto align and translate. arXiv preprint arXiv:1409.0473 (2014) [8] Bench-Capon, T.J.M., Dunne, P.E.: Argumentation in artificial intelligence. Artif.\nIntell. 171(10-15), 619641 (Jul 2007) [9] Bojanowski, P., Grave, E., Joulin, A., Mikolov, T.: Enriching word vectors with\nsubword information. arXiv preprint arXiv:1607.04606 (2016) [10] Boles, D.B., Adair, L.P.: The multiple resources questionnaire (mrq). Proceedings\nof the Human Factors and Ergonomics Society Annual Meeting 45(25), 17901794\n(2001) [11] Branting, L.K.: Reasoning with Rules and Precedents: A Computational Model of\nLegal Analysis. Kluwer Academic Publishers, Dordrect/Boston/London (2000) [12] Branting, L.K., Yeh, A., Weiss, B., Merkhofer, E.M., Brown, B.: Inducing predictive\nmodels for decision support in administrative adjudication. In: AI Approaches to https://peerj.com/articles/cs-93/ Semi-Supervised Methods for Explainable Legal Prediction ICAIL19, June 2019, Montreal, QB, CA the Complexity of Legal Systems AICOL International Workshops 2015-2017,\nRevised Selected Papers. Lecture Notes in Computer Science, vol. 10791, pp.\n465477. Springer (2017) [13] Brooke, J.: SUSa quick and dirty usability scale. Usability evaluation in industry\n189(194), 47 (1996) [14] Brninghaus, S., Ashley, K.D.: Toward adding knowledge to learning algorithms\nfor indexing legal cases. In: Proceedings of the 7th International Conference on\nArtificial Intelligence and Law. pp. 917. ICAIL 99, ACM, New York, NY, USA\n(1999), http://doi.acm.org/10.1145/ 09 [15] Bruninghaus, S., Ashley, K.D.: Predicting outcomes of case based legal arguments.\nIn: Proceedings of the 9th International Conference on Artificial Intelligence and\nLaw. pp. 233242. ICAIL 03, ACM, New York, NY, USA (2003) [16] Chen, T., Guestrin, C.: Xgboost: A scalable tree boosting system. CoRR\nabs/1603.02754 (2016), http://arxiv.org/abs/1603.02754 [17] Gunning, D.: Defense advanced research projects agency (darpa) program infor-\nmation: Explainable artificial intelligence (xai) (2018), https://www.darpa.mil/\nprogram/explainable-artificial-intelligence, last visited December 26, 2018 [18] Hadfield, G.: Rules for a Flat World: Why Humans Invented Law and How to\nReinvent It for a Complex Global Economy. Oxford University Press (2016) [19] Katz, D.M., II, M.J.B., Blackman, J.: A general approach for predicting the behavior\nof the supreme court of the united states. PLoSOne 12(4) (2017) [20] Lippi, M., Torroni, P.: Argumentation mining: State of the art and emerging\ntrends. ACM Trans. Internet Technol. 16(2), 10:110:25 (Mar 2016) [21] Maxwell, K.T., Oberlander, J., Lavrenko, V.: Evaluation of semantic events for\nlegal case retrieval. In: Proceedings of the WSDM 09 Workshop on Exploiting\nSemantic Annotations in Information Retrieval. pp. 3941. ESAIR 09, ACM, New\nYork, NY, USA (2009), http://doi.acm.org/10.1 .1506259 [22] Mikolov, T., Yih, S.W.t., Zweig, G.: Linguistic regularities in continuous space word\nrepresentations. In: Proceedings of the 2013 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies (NAACL-HLT-2013). Association for Computational Linguistics\n(May 2013) [23] Peterson, M., Waterman, D.: Rule-based models of legal expertise. In: Walters,\nC. (ed.) Computing Power and Legal Reasoning, pp. 627659. West Publishing\nCompany, Minneapolis, Minnesota (1985) [24] Rissland, E., Skalak, D., Friedman, T.: Supporting legal arguments through heuris-\ntic retrieval. Artificial Intelligence and Law 4(1), 171 (1996) [25] Rissland, E.L., Ashley, K.D., Branting, L.K.: Case-based reasoning and law. The\nKnowledge Engineering Review 20(3), 293298 (2005) [26] Rush, A.M., Chopra, S., Weston, J.: A neural attention model for abstractive\nsentence summarization. CoRR abs/1509.00685 (2015), http://arxiv.org/abs/1509.\n00685 [27] Sauro, J., Dumas, J.S.: Comparison of three one-question, post-task usability\nquestionnaires. In: Proceedings of the SIGCHI Conference on Human Factors in\nComputing Systems. pp. 15991608. CHI 09 (2009) [28] Sergot, M.J., Sadri, F., Kowalski, R.A., Kriwaczek, F., Hammond, P., Cory, H.T.:\nThe British Nationality Act as a logic program. Commun. ACM 29(5), 370386\n(May 1986), http://doi.acm.org/10.1145/5689.5920 [29] Shulayeva, O., Siddharthan, A., Wyner, A.: Recognizing cited facts and principles\nin legal judgements. Artificial Intelligence and Law 25(1), 107126 (Mar 2017) [30] Sulea, O., Zampieri, M., Vela, M., van Genabith, J.: Predicting the law area and\ndecisions of french supreme court cases. In: RANLP. pp. 716722. INCOMA Ltd.\n(2017) [31] Surdeanu, M., Nallapati, R., Gregory, G., Walker, J., Manning, C.: Risk analysis for\nintellectual property litigation. In: Proceedings of the Thirteenth International\nConference on Artificial Intelligence and Law. ACM, Pittsburgh, PA (June 610\n2011) [32] Wyner, A.Z., Peters, W.: Lexical semantics and expert legal knowledge towards\nthe identification of legal case factors. In: JURIX. Frontiers in Artificial Intelligence\nand Applications, vol. 223, pp. 127136. IOS Press (2010) [33] The EXplainable AI in Law (XAILA) 2018 workshop. http://xaila.geist.re (Decem- ber 1214 2018), groningen, The Netherlands http://doi.acm.org/10.1145/ 09\nhttp://arxiv.org/abs/1603.02754\nhttps://www.darpa.mil/program/explainable-artificial-intelligence\nhttps://www.darpa.mil/program/explainable-artificial-intelligence\nhttp://doi.acm.org/10.1 .1506259\nhttp://arxiv.org/abs/1509.00685\nhttp://arxiv.org/abs/1509.00685\nhttp://doi.acm.org/10.1145/5689.5920\nhttp://xaila.geist.re Abstract\n 1 Introduction\n 2 The Trade-off between Explanation Quality and Development Effort \n 3 A No-Feature-Engineering Paradigm \n 3.1 Explanation in No-Feature-Engineering Systems\n 3.2 Evaluation of Attention-Based Highlighting for Decision Support 4 SCALE: Semi-supervised Case Annotation for Legal Explanations\n 5 Annotation\n 5.1 Argument Elements\n 5.2 Issues\n 5.3 Factors \n 5.4 Attributes 6 Mapping Annotations for Prediction and Explanation\n 6.1 Predicting Decisions from Mapped Tags\n 6.2 Predicting Decisions from Factual Findings Tags\n 6.3 Predicting Findings from Case Text 7 Related Work\n 8 Conclusions and Future Work\n References ",
    "text": " 1 The GATMOC presents the civil aviation communitys mid-term vision for an integrated, harmonized, and globally \ninteroperable air navigation system. 2 Of the operations that rely on lift, unmanned free balloons can go the highest. The current record is well below 200,000 feet. Framework for Evaluating Traffic Management Services in \nHigher Airspace Jennifer Gentry, Anuja Mahashabde, Debra Moch-Mooney \nThe MITRE Corporation, February 2019 Introduction\nThere is a vast realm of airspace that remains unexplored, save for a handful of scientific and \nnational security missions. It is rife with extremes, where flights can reach multi-Mach speeds or \nstay aloft for months as they slowly circumnavigate the globe. This region lies roughly between \n52,000 and 160,000 feet and is referred to as higher airspace in this paper.\nRecent breakthroughs in technology have set the stage for routine commercial operations in this \nrealm. Companies are investing in ways to harness its potential for a wide range of commercial \napplications. Until recently, few have contemplated how this assortment of operations will \ncoexist where the air is thin and manned operations are likely to be the exception, not the rule. \nTodays air traffic management (ATM) system was designed for legacy aircraft, not unmanned \nand lighter-than-air operations. As a result, existing flight rules which govern aircraft behavior, \nare likely to be ill-suited to these non-traditional operations. Just as the current system has \nadapted to meet user needs, so too will adaptations be needed to safely and equitably serve the \nneeds of these new users.\nThus, an assessment of the pros and cons associated with ATM components is needed to \ndetermine the most suitable path for addressing operational needs in higher airspace. This paper \npresents a framework for evaluating ATM services in higher airspace based on the International \nCivil Aviation Organizations (ICAO) Global Air Traffic Management Operational Concept \n(GATMOC), which enumerates user expectations and ATM components for 2025 and beyond.1 It \nprovides an understanding of ATM services relevant to higher airspace, viewed through the \nprism of user expectations along with a discussion of when services beyond what are currently \navailable may be warranted. Higher Airspace Environment\nFor the purposes of this paper, higher airspace begins where passenger transport traffic ends, and \nends where atmospheric density can no longer sustain lift through aerodynamics or buoyancy. As \nmentioned previously, this region is roughly between 52,000 and 160,000 feet. Operations that \nrely on aerodynamic lift rarely exceed 100,000 feet, while operations that rely on buoyancy \ngenerally top out at 140,000 feet, except for some research balloons.2 This region is well below \nthe Karman line (~330,000 feet), and thus still considered airspace. \nThe lower boundary is consistent with the Federal Aviation Administrations (FAA) JO7110.65s 2 3 FAA JO 7400.2, Procedures for Handling Airspace Matters, also defines Jet Routes as being between FL180 and FL450.\n4 Amateur, hobbyist, research and defense related operations, while peripherally considered, are not the focus of this analysis.\n5 These operations include orbital and suborbital spacecraft, amateur rockets, and air launched rockets. Vehicles returning to earth from orbit also transit this airspace; some are controlled reentries (deorbit) and some are not (decay). definition of Jet Routes as not exceeding Flight \nLevel (FL) 450.3 Also, FAA Advisory Circular \nguidance on high altitude operations does not \naddress altitudes above FL510 [1] [2]. Higher airspace, generally associated with the \nstratosphere (see Figure 1), differs from the \ntroposphere below in two key areas: Higher airspace is considered above \nthe weather. High winds associated with the \njet stream top out around 50,000 feet; the \nthunderstorms stop around 60,000 feet. According to the U.S. Naval Flight \nSurgeons manual [3], from a physiological \nviewpoint space begins when 50,000 feet is \nreached since supplemental 100 percent oxygen \nno longer protects man from hypoxia. Anticipated Operations in Higher \nAirspace There are two broad categories of commercial operations that can access this region: 1) \noperations that conduct their mission in higher airspace, and 2) operations that rapidly transit \nhigher airspace en route to their mission.4 The focus of this paper is on the former, since they are \nexpected to dwell in higher airspace, and therefore require a range of traffic management \nservices. Transiting operations will spend little time in this region on the way to their final \ndestination, typically using segregated airspace.5 The needs of these transiting operations remain \nthe same throughout their entire trajectory and are not unique to higher airspace. \nVehicles with wings, rotors, and those that use lighter-than-air gases, rely on air for lift. As \naltitude increases, the air thins and so does the number of viable operations. Only a handful of \nspecialized vehicle types can operate with ease in higher airspace. \nThe five categories of vehicles most likely to operate in this region include: unmanned balloons \n(e.g., sounding, super pressure and zero pressure), manned balloons (e.g., space tourism), \nunmanned aircraft, manned aircraft (e.g., supersonic and hypersonic) and unmanned airships. \nGeneral operational characteristics of these vehicle types are captured in Table 1, and Figure 2 \nclassifies these diversely performing operations by speed and trajectory. Table 1. Performance of Commercial Vehicles Anticipated to Dwell in Higher Airspace Operation Type Speed Duration Cruise Altitude (feet) Unmanned Balloons (Super and Zero Pressure) Low Hours Months 50,000 to 75,000 Figure 1. Atmospheric Layers 3 Manned Balloons (Space Tourism) Low Hours 100,000 Long Endurance Unmanned Aircraft Low Days Months 60,000 to 85,000 Supersonic Transport Aircraft (Manned) Very High Hours 55,000 to 75,000 Unmanned Airships Low Days 55,000 to 70,000 Figure 2. Commercial Vehicle Types Included in each Performance Category Few operations in higher airspace are expected to maintain a steady altitude on mission. Most \nlow-speed horizontal trajectory vehicles ascend in altitude with the heat of the day and descend at \nnight. Some platforms use different altitudes for transiting as opposed to station keeping. Even \nhigh-speed horizontal trajectory flights will slowly ascend as fuel is burned. High level analysis \nindicates that the altitude range between FL550 and FL750 is expected to experience the highest \ndemand. \nOperations in higher airspace will likely be concentrated in specific geographic locations due to \ntheir business needs, operational limitations and/or environmental reasons. While the overall \nanticipated number of operations is low, most of these operations will remain in higher airspace \nfor extended periods of time. This has significant ATM services implications, as current services \nare geared toward legacy traffic operations which are greater in number, but considerably shorter \nin duration.\nThe following is a list of characteristics unique to commercial operations in higher airspace: Long duration operations (typically months) are highly sensitive to weight and tend to 4 rely on solar power. The thinner the atmosphere, the more difficult it becomes for operations that rely on lift \nto maneuver. Super and hypersonic aircraft have narrow viable speed ranges (also known as the \ncoffin corner) and large turning radii. Operations that rely on buoyancy have limited control and maneuverability at all \naltitudes, including higher airspace, unless an engine is present (e.g., airships). Anticipated Service Implications\nThe low atmospheric density characteristic of higher airspace and the unique vehicular \nperformance adaptations for coping with it, pose challenges for an air traffic management system \nbuilt to accommodate a relatively homogenous fleet of maneuverable and responsive aircraft. \nHowever, while some operational characteristics may make air traffic management more \nchallenging, others may actually make it easier. The following categorizes features associated \nwith higher airspace and its anticipated operations by their expected impact on ATM: Positives\nThe lack of convective weather and jet stream increase operational predictability.o The preponderance of unmanned operations would result in less severe collision o\noutcomes.\nTechnologically advanced operators are likely to be able to coordinate well with o\nother operators. Negatives:\nWeight-sensitive vehicles, with limited onboard equipment and power, will limit o\noptions for ATM integration.\nHandling off-nominal situations with unmanned operations may be more complex.o New airspace needs associated with constellations of loitering vehicles will o\nchallenge established norms.\nThe inability to rely on tactical or last-resort collision avoidance will require o\ndeconfliction in advance (strategic planning).\nSingle-use and novel vehicles challenge standard safety practices associated with o\nairworthiness and equipment certification that enable integration. User Expectations\nThe most successful service models are informed by user expectations. Fortunately, ICAO has \noutlined a set of civil aviation user expectations. They can be found in Appendix B of Document \n9854, Global Air Traffic Management [4]. Not all elements are of equal relevance to the higher \nairspace community, as they were developed with legacy operations in mind. Table 2 contains 5 6 A recent National Academies of Science press release (June 11, 2018) about its prepublication report on Assessing the Risks of \nIntegrating Unmanned Aircraft Systems (UAS) into the National Airspace System [5] stated that, FAA Should Change Its \nSafety Risk Assessment Approach for Drones to Effectively Integrate Them Into the Nations Airspace. ICAOs description (in italics) with a brief discussion of each expectations applicability to the \nhigher airspace environment. An additional element, not a part of ICAOs original list, but \nspecific to the higher airspace community is included in the last row of the table. Table 2. ICAO User Expectations and Higher Airspace Application ICAO User Expectations ICAO Definition Higher Airspace Adaptation Safety
Safety is the highest priority in aviation, and \nATM plays an important part in ensuring \noverall aviation safety. The concept of safety may need to be \nreimagined when interactions only \ninvolve unmanned vehicles.6 Global Interoperability The ATM system should be based on global \nstandards and uniform principles to ensure \nthe technical and operational \ninteroperability of ATM systems and \nfacilitate homogeneous and non-\ndiscriminatory global and regional traffic \nflows. An important factor since operators \nintend to have missions that span the \nglobe. Flexibility Flexibility addresses the ability of all \nairspace users to modify flight trajectories \ndynamically and adjust departure and \narrival times, thereby permitting them to \nexploit operational opportunities as they \noccur. Some users will require this more than \nothers, such as those who are reliant on \nwind for propulsion or are highly \nsensitive to wind speed. Mission needs \nare also likely to require flexibility. Access and Equity A global ATM system should provide an \noperating environment that ensures that all \nairspace users have right of access to the \nATM resources needed to meet their specific \noperational requirements and that the shared \nuse of airspace by different users can be \nachieved safely. One of the most difficult requirements \nto meet given the heterogeneous mix of \nmissions and vehicle performance. It \nwill be particularly important for those \noperations that transit regions occupied \nby constellations of on-station vehicles. Security Security refers to the protection against \nthreats that stem from intentional acts (e.g., \nterrorism) or unintentional acts (e.g., human \nerror, natural disaster) affecting aircraft, \npeople or installations on the ground. This is an important concern, given that \nthis region will largely be inhabited by \nunmanned vehicles; cybersecurity and \nspectrum security will be vital but not \nunique to higher airspace. Cost-Effectiveness The ATM system should be cost-effective, \nwhile balancing the varied interests of the \nATM community. The current system (which usually \nrelies on fuel taxes and overflight fees) \nis not aligned well with the mission \nlengths or power sources in higher \nairspace. Predictability Predictability refers to the ability of airspace \nusers and ATM service providers to provide \nconsistent and dependable levels of \nperformance. Trajectories of new vehicles are \nexpected to become more predictable \nover time. However, the broad range of \ntrajectories is likely to persist. Capacity The global ATM system should exploit the \ninherent capacity to meet airspace user \ndemands at peak times and locations while \nminimizing restrictions on traffic flow. Airspace capacity is unlikely to be a \nconcern in the near to mid-term due to \nlow traffic levels and natural \ngeographic segregation. Operators who 6 7 A recent example from surface transportation involves the introduction of autonomous vehicles. A fatal accident made national \nnews when a self-driving Uber car killed a pedestrian [6]. However, the other, approximately 6,000 pedestrian fatalities in \n2017, involving manned vehicles rarely, if ever, make national headlines [7]. use more than one vehicle per mission, \ntypically networked with their nearby \nvehicles, may experience capacity \nconstraints. Participation by the \nATM Community The ATM community should have a \ncontinuous involvement in the planning, \nimplementation and operation of the system \nto ensure that the evolution of the global \nATM system meets the expectations of the \ncommunity. The user community is not anticipated \nto be large, so this should not be \nchallenging, and could prove to be \neffective for collaborative strategic \ndeconfliction. Efficiency Efficiency addresses the operational and \neconomic cost-effectiveness of gate-to-gate \nflight operations from a single-flight \nperspective. Transport operations are likely to value \nthis more than operations that provide \nother services. Environment The ATM system should contribute to the \nprotection of the environment by considering \nnoise, gaseous emissions and other \nenvironmental issues in the implementation \nand operation of the global ATM system. This is not a focus area for operators, as \nmost vehicles with horizontal \ntrajectories in higher airspace are \nenvironmentally friendly, with some \nnotable exceptions (sonic booms from \nMach travel). Additional Requirements \nto Consider (not ICAO) Portability The system can be accessed from multiple locations on the ground and \nuses technology and hardware that are readily available to key system users. Safety is listed first because the expectation of safe passage is fundamental to the system. New \ncommercial operators and vehicle types are particularly susceptible to repercussions when safety \nincidents occur.7 \nSafety, quantified as risk, is a continuum. Not all operations have the same level of risk tolerance \nor aversion. More risk is tolerated when operations are less likely to result in casualties or injuries \n(e.g., unmanned operations) in the air or on the ground. More risk is also tolerated when transport \nis conducted for private purposes rather than for hire. This continuum is a fundamental concept \nthat will be invoked when discussing needs and service levels related to ATM components in the \nnext section.\nThe first column of Table 2 lists the system attributes that all users value in principle and the \nthird column suggests which attributes are most relevant to the higher airspace community. \nWhile there may be general agreement among the higher airspace community, getting all \nstakeholders to agree to a common set of values may be challenging given the diverse mission \nneeds of the operators. Even users of todays ATM system rarely share the same values (e.g., \ngeneral aviation, cargo, and passenger operations have different priorities). \nAdding to the challenge, many system attributes are interdependent and an emphasis in one area \ncan reduce performance in another area. For example: A secure system may restrict access, have less flexibility and forego interoperability. Access and equity may be restricted to ensure safety. Increased flexibility may come at the expense of system efficiency and capacity.\nTo be useful, expectations must be prioritized so that necessary tradeoffs will be guided by what 7 matters most. ICAO recognizes this in its Manual on Global Performance of the Air Navigation \nSystem (Document 9883), which advocates a balanced approach in Part I Appendix B, Section \n4.1 [8]. \nHigher airspace user expectations have been prioritized in Table 3. They represent an average of \nindividual rankings derived from two sources: Rankings provided directly from several operators. We received rankings from three \ndifferent vehicle categories. A compilation of priorities ascertained from discussions with operators, public \nstatements made by industry representatives on conference panels, and during \nAerospace Industry Association meetings. Expectations were ranked using one of three values: high, medium and low. Priorities may \nchange over time; the prioritization of user expectations in Table 3 represents a mid-term (ten \nyears out) outlook. \nSafety, global interoperability, access and equity, and flexibility ranked the highest, with safety \nbeing a unanimous priority. Having stated that, users operating unmanned vehicles in higher \nairspace may have a higher safety risk tolerance than manned operations. Global interoperability \nis crucial to many of the business models and also minimizes conflicting vehicle design and \nequipage requirements. Access and equity will be critical given the diversity in missions and \nvehicle performance. Finally, flexibility will be crucial since many of these operations do not \nplan to follow the traditional transport model (people and cargo) but will need to regularly alter \ntheir flight plans to respond to winds and business needs. Table 3. Prioritization of Higher Airspace User Expectations User Expectation Averaged Priority*\nSafety 1\nGlobal Interoperability 2\nFlexibility 4\nAccess and Equity 4\nSecurity 5\nCost-Effectiveness 5\nPredictability 5\nCapacity 5\nParticipation by the ATM Community 7 8 8 This ranking is more likely a reflection of vehicles that already incorporate environmentally friendly features, as opposed to a \nreflection of value or importance. 9 According to the ICAO GATMOC Air Traffic Management is defined as the dynamic, integrated management of air traffic \nand airspace safely, economically, and efficiently through the provision of facilities and seamless services in collaboration \nwith all parties. Efficiency 7\nEnvironment8 8 * Range is from 1 to 9 Traffic Management in Higher Airspace\nAir traffic management services have evolved to serve legacy operations below 52,000 feet.9 As a \nresult, these services are not as well-suited to serve the unique vehicles and missions planned for \nhigher airspace. This section provides an overview of how current ATM services could be \nadapted to the higher airspace environment. \nThe seven traffic management components identified by ICAOs GATMOC were used to frame \nthe evaluation. For those components relevant to higher airspace, varying levels of service are \nidentified along with qualitative triggers for additional services. Adapting Traffic Management to Meet the Challenges of Higher Airspace\nThe traffic management implications referred to earlier suggest that it would be ineffective to rely \nheavily on tactical separation provision and last resort collision avoidance in higher airspace. \nTactical separation rests largely on a vehicles ability to deconflict trajectories via maneuvering. \nMost vehicles in higher airspace will have a limited range of maneuverability. Last resort \ncollision avoidance relies on the operators situational awareness (visually or though \ntechnological aids akin to Traffic Collision Avoidance System) to see (or detect) and avoid. The \nmajority of higher airspace operations will not have an onboard pilot and will need to limit \nequipage (due to weight sensitivity), leaving few, if any, feasible options for last resort collision \navoidance.\nThis leaves strategic trajectory deconfliction as the primary mechanism for managing traffic in \nhigher airspace. Given the relatively low
number of operations anticipated through the mid-term, \nthere should be enough airspace capacity to safely accommodate operational demands, while still \noffering mission flexibility. The lack of convective weather in higher airspace increases \npredictability and allows for more accurate trajectory estimates. \nTo this end, operators could indicate their intent to fly and request airspace surrounding a 4-\nD trajectory in advance, as long as it does not conflict with other trajectories. This would be \nsimilar in effect to implementing a Temporary Flight Restriction (TFR), an altitude reservation \n(ALTRV) or activating another type of Special Activity Airspace (SAA) but more dynamic in \nnature. The amount of airspace reserved would vary with the certainty and timing associated with \na given operations trajectory. Trajectory separation requirements would be determined by \nassessing the performance of the interacting operations (i.e. speed, maneuverability, equipage, \ncommunication latency, etc.). Initially, distances would be substantially buffered in time and \nspace. But as operational experience accrues, and technology improves, the buffers could be \nreduced. The advantage in this stratum of atmosphere is there are fewer operators that would \nneed to avoid this temporary airspace activation. This activation could be more time sensitive \nbased on the launch parameters/planned departure time for this same reason. Figure 3 illustrates 9 10 Procedural separation could be used because it meets operational requirements, and relative to other methods, it is easy to \nimplement and does not require a large investment in supporting infrastructure. 11 This is similar to current traffic management practices, whereby placeholders are entered 24 hours in advance into the \nAggregated Demand List. A series of triggers update the flights intent, such as the filing of a flight plan. notional airspace needs and buffers. The black buffer reflects the minimum vehicle performance \nbuffer, whereas the green line reflects a trajectory and speed-based buffer relative to other \noperations. Procedural separation would be used during off-nominal events, enhanced by \ntechnology and automated position reporting to confirm route conformance.10 For operations that \ndo not know their full intended trajectory or timing prior to their mission start (because some \nmissions last for months), an initial trajectory (flight plan) would be required, but amendments \ncould be allowed in areas where no other operations would be adversely affected.11 Figure 3. Notional 4-D Trajectory Airspace Buffers Applicability of ICAOs Traffic Management Components\nICAOs air traffic management operational concept describes the services that will be required to \noperate the global air traffic system up to and beyond 2025. As noted earlier, ICAO identified \nseven interdependent system components that make up the GATMOC of the future. Together \nthese components describe how ATM will act directly on the flight trajectory of a manned or \nunmanned vehicle during all phases of flight, and the interaction of that flight trajectory with any \nhazard. \nBy emphasizing global ATM components and services, ICAO avoids complications associated \nwith boundaries (political and/or airspace). This approach facilitates the evolution of an \nintegrated, harmonized and globally interoperable system. The ICAO GATMOC defines the \nfollowing system components: Conflict Management1.\nAirspace Organization and Management*2.\nATM Service Delivery Management3.\nAirspace User Operations4.\nDemand and Capacity Balancing*5.\nTraffic Synchronization*6.\nAerodrome Operations7. 10 12 This has equity implications as well, as less maneuverable vehicles such as UFBs can take advantage of this hierarchy to \nprioritize their use of the airspace. 13 Service providers like the FAA have begun to proactively identify safety risk. A formal methodology, Safety Risk * Indicates components that ICAO considers an integral part of conventional Strategic Conflict \nManagement, but that relationship does not necessarily hold for higher airspace The scope of this paper is limited to operational needs in higher airspace, and therefore does not \ninclude transiting to or from that region. As a result, aerodrome operations are considered out of \nscope and are not addressed. \nThe remainder of this subsection elaborates on each of the individual components, outlining what \nservices already exist in higher airspace and what may be needed in the future. When applicable, \nthe associated level of service is identified, as well as qualitative triggers for when those \ncomponents would be needed. Conflict Management\nApplicability: This is a core requirement of any traffic management system. ICAOs conflict \nmanagement component is made up of layers, which together form a multi-level approach to \nsafety and separation assurance. The layers include: 1) Strategic Conflict Management, 2) \nSeparation Provision (tactical), and 3) Collision Avoidance (last resort). \nFor the reasons provided earlier, tactical and last resort collision avoidance cannot be relied upon \nin the higher airspace environment. Instead, to the extent possible, separation assurance should be \ndetermined strategically to prevent encounters between vehicles. This does not preclude the need \nfor a viable secondary collision avoidance mechanism in the case that the primary mechanism \nfails. \nICAOs vision of strategic conflict management (made up of three other components: airspace \norganization and management, demand and capacity balancing, and traffic synchronization) does \nnot quite align with the expected environment and will need to be tailored to the higher airspace \nregion. The applicability of the three associated strategic components is addressed in subsequent \nsections. \nCurrent Level of Service: In the U.S., the three levels of conflict management are procedurally \naddressed in the following ways: Strategic Conflict Management Typically handled on an ad hoc basis, usually via 1.\nairspace management tools, to separate commercial space launch and reentry or other \nhazardous operations from other vehicles. In the past, specialized routing was used to \nsupport supersonic flight across the Atlantic Ocean. \nSeparation Provision Generally IFR traffic are handled on a first come, first served 2.\nbasis, with some exceptions provided in FAA JO 7110.65 2-1-4 (Operational \nPriority). In addition, JO 7110.65 offers IFR separation criteria applicable to higher \nairspace aircraft including: vertical (4-5-1), lateral (5-5-4) and airspace (9-3-2). \nCollision Avoidance Title 14 Code of Federal Regulations Part 91.113 requires 3.\nvehicles with superior maneuverability to take evasive action.12 Triggers for Additional Service: Acceptable level of collision risk plays a large role in \ndetermining the degree of conflict management services. As the variables that impact collision \nrisk change over time (e.g., trajectory predictability, number of operations, presence of manned \noperations), the appropriateness of the conflict management system should be reviewed.13 11 Management, exists to evaluate airspace changes. In the future, automation may offer a way to provide conflict management services to particularly \nchallenging areas of the NAS. For example, higher airspace and near ground level airspace are \ntwo areas which could eventually benefit from automation. It may also help supplement \nconventional air traffic control, as traffic complexity and levels continue to increase. In the far \nterm it is possible that advanced automation could fulfill all roles. Airspace Organization and Management\nApplicability: Airspace organization and management is expected to play a vital role in safely \nmanaging the anticipated operational diversity and ensuring global interoperability in higher \nairspace. \nCurrent Level of Service: Segregating high-speed vertical operations from other operations, \nusing SAA, is currently the tool of choice that will likely see continued, if not increased use. \nIdeally, as more experience is gained with vehicle operations, the amount of airspace blocked \nwill be reduced in both size and duration. \nTriggers for Additional Service: A preliminary risk assessment performed by MITRE indicates \nthat the near-term (2025) risk of a collision in higher airspace is extremely unlikely [9]. \nHowever, as traffic density increases, and supersonic and/or hypersonic manned flight begin to \ntake place overland, changes to airspace classification and the addition of structure (via charted \nhigh-altitude routes) may be warranted. Supersonics pose two challenges that airspace structure \nand management could potentially mitigate, their extreme speed compared to other operations, \nand the increased risk due to the presence of human life. \nAny airspace classification change (which could involve an existing or a new airspace class) \nwould need to complement conflict management service levels (discussed in the previous \nsection). The addition of airspace structure could be used to minimize the comingling of high and \nlow speed horizontal operations, offering predictable routes or corridors for manned traffic (to \nreduce collision risk), that balloons and other slow-moving operations would avoid when \nactivated. An example of organized flow management might look like the North Atlantic \nOrganized Track System and the Pacific Organized Track System where routes are developed \nand published daily via Notice to Airmen (NOTAM). They are located to take advantage of \nwinds while maintaining lateral separation between the tracks to minimize conflicts and \ncomplexity, and to maximize capacity and efficiency. For higher airspace purposes they may be \nfixed in location, but only activated when needed via a NOTAM. For example, because the \nConcorde flew above the jet stream, only two tracks were created for it (one eastbound and one \nwestbound), thereby eliminating the daily need to optimize for wind. \nNew airspace tools may also be needed to more flexibly and dynamically handle the hazard areas \nbelow some operations, particularly those associated with launch and reentry activity (e.g., \nactivate protective corridors established for the launch duration and then deactivate them once the \nairspace volume is no longer required). The airspace deactivation could also be done in sections \nor layers after the vehicle transitions through them to minimize the impact to nonparticipating \naircraft and/or other vehicles.
Airspace User Operations\nApplicability: The diversity of vehicles and missions expected in higher airspace make this \nATM component particularly relevant. The ability to safely accommodate different vehicle 12 14 As is true for the legacy NAS, measures will need to be taken to ensure that civil operations pose minimal impact to defense \nrelated missions. capabilities and planning horizons will be crucial to any higher airspace ATM system. Of the \nattributes ICAO associates with this component, perhaps the most salient is the limited ability of \nsome vehicles to dynamically change trajectory. In higher airspace, limited tactical \nmaneuverability will be the rule rather than the exception. \nCurrent Level of Service: In the U.S., the FAA is in the process of better understanding the \noperational needs of new entrants. Multiple Aviation Rulemaking Committees have been formed \nincluding Unmanned Aircraft System (UAS) in Controlled Airspace, Part 101, and Airspace \nAccess Priorities. Equipage requirements vary depending on how vehicles are regulated. This \ncurrently creates an inconsistent environment for delivering ATM services.\nVehicle licensing and airworthiness certification are frequently used to ensure compatibility with \nATM operations. In situations where there is no standardized path for new or novel vehicle types, \nproponents must obtain special permission/exemptions to waive regulatory compliance, and a \ncorresponding certificate of authorization. This process can be cumbersome and costly depending \non the safety data required of the proponent.\nTriggers for Additional Service: Once at altitude, the higher airspace community will face \nminimal integration concerns, as they will be among the first commercial operators to routinely \noperate in this airspace.14 Instead, the focus will be on how the system can safely accommodate \nextremes in performance (e.g., an unmanned free balloon and a supersonic business jet). New \nservices and/or procedures will be triggered as risk increases, which will generally coincide with \nmanned flights and incompatible vehicle performance characteristics. ATM Service Delivery Management\nApplicability: Increased reliance on strategic conflict management for collision prevention will \namplify the importance of the situational awareness and collaborative decision-making aspects of \nthis component.\nCurrent Level of Service: Under the FAAs Aeronautical Information Management \nModernization Program (AIMM), the Aeronautical Common Services (ACS) capability serves as \nthe single trusted source for Aeronautical Information, including SAA information. The real-time \navailability of SAA status and schedule information is currently under development. Planned \nfunctionality includes SAA legal descriptions and TFR/ALTRV NOTAM information [10]. The \nACS uses the System Wide Information Management (SWIM) services to disseminate SAA data, \nallowing NAS users the opportunity to view the dimensions and active status of all SAA in the \nNAS. The data contained within these systems could potentially be used for scheduling and \nstrategic deconfliction in the higher altitude stratum. \nTriggers for Additional Service: As traffic density and diversity increases, the need to \ncoordinate traffic trajectories will increase. In the near term, collaboration tools for space \noperations, such as the Information Sharing Capability, could be expanded to serve the higher \nairspace community. In the mid-term, operations could signal intent through trajectory-based \noperations (TBO) as part of the strategic conflict management process. This will be especially \nrelevant for long duration missions where strategic conflict management occurs when a vehicle is \nalready on mission in higher airspace. Demand and Capacity Balancing 13 15 Commercial operations traveling over Mach 1 are currently prohibited overland in the U.S., per 14 Code of Federal \nRegulations Part 91.817. 16 The impact on legacy traffic below and DoD operations must also be factored into requirements. Applicability: Demand is unlikely to routinely exceed higher airspace capacity in the near to mid-\nterm. Notwithstanding, temporary constraints may arise in busy corridors. For example, the \nregion between Florida and Puerto Rico, regularly hosts commercial space launches, Department \nof Defense (DoD) operations and high-altitude balloons. In the future, this busy international \ncorridor may also see supersonic and airship activity. \nCurrent Level of Service: Due to the rare and impromptu nature of imbalances, this is largely an \nad hoc process that is not handled consistently across the NAS. At present, airspace capacity \nshortages are most associated with SAA that is being used for commercial space launch. To \nalleviate capacity shortages, the Air Traffic Organization (ATO) has developed guidelines, based \non five different mission categories, to help determine the level to which SAA use can disrupt the \nactivities of other airspace users. Airspace use associated with commercial launch and reentry \n(including tourism) ranks the lowest. \nShould ongoing mission operations need to be strategically deconflicted, a priority scheme \nsimilar to the ATO guidelines is likely to be employed, whereby DoD operations take precedence \nover commercial operations. However, DoD missions may also choose to deconflict, assuming \nthey have advanced knowledge of the commercial operators intent.\nTriggers for Additional Service: In the next ten years competition for the same airspace should \nrarely occur because operators missions and vehicle characteristics will naturally segregate the \noperations. For example: Fast moving horizontal trajectories of super and hypersonic aircraft operations will \ngenerally be found over international waters as these operations aim to reduce travel \ntime between continents (this also minimizes noise impact15). Fast moving vertical trajectories associated with commercial space operations will \noccur in coastal regions over international waters and from inland spaceports within \ndeveloped economies. Slower moving and station-keeping telecommunication vehicles using unmanned \naircraft, airships and balloons will be concentrated over developing economies near \npopulated regions. There may eventually come a time when vehicles airspace needs routinely conflict. Given the \nrelatively small number of operators, it would be preferable for the users to collaboratively \ndevelop procedures, in partnership with service providers, to balance capacity and demand.16 The \nconcept would be similar to what the collaborative decision making (CDM) community has done \nwith ground delay programs and en route flow constrained areas. Traffic Synchronization\nApplicability: This component has limited relevance in higher airspace because the tactical \nsequencing and spacing to maintain an orderly flow of traffic is unlikely to be needed in the near \nto mid-term given the absence of structured routes and congested airspace. Even if the need \narose, many vehicles would not be able to maneuver well enough for it to be effective. \nCurrent Level of Service: Traffic synchronization is not routinely needed to manage operations \nin higher airspace today. If and when the need arises, it is handled manually. 14 Triggers for Additional Service: In the near to mid-term, it is unlikely that higher airspace will \nbecome so congested as to require routine traffic synchronization. It is possible that points of \ningress and egress into higher airspace (akin to choke points) could become constrained requiring \na method for synchronization or scheduling. Summary \nIn Table 4, we present ATM components through the lens of the user community, synthesizing \nthe analyses from the previous sections. User expectations are grouped in descending order of \npriority and shaded based on the priority level (described earlier). The traffic management \ncomponents are also ordered, starting with the most important based on applicability to higher \nairspace. The table offers a relative ordering, with the upper left-hand corner boxes representing \nthe key expectations and most relevant traffic management components. Conversely, the lower \nright-hand corner, represents less pressing expectations, and less germane traffic management \ncomponents. \nNote that for the most part, the lowest priority expectations intersect with the least applicable \ntraffic management components. Whereas, the highest priority expectations are generally aligned \nwith the most essential traffic management components. Table 4. Global ATM Components and Prioritized User Expectations Sa\nfe ty G\nlo ba\nl I nt\ner op\ner ab\nili ty Fl\nex ib\nili ty A\ncc es\ns & E\nqu ity Se\ncu ri\nty C\nos t-E\nffe ct\niv en\nes s Pr\ned ic\nta bi\nlit y C\nap ac\nity Pa\nrt ic\nip at\nio n \nby A\nT M C\nom m\nun ity E\nffi ci\nen cy E\nnv ir\non m\nen t\nConflict Management Airspace Organization and Management Airspace User Operations ATM Service Delivery Management Demand and Capacity Balancing Traffic Synchronization Primarily contributes to meeting user expectation\n Secondarily contributes to meeting user expectation High Priority Low PriorityMedium Priority U\nse r \nE xp\nec ta\ntio ns Traffic Management Component\n(ranked by descending importance) Concluding Remarks\nFor this analysis, an existing ICAO framework was leveraged as a way to systematically evaluate \nand prioritize traffic management components. It is important to note that this study is not \nadvocating a particular solution or concept, but rather exploring options to determine what traffic \nmanagement components would be of most value as needs in this region evolve. \nThis work focused on nominal operations, however both nominal and off-nominal operations will \nneed to be considered once a concept of operations is established, and a safety case will be \nneeded to support it. A more nuanced approach to off-nominal operations may be needed as not \nall off-nominal situations will pose a risk to humans in the air or on the ground. \nIn the meantime, much can be done on an operational level to improve access and situational 15 awareness in the immediate future. Work should be undertaken to enable operations in the near \nterm by leveraging operator use cases, existing research, and existing capabilities. 16 List of References\n[1] Advisory Circular 25-20 Pressurization, Ventilation and Oxygen systems Assessment for Subsonic Flight Including High Altitude Operation, Federal Aviation \nAdministration, September 10, 1996. [2] Advisory Circular 61-107B Aircraft
Operations at Altitudes Above 25,000 Feet Mean \nSea Leve or Mach Numbers Greater than .75, Federal Aviation Administration, \nMarch 29, 2013. [3] U.S. Naval Flight Surgeons Manual, Naval Aerospace Medical Institute Third Edition, \n1991. [4] Global Air Traffic Management Operational Concept, International Civil Aviation \nOrganization, Doc 9854, First Edition, 2005. [5] National Academies of Science, Assessing the Risks of Integrating Unmanned Aircraft \nSystems (UAS) into the National Airspace System The National Academies \nPress, Washington D.C., 2018. [6] Wakabayashi, Daisuke, Self-Driving Uber Car Kills Pedestrian in Arizona, Where \nRobots Roam, New York Times, March 19, 2018. [7] Pedestrian Fatalities Remain At 25-Year High For Second Year In A Row, National \nPublic Radio, February 28, 2018. [8] Manual on Global Performance of the Air Navigation System, International Civil \nAviation Organization, Doc 9883, First Edition, 2009. [9] Gentry, Jennifer. New Entrant Operations above Flight Level 600 (FL600), Space \nTechnical Exchange Meeting. The MITRE Corp., McLean VA, June 2017. [10] Aeronautical Information Management Modernization (AIMM) Segment 3 Concept of \nOperations, Federal Aviation Administration, June 17, 2017. NOTICE This work was produced for the U.S. Government under Contract DTFAWA-10-C-\n00080 and is subject to Federal Aviation Administration Acquisition Management \nSystem Clause 3.5-13, Rights In Data-General, Alt. III and Alt. IV (Oct. 1996). The contents of this document reflect the views of the author and The MITRE \nCorporation and do not necessarily reflect the views of the Federal Aviation \nAdministration (FAA) or the Department of Transportation (DOT). Neither the FAA \nnor the DOT makes any warranty or guarantee, expressed or implied, concerning \nthe content or accuracy of these views. 2019 The MITRE Corporation. All Rights Reserved. 17 Approved for Public Release; Distribution Unlimited. Case Number 19-0178 _top\n _Toc535242743\n _Hlk535095779\n _Toc522270102\n _Toc522272287\n _Toc522392778\n _Toc522617119\n _Toc535242744\n _Toc535242745\n _Toc535242071\n _Toc535240997\n _Toc535242746\n _Toc535242747\n _Toc535242748\n _Toc535242749\n _Toc535240998\n _Toc535242750\n _Hlk535922470\n _Hlk518018022\n _Hlk519689234\n _Hlk520892098\n _Toc535242751\n _Toc535242752\n _Toc535240632\n _Toc535240633\n _Toc535240634\n _Toc535240635\n _Toc535240636\n _Toc535240637\n _Toc535240638\n _Toc535240640\n _Toc535240641\n _Toc535240642\n _Toc535240644\n _Toc535242753\n _Toc522272311\n _Toc522392802\n _Toc522617143\n _GoBack ",
    "text": " MITRE Briefing Template 4x3 Were Hiring! Attracting Candidates with Employees LinkedIn and Twitter Networks: ABSTRACT | # | \n Donna Gregorio and Jeff Barr\nApril 2018 Approved for Public Release; \nDistribution Unlimited Case 18-1389 Were Hiring!\nAttracting Candidates with Employees LinkedIn and Twitter Networks \n| # | | # | \n Agenda \nAttacking the problem:\nMITREs hiring surge Find better candidates ASAP\nWere Hiring! Getting the word out\n Convincing employees to post to their Twitter and LinkedIn networks\n Providing incentives via employee referral eligibility Addressing implementation challenges Key Takeaways | # | \n 3 Problem Statement Hiring Surge, Find Quality Candidates\nUsing Indeed, MITREs LinkedIn site\nEmployee referrals limited via jobs site to specific job\nTaleo Candidate Sourcing\nNot enough candidates\nWhy cant I refer candidate to any job?\nNo prioritization for hot jobs\nLimited\nReferrals\nHot jobs\nHire 800+ people this year\nHiring Surge | # | \n Problem Statement Hiring Targets\nAdded Social Media Referrals in Jan 2018\nBottom Line: Hire More!\n% 87%\n87%\n87%\n40%\n51%\n37%\n23%\n9% | # | \n Why use Twitter and LinkedIn?\nPersonalize the message: Great for indicating priority\nEmployees get automatic referral bonus whats not to love?\nWhat its\nnot\nEmployee social media networks reach out to more individuals than typical job campaign\nIndividuals are more likely to respond based on recommendation from trusted advisor\nTwitter and LinkedIn attract candidates. But also, if my friend works there, must be a good place to work\nHow to attract people who are friends of employees | # | \n Posting Jobs to Employees Twitter and LinkedIn | # | \n Referrals: On Candidate Employee shares job to Twitter, LinkedIn, Email, Other Social Media\nReferral on Candidate\nCandidate applies using link\nCandidate and employee are linked for 1 year for any job candidate applies to\nEmployee eligible for referral bonus | # | \n Incentivize Employees by offering Referral Bonus\nEmployee and candidate linked via referral\nCandidate applies to job Work with me!\nAdd a personal touch\nMITRE is hiring!\nHard to fill job!\nGreat place to work!\nEmployee shares job\nVia LinkedIn, Twitter, or email | # | \n 9 Employee View: Need Single Sign On Job share creates unique link tied to employee\nEmployee Needs\nAnalytics record when shared and to what network\nUnique link to job tied to employee\nJob share vs. referral\nNo single sign on, no referral, only a share\nNon-employees can share, no referral for them\nCandidate information (except email, if sending)\nEmployee Does Not Need\nCandidate resume | # | \n | # | \n Configurable list of questions\nEmployee can endorse candidates\nSpace to enter text about candidates\nSent to recruiter on the job requisition\nManually attached to candidate record\nThis is record of referral\nNo further record to employee is maintained Employee View: Endorsement Email | # | \n Email to employee if candidate already has a referral\nEmployee gets email notifying someone else already referred\nOnce candidate applies to first shared link, they are connected for 1 year\nIf candidate tries to apply to another job using someone elses link, they can apply but first referral sticks\nEmployee View: If candidate already endorsed | # | \n Candidate View\nCreate account\nApplication process\nUpload resume\nAnswer questions\nClick on link, brings them to job application\nGet link in email or on Social Media | # | \n 14 Challenges\nMany use cases\nEmployee refer, prior referral, multiple referrals\nTesting\nUsed to referring a specific job, limited training attendance\nEmployee Change Management\nNeeded better job search for employees so they could find jobs to share\nJob Search\nGetting recruiters to use Promote Jobs features\nPromote Jobs\nDesign Decisions\nReferral to candidate or to specific job? \nAnalytics tracking\nAnalytics\nResets all services and refreshes all caches for the application:\nUse after making site configuration changes\nReset Site Button | # | \n Employee refers candidate to a specific job\nReferral on Job\nLimiting\nForces employee to do more work to have chance at referral bonus\nEmployee shares job; Once candidate applies, referral is created for any job\nReferral on Candidate\nMore chance of referral with less job shares\nLess work for employees to have chance at referral bonus\nDesign Decisions: Referrals On Job vs. On Candidate | # | \n Testing: Enumerating Use Cases\nLinkedIn post forwarded to candidate\nExample Scenarios\nCandidate applies to req A, hired on req B\nCandidate referred by multiple employees\nCandidate applies to req A then referred to req B\nExisting legacy referral | # | \n Employee change management Tip sheets\nEmployee Change Management\n(training to obtain advocates)\nSamples\nShort videos\nBrown bags | # | \n Job Search | # | \n Referrals on demand\nRecruiters use of promote jobs\nSend jobs to fans and followers\nSearch and message your talent community\nPromote Jobs | # | \n Reset Site Resets all services and refreshes all caches for the application\nReset button\nUse after making site configuration changes | # | \n Can see activity for one month\nAnalytics\nTotal employee count\nTotal resumes\nNumber of jobs shared\nNumber of jobs viewed\nNumber of apply starts\nExtracting and analyzing statistics | # | \n Did We Meet Our Hiring Needs?\nBottom Line: Hire More!\n% 87%\n87%\n87%\n40%\n51%\n37%\n23%\n9%\nHiring numbers are up thanks to social media shares | # | \n Number of job shares up significantly\nAnalytics\nTotal job shares over time has increased | # | \n Key Takeaways Social media job sharing increases quantity (and we believe quality) of prospective candidates\nReferrals challenging, need to think it through\nTool configuration flexible and provides different alternatives\nMake sure your implementation reflects your design decisions\nExample: Candidate referral vs. job-specific referral\nTest program include variety of use cases\nIncentive to employees = $: win-win! | # | \n 25 | 26 | MITRE is a not-for-profit organization whose sole focus is to operate federally funded research and development centers, or FFRDCs. Independent and objective, we take on some of our nation'sand the worldsmost critical challenges and provide innovative, practical solutions.\nLearn and share more about MITRE, FFRDCs,\nand our unique value at www.mitre.org | # | \n ",
    "text": " Copyright On a Quest to Field Better Cyber Awareness Tools for \nWarfighters Today, it's as likely warfighters will be fighting attacks within their networks as in the physical world. That's why an Army center partnered with MITRE on a cybersecurity tool that puts key data into a usable context, to consider for the field. Cyberattacks by adversaries could cripple the networks and systems our nation's warfighters rely on to protect themselves and to project power on the battlefield. As part of a range of approaches to counter such threats, the U.S. Army Cyber Center of Excellence hosts a yearly major exercise called Cyber Quest. For several weeks, the military and allies test emerging cyberspace and electronic warfare technologies in the field. During Cyber Quest 2018, the Army Cyber Center of Excellence invited MITRE employees to help Army cyber protection teams field test CMITCyber Electromagnetic Activities (CEMA) Situational Awareness Tactical Analytics Framework (C-STAF) Mission Impact Tooland with good reason. CMIT is built on and extends the capabilities of MITRE's CyGraph cyber data collection, analysis, and decision-support tool. \"Cyber Quest is like the Army's short list of what they think are good candidates for fielding in the near term,\" says Steve Noel, a MITRE cybersecurity engineer. A Cyber Tool with a Critical Difference: Context CMIT is a software tool for improving network security posture, maintaining situational understanding in https://www.mitre.org/research/technology-transfer/technology-licensing/cygraph Copyright the face of cyberattacks, and focusing on protecting mission-critical assets. What's different about CMIT compared to other software tools? For one thing, there are tools that provide some cyber data and others that enable the operator to see vulnerabilities in network diagrams and systems. \"With CMIT, the big thing is the ability to view information in context,\" says Steve Purdy, a MITRE software systems engineer and former Army Signal Corps officer. He and Noel and demonstrated CMIT together at Cyber Quest 2018. \"Not many technologies bring all of that information together in a way that lets you make decisions,\" Purdy adds. \"CMIT operationalizes cyber data, which is a key sponsor need.\" CMIT combines isolated data and events to provide Army cyber protection teams with an overall picture for situational awareness and decision support. It offers an analysis dashboard that allows operators to formulate and submit queries and visualize the results. CMIT's predecessor, CyGraph, was created under MITRE's independent research and development program. Discussions between MITRE and the U.S. Army Combat Capabilities Development Command, Control, Computers, Communications, Cyber, Intelligence, Surveillance and Reconnaissance (C5ISR) Center led to Army personnel identifying CyGraph as a candidate technology they could build on to map dependencies among information technology assets. CMIT was born. Based at the Aberdeen Proving Ground in Maryland, C5ISR Center is the Army's information technologies and integrated systems center. We support C5ISR Center by developing and delivering tools such as CMIT. MITRE and C5ISR Center furthered the CMIT concept through experimentation with warfighters. This https://www.mitre.org/research/overview\nhttps://www.mitre.org/research/overview\nhttps://www.mitre.org/research/overview\nhttps://www.cerdec.army.mil/inside_c5isr_center/core_technology/ Copyright work occurred as part of the C-STAF Science Distribution Unlimited. Public Release Case Number 18-4233 _top\n _Hlk529453317\n _Hlk3880911\n _GoBack ",
    "text": " Controller Initiation and Monitoring \nof a Relative Spacing Task during \nClosely Spaced Parallel Runway \nOperations Interval Management Paired Approach Human-\nIn-The-Loop Experiment William J. Penhallegon\nH. Peter Stassen\nKara J. MacWilliams March 2019 MTR 190104 MITRE TECHNICAL REPORT Sponsor: The Federal Aviation \nAdministration\nDept. No.: P123\nProject No.: 0217DG02-IM\nOutcome No.: 2\nPBWP Reference: 2-6.B.1-1, A-IM Paired \nApproach Monitoring HITL Simulation \nResults Final Report The views, opinions and/or findings \ncontained in this report are those of The \nMITRE Corporation and should not be \nconstrued as an official government \nposition, policy, or decision, unless \ndesignated by other documentation. Approved for Public Release: 19-0822. \nDistribution Unlimited. \nAll rights reserved. McLean, VA Executive Summary\nThe Federal Aviation Administrations (FAA) Next Generation Air Transportation System \nleverages new technology and concepts to improve efficiency and enhance safety in the \nNational Airspace System. One such concept is Interval Management (IM) which refers to an \napplication suite, enabled by Automatic Dependent Surveillance Broadcast (ADS-B), providing \ngreater air traffic system throughput and efficiency by improving inter-aircraft spacing precision. \nIM avionics (termed flight deck-based IM [FIM] Equipment) provide speed commands to the \nflight crew enabling them to manage a desired spacing relative to another aircraft. IM is a \ntactical capability used to manage spacing based on a separation standard, miles-in-trail \nrestriction, or any air traffic control spacing objective. The closed-loop nature of IM allows for \nmore accurate speed adjustments to achieve the desired spacing for a given flight segment than \ncan be provided by a ground system. IM Paired Approach (PA) is intended for dependent approaches to Closely-Spaced Parallel \nRunways (CSPRs) (i.e., separated by less than 2,500 feet). This application provides a means for \nCSPR approach and landing operations to continue in weather conditions where visual \nseparation cannot be maintained. IM PA maximizes arrival throughput in Instrument \nMeteorological Conditions (IMC) by minimizing the in-trail spacing between successive arrivals \nwithout compromising safety. An IM PA aircraft pair consists of a Lead Aircraft, equipped with ADS-B Out avionics, and a Trail \nAircraft equipped with ADS-B In FIM Equipment on the CSPR. A Collision Safety Limit (CSL) is \ndefined between the two aircraft such that the risk of collision is less than 10-9 in the case that \neither aircraft deviates laterally from its approach path into the adjacent path. A Wake Safety \nLimit (WSL) defines the risk the Trail Aircraft encounters the wake vortices from the Lead \nAircraft at a rate no worse than current operations. All IM PA operations require a CSL; \nhowever, the need for a WSL is based on aircraft weight category and crosswind conditions. The \nFIM Equipment provides speeds to the Trail Aircraft flight crew to manage spacing relative to \nthe Lead Aircraft and keep the Trail Aircraft inside the safety limits for the entire approach to its \nrunway threshold. A new separation standard is envisioned for IM PA operations and it will \nlikely be based on allowable safety limit values as implemented at each airport. The FAA, National Aeronautics and Space Administration (NASA), The MITRE Corporations \nCenter for Advanced Aviation System Development (CAASD), and others have been conducting \nresearch on various aspects of PA for over two decades. In 2016, RTCA Special Committee 186 \n(SC-186) Working Group 4 decided to make PA an IM application and include it in the updated \nFIM Equipment requirements. Through this process, stakeholders determined controllers must \nbe able to monitor the operation relative to a separation standard. This requires controllers to \nbe able to assess separation within an IM PA pair and take effective action before separation is \nlost. Therefore, the IM PA concept was changed to move the safety limit monitoring function \nfrom being a flight crew responsibility and FIM Equipment capability to a ground capability, \nlikely to be hosted in the Standard Terminal Automation Replacement System. The FAAs Surveillance Broadcast Services (SBS) Program Office tasked MITRE CAASD to develop \nand execute a Human-In-The-Loop (HITL) simulation experiment to validate IM PA concept \nchanges, address open controller acceptability and feasibility questions, provide input to air and \nground system requirements, and mitigate technical risks associated with the revised PA iv\n concept. The primary goal of this HITL simulation was to examine new controller monitoring \nfunctions. A secondary goal was to examine acceptability and information requirements for IM \nPA initiation. Addressing the primary goal included an evaluation of the terminal controller monitoring task \nfor IM PA aircraft pairs established on final approach, especially with respect to both minimum \nand maximum separation values that change over the course of the approach, and for lateral \ndeviations. Related to this goal was the acceptability of a single Monitor controller to manage \nLead and Trail Aircraft, or whether separate monitors should be required. The experiment also \nincluded an evaluation of prototype display features to facilitate this monitoring task. These \nfeatures were developed by MITRE CAASD for the FAAs Closely Spaced Parallel Operations \nProgram Office in coordination with SBS and the FAAs Operational Concepts, Validation, and \nRequirements office in 2017. Data collection occurred in April 2018 and twelve currently certified Air Traffic Controllers \nparticipated in the simulation. Four controllers were from the Northern California Terminal \nRadar Approach Control facility and had experience in the areas being simulated. Eight \ncontrollers were from other terminal facilities with parallel runway approach operations. The \ncontroller participants managed scenario traffic that included IM PA operations in both Final \nApproach and Final Monitor positions. Two pseudopilots controlled and responded as all \naircraft. Two confederate controllers served as Local controllers. After initiating and monitoring IM PA operations with varying supporting IM PA (display) Tool \nconfigurations, monitor configurations, and off-nominal deviations, results suggest given the \nappropriate tools and training, the IM PA longitudinal and lateral separation monitoring task \nshould be feasible and acceptable to controllers. IM PA pair-wise separation assurance \nappeared to be a straightforward task for controllers as only a single violation was observed \nwithin an IM Trail Aircraft and IM Lead Aircraft pairing, despite the introduction of far more off-\nnominal deviations than would be expected in actual operations. This instance involved a \ncontroller appearing to attempt to manually manage an IM PA Trail Aircrafts speed. It was not a \nresult of the controller failing to notice a developing situation. Separation was also examined between other aircraft combinations (e.g. between the trail \naircraft of a leading pair and the lead aircraft of a following pair). Twelve total instances of \nseparation violations were observed between aircraft pairs not performing IM PA. It was unclear \nif this was due to the presence of IM PA in the operational environment or was related to \ncontrollers in the simulation not having current separation tools such as Automated Terminal \nProximity Alert available to them. Although these violations occurred in the context of \nsimulation events that were designed to stress test the concept and ground tools, their \npresence still suggests that tools and procedures need to be fully integrated to ensure that \nseparation between aircraft pairs not performing IM PA can be maintained while IM PA \noperations are in progress. In addition, IM PA setup spacing requirements should ensure that \nbetween-pair separation can be sufficiently maintained during compression on final. Controller participants on average reported: low and acceptable workload; acceptable tasks in \neach of the monitoring positions; acceptable levels of traffic awareness for all types of aircraft; \ncomfort in allowing the IM Trail Aircraft to manage their own speeds; and confidence they could \nassess whether the separation between the IM Trail Aircraft and Lead Aircraft would be v\n maintained. They also agreed IM PA is operationally desirable and compatible with terminal \napproach operations, though real-world facility and airspace integration may be challenging. \nController participants appeared to be comfortable monitoring IM PA when both safety limits \n(CSL and WSL) that changed over the course of an approach were active at the same time. Due to the potential logistical and operational challenges certain facilities may have employing \ntwo Local controllers, the HITL experiment examined whether a single, combined Monitor \ncontroller can effectively provide separation for two CSPR final approaches involving IM PA \noperations. Results suggest under nominal conditions, a single, Combined Monitor controller is \nlikely to be able to effectively and acceptably provide separation within and between IM PA \npairs. However, further study is recommended to examine whether separate monitors may \nultimately be required for safety to manage extreme off-nominal lateral deviation situations. The simulation also produced several findings and recommendations with respect to the IM PA \nTool display elements. Graphic depiction of the safety limits were preferred to numeric \ndistances presented in the Trail Aircraft data block. As the WSL only became active late in the \napproach, controllers found a preview feature helpful in indicating whether an aircraft would \neventually require it. Alerts were introduced to direct controller attention to aircraft that were \nstarting to encroach on either limit and controllers found these useful. For the lateral monitoring task, a 4:1 aspect ratio Final Monitor Aid display was found to \nsignificantly help controller lateral deviation assessment; however, questionnaire responses did \nnot appear to suggest it should be a minimum requirement. A Warning was introduced to
\ninform controllers when a lateral deviation occurred and IM PA needed to be terminated. \nControllers found it useful and offered suggestions to increase its saliency. Most controllers reported a Final Monitor controller is the most appropriate position to monitor \nIM PA operations, though this may ultimately depend on the facility. They also expressed a \nstrong preference to provide speeds manually to the IM Trail Aircraft when they observed a \nspacing situation start to develop. However, the practicality of this may depend on whether a \nFinal Approach controller or dedicated Monitor controller is providing separation within and \nbetween IM PA pairs. Controller manual PA speed management must be balanced with the \npotential for undesirable frequency overrides and workload, which may make it highly \nchallenging to implement. With respect to the experiments secondary goal to evaluate the IM PA initiation task, controller \nparticipants on average agreed Final controllers: can acceptably initiate the IM PA operation; \ncan acceptably ensure separation during IM PA operations before transferring aircraft to the \nLocal controller given the appropriate training and tools; and were comfortable with the IM \nTrail Aircraft managing speed to achieve the spacing goal. However, concerns were raised \nregarding the phraseology, available CSL and WSL information at the time of initiation, and the \navailable time and airspace to perform the initiation task as simulated. Overall results suggest given the appropriate tools and training, the IM PA longitudinal and \nlateral separation monitoring and initiation tasks should be acceptable to controllers. In a \nrelated IM PA flight deck features evaluation performed in 2018, pilots also found IM PA to be \ngenerally acceptable, even after experiencing significant lateral deviations by the Lead Aircraft. \nThe current IM PA concept appears feasible and MITRE CAASD recommends the FAA continue \nits development. vi\n This study provided initial findings on the initiation and monitoring of an IM PA operation. The \nresults are intended to provide concept validation for the avionics standard development \nactivities and A-IM Concept of Operations, as well as specific recommendations for the FAA IM \nInitial Program Requirements document with respect to controller information needs and \nsupporting ground tools. These results and recommendations should be considered by RTCA SC-\n186, FAA SBS Program Office, FAA Aircraft Certification, and FAA Flight Standards as IM PA \nproceeds through concept maturation. vii\n Acknowledgments\nThis research was sponsored by the Federal Aviation Administration (FAA) Surveillance and \nBroadcast Services (SBS) Program Office (AJM-432). The authors wish to first thank Program \nManager David Gray, Chief Scientist Douglas Arbuckle, IM Project Lead Lesley Weitz, and \nSystems Engineering Lead Chris Daskalakis for their support and leadership. The authors also \nthank the following individuals who made important contributions to the simulation and report: The FAAs AJV-7 and NATCA organizations for reviewing the IM PA Tools, simulation plan, \nand scenarios before data collection. This included Tim Funari, Stephen Anderson, Daniel \nLittleford, Tom Zarick, and Chris Aymond.\nThe FAAs ANG-C22 organization, including Paul Strande and Mark Palmer, for \nsponsoring the development of the IM PA Tools evaluated. \nJames Bartel of the FAAs Air Traffic Organization and Jeff Minck of SBS for coordinating \nthe participant controllers.\nThe MITRE IM PA Subject Matter Experts for PA concept development, especially for that \nimplemented in the HITL, and for their document reviews. This included: Randy Bone for his work developing the IM Spacing List and data block indicators, o\ninputs to the simulation plan, and for leading the initial scenario testing with the FAA \nSEWG.\nDavid Domino for his extensive inputs to the simulation plan, leading the o\ndevelopment of the IM PA Monitoring Tools, and for his report review.\nSteve Hefley for NCT and SFO operations consulting, scenario development, report o\nreview, and for providing language for this report summarizing current-day CSPR \noperations.\nAndrew Mendolia for his simulation plan inputs, scenario development and testing, o\nand lab support during the conduct of data collection.\nAnand Mundra for general SME consulting, simulation plan and report review, o\nhelping to develop the HITL concept for monitoring for lateral deviations, and for \nproviding language for this report summarizing current-day CSPR operations.\nStephanie Priess for consulting on the IM PA safety limit design.o The Aviation Integration Demonstration and Experimentation for Aeronautics (IDEA) \nLaboratory staff for their development, integration, testing, and data collection / \nreduction efforts. Key contributors included Dylan Drake, Jason Giovannelli, Jacob \nRichkus, David Tuomey, and Russell Wenning.\nThe confederate controllers and pseudopilots and Suzette Porter of MITRE for \ncoordinating and scheduling them.\nKatherine Woods and Janet Harvey of MITRE for their help in preparing this document \nfor release. Thanks also to Katherine for helping to organize the data collection \nquestionnaires and transcribing the responses. And finally, thanks to the participant controllers for their time and valuable feedback, and to \ntheir facility management for making their participation possible. Table of Contents \n1 Introduction \n 4.2.2 IM Spacing List with IM PA Initiation Information \n 4.5.6.2 Day 1 Scenario Matrix (Participants 5-12) \n 5.4.1 Workload Acceptability \nand feasible to monitor IM PA operations with respect to both minimum \nand maximum separation limits \n 5.8.2 H2(RQ2): Given an appropriate tool set, controllers will find it acceptable \nand feasible to provide PA separation with respect to separation values that \nchange over the course of an approach \nto the CSL and WSL useful, but not minimum requirements \nTrail Aircraft begins to encroach on the limits will be useful to Monitor \ncontrollers \nExceedance Warning useful to alert them to IM Lead Aircraft and IM Trail \nAircraft lateral path deviations \nMonitor controller can effectively and acceptably provide separation for \nCSPR finals involving IM PA operations, including separation between \nsuccessive PA pairs \nuse of the Partial IM Clearance, acceptable \n Appendix A Abbreviations and Acronyms \n List of Figures \nFigure 1-1. Improved Spacing Consistency with IM \nMendolia (2018) \nMendolia (2018) \n Figure 4-14. Grey WSL-P \n21 Figure 4-30. UAL748 Crossing the Inboard Lateral Boundary \nMendolia (2018) \noperations \nmonitoring IM PA operations when both a CSL and WSL were active at the \nsame time \nachieve the desired spacing goal at the Final Approach Fix \n Figure 5-7. My overall level of traffic awareness today was acceptable with respect to \n[IM Lead Aircraft / IM Trail Aircraft / Other Aircraft] \nthe IM Trail Aircraft and their Lead Aircraft would be maintained \nOccurrence \nOccurrence \nthe Time of Occurrence \nthe Time of Occurrence \nof the JBU432 Caution Alert \nof the JBU432 Caution Alert \njust experienced \nspacing goal and the IM PA spacing goal communication was acceptable.5-\n31 Figure 5-24. I was comfortable with the use of the Lead Aircraft call sign in the IM \nClearance communication \ntheir speeds to achieve the spacing goal I assigned, while they were in my \narea \nbefore transferring aircraft to the Local controller and I was comfortable \nthat I was transferring appropriately separated aircraft to the Local \ncontroller \n Figure 5-27. CSL Caution Alert at Time of Initiation \nLead Aircraft, IM Trail Aircraft, and Other Aircraft were clear \nseparation issues were developing within an IM PA Aircraft Pair and \nBetween Other Combinations \ncan be effectively monitored by the number of positions I experienced \ntoday \nMonitor controller can effectively ensure separation across both \napproaches during IM PA operations \n(Combined) Monitor Controller can effectively ensure separation across \nboth approaches during IM PA operations \ncontroller monitored the other \nIM PA pair, while another controller monitored the other \nup to and including all aircraft pairs performing IM PA (100%) \njust experienced. (Nominal Scenarios) \ntraffic situation awareness \nachieve the spacing goal assigned by the Final controller \nmake a first assessment of their separation \nthe separation between the IM Trail Aircraft and its Lead, when they were \nmy responsibility \noverall IM PA monitoring task \n block is also helpful \nremain behind the CSL during the approach \nwould remain behind the CSL during the approach \noverall IM PA monitoring task \nthe WSL during the approach, when applicable \nactive WSL \nwhen an aircraft would require a WSL later in the approach \noverall IM PA monitoring task \nactive should the WSL Preview Line start to be displayed? \ndeveloping, vs. only being provided an alert when I have to take an action.5-\n71 Figure 5-57. The IM PA Predictive Alert and IM PA Caution Alert were useful for the \noverall IM PA monitoring task \ndetection of any impending exceedance of the WSL or CSL \nallowed for a timely detection of any spacing or separation issues \nan impending [Caution Alert / loss of separation] \nthe CSL / forward of the WSL] during the approach \nlike to see the Predictive and Caution Alerts? \nlike to see the Predictive and Caution Alerts? \nor WSL line] color change \n Figure 5-65. It was helpful to indicate the Caution Alert via the [Data Block Line 3 / CSL or \nWSL line] color change \nclear \nuseful for the overall IM PA monitoring task \n(Lateral Deviation Scenarios) \nbetween the IM Trail Aircraft and their Lead aircraft. (Lateral Deviation \nScenarios) \noperation were operating within their Lateral Boundaries \nmonitoring task \nhave been [helpful / essential] \nit without undue delay \nchoose and execute appropriate corrective action once the warning (red) \nalert occurred \nClearance completion task and the IM PA monitoring task \n List of Tables \nTable 2-1. IM PA Setup in
Metering and Non-Metering Environments \n40 Table 4-11. Week 3, Day 2 Scenario Run Order and IM PA Tool Variable Manipulations4-\n41 Table 4-12. Week 2-3 Alert Timing Values and Counterbalance Order \nOperations \nOwn Speed \nIM Trail and their Lead Aircraft \n16 Table 5-10. Between Pair Separation Violations (Weeks 2-3) \n Table 5-11. Controller Responses to Task Acceptability by Position \nPosition \n32 Table 5-17. 28R Final Controller Speed Control Responses \nScenarios) \n \nEffectively Ensure Separation Across Both Approaches \nEffectively Ensure Separation Across Both Approaches: IM PA Tool \nConfiguration \n \n Table 5-38. 28R Final Controller Responses to CSL Assessment \n \n \nResults \nHelpfulness \n83 Table 5-57. Controller Responses to Clarity of Responsibilities \nScenarios) \n \nNotice \n Table 5-65. Controller Responses to Salience of Exceedance Warning \n \nResults \nBoundary Exceedance Warning \nResults \n Introduction1\nThe Federal Aviation Administrations (FAA) Next Generation Air Transportation System \n(NextGen) leverages new technology and concepts to improve efficiency and enhance safety in \nthe National Airspace System (NAS). These include improvements in communication, navigation, \nand surveillance systems, such as the deployment of Automatic Dependent Surveillance-\nBroadcast (ADS-B), and expanded use of trajectory based operations (TBO), including time-\nbased aircraft spacing and scheduling. New traffic management concepts based on the \nconfluence of these technologies are intended to mitigate the potential for increased delays in \nthe NAS and projected airport capacity shortfalls. One such concept is Interval Management (IM) which refers to an application suite, enabled by \nAutomatic Dependent Surveillance-Broadcast (ADS-B), providing greater air traffic system \nthroughput and efficiency by improving inter-aircraft spacing precision. IM is a tactical capability \nused to manage spacing based on a separation standard, miles-in-trail restriction, or any air \ntraffic control (ATC) spacing objective. Or, as it relates to TBO, to the metering schedule. IM avionics (termed flight deck-based IM [FIM] Equipment) provide speed commands to the \nflight crew enabling them to manage a desired spacing relative to a Lead Aircraft. The closed-\nloop nature of IM allows for more accurate speed adjustments to achieve the desired spacing \nfor a given flight segment than can be provided by a ground system. As shown in Figure 1-1, this \nleads to improved inter-aircraft spacing precision and allows aircraft to be consistently spaced \ncloser to the separation standard or metering constraints, thus increasing throughput in \ncapacity-constrained airspace. IM is primarily being developed to increase arrival throughput at \nmetered airports; however, it is also expected to enable more efficient spacing during high \ntraffic periods at other facilities as well. Figure 1-1. Improved Spacing Consistency with IM An initial set of avionics standards supporting a limited set of IM operations were published by \nRTCA Special Committee (SC) 186 Working Group (WG) 4 in 2015 (RTCA, 2015). Three years \nlater, an FAA Systems Engineering Working Group (SEWG) developed an Advanced IM (A-IM) \nConcept of Operations (ConOps) for IM during arrivals and approaches, and en route and \nterminal merging operations (FAA, 2017b). In conjunction with that activity, RTCA SC-186 WG4 ii\n group is currently updating the Flight-deck Interval Management (FIM) Safety and Performance \nRequirements (SPR) (DO-328A) (RTCA, 2019a) and the FIM Minimum Operational Performance \nStandards (MOPS) (DO-361) (RTCA, 2019b) documents to enable the A-IM operations included \nin the ConOps. This includes enabling more complex route geometries, such as an IM and Lead \nAircraft arriving to parallel or crossing or converging dependent runway configurations. In \naddition, these updates improve the utility of IM operations through further integration with \ndata communications, leveraging air/ground trajectory synchronization, and better \nperformance from the use of higher fidelity wind data. There are many possible applications of IM with varying operational objectives, desired spacing \nbehavior, and operating environments. One of the advanced concepts supported by the new \nstandards and ConOps is IM Paired Approach (PA), which is intended for use on dependent \napproaches to Closely-Spaced Parallel Runways (CSPRs) (i.e., separated by less than 2,500 feet \n[ft]). IM PA provides a means for CSPR approach and landing operations to continue in weather \nconditions where visual separation cannot be maintained. IM PA maximizes arrival throughput \nin IMC by minimizing the in-trail spacing between successive arrivals without compromising \nsafety. For example, IM PA may be able to preserve two runway operations at San Francisco \nInternational Airport (SFO) to applicable Category (CAT) I minima for the approaches in use \nStassen, et al. (2013). The FAA, National Aeronautics and Space Administration (NASA), The MITRE Corporations \nCenter for Advanced Aviation System Development (CAASD), and others have been conducting \nresearch on PA as a separate ADS-B concept for over two decades. In 2016, RTCA SC-186 WG4 \ndecided to make PA an IM application and include it in the updated FIM Equipment \nrequirements. Through this process, stakeholders determined controllers must be able to \nmonitor the operation relative to a separation standard. This requires controllers to be able to \nassess separation within an IM PA pair and take effective action before separation is lost. \nTherefore, the IM PA concept was changed from that described in Stassen, et al. (2013), to \nmove the safety limit monitoring function was move from being a flight crew responsibility and \nFIM Equipment capability to a ground capability, likely to be hosted in Standard Terminal \nAutomation Replacement System (STARS). To validate the revised PA concept, the FAAs Surveillance Broadcast Services (SBS) Program \nOffice tasked MITRE CAASD to develop and execute a Human-In-The-Loop (HITL) simulation \nexperiment to address open controller acceptability and feasibility questions, provide input to \nair and ground system requirements, and mitigate technical risks associated with the revised PA \nconcept. This HITL simulation helped define the controllers role in IM PA and informed the \ndesign of new ground tools needed to enable the operation. These features were developed by \nMITRE CAASD for the FAAs Closely Spaced Parallel Operations (CSPO) Program Office in \ncoordination with SBS and the FAAs Operational Concepts, Validation, and Requirements office \nin 2017. The results and recommendations should be considered by RTCA SC-186, FAA SBS \nProgram Office, FAA Aircraft Certification, and FAA Flight Standards as IM PA proceeds through \nconcept development. This document presents the findings of the simulation and has seven main sections including \nthis one. Section 2 Background, Concept Description, and Prior Research provides an overview \nof CSPR arrival operations, the IM PA concept, and summarizes relevant past work. Section \n3Research Goals, Questions, and Hypotheses presents the main research questions and iii\n hypotheses for this study. Section 4Experiment Methodology describes how the simulation \nwas conducted. Section 5Results summarizes the results of the data collection, including the \nstatistical analyses. Section 6Discussion reviews the major findings and puts them in an \noperational context. Section 7Conclusions and Recommendations reviews the key findings and \nprovides recommendations for continued IM PA development and future research. 2 i\n 1 Except for the 7110.308C operation, which is described later, and which does not quite fill the throughput gap. \n2 At SFO, the two runway visual operations rate is 54, and the single runway rate is 32. However, SFO can also use 7110.308C which allows them to use staggered approaches down to Cat I minima, with a rate between 34 and 36. \n3 At SFO, to facilitate departures, arrival aircraft may be paired (i.e., they are side-by or nearly so) so that arrivals may cross Background, Concept Description, and Prior Research3\nThis section provides an overview of the CSPR operational environment, describes the IM PA \nconcept including its potential implementation at SFO, and summarizes past PA and IM research \nthat is relevant to this study. Closely Spaced Parallel Runway Arrival Operations 3.1\nParallel runways spaced closer than 2500 ft are defined as closely spaced parallel runways \n(CSPRs). Current separation minima require that such runways be treated as one for arrivals and \ndepartures, unless other types of separation (e.g. visual or 7110.308C) are used in place of \nstandard radar separation. To maximize throughput for CSPRs, facilities employ simultaneous \nvisual approaches whenever possible. During simultaneous visual approach operations to CSPRs, \nmaximum arrival throughput relies on the use of pilot-provided visual separation between two \narrival aircraft. This effectively allows two streams of traffic to the CSPRs. However if aircraft \ncannot provide its own visual separation relative to a lead aircraft on the CSPR, one of the \naircraft is broken out of the flow. This results in a single runway operation1 and loss of \nthroughput. As described in FAA (2017a), the application of visual separation is relatively straightforward in \ngood Visual Meteorological Conditions (VMC) when conditions exceed visual approach minima. \nVisual approach minima are required to be at least MVA+500, where the MVA is the Minimum \nVectoring altitude. In actual operations, the minima to which Terminal Radar Approach Controls \n(TRACONs) will conduct visual approaches vary greatly from airport to airport, depending on the \nairspace and the airport operations. At SFO, for example, visual operations can be conducted \nwith relative ease for ceilings and visibilities exceeding 5000 ft and 10 miles. However, pilot-\napplied visual separation is more difficult in Marginal Meteorological Conditions (MMC). At SFO, \nfor example, these consist of a ceiling of ~4000 ft and 5-7 miles visibility. Pilot-applied visual separation is impossible in IMC with ceiling and visibility less than 1000 ft \nand 3 miles, respectively. When
simultaneous visual approaches to the CSPRs cannot be \nconducted, the airport operations change from a two-runway operation to a single runway \noperation, with a consequent significant loss of throughput2. To regain some of this lost \nthroughput, reduced separation standards and procedures have been developed for airports \nwith CSPRs in MMC and IMC operations. The following describes the various available CSPR \noperations in each type of meteorological condition. Good VMC. Side-by visual approaches at CSPR airports can be conducted down to visual \napproach minima. Controllers vector aircraft, or procedures are developed, to deliver aircraft to \ntheir respective final approach courses separated with 1000 ft vertical or 3 nautical miles (NM) \nlateral separation. When the trail aircraft can provide and maintain visual separation with the \nparallel traffic, vertical or lateral separation is discontinued and each aircraft is cleared for an \napproach3. Any weight class (excluding Super) may be the lead of a pair; the only requirement is \na Heavy/Boeing 757 (B757) may not pass any other aircraft once inside the Final Approach Fix ii\n the runway thresholds within 0 0.25 NM of each other. (FAF). Also, a large weight class aircraft may not pass a small weight class aircraft. MMC. When cloud layers or other visual obscurations keep aircraft from sighting each other \nbelow visual approach minima, Simultaneous Offset Instrument Approaches (SOIA) procedures \ncan be used to reduce separation between parallel arrivals to CSPRs (FAA, 2018c). SOIA \nprocedures are instrument approaches with a visual segment after the FAF. The visual segment \nis designed for the trail aircraft of a pair to sight and provide pilot-applied visual separation \nrelative to a lead aircraft. Sufficient ceiling and visibility are required to allow visual acquisition \nto occur, which are typically low VMC minima. SOIA normally uses a straight-in ILS approach for the lead runway and an offset localizer or Area \nNavigation (RNAV) approach for the trail runway, as shown in Figure 2-1 reproduced from FAA \n(2018c). Shortly before the runway, the trailing aircraft turns to join the final and visual \nseparation is then established for the remainder of the approach. If visual contact has not been \nmade by the turn point, the trailing aircraft must execute a missed approach procedure. As with \nthe good VMC operation, any weight class other than a Super may lead a SOIA pair, and there is \nno passing inside the FAF. Aircraft are delivered to their respective final approach courses \nseparated 1000 ft vertically or 3 NM laterally. Once both aircraft are established on their \nrespective final approach courses, they are cleared for the approach and vertical separation is \ndiscontinued. Figure 2-1. SOIA Concept from FAA (2018c) Due to the relatively short distance between the final approach courses, SOIA operations \nrequire a 2000 ft wide No-Transgression Zone (NTZ) between them. Monitor controllers use Image: FAA Order 8260.3D iii\n 4 The airports are: BOS, CLE, EWR, MEM, PHL, SEA, SFO, and STL. They are in regular use at SFO, though their use at the other \nairports is not as prevalent. Precision Runway Monitors (PRMs) or Final Monitor Aid (FMA) to monitor aircraft position \nrelative to the NTZ, and must use an override frequency for communications. If an aircraft \ndeviates from its final approach course toward the NTZ, the controller must advise the flight \ncrew that they are off course and to return to the final approach course. If the aircraft does not \ncomply and enters the NTZ, the other aircraft of the pair is issued a traffic alert and is vectored \naway from the deviating aircraft. In the event of such a time-critical PRM breakout instruction, \nthe Monitor controller overrides the Final controller on the PRM frequency. Therefore, these \noperations require flight crews to tune their radios to both the final approach frequency and a \nsecond monitor frequency. IMC. When weather conditions do not allow visual separation or SOIA procedures between \narrivals on CSPRs, aircraft must land single-file to one runway or they may be staggered to each \nof the parallel runways. While both runways are used in this configuration (by alternating arrival \nrunways, for example), the resulting arrival throughput is effectively the same as if operating to \na single runway. However, FAA Order 7110.308C allows for reduced diagonal separation on the \nparallel final approach course if certain weather and weight restrictions are met (FAA, 2018b). For the 7110.308C procedure, as with the VMC and MMC procedures, aircraft are delivered to \ntheir respective final approach courses separated by the standard 1000 ft or 3 NM. Once \nestablished on their respective courses, each aircraft is cleared for an approach and standard \nlateral and vertical separation are discontinued. The diagonal separation for this dependent pair \ncan be as low as 1 NM at certain airports. Standard radar or wake turbulence separation must \nbe provided to the next aircraft to follow a dependent pair. These approaches may be \nconducted down to CAT I minima; however, a Super, Heavy, or B757 may not lead a dependent \npair. No Monitor controllers are required for these dependent approaches. Though helpful, the 7110.308C and SOIA procedures have restrictions that limit how often they \ncan be used and how close the aircraft can get from each other. The 7110.308C operation is \ncurrently only available at eight airports4 in the NAS, the leading aircraft must be a large or small \nweight category, and the closest possible intra-pair diagonal spacing is 1 NM. The SOIA \noperation requires specialized ground equipment, NTZ monitoring, an offset approach, special \nflight crew training, and a visual segment during the final portion of the approach. The visual \nmaneuver with SOIA involves first a bank towards the parallel final, followed by a bank away \nfrom the parallel final. During this time, aircraft structure can interfere with the flight crews \nability to maintain visual contact with the aircraft on the parallel final. SOIA is currently only \navailable for SFO and Cleveland-Hopkins International Airport (CLE). At SFO, it is authorized for \nuse down to a ceilings and visibility of 1400 ft and 4 miles. However, the SOIA procedure at SFO \nhas been replaced with 7110.308C procedures, which are more predictable, deliver about the \nsame aircraft arrival rate, and requires fewer controllers and less specialized equipment. SFO is \nable to attain an arrival rate of 36 with 7110.308C, which is still a considerable decrement from \nits rate of 54 for visual operations. The IM PA operation is intended to help close this gap. Concept Overview3.2\nPA is one of several applications of IM. This section first summarizes the general concept of IM. \nThen, the specifics of the IM PA application are discussed in greater detail. iv\n Interval Management3.2.1\nIM is intended to enable an increase in the reliability and accuracy of the spacing interval \nbetween an IM Aircraft and its Target Aircraft than is possible from a ground system alone. A \nmore accurate and reliable spacing interval can support a decrease in spacing buffers, which in \nturn increases throughput during high-demand arrival operations (Bone & Mendolia, 2018). \nOther advantages include increased predictability of the overall arrival flow, which should \nincrease the number of aircraft that remain on their RNAV arrival procedures. This also reduces \nthe number of speed assignments needed to manage the arrivals, thereby reducing \ncommunications and workload. An overview and history of IM is available in Barmore, et al. \n(2016). As described in Penhallegon & Stassen (2018), a general IM operation involves an air traffic \ncontroller, assisted by automation as needed, clearing an IM-capable aircraft to manage a \ndesired time or distance-based spacing interval (termed Assigned Spacing Goal), relative to a \nspecified Target Aircraft. Two types of spacing goal behavior have been defined by RTCA \n(2019b). The first, termed Achieve, has the IM Aircraft achieve the Assigned Spacing Goal by a \ndesired location, termed the Achieve-by Point (ABP), within 10 seconds (sec) across 95% of IM \nAchieve operations. The second behavior, termed Maintain, has the IM Aircraft manage its \nspeed to stay within +/- 10 sec of the Assigned Spacing Goal for at least 95% of the operation on \na specified route segment. When the flight crew receives the IM Clearance, they enter its information into their on-board \nFlight-deck IM avionics (termed FIM Equipment), which then starts providing speed guidance \n(termed IM Speeds) to help them achieve and/or maintain the desired spacing. The flight crew \nthen follows the IM Speeds until the IM operation is terminated either by a controller or at \nspecified location, termed the Planned Termination Point (PTP). An IM operation begins immediately after a controller provides all the IM Clearance information \nat once and the flight crew accepts. Alternatively, a controller may issue a Partial IM Clearance. \nA Partial IM Clearance contains all required IM Clearance information except the Assigned \nSpacing Goal. This allows a flight crew to prepare the FIM Equipment before IM is intended to \nbegin. For terminal IM operations, this should allow an en-route controller to transmit IM \ninformation using Controller Pilot Data Link Communications (CPDLC) possibly during a less busy \nphase of flight for the flight crew. Then, at the desired start of
the IM operation, a terminal \ncontroller provides the Assigned Spacing Goal over voice. Flight crew acceptance of this second \nmessage constitutes acceptance of the IM Clearance and IM begins. A Partial IM Clearance can \nbe provided to an IM Aircraft already executing an IM operation; however, only a single Partial \nIM Clearance can be accommodated by the FIM Equipment at a time (RTCA, 2019a). Introducing a relative spacing task to the flight deck will require additional training for both \ncontrollers and flight crews. Though IM operations will not change the separation \nresponsibilities of ATC, they are intended to be used in the context of a variety of types of \noperations, governed by a variety of separation standards. In most cases, the increased spacing \naccuracy IM provides enables a reduction in the buffers added to the applicable separation \nstandard. IM can also reduce buffers and increase accuracy when the spacing objective exceeds \nthe separation requirement, such as when spacing between successive arrivals is increased to \nallow for departures in the intervening time. v\n IM Paired Approach3.2.2\nThe IM PA application provides a means for CSPR approach and landing operations to continue \nin weather conditions where visual separation cannot be maintained. IM PA maximizes arrival \nthroughput in IMC by minimizing the in-trail spacing between successive arrivals without \ncompromising safety. The concept combines beneficial aspects of both 7110.308C and SOIA \noperations, while mitigating some of their restrictions. In its fully developed state, IM PA \noperations are envisioned to be available in weather conditions down to the applicable CAT I \nminima for the approaches used. The ability to support operations independent of wake \ncategory and/or crosswind components along the approach is still being determined. Benefits \nand feasibility analyses performed by the FAA, MITRE, and other stakeholders suggest IM PA is \nlikely to result in significant throughput increases and reduced delays, especially during IMC \nStassen, et al. (2013), (Penhallegon, Stassen, Elliott, & Gryphon, 2016), (FAA, 2018a). In addition, \nground delay programs and airspace flow programs can be modified to ensure an appropriate \nflow of additional aircraft is available to increase throughput at the terminal facility conducting \nIM PA operations (FAA, 2017b). Airports that may benefit from IM PA include: Boston, \nCleveland, Newark, Chicago Midway, Philadelphia, San Francisco, and San Jose (Mendolia, et al., \n2016). An IM PA aircraft pair consists of an IM Lead Aircraft, equipped with ADS-B Out avionics, and an \nIM Trail Aircraft equipped with ADS-B In FIM Equipment. A Collision Safety Limit (CSL) is defined \nbetween the two aircraft such that the risk of collision is less than 10-9 in the case that either \naircraft deviates laterally from its approach path into the adjacent path. As shown in Figure 2-2, \nthe CSL ensures the aircraft do not collide in the event of a flight path deviation by providing \nenough spacing so the deviating aircraft can pass through the other aircrafts approach path. A \nWake Safety Limit (WSL) defines the risk the Trail Aircraft encounters the wake vortices from \nthe Lead Aircraft at a rate no worse than current operations. It ensures the IM Trail Aircraft \nremains close enough longitudinally so the IM Lead Aircrafts wake turbulence passes behind \nthe trail aircraft. These safety limits provide the time needed for controllers to detect and \nmitigate potential exceedances before they occur. All IM PA operations require a CSL; however, \nthe need for a WSL is based on aircraft weight category and crosswind conditions. Figure 2-2. IM PA Safety Limits The IM Trail Aircraft is protected from collision by the CSL in case of an inboard lateral deviation \nby the IM Lead Aircraft as shown in Figure 2-3. Additionally, by staying forward of the WSL, it is \nprotected from the IM Lead Aircrafts wake even under unfavorable crosswind conditions. vi\n Figure 2-3. IM Trail Aircraft between WSL and CSL In the IM PA procedure, the Assigned Spacing Goal is designed to keep the IM Trail Aircraft \ninside the safety limits for the entire flight to the runway threshold. IM PA begins when a \nterminal controller clears an IM Trail Aircraft to pair behind an IM Lead Aircraft, and to capture \nand maintain a desired Assigned Spacing Goal by flying the IM Speeds generated by the FIM \nEquipment. This continues until the PTP which in most cases is expected to be collocated with \nthe FAF. After this point, the IM Speed guidance is terminated, and the IM Trail Aircraft begins \nconfiguring to its final approach speed. The Assigned Spacing Goal therefore represents the \ndesired spacing between the two aircraft at the PTP and is a function of a variety of factors. \nThese include the approach geometry and the difference in IM Trail Aircraft and IM Lead \nAircraft predicted flight times between the PTP and the runway threshold, which is largely a \nfunction of the difference in landing speeds. The IM PA operation depends on the ability of ground automation to compute an Assigned \nSpacing Goal that keeps the IM Aircraft within the safety limits, with time for controllers to \nrespond to any developing encroachment of the CSL and WSL. Separation will need to be \nensured by the controller until the IM Lead Aircraft crosses its runway threshold; therefore, the \nAssigned Spacing Goal must be attainable before termination of speed guidance at the PTP and \nstill allow for the compression or expansion that may occur during the final phase of the \napproach. As described in the FAA A-IM ConOps (FAA, 2017b), the CSL and WSL are airport-specific and will \nchange over the course of a typical IM PA operation. The notional example in Figure 2-4 \nillustrates how the CSL (lower, red line) moves closer to the IM Lead Aircraft on a six-mile final in \nthe vicinity of the FAF and the PTP. Therefore, to increase throughput by reducing the spacing \ninterval at the runway threshold, some amount of compression is desirable after the PTP. This vii\n suggests that whenever possible, controllers and/or ground automation should select the \naircraft with the higher landing speed as the IM Aircraft in an IM PA operation. Figure 2-4. Notional IM PA Example Safety Limits In some cases, it may be operationally desirable to allow the faster aircraft to lead in an IM PA \noperation, such as when the effort associated with exchanging the lead and trail positions on \nthe approach leads to a greater loss of throughput than the expansion that would otherwise \noccur after the PTP. However, the amount of expansion that can be tolerated is limited by the \nWSL (if required, the upper, blue line in Figure 2-4). For the geometry shown in the figure, \nanything more than a small amount of expansion would lead to exceedance of the WSL on short \nfinal. Therefore, the ability of the IM PA operation to tolerate a faster leading aircraft depends \non the runway spacing, winds, and WSL. PA Separation3.2.3\nIM PA will require a new dependent parallel runway separation standard. Though the FAA has \nnot yet begun to define this standard, it will likely be based on allowable CSL and WSL values as \nimplemented at specific airports. In order to define an IM performance requirement for PA, \nsafety limit values at various facilities with CSPR, including SFO, are being considered by RTCA SC-\n186, WG4, based on FAA Flight Standards (AFS) analyses (Williams & Wood, 2017) and empirical \nwake data provided by Volpe (unpublished). These safety limits were designed to accommodate \nsome amount of normal aircraft crosstrack error from the approach path centerline. However, \nlateral deviations beyond the design limits (e.g. blunders) may result in the CSL and WSL no \nlonger being adequate to ensure the required level of safety. Therefore, to indicate to \ncontrollers when lateral deviations exceed the CSL and WSL design error assumptions, inboard \nand outboard lateral boundaries for each aircraft in an IM PA pairing could be part of the \nseparation standard. As described further in Section 4.2.1, the PA separation standard assumed for the HITL \nexperiment that is the subject of this paper was informed by SC-186 WG4 safety limit \ncalculations for SFO (Williams & Wood, 2017). The HITL further assumes that controllers will not WSL CSL viii\n be required to detect lateral deviations and break out an IM Trail Aircraft for collision protection \nbefore one aircraft in an IM PA crosses the path of the other. However, they will need to be \ninformed as to when an aircrafts crosstrack error may result in the CSL and WSL no longer \nproviding the required protection from collision or wake risk. Research in this area is still on-\ngoing, especially with respect to air versus ground deviation detection and appropriate response \nprocedures. Many unknowns remain with respect to what will be required for PA separation \nand therefore the limits, assumptions, and procedures used in this HITL may not ultimately \nmatch the FAAs final PA separation standard design. In addition, a full IM PA operation may not necessarily need to be implemented all at once. \nSome consideration has been given to a potential evolutionary approach which supports \nbuilding experience with more benign operations
before progressing to more challenging \nimplementations. For example, initial implementations that limit allowable wake category \npairings and operate to higher approach weather minima could be considered in advance of a \nPA-specific separation standard being finalized (Bateman, et al., 2017). IM PA separation and \nimplementation may not be fully understood until after the completion of a full safety process, \nseparation standard design, and determination of facility-specific adaption parameters. IM PA Setup3.2.4\nThe IM PA procedure is contained within the terminal area and can only be executed once both \naircraft are established on their final approach courses. IM PA would function equally well \nwithin metered and non-metered flows. The two domains differ mainly in the way aircraft are \ndelivered to the approach and their initial spacing controlled to ensure success. These \ndifferences are shown in Table 2-1. Table 2-1. IM PA Setup in Metering and Non-Metering Environments Metering Environment Non-Metering Environment Flight Paths Continuous RNAV routes Vectors and/or RNAV routes Identification of pair, \nASG* & IM Clearance(s) Time-Based Flow \nManagement (TBFM) (possibly 2 IM operations) Coordinator controller\n(aided by automation) Initial Aircraft Delivery Aided by IM or Terminal Sequencing and Spacing \n(TSAS) Vectors and/or speed \nassignments Start of PA operation Once both aircraft are established on final\n*Assigned Spacing Goal In a TBFM environment, en route and terminal time-based metering automation can provide \nspeed guidance to controllers to position the aircraft pair with a suitable starting interval at the \nstart of the IM PA operation. Or, when available, IM PA can be set up by another IM operation \nthat is initiated en route. This other IM operation delivers the IM PA pair to their final approach \nsegments in position to transition to an IM PA procedure. A scenario that illustrates both cases \nis summarized in Penhallegon & Stassen (2018). ix\n 5 Several of the figures in this section are adapted from Mendolia, et al. (2016). When metering is not available, controllers must manually set up a tactical IM PA operation, \npossibly with the support of unique IM PA tools. this involves the identification of aircraft pairs, \nAssigned Spacing Goals, and establishing the aircraft on their final approaches with the \nappropriate initial spacing as described in Stassen, et al. (2013) and FAA (2017b). ATC HITL \nresearch involving controllers from Northern California TRACON (NCT) suggests this is feasible \n(Domino, Tuomey, Stassen, & Mundra, 2014), though somewhat challenging if a 15 NM or \nlonger final is an absolute minimum requirement (Mendolia, et al., 2016). General setup conditions and procedures for either the metering or non-metering (tactical) case \nare not further described in this paper as they are not directly relevant to the findings. \nHowever, potential concepts for setting up IM PA for SFO arrival operations are described in \nSection 2.3.3. Planned Final Approach Speed3.2.5\nIn any arrival and approach operation, it is important to understand the speed profile of \nsuccessive arrivals late in the approach to maximize buffer reduction. As described in Stassen, \nPriess, & Weitz (2016), factors such as final approach speed have a bearing on the evolution of \nthe spacing interval late in the approach. Because of this, the PA concept has traditionally \nassumed the need for Planned Final Approach Speed (PFAS) as input to the spacing goal \ncalculation Stassen, et al. (2013). One implication is that if the relative difference in PFAS \nbetween the IM Trail Aircraft and IM Lead Aircraft changes beyond a certain threshold, the \nAssigned Spacing Goal may need to be recalculated and sent to the IM Trail Aircraft. It is not \nknown if it will be necessary to consider changes in PFAS in real time once the aircraft have \nbeen cleared for their approaches. It may ultimately be decided to allow the aircraft to be \nbroken out only if it appears that either the CSL and WSL will be exceeded. The requirements for providing PFAS and managing revisions are still being determined. Due to \nthe lack of definition around the alternatives and trade space, the research scope for this study \ndid not include an examination of the human factors issues associated with relative PFAS \nchanges and Assigned Spacing Goal updates. Application of IM PA to NCT and SFO Operations3.3\nImplementation of the IM PA procedure is highly dependent on the facility and operational \nenvironment. As this HITL simulation examined an IM PA operation at NCT/SFO, this section \nprovides an overview of the relevant airspace, then summarizes how IM PA operations could \npossibly be incorporated into NCT and SFO arrival operations in both metering and non-\nmetering environments. NCT/SFO Airspace Overview3.3.1\nAs shown in Figure 2-55, NCT manages three main flows into SFO airspace, worked by a variety \nof positions. The DYAMD flow is worked by the Cedar High Feeder, Niles Low Feeder and Foster \nFinal. The SERFR flow is worked by the Laguna High Feeder, Boulder Low Feeder and Woodside \nFinal, and the BDEGA flow is worked by the Boulder Low Feeder and Woodside Low Final \n(landing Runway 28L) or Foster Final (landing Runway 28R). The approximate balance of traffic x\n on these three routes is 50 percent on DYAMD, 25 percent on SERFR, and 25 percent on BDEGA. A \nsmall number of satellite airport operations (Oakland, San Carlos, San Jose) and tailored oceanic \narrivals (PIRAT) occur in the airspace. In addition, vectoring airspace floors are established to \naccommodate Moffet Federal Airfield operations. Figure 2-5. SFO Traffic Flows and ATC Positions The SFO arrival and departure sectors are depicted in Figure 2-6. Four arrival positions normally \nmanage the inbound flows to SFO. The low altitude arrival positions are NILES and BOULDER \nand the high-altitude positions are CEDAR and LAGUNA. All breakouts are handed off to the \ndeparture sector SUTRO. xi\n Figure 2-6. NCT/SFO Arrival and Departure Sectors The two Final Approach sectors, FOSTER and WOODSIDE, are shown in Figure 2-7. Figure 2-7. NCT/SFO Final Approach Sectors IM PA Monitoring at NCT/SFO3.3.2\nRequirements for separation monitoring and controller roles and responsibilities for IM PA at \nNCT and SFO must be generally compatible with the facilitys arrival operation and equipment \ncapabilities. Due to its dual intersecting runway configuration shown in Figure 2-8, SFO currently \nemploys a single Local controller (plus a radar assist) to manage arrivals and departures on the \n28 Left (L)/28R runways and 1L/1R runways. During SOIA operations, FAA Order 7110.65X \nrequires separate monitor controllers, each with transmit / receive and override capability for \ntheir assigned runway on the local control frequency (FAA, 2017a). In the case of SFO and NCT, a \nwaiver was granted to allow the monitoring of SOIA arrivals at NCT on Woodsides and Fosters \nfrequencies which eliminates the possibility of the monitors blocking critical transmissions on \nSFO Local frequency. This is possible at SFO because SOIA procedures allow for separate \nleft/right (L/R) Final Approach controllers to work the finals until the aircraft are 3.3 mile from \nthe runway. Only then are they handed off to the Local controller. The trailing aircraft then \nnavigates visually for the last portion of the approach. At this point, the aircraft no longer \nrequire monitoring and are transferred to the single Local controller. xii\n Figure 2-8. SFO Airport Map IM PA is intended for operations in IMC and does not require the use of visual separation during \nthe final portion of the approach. Implementing separate L/R Monitor controllers, as would be \nrequired by current 7110.65X rules, may not be practical or feasible at SFO since that would also \nrequire separate Local controllers and frequencies, one for each arrival runway. This could \nintroduce significant coordination challenges managing the airports four runway intersections \nand runway crossings for arrival aircraft. However, past research results suggest that similar to \nSOIA, dedicated Monitor controllers would be the preferred implementation at NCT/SFO to \nprovide IM PA separation (Mendolia, et al., 2016). Due to the challenges this would introduce at \nfacilities such as SFO, the feasibility and acceptability for a single monitor controller to provide \nIM PA separation needed to be examined. Lateral Deviations3.3.2.1\nThe SFO monitor display consists of a PRM display with 4:1 lateral expansion and 1 second \nupdate, an NTZ region that aircraft are not allowed to penetrate, and NTZ alerting that indicates \nif one does penetrate or is predicated to penetrate the NTZ located between the two runways. \nThe NTZ for SOIA requires straight-in approaches until the visual segment (FAA, 2017a). The \nSOIA monitoring task requires that controllers take action if an aircraft enters the NTZ region. At \nSFO the NTZ consists of a rectangle that is 2000 ft wide, beginning at the point where vertical xiii\n 6 The offset is also required to overcome navigation overlap and to enable the design of the IM PA safety limits. separation would be lost, and ending approximately 3.3 NM from the runways. At that point the \ndistance between the respective approach courses is the required 3000 ft, which provides a 500 \nft buffer to the end of the NTZ. After this point, monitoring ends as the aircraft transition to \nvisual separation approximately 3.3 NM from the runway for the Lead and 3.4 NM from the \nrunway for the Trail. An IM PA RNAV
approach path to SFO Runway 28R will likely involve a 3 degree angled offset to \nreduce the risk of a wake encounter6. The offset also permits increasing the space between the \nIM PA safety limits. As shown in Figure 2-9, the existing SOIA NTZ cannot be directly applied to \nthe IM PA operation, because the RNAV PA 28R approach path would pass through it. The \nlateral deviation monitoring task for IM PA and supporting display features implemented for the \nHITL experiment are described in Section 4.2.8. Figure 2-9. SFO 28R IM PA Approach Path Penetrates SOIA NTZ Automated Terminal Proximity Alert3.3.2.2\nAutomated Terminal Proximity Alert (ATPA) Phase 1 functionality is available at NCT and would \nalso be available during IM PA operations. ATPA Phase 1 alert timing served as the basis for the \ndevelopment of the IM PA monitoring tools and is summarized here for background. The ATPA becomes active in a facility-specified zone along the final, approximately 10 to 12 NM \nfrom touchdown. When an aircraft enters the zone and meets ATPA eligibility criteria, ATPA \nbegins monitoring proximity with the aircraft ahead and tracks closure rates to alert the \ncontroller if a separation violation is predicted to occur. Controllers may toggle the display of a \ncone ahead of the aircraft which indicates the minimum authorized separation (Figure 2-10). \nUnder nominal conditions (no alerts), the cone is blue and radiating outward from a trailing \naircraft with separation limits displayed. In addition, the distance to lead is displayed in the data \nblock. The cone and the data block distance both turn amber (warning state) when a \nseparation violation is predicted to occur in 45 seconds. The cone and data block distance turn \norange (alert state) if a violation is predicted to occur in 24 seconds. xiv\n Figure 2-10. ATPA Symbology from Bone and Mendolia (2018) ATPA is an important tool at NCT for monitoring separation along final. However, the use of \nATPA with IM PA, and integration of display features and potential alerting has not been \nconsidered. Therefore, to avoid a potential confound from tools that may not be well \nintegrated, the HITL did not include ATPA functionality. However, the IM PA alerting is based on \nthe ATPA alert construct, as described in Section 4.2.7. NCT/SFO IM PA Monitoring Summary for the HITL 3.3.2.3\nThe HITL design team made the following eight assumptions with respect to the implementation \nof the IM PA operation in NCT/SFO airspace. More detail for each can be found in the \nreferenced sections. The 28R Final controller will initiate IM PA once the Trail Aircraft is established on final, 1.\nand then transfer it to the Local controller at approximately 15 to 20 NM (see Section \n4.4.1). IM PA separation responsibility within an IM Trail Aircraft and IM Lead Aircraft will rest 2.\nwith a Monitor controller, who will monitor all arrival aircraft on their respective Local \ncontrollers frequency. Monitoring will be required until the IM Lead Aircraft crosses its \nrunway threshold. This also avoids flight crews being required to make a frequency \nchange from final to local (i.e., Tower) during the mid or late stages of the operation (see \nSection 4.4.3.3). The Monitor controller will also provide the appropriate separation between the aircraft 3.\npairs (see Section 4.4.3.3). Collision protection is assured by taking action if the IM Trail Aircraft is expected to 4.\nviolate the CSL (see Section 2.2.2). In the event of a lateral flight path deviation by the IM Lead Aircraft, controllers are not 5.\nrequired to break out the IM Trail Aircraft before the IM Lead Aircraft crosses its path \n(see Section 4.4.3.2). Monitor controllers will be required to provide separation in the event of a lateral 6.\ndeviation by any aircraft in their airspace (see Section 4.2.8). The HITL will evaluate the IM PA monitoring task against both Combined 28R/L and 7.\nSeparate Monitor controller configurations (see Section 4.4.3.3). The HITL will not include ATPA functionality; however, IM PA alerting was based on the 8. Figure reprinted \nfrom: Bone and \nMendolia (2018) xv\n ATPA alert construct (see Section 4.2.7). IM PA Setup at NCT/SFO 3.3.3\nBased on FAA (2017b), this section summarizes the overall setup and chronology for how an IM \nPA operation could be scheduled and initiated at NCT/SFO, in both terminal (tactical) and en \nroute (metering) environments. Chronology and details for the IM PA setup specifically assumed \nfor the HITL are described in Section 4.3.1. Tactical Setup3.3.3.1\nTactical IM PA operations are designed to be planned and executed entirely within terminal \nairspace. RNAV routes connecting to the instrument approach procedure to be used may or \nmay not be available. In the case of NCT/SFO, the assumption has been that a continuous RNAV \npath would be available for arrivals to runway 28R (the IM Trail Aircraft) and that vectoring \nwould be used to deliver the IM Lead Aircraft to 28L. A scenario for a generic tactical IM PA operation is detailed in FAA (2017b). Based on that and a \nscenario for a tactical operation from the earlier IM PA concept detailed in Stassen, et al. (2013), \na possible chronology of events for a tactical IM PA operation at SFO could be as follows. First, \nthe candidate IM Trail Aircraft and IM Lead Aircraft check in on frequency with their respective \nFeeder Controllers and both aircraft report PFAS. Each Feeder Controller annotates the \nreported speed in the secondary scratchpad. A Coordinator Controller observes the speeds, \ncompares flying miles to the runway, and evaluates the speeds for compatibility. If the aircraft \npair is suitable for an IM PA operation, the Coordinator Controller uses automation or another \nmethod to compute an Assigned Spacing Goal and then populates the IM Spacing List. The \nCoordinator Controller then coordinates with the Feeder and Final controllers to ensure that the \npairings are acceptable. The Feeder Controllers inform the candidate IM Trail Aircraft of the planned IM PA operation, \nproviding the IM Clearance Type (IM PA) and IM Lead Aircraft Flight Identification. They do not \nyet provide the Assigned Spacing Goal. The flight crew of the IM Trail Aircraft initializes the FIM \nEquipment entering the information they have been provided. The Feeder Controllers provide \nspeed assignments and vectors as necessary to deliver the aircraft to the Final controllers such \nthat their spacing targets can be achieved. The Woodside (Final Approach) Controller vectors \nthe IM Lead Aircraft in front of the IM Trail Aircraft, targeting an in-trail spacing between 1 and \n2 NM. The Foster (Final Approach) Controller provides the IM Trail Aircraft its Assigned Spacing \nGoal once both aircraft are established on the final approach course, which initiates the IM PA \noperation. The flight crew of the IM Trail Aircraft enters the Assigned Spacing Goal into the FIM \nEquipment and begins following the IM Speeds. The Final Approach controllers clear the aircraft \nfor their approaches and instruct the aircraft to change to the Local controller frequency. \nMonitor controllers monitor separation with respect to the CSL and WSL (if applicable) until the \nIM Lead Aircraft crosses its runway threshold. For tactical IM PA operations, terminal automation may be required to: 1) Identify candidate IM \nTrail and IM Lead Aircraft (possibly through filed flight plans); 2) Calculate an Assigned Spacing \nGoal based on PFAS inputs; 3) Display IM PA information to Final and Monitor controllers; 4) \nAccept controller inputs indicating initiation and termination of the IM PA operation. xvi\n Metering Setup3.3.3.2\nWhen IM PA is conducted in a metering environment, the aircraft are likely to be scheduled for \nan IM PA operation while still in en route airspace. TBFM is expected to identify suitable aircraft \npairs and, optionally, define an IM operation that precedes the IM PA operation to ensure that \nthe aircraft are delivered to the final approach course with suitable spacing. The required IM \ninformation is then forwarded to the terminal controllers displays (e.g., STARS), as appropriate. \nA scenario for an IM PA operation in a metering environment is detailed in FAA (2017b). That \nscenario suggests a chronology of events associated with IM PA in a metering environment at \nSFO which includes both IM operations and is summarized below. First, all aircraft landing at SFO report PFAS at an appropriate point in en route airspace. This \nmay be accomplished using some form of digital communications (e.g., CPDLC), or other means. \nTBFM captures the PFAS information, assesses the traffic flow, identifies aircraft pairs for IM PA \noperations, and builds a runway schedule based on IM PA capability. TBFM then creates two IM \nClearances: (1) an Achieve-by then Maintain clearance that ends when the aircraft arrive on the \nfinal approach course, and (2) a Pair (PA) IM Clearance that begins when the first clearance is \nplanned to end. (Alternatively, the Achieve-by then Maintain Clearance could be amended to a \nPair Clearance by a terminal controller at the appropriate time.) TBFM proposes both IM clearances to the en route controller, who evaluates and accepts the \nclearances. The en route controller, via voice or CPDLC (if available) sends both clearances to \nthe IM Aircraft, withholding the Assigned Spacing Goal for the PA IM Clearance.
The IM Aircraft \nflight crew accepts the Achieve-by then Maintain Clearance, enters the information into the FIM \nEquipment, and begins their spacing. They then enter the PA IM Clearance as a Partial IM \nClearance and wait for the IM PA Assigned Spacing Goal to be provided. TBFM forwards the \nclearance information to STARS. As the aircraft enter terminal airspace, the IM Trail Aircraft continues to execute its Achieve-by \nthen Maintain IM Clearance. Once the IM Trail Aircraft reaches its ABP (on the extended final \napproach course), the Foster (Final Approach) Controller consults the IM Spacing List and issues \nthe Assigned Spacing Goal to the IM Trail Aircraft. The flight crew enters the Assigned Spacing Goal into the FIM Equipment, which terminates the \nAchieve-by then Maintain IM operation and initiates the IM PA operation. The Foster Controller \nreflects the change in IM Clearance state on STARS. The Final controllers clear the aircraft for \ntheir approaches and instruct them to change to the Local controller frequency. Monitor \ncontrollers monitor separation with respect to the CSL and WSL (if applicable) until the IM Lead \nAircraft crosses its runway threshold. Based on this scenario, the key controller actions, locations and agents for an NCT/SFO IM PA \noperation in a metering environment are summarized in Table 2-2. Table 2-2. Key Functions for NCT/SFO IM PA Operation with Metering Aircraft are in \nPerformed by Tactical PA Metering PA\nIdentification of Pairs Cedar, Laguna, Niles, Boulder En route Coordinator Controller TBFM xvii\n IM Clearance Definition / ASG* \nComputation Cedar, Laguna, Niles, Boulder En route\nCoordinator Controller TBFM Provision of First IM Clearance N/A En route\nN/A TBFM/En route Controller Placing Aircraft on Final / Initial Spacing TRACON En route/TRACON\nMainly Boulder/Woodside TBFM/TSAS/IM Provision of ASG* (PA IM Clearance) Foster Foster\nFoster Controller Foster Controller Updating IM Spacing List Foster Foster\nFoster Controller Foster Controller CSL/WSL Monitoring Foster/Woodside Foster/Woodside\nMonitor Controllers Monitor Controllers Re-computation of ASG* (if needed) Foster/Woodside Foster/Woodside\nMonitor Controller STARS/TBFM *Assigned Spacing Goal Related PA and IM Research 3.4\nFlight crew and ATC HITL research on PA has been performed for more than two decades, with \none of the earliest concept studies being performed in 2001 (Bone, Mundra, & Olmos, 2001). \nMore recently, MITRE and the FAA have conducted several flight deck and ATC HITL \nexperiments to mature the IM PA concept, as shown in Figure 2-11. The PA concept tested in \nthese HITLs was not yet part of IM and assumed that safety limit monitoring would be a \nresponsibility of airborne equipment and flight crews. Though this has changed for the current \nIM PA concept examined in this paper, several aspects of these HITLs remain relevant to the \ncurrent work. Selected results from the 2013 and 2015 ATC HITL experiments and another \nrecent, relevant IM HITL are summarized in this section. An extensive review of past IM research \ncan be found in Bone & Mendolia (2018) A review of PA flight deck research from the recent \naircrew-based HITLs can be found in Lewis, Bone, Mendolia, & Nguyen (2019). Figure 2-11. Recent PA HITLs The 2013 and 2015 ATC HITL experiments were performed by MITRE and developed in \ncoordination with NCT and included controller vectoring to set up the aircraft. The 2013 HITL xviii\n focused on mainly on nominal operations and involved Niles and Boulder Feeder controllers and \nFoster and Woodside Final Approach controllers (Domino, Tuomey, Stassen, & Mundra, 2014). \nThe 2015 HITL included both nominal and off-nominal operations and was expanded to include \nTRACON Feeder, TRACON Monitor, and Tower controllers (Mendolia, et al., 2016). In these \nHITLs, ATC remained responsible for separation between all other aircraft and for managing the \noverall arrival flow to the airport to ensure that both arrival and departure operations were \nconducted efficiently. The ATC task was to deliver the PA pair onto a long final approach with \nbetween 1 and 2 NM longitudinal (in-trail) spacing. At the time, the PA concept required controllers to communicate the PFAS of the IM Lead \nAircraft to the IM Trail Aircraft. The task of obtaining the leading aircrafts PFAS and entering it \ninto the data block scratch pad was given to the High Feeder Controller. This position would also \nadvise which approach they would expect to fly, if known. In the 2013 ATC HITL, this position \nwas not staffed with a participant therefore these communications were assumed to happen \nupstream and were not directly included in the study. The HITL procedures also did not \ndistinguish between a PA operation and PA approach and therefore did not require \nseparate clearances. In the HITL, the clearance for the RNAV (Required Navigation Performance \n[RNP]) PA runway (RWY) 28R approach constituted clearance to perform the PA operation (D. \nDomino, personal communication, 02/28/2019). For the south and Modesto north arrivals (see \nSection 2.3.1), staffed low feeder positions provided the Lead Aircrafts PFAS to the trailing \naircraft. For the Golden Gate north arrivals, the Final controller was responsible for soliciting \nand entering PFAS data in the arrival data block. The Boulder Low Feeder position did this in \n2013 for the PYE (at that time prior to BDEGA implementation) and PIRATs. This general procedure was the same for the 2015 study, except that an IM PA operation was \ninitiated via a separate IM Clearance. The Final Approach controller positions provided the IM \nClearance, including the Lead Aircrafts PFAS, to each candidate Trail Aircraft. The Low Feeder \ncontrollers advised aircraft to expect the IM PA procedure, as described further in Section \n2.4.2. The following two sections provide more detail with respect to these two IM PA ATC HITL \nexperiments and results. Section 2.4.3 describes the general IM initiation task and display \nfeatures that provided a foundation for the current HITL simulation. 2013 ATC Initial Feasibility HITL Experiment3.4.1\nAs described in Domino, Tuomey, Stassen, & Mundra (2014), the objective of 2013 ATC Initial \nFeasibility HITL was to perform initial ATC acceptability and feasibility assessments of the \noriginal PA concept under nominal conditions (i.e., no blunders) and determine potentially \nachievable arrival rates under IMC at CAT I limits with varying levels of PA equipage. It also \nexamined whether controllers could deliver the required initial interval for candidate IM PA \npairs. The NCT airspace was simulated for this study with PA operations to SFOs runways 28L \nand 28R. NCT controllers provided subject matter expertise during the development of the HITL, \naiding the researchers both in creating a sufficiently representative simulated environment and \nin refining key conceptual details. Five other controllers and supervisors from NCT participated \nin the data collection. The simulation design tested three levels of PA equipage and three levels of allowable PFAS xix\n differences. A Pair List was implemented to display eligible pairs and display the PFAS value of \nthe Lead Aircraft. Trail and Lead capability was also included in the data blocks along with their \nreported PFAS values. Results data consisted of hourly achieved arrival rates, pair interval at \nturn on, and questionnaire subjective data including workload. Results suggested that controllers found that their tasks, including querying for PFAS, entering it \ninto the data block scratchpad, and communicating it to the trail aircraft, were feasible, \nacceptable, and could be performed by the average controller at NCT. Controllers indicated that \nthe procedure was possible using voice communications and there was no indication that the \nphraseology used in the HITL posed a problem at any of the simulated traffic levels (D. Domino, \npersonal communication, 02/27/2019). The controllers also suggested that the procedure did \nnot require new ground automation for pairing aircraft and that the PA procedure was similar to \nSOIA. Finally, the STARS Pair List was reported to be an effective way to advise the pair \nassignments. In the HITL, controllers were able to deliver the required initial spacing interval of 1-2 NM, with \n1000 ft altitude separation, on a 15-17 NM long final. They also achieved arrival rates of 34 to 46 \naircraft depending on the equipage level of the scenarios (34 for 30% equipage; 46 for 100% \nequipage), exceeding SFOs single runway capacity at the time of 30 aircraft per hour, or 36 with \na SOIA operation. Workload was consistently rated higher than a baseline scenario consisting of \nSOIA operations, but decreased with experience and was still reported on average as acceptable \nfor all control positions. 2015 ATC Off-Nominal HITL Experiment3.4.2\nAs described in Mendolia, et al. (2016), the 2015 ATC HITL experiment was conducted to \nexamine PA operations at both the TRACON and Tower (i.e., NCT and SFO). SFO Tower and NCT \ncontrollers provided subject matter expertise during the development of the HITL, and \nparticipants included two SFO Tower (Local) controllers and five NCT controllers. Staffing \nincluded two Final positions (Woodside and Foster), two Arrival Feeder positions (Boulder and \nNiles), and one Departure position (Sutro) (see Section 2.3.1 for an overview of the airspace). The HITL involved a lateral deviation monitoring task with a custom-designed Non-Normal Zone \n(NNZ), based on an NTZ, and associated caution and warnings designed to assist aircraft in \navoiding wake encounters. It accommodated the 3 deg offset for the 28R RNAV approach and \nextended from approximately 15
NM to 3.4 NM from the runway threshold. A shown in Figure \n2-12, three separate zones were created at different locations along the NNZ, each with an \nassociated Caution or Warning for aircraft encroachment. These alerts were not predictive and \nappeared only when an aircraft entered one of the alerting zones. In the Early Zone (EZ), \ncontrollers had the option of bringing a deviating aircraft back into compliance. In the Imbedded \nLate Zone (ILZ) and Late Zone (LZ), controllers were required to issue warning alerts and provide \nappropriate break out instructions. Alerts were displayed via flashing, color-coded text \nindication in the deviating aircrafts data block along with a color-coded ATPA-like cone that was \ndisplayed in a direction that corresponded with the deviating aircrafts current track. xx\n Figure 2-12. NNZ Parameters and Alerting Zones from Mendolia, et al. (2016) Two controller configurations were evaluated: 1) dedicated Separate Monitor positions for each \napproach in which they were alerted to any intrusion into the NNZ on a 4:1 aspect ratio FMA \ndisplay with a 4.8 sec surveillance update, and 2) a configuration where the NNZ and deviation \nalerts were displayed to Final controllers on a normal STARS 1:1 aspect ratio display with 1 sec \nupdates. Final controllers had the option of toggling the NNZ on or off and changing its \nbrightness. When off, the alerts still automatically indicated that an aircraft was entering one of \nthe alerting zones. If the NNZ was displayed, its outline brightened until the aircraft exited the \nalerting zone. Also, when an alert was triggered, a flashing text string indicating the type of alert \nwas displayed in the deviating aircrafts data block line 0 until the alert was no longer active. For \nthe FMA display, the entire data block changed color to indicate the alert. For the Final \ncontroller display configuration, the data block remained green and only the alert text was color-\ncoded. The HITL included nominal and non-nominal scenarios, though the research emphasis was on \nTower feasibility and off-nominal (e.g., blunder) events. Off-nominal events occurred any time \nafter both aircraft were established on final, and included: a gate breakout (i.e., a Trail Aircraft \nexceeds a safety limit), a Lead Aircraft executing a missed approach, an overtake (i.e., the Lead \nAircraft of a second pair overtakes the Lead / Trail Aircraft of the first pair), a late departure take-\noff, lateral deviations into the NNZ, and pairs modified or abandoned the IM PA procedure in \nresponse to (for example) a surveillance or algorithm failure, or disqualifying adjustment to \nPFAS. Controllers used the same Pair List and data block implementations as Domino, Tuomey, \nStassen, & Mundra (2014) to view proposed IM PA pairings and PFAS information. Figure 2-13 \nshows the Pair List as implemented in Mendolia, et al. (2016). xxi\n Figure 2-13. Pair List from Mendolia, et al. (2016) IM Clearance and PFAS communications were generally as described in Section 2.4. First, \ncandidate Trail Aircraft were assumed to have been informed by High Feeder controllers (not \nstaffed) to expect an RNAV Runway 28R Approach and to perform an IM PA operation. Then \nthey were reminded by Low Feeder controllers (staffed) that they would be performing an IM \nPA operation and were given the Lead Aircrafts identification, runway assignment, and PFAS. \nExample phraseology consisted of: United 123, expect Paired Operation with United 345 on ILS \n28L, planned final approach speed 140 knots. The 28L Final controller vectored the Lead in \nfront of the Trail Aircraft and targeted 12 NM spacing and cleared it for the approach. The 28R \nFinal sector controller then issued the Trail Aircraft the IM Clearance: United 123, cleared \nPaired Operation with United 345. This HITL assumed that coupled approaches would be \nrequired for IM PA, and so the approach clearance phraseology to both aircraft also included a \nreminder to check autopilot on as an additional safety check for the prevention of blunders. The human factors-related simulation findings were generally positive. Controllers indicated \nthat the procedure was acceptable, desirable, and expressed confidence that other controllers \ncould conduct the operation. They understood their roles and responsibilities during the \noperation. The majority of workload responses were on the low side of the scale. The few \nhigher ratings were mainly attributed to the extension of the final approach course and high \nfrequency of off-nominal events. The Local controllers reported no difference in PA workload as \ncompared to CSPR 7110.308 and SOIA operations currently used at SFO. However, the Arrival \nControllers reported that PA somewhat increases or increases their workload. All controllers indicated a need for modification to the phraseology employed in the HITL and \nroutinely commented that the communications were too long. They emphasized removing the \nPFAS from the IM Clearance and eliminating the autopilot on check. They also suggested \nputting as much information as possible on the approach chart or Attention All Users Page. The \nmajority of participants did not identify any issues with using third party flight identification as \npart of the clearance. The lateral deviation detection scenarios were included in the HITL as an initial study to enable \nrecommending future research direction. Several controllers in the lateral deviation scenarios \nindicated issues with the breakout procedure, citing confusion with what to do with the non-\ncompliant aircraft when it penetrated the EZ. Participant agreement as to the acceptability of \nthe Lateral Deviation scenarios appeared variable. Three of the four arrival controllers indicated \na preference for separate dedicated FMA monitor position as opposed to a non-FMA \nconfiguration where the final arrival controllers are responsible for detecting and responding to \ndeviations into the NNZ. The study recommended additional research with respect to controller \ndetection of lateral deviations. xxii\n Participants in the study were able to maintain average arrival and departure rates above 40 \noperations per hour. The arrival rate ranged between 41 and 44 during nominal scenarios. \nControllers were, on average, able to deliver an intra-pair spacing of 1.55 NM during initiation \nas required, though they were not able to consistently meet the 15 NM distance to threshold \nrequirement. At the simulated arrival rates, this requirement was reported to require significant \nvectoring to achieve the required sequencing. 2017 IM TSAS HITL Experiment3.4.3\nIn 2017, MITRE conducted an IM HITL experiment in the TRACON environment to determine the \nfeasibility and operational acceptability of the integration of TSAS and IM spacing to both flight \ncrews and controllers (Bone & Mendolia, 2018). Though the HITL experiment did not involve IM \nPA operations, IM arrival spacing in the terminal area was evaluated and relevant results from \nthis aspect of the simulation are summarized here. In addition, IM Spacing List and data block \ntools developed for this HITL were used for the IM PA HITL that is the subject of this paper, and \nare therefore also summarized here. The 2017 IM TSAS HITL had several ATC-based objectives. The first was to evaluate information \nand communication needs, and the associated procedures, from a human factors perspective. \nThe HITL was also intended to support the definition of IMs integration with TSAS and \ndetermine desirable initiation points (i.e., en route, early terminal, feeder to final transition, and \nfinal approach). Finally, the HITL determined and validated controller information needs, \nincluding IM situation awareness and progress monitoring. Similar in purpose to the Pair Lists developed for the PA ATC HITLs described earlier, a prototype \nSTARS IM Spacing List, shown in Figure 2-14, was developed to provide IM Clearance and IM \nStatus information. The text was coded in white when proposing an IM Clearance, green if the \nIM Clearance was active, and yellow if the IM Clearance was terminated or an issue existed. The \norder of the text was presented to reflect how it would likely be issued by the controller in a \nvoice clearance. Figure 2-14. Prototype STARS IM Clearance Window from Bone and Mendolia (2018) An IM Clearance was only proposed when specified conditions were met. These included, for \nexample, times when the IM Trail Aircraft and IM Lead Aircraft were on appropriate route \ngeometries for the clearance type and both aircraft were qualified to act in their respective \nroles. In addition, the IM Lead Aircraft needed to be directly ahead of the IM Trail Aircraft for \nthe same runway, the Assigned Spacing Goal needed to be between 75 and 240 seconds, the IM \nLead Aircraft needed to be in surveillance range of the IM Trail Aircraft, the IM Trail Aircraft xxiii\n could not be beyond the ABP, and a speed-only spacing solution needed to be available. After \nan IM Clearance was proposed, it could be rejected by the controller. It then remained in the list \nfor 30 seconds, so the rejection could be retracted if desired. Bone and Mendolia (2018) developed and tested a prototype design for providing IM \nInformation in the data block for the IM Trail Aircraft and IM Lead Aircraft. The IM Trail data \nblock design is shown in Figure 2-15 and the IM Lead data block design is shown in Figure 2-16. Figure 2-15. Prototype IM Information in Data Block, IM Trail Aircraft from Bone and Mendolia (2018)
Figure reprinted \nfrom: Bone and \nMendolia (2018) xxiv\n Figure 2-16. Prototype IM Information in Data Block, IM Lead Aircraft from Bone and Mendolia (2018) The researchers reported that when asked whether the information in the IM Spacing List was \nhelpful for IM, the majority of controllers agreed that in general, the IM elements were helpful \nfor IM operations / Aircraft. Controllers also specifically found the IM Status information to be \nhelpful for IM operations / Aircraft. For the data block IM elements, IM Trail Aircraft and IM Lead Aircraft status indicators were \nreported as helpful by a majority of controllers. Controllers appeared to favor maintaining the \ndisplay of IM Status in the data block and not just in the IM Spacing List. They did not want IM \nStatus to be removed from the data blocks near and on final. Figure reprinted \nfrom: Bone and \nMendolia (2018) i\n Research Goals, Questions, and Hypotheses4\nIM PA Concept Evolution and Research Gaps4.1 The Legacy PA concept evaluated in the HITL experiments described in Section 2.4 assumed \nthat safety limit monitoring would be a responsibility of the airborne equipment and flight \ncrews. The controllers role was to establish alternate separation in the event of a PA Equipment-\ncommanded breakout. As PA began to be incorporated into the FIM Equipment standards \nprocess in RTCA, stakeholders determined that the concept needed to change to ensure that \ncontrollers explicitly maintain separation responsibility and therefore must be able to monitor \nthe operation relative to a clear separation standard. This requires controllers to be able to \nassess aircraft pair PA separation such that they can take effective action before separation is \nlost. The flight crew task should become speed guidance conformance, as with the other IM \napplications. Therefore, the concept was changed to move the safety limit monitoring function \nfrom being a flight crew responsibility and FIM Equipment capability to a ground capability, \nlikely to be hosted in STARS. The updated IM PA concept introduces two new aspects to the controller separation assurance \ntask. First, controllers today typically monitor aircraft against a single minimum separation \nvalue. With IM PA, however, controllers will likely be required to monitor some aircraft parings \nwith respect to a minimum limit (CSL) and a maximum limit (WSL). Second, current separation \nminima are usually static; i.e., they are a known value that remains fixed for a given set of \nconditions. For IM PA, however, the distance allowed between the aircraft and both limits will \nchange as a function of the distance to the runway, as illustrated in Figure 2-4. Due to IM PAs minimum and maximum safety limits that change over the course of an \napproach, and the close inter-aircraft pair distances, stakeholders expected that controllers \nwould likely require new ground tools to detect and act on potential exceedances of the safety \nlimits. Also, these tools would be required to allow controllers to provide a timely response to \nan aircraft deviation in either the longitudinal (along-track) or lateral (i.e., blunder) dimensions. \nNeither the new monitoring task and nor the potentially enabling tool set has yet been \nexamined in a HITL environment. In addition, due to flight crew workload in preparing the FIM Equipment, nominal IM PA setup \nshould be possible in en route or feeder airspace, possibly via a Partial IM Clearance (as \ndescribed in Section 2.2.1). Although prior PA ATC research assumed the use of an expect \nmessage to provide setup information before the operation was to begin (see Section 2.4), the \nuse of a Partial IM Clearance as described in FAA (2017b) and RTCA (2019a) to prepare an IM PA \noperation has not yet been examined in a HITL activity. Research Goals4.2\nPrior PA HITL research such as Domino, Tuomey, Stassen, & Mundra (2014) and Mendolia, et al. \n(2016) examined controller tactical setup and separation monitoring as a flight crew \nresponsibility. The results regarding tactical setup are expected to still be generally relevant to \nthe IM PA concept as currently defined. Therefore, the primary goal of this HITL was to examine \nthe updated IM PA concept with a focus on the new controller monitoring functions. This ii\n included an evaluation of the terminal controller monitoring task for IM PA pairs established on \nfinal, especially with respect to minimum and maximum separation limits that change over the \ncourse of an approach. Related to this is whether it is acceptable for a single monitor controller \nto manage IM Lead and IM Trail Aircraft on both approaches, or whether separate monitors \nwould be required. It also included an evaluation of alternative supporting display features to \nfacilitate this monitoring task. A secondary goal was to examine the use of a Partial IM \nClearance procedure to initiate IM PA operations on final. This HITL experiment was not intended to comment on the feasibility of tactical or metering IM \nPA setup procedures, beyond having the Final Approach controller initiate the operation, nor \nwas it intended to precisely replicate SFO airspace and operations and draw specific conclusions \nwith respect to a mature IM PA implementation at that facility. Additionally, this HITL did not \nsuggest any final design criteria with respect to a future PA separation standard or any final IM \nPA ground tool interface or display requirements (although recommendations are made for \nconsideration by the appropriate design groups). The results of the HITL are intended to provide concept validation for the avionics standard \nactivities and A-IM ConOps, as well as specific recommendations for the FAA IM Initial Program \nRequirements document with respect to controller information needs and supporting ground \ntools. Research Questions and Hypotheses4.3\nBased on the research goals and past studies, six research questions and corresponding \nhypotheses were developed. These are listed below: RQ1: Is it feasible and acceptable for controllers to monitor PA separation with respect to \nboth minimum and maximum separation limits? The controller separation assurance task includes spacing and separating among in-trail aircraft \nwithin flows and on approaches. In these situations, controllers today must ensure that a given \naircraft maintains appropriate spacing from an aircraft ahead as well as an aircraft behind. \nThough IM PA introduces a minimum and maximum limit with respect to a single leading \naircraft, the task of keeping an aircraft within a forward and aft boundary should be a simple \nextension of this basic controller task. Therefore, it is hypothesized that controllers will find IM \nPA safety limit monitoring both feasible and acceptable. H1(RQ1): Given an appropriate tool set, controllers will find it acceptable and feasible to monitor \nIM PA operations with respect to both minimum and maximum separation limits. RQ2: Is it feasible and acceptable for controllers to provide PA separation with respect to \nvalues that change over the course of an approach? Controllers today have experience with separation minima that can change for a given pair of \naircraft depending on conditions. For example, an aircraft pair turning onto final may initially be \nseparated via Minimum Radar Separation (MRS) of 3 NM or 1000 ft vertical. Then, when aircraft \nare within 10 NM of the airport on final, pairs may be allowed to close to 2.5NM per Section 5-5-\n4 in FAA (2017a). In another example, at certain facilities aircraft may be transitioned to a \n7110.308C operation and allowed to close to within 1 NM diagonal (FAA, 2018b). Aircraft \nseparation on approach may be further complicated at some facilities due to MRS applying to iii\n certain aircraft pairs and new Wake Recategorization (RECAT) Separation minima required for \nother combinations (FAA, 2016). Controllers are therefore used to managing complexity in \napplying the appropriate separation standards to pairs of aircraft. However, clear rules are \nrequired to govern which standard applies for any given aircraft pairing, operation, and set of \nconditions. A PA separation standard should therefore also be manageable, even if it changes over the \ncourse of an approach, as long as the required separation distance minimum is clear at any \ngiven time and the trend is generally predictable. As this can be incorporated in the design of a \nground tool, it is therefore hypothesized that if done correctly, controllers can find it acceptable \nand feasible to provide PA separation with respect to separation values that change over the \ncourse of an approach. H2(RQ2): Given an appropriate tool set, controllers will find it acceptable and feasible to provide \nPA separation with respect to separation values that change over the course of an approach. RQ3: What information elements and tools may be required for Monitor controllers to \nlongitudinally monitor IM PA operations? As described above, it is expected that controllers will need to know the required separation \ndistance for an IM PA pair at any given time. This may be in the form of a graphical indicator or \nnumeric indicator. It is hypothesized that one form will be required by controllers, but not both. \nIn addition, to ensure the acceptability of a standard that involves limits that change over the \ncourse of an approach, the changes must be generally predictable and manageable. As the WSL \nonly applies to certain aircraft pairings, and even then, only in the last portion
of the approach, \nthere is the potential for controllers to be surprised by a pop-up WSL value. This surprise could \nbe mitigated by a preview or pre-activation feature; however, the underlying WSL should be \npredictable over time and therefore this additional display feature could be considered display \nclutter by controllers. It is therefore hypothesized that a WSL pre-activation feature may be \nuseful, but not a minimum requirement. H3(RQ3): Controllers will find a WSL Pre-Activation indication and distances to the CSL and WSL \nuseful, but not minimum requirements. As the IM PA inter-pair spacing will be smaller than what controllers are used to today, and \nbecause the controller will be required to take action before an IM PA Aircraft longitudinally \nencroaches on either the WSL or CSL, it is expected that alerting will be helpful to controllers to \nindicate when an intervention is required. Based on the fielded ATPA Phase 1 alert \nimplementation described in Section 2.3.2.2, it is hypothesized that a similar IM PA two-level \nalerting scheme will be acceptable to controllers. H4(RQ3): A representation of the safety limits and an alert when the IM Trail Aircraft begins to \nencroach on the limits will be useful to Monitor controllers. RQ4: What types of information and display features will controllers need to monitor IM PA \noperations for lateral deviations from the intended flight path? Past research results suggest that similar to SOIA, the lateral monitoring task is enhanced by an \nNTZ-like area and associated alerting to indicate when controller action is needed to resolve a \nlateral deviation (Mendolia, et al., 2016). As noted in Section 2.2.3, the CSL and WSL were \ndesigned to accommodate some amount of normal aircraft crosstrack error from the approach iv\n path centerline. Although controllers are not required to detect lateral deviations and break out \none of the aircraft in an IM PA pair before the other crosses its path, they are expected to find it \nhelpful to be informed as to when an aircrafts crosstrack error may result in the CSL and WSL \nno longer providing the required protection from collision or wake risk. Therefore, as with SOIA \noperations and their associated NTZ, controllers are hypothesized to find useful a display \nelement to indicate when they need to take action based on a lateral deviation. Also, controllers \nare hypothesized to find useful an automated warning to draw their attention to the deviation. H5(RQ4): Controllers will find features such as Lateral Boundaries and an Exceedance Warning \nuseful to alert them to IM Lead Aircraft and IM Trail Aircraft lateral path deviations. RQ5: Can a single, combined Monitor controller effectively monitor an IM PA operation?\nPast research results suggest that similar to SOIA, dedicated Monitor controllers providing IM \nPA separation would be the preferred implementation at NCT/SFO (Mendolia, et al., 2016). As \ndescribed in Section 2.3.2, current operations such as SOIA require separate Monitor \ncontrollers, each with transmit / receive and override capability on the respective final approach \nfrequency, to ensure aircraft do not penetrate the depicted NTZ. This is possible at SFO because \nseparate L/R Final Approach controllers work the finals and aircraft are navigating visually for \nthe last portion of the approach. At this point, the aircraft no longer require Monitor controllers \nto provide separation and are transferred to the single Local controller. IM PA, however, is intended for operations in IMC and may not be able to accommodate visual \nseparation during the final portion of the approach. Implementing separate L/R Monitor \ncontrollers, as would be required by current 7110.65 rules (FAA, 2017a), may thus not be \npractical or feasible at SFO. It is therefore of interest to determine whether a single, combined \nMonitor controller can effectively provide separation for CSPR finals involving IM PA operations \nover a relatively long final approach segment. Facilities with dependent parallel runway operations typically employ separate L/R Final \nApproach controllers due to the workload involved in vectoring aircraft to final and other \nintensive tasks. Todays Monitor controller workload, however, is much reduced as they are \nonly required to take action if an aircraft penetrates the NTZ. Workload for the IM PA concept \nas tested in the HITL may be higher, as the Monitor controllers must provide separation for all \naircraft on the approach, including within and between IM PA pairs, and must monitor for \nlateral deviations. However, IM PA will likely involve alerting to tell controllers when to take \naction for an impending loss of IM PA separation. Therefore, if vectoring to final (or managing \naircraft on RNAV paths that connect to the final) remains the responsibility of Final Approach \ncontrollers, it is hypothesized that a single Monitor controller can effectively and acceptably \nMonitor separation for IM PA and non-IM PA aircraft over the course of a long final approach \nsegment. H6(RQ5): Though the workload may be increased, a single, combined Monitor controller can \neffectively and acceptably provide separation for CSPR finals involving IM PA operations, \nincluding separation between successive PA pairs. RQ6: Is it feasible and acceptable to use Partial IM Clearance procedures to initiate an IM PA \noperation? Prior PA HITL research such as Domino, Tuomey, Stassen, & Mundra (2014) and Mendolia, et al. v\n (2016) examined the use of an expect message to provide IM PA setup information before the \noperation was intended to begin. Controller results suggested that clearance formulation in this \nmanner was acceptable, though issues were raised with respect to the length of the \nphraseology as described in Section 2.4.2. The use of expect was modified during concept \ndevelopment to the use of a Partial IM Clearance summarized in Section 2.2.1. More fully \ndescribed in FAA (2017b) and RTCA (2019a), the intent of the Partial IM Clearance was generally \nthe same as the expect message and the sequence of communications and information \ntransfers is similar. It is therefore hypothesized that Final controllers will find the IM PA \ninitiation task, including the use of Partial IM Clearance procedures, acceptable. H7(RQ6): Final controllers will find the IM PA initiation task, including the use of the Partial IM \nClearance, acceptable. i\n Experiment Methodology5\nThe purpose of this HITL experiment was to evaluate the terminal controller monitoring task for \nIM PA pairs established on final, especially with respect to minimum and maximum separation \nlimits that change over the course of an approach. In addition, it evaluated alternative \nsupporting display features to facilitate this monitoring task and the use of Partial IM Clearance \nprocedures to initiate IM PA operations on final. This section details the simulation \nenvironment, prototype ground tools developed for the evaluation, IM PA concept \nimplementation as tested including controller roles and responsibilities, and the experimental \ndesign. Simulation Environment5.1\nThe HITL was conducted in the MITRE Aviation Integration Demonstration and Experimentation \nfor Aeronautics (IDEA) Laboratory at the MITRE McLean campus. The simulation utilized \ncontroller and pseudopilot workstations that incorporated new display features as necessary for \nthis evaluation. An overview of the capabilities and workstations are provided below. Controller Workstation5.1.1\nThe ATC interface consisted of a representative 2K display that hosted an interface similar to the \ncurrently fielded STARS system. The display contained an SFO terminal map and the same \ndisplay and features were available to both the Monitor controller(s) and Final Approach \ncontroller and is shown in Figure 4-1. Some of the IM PA features are depicted in the figure and \nare described in Section 4.2. ATPA and Wake RECAT aircraft categories were not available to \ncontrollers on the display; however, other tools such as bats and Predicted Track Lines (PTLs) \ncould be toggled on or off. The workstation contained the majority of the basic STARS \nfunctionality and used a typical STARS keyboard and trackball. Special keyboard entries were \nprogrammed to serve as unique IM PA functions (described in Section 4.2.2). ii\n 7 This figure first appeared in Mendolia, et al. (2016). Figure 4-1. STARS Display used in the HITL Experiment (with IM PA Display Features) Pseudopilot and Confederate Controller Workstations5.1.2\nAircraft in the HITL were piloted by pseudopilots, which allowed the controller participants to \ninteract normally with the traffic. The pseudopilots input the controller participant instructions \ninto an interface termed Simpilot as shown in Figure 4-27, which allowed for the simultaneous \ncontrol of multiple simulated aircraft. The HITL scenarios also required the use of a confederate \nto act as a Local (Tower) Controller. This Confederate Controller communicated directly with the \npseudopilots on the voice frequency, which the participant Monitor controllers could listen to \nand override as needed. HITL scenarios involved different roles and configurations for the \nparticipant controllers. This required different configurations and communications loops for the \npseudopilots and confederate controllers as described in Section 4.1.3. iii\n Figure 4-2. Pseudopilot Interface (Simpilot) Communications Environments5.1.3\nVarious communications configurations were used during the HITL, depending on whether \nparticipant controllers managed traffic as combined or separate monitors, as described in \nSection 4.3. Figure 4-3 shows the communications environment for the Combined Monitor \nconfiguration. Two separate loops were created: the first for the 28L/R Combined Monitor \ncontroller (participant), who monitored the frequency with a Combined 28L/R Local controller \nand the pseudopilot managing the traffic arriving to
both runways. The second was the 28R \nFinal controller, who communicated directly with a pseudopilot. iv\n Figure 4-3: Combined Monitor Configuration Communications Environment Figure 4-4 shows the communications environment for the Separate Monitor configuration. \nTwo separate loops were created: the first for the 28L Monitor controller (participant) who \nmonitored the frequency with a 28L Local controller and the pseudopilot managing the traffic \narriving on 28L. The second was the 28R Monitor controller, who monitored a frequency \nbetween the 28R Local controller and the corresponding pseudopilot managing arrival traffic to \n28R. Figure 4-4. Communications Environment: Separate Monitor Configuration The communications configuration shown in Figure 4-5 was used for the Combined Monitor \nAlert Timing and Lateral Deviation Combined Monitor Scenarios, as described in Section 4.5. v\n Only one loop was created: a 28L/R Combined Monitor controller (participant) monitored the \nfrequency with a Combined 28L/R Local controller and the pseudopilot managing the traffic \narriving to both runways. Two versions of this configuration were run at the same time, \nindependent and in parallel. Figure 4-5. Single Participant Configuration Communications Environment IM PA Ground Tools5.2\nAs discussed in Section 3.1, new ground tools are expected to be required to allow controllers to \nprovide a timely response to an aircraft deviation in either the longitudinal (along-track) or \nlateral (i.e., blunder) dimensions. Several new display features were therefore introduced and \nevaluated in the HITL to support IM initiation and monitoring functions. The following list \nsummarizes the new display features and notes the sections of this report in which the features \nare described: IM Spacing List with IM PA Initiation Information (Section 4.2.1).\nData Block Display of IM Status and the Distances to the CSL and WSL (Section 4.2.3).\nLine Representing the CSL (Section 4.2.4).\nLine Representing the WSL (Section 4.2.5).\nWSL Preview Line (WSL-P) (Section 4.2.6).\nSafety limit Predictive Alert and Caution Alert (Section 4.2.7).\nLateral Boundaries and Exceedance Warning (Section 4.2.8). The IM Spacing List and Lateral Boundary features were developed by MITRE through research \nsupported by the FAAs SBS and ANG-C1 organizations. The other, IM PA-specific monitoring \ntools were developed by MITRE and supported by the FAAs CSPO Program Office. Tool design \ndepends on the PA Separation Standard assumed for the HITL, so those assumptions are \ndetailed in the following section. Detailed description for each of the IM PA tools is then \ndescribed in the sub-sections that follow. PA Separation Standard Assumed for the HITL5.2.1\nAs described in Section 2.2.3, IM PA will require a new dependent parallel runway separation \nstandard. The FAA has not yet begun to define this standard, however, so one needed to be \nassumed for the HITL experiment to inform: 1) suggested controller tasking and procedures, and \n2) the design of the supporting monitoring tools and display features. vi\n Previous research (Stassen, et al., 2017) suggests that although wind-independent IM PA \noperations at SFO requiring a WSL are likely infeasible, wake-free IM PA operations (that do not \nrequire a WSL) may be possible for more than 80% of the potential IM PA operations. As one of \nthe primary objectives of the HITL is to examine controller monitoring with respect to both \nsafety limits being active at the same time, it will assume that the implementation includes IM \nPA pairs that require a WSL. Therefore, the key PA separation standard characteristics assumed \nfor the HITL experiment included: The PA separation standard is defined by the safety limit values and guarantees \nprotection from collision in the event of a deviation by either the IM Trail Aircraft or IM \nLead Aircraft and from a hazardous wake encounter. \nThe safety limit values are dependent on facility geometry and independent of avionics \ncapability. An IM termination does not automatically mean that PA separation is lost.\nNo single safety limit value applies to a pair of aircraft for the entirety of the approach. \nBoth the forward standard and aft standard change as a function of the Lead Aircrafts \nproximity to its runway threshold. Some aircraft pairings do not require a WSL. For the purpose of the HITL, controllers were informed that separation is assured if the IM Trail \nAircraft remains within the safety limits. The CSL values used in the HITL experiment are shown \nin blue in Figure 4-6, and were based on AFS, Flight Technologies Division, Flight Systems Lab \n(AFS-450) Monte-Carlo simulations at SFO and provided to RTCA SC-186 WG4 (Williams & \nWood, 2017). The Monte-Carlo simulations examined longitudinal spacings between IM and \nTarget Aircraft until an acceptable collision probability was found (1x10-9). Figure 4-6. CSL and WSL Values Used in the HITL vii\n A WSL value of 1.5 NM, starting when the IM Lead Aircraft was 2 NM from the runway \nthreshold, was assumed for IM PA pairs involving a heavy category aircraft as the lead. This is \nshown as the red line in Figure 4-6. Collision protection from a lateral deviation (i.e., blunder) is assured by the controller being \nrequired to take action to keep the IM Trail Aircraft from crossing the CSL. There is no \nexpectation that controllers provide lateral deviation protection beyond this, therefore no \nearly detection and protection requirements were assumed. However, because the CSL and \nWSL comprise the PA separation standard for the HITL, it was assumed that the controller \nparticipants need to know how much lateral deviation the limits have been designed to \naccommodate. If either aircraft then goes beyond that amount in either direction (left or right), \nthen PA separation would no longer apply. Therefore, controllers were informed that the PA \nseparation standard (CSL and WSL) applies as long as the IM Lead Aircraft and IM Trail Aircraft \nremain within defined lateral boundaries. Though the general concept for these boundaries was \ndiscussed and agreed upon by FAA stakeholders and operational experts, the implementation in \nthis HITL, as described in Section 4.2.8, was the first attempt at a specific design. IM Spacing List with IM PA Initiation Information5.2.2\nThe IM Spacing List provided the necessary information to enable the 28R Final controller to \ninitiate the IM PA operation. The list was also displayed to the Monitor controller and provided \nIM Status information and an interface to the automation to indicate when IM PA was \nterminated early. The IM Spacing List design was based on that used in the 2017 IM TSAS HITL \nreported in Bone & Mendolia (2018). An example IM Spacing List is depicted in Figure 4-7 and \ncontrollers could position it as desired on the STARS display. Figure 4-7. IM Spacing List with IM PA Initiation Information The IM Spacing List display included a list of proposed aircraft pairings, associated Assigned \nSpacing Goals, and status (i.e., eligible, active, terminated). The order of the text was presented \nto reflect how the IM Clearance would likely be issued via voice. The IM Spacing List also \nincluded an accept or reject function, which enabled the controller to indicate to the \nautomation that the IM PA operation had been successfully initiated or not. Final controllers \nused the STARS keyboard keystroke sequence [MULTI FUNC]-[T]-[A]-SLEW (Lead+Trail Selection) \nto accept an IM Clearance. This triggered the automation to activate and display, as \nappropriate, the IM PA monitoring tools, including changing the Status field in the IM Spacing \nList to Active. To terminate an IM operation, Final or Monitor controllers used the STARS \nkeyboard keystroke sequence [MULTI FUNC]-[T]-[T]-SLEW (Trail Selection). This removed the IM \nPA information from the radar display and changed the Status field in the IM Spacing List to \nTerminated. The text in the IM Spacing List was colored based on the status: white if eligible, \ngreen if active, and yellow if terminated. viii\n The proposed IM PA pairs consisted of a variety of weight categories and initial spacings. An IM \nPA feasibility check was assumed to prevent the automation from proposing pairs for IM PA \nthat arrive outside of the initial spacing window and thus are unlikely to remain within the \nsafety limits. It was not assumed, however, that this check was sufficient to predict all possible \ninfeasible operations. For example, scenarios included off-nominal conditions in which IM PA \noperations were proposed where an IM Trail Aircraft arrived near the CSL at the start of the \napproach and subsequently could not slow down quickly enough to remain behind the CSL. As this list would likely be the same across the Feeder, Final, and Monitor controller positions, \neligible IM PA pairs were displayed before they entered the Final controllers area. It was \nassumed that any flight crew rejection of the initial Partial IM Clearance message would \nhappen in feeder airspace. Therefore, Final controllers could assume that eligible pairs \nappearing on the IM Spacing List had already accepted the Partial IM Clearance. Data Block Display of IM Status and CSL and WSL Values5.2.3\nThe data block provided an indication of the IM Trail Aircraft and IM Lead Aircraft IM Status to \nthe controllers and was incorporated into the data blocks similar to Bone & Mendolia (2018). \nFor the IM Trail Aircraft, a T(E) symbol in Line 3 indicated a proposed IM Clearance (Trail \nEligible), as shown in Figure 4-8. A T(A) symbol indicated an active
IM Trail Aircraft (Trail Active). \nFor the IM Lead Aircraft, L(A) indicated an active IM Lead Aircraft (Lead Active) as shown in \nFigure 4-9. Figure 4-8. IM Trail Aircraft IM Status Figure 4-9. IM Lead Aircraft IM Status ix\n The data block also was able to display CSL and WSL distance, which provided controllers with a \nnumeric indication of the distance from the IM Trail Aircraft to each safety limit. In cases where \na WSL was not yet active, the data block indicated whether it would eventually apply to the \naircraft pair by displaying a W with no corresponding numeric value. Figure 4-10 provides an annotated representation highlighting the CSL and WSL elements in the \ndata block. Figure 4-11 shows the data block elements as displayed on the controllers screen \nduring the simulation. In summary, the data block line 3 information elements included the \nfollowing four items: In the first field, the IM Trail Aircraft Status was displayed.1. In the second field, the distance to the CSL (in NM) was displayed, coded with a C.2. In the third field, when a WSL applies to that pairing, the distance to the WSL (in NM) is 3.\ndisplayed, coded with a W. Before the WSL applies in these cases, only the W was \ndisplayed as a pre-active WSL indication. If no WSL applies to that pairing, only the IM Trail Aircraft Status and CSL distance value 4.\nare displayed. Figure 4-10. Annotated Display of CSL and WSL Data Block Elements Figure 4-11. Data Block Elements, as Displayed in the HITL As described in Section 4.5.4, the Data Block Distances to the CSL and WSL were investigated as \nan independent variable. They were either turned on or off for the Monitor controllers, \ndepending on the scenario. x\n Line Representing the CSL5.2.4\nA line was introduced on the display to provide a graphical indication of the minimum limit of \nthe PA separation standard which, for the HITL, was set to the CSL value. Controllers ensured \nseparation by keeping the IM Trail Aircraft behind this line. The CSL was represented by a cyan \nline on the IM Trail Aircrafts path as depicted in Figure 4-12, and moved with the IM Lead \nAircrafts progression along its path. The CSL line represented the values shown in Figure 4-6. Figure 4-12. Cyan Line Representing the CSL Line Representing the WSL5.2.5\nA second line was introduced on the display to provide a graphical indication of the maximum \nlimit of the PA separation standard which, for the HITL, was set to the WSL value. Controllers \nensured separation and wake protection by keeping the IM Trail Aircraft forward of this line. \nThe WSL was a cyan line on the IM Trail Aircrafts path as shown in Figure 4-13, and moved with \nthe IM Lead Aircrafts progression along its path. When a WSL was applicable, it became active \nwhen the lead was 2 NM from the runway as shown in Figure 4-6. Figure 4-13. Cyan Lines Representing the CSL and WSL xi\n WSL Preview Line 5.2.6\nWhen a WSL applied to an aircraft pair, it was only active for the last 2 NM of the final. \nTherefore, to avoid surprising controllers with a sudden display of the WSL, it was hypothesized \nthat it would be useful to provide controllers with an advance indication that a WSL would \neventually apply and its relative location at that time to the IM Trail Aircraft. Therefore, a WSL-P \nwas implemented to provide an advance indication of where the WSL will appear when it \nbecomes active. It was represented by a grey line at the location where the WSL would \neventually appear, as shown in Figure 4-14. Figure 4-14. Grey WSL-P Although a WSL shape could theoretically change over the course of an IM PA operation, only \none preview limit was displayed during the simulation to represent the initial wake separation \nlimit that would come into effect. The behavior of the WSL-P remained continuous as it \ntransitioned to reflect the compression of the aircraft pair. When the WSL became a \nrequirement, the display then changed to the active state symbology (i.e., the cyan WSL line \ndescribed in Section 4.2.5). During its development, at least two potential issues were identified with the WSL-P that \nneeded additional investigation. First, it does not indicate when a WSL would become active; it \nonly indicates that at some point a WSL will become active. Second, at greater groundspeed \ndifferentials between the IM Trail Aircraft and IM Lead Aircraft, the WSL-P can first appear in \nfront of the IM Trail Aircrafts current position. Then, as the IM Trail Aircraft caught up, it \ncrosses over the WSL-P. It is possible that this may prove confusing and undesirable to \ncontrollers and was therefore included in the scenarios. In the HITL, the WSL-P was first displayed when the IM Trail Aircraft was approximately seven \nNM from the runway threshold. Therefore, the WSL-P was not expected to be useful for the \nFinal controller. As described in Section 4.5.4, the usefulness and acceptability of the WSL-P was \ninvestigated as an independent variable and it could thus be turned on or off for the Monitor \ncontrollers, depending on the scenario. Longitudinal Alerting5.2.7\nAs noted in Section 2.3.2.2, ATPA Phase 1 alert timing served as a foundation for the \ndevelopment of the IM PA alerting. The objectives of the IM PA alerts were to indicate to the \ncontroller when: 1) an IM Trail Aircraft was potentially at risk of encroaching on either of the xii\n 8 The terminology for these alerts is consistent with those used for ATPA. These are, however, departures from industry \nstandard definitions for Caution and Warning, in which a Caution is only an advisory and a Warning requires an action. safety limits, and 2) when the controller must take an action (e.g., aircraft breakout) to maintain \nseparation. Two levels of longitudinal alerting were implemented in the simulation: A Predictive Alert was displayed in yellow when crossing a limit boundary was predicted 1.\nto occur within <X> seconds. Here, the controller may still have had time to intervene by \ncontacting the aircraft and confirming that the flight crew was still following the IM \nSpeeds. This was a situation awareness advisory and controller action was not required. A Caution Alert was displayed in orange when a limit boundary would be crossed within 2.\n<Y> seconds. When receiving this alert, the controller was required8 to break out the IM \nAircraft and establish an alternate form of separation. The two alerts shared the same logic; only the timing values were different. The default \nPredictive / Caution alert timings were the same as those implemented for ATPA: 45 seconds \nand 24 seconds, respectively. Alternate Timings investigated in the HITL included: 35 seconds / \n20 seconds and 25 seconds / 15 seconds. This was intended to examine whether lower alert \ntimings than those chosen for ATPA remain acceptable to controllers for the IM PA monitoring \ntask. Reduced timings may ultimately be used to mitigate against nuisance alerts (which would \noccur more frequently with greater timings). Prior to the HITL, training emphasized that the predictive advisories do not necessarily require \nan action and that controllers should not break out aircraft prematurely to avoid one. The alerts \napply to both the CSL and WSL, and it was possible to receive a WSL alert before the WSL was \nactive as described in Figure 4-15. Figure 4-15. Predictive Alerting Logic xiii\n Figure 4-16 provides an example of the default alert timing distances. In the figure, the CSL and \nWSL are illustrated for operations inside 2 NM from the threshold. The CSL alert distances are \nbased on a hypothetical 30 knots (kt) faster trail aircraft. The WSL alert distances are based on a \nhypothetical 10 kt faster Lead Aircraft. The Predictive Alert Timing is 45 seconds and the Caution \nAlert Timing is 24 seconds. Figure 4-16. Default Alert Timing Distance Example The alerts were active with respect to both the CSL and WSL. When the alerts were triggered, \nthe CSL or WSL display, and the CSL/WSL Data Block Distance value (if displayed) changed color \naccording to the level of alert and which limit was being encroached upon. Figure 4-17 depicts the IM PA Predictive Alert relative to the CSL. The CSL display and Data Block \nDistance value are color-coded yellow to indicate the Predictive Alert state. Figure 4-17. IM PA Predictive Alert Relative to CSL Figure 4-18 depicts the IM PA Caution Alert relative to the CSL. The CSL display and Data Block \nDistance value are color-coded orange to indicate the Caution Alert state. xiv\n Figure 4-18. IM PA Caution Alert Relative to CSL Some scenarios involved the use of a 4:1 FMA display for IM PA monitoring in a simulated \nFUSION mode which provides a one-second update rate. Figure 4-19 shows a Predictive Alert \ndepiction on this display, relative to the CSL. The figure also depicts the Lateral Boundaries, \nwhich are described in Section 4.2.8. Note also that the controller is using the (optional) STARS \nbats to track aircraft ground tracks relative to the
approach paths and to quickly detect \ndeviations. Figure 4-19. Predictive Alert Depiction on the 4:1 FMA Display Relative to the CSL Lateral Boundaries and Exceedance Warning5.2.8\nThe lateral monitoring task and associated procedures and requirements for IM PA operations \nare still in the early stages of development. As described in Section 2.4.2, Mendolia, et al. (2016) \nexamined a lateral deviation monitoring task with a custom-designed NNZ, based on an NTZ, \nand associated caution and warnings. Its purpose was to assist aircraft in avoiding wake \nencounters as it assumed that collision protection was afforded by keeping aircraft aft of the \nCSL. The lateral monitoring task, however, evolved for the current HITL due to the new IM PA \nrequirement that controllers are responsible for separation and therefore must be able to xv\n monitor the operation relative to a clear separation standard. As described in Section 4.2.1, the \nPA separation standard for the HITL was defined by the CSL and WSL. It was thus assumed that \ncontrollers needed to know how much lateral deviation was permitted before the limits were \nno longer valid. If either aircraft then deviated beyond those values in either direction (left or \nright), PA separation would no longer apply and another form of separation would be required. \nThe lateral monitoring task was therefore different from that in Mendolia, et al. (2016) and the \nNNZ and alerting design needed to be reconsidered to help controllers determine whether \nobserved lateral flight path deviations were within the allowable normal variability, or whether \nthey were large enough to render the CSL and WSL invalid. This section describes the design assumptions behind the Lateral Boundaries and Exceedance \nWarning as implemented. Procedures suggested to the controller participants for managing \naircraft deviations across any of these boundaries are described in Section 4.3. The Lateral \nBoundaries and procedures are notional constructs developed specifically for the HITL \nsimulation. Procedures and tools for managing IM PA operations across the range of possible \nlateral deviation geometries require further development. Lateral Boundary Configurations5.2.8.1\nDue to the revised lateral monitoring task, an inner and outer boundary is required for each \napproach path. To inform this work, the HITL examined two Lateral Boundary configurations \nbased on the navigation error assumed in deriving the CSL (Williams & Wood, 2017): A configuration based on the most constraining Total System Error (TSE) accommodation 1.\nfor current NTZ implementations for independent runway operations. This consists of a \n500 ft distance from the approach path to each boundary, for both approaches. This was \nthe default condition and used during the Nominal (Section 4.5.5.1) and Alert Timing \nscenarios (Section 4.5.5.2). A configuration that assumes the 500 ft TSE for 28R (as with Configuration #1), and three 2.\ntimes the standard deviation of TSE assumed by Volpe in the wake research for the ILS \n28L approach (unpublished). This configuration was examined only during the Lateral \nDeviation scenarios (Section 4.5.5.3). The boundaries for both configurations extended from the start of the approach (15 NM final) \nto approximately 2 NM from the runway threshold. Inside of 2 NM, a deviation allowance of 75 \nft was assumed. As boundaries at that distance are not realistically distinguishable from the \napproach path centerlines on the radar display, no attempt was made to display them. \nTherefore, from 2 NM to the runway, the controller task was to monitor deviations by ensuring \nthe center of the target symbol remained on the approach path centerline. Unlike the NNZ \ndescribed in Mendolia, et al. (2016), the Lateral Boundaries could not be toggled on or off or \nchanged in brightness. For the Lateral Deviation scenarios, this lateral monitoring task was \nevaluated against both the standard 1:1 STARS display and a 4:1 FMA display. Both operated in \na simulated FUSION mode with a one-second surveillance update rate. Configuration #1, with 500 ft for both runways, was used for all HITL scenarios except for some \nDay 3 Lateral Deviation cases. A scaled depiction of the lateral boundaries for this configuration \nis illustrated in Figure 4-20. xvi\n Figure 4-20. Scaled Depiction of Lateral Boundaries for Configuration #1 xvii\n Figure 4-21 shows a scaled representation of the Lateral Boundaries in TARGETS with the \nelements labeled. Figure 4-22 contains scaled depictions of the Lateral Boundaries for \nConfiguration #1 as implemented in the simulation. Figure 4-21. TARGETS Depiction of Configuration #1 Figure 4-22. Configuration #1 on Standard STARS Display Configuration #2 (500 ft for 28R and ILS for 28L) was examined in some of the Day 3 Lateral \nDeviation scenarios. A scaled depiction of the lateral boundaries for this configuration is \nillustrated in Figure 4-23. xviii\n Figure 4-23. Scaled Depiction of Lateral Boundaries for Configuration #2 xix\n Figure 4-24 shows Configuration #2 on the standard STARS display. Figure 4-25 shows how \nConfiguration #2 appeared on the 4:1 FMA display. Figure 4-24. Configuration #2 on Standard STARS Display Figure 4-25. Configuration #2 on the 4:1 FMA Display Lateral Boundary Exceedance Warning5.2.8.2\nUnder nominal conditions, the Lateral Boundary outlines were depicted in white on the display. \nWhen an aircraft crossed either of its respective boundary lines, an Exceedance Warning was \npresented to the controller. This consisted of two elements: 1) the inboard or outboard \nboundary line that was crossed turned red, then 2) a lateral LAT indication was displayed in \nthe deviating aircrafts data block line 0, similar to the zone alert text string indications in \nMendolia, et al. (2016). Unlike in the prior study, it did not flash while active nor did the entire \ndata block change color on the FMA display to indicate the alert. When a lateral deviation occurred, the IM PA operation automatically terminated and the \nrelated IM PA display features (other than the Lateral Boundaries) were removed. The Lateral \nBoundary line remained red until the deviating aircraft was greater than 3000 ft past it. The line \nthen returned to its former white color. Arrival aircraft not involved in IM PA operations would \nnot trigger the Exceedance Warning. Figure 4-26 illustrates an Exceedance Warning for United \n(UAL) 748 crossing the inboard Lateral Boundary. The 28L Inboard Boundary is red, and a red \nLAT is displayed in Line 0 of its data block. xx\n Figure 4-26. Exceedance Warning for UAL748 Crossing Inboard Lateral Boundary Controllers could use existing STARS tools such as the PTLs and ground track bats to help detect \nlateral deviations on both the STARS and FMA displays. Figure 4-27 shows how PTLs appeared \nagainst the lateral boundary on Configuration #2 (500 ft for 28R and ILS for 28L) on the FMA \ndisplay. In this scenario, UAL12 has just begun an outboard deviation but has not yet crossed \nthe boundary. Figure 4-27. PTLs on Configuration #2 on the FMA Display Figure 4-28 shows ground track bats on Configuration #2 (500 ft for 28R and ILS for 28L) on the \n4:1 FMA display. Figure 4-28. Heading Bats on Configuration #2 on the FMA Display xxi\n Figure 4-29 and Figure 4-30 show a lateral inboard deviation by an IM Lead Aircraft, UAL748, on \nthe 4:1 FMA display when ground track bats were active. In the former, UAL748 started the \ndeviation but has not yet crossed the boundary. In the latter, UAL748 has crossed the boundary, \ntriggered the Exceedance Warning, and had its IM PA display information automatically \nremoved. Figure 4-29. Start of UAL748 Deviation, Before Crossing the Inboard Lateral Boundary Figure 4-30. UAL748 Crossing the Inboard Lateral Boundary As with the zone warnings described in in Mendolia, et al. (2016), the Exceedance warning only \nappeared when an aircraft crossed one of the boundaries. There was no Predictive Alert \ncapability for lateral deviations. Unlike the three different zone warnings shown in Figure 2-12, \nthe current study design only involved a single Exceedance Warning for the entire length of the \napproach. This was because of the changes to the monitoring task as described in the beginning \nof Section 4.2.8. Scenarios5.3\nThis section provides an overview of the simulation scenarios, including the setup assumptions, \nairspace, and traffic flows. IM PA Setup and Simulated Airspace5.3.1\nEach traffic scenario consisted of streams of arrival aircraft to SFO 28L and 28R parallel runways \n(see Figure 2-8). The flows contained a mix of aircraft separated via the PA and Single Runway xxii\n Spacing (SRS) standards. Wake turbulence RECAT separation standards (FAA, 2016) were \napplied and are discussed in more detail in Section 4.3.3. Based on current airspace and RNAV procedures at SFO, a significant amount of vectoring would \nbe needed to support the IM PA operation being evaluated in this HITL simulation. Aircraft \nlanding on 28L generally approach the final approach course from the south, following vectoring \nfrom Boulder. These final sectors reach only to 5000 ft mean sea level. Most aircraft operating \ninto SFO will be above that altitude and therefore under the control of an overlying sector when \nthey enter the lateral extent of the sector. It is typically not until the aircraft nears the final \napproach course that they descend into Final controller airspace. However, the simulation was not scoped to examine IM PA setup in feeder airspace. The initial \npositioning of the aircraft in the
arrival stream was therefore assumed to have been \naccomplished at the start of each scenario, before the aircraft arrived in the participant \ncontrollers airspace. The HITL did not take a position on whether this initial spacing was \naccomplished manually or with metering, a separate (non-PA) IM operation, or some other \nmeans. The simulation used RNAV routes, as depicted in Figure 4-31, to ensure that aircraft were \ndelivered to the final approach courses in a consistent, reproducible manner. The aircraft \nentered Final controller airspace on modified base legs, approximately 25 NM from the runway, \nwith the desired initial spacing, and separated in altitude by 1000 ft. A lengthened, straight-in \nRNAV arrival to runway 28L was designed to allow aircraft pairs to enter Final controller \nairspace having been already established on extended final. IM Trail Aircraft joined a (new) \nRNAV procedure to 28R that included a 3-degree angled offset joining the final at 0.5 NM. IM \nLead Aircraft turned to join the Instrument Landing System (ILS) to 28L. These procedures were \ndeveloped for the HITL and are not currently in place at SFO. However, they may approximate \nprocedures for a future metering environment. Figure 4-31. Simulation Airspace and Extended Arrivals Traffic and Arrival Flows5.3.2\nAll aircraft in the simulation were equipped with ADS-B Out and were thus capable of acting as \nIM Leads. Aircraft types in the simulated traffic flow were similar to those in Mendolia, et al. \n(2016) and included: Airbus A319, Airbus A320, Boeing 737-700, Boeing B737-800, Boeing xxiii\n 9 At the time of the experiment, it was thought that controllers should wait to receive flight crew acceptance of the IM \nClearance before changing the IM PA status in the automation. This was intended to ensure that they would not change the \nstatus but then forget to give the IM Clearance in case of distraction. The HITL used this procedure; however, it should likely \nbe modified based on results described in Section 5.3. 747-400, Boeing 747-800, Boeing 757-200, Boeing 767-300, B777-200, B777-300ER, CRJ-200, \nand CRJ-700. The 28L approach consisted of mostly heavy category aircraft such that WSLs \nwould often be required. The simulated final approach speeds were appropriate set to the \ntypes, but were varied in each scenario. Aircraft liveries were primarily domestic, but also \nincluded some international carriers. Aircraft were vertically separated when established on the extended final. At that point, the \nFinal Approach controller provided the Assigned Spacing Goal and received flight crew \nacceptance. This initiated the IM PA operation and the controller then activated the IM PA \noperation via the automation9. PA Separation could then be applied. The Final Approach \ncontroller then gave the approach clearance and the IM Trail Aircraft could start descending. \nControllers then monitored the IM PA operation and non-IM PA traffic (using Wake Turbulence \nand MRS minima discussed in Section 4.3.3) until landing. The SFO traffic flows developed for \nthe HITL are depicted in Figure 4-32. Figure 4-32. SFO Traffic Flows used in the HITL The SFO arrival traffic in the HITL generally consisted of: \n50% of total traffic from the east (DYAMD3 28R).\n25% of total traffic from the north (BDEGA2 28L).\n20% of total traffic from the south (SERFR2 28L).\n5% of total traffic from the ocean (PIRAT 28L). xxiv\n In addition, SFO departures occurred via 1L/1R (10 for the scenario).\nSome Oakland International Airport (OAK) arrival and departure traffic was also included: Arrivals to runway 30 (approximately 16 for the scenario).\nDepartures to the north and east (approximately 15 for the scenario). San Jose International Airport (SJC) arrival and departure traffic was also included:\nDepartures to the northeast.\nArrivals to 30R. Wake Turbulence and Minimum Radar Separation5.3.3\nWake Turbulence and MRS was required for aircraft on same and adjacent approach courses. \nThe participants in the HITL were instructed to follow Wake RECAT On Approach separation \nminima by aircraft category (FAA, 2016), and were provided the separation minima shown in \nTable 4-1. Table 4-1. FAA JO 7110.659C Wake Turbulence Separation on Approach Follower A B C D E F L\ne\na\nd\ne\nr A 5 NM 6 NM 7 NM 7 NM 8 NM\nB 3 NM 4 NM 5 NM 5 NM 7 NM\nC 3.5 NM 3.5 NM 6 NM\nD 4 NM\nE\nF MRS is 3 NM for terminal operations and applies to pairings for which Table 4-1 does not specify \nwake turbulence separation. As an example, Figure 4-33 depicts the Wake RECAT and MRS \nseparations that apply for the specified aircraft categories. In the HITL, 2.5 NM separation within \n10 NM of the runway was allowed as it is in use in several facilities in the NAS (though not at \nSFO). Figure 4-33. Application of Wake RECAT and MRS Standards The aircraft types used in the scenarios correspond to the aforementioned categories and are \nshown in Table 4-2. xxv\n 10 Not every scenario included staffing the Final Controller position with a participant. See Section 4.5.6. Table 4-2. Aircraft Types and Categories in HITL Scenarios B C D E\nB772/W B763 B737/8 CRJ2/7 A346 A319\nA332 A320 B744/8 B752 Operational Chronology Summary5.3.4\nThe following five series of non-simulated events were assumed to have occurred prior to the \nstart of the scenarios: For pairing compatibility and spacing goal computations, ground automation was made 1.\naware of the final approach speeds for each aircraft. IM PA pairs were identified, and spacing goals were computed by automation.2. An IM Spacing List was generated to represent the pairing and spacing goal information. 3.\nAircraft pairs were added and removed, along with their associated information, at the \nappropriate times. The first part of the IM Clearance was provided in feeder airspace. The Assigned Spacing 4.\nGoal, however, was withheld. It was assumed that any flight crew rejection of the initial Partial IM Clearance 5.\nmessage would happen in feeder airspace. If that occurred, the Feeder Controllers \nwould remove those aircraft from the IM Spacing List and they would therefore not be \npresented as IM PA candidates on the IM Spacing List. After the non-simulated events were completed, the following six events in the operational \nchronology were simulated and evaluated: A list of proposed IM PA pairs and related information (via the IM Spacing List) was 6.\ndisplayed to the Final Approach controllers10. As the aircraft entered the final sectors and were established on their extended final 7.\napproach courses, the Foster (28R) Controller consulted the IM Spacing List and \nprovided the Assigned Spacing Goal to the IM Trail Aircraft. Altitude separation was then \nno longer required. The IM Trail Aircraft flight crew accepted the Assigned Spacing Goal and entered it into 8.\ntheir FIM Equipment. The controller assumed the operation then began; the IM Trail \nAircraft started following its IM Speeds. The Final Approach controllers cleared the aircraft for their approaches and instructed 9.\nthem to change to the Local controller frequency. The IM Trail Aircraft followed the IM Speeds until reaching the FAF, at which point 10.\nnominal termination occurred. The Monitor controller(s) monitored the IM PA pairs until the IM Lead Aircraft crossed 11.\nthe runway threshold. xxvi\n Controller Roles, Responsibilities, and Procedures5.4\nController participants had two primary tasks in the simulation: 1) initiate IM PA operations and \n2) provide separation on final, including for IM PA and non-IM PA aircraft. The specific positions \nand tasks for each are detailed in the following sections. The simulation also used confederates \nas Local controllers; their responsibilities in the HITL are also described in this section. IM PA Initiation and Final Approach Controller Tasking5.4.1\nAs described in Section 4.3.4, before an arriving IM Trail Aircraft entered the Final controllers \nairspace, it will have been provided a Partial IM Clearance by the Feeder Controller to allow the \nflight crew to prepare the FIM Equipment for the operation. Therefore, the Final controller only \nneeded to provide the Assigned Spacing Goal to clear the aircraft to begin the IM PA operation. The 28R Final controller was the only position that could issue the Assigned Spacing Goal to \ncomplete the IM Clearance. Using the information provided via the IM Spacing List, the 28R \nFinal controller completed the Partial IM Clearance after the IM Trail Aircraft entered their \nairspace. Upon receipt of the Assigned Spacing Goal, the IM Trail Aircraft was able to begin the \nprocedure. Therefore, the Assigned Spacing Goal and clearance for the instrument approach \nhad to be provided before the IM Trail Aircraft joined its glideslope. Participants were allowed \nto provide the Assigned Spacing Goal before, after, or as part of the final approach clearance. As the IM PA operation begins as soon as the Assigned Spacing Goal is provided, the 28R Final \ncontroller also had to ensure that the IM Trail Aircraft remained behind its CSL until transfer to \nthe Local controller. If the IM Trail Aircraft was forward of the CSL at the time of initiation, the \nFinal Approach controller was instructed to cancel the IM Clearance and establish alternate \nseparation. The suggested procedure was to put the 28R aircraft on a 280 heading and transfer \nit to TRACON Departure (SUTRO), but participants were told they had full discretion to resolve \ndeveloping separation problems as they saw fit. The tasking for Final Approach controllers varied
based on the runway they were working. In the \nHITL, the 28L Final controller position was not staffed by a participant; the HITL automation \nmanaged the arrivals and frequency changes for arriving aircraft. Still, tasking for the 28L Final \ncontroller position needed to be identified. The 28L Final controller was responsible for the following tasks: Accept 28L handoffs from Feeder Controller.\nProvide 28L traffic with approach clearances.\nIssue 28L traffic frequency change to Local controller at approximately 15 to 20 NM. The 28R Final controller had initiation and monitoring responsibilities related to the IM PA \noperation and had access to the following tools: IM Spacing List, Data Block Distances, and the \nCSL when PA is initiated. The 28R Final controller was responsible for the following tasks: Accept 28R handoffs from Feeder Controller.\nProvide 28R traffic with approach clearances.\nView IM Spacing List and provide 28R traffic with Assigned Spacing Goal at the xxvii\n appropriate time.\nIndicate proposed IM Clearance acceptance, rejection, or termination in the IM Spacing \nList.\nEnsure the IM Trail Aircraft remains behind the CSL from the time the Assigned Spacing \nGoal is issued to when the aircraft has transferred to the Local controller frequency.\nIssue frequency change to 28R traffic to Local controller at approximately 15 to 20 NM. Local Controller Position Tasking5.4.2\nStaffed by confederates in the HITL, Local (Tower) Controllers were necessary to provide \nlanding, takeoff, and other clearances as necessary for SFO arrival and departure traffic. They \nprovided a steady stream of communications that the controller participants, serving as Monitor \ncontrollers, could hear. Though the confederate Local controllers issued landing clearances, \nthey were not responsible for aircraft separation along the final approaches. IM PA monitoring in both combined and separate Local controller configurations was examined. \nThe Combined Monitor configuration employed a single Local controller who issued landing \nclearances for both 28L and 28R runways. The Separate Monitor configuration involved \nseparate Local controllers, one for each arrival runway, and had split responsibilities. The \ntasking for the confederate Local controllers for each configuration is described below. Combined Local controller configuration: Provide landing clearances to arriving 28L/28R traffic.\nProvide takeoff clearances to aircraft on 1L/1R.\nProvide other clearances, such as runway crossings, as needed. Separate Local controller configuration: 28L Local controller\nProvide landing clearances to arriving 28L traffic.o 28R Local controller\nProvide landing clearances to arriving 28R traffic.o\nProvide takeoff clearances for aircraft on 1L/1R.o\nProvide other clearances, such as the 28L runway crossing, as needed.o IM PA Monitoring and Monitor Controller Tasking5.4.3\nAlthough the Final Approach controller ensured that the IM PA operations began with the IM \nTrail Aircraft behind the CSL, the Monitor controller(s), assisted by IM PA display features and \nalert automation had separation responsibility for the majority of the approach. The general \nmonitoring task and procedures for both longitudinal (along track) and lateral deviations is \ndescribed below, followed by specific Monitor controller responsibilities and procedures as \nconveyed to the participants. Longitudinal Monitoring Procedures5.4.3.1\nAs described in Section 4.2.1, controllers were informed that an IM Trail Aircraft was safely xxviii\n 11 The controller procedures for managing aircraft deviations across any of the Lateral Boundaries were notional constructs \ndeveloped specifically for the HITL simulation. Actual procedures accounting for the range of possible lateral deviation \ngeometries require further development. separated while it remained within the safety limit(s). Controllers were alerted if an aircraft \nbegan to encroach on either of the safety limits. Depending on the alert, the procedures to \nresolve the situation and ensure separation are as described in Section 4.2.7. These consisted \nof: Predictive (yellow) CSL or WSL Alert: Monitor the situation, be prepared to take action. If \ndesired, can optionally confirm IM PA equipment status with IM PA aircraft.\nCaution (orange) CSL or WSL alert: Break out the trail aircraft. Lateral Monitoring Procedures5.4.3.2\nAs described in Section 4.2.8, Lateral Boundaries were implemented to help controllers \ndetermine whether observed flight path deviations were within design bounds for normal \nvariability, or whether they constituted a situation beyond what the CSL and WSL were designed \nto accommodate. Research with respect to lateral deviations during an IM PA operation is still in its early stages. \nThus, in the design of the lateral deviation monitoring task and response procedures, the HITL \nmade assumptions based on work done to date. An analysis of over 1.8 million recorded \napproach paths suggests that flight path deviations on approach are rare; 82 were found, for a \nrate of 4.47x10-5 (Eckstein, Massimini, McNeill, & Niles, 2012). Of those, 42 involved a deviation \nangle of 10 degrees or more. The remainder involved a deviation angle of less than 10 degrees. \nThe impact on spacing, separation and wake turbulence avoidance of a potential protracted \nshallow angle deviation during a PA operation is not fully understood. However, the safety limits \nare designed using assumptions about the nature of TSE with respect to lateral course tracking \n(Williams & Wood, 2017). Flight path deviations in excess of the assumed TSE invalidate the \nprotections that the CSL and WSL provide. It may therefore become necessary to break out one \nor both IM PA Aircraft in response to some flight path deviations, not just to terminate IM PA, \nbut also to manage collision and wake turbulence risk within the IM PA pair. This may especially \nbe the case for an inboard deviation by the IM Lead Aircraft. The HITL simulation assumed that outboard deviations by either aircraft beyond what the CSL \nand WSL have been designed to accommodate result in the end of the IM PA operation and the \nneed to establish an alternate form of separation. However, the safest course of action in these \ncases is probably for the non-deviating aircraft of the pair to continue on the approach. An \ninboard deviating IM Trail Aircraft, in either direction, should not be in a position to affect the \nIM Lead Aircraft. Based on this, controllers were provided three procedures11 two with respect to IM Lead Aircraft \nlateral deviations, and one with respect to an IM Trail Aircraft lateral deviation. They were not \nrequired to take action until the Lateral Boundary Exceedance Warning was triggered. IM Lead Inboard Deviation: If the IM Lead Aircraft deviates to the right and crosses its 1.\ninboard lateral boundary, advise the IM Trail Aircraft that the IM PA operation is over, \nissue a go-around procedure to the IM Trail Aircraft, and manage the IM Lead Aircraft \nper standard operating procedures. xxix\n IM Lead Outboard Deviation: If the IM Lead Aircraft deviates to the left and crosses its 2.\noutboard lateral boundary, do not break out the IM Trail Aircraft. Terminate the IM PA \noperation, establish an alternate form of separation, and manage the resolution per \nstandard operating procedures. IM Trail Deviation: If the IM Trail Aircraft deviates laterally and crosses either boundary, 3.\ninboard or outboard, the IM PA operation ends. The controller leaves the IM Lead \nAircraft on the approach, advises the IM Trail Aircraft that the procedure has ended, and \nmanages the deviating aircraft per standard operating procedures. Controllers were given the following guidance for breakouts, but were told they had full \ndiscretion to resolve developing separation problems as they saw fit: For the left aircraft, the controller was to climb them to an altitude of their discretion, \nput them on a 260 heading, and transfer them to Departure (SUTRO). \nFor the aircraft on the right, the controller was to climb them to an altitude of their \ndiscretion, put them on a 280 heading, and transfer them to Departure (SUTRO). Monitor Controller Position Tasking5.4.3.3\nAs described earlier, this HITL examined IM PA monitoring with respect to both Combined and \nSeparate Monitor configurations. The specific tasking for each configuration is outlined below. Combined Monitor configuration: Monitor the Local controllers frequency.\nIssue speed instructions to aircraft as needed to provide required separation. For an IM PA pair, any speed instructions should be given to the IM Lead Aircraft. o\nSpeed instructions given to the IM Trail Aircraft terminate the IM PA operation.\nBreak out any aircraft as needed to ensure separation.o\nIf breaking out a Lead Aircraft, terminate IM PA operation with the trail aircraft.o Use the display features to monitor the IM PA operation and provide separation.\nIssue control instructions as needed to keep the IM Trail Aircraft from violating the o\nWSL and CSL. Terminate IM PA operation in the event of a lateral deviation by either aircraft.\nIn this configuration, the Monitor controller had the following tools available: CSL, WSL, WSL-P, \ndata block additions, Alerting, and Lateral Boundaries. Separate Monitor configuration: 28L Monitor Controller: Monitor the 28L Local controllers frequency. Provide separation \nbetween (not within) IM PA pairs by providing speed assignments to 28L aircraft, \nincluding the IM Lead Aircraft, if needed.\n28R Monitor Controller: Monitor the 28R Local controllers frequency. Provide separation \nwithin IM PA pairs by taking action if a safety limit is about to be exceeded. \nBoth controllers had the following tasks: xxx\n Monitor aircraft positions with respect to the lateral boundaries.o\nIntervene as needed to ensure separation is maintained.o\nApply (Wake RECAT) single runway separation to non-IM aircraft. o Both controllers had the following tools available: CSL, WSL, WSL-P, data block additions, \nAlerting, and Lateral Boundaries. IM PA Termination5.4.4\nThe Monitor and
Local controllers were made aware that IM Speeds were only provided up to \nthe IM PTP, which was co-located with the FAF. The Assigned Spacing Goal would have been \ncalculated to ensure separation was maintained during compression between the FAF and \nrunway. However, the Monitor controller(s) still had to monitor with respect to the safety limits \nuntil the IM Lead Aircraft crosses the threshold. WSL monitoring was no longer needed once the \nIM Lead Aircraft crossed its runway threshold. All IM PA monitoring tools, including alerting, \nwere suppressed at this point. Under nominal IM PA operations, flight crews were not required \nto inform controllers that they were no longer following IM Speeds as they crossed the PTP/FAF. Simulation Phraseology5.4.5\nThe HITL assumed that Feeder Controllers informed the aircraft which approach to expect and \nprovided the initial communication as part of a Partial IM Clearance. Therefore, the simulation \nphraseology was only applicable to the (28R) Final controller and Monitor position(s). \nParticipants were provided the phraseology below to use during the experiment. Non-IM PA Aircraft Approach Clearance:\nFinal Controller: Aircraft 123, maintain 6000 until established. Cleared RNAV 28R \napproach. Partial IM Clearance Assigned Spacing Goal Message:\nFinal Controller: Aircraft 123, spacing goal [x] seconds behind Aircraft 456. IM Trail Aircraft Approach Clearance:\nFinal Controller: Aircraft 123, cleared RNAV PAPA 28R approach. IM PA Off-Nominal Termination, Flight Crew Unable:\nAircraft 123: ATC, unable interval spacing.\nATC: Aircraft 123, terminate interval spacing. [Instructions] IM PA Off-Nominal Termination, Controller Initiated:\nATC: Aircraft 123, terminate interval spacing. [Instructions] Experimental Design5.5\nThis section describes how the HITL experiment was conducted, including detailed research \nobjectives, participants, traffic files, scenario matrices, and the run order and data collection \nstrategy. xxxi\n Objectives5.5.1\nBased on the research questions and hypotheses described in Section 3.3, the experimental \ndesign addressed the following seven objectives: Examine overall acceptability of monitoring nominal IM PA operations, in both 1.\nCombined and Separate Monitor configurations. Examine acceptability of the following IM PA Tools: IM Spacing List, Data Block IM 2.\nStatus, CSL/WSL Line Displays, Predictive and Caution Alerts, Lateral Boundaries and \nExceedance Warning. Examine usefulness of potentially optional IM PA tools: WSL-P and Data Block Distance 3.\nto CSL/WSL display. Examine the effect of decreasing the alert timing values: ATPA Timing, plus two 4.\nadditional Timings. Examine the acceptability of the IM PA Tools with respect to two off-nominal conditions: 5.\nSpacing Loss, IM Lead Aircraft Deviations. Examine the impact of display type, monitor configuration, and Lateral Boundaries on 6.\nthe lateral monitoring task. Examine feasibility and acceptability of using Partial IM Clearance procedures to initiate 7.\nan IM PA operation. The design strategy to collect data to evaluate these is described in the following sections. Participants5.5.2\nParticipant controllers were coordinated through the FAA and National Air Traffic Controllers \nAssociation (NATCA) using standard procedures. Controllers were compensated for their \nparticipation through standard FAA processes. Twelve certified and current terminal area \ncontrollers with at least three years of experience in parallel runway approach operations were \nrequested. This included at least two from NCT per week, each with at least three years \ncertification in Area B. The request also asked that no one with prior MITRE PA simulation \nexperience should be included. Twelve currently certified controllers participated in the simulation. Four of the controllers were \nfrom NCT and had experience in the area being simulated (Area B). Eight of the controllers were \nfrom other terminal facilities with parallel runway approach operations. Including those from \nNCT, eight of the twelve participants were current TRACON Approach Controllers. Two of the \nparticipants were currently Tower controllers, but had TRACON experience. Due to a \nmiscommunication related to the request, two participants only had Tower experience. These \ntwo controllers were provided extra training on the separation tasking and their results were \nusually pooled separately. The TRACON controllers and Tower controllers with TRACON experience had an average age of \n37.1 years and on average actively controlled traffic for 13.75 years (with a minimum of 9 years \nand a maximum of 26 years). The two Tower-only controllers had an average age of 33.5 years \nand had controlled traffic for 8.5 and 11 years. xxxii\n There were four non-participant roles. Two pseudopilots controlled and responded as all \naircraft. Two confederate controllers served as Local controllers. Simulation Schedule, Procedures, and Controller Training5.5.3\nThe HITL was conducted over three weeks. Each week involved the four participant controllers \nparticipating in a 3-day simulation session. The schedule was based on a repeated-measures \nexperimental design, intended to maximize experimental power by having every participant \nexperience each experimental condition from each position. Each weekly session consisted of three self-contained experiments. The first, which occurred \nover Days 1 and 2, examined normal operations with combined versus separate Monitor \ncontrollers. The IM PA tools were also varied to examine their relative usefulness. The first day \nbegan with a pre-simulation briefing, which covered the PA concept, the simulation \nenvironment (i.e., airspace, traffic, separation, and other procedures), controller roles and \nresponsibilities (as described in Section 4.4), and the overall schedule and conduct of the \nsimulation. Controllers were also After that, controllers were brought into the lab and given a \npractice scenario that allowed them to familiarize themselves with the workstation and \nsimulation-specific procedures, including initiating, monitoring, and terminating IM PA. \nControllers were also provided a summary sheet with key procedures (such as responses to off-\nnominal conditions) and communications frequencies. Following the training, controllers started \nthe data collection scenarios. Day 2 started with a shortened training briefing that summarized the IM PA concept \ninformation from Day 1 and introduced new procedures for the roles the participants would be \nassuming that day. Controllers were again provided a practice scenario that allowed them to \nfamiliarize themselves with the new procedures and tasks. As with Day 1, controllers began the \ndata collection scenarios directly following the training. The third day of each session consisted of two separate, self-contained evaluations. The first, in \nthe morning, examined different longitudinal alert timing values. The second, in the afternoon, \ntook an initial look at lateral monitoring and introduced IM Lead Aircraft and IM Trail Aircraft \ndeviations that exceeded the Lateral Boundaries. Each evaluation was preceded by a short \ntraining briefing that described the new aspects of the scenarios they would be working and \nreviewed key procedures. For the Alert Timing scenarios, controllers were informed what the \nnew alert values would consist of. For the lateral monitoring scenarios in the afternoon, \ncontrollers were reminded of the procedures to manage these off-nominal deviations. Training \nscenarios were not provided for either as the traffic and controller position configurations were \nthe same as they had already experienced in Days 1 and 2. Each run for all three days was followed by a short questionnaire asking for controllers to rate \ntheir experience in that scenario across a variety of metrics. A final questionnaire was provided \nat the end of Day 1 asking about their experience across all the scenarios they experienced that \nday. A different final questionnaire was provided at the end of Day 2 and consisted of two parts. \nThe first asked controllers to rate their experiences for only the scenarios they experienced on \nDay 2. A second part then asked controllers to rate their experiences across both Days 1 and 2. \nFor Day 3, in addition to the post-run questionnaires, final questionnaires were provided at the \nend of each of the two evaluations (i.e., Alert Timing and Lateral Deviations) asking them to rate xxxiii\n their experience across all the scenarios for that particular evaluation. A Day 3 final \nquestionnaire was also provided at the end of Day 3 which asked controllers to rate their \nexperiences across all the scenarios for all three days. After that, controllers were invited into a \nconference room for a discussion and debrief. Some questions were prepared to guide the \ndiscussion, but controllers were also invited to provide feedback on any topic or aspect of the \nsimulation they wished. As shown in the daily schedules in Figure 4-34, the four participants were divided into a Pair \nA and a Pair B for each of the three days. Each scenario involved only two participants at \na time. Therefore, two participants filled out their post-run questionnaires while the \nother two ran the scenario. Figure 4-34. Daily Schedules Independent Variables5.5.4\nIndependent variables were chosen to test the hypotheses described in Section 3.3 and the \nmore detailed research objectives listed in Section 4.5.1 including Number of Monitor \ncontrollers, selected PA Tools, alert timing values, and display type. The independent variables \nand associated levels of each are shown in Figure 4-35. xxxiv\n Figure 4-35. HITL Independent Variables and Levels For both the Day 1 and Day 2 Nominal scenarios and the Day 3 Lateral Monitoring and Deviation \nscenarios, the Number of Monitor controllers was varied as an Independent Variable. Some \nscenarios involved a single, Combined Monitor controller assuring separation for traffic arriving \nto both 28L and 28R. Other scenarios involved Separate Monitor controllers managing the \ntraffic only on their respective approach. For the Day 1 and Day 2 Nominal scenarios, the WSL-Display and the Data Block CSL/WSL \nDistance Display were made to be Independent Variables and were either
made available or \nremoved from the display, depending on the scenario. This was intended to examine whether \nthey were helpful or necessary for the controller IM PA monitoring task. The other IM PA tools \nsuch as the IM Spacing List, IM Status, CSL/WSL Lines, Alerts, and Lateral Boundaries features \nwere fixed. These were always available to participants, for every scenario. Day 3 for each session included a self-contained evaluation of the longitudinal alert timing \nvalues. As described in Section 4.2.7, the default Predictive / Caution alert timings were the \nsame as those implemented for ATPA: 45 seconds and 24 seconds, respectively. However, \nreduced timings may ultimately be used to mitigate against nuisance alerts (which would occur \nmore frequently with greater timings). Therefore, two additional alert timings were investigated \nin the HITL to examine whether lower alert timings than those chosen for ATPA remain \nacceptable to controllers for the IM PA monitoring task. These were: 35 seconds / 20 seconds \nand 25 seconds / 15 seconds, for the Predictive and Caution Alerts, respectively. To create a \nmore stressing condition, these scenarios only evaluated alert timing in the context of the \nCombined Monitor configuration. However, all of the IM PA-related tools described previously \nwere available to the Combined Monitor controller for these scenarios. Day 3 also took an initial look at lateral monitoring with deviations as a self-contained xxxv\n evaluation in the afternoon. This included determining to what degree will controllers want to \ndetect developing deviations before a Lateral Boundary is crossed, whether a 4:1 aspect ratio \nFMA display is needed, especially with only an Exceedance Warning (no Lateral Predictive Alert) \nwith a tighter Lateral Boundary size (ILS versus 500 ft), and how task acceptability was affected \nby Combined versus Separate Monitor positions. Therefore, the Independent Variables for this \nportion of the experiment included display type (STARS versus FMA) and the number of Monitor \ncontrollers (Combined versus Separate). All of the IM PA-related tools described previously \nwere available to the Monitor controllers for these scenarios. Traffic File Attributes5.5.5\nThree general types of scenario traffic files were developed for the HITL, one for each type of \nscenario. These included: 1) Nominal scenarios, 2) Alert Timing scenarios, and 3) Lateral \nDeviation scenarios. Depending on what was being tested, these traffic files may have contained \neither of two types of off-nominal events: Spacing Loss and Lateral Deviation. A Spacing Loss occurred when an IM Trail Aircraft began to encroach on one of the \nsafety limits, triggering an alert. When this occurred, the controller procedures varied \ndepending on if it was a Predictive Alert or a Caution Alert. \nA Lateral Deviation occurred when during the IM PA operation, one aircraft sharply \ndeviates from its approach path, either to the left or right, and keeps going; or, one \naircraft starts a long, shallow deviation to the left or right. In this instance, the controller \nfollowed the procedures for lateral deviations discussed. These only apply to aircraft in IM PA pairings, though loss-of-separation could occur between \nnon-IM PA aircraft as well. None of these cases were intentionally introduced, however. The traffic file attributes for each type of scenario are summarized in the following sections. Nominal Scenarios5.5.5.1\nFour nominal core traffic files approximately 20 minutes in length. Each had seven IM PA \npairings, five with WSL and two without WSL. There were two non-paired SRS aircraft. There \nwere two Spacing Loss events per scenario; one was an IM PA Predictive Alerts that was \nintended to resolve without controller intervention being required. The second was an IM PA \nPredictive Alert that led to a Caution Alert if the controller did not intervene. Given the scenario \ntimeframe, these occurred at a higher frequency than would be experienced in actual \noperations to provide controllers with concentrated experience in dealing with them and to get \nfeedback on the alerting. These core traffic files were then cloned and varied in which aircraft experienced the Predictive \nand Caution Alerts, the location of SRS aircraft within the flow, with respect to the IM PA \npairings, the order of the IM PA pairings, and the aircraft call signs. Alert Timing Scenarios5.5.5.2\nThe Alert Timing scenarios were based on the nominal scenario and was approximately 20 \nminutes in duration, with six IM PA pairings. All pairs required a WSL and five of the six parings \nwere manipulated to show an alert related to Spacing Loss. The same traffic file was used for \neach run so participants could clearly isolate the effect of each alert timing set. xxxvi\n A CSL alert can be triggered either earlier in the approach, or later. A WSL alert can only be \ntriggered late, when the WSL is active. The distribution of the alerts in the scenario is shown in \nTable 4-3. Table 4-3. Distribution of CSL and WSL Alerts in the Scenario Pair 1 Pair 2 Pair 3 Pair 4 Pair 5 Pair 6\nEarly Late Early Late Early Late Early Late Early Late Early Late\nCSL WSL CSL WSL CSL Lateral Deviation Scenarios5.5.5.3\nEach Lateral Deviation scenario lasted for approximately 10 minutes and included four IM PA \npairings, two of which exhibited Lateral Deviations that required the controller to take action. \nThere were three potential lateral deviation variables considered in the scenario design. First, \nthe deviating aircraft could be either be the IM Lead or IM Trail Aircraft. Second, the deviation \nangle could be sharp or shallow. A sharp deviation occurs suddenly, with little warning. A \nshallow deviation evolves gradually, over a long portion of the approach. And third, the \ndeviation could either be inboard (toward the other aircraft) or outboard (away from the other \naircraft). Based on the lateral deviation variables, two deviation types were developed: Deviation Type A: Lead / Sharp (30 deg) / Inboard.\nDeviation Type B: Trail / Shallow (10 deg) / Outboard. A lateral deviation could also occur earlier or later in the approach. Therefore, four traffic files \nwere developed for the Lateral Deviation scenarios. Variations included deviation location \n(earlier versus later), deviation order (whether Type A occurred before Type B, or whether Type \nB occurred before Type A), and which of the four IM PA pairings experienced them. Table 4-4 \nshows the how the variations were implemented and distributed across each of the four traffic \nfiles (named L through O). Table 4-4. Distribution of Lateral Deviation Types Pair 1 Pair 2 Pair 3 Pair 4\nTraffic File 10 NM 5 NM 10 NM 5 NM 10 NM 5 NM 10 NM 5 NM L A B\nM B A\nN A B\nO B A These lateral deviation events occurred at a far higher frequency than would be experienced \nin actual operations. This was intended to provide controllers with concentrated \nexperience in dealing with them to get feedback on the lateral monitoring display \nfeatures. It should also be noted that the scenario presented in the scenario that \ninvolved traffic file O was deliberately designed as an extreme case. The timing of this \nscenario was such that that the shallow-deviating Trail crossed its Lateral Boundary and \ntriggered its Exceedance Warning shortly after the Lead Aircraft (of a different pair) \ntriggered its Exceedance Warning. In effect, this appeared to controllers as a near-\nsimultaneous lateral deviation of two aircraft. In real world operations, a near- xxxvii\n simultaneous lateral deviation of multiple aircraft on CSPR is expected to occur rarely, if \nat all. An investigation of over 1.8 million approach paths did not detect any (Eckstein, \nMassimini, McNeill, & Niles, 2012), nor was there a record of any in an examination of \n7790 go-arounds that were logged over multiple years by NCT (Stassen, Domino, Hefley, \n& Weitz, 2019). Though this has never been observed in real world operations, it was still \nincluded in the simulation to stress the display features and probe for a potential failure \npoint with IM PA Tools or Monitoring configuration. Scenario Matrices and Run Orders5.5.6\nThis section describes the scenario matrices across the three weeks of runs. Some changes were \nmade after the Week 1 scenarios were run, so they are described separately from the Week 2-3 \nscenarios. The data reduction and analysis process accounted for those differences. The Day 1-2 scenarios were considered nominal operations. Though some longitudinal \nSpacing Loss events were included, the alert timing values were fixed, and no deliberate Lateral \nDeviations were introduced. As noted in Section 4.5.3, two controllers participated per run \nwhile the other two filled out their post-run questionnaires. When the Combined Monitor \nconfiguration was evaluated, one participant controller served as the Monitor and the other \nserved as the 28R Final controller. When the Separate Monitor configuration was run, one \nparticipant served as the 28L Monitor controller and the other served as the 28R Monitor \ncontroller. The 28R Final controller position was not staffed in these cases, and IM PA pairs were \ninitiated via the simulation before they were turned over to the Local controller. The scenario order for each day was counterbalanced across the three weeks. The monitor \nconfigurations were alternated by run week. The daily simulation topic by week is summarized \nin Table 4-5. Table 4-5. Daily Simulation Topic
by Week Week 1 \n(ATC 1-4) Week 2 \n(ATC 5-8) Week 3 \n(ATC 9-12) Day 1 Combined Monitor / 28R Final Separate Monitors Separate Monitors\nDay 2 Separate Monitors Combined Monitor / 28R Final Combined Monitor / 28R Final\nDay 3 Alert Timing / Lateral Deviation Alert Timing / Lateral Deviation Alert Timing / Lateral Deviation Day 1 Scenario Matrix (Participants 1-4)5.5.6.1\nFor Week 1, Day 1, Participant controllers (referred to as ATC 1-4) staffed the Combined 28L/R \nMonitor and the 28R Final controller positions. A confederate controller (Conf) served as the \nCombined 28L/R Local controller. Two unique traffic files were created and alternated across \nthe scenarios. The traffic files were then cloned, and the call signs changed to create two \nalternate traffic files. For this day of runs: Traffic File A = Traffic File C (except for call signs) and \nTraffic File B = Traffic File D (except for call signs). Table 4-6 shows the scenario run order and \nIM PA Tool Independent Variable manipulations. Table 4-6. Week 1, Day 1 Scenario Run Order and IM PA Tool Variable Manipulations Data Block (DB) Combined Monitor Combined Local Final Approach\nScenario Name CSL/WSL WSL-P 28L/R 28L/R 28L 28R xxxviii\n 1A On On ATC 1 Conf ATC 2\n1C On On ATC 3 Conf ATC 4\n1B On On ATC 2 Conf ATC 1\n1D On On ATC 4 Conf ATC 3 2A* Off On ATC 4 Conf ATC 3\n2D Off On ATC 3 Conf ATC 4\n2C Off On ATC 2 Conf ATC 1 2B* Off On ATC 1 Conf ATC 2\n4A Off Off ATC 2 Conf ATC 1\n4B Off Off ATC 3 Conf ATC 4\n4C Off Off ATC 4 Conf ATC 3\n4D Off Off ATC 1 Conf ATC 2 * Due to a simulation issue, scenarios 2A and 2B were erroneously transposed in the run order. Day 1 Scenario Matrix (Participants 5-12)5.5.6.2\nFor Day 1 in Weeks 2-3, participant controllers (ATC 5-12) staffed the Separate 28L/28R Monitor \npositions. The 28R Final controller position was not staffed and IM PA pairs were initiated via \nthe simulation. Two confederate controllers (A and B) served as separate 28L and 28R Local \ncontrollers, and two other confederate controllers served as the pseudopilots. Three unique traffic files were used. Two of these (A and E) were clones, except for call signs. \nThe traffic file used in each scenario is reflected in its name code. The scenario matrices in Table \n4-7 and Table 4-8 show the scenario run order counterbalancing and display Independent \nVariable manipulations for Week 2 and Week 3, respectively. Table 4-7. Week 2, Day 1 Scenario Run Order and IM PA Tool Variable Manipulations Scenario \nName DB \nCSL/WSL WSL-P Monitor Local\n28L 28R 28L 28R 1E On On ATC 5 ATC 6 Conf A Conf B\n4E Off Off ATC 7 ATC 8 Conf A Conf B\n2F Off On ATC 6 ATC 5 Conf B Conf A\n1F On On ATC 8 ATC 7 Conf B Conf A\n2A Off On ATC 5 ATC 6 Conf A Conf B\n1A On On ATC 7 ATC 8 Conf A Conf B\n4E Off Off ATC 6 ATC 5 Conf B Conf A\n2E Off On ATC 8 ATC 7 Conf B Conf A\n4F Off Off ATC 5 ATC 6 Conf B Conf A\n2F Off On ATC 7 ATC 8 Conf B Conf A\n1A On On ATC 6 ATC 5 Conf A Conf B\n4A Off Off ATC 8 ATC 7 Conf A Conf B Table 4-8. Week 3, Day 1 Scenario Run Order and IM PA Tool Variable Manipulations Scenario \nName DB \nCSL/WSL WSL-P Monitor Local\n28L 28R 28L 28R 2A Off On ATC 9 ATC 10 Conf A Conf B\n1A On On ATC 11 ATC 12 Conf A Conf B xxxix\n 4E Off Off ATC 10 ATC 9 Conf B Conf A\n2E Off On ATC 12 ATC 11 Conf B Conf A\n4F Off Off ATC 9 ATC 10 Conf A Conf B\n2F Off On ATC 11 ATC 12 Conf A Conf B\n1A On On ATC 10 ATC 9 Conf B Conf A\n4A Off Off ATC 12 ATC 11 Conf B Conf A\n1E On On ATC 9 ATC 10 Conf B Conf A\n4E Off Off ATC 11 ATC 12 Conf B Conf A\n2F Off On ATC 10 ATC 9 Conf A Conf B\n1F On On ATC 12 ATC 11 Conf A Conf B Day 2 Scenario Matrix (Participants 1-4)5.5.6.3\nFor Week 1, Day 2, participant controllers (ATC 1-4) staffed the separate 28L and 28R Monitor \ncontroller positions. The 28R Final controller position was not staffed and IM PA pairs were \ninitiated via the simulation. Two confederate controllers (A and B) served as separate 28L and \n28R Local controllers and two other confederate controllers served as the pseudopilots. Two unique traffic files were created and alternated across the scenarios. The traffic files were \nthen cloned, and the call signs changed to create two alternate traffic files. For this day of runs \nTraffic File E = Traffic File G (except for call signs), and Traffic File F = Traffic File H (except for call \nsigns). The traffic file used in each scenario is reflected in its name code. Table 4-9 shows the \nscenario run order and display Independent Variable manipulations. Table 4-9. Week 1, Day 2 Scenario Run Order and IM PA Tool Variable Manipulations Scenario \nName DB \nCSL/WSL WSL-P Monitor Local\n28L 28R 28L 28R 1E On On ATC 1 ATC 2 Conf A Conf B\n1G On On ATC 3 ATC 4 Conf A Conf B\n1F On On ATC 2 ATC 1 Conf B Conf A\n1H On On ATC 4 ATC 3 Conf B Conf A\n3G On Off ATC 1 ATC 2 Conf A Conf B\n3E On Off ATC 3 ATC 4 Conf A Conf B\n3H On Off ATC 2 ATC 1 Conf B Conf A\n3F On Off ATC 4 ATC 3 Conf B Conf A\n4H Off Off ATC 1 ATC 2 Conf B Conf A\n4F Off Off ATC 3 ATC 4 Conf B Conf A\n4E Off Off ATC 2 ATC 1 Conf A Conf B\n4G Off Off ATC 4 ATC 3 Conf A Conf B Day 2 Scenario Matrix (Participants 5-12)5.5.6.4\nParticipant controllers (ATC 512) staffed the Combined 28L/R Monitor and the 28R Final \ncontroller positions for Day 2 in Week 2 and Week 3. A confederate controller served as the \nCombined 28L/R Local controller. Three unique traffic files were used. Two of these (C and G) \nwere clones, except for call signs. The traffic file used in each scenario is reflected in its name \ncode. The scenario matrices in Table 4-10 and xl\n Table 4-11 show the scenario run order and IM PA Tool Independent Variable manipulations. Table 4-10. Week 2, Day 2 Scenario Run Order and IM PA Tool Variable Manipulations Scenario \nName DB \nCSL/WSL WSL-P Comb Mon\n28L/R Comb Local\n28L/R Final Approach\n28L 28R 3B On Off ATC 5 Conf ATC 6\n1B On On ATC 7 Conf ATC 8\n4G Off Off ATC 6 Conf ATC 5\n3G On Off ATC 8 Conf ATC 7\n4C Off Off ATC 5 Conf ATC 6\n3C On Off ATC 7 Conf ATC 8\n1B On On ATC 6 Conf ATC 5\n4B Off Off ATC 8 Conf ATC 7\n1G On On ATC 5 Conf ATC 6\n4G Off Off ATC 7 Conf ATC 8\n3C On Off ATC 6 Conf ATC 5\n1C On On ATC 8 Conf ATC 7 Table 4-11. Week 3, Day 2 Scenario Run Order and IM PA Tool Variable Manipulations Scenario \nName Data Block \nCSL/WSL WSL-P Comb Mon\n28L/R Comb Local\n28L/R Final Approach\n28L 28R 1G On On ATC 9 Conf ATC 10\n4G Off Off ATC 11 Conf ATC 12\n3C On Off ATC 10 Conf ATC 9\n1C On On ATC 12 Conf ATC 11\n3B On Off ATC 9 Conf ATC 10\n1B On On ATC 11 Conf ATC 12\n4G Off Off ATC 10 Conf ATC 9\n3G On Off ATC 12 Conf ATC 11\n4C Off Off ATC 9 Conf ATC 10\n3C On Off ATC 11 Conf ATC 12\n1B On On ATC 10 Conf ATC 9\n4B Off Off ATC 12 Conf ATC 11 Day 3 Scenario Matrix: Alert Timing (Participants 1-12)5.5.6.5\nThis portion of the study focused on differences to the Monitor controller with respect to alert \ntiming. All IM PA Tools were On (i.e., Data Block [DB] CSL/WSL and the WSL-P) and only the alert \ntimings were varied. In this case, only the 28R traffic experience a longitudinal alert. Therefore, \nthese scenarios used a Combined Monitor configuration and two participants were run side-by-\nside, independent and in parallel (indicated by the shading in Table 4-12). Each scenario also \ninvolved a single, confederate Local controller and a pseudopilot. The same traffic file was used \nfor each run so participants could clearly isolate the effect of each alert timing set. A scenario \nissue compromised the usability of the alert timing data for Week 1; therefore, only the Week 2-\n3 runs are summarized here and only Week 2-3 alert timing data is included in the results. The xli\n timing values used in the HITL and the counterbalance order is shown in the matrix in Table \n4-12. Table 4-12. Week 2-3 Alert Timing Values and Counterbalance Order Comb \nMonitor
Week 2 Timing Order \n(sec) Comb \nMonitor Week 3 Timing Order (sec)\nPredictive Caution Predictive Caution ATC 5 45 24 ATC 9 25 15\nATC 6 45 24 ATC 10 25 15\nATC 7 45 24 ATC 11 25 15\nATC 9 45 24 ATC 12 25 15\nATC 5 35 20 ATC 9 35 20\nATC 6 35 20 ATC 10 35 20\nATC 7 35 20 ATC 11 35 20\nATC 9 35 20 ATC 12 35 20\nATC 5 25 15 ATC 9 45 24\nATC 6 25 15 ATC 10 45 24\nATC 7 25 15 ATC 11 45 24\nATC 9 25 15 ATC 12 45 24 Day 3 Scenario Matrix: Lateral Deviations (Participants 1-12)5.5.6.6\nAs described in Section 4.5.5.3, the Lateral Deviations portion of the study focused on \ndifferences to the Monitor controller with respect to IM Lead Aircraft and IM Trail Aircraft \ndeviations against the Lateral Boundaries. Two variables were manipulated: Monitor \nconfiguration (Combined versus Separate) and Display Type (STARS versus FMA 4:1). Four \nseparate traffic files (termed L, M, N, and O) were developed for the Lateral Deviation scenarios. \nThey included variations on deviation location (earlier versus later), deviation order (whether \nType 1 occurred before Type 2, or whether Type 2 occurred before Type 1), and which of the \nfour IM PA pairings experienced them. The Combined Monitor configuration scenarios were run in the same manner as the Alert \nTiming scenarios: two participants side-by-side, independent and in parallel (indicated by the \nshading in the following tables). The Separate Monitor configuration scenarios were run in the \nsame manner as the Day 1-2 Nominal scenarios. Each scenario lasted approximately 10 minutes. Table 4-13 shows the scenario run order and Independent Variable manipulations for Week 1. \nThe traffic file used in each scenario is reflected in its name code. Due to time constraints, \nscenarios 1N, 4O, 1O, and 4N were not run for ATC 1-4 (indicated by the strikethroughs in Table \n4-13). Table 4-13. Week 1 Lateral Deviation Run Order and Variable Manipulations Scenario \nName Traffic File Monitor \nConfig Display Type Monitor Position\n28L (M) 28R (M) 1L L Combined STARS ATC 1\n2L L Combined STARS ATC 2 xlii\n 3L L Combined STARS ATC 3\n4L L Combined STARS ATC 4\n1M M Combined FMA 4:1 ATC 1\n2M M Combined FMA 4:1 ATC 2\n3M M Combined FMA 4:1 ATC 3\n4M M Combined FMA 4:1 ATC 4\n1N N Separate STARS ATC 1 ATC 2\n2O O Separate STARS ATC 2 ATC 1\n3N N Separate STARS ATC 3 ATC 4\n4O O Separate STARS ATC 4 ATC 3\n1O O Separate FMA 4:1 ATC 1 ATC 2\n2N N Separate FMA 4:1 ATC 2 ATC 1\n3O O Separate FMA 4:1 ATC 3 ATC 4\n4N N Separate FMA 4:1 ATC 4 ATC 3 Table 4-14 and Table 4-15 show the scenario run order and Independent Variable manipulations \nfor the Week 2 and Week 3 participants, respectively. The traffic file used in each scenario is \nreflected in its name code. Table 4-14. Week 2 Lateral Deviation Run Order and Variable Manipulations Scenario \nName Monitor \nConfig Display Type Monitor Position\n28L (M) 28R (M) 1N Separate STARS ATC 5 ATC 6\n3N Separate STARS ATC 7 ATC 8\n2O Separate STARS ATC 6 ATC 5\n4O Separate STARS ATC 8 ATC 7\n1L Combined STARS ATC 5\n2L Combined STARS ATC 6\n3L Combined STARS ATC 7\n4L Combined STARS ATC 8\n1M Combined FMA 4:1 ATC 5\n2M Combined FMA 4:1 ATC 6\n3M Combined FMA 4:1 ATC 7\n4M Combined FMA 4:1 ATC 8\n1O Separate FMA 4:1 ATC 5 ATC 6\n3O Separate FMA 4:1 ATC 7 ATC 8\n2N Separate FMA 4:1 ATC 6 ATC 5\n4N Separate FMA 4:1 ATC 8 ATC 7 Table 4-15. Week 3 Lateral Deviation Run Order and Variable Manipulations Scenario \nName Monitor \nConfig Display Type Monitor Position\n28L (M) 28R (M) 1M Combined FMA 4:1 ATC 9 \n2M Combined FMA 4:1 ATC 10\n3M Combined FMA 4:1 ATC 11\n4M Combined FMA 4:1 ATC 12\n1N Separate FMA 4:1 ATC 9 ATC 10 xliii\n 3N Separate FMA 4:1 ATC 11 ATC 12\n2O Separate FMA 4:1 ATC 10 ATC 9 \n4O Separate FMA 4:1 ATC 12 ATC 11\n1L Combined STARS ATC 9 \n2L Combined STARS ATC 10\n3L Combined STARS ATC 11\n4L Combined STARS ATC 12\n1O Separate STARS ATC 9 ATC 10\n3O Separate STARS ATC 11 ATC 12\n2N Separate STARS ATC 10 ATC 9 \n4N Separate STARS ATC 12 ATC 11 Data Collection 5.5.7\nTwo main methods of data collection were used for this simulation. These were subjective data \n(i.e., participant questionnaires) and objective data (i.e., system recorded data). In addition, \nsimulation observers made notes throughout the sessions and a final discussion/debrief was \nheld at the end of each week. Subjective Data Collection5.5.7.1\nAs described in Section 4.5.3, the subjective data included questionnaires after each run, each \nday, and at the end of the simulation. The topics included: workload, acceptability of displays / \nindividual IM PA Tools, communications and concepts, monitoring configuration, and ideas for \nimprovements. The individual questionnaires are included in the appendices and are as follows: Day 1-2 Questionnaires\nDemographics (Appendix B)\nCombined Monitor Post-Run (Appendix C)\n28R Final Approach Post-Run (Appendix C)\n28R Monitor Post-Run (Appendix C)\n28L Monitor Post-Run (Appendix C)\nDay 1 End (Appendix D)\nDay 2 End (Appendix D) Day 3 Questionnaires\nAlert Timing Post-Run (Appendix E)\nAlert Timing Final (Appendix E)\nLateral Deviation Post-Run (Appendix F)\nLateral Deviation Final (Appendix F)\nSimulation Final (Day 3 End) (Appendix G)\nDebrief Questions (Appendix G) Objective Data Collection5.5.7.2\nObjective data was automatically collected and recorded by the simulation environment after \neach run. This data included: xliv\n Aircraft state including position, altitude, heading, speed, etc.\nIM Clearances provided.\nIM Trail Aircraft tolerance within Assigned Spacing Goal and location relative to safety \nlimits.\nOccurrences of Predictive and Caution Alerts.\nIM Speed changes, reversals, and increases.\nTime between IM Speed changes and distance to go.\nAircraft broken out per longitudinal alert.\nAircraft broken out relative to Lateral Bound proximity.\nTimes and occurrences of Push-To-Talk (PTT) clicks.\nController screen video recordings. This data was filtered and reduced to provide the summary data for analyzing the effect of the \nprocedures and tools on controller response time to developing separation issues and any \nactual separation violations. i\n Results6\nThis section summarizes the results from the questionnaire subjective data and objective data \nanalyses. Section 5.1 first discusses the methods for data reduction, analysis and presentation \nused to convey the results of the subjective and objective data. Results are organized and \npresented by topic in Sections 5.2 through 5.7. Section 5.8 evaluates the hypotheses described \nin Section 3.3 in consideration of results across various related metrics. All of the major results \nare then listed in Section 5.9. Data Analysis Methodology6.1\nSubjective Data6.1.1 The subjective data analysis methodology and presentation of the subjective (questionnaire) \ndata are summarized in this section. To reduce the potential for family-wise error (i.e., \nerroneously finding a significant result due to excessive unplanned comparisons), statistical \ntests were only performed on subjective results that were specifically used to examine a \nhypothesis. Therefore, the subjective results reported in Sections 5.2 through 5.7 only include \ndescriptive statistics and any trends that are inferred are based on the methodology described \nin Section 5.1.1.3. The statistical analysis results for subjective data are reported separately in \nthe hypothesis evaluations in Section 5.8, though results are referenced in the individual \nquestions in the prior sections. Sample Sizes6.1.1.1\nDespite having a total of 12 controllers participate in the experiment, not all 12 questionnaire \nresponses were included in every question analysis. This results in different sample size (n) \nvalues across the various questions. One of the main reasons was that the Nominal and Alert \nTiming scenarios were modified after Week 1. The Week 1 post-run results could therefore not \nbe appropriately combined with Week 2-3 results. However, the experimenters felt that the \nWeek 1 controller participants still received sufficient experience with the IM PA Tools and thus \ntheir responses were still typically included in the Day End and Final Questionnaires. No changes \nwere made to the Lateral Deviation scenarios after Week 1; therefore, all controller responses \nwere included in the analyses for these cases. In addition, as noted in Section 4.5.2, two participants only had Tower experience; on \nparticipant in Week 1 and one participant in Week 3. The results from these participants were \nrarely pooled with the TRACON controller responses, unless the experimenters felt it was \nappropriate to do so. The Tower controller responses are thus usually reported separately. ii\n Unless otherwise noted, the following rationales were used for the typically occurring n values \nused for each of the reported statistical calculations. If an individual result does not include a \nspecific explanation for the n, it falls into one of the below cases. n = 12: All 12 participant controllers responses were included in reported findings.\nn = 10: Includes responses for participant controllers with TRACON experience across all \nthree run weeks. It does not include Tower-only responses.\nn = 7: Due to scenario changes made between Week 1 and Weeks 2-3, it was not always \nappropriate to include Week 1 TRACON controller responses in the data pool for the \npost-run questionnaires. Therefore, this case represents only the Week 2-3 TRACON \ncontroller responses.\nn = 6, n = 4: For questions where NCT responses may be of particular interest, the four \nNCT
Controller responses were reported separately. This resulted in an n = 6 for non-NCT \nTRACON controller responses.\nn = 2, n = 1: Indicates the responses for controllers that only had Tower (i.e., no \nTRACON) experience. Other n values were possible if questionnaire responses were left blank. These are noted on a \ncase-by-case basis in the results. In many figures, additional responses such as NCT-specific \nvalues or Week 1 controller responses are represented with an open circle. These may or may \nnot be included in the findings analysis and any of these special cases are noted alongside each \nresult. Questionnaire Sources6.1.1.2\nAs introduced in Section 4.5.3 and Section 4.5.7, the findings present results from across the \neight Questionnaire Types (QT). These included: QT1: Day 1-2 Post-Run\nQT2: Day 1 End and Day 2, Part 1 End\nQT3: Day 2, Part 2 End\nQT4: Alert Timing Post-Run\nQT5: Alert Timing Final\nQT6: Lateral Deviation Post-Run\nQT7: Lateral Deviation Final\nQT8: Simulation Final (Day 3 End) In some cases, similar questions were asked in the post-run and final questionnaires. Post-run \nresults were usually reported when examining controller response to an independent variable. \nFinal questionnaire results were reported when summarizing overall results, irrespective of a \nmanipulated variable. Sometimes both are reported, sometimes only one. Therefore, the source \nquestionnaire (e.g., QT1) is included with the results. iii\n In summary, the major types of reported results came from the following questionnaire types: When the sample size was greater than seven (i.e., n > 7) for the TRACON controllers, \nthe question(s) likely came from either the Day End or Final Questionnaires (QT2, QT3, \nQT5, QT8). This is because, as described earlier, Tower controller and some Week 1 \nresponses were usually included in the final questionnaire results, but not in the post-\nrun data summaries. \nWhen monitor configuration is compared (i.e., Combined versus Separate), these are \ncomparisons from the Day 1 and Day 2 End Questionnaires (QT2, QT3).\nWhen IM PA Tools configuration is compared (i.e., IM PA Tools On versus IM PA Tools \nOff; Data Block Distances On / WSL-P Off versus Data Block Distances Off / WSL-P On), \nthese are comparisons from the Day 1 and Day 2 Post-Run Questionnaires (QT1).\nWhen the specific alert timings are compared, these are from the Alert Timing Post-Run \nQuestionnaires (QT4).\nFor Lateral Deviation results, when display type and monitor configuration are \ncompared, these are from the Lateral Deviation Post-Run and Final Questionnaires (QT6, \nQT7). Question Analysis and Presentation6.1.1.3\nThe majority of questions on each of the different questionnaire types consisted of statements \nwith a scale containing 100 hash marks (without numeric labels). Participants were instructed to \nanswer the questions by drawing a vertical line through the option on each of the scales at the \npoint that matched their experience (i.e., how strongly they agreed with the statement). The \nscale was anchored on the left with the label Strongly Disagree and on the right with the label \nStrongly Agree. During data reduction, responses were rounded to the nearest single digit \nbetween 0 and 100. If it could not be determined which mark was closest to the participant \nrating, the response was rounded to the mark closer to the Strongly Disagree anchor. Figure 5-1. Questionnaire Scale and Anchors The analysis methodology is similar to that used in Bone & Mendolia (2018). In their \npresentation of results shown in Figure 5-2, any individual response below the midpoint (i.e., \nlower than 50) on the scale was characterized to be on the disagree side, while any response \nabove the midpoint (i.e., higher than 50) on the scale was considered to be on the agree side. \nAny response at the midpoint (i.e., equal to 50) was considered to be neutral. iv\n 500 100 Disagree AgreeNeutral Figure 5-2. 100-Point Agreement Scale Agreement Rating Breakdown from Bone & Mendolia (2018) When presenting results on the 100-point agreement scale in the post-simulation \nquestionnaires, the following terminology / methodology was used to describe five possible \nlevels of agreement based on the Mean (M) and Standard Deviation (SD) of the responses. It is \nmodified slightly from that defined in Bone & Mendolia (2018). All Controllers [agreed / disagreed].1. All of the individual participant responses were on the agree or disagree side of the o\nscale. The majority (n; %) of Controllers [agreed / disagreed].2. Low variability, e.g., SD was less than 25 (unless one value drove a SD slightly higher).o\nController responses were variable, but the majority (n; %) [agreed / disagreed].3. Response SD was greater than 25 and distribution was skewed to either side of the o\nscale. Controllers neither agreed nor disagreed.4. Response M was within one point of neutral (49-51), and no clear skew of the o\ndistribution to either side of the scale was observable. Controller responses were variable.5. Response SD was greater than 25 and no clear skew of the distribution to either side o\nof the scale was observable. Figure 5-3 provides an example of annotated description of the information presented in the \nfigures depicting the reported statistical calculations. The figure includes the M, the SD of the \nresponses as upper and lower bounds, and the individual responses included in the descriptive \nstatistics. Smiling or frowning faces are shown on the scale where the replies to the \nstatements have a subjectively positive or negative meaning. In most cases, TRACON and Tower \ncontroller responses are described separately and SDs are not shown for Tower controller \nresults due to a typical n of only 1 or 2 responses. Tower controller results are included in the \nfigures and tables for completeness; however, they are only discussed in the text when there is \na particular applicability to the question. Any additional presentation-specific information is v\n indicated below the figures. Related questions are sometimes grouped together in the same \nfigure. Figure 5-3. Explanation of Questionnaire Figures In addition to the subjective ratings, the Bedford Workload Rating Scale (Roscoe & Ellis, 1990) \nwas used in the post-run questionnaires to measure subjective controller workload for each \nscenario. Also, some questions in the questionnaires were yes / no and participants were asked \nto circle their answer. Almost all questions had space for participants to provide any open-ended comments. \nComments that illuminate the reason for a response that varies from many of the other \nresponses are included in explanation when available. Other selected comments are \nreproduced in the results to provide additional insights. Minor spelling and grammar edits were \nmade for some comments to improve their readability. IM PA Tool Configurations 6.1.1.4\nAs described in the experimental design in Section 4.5.4, the Day 1-2 Nominal scenarios varied: \n1) the display presentation of the Distances to the CSL/WSL in Line 3 of the Data Block (termed \nDB CSL/WSL or DB Distances), and 2) the display of the WSL-P. IM PA Tools On means that BOTH the DB Distances AND the WSL-P were displayed in \nthat scenario.\nIM PA Tools Off means that NEITHER the DB Distances NOR the WSL-P were displayed \nin that scenario.\nAll the other described IM PA features, such as the CSL/WSL Lines, Alerting, and Lateral \nBoundaries, were displayed for every scenario. All controllers experienced the IM PA Tools On and IM PA Tools Off for each monitor \nconfiguration, allowing for direct comparisons. However, there was insufficient time for each vi\n controller to experience each IM PA Tool variation for each monitor configuration. Therefore, \npost-run scenario comparisons of Data Block Distances and the WSL-P were across different \nmonitor configurations, which may have also affected the responses. Additionally, due to \nscenario changes between Week 1 and Weeks 2-3, post-run comparative responses for Week 1 \nwere not included in the monitor configuration results. However, the Final Approach controller \nposition was not affected by these changes. Therefore, Week 1 28R Final controller responses \nfor IM PA Tools On and IM PA Tools Off are reported in the results. Table 5-1 summarizes the \nvariations that were tested for each monitor configuration. Table 5-1. Monitor Configuration IM PA Tool Configurations Monitor \nConfiguration Week 1 *\n(ATC 1-4) Week 2 \n(ATC 5-8) Week 3 \n(ATC 9-12) Combined DB Distances OffWSL-P On\nDB Distances On WSL-P Off\nDB Distances On WSL-P Off Separate DB Distances OnWSL-P Off\nDB Distances Off WSL-P On\nDB Distances Off WSL-P On * Due to scenario changes between Week 1 and Weeks 2-3, post-run comparative responses for \nWeek 1 are usually not included in the monitor results. Exceptions are otherwise noted. Objective Data6.1.2\nThree analyses were performed on the objective data that was described in Section 4.5.7.2. \nThese were: Whether any losses of separation occurred and if so, if monitor configuration or IM PA \nTool configuration had any effect. (Section 5.2.5.2)\nAn evaluation of alternate longitudinal alert timings to examine whether lower alert \ntimings than those chosen for ATPA affected controller response time to a Caution Alert. \n(Section 5.5.4.3)\nWhether Controller Monitor or Display configuration had an effect on controller \nresponse time to an aircraft crossing a Lateral Boundary. (Section 5.6.5) The data reduction, assumptions, and statistical methods used for each analysis are described in \ntheir respective sections. However, it should be noted that the objective response-time analyses \nwere based on PTT post-processing, which proved challenging. First, the simulation audio \nsystem PTT
handset click data had to be manually aligned with scenario data after data \ncollection was complete. This was a complicated process and though the experimenters have \nconfidence that it was done correctly, it is still possible that the resulting combined data \ncontains error. Secondly, the use of the PTT data in this way required an assumption that the \nclick immediately following an event of interest (such as a Caution Alert) was the controllers \nintent to resolve the situation. Therefore, the first click that was recorded after an event of \ninterest was used as a proxy for the controller response time to resolve a situation. Though this \nis likely to be a safe assumption generally, there may be an occasional case where it is not. \nThough these cases cannot be precisely identified from the data, some additional post-\nprocessing was done to increase confidence that the correct PTT value was being used. These vii\n methods are described further in the context of the specific analyses. Finally, the audio system did not allow a true override capability for the Monitor controllers. If \nthe Local controller or pseudopilot was talking on the frequency, the Monitor controllers could \nnot break in. They were, however, told to still click their handsets when they wanted to speak. \nHowever, it is possible that some controllers did not click when blocked. In these cases, \nresponse times may therefore have been artificially inflated. Results Topic 1: Overall Acceptability and Performance6.2\nThis section includes results related to the acceptability and performance of IM PA operations \nas examined. The metrics consisted of: Concept Desirability and Terminal Compatibility, Dual \nSafety Limit Acceptability, IM Speed Control, Traffic Situation Awareness, Separation \nAssessment, and Task Acceptability by Position. Participant responses to open-ended questions \nare also summarized, including what they liked about IM PA, what concerned them, and what \naspects of the operation they felt could be improved. Concept Desirability and Terminal Compatibility6.2.1\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if IM PA is operationally desirable and \ncompatible with terminal approach operations. Given their specific experience in the areas \nbeing simulated, NCT responses are shown separately. Non-NCT and Tower responses are thus \nalso shown as separate categories. Response Means and Standard Deviations are summarized in \nTable 5-2. Scale responses are shown in Figure 5-4. Table 5-2. Controller Responses to Concept Desirability and Terminal Compatibility Participant Experience Non-NCT NCT Tower\nIM PA is operationally desirable. Sample Size (n) 6 4 2 Mean (M) 76.0 75.0 91 Standard Deviation (SD) 17.6 19.1  IM PA is compatible with terminal \napproach operations. Sample Size (n) 6 4 2 Mean (M) 77.0 57.3 90.0 Standard Deviation (SD) 19.0 15.2  viii\n Figure 5-4. IM PA is operationally desirable and compatible with terminal approach operations. The majority (83%) of non-NCT (M=76.0; SD=17.6) and the majority (75%) of NCT (M=75.0; \nSD=19.1) controllers agreed IM PA is operationally desirable. Though not shown in Figure 5-4, \n80% of all TRACON controllers agreed (n=10, M=75.6, SD=17.1) when averaged together. Open-ended comments for this question included: (Non-NCT TRACON) Allows focus elsewhere and reduces workload.\n(Non-NCT TRACON) This operation could provide a benefit to airports with closely \nspaced parallels like SFO in IMC conditions, especially where there are a lot of heavy jets. \nWhere there are less heavy jets and a tighter final (no need for departure gaps), this \noperation could be more challenging, and provide less operational gain. When asked if IM PA is compatible with terminal approach operations, the majority (83%) of \nnon-NCT (M=77.0; SD=6.0) controllers agreed. On average the NCT controllers also agreed \n(M=57.3; SD=15.2). However, this was driven by an 80 rating by one of the four NCT \ncontrollers. The other three controllers neither agreed nor disagreed. Though not shown in \nFigure 5-4, 60% of all TRACON controllers agreed (n=10, M=69.1, SD=19.5) when averaged \ntogether. Open-ended comments for this question included: (NCT) I'm just not sure about the monitor position overriding local. I think it is totally \ndoable in some form, though. Kinks would have to be worked out at facility level. --------------------------------- At the end of Day 3 (QT8) controllers were asked which is the most appropriate position to \nmonitor IM PA operations? They were given the choices of Final Approach Monitor, \nFinal Approach Control, Local controller, or Other. Some participants selected more than \none and their responses and comments are provided in Table 5-3. Table 5-3. Controller Responses to Most Appropriate Position to Monitor IM PA Operations ix\n Position Number \nof \nSelect\nions Comments Final \nApproac\nh \nMonitor 8 (NCT) Final Monitor needs to be able to solely focus on \nIM PA operations.\n(non-NCT TRACON) Depends on the airport. At SFO it \nseems like monitor. At BOS, I feel like it would be a \nLocal controller. Others it may be Final.\n(NCT) I think it could work as a Final controller. \nHowever, the Monitor controller is the most \nappropriate due to workload.\n(NCT) Its their only task. They can watch aircraft in the \nzone with no other distractions.\n(non-NCT TRACON) They can concentrate on one task \nand act quickly to establish separation when it doesn't \nwork correctly.\n(non-NCT TRACON) A dedicated position w/ override \ncapability is needed, as every other position would \nlikely be too busy to safely provide this service.\n(non-NCT TRACON) The available reaction time given \nthe close proximity of aircraft pairs requires a \ndedicated controller to the monitor function. Final \nApproac\nh Control 3 (Tower) Depends on facility. At [my facility], the Final & \nLocal controller would most likely do this. Local \nControlle\nr 2\n(Tower) At [my facility], 2000 and below should be \nmonitored by local due to all the airport vectoring and \nsituational awareness of terminal traffic. Other 1 It depends on how each individual operation is run. Dual Safety Limit Comfort 6.2.2\nIn the Day 1-2 Post-Run Questionnaires (QT1), controllers were asked: given the IM PA-related \ntools provided in this scenario, I was comfortable monitoring IM PA operations when both a \nCSL and WSL were active at the same time. Their responses were examined with respect to \nboth the IM PA Tools and monitor configurations. Response Means and Standard Deviations are \nsummarized in Table 5-4. Scale responses are shown in Figure 5-5. For the Separate Monitor \nconfiguration, only 28R Monitor responses are included because the safety limits did not apply \nto the 28L Monitor position. Table 5-4. Controller Responses to Dual Safety Limit Comfort x\n IM PA Tool Configuration Tools On Tools Off\nDB On / WSL-P Off\nDB Off / WSL-P On\nCombined 28L/28R Monitor Sample Size (n) 7 7 7 0 Mean (M) 94.0 92.7 75.9  Standard Deviation (SD) 8.4 8.2 31.6  28R Monitor\nSample Size (n) 7 7 0 7 Mean (M) 93.9 85.7 88.9 Standard Deviation (SD) 6.1 19.2 15.8 Figure 5-5. Given the IM PA-related Tools provided in this scenario, I was comfortable monitoring IM \nPA operations when both a CSL and WSL were active at the same time. *Combined Monitor configuration / **28R Monitor configuration\nNote: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. For the Combined 28L/28R Monitor configuration, all Week 2-3 TRACON controllers agreed they \nwere comfortable monitoring IM PA operations with both limits at the same time with IM PA \nTools On (M=94.0; SD=8.4) and IM PA Tools Off (M=92.7; SD=8.2). For the Separate 28R Monitor \nconfiguration position, all Week 2-3 TRACON controllers agreed with IM PA Tools On (M=93.9; \nSD=6.1). With IM PA Tools Off, the majority (86%) of controllers agreed (M=85.7; SD=19.2). One \ncontroller neither agreed nor disagreed in this case. As described in Section 5.8.1, a two-tailed T-\nTest analysis did not find a significant difference in strength of controller agreement between \nthe two IM PA Tool configurations. xi\n Responses were variable for the Data Block CSL Distance On / WSL-P Off configuration, but a \nmajority (86%) of Week 2-3 TRACON controllers agreed (M=75.9; SD=31.6). One controller \ndisagreed, however this same controller agreed to this question in both the IM PA Tools On and \nOff conditions. Therefore, this particular rating may not have been deliberate. All Week 2-3 \nTRACON controllers agreed with the Data Block CSL Distance Off / WSL-P On configuration \n(M=88.9; SD=15.8). IM Speed Control6.2.3\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if they were comfortable allowing an IM Trail \nAircraft to manage its own speed to achieve the desired spacing goal at the FAF. Responses \nare shown for all TRACON (NCT and non-NCT combined) and Tower Only. Response Means and \nStandard Deviations are summarized in Table 5-5. Scale responses are shown in Figure 5-6. Table 5-5. Controller Responses to Comfort in Allowing an IM Trail Aircraft to Manage its Own Speed Participant Experience TRACON Tower\nSample Size (n) 10 2 Mean (M) 76.5 87.5 Standard Deviation (SD) 19.8  Figure 5-6. I was comfortable allowing an IM Trail Aircraft to manage its own speed to achieve the \ndesired spacing goal at the Final Approach Fix. Note: o indicates NCT controller
responses. The majority (80%) of TRACON controllers agreed (M=76.5; SD=19.8) that they were \ncomfortable allowing an IM Trail Aircraft to manage its own speed to achieve the desired \nspacing goal at the FAF. Two controllers neither agreed nor disagreed. From the open-ended comments, at least three of the lower ratings appeared to be a result of \ncontrollers not being allowed to manually keep the IM Trail Aircraft between the limits when it \nbecame apparent that a Caution Alert was imminent. xii\n Traffic Awareness6.2.4\nAt the end of Day 1 and Day 2, controllers were asked about the acceptability of their overall \nlevel of traffic awareness with respect to the IM Lead Aircraft, IM Trail Aircraft, and Other \nAircraft. Their responses were examined with respect to monitor configuration. Response \nMeans and Standard Deviations are summarized in Table 5-6. Scale responses are shown in \nFigure 5-7. Only Week 2-3 TRACON controller responses were included in the analysis. Table 5-6. Controller Responses to Traffic Awareness Acceptability: Aircraft Type Monitor Configuration Separate Combined\nIM Lead Aircraft Sample Size (n) 7 7 Mean (M) 95.4 90.9 Standard Deviation (SD) 4.7 8.2 IM Trail Aircraft\nSample Size (n) 7 7 Mean (M) 83.7 87.3 Standard Deviation (SD) 18.7 15.3 Other Aircraft\nSample Size (n) 7 7 Mean (M) 82.9 88.0 Standard Deviation (SD) 23.5 8.4 Figure 5-7. My overall level of traffic awareness today was acceptable with respect to [IM Lead Aircraft \n IM Trail Aircraft / Other Aircraft]. xiii\n Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed their overall level of traffic awareness was acceptable \nwith respect to all aircraft types for both monitor configurations, except for Separate Monitors / \nOther Aircraft. In this case, the one participant that disagreed noted in the open-ended \ncomments: Difficult to determine distance between successive lead aircraft. This participant \nhas TRACON experience, though is currently assigned to a Tower position. This may help explain \nthe lower rating. The overall results do not suggest any apparent differences in acceptability by monitor \nconfiguration among aircraft types. However, Lead Aircraft response variability for the IM Lead \nAircraft appeared to be lower for the Separate Monitor configuration than for all the other \ncases. Other open-ended comments for this question included: (Non-NCT TRACON / Separate): Trails do not need to be monitored as closely because \nthere is automation to ensure separation. Focus can be spent elsewhere.\n(Non-NCT TRACON / Combined): Definitely was more aware of the trail aircraft because \nof the new procedures. But spacing required more attention to the lead aircraft \nfollowing other pairs.\n(Non-NCT TRACON / Combined): As the day went on, I focused more on distance \nbetween pairs as opposed to the aircraft in the PA. This was easy because of the alerts \nand warnings. Separation6.2.5\nThis section summarizes the subjective questionnaire data with respect to controller confidence \nof ensuring separation within the IM PA pairs. It also includes the objective data analysis with \nrespect to observed separation violations within and between the IM PA pairs on the arrivals. Subjective Data Assessment6.2.5.1\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked: overall, I was confident that I could assess \nwhether the separation between the IM Trail Aircraft and their Lead Aircraft would be \nmaintained. Responses are shown for all TRACON (NCT and non-NCT combined) and Tower \nOnly. Response Means and Standard Deviations are summarized in Table 5-7. Scale responses \nare shown in Figure 5-8. Table 5-7. Monitor Controller Responses to Confidence in Assessing Separation between IM Trail and \ntheir Lead Aircraft Participant Experience TRACON Tower\nSample Size (n) 10 2 xiv\n Mean (M) 77.9 75.5 Standard Deviation (SD) 21.1  Figure 5-8. Overall, I was confident that I could assess whether the separation between the IM Trail \nAircraft and their Lead Aircraft would be maintained. Note: o indicates NCT Controller responses. When asked if they could assess whether the separation between the IM Trail Aircraft and their \nLead Aircraft would be maintained, the majority (80%) of TRACON controllers agreed (M=77.9; \nSD=21.1). One TRACON controller disagreed and commented: Need CSL & WSL sooner. It is \nunclear why CSL was noted since it was present at the start of the IM PA operation. Though not \nshown, further analysis suggests the subjective separation assessment did not appear to be \naffected by varying the alert timing. Another open-ended comment from a TRACON controller noted: Relying on the automation. \nWithout it, I could not at this proximity. Objective Data Assessment6.2.5.2\nAs noted in Section 4.5.7.2, the simulation recorded aircraft state data and PTT click data for \neach scenario. This data was then post-processed to determine if any losses of separation \noccurred and if so, whether monitor configuration or IM PA Tool configuration had any effect. \nThis data only includes the Nominal and Alert Timing scenarios for Weeks 2-3 due to scenario \nchanges after Week 1. The Day 3 Lateral Deviation scenarios were not included in the post-\nprocessing analysis due to their complexity. There was one controller in Week 3 who had \nconsiderable experience at a major tower, but no TRACON experience. This participants \nseparation data is not included and 21 runs (across seven controller participants) were \nevaluated for the Day 1-2 Nominal scenarios. The same number of runs, 21, were also evaluated \nfor the Day 3 Alert Timing scenarios. Separation was considered within and between IM PA pairs. Within IM PA Pairs. Here, separation was considered lost if a trail aircraft crossed a CSL \nor WSL boundary before a controller contacted it to provide breakout instructions. \nContact was determined to have occurred if there was a PTT click between the time of a \nCaution Alert and the aircraft crossing either safety limit. xv\n Between Pairs. Here, separation was defined per the minima as described in Section \n4.3.3. If the spacing between any non-IM PA combination of aircraft went below than \nthe Wake Turbulence or MRS minima, it was considered a separation violation. The post-processing involved an automated script that examined the traffic data and flagged \ninstances where the above separation definitions were violated. Each resulting case was then \nverified manually against the controller display video capture videos and/or other MITRE \nvisualization tools. MITRE controller subject matter expert (SME) input was used to make a final \ndetermination of the instances that should count as violations. Across all the scenarios, the \nnumber of separation violations that were observed is summarized in Table 5-8: Table 5-8. Number of Observed Separation Violations (Weeks 2-3) Separation Violations Within IM PA \nPairs Between \nPairs Day 1-2 Nominal 0 10 Day 3 Alert Timing 1 2 Within IM PA Pair Separation Violations For the seven TRACON Week 2-3 participants, there were zero IM PA separation violations \nobserved for the 21 evaluated Day 1-2 Nominal scenarios. For the 21 evaluated Week 2-3, Day 3 Alert Timing scenarios, 5 cases were observed in which an \nIM Trail Aircraft crossed a safety limit line while it was still being displayed. These may have \nbeen cases, however, where the controller prioritized communicating a break out instruction to \nthe aircraft before terminating IM PA in the automation. A controller PTT click was observed \nbetween the time of the Caution Alert and the time of the crossing. As described in Section \n5.1.2, due to the lack of override capability, it was also possible that the controller was blocked \nand therefore the break out instruction could not be provided to the IM Trail Aircraft before IM \nPA was terminated and the safety limit line was crossed. These cases were therefore not \ncounted as violations as the controller may have in effect terminated the operation before the \nline was crossed. Further analysis was performed to examine how soon the PTT click happened \nin these cases before the crossing occurred. The results are shown in Table 5-9. Table 5-9. Day 3 Alert Timing Safety Limit Exceedances with PTT Response (Weeks 2-3) Case Alert Timing Safety Limit Crossed Time Between \nPreceding PTT click and Crossing\n1 25/15 WSL 8 sec\n2 25/15 CSL 11 sec\n3 25/15 CSL 9 sec\n4 25/15 CSL 17 sec xvi\n 5 25/15 WSL 9 sec M 10.8 sec\nSD 3.6 sec Only a single separation violation case was observed for the 21 evaluated Week 2-3, Day 3 Alert \nTiming scenarios, and it involved the 25/15 sec alert timing. In this scenario, an IM Trail Aircraft, \nAAL2435, was deliberately designed to maintain a faster-than-normal speed on the approach so \nthat the IM PA alerts would be triggered relative to its CSL. Shortly after the Predictive Alert was \ndisplayed, the controller issued a 30 kt speed reduction to this aircraft. Per the instructions to \nthe participants, the controller should then have terminated IM PA and broken the aircraft out. \nHowever, the controller elected to keep the IM PA active and watch the situation. The aircraft \nbegan to implement the 30 kt speed reduction but due to a simulation artifact, did not reduce \nfurther to its final approach speed after the FAF. A
Caution Alert was triggered and the aircraft \nexceeded the CSL on a three-mile final. Exactly 15 seconds after the Caution Alert was displayed, \nthe aircraft exceeded the CSL, as shown in Figure 5-9. The controller then terminated IM PA \napproximately two seconds later and issued the break out. Figure 5-9. IM PA Day 3 Alert Timing Scenario Separation Violation Although a situation like this was only observed to occur once across all of the evaluated \nscenarios, it supports comments and feedback from several controllers that they would like the \nability to try to manually provide speed assignments to aircraft that were at risk of encroaching \non a safety limit. It is notable that every observed instance of a safety limit exceedance, \nwhether or not it resulted in an IM PA separation violation, occurred with the shortest alert \ntiming values. Therefore, if a PA separation standard would allow controllers to manually \nmanage Trail Aircraft speeds, further alert timing research is recommended to examine values \nthat would ensure interventions can be successfully implemented before a safety limit is \nexceeded. Between Pair Separation Violations The Day 1-2 Nominal and Day 3 Alert Timing scenarios were also examined to determine if any \nseparation violations occurred between aircraft that were being separated with MRS or RECAT \nminima. Twelve total instances were observed; the circumstances are shown in Table 5-10. \nThese instances had many similar or identical circumstances and so they were then categorized \ninto five unique cases for analysis and discussion. In the table, Nom is short for Nominal, AT is \nshort for Alert Timing, Comb is short for Combined, and Sep is short for Separate. An MRS value \nof 2.5 NM within 10 NM of the runway was used in the analysis as the participants were trained \nthat they could allow that level of compression. xvii\n Table 5-10. Between Pair Separation Violations (Weeks 2-3) O\nc\nc\nu\nr\nr\ne\nn\nc\ne \nN\nu\nm\nb\ne\nr U\nn\ni\nq\nu\ne \nC\na\ns\ne Sc\nen\nar\nio \nTy\npe Cont\nrolle\nr \nConf\nigura\ntion IM \nPA \nTo\nols \n \nAle\nrt \nTi\nmi\nng \nCo\nnfi\ngur\nati\non\n* Lea\ndin\ng \nAir\ncra\nft \nTy\npe Lea\ndin\ng \nAir\ncra\nft \nRu\nnw\nay Tra\nilin\ng \nAir\ncra\nft \nTy\npe Tra\nilin\ng \nAir\ncra\nft \nRu\nnw\nay Separa\ntion \nStanda\nrd / \nValue \n(NM) IM \nPA \nAler\nt \ncon\ncurr\nent \nwit\nh \nViol\natio\nn? 1 A Nom Comb 4 B772 28L A320 28R RECAT / 5 Unk 2 Nom Comb 3 B772 28L A320 28R RECAT / 5 Yes\n3 Nom Comb 3 B772 28L A320 28R RECAT / 5 Yes\n4 Nom Comb 1 B772 28L A320 28R RECAT / 5 Yes\n5 Nom Comb 3 B772 28L A320 28R RECAT / 5 Yes\n6 Nom Comb 4 B772 28L A320 28R RECAT / 5 Yes\n7 Nom Comb 3 B772 28L A320 28R RECAT / 5 No 8 B Nom Comb 3 B772 28L B763 28L RECAT / 4 No\n9 C Nom Comb 4 A320 28R B763 28L MRS / 2.5 No 10 D Nom Sep 2 B772 28L B737 28L RECAT / 5 Unk 11 E AT Comb*\n* 35/20 A320 28R B763 28L MRS / 2.5 No 12 AT Comb*\n* 25/15 A320 28R B763 28L MRS / 2.5 Yes * IM PA Tool Configurations: [1] All On; [2] DB Distance Off / WSL-P On; [3] DB Disc On / WSL-P Off; and [4] All Off. \n** All Alert Timing scenarios used All Tools On and a Combined Monitor Configuration.\n A simulation error in the recording of the controller display for this scenario precluded further assessment. Case A. Of the ten Nominal scenario occurrences, seven involved the same aircraft pairing \nunder nearly identical circumstances. As a B772 aircraft (Category B) on 28L (UAL905) \napproached the runway threshold, the A320 aircraft (Category D) behind it on the parallel \nrunway (UAL136) continued to compress. Based on the Wake RECAT standards used in the HITL \n(Table 4-1), 5 NM was the required separation. However just before the B772 crossed the \nthreshold, the spacing reduced to between 4.8 to 4.9 NM, which at SFO is considered a \ncompression error. As shown in Figure 5-10, one controller used the STARS range tool to xviii\n 12 Controller video capture was not available for one of the runs and so the other circumstances at the time of this violation \nwere not able to be assessed. monitor this pair; however, still elected not to intervene. Figure 5-10. Case A: Example Separation Violation Between UPS905 and UAL136 At the time this occurred, one to two other IM PA alerting events were happening \nsimultaneously in the scenario. In at least four12 cases, UAL136 was experiencing a Predictive \nAlert as shown in Figure 5-10. In those same four cases, plus at least two more, an aircraft that \njust joined the 28R approach experienced a Caution Alert as shown in Figure 5-27. It is possible, \neven likely, that the controller participants were aware of the compression error occurring \nbetween these two aircraft. However, they may have determined that the safest course of \naction was to prioritize their attention with the IM PA issues occurring at the same time and let \nthe aircraft proceed to landing. Case B. This situation occurred in one of the Case A scenarios and involved one of the same \ncontrollers. This time, however, the separation violation occurred between the leading B772 \n(UAL905) and the trailing B763 (UAL951) arriving to the same runway as shown in Figure 5-11. \nBased on the Wake RECAT standards used in the HITL (Table 4-1), 4 NM between these aircraft \nwere required. The aircraft compressed to approximately 3.5 NM at the time UAL905 crossed \nthe threshold, as shown in Figure 5-12. At the time of this violation, there was no Predictive \nAlert for UAL136 and no Caution Alert (yet) for the aircraft joining the 28R Approach forward of \nthe CSL. Figure 5-11. Case B: Separation Violation Between UPS905 and UAL951 at the Time of Occurrence xix\n Figure 5-12. Case B: Minimum Observed Separation Between UPS905 and UAL951 Case C. This situation involved a B763 (UAL723, Category C) compressing to less than 2.5 NM \nbehind an A320 (JBU231, Category D) arriving to the parallel runway. Due to the weight \ncategories involved (C following D), 2.5 NM MRS was required. The situation at the time of the \nviolation is shown in Figure 5-13. As this was an All Tools Off scenario, this particular controller \nfound that placing a 1.5 NM ring around each Heavy IM Lead Aircraft helped keep track of \npairings in which a WSL would eventually become active. Figure 5-13. Case C: Separation Violation Between JBU231 and UAL723 at the Time of Occurrence As shown in Figure 5-14, the two aircraft compressed to approximately 2.25 NM at the time \nUAL905 crossed the threshold. No other scenario alerts were observed to have occurred during \nthis event. Figure 5-14. Case C: Minimum Observed Separation Between JBU231 and UAL723 Case D. This was the only case to involve the Separate Controller configuration. Here, a \nseparation violation occurred between a leading B772 and a trailing B737 arriving to the same \nrunway. Based on the Wake RECAT standards used in the HITL (Table 4-1), 5 NM were required \nbetween the two aircraft. From the aircraft state data, they compressed to 4.4 NM at their \nclosest point. A simulation error in the recording of the controller display for this scenario xx\n precluded further assessment. Case E. The two occurrences observed for the Alert Timing scenarios involved the same aircraft \npairing under similar circumstances. A B763 (DAL811, Category C) compressed to less than 2.5 \nNM behind an A320 (JBU432, Category D) arriving to the parallel runway. Due to the weight \ncategories involved (C following D), 2.5 NM MRS was required. The situation at the time of \nviolation occurrence 11 (as listed in Table 5-10) is shown in Figure 5-15. The situation at the \ntime of violation occurrence 12 is shown in Figure 5-16. Figure 5-15. Case E, Occurrence 11: Separation Violation Between JBU432 and DAL811 at the Time of \nOccurrence Figure 5-16. Case E, Occurrence 12: Separation Violation Between JBU432 and DAL811 at the Time of \nOccurrence The only difference between the two Case E scenarios was the alert timing values and that a \nPredictive Alert was displayed for occurrence 12 as it had the smaller value. However, this may \nnot have been a primary distraction as this violation was also observed in occurrence 11, where \nthere was no Predictive Alert for this pairing at the time of the occurrence (though it came a few \nseconds later). The situation was further complicated as JBU432 then experienced a WSL \nCaution Alert. The alert happened 18 seconds after the separation violation for occurrence 11 \n(Figure 5-17), and 11 seconds after the separation violation for occurrence 12 (Figure 5-18). \nControllers in both situations then terminated IM PA for JBU432. In both cases, the distance \nbetween the two aircraft at the time of the JBU432 Caution Alert was just over 2 NM. xxi\n Figure 5-17. Case E, Occurrence 11: Separation Between JBU432 and DAL811 at the Time of the JBU432 \nCaution Alert Figure 5-18. Case E, Occurrence 12: Separation Between JBU432 and DAL811 at the Time of the JBU432 \nCaution Alert In summary, twelve total separation violations were observed across the evaluated runs. They
\nwere distributed across the seven individual participants; every participant had at least one and \nno single controller was responsible for more than two. The separation violations occurred \nunder varying circumstances. Ten of the 12 involved aircraft arriving to different runways, and 9 \nof the 12 involved a Category B aircraft in the lead. In at least half of the occurrences, an IM PA \nPredictive or Caution Alert was active on the display at the time of the separation violation, \nwhich may have served as either a distraction or was determined to be a higher priority. It \nshould also be noted that ATPA functionality and data block weight category information (other \nthan identifying Heavy aircraft) were not present. This made the between-pair separation task \nmore difficult than what controllers were used to, as several noted in open-ended comments. Eight of the 12 violations occurred with either just the WSL-P Off (IM PA Tool configuration 3 as \nshown in Table 5-10) or both the Data Block Distances and WSL-P Off (IM PA Tool configuration \n4). When reviewing the individual occurrences, however, they either happened late in the \napproach when the WSL was already active or had other circumstances that made it challenging \nto see what effect a WSL-P might have for helping to avoid the occurrence. As these \noccurrences did not appear to be related to IM PA, at least directly, it seems unlikely that the \npresence or absence of the WSL-P may have been a contributing factor. Across the 10 Nominal Scenario occurrences, 9 involved the Combined Monitor configuration. \nHowever, a review of the equivalent scenarios for cases A and B during the Separate Monitor xxii\n configuration runs showed that the separation for these pairs only decreased below the RECAT \nminima once the leading B772 crossed the runway threshold. Observer notes for these \nscenarios did not indicate any controller interventions that would have precluded this \ncompression error from occurring. Therefore, this occurrence of the violation in these cases was \nonly present in the Combined Monitor Scenarios. It is likely more of an artifact of the slight \ntiming variations between the scenarios and thus cannot be conclusively attributed to monitor \nconfiguration. IM PA pair-wise separation assurance appeared to be a straightforward task for controllers as \nonly a single violation was observed within an IM Trail Aircraft and IM Lead Aircraft pairing, \ndespite the introduction of far more lateral and longitudinal deviations than would be expected \nin actual operations. This instance involved a controller appearing to attempt to manually assign \na speed to keep an IM Trail Aircraft behind the CSL and allowing the IM PA operation to \ncontinue. The controller may have then expected the aircraft to reduce to its final approach \nspeed; however it did not due to a simulation artifact. Still, the aircraft crossed the CSL before \nthe controller commanded a break out. Though the controller should have terminated IM PA \nand commanded a break out sooner than what occurred, this instance was not a result of the \ncontroller failing to notice a developing situation. The separation violation occurrences observed between the aircraft pairs not performing IM PA \nhappened under varying circumstances, which makes it difficult to conclude that they were \nsignificantly influenced by the presence of IM PA operations in the environment or any of the \nindependent variable manipulations. They may have been more related to controllers in the \nsimulation not having current separation tools such as ATPA available to them. Although these \nviolations occurred in the context of simulation events that were designed to stress test the \nconcept and ground tools, their presence still suggests that tools and procedures need to be \nfully integrated to ensure that separation between aircraft pairs not performing IM PA can be \nmaintained while IM PA operations are in progress. In addition, IM PA setup spacing \nrequirements should ensure that between-pair separation can be sufficiently maintained during \ncompression on final. Task Acceptability by Position6.2.6\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nRole configurations, controllers were asked if the tasks required of each simulation position \nwere acceptable. Responses are shown for all TRACON (NCT and non-NCT combined) and Tower \nOnly. Response Means and Standard Deviations are summarized in Table 5-11. Scale responses \nare shown in Figure 5-19. Table 5-11. Controller Responses to Task Acceptability by Position Participant Experience TRACON Tower\nCombined Monitor Sample Size (n) 10 2 xxiii\n Mean (M) 86.9 86.5 Standard Deviation (SD) 15.4  28L Monitor\nSample Size (n) 10 2 Mean (M) 90.0 82.5 Standard Deviation (SD) 7.3  28R Monitor\nSample Size (n) 10 2 Mean (M) 90.1 81.0 Standard Deviation (SD) 7.6  28R Final Approach\nSample Size (n) 10 2 Mean (M) 84.2 89.0 Standard Deviation (SD) 14.6  Figure 5-19. The tasks required of each simulation position were acceptable. Note: o indicates NCT Controller responses. When asked if the tasks required of each simulation position were acceptable, all (100%) \nTRACON controllers agreed for the Separate 28L (M=90.0; SD=7.3) and 28R (M=90.1; SD=7.6) \nMonitor positions. In the Combined Monitor configuration, the majority (90%) of controllers \nagreed (M=86.9; SD=15.4). One controller neither agreed nor disagreed in this case. For the 28R \nFinal Approach position, the majority (90%) of controllers agreed (M=84.2; SD=14.6). The same \ncontroller that neither agreed nor disagreed in the Combined Monitor configuration, also xxiv\n neither agreed nor disagreed in this case. From the open-ended comments, one controller noted that the final could be much more \ndifficult than we saw today. Given point outs, traffic calls, Visual Flight Rules (VFRs), and other \ncoordination, it may be difficult to clear and give spacing in the short window afforded. This is \nan understandable comment, given that the Final Approach position in the simulation was \nintended to be a part task position to evaluate the Partial IM Clearance phraseology and \ncommunication of the Assigned Spacing Goal. Due to the setup assumptions detailed in Section \n4.3.1, it did not involve vectoring to final. Overall, the tasks required for the combined 28L/28R Monitor position, separate 28L and 28R \nMonitor positions, and 28R Final Approach position all appeared to be acceptable. General Comments: Likes, Concerns, Improvements6.2.7\nThe Day 2 Final Questionnaire (QT3) included questions relating to what controllers generally \nliked about IM PA, what concerned them, and what aspects of the operation could be improved. \nThis section summarizes the controller responses. Given their specific experience in the areas \nbeing simulated, NCT responses are specifically identified. Non-NCT TRACON and Tower \nresponses are thus also individually identified. When asked if there were any aspects of the IM PA operation that you especially liked, \ncontrollers provided the following comments: (NCT) Extra [number] of planes potentially landing per hour.\n(NCT) I liked that heavies could be the lead or trailing aircraft. \n (Non-NCT TRACON) Ability to run more aircraft in with lower visibility/ceilings.\n(Non-NCT TRACON) The ability not to have to watch the spacing closely knowing an alert \nwould occur if anything needed to be done.\n (Non-NCT TRACON) The CSL & WSL lines are useful.\n(Non-NCT TRACON) Simplicity of 28R final. There aren't really options, traffic just needs \n[to be] pulled out if spacing is lost. Makes that part idiot proof.\n(Non-NCT TRACON) Entire operation is very straight forward and easy to understand. Controllers were also asked if they had concerns with any aspect of the IM PA operation. The \nmajority of the responses were related to wanting more manual control when it became clear \nan aircraft was going to encroach upon a safety limit. Several controllers expressed frustration \nthat they were unable to manually issue a speed to keep an IM Trail Aircraft within the limits \nwhen they observed a spacing situation start to develop. Other comments included: (NCT) Shipping the aircraft to the tower so early clearly is not a practical application, I \nwas transmitting way too much as the monitor, that would cause a real unsafe situation \nfor the local controller having to split time with the monitor.\n(Non-NCT TRACON): WSL is my main concern. It shows up late and without a preview \nWSL, I focus too much on the area of final where WSL activates. xxv\n (Non-NCT TRACON) When a pair appeared as though they were close to alerting, I \nfocused on that pair (so as not to miss an alert) and lost some degree of focus on the \nother pairs.\n(Non-NCT TRACON) Judging spacing and separation between aircraft outside the pairs on \nadjacent approach courses.\n(Tower) The initial separation using IM before predictions are turned on. Controllers were also asked how the conduct of IM PA operations could be improved. Related \nto the concern about not being able to intervene manually to keep an IM Trail Aircraft within \nthe safety limits, several controllers, including those from NCT, suggested allowing controllers to \nissue speeds to the trailing aircraft to allow it to stay on the approach. Another NCT controller \nsuggested that the Assigned Spacing Goal should be in data block and that if an aircraft starts to \nencroach on a safety limit, controllers should be able to cancel IM, resolve the issue, then re-\ninitiate
IM once the trailing aircraft is back within the limits. Another participant felt that the IM \nportion of the operation was not a requirement and noted that if IM was not available, but the \nCSL and WSL lines were, controllers could manually provide speeds to keep a trailing aircraft \nwithin the safety limits and save a go-around. Some controllers also commented on the need for more predictive information, earlier. This \nincluded providing the WSL lines sooner and adding a CSL Preview line on the display to \nindicate where the IM Trail Aircraft was relative to the IM PA safety limits before controllers \nneeded to provide the IM Clearance. This would enable a Tower controllers request for the \nability to adjust speeds prior to the start of IM PA to increase the probability of the trail aircraft \nachieving its spacing. Comments were also made with respect to the feeder and final approach tasks. These included: (NCT) For this to provide the greatest benefit and efficiency, the vectoring to final by the \nfeeders/final will be the most critical part. If that is done well, this offers much hope.\n(NCT) Figure out some phraseology, maybe high feeder can tell trail aircraft to expect to \nfollow so final controller only has to say spacing interval & issue approach clearance.\n(Non-NCT TRACON) More airspace for final to finesse if feeder didn't achieve correct \nspacing. Spacing between 28R and following 28L traffic should be retained. Crossing \nrestriction for 28R final so clearance can be issued early.\n(Non-NCT TRACON) For future implementation, a fix with an above crossing altitude \nwould allow final to clear for the approach, then assign the spacing goal once established \non final, which would make the timing less critical.\n(Non-NCT TRACON) Cancelling approach clearance should automatically terminate IM \nspacing.\n(Tower) The Monitor should have its own frequency, as opposed to being a Local \noverride. xxvi\n Results Topic 2: 28R Final Position6.3\nThis section includes results related to the examination of the 28R Final controller IM PA \ninitiation task. The metrics consisted of: workload, IM PA initiation acceptability and \ninformation requirements, IM Clearance communications, IM Speed control, and separation at \nhandoff. It also summarizes participant responses to open-ended questions related to the 28R \nFinal controller role and IM PA initiation. The scenario changes that precluded the inclusion of Week 1 monitoring task data in the results \ndid not affect the 28R Final controller position tasking. Therefore, the data in this section \nincludes response data from all three weeks, unless otherwise indicated. Also, as with the \nMonitor positions, IM PA Tool configuration was also varied for the 28R Final controllers. \nSeveral of the metrics in this section were thus examined with respect to having IM PA Tools On \nand IM PA Tools Off. Workload6.3.1\nAt the end of each run, controllers were asked to rate their workload for the scenario they just \nexperienced (QT1) using the Bedford Workload Scale. Their responses were then examined with \nrespect to IM PA Tool configuration. Response Means and Standard Deviations are summarized \nin Table 5-12. Scale responses are shown in Figure 5-20. Only TRACON controller responses \nwere included in the analysis. Table 5-12. Controller Average Workload Ratings for 28R Final Position IM PA Tool Configuration Tools On Tools Off\nSample Size (n) 10 10 Mean (M) 1.7 1.8 Standard Deviation (SD) 0.5 0.6 Figure 5-20. Controller Average Workload Ratings for 28R Final Position Note: o indicates NCT Controller responses. On average, the TRACON controllers reported low workload in the 28R Final controller position \nfor IM PA Tools On (M=1.7; SD=0.5) and IM PA Tools Off (M=1.8; SD=0.6). No practical \ndifference was observed between the two IM PA Tool configurations. --------------------------------- xxvii\n At the end of each run (QT1), controllers were also asked if their overall workload was \nacceptable for the scenario they just experienced. Their responses were then examined with \nrespect to IM PA Tool configuration. Response Means and Standard Deviations are summarized \nin Table 5-13. Scale responses are shown in Figure 5-21. Only TRACON controller responses \nwere included in the analysis. Table 5-13. Controller Responses to Acceptability of Overall Workload for 28R Final Position IM PA Tool Configuration Tools On Tools Off\nSample Size (n) 10 10 Mean (M) 90.2 92.5 Standard Deviation (SD) 15.0 12.0 Figure 5-21. 28R Final Controller: My overall workload was acceptable for the scenario I just \nexperienced. Note: o indicates NCT Controller responses. On average, the TRACON controllers reported acceptable workload in the 28R Final controller \nposition for IM PA Tools On (M=90.2; SD=15.0) and IM PA Tools Off (M=92.5; SD=12.0). No \npractical difference was observed between the two IM PA Tool configurations. Open-ended \ncomments suggested that workload was low and that more tasks could have been handled. IM PA Initiation Task6.3.2\nAt the end of each run (QT1), controllers were asked questions regarding the IM PA initiation \ntask. These were: Given the appropriate training, and the IM PA-related tools I had available in this \nscenario, Final controllers can acceptably initiate the IM PA operation.\nOnce the IM Trail Aircraft joined the final, I had sufficient time and airspace to initiate \nIM PA before transferring the aircraft to the Local controller.\nIn this scenario, I had the necessary display elements to provide the appropriate IM \nClearance information to the trail aircraft in an IM PA pair. Their responses were then examined with respect to IM PA Tool configuration. Response Means xxviii\n and Standard Deviations for each question are summarized in Table 5-14. Scale responses are \nshown in Figure 5-22. Only TRACON controller responses were included in the analysis. xxix\n Table 5-14. Controller Responses to IM PA Initiation Task IM PA Tool Configuration Tools On Tools Off\nFinal controllers can acceptably \ninitiate the IM PA operation Sample Size (n) 10 10 Mean (M) 81.2 73.6 Standard Deviation (SD) 31.4 29.1 Sufficient time and airspace to \ninitiate IM PA Sample Size (n) 10 10 Mean (M) 76.5 74.5 Standard Deviation (SD) 34.3 27.8 Had the necessary display \nelements Sample Size (n) 10 10 Mean (M) 86.7 83.1 Standard Deviation (SD) 20.3 18.8 Figure 5-22. IM PA Initiation Task Responses Note: o indicates NCT controller responses. Controller responses were variable for the first question, but a majority (80%) agreed Final \ncontrollers can acceptably initiate the IM PA operation with IM PA Tools On (M=81.2; SD=31.4) \nand with IM PA Tools Off (M=73.6; SD=29.1). The high variability resulted from strong xxx\n disagreement by a non-NCT TRACON controller, who indicated in the open-ended comments \nthat the WSL was needed sooner. In the IM PA Tools Off case, another non-NCT controller \ndisagreed and explained this rating in a comment by saying the CSL and WSL are needed \nsooner. Despite this, no practical difference between the two IM PA Tool configurations was \nobserved for this question. Other open-ended comments for this question included: (non-NCT TRACON / Tools On) The [Spacing] list is very clear and easy to understand. I \nlike having the list displayed in the order the radio transmissions are made. \n(non-NCT TRACON / Tools Off) There was an aircraft that is already ahead of CSL when \nclearance is issued \n\"preview\" CSL available prior to initiation of IM Clearance to prevent this.\n(NCT) Spacing list should show all aircraft, not just who can play. Controller responses were also variable for the second question, but a majority (70%) agreed \nonce the IM Trail Aircraft joined the final, they had sufficient time and airspace to initiate IM PA \nbefore transferring the aircraft to the Local controller. This was for both IM PA Tools On \n(M=76.5; SD=34.3) and with IM PA Tools Off (M=74.5; SD=27.8). One NCT controller disagreed \nfor both configurations and explained in a comment that more than 2-3 miles are needed when \nthe aircraft turns on final. The controller noted further that 7-10 miles would help make sure \naircraft are in a better position. However, two non-NCT controllers felt there was sufficient time \nand airspace to initiate IM PA. One commented that this was because the aircraft were already \nsequenced and vectored to join the final approach course. Another noted that a 20 mile final at \n6000 ft is sufficient time and altitude. No practical difference between the two IM PA Tool \nconfigurations was observed for this question. Controller responses were less variable for the third question. A majority (90%) agreed they had \nthe necessary display elements to provide the appropriate IM Clearance information to the trail \naircraft in an IM PA pair. This was for both IM PA Tools On (M=86.7; SD=20.3) and with IM PA \nTools Off (M=83.1; SD=18.8). In explaining a disagree rating with IM PA Tools On, one NCT \ncontroller commented that the data block should include the Assigned Spacing Goal and that \nregular viewing of the Spacing List distracts from scanning the traffic. A different NCT controller \nwith a disagree rating with IM PA Tools Off commented that the CSL should be available prior to \ninitiating IM PA. No practical difference between the two IM PA Tool configurations was \nobserved for this question. Other open-ended comments for this question included: (Non-NCT TRACON / Tools On) Spacing list read
easily from left to right.\n(NCT / Tools On) Yes but the box is annoying & I couldnt find an acceptable location to \nhave it on my scope.\n(NCT / Tools Off) Would be nice if spacing list has indicator if it was a heavy next to \naircraft call sign that aircraft are pairing with. xxxi\n IM Clearance Communications6.3.3\nAt the end of Day 2 (QT3), controllers were asked two questions regarding the acceptability of \nIM Clearance communications. These were: It is operationally acceptable for the Final controller to provide the IM PA spacing goal.\nThe IM PA spacing goal communication was acceptable. Responses are shown for all TRACON (NCT and non-NCT combined) and Tower Only. Response \nMeans and Standard Deviations are summarized in Table 5-15. Scale responses are shown in \nFigure 5-23. Table 5-15. Controller Responses to IM Clearance Communications Acceptability Participant Experience TRACON Tower\nFinal Controller Provides Spacing Goal Sample Size (n) 10 2 Mean (M) 81.3 89.0 Standard Deviation (SD) 12.9  Spacing Goal Communication\nSample Size (n) 10 2 Mean (M) 61.6 81.0 Standard Deviation (SD) 33.4  Figure 5-23. It is operationally acceptable for the Final controller to provide the IM PA spacing goal and \nthe IM PA spacing goal communication was acceptable. Note: o indicates NCT controller responses. For the first question, all (100%) TRACON controllers agreed it is operationally acceptable for \nthe Final controller to provide the IM PA spacing goal (M=81.3; SD=12.9). One non-NCT TRACON xxxii\n controller commented that it takes the place of speed control so there was little impact on \nworkload. Two other controllers noted that the phraseology could be consolidated and \nimproved. One suggestion was that the word Goal should be replaced with your interval \nspacing. Controller responses were variable for the second question, but a majority (70%) agreed the IM \nPA spacing goal communication was acceptable (M=61.6; SD=33.4). The controllers that \ndisagreed provided comments that suggested they had concerns with the overall phraseology \nand that there were too many transmissions on the override frequency. Their disagreement did \nnot appear to be specifically related to providing the Assigned Spacing Goal. Another open-ended comment for this question included: (Non-NCT TRACON) Seconds is unfamiliar to controllers and somewhat cumbersome to \nsay. I don't know what the alternative could be though. --------------------------------- Controllers were also asked at the end of Day 2 (QT3) whether they were comfortable with the \nuse of the Lead Aircraft call sign in the IM Clearance communication. Responses are shown for \nall TRACON (NCT and non-NCT combined) and Tower Only. Response Means and Standard \nDeviations are summarized in Table 5-16. Scale responses are shown in Figure 5-24. Table 5-16. Controller Responses to Use of Lead Aircraft Call Sign in the IM Clearance Participant Experience TRACON Tower\nSample Size (n) 10 2 Mean (M) 69.1 86.5 Standard Deviation (SD) 28.9  Figure 5-24. I was comfortable with the use of the Lead Aircraft call sign in the IM Clearance \ncommunication. Note: o indicates NCT controller responses. TRACON controller responses were variable, but the majority (80%) agreed they were \ncomfortable with the use of the Lead Aircraft call sign in the IM Clearance communication xxxiii\n (M=69.1; SD=28.9). One controller disagreed and another neither agreed nor disagreed. IM Speed Control6.3.4\nAt the end of each run (QT1), controllers were asked if they were comfortable with the IM Trail \nAircraft managing their speeds to achieve the spacing goal I assigned, while they were in my \narea. Their responses were then examined with respect to IM PA Tool configuration. Response \nMeans and Standard Deviations are summarized in Table 5-17. Scale responses are shown in \nFigure 5-25. Only TRACON controller responses were included in the analysis. Table 5-17. 28R Final Controller Speed Control Responses IM PA Tool Configuration Tools On Tools Off\nSample Size (n) 10 10 Mean (M) 90.1 80.3 Standard Deviation (SD) 15.4 25.9 Figure 5-25. 28R Final Controller: I was comfortable with the IM Trail Aircraft managing their speeds to \nachieve the spacing goal I assigned, while they were in my area. Note: o indicates NCT controller responses. The majority (90%) of TRACON controllers agreed they were comfortable with the IM Trail \nAircraft managing their speeds to achieve the spacing goal with IM PA Tools On (M=90.1; \nSD=15.4) and IM PA Tools Off (M=80.3; SD=25.9). With IM PA Tools On, one controller neither \nagreed nor disagreed. Though the response variability was lower with IM PA Tools On, no \npractical difference was observed between the IM PA Tool configurations for the 28R Monitor \nposition. Separation at Handoff6.3.5\nAt the end of Day 2 (QT3), controllers were asked two questions regarding IM Trail Aircraft \nseparation at the time of handoff to the Local controller. These were: Given the appropriate training, and the IM PA-related tools I had available in this \nscenario, Final controllers can acceptably ensure separation during IM PA operations \nbefore transferring aircraft to the Local controller. xxxiv\n I was comfortable that I was transferring appropriately separated aircraft to the Local \ncontroller. Their responses were examined with respect to both the IM PA Tools and monitor \nconfigurations. Response Means and Standard Deviations are summarized in Table 5-18. Scale \nresponses are shown in Figure 5-26. Table 5-18. 28R Final Controller Responses to Separation at Handoff IM PA Tool Configuration Tools On Tools Off\nAcceptable Separation Before \nHandoff Sample Size (n) 10 10 Mean (M) 68.7 82.0 Standard Deviation (SD) 34.7 23.6 Transferred Appropriately \nSeparated Aircraft Sample Size (n) 10 10 Mean (M) 77.4 84.0 Standard Deviation (SD) 31.2 17.6 Figure 5-26. Final Controllers can acceptably ensure separation during IM PA operations before \ntransferring aircraft to the Local controller and I was comfortable that I was transferring appropriately separated aircraft to the Local controller. Note: o indicates NCT controller responses. Controller responses were variable for the first question, but a majority (60%) agreed Final \ncontrollers can acceptably ensure separation during IM PA operations, before transferring \naircraft to the Local controller with IM PA Tools On (M=68.7; SD=34.7). A majority (80%) also \nagreed with IM PA Tools Off (M=82.0; SD=23.6). Though no practical difference was observed xxxv\n between IM PA Tool configurations, response variability was lower with IM PA Tools Off. It is \nunclear why. The four controllers that disagreed when IM PA Tools were On provided the following \ncomments: (NCT / Tools On) For Foster this statement is true, because no speeds are being assigned \nto the trail, but Woodside might have to hold onto the aircraft to ensure separation.\n(NCT / Tools On) We have to ship them too early. You are asking finals to ensure \nseparation and then ship them far out right before most of the speed adjustments for in \ntrail spacing are made.\n(NCT / Tools On) Need to have some sort of CSL or WSL line on so controller knows \nbefore they clear aircraft if they are within the zones. \n(Non-NCT TRACON / Tools On) Need to figure out when and where spacing can be lost \nbefore ship to tower, possibly re-design approaches to accommodate. Controller responses were also variable for the second question, but a majority (80%) agreed \nthey were comfortable that they were transferring appropriately separated aircraft to the Local \ncontroller with IM PA Tools On (M=77.4; SD=31.2). A majority (90%) also agreed with IM PA \nTools Off (M=84.0; SD=17.6). Though no practical difference was observed between IM PA Tool \nconfigurations, response variability was lower with IM PA Tools Off. It is unclear why. One NCT controller that disagreed when IM PA Tools were On provided the following comment: (NCT / Tools On) Again, for Foster it's no big deal, but for the Woodside controller \nspacing can change dramatically 15-2 miles and in. Open-Ended Questions6.3.6\nThe 28R Final controller Post-Run Questionnaires (QT1) included general questions relating to \nwhat controllers liked about IM PA and what concerned them. This section summarizes \nresponses specific to 28R Final controller tasking. Given their experience in the areas being \nsimulated, NCT responses are specifically identified. Non-NCT TRACON and Tower responses are \nthus also individually identified. When asked if there was any operational information not provided in this scenario that you \nwould have found helpful, numerous comments were made that related to adding predictive \nCSL and WSL lines. A representative comment by a TRACON controller was: A preview of where \nthe CSL will be would be useful before clearing for the approach. That way a clearance would \nnot need to be cancelled immediately if the aircraft was ahead of it. As shown in Figure 5-27, controllers experienced this situation in one of the nominal scenarios. \nIn this case, VRD112 was inside of the allowable spacing with the IM Lead Aircraft, UAL857, at \nthe time of initiation. This was not apparent from the display, thus the 28R Final controller had \nto terminate IM PA for that pair just after providing the clearance. A preview CSL would have \nhelped avoid this situation. xxxvi\n Figure 5-27. CSL Caution Alert at Time of Initiation Controllers were also asked if they had concerns with any aspect of the IM PA operation while \nworking as the 28R Monitor. Comments included: (NCT) Monitor breaking
a guy out at a higher altitude. Prob not a concern in real life \nbecause programs would be in place to standardize.\n(NCT) (Aircraft in front of CSL) what if I needed to take aircraft off final to get them in the \nzone, no tools to show me how much I need, if I needed a short vector to set aircraft in \nzone.\n(NCT) Not enough space for final controller to make speed adjustments if needed. Results Topic 3: Monitor Configurations6.4\nThe analyses in this section examine the Combined and Separate Monitor configurations for the \nDay 1-2 Nominal scenarios. No lateral deviations were deliberately introduced; further monitor \nconfiguration results for these off-nominal conditions are described in Section 5.6. As described in Table 4-5, monitor configuration for the Day 1-2 Nominal scenarios was divided \nby simulation day. That is, the same monitor configuration was used for the first day, then the \nother configuration was used for the second day. As the IM PA Tool configurations and \nscenarios were varied in the same way between the two days, monitor configuration was the \nprimary difference. Therefore, differences between the days with respect to the various metrics \nshould be primarily attributable to the difference in monitor configuration. These metrics \ninclude: Workload, Clarity of Roles and Responsibilities, Spacing Issue Detection, and \nEffectiveness and Acceptability. Workload Acceptability6.4.1\nAt the end of Day 1 and Day 2 (QT2), controllers were asked if their overall workload today was \nacceptable. Their responses were then examined with respect to monitor configuration. \nResponse Means and Standard Deviations are summarized in Table 5-19. Scale responses are \nshown in Figure 5-28. Only Week 2-3 TRACON controller responses were included in the \nanalysis. Table 5-19. Controller Responses to Acceptability of Overall Workload (Nominal Scenarios) Monitor Configuration xxxvii\n Separate Combined\nSample Size (n) 7 7 Mean (M) 96.1 95.7 Standard Deviation (SD) 3.8 6.7 Figure 5-28. My overall workload today was acceptable. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed their overall workload was acceptable for both the \nSeparate Monitor configuration (M=96.1; SD=3.8) and Combined Monitor configuration \n(M=95.7; SD=6.7). No practical difference was observed between the two monitor \nconfigurations. With respect to workload by monitor configuration, open-ended comments included: (Non-NCT TRACON / Separate Monitor configuration) Busier than [Combined], due to \nrequired speed control. The IM PA was a very minimal part of the workload.\n(Non-NCT TRACON / Separate Monitor configuration) Workload this low could lull a \ncontroller into complacency.\n(Non-NCT TRACON / Separate Monitor configuration) Somewhat complex with spacing \ncomplexity between different runways and types. Not overworked, but not in drone \nzone.\n(Non-NCT TRACON / Combined Monitor configuration) I felt better about working both \ncombined. The extra traffic helped me to stay focused. Clarity of Roles and Responsibilities6.4.2\nAt the end of Day 1 and Day 2 (QT2), controllers were asked if when monitoring today, my roles \nand responsibilities with respect to the IM Lead Aircraft, IM Trail Aircraft, and Other Aircraft \nwere clear. Their responses were examined with respect to monitor configuration. Response \nMeans and Standard Deviations are summarized in Table 5-20. Scale responses are shown in \nFigure 5-29. Only Week 2-3 TRACON controller responses were included in the analysis. Table 5-20. Controller Responses to Clarity of Roles and Responsibilities xxxviii\n Monitor Configuration Separate Combined\nIM Lead Aircraft Sample Size (n) 7 7 Mean (M) 96.7 93.9 Standard Deviation (SD) 3.6 8.3 IM Trail Aircraft\nSample Size (n) 7 7 Mean (M) 96.9 93.4 Standard Deviation (SD) 3.6 8.0 Other Aircraft\nSample Size (n) 7 7 Mean (M) 96.7 92.4 Standard Deviation (SD) 3.6 8.5 Figure 5-29. When monitoring today, my roles and responsibilities with respect to the IM Lead Aircraft, \nIM Trail Aircraft, and Other Aircraft were clear. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed their roles and responsibilities were clear with respect \nto all aircraft for both monitor configurations. Though no practical differences were observed in \nthe responses, the overall response variability was slightly greater for the Combined Monitor \nconfiguration. Spacing Issue Detection6.4.3\nAt the end of Day 1 and Day 2 (QT2), controllers were asked if they were able to detect in a \nsufficient amount of time when spacing / separation issues were developing within an IM PA xxxix\n Aircraft Pair and Between Other Combinations. Their responses were examined with respect to \nmonitor configuration. Response Means and Standard Deviations are summarized in Table 5-21 \n. Scale responses are shown in Figure 5-30. Only Week 2-3 TRACON controller responses were \nincluded in the analysis. Table 5-21. Controller Responses to Detection of Developing Spacing / Separation Issues Monitor Configuration Separate Combined\nWithin an IM PA Aircraft Pair Sample Size (n) 7 7 Mean (M) 94.7 90.7 Standard Deviation (SD) 7.5 9.2 Between Other Combinations\nSample Size (n) 7 7 Mean (M) 87.6 79.4 Standard Deviation (SD) 14.7 13.1 Figure 5-30. I was able to detect in a sufficient amount of time when spacing / separation issues were \ndeveloping within an IM PA Aircraft Pair and Between Other Combinations. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed they were able to detect in a sufficient amount of time \nwhen spacing / separation issues were developing within an IM PA pair and Between Other \nCombinations for both monitor configurations. Though no practical differences were observed \nin the responses between the two monitor configurations, the means were slightly higher and \noverall response variability was slightly lower for IM PA pairs versus other aircraft pair \ncombinations. With respect to spacing issue detection, open-ended comments included: (Non-NCT TRACON / Separate Monitor configuration) The pairs were easier to determine xl\n and required less focus.\n(Non-NCT TRACON / Combined Monitor configuration) The IM PA pair did not have to be \nwatched nearly as closely which allowed focus on the other a/c spacing.\n(Non-NCT TRACON / Combined Monitor configuration) It is more difficult to determine \ndistance between pairs than it is within pairs. Effectiveness and Comfort6.4.4\nAt the end of Day 1 and Day 2 (QT2), controllers were asked if given the appropriate training \nand IM PA-related tools, IM PA operations can be effectively monitored by the number of \npositions I experienced today. Their responses were then examined with respect to monitor \nconfiguration. Response Means and Standard Deviations are summarized in Table 5-22. Scale \nresponses are shown in Figure 5-31. Only Week 2-3 TRACON controller responses were included \nin the analysis. Table 5-22. Controller Responses to Effective Monitoring Monitor Configuration Separate Combined\nSample Size (n) 7 7 Mean (M) 96.6 90.9 Standard Deviation (SD) 3.9 9.3 Figure 5-31. Given the appropriate training and IM PA-related tools, IM PA operations can be \neffectively monitored by the number of positions I experienced today. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed IM PA operations can be effectively monitored by both \nthe Separate Monitor configuration (M=96.6; SD=3.9) and Combined Monitor configuration \n(M=90.9; SD=9.3). Though no practical differences were observed in the responses, the overall \nresponse variability was slightly greater for the Combined Monitor configuration. With respect to monitoring effectiveness by configuration, open-ended comments included: (NCT / Separate Monitor configuration) Depends on traffic, but two monitors \n[controllers] seem better than one. xli\n (Non-NCT TRACON / Separate Monitor configuration) Maybe overly monitored, but \ndefinitely effective.\n(NCT / Separate Monitor configuration) I feel it could be done by final by itself.\n(Non-NCT TRACON / Combined Monitor configuration) Better today with one monitor. --------------------------------- At the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if given the appropriate training and IM PA-\nrelated tools, a single (Combined) Monitor controller can effectively ensure separation across \nboth approaches during IM PA operations. Responses are shown for all TRACON (NCT and non-\nNCT combined) and Tower Only. Response Means and Standard Deviations are summarized in \nTable 5-23. Scale responses are shown in Figure 5-32. Table 5-23. Controller Responses to whether a Single (Combined) Monitor Controller can Effectively \nEnsure Separation Across Both Approaches Participant Experience TRACON Tower\nSample Size (n) 10 2 Mean (M) 84.2 89.0 Standard Deviation (SD) 15.6  Figure 5-32. Given the appropriate training and IM PA-related tools, a single (Combined) Monitor \ncontroller can effectively ensure separation across both approaches during IM PA operations. Note: o indicates NCT controller responses. The majority (90%) of TRACON controllers agreed (M=84.2; SD=15.6) that a single Monitor \ncontroller can effectively ensure separation across both approaches during IM PA operations. \nOne NCT controller neither agreed nor disagreed and noted that more runs as a single monitor \nwould be helpful to evaluate this better. With respect to the effectiveness of a Combined Monitor position, open-ended comments \nincluded: (Non-NCT TRACON) I think it would be reasonable, especially when the final controller \nsets up a well-spaced final. xlii\n (Non-NCT TRACON) Depends on airport, but KSFO
seems to work better combined.\n(Non-NCT TRACON) If using STARS display, two monitors should be used. If using FMA, \none monitor is okay. To examine if the IM PA Tool configuration affected the effectiveness of the Combined Monitor \nconfiguration, controllers were asked the same question at the end of each run (QT1). Their \nresponses were then examined with respect to IM PA Tool configuration. Response Means and \nStandard Deviations are summarized in Table 5-24. Scale responses are shown in Figure 5-33. Table 5-24. Controller Responses to whether a Single (Combined) Monitor Controller can Effectively \nEnsure Separation Across Both Approaches: IM PA Tool Configuration IM PA Tool Configuration Tools On Tools Off\nSample Size (n) 7 7 Mean (M) 86.7 84.1 Standard Deviation (SD) 10.3 18.2 Figure 5-33. Given the appropriate training and the IM PA-related tools, a single (Combined) Monitor \nController can effectively ensure separation across both approaches during IM PA operations. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed a single (Combined) Monitor controller can effectively \nensure separation across both approaches during IM PA operations with IM PA Tools On \n(M=86.7; SD=10.3) and IM PA Tools Off (M=84.1; SD=18.2). This is consistent with the prior \nresults and no practical difference was observed between the two IM PA Tool configurations. Selected open-ended comments for this question included:\n(NCT / Tools On) Seems like a lot for one person with a busy final. \n(Non-NCT TRACON / Tools On) The IM PA allows much less need to monitor that spacing \nand more time to monitor spacing on same runway or between pairs. --------------------------------- At the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if they were comfortable monitoring one xliii\n aircraft in an IM PA pair, while another controller monitored the other. Responses are shown \nfor all TRACON (NCT and non-NCT combined) and Tower Only. Response Means and Standard \nDeviations are summarized in Table 5-25. Scale responses are shown in Figure 5-34. Table 5-25. Controller Responses to Separate Monitor Comfort Participant Experience TRACON Tower\nMonitor Trail / Other Controller \nMonitors Lead Sample Size (n) 10 2 Mean (M) 87.0 76.5 Standard Deviation (SD) 10.9  Monitor Lead / Other Controller \nMonitors Trail Sample Size (n) 10 2 Mean (M) 87.5 84.0 Standard Deviation (SD) 10.3  Figure 5-34. I was comfortable monitoring one aircraft in an IM PA pair, while another controller \nmonitored the other. Note: o indicates NCT controller responses. All (100%) TRACON controllers agreed they were comfortable monitoring the Trail Aircraft in an \nIM PA pair, while another controller monitored the Lead Aircraft (M=87.0; SD=10.9). All (100%) \nTRACON controllers also agreed they were comfortable monitoring the Lead Aircraft in an IM PA \npair, while another controller monitored the Trail Aircraft (M=87.5; SD=10.3). To examine if the IM PA Tool configuration affected the effectiveness of the Combined Monitor \nconfiguration, controllers were asked the same question at the end of each run (QT1). Their \nresponses were then examined with respect to IM PA Tool configuration. Response Means and xliv\n Standard Deviations are summarized in Table 5-26. Scale responses are shown in Figure 5-35. Table 5-26. Controller Responses to Separate Monitor Comfort: IM PA Tools IM PA Tool Configuration Tools On Tools Off\nMonitor Trail / Other Controller \nMonitors Lead Sample Size (n) 7 7 Mean (M) 92.6 94.0 Standard Deviation (SD) 9.0 7.2 Monitor Lead / Other Controller \nMonitors Trail Sample Size (n) 7 7 Mean (M) 95.1 93.6 Standard Deviation (SD) 6.5 7.1 Figure 5-35. IM PA Tool Configuration: I was comfortable monitoring one aircraft in an IM PA pair, \nwhile another controller monitored the other. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed they were comfortable monitoring one aircraft in an \nIM PA pair, while another controller monitored the other aircraft. This is consistent with the \nprior results and no practical difference was observed between the two IM PA Tool \nconfigurations. --------------------------------- At the end of Day 3 after all scenarios were complete (QT8), controllers were asked if they \nwould expect to be able to effectively monitor any number of IM PA pairs, up to and including \nall aircraft pairs performing IM PA (100%). Their responses were then examined with respect to \nmonitor configuration. Response Means and Standard Deviations are summarized in Table 5-27. xlv\n Scale responses are shown in Figure 5-36. Only Week 2-3 TRACON controller responses were \nincluded in the analysis. Table 5-27. Controller Responses to Effective Monitoring Any Number if IM PA Pairs Participant Experience TRACON Tower\nCombined Monitor Position for \nBoth Approaches Sample Size (n) 10 2 Mean (M) 73.6 87.5 Standard Deviation (SD) 29.1  Separate Monitor for Each \nApproach Sample Size (n) 10 2 Mean (M) 88.8 65.5 Standard Deviation (SD) 24.5  Figure 5-36. I would expect to be able to effectively monitor any number of IM PA pairs, up to and \nincluding all aircraft pairs performing IM PA (100%). Note: o indicates NCT controller responses. Responses were variable, but the majority (70%) of TRACON controllers agreed they would \nexpect to be able to effectively monitor any number of IM PA pairs in a Combined Monitor \nposition (M=73.6; SD=29.1). A majority (90%) also agreed for a Separate Monitor configuration \nfor each approach (M=88.8; SD=24.5). The controller that disagreed for the Separate Monitor \nconfiguration also disagreed for the Combined Monitor configuration. As described in Section 5.8.6, a paired-sample T-Test analysis found a significant difference in \ncontroller agreement with respect to the strength of agreement between the two \nconfigurations, with controllers appearing to expect to be able to more effectively monitor any \nnumber of IM PA pairs in a Separate Monitor configuration. xlvi\n Results Topic 4: IM PA Tools6.5\nThis section examines the general effects of varying the IM PA Tool configurations as well as \nfocused evaluations of the individual features. The Lateral Boundaries and Exceedance Warning \nfeatures, however, are examined in Section 5.6. Results in this section are usually from the Post-\nRun Questionnaires (QT1), unless otherwise indicated. General Effects6.5.1\nThis section examines differences between the IM PA Tool configurations with respect to \nMonitor controller workload (in the nominal scenarios), traffic awareness, IM Speed control, \nand separation assessment. Monitor Controller Workload (Nominal Scenarios)6.5.1.1\nAt the end of each run, controllers were asked to rate their workload for the scenario they just \nexperienced (QT1) using the Bedford Workload Scale. Their responses were then examined with \nrespect to IM PA Tool configuration. Response Means and Standard Deviations are summarized \nin Table 5-28. Scale responses are shown in Figure 5-37. Only TRACON controller responses \nwere included in the analysis. Also, some rows indicate an n=6 because one of the participants \ndid not include a rating in the questionnaire. Table 5-28. Monitor controller Workload Ratings: IM PA Tools On/Off IM PA Tool Configuration Tools On Tools Off\nCombined 28L/28R Monitor Sample Size (n) 7 7 Mean (M) 2.0 1.9 Standard Deviation (SD) 0.6 0.7 28R Monitor\nSample Size (n) 6 6 Mean (M) 2.0 1.8 Standard Deviation (SD) 0.6 0.4 28L Monitor\nSample Size (n) 6 7 Mean (M) 1.7 1.6 Standard Deviation (SD) 0.5 0.5 xlvii\n Figure 5-37. Monitor Controller Workload Ratings: IM PA Tools On/Off Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. On average, the TRACON controllers reported low workload for all three Monitor positions and \nfor both IM PA Tool configurations. No practical difference was observed between the two IM \nPA Tool configurations and among any of the positions. Workload ratings were also collected for the other IM PA Tool configurations: Data Block \nDistance On / WSL-P Off and DB Distance Off / WSL-P On. However, due to simulation time \nlimits, the former was only run for the Combined Monitor configuration and the latter was only \nrun with the 28R (Separate) Monitor configuration. This data was still captured, however, to \npossibly illuminate any workload effects that could be attributed to having or not having one of \nthe individual features available, when compared to the all IM PA Tools On or Off configurations \nfor the Combined and 28R Monitor positions. Response Means and Standard Deviations are \nsummarized in Table 5-29. Scale responses are shown in Figure 5-38. Only TRACON controller \nresponses were included in the analysis. Table 5-29. Monitor Controller Workload Ratings: Other IM PA Tool Configurations IM PA Tool Configuration DB On / WSL-P Off DB Off / WSL-P On\nSample Size (n) 7 7 Mean (M) 2.0 1.7 Standard Deviation (SD) 0.8 0.8 xlviii\n Figure 5-38. Monitor Controller Workload Ratings: Other IM PA Tool Configurations *Combined Monitor configuration / **28R Monitor configuration\nNote: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. On average, the TRACON controllers also reported low workload for these additional IM PA \nTools configurations and no practical difference was observed between them. When
examined \nin context with the all IM PA Tools On or Off configurations, there did not appear to be any \npractical workload differences attributable to IM PA Tool or monitor configuration. --------------------------------- At the end of each run (QT1), controllers were also asked if their overall workload was \nacceptable for the scenario they just experienced. Their responses were then examined with \nrespect to IM PA Tool configuration. Response Means and Standard Deviations are summarized \nin Table 5-30. Scale responses are shown in Figure 5-39. Only TRACON controller responses \nwere included in the analysis. Table 5-30. Monitor Controller Workload Acceptability (Nominal Scenarios) IM PA Tool Configuration\nTools On Tools Off Combined 28L/28R Monitor\nSample Size (n) 7 7 Mean (M) 97.0 96.1 Standard Deviation (SD) 4.7 4.7 28R Monitor\nSample Size (n) 7 7 Mean (M) 95.4 97.3 Standard Deviation (SD) 5.4 3.7 28L Monitor\nSample Size (n) 7 7 Mean (M) 97.0 95.4 Standard Deviation (SD) 3.7 5.1 xlix\n Figure 5-39. Monitor Controllers: My overall workload was acceptable for the scenario I just \nexperienced. (Nominal Scenarios) Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed their overall workload was acceptable for all three \nMonitor positions and for both IM PA Tools configurations. No practical difference was \nobserved between the two IM PA Tool configurations and among any of the positions. This is \nconsistent with the Day 1 and Day 2 End Questionnaire results described in Section 5.4.1. The Week 1 controllers had consistently lower workload acceptability ratings; however, the \nWeek 2-3 scenarios were modified to resolve some scenario issues that the Week 1 controllers \nexperienced. Traffic Awareness6.5.1.2\nAt the end of each run (QT1), controllers were asked if given the IM PA-related tools they had \nin this scenario, they had sufficient overall traffic situation awareness. Their responses were \nthen examined with respect to IM PA Tool configuration. Response Means and Standard \nDeviations are summarized in Table 5-31. Scale responses are shown in Figure 5-40. Only \nTRACON controller responses were included in the analysis. Table 5-31. Controller Responses to Traffic Awareness: IM PA Tool Configuration IM PA Tool Configuration\nTools On Tools Off Combined 28L/28R Monitor\nSample Size (n) 7 7 Mean (M) 89.1 79.7 Standard Deviation (SD) 11.7 15.1 28R Monitor\nSample Size (n) 7 7 l\n Mean (M) 88.1 84.0 Standard Deviation (SD) 18.4 13.3 28L Monitor\nSample Size (n) 7 7 Mean (M) 83.0 84.4 Standard Deviation (SD) 33.5 12.4 Figure 5-40. Given the IM PA-related tools I had in this scenario, I had sufficient overall traffic situation \nawareness. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. On average, all Week 2-3 TRACON controllers agreed they had sufficient overall traffic situation \nawareness for the Combined Monitor configuration with IM PA Tools On (M=89.1; SD=11.7) and \nIM PA Tools Off (M=79.7; SD=15.1). They also all agreed for the 28R Monitor Position with IM PA \nTools Off (M=84.0; SD=13.3) and the 28L Monitor Position with IM PA Tools Off (M=84.4; \nSD=12.4). The majority (90%) all Week 2-3 TRACON controllers agreed for the 28R Monitor Position with \nIM PA Tools On (M=88.1; SD=18.4), with one controller neither agreeing nor disagreeing. This \ncontroller made the following comment with respect to this rating: I would have preferred the \ngrey wake line was visible farther out, on initial contact. A majority (90%) also agreed for the 28L Monitor Position with IM PA Tools On (M=83.0; \nSD=33.5). The (NCT) controller that disagreed commented that Would have been great to have \n[A]TPA on so you can see the miles between pairs. This rating therefore appears to be related \nto not having ATPA available versus the efficacy of the IM PA Tools. Given the response variability, no apparent practical differences in acceptability between the IM \nPA Tool configurations were observed across the monitor configurations. However, Lead \nAircraft response variability for the IM Lead Aircraft appeared to be lower for the Separate \nMonitor configuration than for all the other cases. Examination of the Data Block Distance and \nWSL-P Tool configurations in the post-run responses (not shown) also did not indicate a li\n difference with respect to Traffic Awareness. IM Speed Control6.5.1.3\nAt the end of each run (QT1), controllers were asked if they were comfortable with the IM Trail \nAircraft managing their speeds to achieve the spacing goal assigned by the Final controller. \nTheir responses were then examined with respect to IM PA Tool configuration. Response Means \nand Standard Deviations are summarized in Table 5-32. Scale responses are shown in Figure \n5-41. Only TRACON controller responses were included in the analysis. lii\n Table 5-32. Controller Responses to IM PA Speed Control IM PA Tool Configuration Tools On Tools Off\nDB On / WSL-P Off\nDB Off / WSL-P On\nCombined 28L/28R Monitor Sample Size (n) 7 7 7 0 Mean (M) 92.7 72.9 83.9  Standard Deviation (SD) 8.4 33.7 18.2  28R Monitor\nSample Size (n) 7 7 0 7 Mean (M) 90.6 86.4 93.1 Standard Deviation (SD) 9.0 18.4 7.5 28L Monitor\nSample Size (n) 7 7 0 0 Mean (M) 91.0 88.9 - Standard Deviation (SD) 8.0 10.1 - Figure 5-41. I was comfortable with the IM Trail Aircraft managing their speeds to achieve the spacing \ngoal assigned by the Final controller. *Combined Monitor configuration / **28R Monitor configuration\nNote: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All Week 2-3 TRACON controllers agreed they were comfortable with the IM Trail Aircraft liii\n managing its speeds to achieve the spacing goal for the Combined Monitor position with the IM \nPA Tools On (M=92.7; SD=8.4). A majority (86%) of controllers agreed with the IM PA Tools Off \n(M=72.9; SD=33.7). One controller disagreed and suggested that it was because one of the \naircraft failed to maintain a realistic speed. This response is therefore more due to a simulation \nartifact as that speed change was an intentional, off-nominal event implemented to trigger the \nlongitudinal alerting. However, it occurred in the IM PA Tools On scenario as well and the \ncontroller did not appear to have as negative reaction to it then. Therefore, the increased \nvariability for the IM PA Tools Off configuration suggests that at least for the Combined Monitor \nposition, having the IM PA Tools available may increase controller comfort with IM Trail Aircraft \nmanaging their own speeds. For the 28R Monitor position, all Week 2-3 TRACON controllers agreed with the IM PA Tools On \n(M=90.6; SD=9.0) and a majority (86%) of controllers agreed with the IM PA Tools Off (M=86.4; \nSD=18.4). Despite the higher variability with IM PA Tools Off, no practical difference was \nobserved between the configurations. For the 28L Monitor position, all Week 2-3 TRACON controllers agreed with the IM PA Tools On \n(M=91.0; SD=8.0) and IM PA Tools Off (M=88.9; SD=10.1). Despite the higher variability with IM \nPA Tools Off, no practical difference was observed between the configurations. All Week 2-3 TRACON controllers agreed with the Data Block CSL Distance On / WSL-P Off \n(M=83.9; SD=18.2) and Data Block CSL Distance Off / WSL-P On (M=93.1; SD=7.5) configurations. Overall, no practical differences between the Monitor and IM PA Tool configurations were \nobserved. Selected open-ended comments for this question included: (NCT Combined / Tools On) I didn't trust them at first but gradually became a little more \ncomfortable.\n(NCT 28R / Tools Off) I would like to be able to override the IM PA and give a speed that I \nthink would keep them in the window & try to prevent the go around.\n(Non-NCT TRACON 28R / Tools Off) It didn't always work out but gave fair warning.\n(Non-NCT TRACON 28L / Tools On) I trusted the equipment and did not pay much \nattention to the trail a/c IM spacing. Separation Assessment6.5.2\nAt the end of each run (QT1), controllers were asked as the IM PA aircraft pairs became my \nresponsibility, I had sufficient time to make a first assessment of their separation. Their \nresponses were then examined with respect to IM PA Tool configuration. Response Means and \nStandard Deviations are summarized in Table 5-33. Scale responses are shown in Figure 5-42. \nOnly TRACON controller responses were included in the analysis. Table 5-33. Controller Responses for Sufficient Time for First Separation Assessment IM PA Tool Configuration Tools On Tools Off\nDB On / WSL-P Off\nDB Off / WSL-P On liv\n Combined 28L/28R Monitor\nSample Size (n) 7 7 7 0 Mean (M) 79.0 74.3 78.1  Standard Deviation (SD) 32.2 33.9 32.7  28R Monitor\nSample Size (n) 7 7 0 7 Mean (M) 84.1 73.7 85.3 Standard Deviation (SD) 33.4 37.7 29.1 28L Monitor\nSample Size (n) 10 10 0 0 Mean (M) 83.9 82.0 - Standard Deviation (SD) 29.8 22.8 - Figure 5-42. As the IM PA aircraft pairs became my responsibility, I had sufficient time to make a first \nassessment of their separation. *Combined Monitor configuration / **28R Monitor configuration\nNote: o indicates Week 1 TRACON controller responses for reference. These are not included in
the M and SD computations. Responses were variable, but a majority (86%) of Week 2-3 TRACON controllers agreed they had \nsufficient time to make a first assessment of IM PA pair separation for the Combined Monitor \nposition with the IM PA Tools On (M=79.0; SD=32.2). The controller that disagreed commented \nthat the WSL should be displayed sooner. Responses were also variable for the majority (71%) lv\n of controllers that agreed with the IM PA Tools Off (M=74.3; SD=33.9). The two controllers that \ndisagreed both commented that the WSL should be displayed sooner (one was the same \ncontroller in both cases). No practical differences were observed between the IM PA Tool \nconfigurations. For the 28R Monitor position, responses were variable, but a majority (86%) of Week 2-3 \nTRACON controllers agreed they had sufficient time to make a first assessment of IM PA pair \nseparation for the Combined Monitor position with the IM PA Tools On (M=84.1; SD=33.4). The \ncontroller that disagreed commented that the WSL should be displayed sooner. Responses \nwere also variable for the majority (71%) of controllers that agreed with the IM PA Tools Off \n(M=73.7; SD=37.7). The two controllers that disagreed both commented that the WSL should be \ndisplayed sooner. For the 28L Monitor position, responses were variable, but a majority (86%) of Week 2-3 \nTRACON controllers agreed they had sufficient time to make a first assessment of their \nseparation for the Combined Monitor position with the IM PA Tools On (M=83.9; SD=29.8). The \ncontroller that disagreed commented that the WSL should be displayed sooner. A majority \n(71%) of controllers also agreed with the IM PA Tools Off (M=82.0; SD=22.8). One of the two \ncontrollers that disagreed commented that the WSL should be displayed immediately. Responses were variable, but the majority (90%) of Week 2-3 TRACON controllers agreed with \nthe Data Block CSL Distance On / WSL-P Off (M=78.1; SD=32.7) and Data Block CSL Distance Off / \nWSL-P On (M=85.3; SD=29.1) configurations. The same controller disagreed in both cases and \ncommented that the WSL should be displayed sooner. Due to the high variability in the responses no differences were observed between any of the \nIM PA Tool and monitor configurations. Selected open-ended comments for this question included: (NCT Combined / Tools On) I watched prior to becoming my responsibility, so I was able \nto have an idea of what was happening.\n(Non-NCT TRACON / Tools On) It was quick and easy to see the CSL line and A/C target \nlocation with one quick glance. --------------------------------- At the end of each run (QT1), controllers were asked with the IM PA-related tools provided in \nthis scenario, I could easily assess the separation between the IM Trail Aircraft and its Lead, \nwhen they were my responsibility. Their responses were then examined with respect to IM PA \nTool configuration. Response Means and Standard Deviations are summarized in Table 5-34. \nScale responses are shown in Figure 5-43. Only TRACON controller responses were included in \nthe analysis. This question also only applied to controllers responsible for 28R, so the Separate \n28L Monitor position results are not included. The 28R Final controller results are included as \nthey were responsible for assessing separation before they transferred the IM Trail Aircraft to \nthe Local controller. In this case, results for all three weeks are included as the Final controller \ntasks were not affected by the scenario issues that affected the Monitor controller tasks. lvi\n Table 5-34. Controller Responses for Ease of Separation Assessment IM PA Tool Configuration Tools On Tools Off\nDB On / WSL-P Off\nDB Off / WSL-P On\nCombined 28L/28R Monitor Sample Size (n) 7 7 7 0 Mean (M) 89.9 80.3 85.7  Standard Deviation (SD) 9.8 23.5 16.4  28R Monitor\nSample Size (n) 7 7 0 7 Mean (M) 82.3 84.4 79.0 Standard Deviation (SD) 21.1 15.2 25.3 28R Final \nSample Size (n) 10 10 0 0 Mean (M) 84.9 90.3 - Standard Deviation (SD) 21.7 10.3 - Figure 5-43. With the IM PA-related tools provided in this scenario, I could easily assess the separation \nbetween the IM Trail Aircraft and its Lead, when they were my responsibility. *Combined Monitor configuration / **28R Monitor configuration\nNote: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations for \nthe monitor configurations. However, they are included in the M and SD computations for the 28R Final controller position. All Week 2-3 TRACON controllers agreed they could easily assess the separation between the IM \nTrail Aircraft and its Lead with the IM PA Tools On (M=89.9; SD=9.8) for the Combined Monitor lvii\n configuration. A majority (71%) of controllers agreed with the IM PA Tools Off (M=80.3; \nSD=23.5). The increased variability for the IM PA Tools Off configuration suggests that at least \nfor the Combined Monitor position, having the IM PA Tools available may help controllers more \neasily assess the separation between the IM Trail Aircraft and its Lead. For the 28R Monitor position, a majority (86%) of Week 2-3 TRACON controllers agreed with the \nIM PA Tools On (M=82.3; SD=21.1). The controller that disagreed commented the WSL should \nbe displayed sooner. All controllers agreed with the IM PA Tools Off (M=84.4; SD=15.2), \nthough one commented that A predictive WSL would be an improvement. No practical \ndifference was observed between the IM PA Tool configurations. For the 28R Final controller position, a majority (90%) of TRACON controllers agreed with the IM \nPA Tools On (M=84.9; SD=21.7). The controller that disagreed commented the CSL and WSL \nshould be displayed before the aircraft is cleared. All controllers agreed with the IM PA Tools Off \n(M=90.3; SD=10.3), though one commented that they would have liked to have seen the \nautomatic distance displayed. Despite the higher variability in the responses with IM PA Tools \nOn, no practical difference was observed between the two configurations. All Week 2-3 TRACON controllers agreed with the Data Block CSL Distance On / WSL-P Off \nconfiguration (M=85.7; SD=16.4). A majority (71%) agreed with the Data Block CSL Distance Off / \nWSL-P On configuration (M=79.0; SD=25.3). No practical difference was observed between the \ntwo configurations. Overall, no practical differences were observed between any of the IM PA Tool configurations \nand positions. However, for the Combined Monitor position, having the IM PA Tools available \nmay help controllers more easily assess the separation between the IM Trail Aircraft and its \nLead. Safety Limit Depictions6.5.3\nThis section examines the acceptability, effectiveness, and usefulness of the CSL and WSL \nfeatures as implemented. CSL Features6.5.3.1\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if the CSL Line and Data Block Distance to CSL \nfeatures were useful for the overall IM PA monitoring task. Responses are shown for all \nTRACON (NCT and non-NCT combined) and Tower Only. Response Means and Standard \nDeviations are summarized in Table 5-35. Scale responses are shown in Figure 5-44. Table 5-35. Controller Responses to CSL Feature Usefulness Participant Experience TRACON Tower\nCSL Line Sample Size (n) 10 2 lviii\n Mean (M) 96.2 93.0 Standard Deviation (SD) 5.0  Data Block Distance to CSL\nSample Size (n) 10 2 Mean (M) 32.9 68.0 Standard Deviation (SD) 27.2  Figure 5-44. The CSL Line and Data Block Distance to CSL features were useful for the overall IM PA \nmonitoring task. Note: o indicates NCT controller responses. All (100%) TRACON controllers agreed the CSL Line was useful for the overall IM PA monitoring \ntask (M=96.2; SD=5.0). However, only one TRACON controller agreed the Data Block Distance to \nthe CSL was useful for the overall IM PA monitoring task (M=32.9; SD=27.2). Another controller \nneither agreed nor disagreed. --------------------------------- At the end of Day 2 (QT3), controllers were also asked to compare the two CSL features directly \nby rating their agreement with the statement: If the CSL is shown as a graphic line, the numeric \ndistance to it in the data block is also helpful. Responses are shown for all TRACON (NCT and \nnon-NCT combined) and Tower Only. Response Means and Standard Deviations are summarized \nin Table 5-36. Scale responses are shown in Figure 5-45. Table 5-36. Controller Responses to Helpfulness of CSL Numeric Distance, Given CSL Line Participant Experience TRACON Tower\nSample Size (n) 10 2 Mean (M) 35.6 57.5 Standard Deviation (SD) 29.1  lix\n Figure 5-45. If the CSL is shown as a graphic line, the numeric distance to it in the data block is also \nhelpful. Note: o indicates NCT controller responses. Responses were variable, but the majority (60%) of TRACON controllers disagreed the CSL \nDistance was helpful, if given the CSL Line (M=35.6; SD=29.1). Three controllers neither agreed \nnor disagreed. One controller agreed and was the same controller that agreed the Distance to \nCSL was useful in Figure 5-44. In a comment for a separate question, this controller noted that: \nThe numbers in the data block gave very good trend information as to what was happening to \nseparation. Open-ended comments for this question included: (Non-NCT TRACON) Not necessary. Visual indications are often more
useful than \nnumerical.\n(NCT) The line helps, but didn't look at distance in data block as I was looking at speeds \nto see if there was a difference. \n(Non-NCT TRACON) The distance can be misleading since sometimes 0.1 was still blue \nwhile 0.5 was yellow. Speed is the factor, not so much distance. --------------------------------- At the end of each run (QT1), controllers were asked if they could easily assess whether the IM \nTrail Aircraft would remain behind the CSL during the approach. Their responses were then \nexamined with respect to IM PA Tool configuration. Response Means and Standard Deviations \nfor the monitor configurations are summarized in Table 5-37. Scale responses are shown in \nFigure 5-46. Only TRACON controller responses were included in the analysis. Table 5-37. Monitor Controller Responses to CSL Assessment IM PA Tool Configuration Tools On Tools Off\nDB On / WSL-P Off\nDB Off / WSL-P On\nCombined 28L/28R Monitor Sample Size (n) 7 7 7 0 Mean (M) 93.4 92.7 86.9  lx\n Standard Deviation (SD) 7.8 8.7 20.0  28R Monitor\nSample Size (n) 7 7 0 7 Mean (M) 90.0 87.4 81.4 Standard Deviation (SD) 9.2 13.0 22.3 Figure 5-46. Monitor Controller: I could easily assess whether the IM Trail Aircraft would remain \nbehind the CSL during the approach. *Combined Monitor configuration / **28R Monitor configuration\nNote: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All (100%) Week 2-3 TRACON controllers agreed they could easily assess whether the IM Trail \nAircraft would remain behind the CSL during the approach for both monitor configurations with \nIM PA Tools On and IM PA Tools Off. The majority of Week 2-3 TRACON controllers agreed with \nthe Data Block CSL Distance On / WSL-P Off (86%) and with Data Block CSL Distance Off / WSL-P \nOn (71%) configurations. Overall, no practical differences between the Monitor and IM PA Tool \nconfigurations were observed. This same question, whether they could easily assess whether the IM Trail Aircraft would \nremain behind the CSL during the approach, was also examined for the 28R Final controllers at \nthe end of each run (QT1). TRACON controller responses were also then examined with respect \nto IM PA Tool configuration. Response Means and Standard Deviations for the 28R Final \ncontroller position are summarized in Table 5-38. Scale responses are shown in Figure 5-47. \nOnly TRACON controller responses were included in the analysis. Table 5-38. 28R Final Controller Responses to CSL Assessment IM PA Tool Configuration lxi\n Tools On Tools Off\nSample Size (n) 10 10 Mean (M) 70.4 67.4 Standard Deviation (SD) 32.9 31.4 Figure 5-47. 28R Final Controller: I could easily assess whether the IM Trail Aircraft would remain \nbehind the CSL during the approach. Note: o indicates NCT controller responses. Responses were variable, but a majority (70%) of TRACON controllers agreed the 28R Final \ncontroller position could easily assess whether the IM Trail Aircraft would remain behind the \nCSL during the approach for both IM PA Tool configurations. Several comments from the \ncontrollers that disagreed suggested this was because there was no indication of where the CSL \nwould be located before they cleared the IM Trail Aircraft for IM PA. Overall, no practical \ndifference between the IM PA Tool configurations was observed. Other open-ended comments for this question included: (NCT / Tools On) Was not easy to determine, but wasn't a concern as I knew the Monitor \ncontroller could react next to the CSL warning if needed.\n(NCT / Tools On) I did not pay as close attention after I shipped them. WSL and Pre-Activation Features6.5.3.2\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if the WSL Line and Data Block Distance to WSL \nfeatures were useful for the overall IM PA monitoring task. Responses are shown for all \nTRACON (NCT and non-NCT combined) and Tower Only. Response Means and Standard \nDeviations are summarized in Table 5-39. Scale responses are shown in Figure 5-48. Table 5-39. Controller Responses to WSL Feature Usefulness Participant Experience TRACON Tower\nWSL Line lxii\n Sample Size (n) 10 2 Mean (M) 96.4 94.0 Standard Deviation (SD) 4.7  Data Block Distance to WSL\nSample Size (n) 10 2 Mean (M) 32.9 68.0 Standard Deviation (SD) 26.9  Figure 5-48. The WSL Line and Data Block Distance to WSL features were useful for the overall IM PA \nmonitoring task. Note: o indicates NCT controller responses. All (100%) TRACON controllers agreed the WSL Line was useful for the overall IM PA monitoring \ntask (M=96.4; SD=4.7). However, only one TRACON controller agreed the Data Block Distance to \nthe WSL was useful for the overall IM PA monitoring task (M=32.9; SD=27.2). This was the same \ncontroller in Section 5.5.3.1 that agreed the Distance to the CSL was useful. Another controller \nneither agreed nor disagreed. --------------------------------- At the end of each run (QT1), controllers were asked if they could easily assess whether the IM \nTrail Aircraft would remain forward of the WSL during the approach, when applicable. Their \nresponses were then examined with respect to IM PA Tool configuration. Response Means and \nStandard Deviations for the monitor configurations are summarized in Table 5-40. Scale \nresponses are shown in Figure 5-49. Only TRACON controller responses were included in the \nanalysis. Table 5-40. Monitor Controller Responses to WSL Assessment IM PA Tool Configuration Tools On Tools Off\nDB On / WSL-P Off\nDB Off / WSL-P On lxiii\n Combined 28L/28R Monitor\nSample Size (n) 7 7 7 0 Mean (M) 88.9 75.4 60.7  Standard Deviation (SD) 13.2 34.0 38.1  28R Monitor\nSample Size (n) 7 7 0 7 Mean (M) 75.6 68.7 69.6 Standard Deviation (SD) 19.0 32.2 28.6 Figure 5-49. I could easily assess whether the IM Trail Aircraft would remain forward of the WSL during \nthe approach, when applicable. *Combined Monitor configuration / **28R Monitor configuration\nNote: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. All (100%) Week 2-3 TRACON controllers agreed they could easily assess whether the IM Trail \nAircraft would remain forward of the WSL for the Combined Monitor position with IM PA Tools \nOn (M=88.9; SD=13.2). Responses were variable, but a majority (86%) agreed for the Combined \nMonitor position with IM PA Tools Off (M=75.4; SD=34.0). This higher variability was due to one \ncontroller who strongly disagreed and noted that the WSL should appear sooner. Other \ncontrollers agreed in the comments that the WSL should appear sooner, though they still \nresponded on the agree side of the scale. Responses were variable for the other IM PA Tool configurations. However, the majority (71%) \nof Week 2-3 TRACON controllers agreed with the Data Block CSL Distance On / WSL-P Off \n(M=60.7; SD=38.1) and the majority (57%) agreed with Data Block CSL Distance Off / WSL-P On \n(M=69.6; SD=28.6). lxiv\n As described in Section 5.8.2, a three-factor analysis of variance (ANOVA) test found that though \nall or most controllers agreed they could easily asses the IM Trail Aircraft with respect to both \nthe CSL versus the WSL, they agreed more strongly for the CSL. No statistically significant \ndifferences were observed between Monitor and IM PA Tool configurations or any of the factor \ncombinations. Several controllers made open-ended comments across these scenarios that suggested the WSL \nappeared later than desired and that having the WSL-P would help. These included: (NCT / Tools On) I'm just not sure where the WSL will be until the preview pops up, once \nit does show up then I am more easily able to assess.\n(Non-NCT TRACON / Tools On) Once the line appeared, it was easy.\n(NCT / Tools On) The WSL should come on sooner so that if aircraft is lagging, we could \nuse speed to get aircraft in front of WSL instead of sending around. \n(NCT / Tools Off) WSL is a little bit harder to notice and focus on when it pops up so late \nand without predictor.\n(NCT / Tools Off) I find myself staring when they get close to where the WSL activates \nand I'm spending too much time guessing where the AC will be in relation to active WSL. \nThis is mitigated by preview WSL.\n(Non-NCT TRACON / DB Distance On/WSL-P Off) Not as much situational awareness as \nwhen the gray line is active, but still doable without difficulty. --------------------------------- At the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if it was helpful to know whether an aircraft \nwould eventually require an active WSL. Responses are shown for all TRACON (NCT and non-\nNCT combined) and Tower Only. Response Means and Standard Deviations are summarized in \nTable 5-41. Scale responses are shown in Figure 5-50. Table 5-41. Controller Responses to Helpfulness of CSL Numeric Distance, Given CSL Line Participant Experience TRACON Tower\nSample Size (n) 10 2 Mean (M) 69.3 86.0 Standard Deviation (SD) 28.6  lxv\n Figure 5-50. It was helpful to know whether an aircraft would eventually require an active
WSL. Note: o indicates NCT controller responses. Responses were variable, but a majority (60%) of TRACON controllers agreed it was helpful to \nknow whether an aircraft would eventually require an active WSL (M=69.3; SD=29.1). Two \ncontrollers that neither agreed nor disagreed commented aircraft type differences would \nindicate an active WSL to the controller. --------------------------------- In the Day 1-2 Post-Run Questionnaires (QT1), controllers were asked if given the IM PA-related \ntools provided in this scenario, I could easily tell when an aircraft would require a WSL later in \nthe approach. Their responses were examined with respect to both the IM PA Tools and \nmonitor configurations. Response Means and Standard Deviations are summarized in Table \n5-42. Scale responses are shown in Figure 5-51. For the Separate Monitor configuration, only \n28R Monitor responses are included because the WSL and WSL-P did not apply to the 28L \nMonitor position. lxvi\n Table 5-42. Controller Responses to Ease of Predicting WSL IM PA Tool Configuration Tools On Tools Off\nCombined 28L/28R Monitor Sample Size (n) 7 7 Mean (M) 62.7 52.6 Standard Deviation (SD) 33.6 38.0 28R Monitor\nSample Size (n) 7 7 Mean (M) 64.9 38.0 Standard Deviation (SD) 30.6 29.4 Figure 5-51. Given the IM PA-related tools provided in this scenario, I could easily tell when an aircraft \nwould require a WSL later in the approach. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. Responses were variable for all configurations. For the Combined 28L/28R Monitor \nconfiguration, a majority (71%) of Week 2-3 TRACON controllers agreed they could easily tell \nwhen an aircraft would require a WSL later in the approach with IM PA Tools On (M=62.7; \nSD=33.6). An equal number (43%) agreed and disagreed with IM PA Tools Off (M=52.6; SD=38.0) \nand one controller neither agreed nor disagreed. For the Separate 28R Monitor configuration position, a majority (57%) of Week 2-3 TRACON \ncontrollers agreed with IM PA Tools On (M=64.9; SD=30.6). With IM PA Tools Off, a majority \n(71%) of controllers disagreed (M=38.0; SD=29.4). Due to the high variability observed with the IM PA Tools Off conditions, no practical difference \nwas observed overall among the configurations. However, controllers may have found it \nsomewhat easier to determine if a WSL would be required for the 28R Monitor position when lxvii\n the IM PA Tools were available. Several controllers made open-ended comments that suggested \naircraft type was sufficient to indicate whether a WSL would be required, though the Data Block \nW or WSL-P features would have made it easier. --------------------------------- At the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if the WSL-P and WSL Pre-Active Indication (\nW) features were useful for the overall IM PA monitoring task. Responses are shown for all \nTRACON (NCT and non-NCT combined) and Tower Only. Response Means and Standard \nDeviations are summarized in Table 5-43. Scale responses are shown in Figure 5-52. Table 5-43. Controller Responses to WSL Pre-Activation Feature Usefulness Participant Experience TRACON Tower\nWSL-P Sample Size (n) 10 2 Mean (M) 92.8 94.0 Standard Deviation (SD) 8.4  WSL Pre-Active Indication (W)\nSample Size (n) 10 2 Mean (M) 32.7 68.0 Standard Deviation (SD) 32.1  Figure 5-52. The WSL-P and WSL Pre-Active Indication (W) features were useful for the overall IM PA \nmonitoring task. Note: o indicates NCT controller responses. All (100%) TRACON controllers agreed the WSL-P was useful for the overall IM PA monitoring \ntask (M=92.8; SD=8.4). However, responses were variable for the WSL Pre-Active Indication ( lxviii\n W) and a majority (70%) of TRACON controllers disagreed it was useful (M=32.7; SD=32.1). As \ndescribed in Section 5.8.3, a two-tailed, paired sample T-Test analysis found a significant \ndifference in controller agreement for the usefulness of the two elements, with controllers \nappearing to prefer the WSL-P instead of the WSL Pre-Active Indication (W) in the data block. --------------------------------- At the end of Day 2 (QT3), controllers were also asked to compare the two WSL Pre-Activation \nfeatures directly by rating their agreement with these statements: If provided the initial WSL W indicator in the data block, I do not also need the WSL \nPreview Line.\nIf provided the WSL Preview Line, I do not also need the initial WSL W indicator in \nthe data block. Responses are shown for all TRACON (NCT and non-NCT combined) and Tower Only. Response \nMeans and Standard Deviations are summarized in Table 5-44. Scale responses are shown in \nFigure 5-53. Table 5-44. Controller Responses to WSL Pre-Activation Feature Comparison Participant Experience TRACON Tower\nCSL Line Sample Size (n) 10 2 Mean (M) 13.4 57.5 Standard Deviation (SD) 9.8  Data Block Distance to CSL\nSample Size (n) 10 2 Mean (M) 86.7 70 Standard Deviation (SD) 19.0  Figure 5-53. WSL Pre-Activation Feature Comparison Note: o indicates NCT controller responses. lxix\n 13 As noted in Section 4.2.6, the WSL-P was first displayed in the HITL when the IM Trail Aircraft is approximately 7 NM from the \nrunway threshold. All (100%) TRACON controllers disagreed they did not need the WSL-P if they were provided \nwith the Pre-Activation W in the data blocks (M=13.4; SD=9.8). Conversely, a majority (90%) of \nTRACON controllers agreed they did not need the Pre-Activation W in the data blocks if they \nwere provided with the WSL-P. Consistent with prior results, TRACON controllers appeared to \nfind the WSL-P to be more useful than the WSL W and several open-ended comments for this \nquestion suggested the WSL-P was far more useful than the W. --------------------------------- At the end of Day 2 (QT3), controllers were also asked if the WSL-P first appeared with \nsufficient lead time13 to be useful. Responses are shown for all TRACON (NCT and non-NCT \ncombined) and Tower Only. Response Means and Standard Deviations are summarized in Table \n5-45. Scale responses are shown in Figure 5-54. Table 5-45. Controller Responses to WSL-P Activation Location Participant Experience TRACON Tower\nSample Size (n) 10 2 Mean (M) 54.6 79.5 Standard Deviation (SD) 36.8  Figure 5-54. The WSL-P first appeared with sufficient lead time to be useful. Note: o indicates NCT controller responses. TRACON controller responses were variable, but a majority (60%) agreed the WSL-P first \nappeared with sufficient lead time to be useful (M=54.6; SD=36.8). As a follow on, controllers at the end of Day 2 (QT3), were asked: approximately how many \nmiles prior to the Wake Safety Limit becoming active should the WSL Preview Line start to be \ndisplayed? They were given an open field to enter any value they wished. Figure 5-55 shows \nparticipant responses for all TRACON (NCT and non-NCT combined) and Tower Only. lxx\n Figure 5-55. Approximately how many miles prior to the Wake Safety Limit becoming active should the \nWSL Preview Line start to be displayed? Thought the responses were dispersed with regard to individual values, the groupings support \nprior results that controllers would like to have a preview become available sooner than what \nwas implemented. Selected open-ended comments for this question included: (NCT) It should start when the IM PA is activated, same time as CSL starts.\n(NCT) It should be on once cleared for approach. This tells controller if aircraft is behind \nand enough time to pick their speed up to get in front of zone. \n(Non-NCT TRACON) Wherever Monitors responsibility starts for separation, thats where \nit needs to begin. \n(Non-NCT TRACON) The more times I worked monitor, I got better at predicting where \nthe line would show up. Earlier would be better though.\n(Non-NCT TRACON) It was fine the way it was, but more time is beneficial. The more \ntime I have to fix a potential problem, the better. Longitudinal Alerting6.5.4\nThe Predictive and Caution Alerts described in Section 4.2.7 were examined in terms of their \nusefulness, timing values, display implementations in the HITL, and response procedures. Usefulness6.5.4.1\nAt the end of Day 3 after all scenarios were complete (QT8), controllers were asked if they: \nwant to be able to see a longitudinal CSL or WSL exceedance problem developing, vs. only \nbeing provided an alert when I have to take an action. Responses are shown for all TRACON \n(NCT and non-NCT combined) and Tower Only. Response Means and Standard Deviations are \nsummarized in Table 5-46 . Scale responses are shown in Figure 5-56. Table 5-46. Controller Responses to Wanting to See a Developing CSL or WSL Exceedance Participant Experience lxxi\n TRACON Tower\nSample Size (n) 10 2 Mean (M) 76.7 88.5 Standard Deviation (SD) 30.2  Figure 5-56. I want to be able to see a longitudinal CSL or WSL exceedance problem developing, vs. \nonly being provided an alert when I have to take an action. Note: o indicates NCT Controller responses. TRACON controller responses were variable, but a majority (80%) agreed they wanted to be able \nto see a situation developing versus only being provided an alert when they had to take action \n(M=76.7; SD=30.2). Two controllers disagreed and made the following comments in response to this question: (NCT) I don't mind it. However, just being alerted to take action is
preferable.\n(Non-NCT TRACON) If I see it developing, I have very few options for keeping aircraft \nwithin limits, so I probably won't take action anyway until required. --------------------------------- At the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if the IM PA Predictive Alert and IM PA Caution \nAlert features were useful for the overall IM PA monitoring task. Responses are shown for all \nTRACON (NCT and non-NCT combined) and Tower Only. Response Means and Standard \nDeviations are summarized in Table 5-47. Scale responses are shown in Figure 5-57. Table 5-47. Controller Responses to IM PA Alert Usefulness Participant Experience TRACON Tower\nPredictive Alert Sample Size (n) 10 2 Mean (M) 80.2 93.0 Standard Deviation (SD) 24.4  Caution Alert lxxii\n Sample Size (n) 10 2 Mean (M) 93.5 93.5 Standard Deviation (SD) 7.6  Figure 5-57. The IM PA Predictive Alert and IM PA Caution Alert were useful for the overall IM PA \nmonitoring task. Note: o indicates NCT controller responses. The majority (90%) of TRACON controllers agreed the IM PA Predictive Alert was useful for the \noverall IM PA monitoring task (M=80.2; SD=24.4). One controller disagreed and was the same \ncontroller that noted in the previous question that they probably wouldnt take action until \nrequired. All (100%) TRACON controllers agreed the IM PA Caution Alert was useful for the \noverall IM PA monitoring task (M=93.5; SD=7.6). As described in Section 5.8.4, a one-tailed, paired sample T-Test found a significant difference in \ncontroller agreement with respect to the usefulness of the two elements. Though both were \nfound useful, stronger agreement was observed with the Caution Alert The higher average and lower variability of the Caution Alert suggests that controllers seem to \nhave found it more useful than the Predictive Alert. Timeliness Assessment6.5.4.2\nAt the end of each run (QT1), controllers were asked if the IM PA-related tools provided in this \nscenario allowed for a timely detection of any impending exceedance of the WSL or CSL. Their \nresponses were then examined with respect to IM PA Tool configuration. Response Means and \nStandard Deviations are summarized in Table 5-48. Scale responses are shown in Figure 5-58. \nOnly Week 2-3 TRACON controller responses were included in the analysis. This question only \napplied to controllers responsible for 28R, so the Separate 28L Monitor position results are not \nincluded. Table 5-48. IM PA Tool Notification Timeliness IM PA Tool Configuration lxxiii\n Tools On Tools Off\nCombined 28L/28R Monitor Sample Size (n) 7 7 Mean (M) 75.0 64.1 Standard Deviation (SD) 31.3 34.4 28R Monitor\nSample Size (n) 7 7 Mean (M) 63.9 63.6 Standard Deviation (SD) 33.1 32.1 Figure 5-58. The IM PA-related tools provided in this scenario allowed for a timely detection of any \nimpending exceedance of the WSL or CSL. Note: o indicates Week 1 TRACON controller responses for reference. These are not included in the M and SD computations. Week 2-3 TRACON controller responses were variable for each IM PA Tools and monitor \nconfiguration. However, the majority (86%) of TRACON controllers in the Combined Monitor \nconfiguration agreed the IM PA Tools allowed for a timely detection of an impending \nexceedance when On (M=75.0; SD=31.3). A majority (71%) also agreed when Off (M=64.1; \nSD=34.4). For the Separate 28R Monitor position, a majority (57%) agreed when On (M=33.1; \nSD=33.1) and Off (M=63.6; SD=32.1). Though the mean was higher, and the variability was lower for the IM PA Tools On in the \nCombined 28L/28R Monitor configuration, the high variability across all of the conditions \nsuggest none were actually more or less effective to the Week 2-3 TRACON controllers than any \nof the others. --------------------------------- A similar question was asked at the end of each run (QT1) to participants working as the 28R \nFinal controller: The IM PA-related tools provided in this scenario allowed for a timely \ndetection of any spacing or separation issues. TRACON controller responses were also then lxxiv\n examined with respect to IM PA Tool configuration. Response Means and Standard Deviations \nfor the 28R Final controller position are summarized in Table 5-49. Scale responses are shown in \nFigure 5-59. Only TRACON controller responses were included in the analysis. Table 5-49. 28R Final Controller: IM PA Tools Allowed for Timely Issue Detection IM PA Tool Configuration Tools On Tools Off\nSample Size (n) 10 10 Mean (M) 70.7 65.6 Standard Deviation (SD) 33.2 30.4 Figure 5-59. 28R Final Controller: The IM PA-related tools provided in this scenario allowed for a timely \ndetection of any spacing or separation issues. Note: o indicates NCT controller responses. TRACON controller responses were variable, but the majority (70%) agreed with IM PA Tools On \n(M=70.7; SD=33.2) and the majority (60%) agreed with IM PA Tools Off (M=65.6; SD=30.4). \nComments from controllers who disagreed were related to not having prior knowledge of the \nsafety limit proximity before issuing the clearance and not knowing the WSL sooner. No \npractical difference was observed between the two IM PA Tool configurations. --------------------------------- As described in Sections 4.5.4 and 4.5.6.5, a portion of the evaluation on Day 3 involved \nmanipulating the Timing values for the Predictive and Caution Alerts to determine if \nreducing the alerting time would be more or less acceptable in the separation \nmonitoring task. The timing values used in the HITL are shown in Table 4-12. Due to a \nWeek 1 Alert Timing scenario issue, only the Week 2-3 TRACON controller responses are \nincluded in the analysis. In the Alert Timing Post-Run Questionnaires (QT4), controllers were asked if: The Predictive (yellow) alert provided sufficient advance notice of an impending \nCaution Alert. \nThe Caution (orange) alert provided sufficient advance notice of an impending loss of \nseparation. lxxv\n Responses are shown for all TRACON (NCT and non-NCT combined) for each Alert Timing value. \nResponse Means and Standard Deviations are summarized in Table 5-50. Scale responses are \nshown in Figure 5-60. Table 5-50. Controller Responses to Sufficiently of Alert Timing Advance Notice Alert Timing (Predictive / Caution) 45 / 24 sec 35 / 20 sec 25 / 15 sec\nPredictive Alert Sample Size (n) 7 7 7 Mean (M) 68.0 78.3 62.7 Standard Deviation (SD) 37.4 33.4 33.7 Caution Alert\nSample Size (n) 7 7 7 Mean (M) 74.3 79.1 69.3 Standard Deviation (SD) 34.6 33.0 37.5 Figure 5-60. The IM PA [Predictive / Caution] Alert provided sufficient advance notice of an impending \n[Caution Alert / loss of separation]. Note: o indicates Week 2-3 Tower controller responses for reference. These are not included in the M and SD computations. Week 2-3 TRACON controller responses were variable for each type of alert and timing value. \nThe majority (71%) of TRACON controllers agreed for the Predictive Alert with the 45/24 and \n25/15 values. The majority (86%) of TRACON controllers agreed for 35/20 value. For the Caution \nAlert, the majority (86%) agreed for the 45/24 and 35/20 values and the majority (71%) agreed \nfor the 25/15 value. Though the means were relatively higher for the 35/20 value for both alert types, the high \nvariability across all of the Alert Timing scenarios suggests that none of the timings were lxxvi\n actually more or less acceptable to the Week 2-3 TRACON controllers than any of the others. --------------------------------- In the Alert Timing Post-Run Questionnaires (QT4), controllers were also asked if: I could easily assess whether the IM Trail aircraft would remain behind the CSL during \nthe approach. \nI could easily assess whether the IM Trail aircraft would remain forward of the WSL \nduring the approach (when applicable). Responses are shown for all TRACON (NCT and non-NCT combined) for each alert timing value. \nResponse Means and Standard Deviations are summarized in Table 5-51. Scale responses are \nshown in Figure 5-61. Table 5-51. Controller Responses to Safety Limit Assessment Alert Timing (Predictive / Caution) 45 / 24 sec 35 / 20 sec 25 / 15 sec\nBehind the CSL Sample Size (n) 7 7 7 Mean (M) 92.3 90.9 71.1 Standard Deviation (SD) 9.1 8.7 34.3 Forward of the WSL\nSample Size (n) 7 7 7 Mean (M) 76.6 85.6 71.0 Standard Deviation (SD) 34.4 17.2 35.0 Figure 5-61. I could easily assess whether the IM PA trail aircraft would remain [behind the CSL / \nforward of the WSL] during the approach. Note: o indicates Week 2-3 Tower controller responses for reference. These are not included in the M and SD computations. lxxvii\n All Week 2-3 TRACON controllers agreed they could easily assess whether the IM PA Trail \nAircraft would remain behind the CSL during the approach for the 45/24 value (M=92.3; SD=9.1) \nand the 35/20 value (M=90.9; SD=8.7). All also agreed they could easily assess whether the IM \nPA Trail Aircraft would remain forward of the WSL during the approach for the 35/20 value \n(M=85.6.9; SD=17.2). Week 2-3 TRACON controller responses were variable for the 25/15 alert timing values for each \nsafety limit, but a majority (71%) agreed for the CSL (M=71.1; SD=34.3) and WSL (M=71.0; \nSD=35.0). Responses were also variable for the 45/24 value for the WSL, but a majority (86%) \nalso agreed (M=76.6; SD=34.4).
The means were relatively higher, and the variability lower, for the 45/24 and 35/20 values for \nthe CSL than the other conditions. This suggests greater controller agreement on the \neffectiveness of these alert timing values for the CSL than the 25/15 value. For the WSL, the \nrelatively higher mean and lower variability for the 35/20 value suggests greater controller \nagreement on the effectiveness of this value than the other two. Selected open-ended comments for this question included: (Non-NCT TRACON / 45/24) Not easily, but definitely could guess with confidence when \na deviation on the CSL would occur.\n(Non-NCT TRACON / 25/15) The more I watch scenarios, the better I become at \npredicting if the a/c will or will not stay behind the CSL. The automation helps in addition \nto this (i.e., warning and caution).\n(NCT / 45/24) Definitely works better w/ preview line, so I don't have to narrow my focus \nto the area where the WSL pops up.\n(Non-NCT TRACON / 25/15) [WSL is] more difficult than CSL assessment because WSL is \neffective so late on final. The warning helped. --------------------------------- After all the Alert Timing scenarios were run (QT5), controllers were asked: how many seconds \nbefore the IM Trail Aircraft crosses the CSL would you like to see the Predictive and Caution \nAlerts. Participants were allowed to enter any value they liked. Responses are shown in Figure \n5-62 for Week 2-3 TRACON (NCT and non-NCT combined) and Tower Only. lxxviii\n Figure 5-62. How many seconds before the IM Trail Aircraft crosses the CSL would you like to see the \nPredictive and Caution Alerts? With respect to the CSL, the majority of Week 2-3 TRACON controllers responded with 35 \nseconds for the Predictive Alert. Controllers tied between 15 and 20 seconds for the Caution \nAlert. After all the Alert Timing scenarios were run (QT5), controllers were also asked: how many \nseconds before the IM Trail Aircraft crosses the WSL would you like to see the Predictive and \nCaution Alerts. Participants were allowed to enter any value they liked. Responses are shown in \nFigure 5-63 for Week 2-3 TRACON (NCT and non-NCT combined) and Tower Only. Figure 5-63. How many seconds before the IM Trail Aircraft crosses the WSL would you like to see the \nPredictive and Caution Alerts? With respect to the WSL, the majority of Week 2-3 TRACON controllers responded with 35 \nseconds for the Predictive Alert. TRACON controllers tied between 15 and 20 seconds for the \nCaution Alert. In the comments, one participant noted for the Caution Alert: Timing depends \non type of position responsible for the aircraft pairs at the time. With a monitor, no less than 15 \nseconds. With a local or final, 24 seconds seems reasonable. Alert Response Times6.5.4.3\nAs described in Section 4.5.4, Day 3 for each week included a self-contained evaluation of \nalternate longitudinal alert timings. The analysis in this section examined whether lower alert \ntimings than those chosen for ATPA affected controller response time to a Caution Alert, as \nreduced timings may ultimately be used to mitigate against nuisance alerts (which would occur \nmore frequently with greater timings). Three sets of alert timing values were investigated in the \nHITL as levels of the Alert Timing Independent Variable and are shown in Table 5-52. Table 5-52. Alert Timing Independent Variable Levels Predictive Alert Time (sec) Caution Alert Time (sec) Set X 45 24 Set Y 35 20 Set Z 25 15 The different alert timings were only examined in the context of the Combined Monitor lxxix\n configuration. All of the IM PA-related tools described previously were available to the \nCombined Monitor controller. The counterbalancing of the timing values used in the HITL is \nshown in Table 4-12. As noted in Section 4.5.7.2, objective data was collected with respect to controller PTT times, \naircraft state, and longitudinal alerting. The PTT data caveats described in Section 5.1.2 apply \nhere. In sum, if the Local controller or pseudopilot was talking on the frequency, participants \ncould not break in to override. They were, however, told to still click their handsets when they \nwanted to speak. The first click that was recorded after an event of interest was used as a \nproxy for the controller response time to resolve a situation. It was generally assumed that the \nfirst click that was recorded after an event of interest represented the controller response time \nto resolve a situation. Though this is likely to be a safe assumption generally, there were five cases in which unusually \nlong delays (> 11 sec) were observed between the Caution Alert and the next PTT click. The \nlowest of these values were eight or more times higher than the other average responses and \nmore than twice the average controller response times to the NTZ Warnings reported in Cox, \nYates, & Savage (2011). These cases were further examined and it was found that there was also \na very short time difference between the preceding PTT click and the Caution Alert. These likely \nrepresented instances in which the controller felt confident that the aircraft would receive a \nCaution Alert and therefore intervened just before the alert actually occurred. These five \ninstances were removed from the data, resulting in different n values per condition, and are \nfurther discussed later in this section. PTT response time Means and Standard Deviations are summarized in Table 5-53. Responses \nare shown for all TRACON (NCT and non-NCT combined) for each alert timing value. Due to a \ntechnical issue in Week 1 that affected the Alert Timing scenarios, only the Week 2-3 TRACON \ncontroller responses are included in the analysis. Table 5-53. Average Controller PTT Response Time (sec) After Caution Alert Alert Timing (Predictive / Caution) 45 / 24 sec 35 / 20 sec 25 / 15 sec\nCSL Caution Alert Sample Size (n) 16 16 15 Mean (M) 1.8 sec 1.1 sec 1.5 sec Standard Deviation (SD) 2.7 1.6 1.9 WSL Caution Alert\nSample Size (n) 9 10 10 Mean (M) 1.0 sec 0.9 sec 1.4 sec Standard Deviation (SD) 1.0 1.2 1.8 Total\nSample Size (n) 25 26 25 lxxx\n Mean (M) 1.5 sec 1.0 sec 1.5 sec Standard Deviation (SD) 2.2 1.4 1.8 The HITL data shows that on average, controllers responded (via a PTT click) to Caution \nAlerts within approximately 1-2 seconds. Note this does not suggest controllers first \nnoticed the Caution Alert 1-2 seconds after it occurred; these values only represent the \ntime between the Caution Alert display and the next PTT click of the participants \nhandset. To examine whether alert timing had an effect on PTT Response times, a single-factor \nANOVA test was performed. Due to the three levels of the Alert Timing Independent \nVariable, the Bonferroni correction was used to control for the potential for familywise \nerror. The probability of finding an effect when there was none, alpha (), was set to \n0.05. The results are shown in Table 5-54. Table 5-54. Controller PTT Response Time After Caution Alert: Single Factor ANOVA Results SS df MS F p-value Significant?\nBetween Groups 4.30 2 2.15 0.64 0.53 no Within Groups 246.48 73 3.38\nTotal 250.78 75 3.34 The statistical analysis results from the simulation suggest there was no significant \ndifference between average controller response times for any of the three alert timings \n(p = 0.53). --------------------------------- As noted earlier, five out of 82 (6%) cases were observed in which controllers appeared to have \nintervened with an aircraft before it triggered a Caution Alert. Three of these were with the \n45/24 timing and three were with the 35/20 timing. Four of the five cases were related to a WSL \nalert and one was related to a CSL alert. Overall there were too few occurrences to suggest any \ntrends. Display Implementation6.5.4.4\nAs described in Section 4.2.7, an alert was indicated by both the respective safety limit line and \ndata block numeric indicator changing color. To determine if controllers might exhibit a display \npreference for the Predictive Alert, they were asked after all the Alert Timing scenarios were run \n(QT5) if it was helpful to indicate the Predictive Alert via the [Data Block Line 3 / CSL or WSL \nline] color change. Responses are shown for all TRACON (NCT and non-NCT combined) and \nTower Only. Response Means and Standard Deviations are summarized in Table 5-55. Scale \nresponses are shown in Figure 5-64. One NCT and one Tower participant did not respond to this \nquestion, therefore n=9 for the TRACON controller responses and n=1 for the Tower responses. Table 5-55. Controller Responses for Predictive Alert Display Implementation Helpfulness lxxxi\n Participant Experience TRACON Tower\nData Block Value Color Change Sample Size (n) 9 1 Mean (M) 77.8 100 Standard Deviation (SD) 19.5  CSL or WSL Line Color Change\nSample Size (n) 9 1 Mean (M) 81.9 100 Standard Deviation (SD) 17.8  Figure 5-64. It was helpful to indicate the Predictive Alert via the [Data Block Line 3 / CSL or WSL line] \ncolor change. Note: o indicates NCT controller responses. Rows indicate an n=9 and N=1 because one TRACON and one Tower participant did \nnot include a rating in their questionnaires.
The majority (78%) of TRACON controllers agreed it was helpful to indicate the Predictive Alert \nvia the data block line 3 color change (M=77.8; SD=19.5). The majority (89%) of TRACON \ncontrollers agreed it was helpful to indicate the Predictive Alert via the CSL or WSL line color \nchange (M=81.9; SD=17.8). No practical difference was observed between displaying the \nPredictive Alert via a safety limit line color change versus the Data Block CSL/WSL value color \nchange. --------------------------------- To determine if controllers might exhibit a display preference for the Caution Alert, they were \nasked after all the Alert Timing scenarios were run (QT5) if it was helpful to indicate the \nCaution Alert via the [Data Block Line 3 / CSL or WSL line] color change. Responses are shown \nfor all TRACON (NCT and non-NCT combined) and Tower Only. Response Means and Standard \nDeviations are summarized in Table 5-56. Scale responses are shown in Figure 5-65. lxxxii\n Table 5-56. Controller Responses for Caution Alert Display Implementation Helpfulness Participant Experience TRACON Tower\nData Block Value Color Change Sample Size (n) 10 2 Mean (M) 76.3 92.0 Standard Deviation (SD) 19.1  CSL or WSL Line Color Change\nSample Size (n) 10 2 Mean (M) 82.5 93.5 Standard Deviation (SD) 15.4  Figure 5-65. It was helpful to indicate the Caution Alert via the [Data Block Line 3 / CSL or WSL line] \ncolor change. Note: o indicates NCT controller responses. The majority (80%) of TRACON controllers agreed it was helpful to indicate the Caution Alert via \nthe data block line 3 color change (M=76.3; SD=19.1). The majority (90%) of TRACON controllers \nagreed it was helpful to indicate the Caution Alert via the CSL or WSL line color change (M=82.5; \nSD=15.4). No practical difference was observed between displaying the Caution Alert via a \nsafety limit line color change versus the Data Block CSL/WSL value color change. However, one \nTRACON controller commented for both Alert Types: The color change is necessary, but not \nenough. The color change alone is not enough to grab my attention if I am focused on another \npart of the radar scope. Response Procedures6.5.4.5\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if my responsibilities with respect to a \nPredictive Alert and Caution Alert were clear. Responses are shown for all TRACON (NCT and lxxxiii\n non-NCT combined) and Tower Only. Response Means and Standard Deviations are summarized \nin Table 5-57. Scale responses are shown in Figure 5-66. Table 5-57. Controller Responses to Clarity of Responsibilities Participant Experience TRACON Tower\nPredictive Alert Sample Size (n) 10 2 Mean (M) 83.3 87.5 Standard Deviation (SD) 27.5  Caution Alert\nSample Size (n) 10 2 Mean (M) 95.0 90.0 Standard Deviation (SD) 4.4  Figure 5-66. My responsibilities with respect to a Predictive Alert and Caution Alert were clear. Note: o indicates NCT controller responses. Responses were variable, but the majority (90%) of TRACON controllers agreed their \nresponsibilities with respect to an IM PA Predictive Alert were clear (M=83.3; SD=27.5). One \nNCT controller commented: Maybe develop some phraseology so I can make pilot aware they \nare messing up and need to take quick action to prevent a go around. All (100%) TRACON controllers agreed their responsibilities with respect to an IM PA Caution \nAlert were clear (M=95.0; SD=4.4). The higher average and lower variability of the Caution Alert \nsuggests controllers found its response procedures more clear than those for the Predictive \nAlert. lxxxiv\n IM Spacing List and IM Aircraft Status6.5.5\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if: The IM Spacing List IM Status Information was useful for the overall IM PA monitoring \ntask.\nThe Monitor controller should be provided an IM Spacing List. Responses are shown for all TRACON (NCT and non-NCT combined) and Tower Only. Response \nMeans and Standard Deviations are summarized in Table 5-58. Scale responses are shown in \nFigure 5-67. Table 5-58. Controller Responses to IM Spacing List Usefulness Participant Experience TRACON Tower\nIM Status on Spacing List Useful Sample Size (n) 10 2 Mean (M) 50.6 86.0 Standard Deviation (SD) 34.8  Monitor should have Spacing List\nSample Size (n) 10 2 Mean (M) 23.7 30.0 Standard Deviation (SD) 35.0  Figure 5-67. IM Spacing List for Monitoring Task Note: o indicates NCT controller responses. Responses were variable, but the majority (60%) of TRACON controllers agreed the IM Spacing \nList IM Status Information was useful for the overall IM PA monitoring task. However, on lxxxv\n average, controllers neither agreed nor disagreed (M=50.6; SD=34.8). Responses were variable, but a majority (70%) of TRACON controllers disagreed the Monitor \ncontroller should be provided an IM Spacing List (M=23.7; SD=35.0). One controller commented \nthat it should be customizable. Personally, I would not want it but it should be an option if \nothers do. --------------------------------- At the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if the IM Lead Aircraft and IM Trail Aircraft \nStatus [in the data block] was useful for the overall IM PA monitoring task. Responses are \nshown for all TRACON (NCT and non-NCT combined) and Tower Only. Response Means and \nStandard Deviations are summarized in Table 5-59. Scale responses are shown in Figure 5-68. Table 5-59. Controller Responses to IM Lead / Trail Aircraft Status Usefulness Participant Experience TRACON Tower\nIM Lead Aircraft Status Useful Sample Size (n) 10 2 Mean (M) 41.7 75.5 Standard Deviation (SD) 32.4  IM Trail Aircraft Status Useful\nSample Size (n) 10 2 Mean (M) 46.6 74.0 Standard Deviation (SD) 32.8  Figure 5-68. The IM Lead Aircraft and IM Trail Aircraft Status [in the data block] was useful for the \noverall IM PA monitoring task Note: o indicates NCT controller responses. lxxxvi\n Responses were variable, but a majority (60%) of TRACON controllers disagreed the IM Lead \nAircraft Status [in the data block] was useful for the overall IM PA monitoring task (M=41.7; \nSD=32.4). Responses were also variable for the IM Trail Aircraft, but only half (50%) of TRACON \ncontrollers agreed it was useful. On average, however, they disagreed (M=46.6; SD=32.8). Display Feature Recommendations6.5.6\nThis section presents the participants recommendations for the various IM PA tool and display \nfeatures. The Lateral Deviation results are discussed in Section 5.6. However, controller \nrecommendations regarding the individual Lateral Monitoring display features are still \nsummarized here. Monitoring6.5.6.1\nAt the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked: what combination of tools would you \nrecommend for the IM PA Monitor controller? Participants selected [Always On / User \nToggleable / Not Needed] for each element. Figure 5-69 shows the number of participant responses for each type of recommendation for \neach IM PA Tool and display feature for the IM PA Monitor controller. The left column for each \nelement consists of TRACON controller responses and the right column is the Tower controller \nresponses. One participant selected both User Toggleable and Not Needed for several elements; \nthis is therefore shown as a separate category. Figure 5-69. Monitoring Tool Recommendations All (100%) TRACON controller participants responded that the CSL and WSL Lines should always \nbe on. A majority (90%) responded that the Predictive and Caution Alerts should also always be lxxxvii\n on. Half (50%) felt the WSL-P should always be on and half felt that it should be user toggleable. \nOnly half (50%) responded that the various data block IM PA features should either always be \non or user toggleable. Responses were more variable for the necessity of the other elements. As \ndescribed in Section 5.5.5, the majority of controllers disagreed the Monitor controller should \nbe provided an IM Spacing List, though it was suggested in Section 5.2.7 that some information \nin the list, such as the Assigned Spacing Goal, could be provided in the IM Trail Aircrafts data \nblock. At the end of Day 2 (QT3), a majority (80%) of TRACON controller responses suggested that the \nInner and Outer Lateral Bounds should either be should either always be on or be user \ntoggleable. These ratings were made before the participants experienced the Day 3 Lateral \nDeviation scenarios. Therefore, after the Lateral Deviation scenarios were complete (QT7), \ncontrollers were asked: In terms of handling lateral deviations, what combination of tools \nwould you recommend for the IM PA Monitor controller? Participants selected [Always On / \nUser Toggleable / Not Needed] for the following four features: Exceedance Warning: Boundary Line Color Line Change to Red\nExceedance Warning: Red LAT in the data block\nInner Bounds\nOuter Bounds Figure 5-70 shows the number of participant responses for each type of recommendation for \neach Lateral Monitoring display feature for the IM PA Monitor controller. The left column for \neach element consists of TRACON controller responses and the right column is the Tower \ncontroller responses. One participant selected both User Toggleable and Not Needed for several \nelements; this is therefore shown as a separate category. Figure 5-70. Lateral
Monitoring Tool Recommendations After experiencing the Lateral Deviation scenarios, the number of TRACON controllers that felt lxxxviii\n the Lateral Boundaries should always be displayed increased by 10-20%. The majority of \ncontrollers felt the Inner Boundary should always be displayed (80%) and the Outer Boundary \nshould always be displayed (70%). The rest felt the boundaries should be user toggleable. There \nwere no instances of Not Needed. For the two features related to the Exceedance Warning, all (100%) TRACON controllers thought \nthe red LAT in the data block should always be displayed. A majority (90%) thought the \nBoundary Line Color Change to Red should always occur; however, one controller thought that \nit was not needed/should be user toggleable. In the comments, two controllers recommended that for an Exceedance Warning, the entire \ndata block of the deviating aircraft should turn red. Controllers also made the following \ncomments with respect to the Lateral Boundaries: (NCT) Lateral bounds not needed when monitoring from standard scope display since \nthey are so hard to see inside them.\n(Non-NCT TRACON) Lateral bounds work great on 4:1 aspect ratio, but clutter final when \non regular aspect. IM Clearance Completion6.5.6.2\nAt the end of Day 2 (QT3), after experiencing all nominal scenarios, controllers were asked a \nsimilar question: what combination of tools would you recommend to help the Final controller \ncomplete the IM Clearance? Participants selected [Always On / User Toggleable / Not Needed] \nfor each element. Figure 5-71 shows the number of participant responses for each type of recommendation for \neach IM PA Tool and display feature for the IM PA Final controller. The left column for each \nelement consists of TRACON controller responses and the right column is the Tower controller \nresponses. One participant selected both User Toggleable and Not Needed for several elements; \nthis is therefore shown as a separate category. The WSL Line was not included as it never \napplied in Final controller airspace. lxxxix\n Figure 5-71. IM Clearance Completion Tool Recommendations Note: The Week 1 controller questionnaires inadvertently omitted the IM PA Spacing Goal and Lead Aircraft Call Sign features. \nTherefore, only eight responses are shown for these features instead of twelve. All (100%) TRACON controller participants responded that the CSL Line should always be on. A \nmajority (70%) of responses suggested that the WSL-P should either always be on or be user \ntoggleable. A majority (80%) responded that the Predictive and Caution Alerts should always be \non and the others responded that it should be user toggleable. All (100%) TRACON controllers responded that the IM PA Spacing Goal and Lead Aircraft Call \nSign should always be on. A majority (80%) responded that the Lead Aircraft Runway should \neither always be on or be user toggleable. A majority (70%) responded that IM Status (in the \nSpacing List) should either always be on or be user toggleable. This was higher than the \nresponses to the IM Lead and IM Trail Aircraft Status indicators in the data blocks. Only a \nminority of controllers responded that the Distance to the CSL (30%) and WSL W (40%) should \nbe user toggleable. The rest responded that they were not needed. A majority (60%) of responses suggested that the Inner and Outer Lateral Bounds should either \nalways be on or be user toggleable. These features are discussed further in Section 5.6. \nResponses were more variable regarding the necessity of the other elements. --------------------------------- At the end of Day 2 (QT3), controllers were also asked if the usefulness of any of the tools \ndepend on whether there was single monitor for both approaches, or separate monitors for \neach approach? All participants (n=12) answered No. xc\n Other IM PA Tool Comments6.5.7\nThe following is a collection of other selected comments made by the controller participants \nwith respect to the IM PA Tools. Given their specific experience in the areas being simulated, \nNCT responses are specifically identified. Non-NCT TRACON and Tower responses are thus also \nindividually identified. (NCT) I relied on the IM PA automation and trusted it, but could not verify because the \naircraft were already much closer than standard separation.\n(Non-NCT TRACON) I think the best experience was with all tools available turned on. \nWith select tools off, the scenarios were still easily workable, but the extra tools provide \ngood trend data and overall improved awareness.\n(Non-NCT TRACON) The WSL did advise when I need to terminate an approach but did \nnot provide a good advance notice.\n(Non-NCT TRACON) Situational awareness may be increased even more if the gray line \n[WSL-P] was there the whole time.\n(Non-NCT TRACON) Third line and wake preview lines are better than without. Not \nhaving the gray wake line hinders overall awareness. [WSL-P Only] I think I still had \nenough awareness but the numbers not being in the data block takes away a measure of \nawareness.\n(Non-NCT TRACON) Distance processing on CSL and WSL in data block not necessary for \ntrailing aircraft unless it goes into alert status.\n(NCT) The CSL data turning color really caught my attention better than the line turning \ncolor. Dont care to have either on but they should pop up when it goes into an alert \nstatus. \n(NCT) The CSL line isn't that helpful but the data block changing color is more helpful and \nnoticeable.\n(TRACON/NCT) Spacing list should show all aircraft not just who can play, put (non-pair \nwith aircraft on 28R final) this will allow controller to know right away instead of \nsearching for aircraft pair that they don't have. Results Topic 5: Lateral Deviations6.6\nAs described in Sections 4.5.4 and 4.5.6.6, a portion of the evaluation on Day 3 involved \nintroducing lateral deviations to examine the acceptability of the monitoring configurations and \neffectiveness of the IM PA Tools in these rare, off-nominal conditions. This included determining \nto what degree will controllers want to detect developing deviations before a Lateral Boundary \nis crossed, whether a 4:1 aspect ratio display is needed, especially with only an Exceedance \nWarning (no Lateral Predictive Alert) with a tighter Lateral Boundary size (ILS versus 500 ft). All \nof the IM PA-related tools described previously were available to the Monitor controllers for \nthese scenarios. The Final controller position was not evaluated for these conditions and unless \notherwise noted, the results in this section are in response to the Lateral Deviation scenarios \nonly. xci\n Workload Acceptability6.6.1\nAt the end of each Lateral Deviation scenario (QT6), controllers were asked if their workload \nwas acceptable in the scenario they just experienced. Their responses were examined with \nrespect to monitor configuration and display type. Response Means and Standard Deviations \nare summarized in Table 5-60. Scale responses are shown in Figure 5-72. Some rows indicate \nn=9 and n=8 because not all Week 1 controllers experienced all scenarios (see Section 4.5.6.6). Table 5-60. Controller Responses to Acceptability of Overall Workload (Lateral Deviation Scenarios) Display Type STARS FMA\nCombined 28L/28R Monitor Sample Size (n) 10 10 Mean (M) 88.6 91.6 Standard Deviation (SD) 18.2 12.4 28R Monitor\nSample Size (n) 9 9 Mean (M) 94.4 90.3 Standard Deviation (SD) 4.9 13.3 28L Monitor\nSample Size (n) 8 8 Mean (M) 95.8 95.0 Standard Deviation (SD) 5.1 6.1 xcii\n Figure 5-72. My overall workload was acceptable for the scenario I just experienced. (Lateral Deviation \nScenarios) Note: o indicates the Tower controller responses for reference. These are not included in the M and SD computations. Some rows \nindicate n=9 and n=8 because not all Week 1 controllers experienced all of the Lateral Deviation scenarios. All (100%) TRACON controllers agreed their workload was acceptable across all display types \nand monitor configurations, except for one. This controller disagreed for the Combined Monitor \nconfiguration with the STARS display and commented Breaking out a 28L aircraft blundering \nright requires two simultaneous transmissions. Despite this, no practical difference in workload \nacceptability was observed among any of the display type and monitor configurations. Other selected open-ended comments for this question included: (NCT / 28R/FMA) Two blundering at once was work intensive.\n(Non-NCT TRACON / 28R/FMA) Multiple alerts simultaneously make it impossible to talk \nto all involved aircraft in a timely manner. Separation Assessment6.6.2\nAt the end of each Lateral Deviation scenario (QT6), controllers were asked if they were \nconfident that I could assess whether separation would be maintained between the IM Trail \nAircraft and their Lead aircraft in the scenario they just experienced. Their responses were \nexamined with respect to monitor configuration and display type. Response Means and \nStandard Deviations are summarized in Table 5-61. Scale responses are shown in Figure 5-73. \nSome rows indicate n=9 and n=8 because not all Week 1 controllers experienced all scenarios \n(see Section 4.5.6.6). Table 5-61. Controller Responses to Separation Assessment (Lateral Deviation Scenarios) Display Type STARS FMA\nCombined 28L/28R Monitor Sample Size (n) 10 10 Mean (M) 90.5 91.3 Standard Deviation (SD) 6.9 10.6 28R Monitor\nSample Size (n) 9 9 Mean (M) 89.3 93.6 Standard Deviation (SD) 14.0 6.7 28L Monitor\nSample Size (n) 8 8 Mean (M) 91.3 93.9 xciii\n Standard Deviation (SD) 7.9 6.3 Figure 5-73. I was confident that I could assess whether separation would be maintained between the \nIM Trail Aircraft and their Lead aircraft. (Lateral Deviation Scenarios) Note:
o indicates the Tower controller responses for reference. These are not included in the M and SD computations. Some rows \nindicate n=9 and n=8 because not all Week 1 controllers experienced all of the Lateral Deviation scenarios. All (100%) TRACON controllers agreed they were confident they could assess whether \nseparation would be maintained between the IM Trail Aircraft and their Lead aircraft for all \ndisplay type and monitor configurations. No practical difference in workload acceptability was \nobserved. Lateral Boundaries Display Implementation6.6.3\nAt the end of each Lateral Deviation scenario (QT6), controllers were asked if they could easily \nassess whether aircraft involved in a PA operation were operating within their Lateral \nBoundaries in the scenario they just experienced. Their responses were examined with respect \nto monitor configuration and display type. Response Means and Standard Deviations are \nsummarized in Table 5-62. Scale responses are shown in Figure 5-74. Some rows indicate n=9 \nand n=8 because not all Week 1 controllers experienced all scenarios (see Section 4.5.6.6). Table 5-62. Controller Responses to Lateral Boundary Assessment Display Type STARS FMA\nCombined 28L/28R Monitor Sample Size (n) 10 10 Mean (M) 64.1 94.3 Standard Deviation (SD) 30.6 4.9 28R Monitor xciv\n Sample Size (n) 9 9 Mean (M) 71.7 94.3 Standard Deviation (SD) 26.1 7.5 28L Monitor\nSample Size (n) 8 8 Mean (M) 66.8 95.4 Standard Deviation (SD) 23.0 4.4 Figure 5-74. In this scenario, I could easily assess whether aircraft involved in a PA operation were \noperating within their Lateral Boundaries. Note: o indicates the Tower controller responses for reference. These are not included in the M and SD computations. Some rows \nindicate n=9 and n=8 because not all Week 1 controllers experienced all of the Lateral Deviation scenarios. All (100%) TRACON controllers agreed they could easily assess whether aircraft involved in a PA \noperation were operating within their Lateral Boundaries for every monitor configuration with \nthe FMA display. With the STARS display, however, a majority agreed for the Combined Monitor \n(70%), 28R Monitor (67%), and 28L Monitor (50%). Though responses suggest the lateral \nmonitoring task is possible with both display types across all configurations, means were higher \nand variability was lower for the FMA display. As described in Section 5.8.5, a two-factor, repeated measures ANOVA test on this data found a \nsignificant difference with respect to display type. No difference was observed with respect to \nmonitor configuration, nor were there any interaction effects. This suggests controllers found \nthat the FMA display aided in their Lateral Boundaries Assessment, but that the assessment was \nnot affected by the monitor configuration. Selected open-ended comments for this question included: (NCT / Combined/FMA) In comparison to STARS, 4:1 was more effective at displaying \nmovement in the lateral confines.\n(NCT / 28R/STARS) Its difficult to observe movement within the lateral confines of the \ncourse windows. It's easier to determine movement on the 4:1 scope. xcv\n (NCT / 28L/STARS) I wouldn't say easily, but you can see.\n(Non-NCT TRACON / 28L/FMA) Was more evident with this aspect ratio. I even noticed \nan aircraft off course on the other final before it alerted.\n(Non-NCT TRACON / Combined/FMA) 4:1 ratio was much better, you could see aircraft \nstart to come off center and could correct if allowed.\n(Non-NCT TRACON / Combined/STARS) Both sides of 28L primary target are outside of \nlateral bounds. Extremely difficult to tell if they are starting to deviate until alert goes \noff. \n(Non-NCT TRACON / Combined/STARS) The lateral bounds are very narrow and the \nwidth of the target fills the entire bounds. Very difficult to spot impending deviation. 4:1 \naspect ratio made it much easier to see. --------------------------------- At the end of Day 2 (QT3), after experiencing the nominal scenarios across all IM PA Tool and \nmonitor configurations, controllers were asked if the Inner and Outer (Lateral) Bounds were \nuseful for the overall IM PA monitoring task. Responses are shown for all TRACON (NCT and \nnon-NCT combined) and Tower Only. Response Means and Standard Deviations are summarized \nin Table 5-63. Scale responses are shown in Figure 5-75. xcvi\n Table 5-63. Controller Responses to Lateral Boundary Usefulness Participant Experience TRACON Tower\nInner Bounds Sample Size (n) 10 2 Mean (M) 42.2 87.5 Standard Deviation (SD) 39.5  Outer Bounds\nSample Size (n) 10 2 Mean (M) 42.2 88 Standard Deviation (SD) 40.1  Figure 5-75. The Inner and Outer (Lateral) Bounds were useful for the overall IM PA monitoring task. Note: o indicates NCT controller responses. Responses were variable, but a majority (60%) of TRACON controllers disagreed the Inner \n(M=42.2; SD=39.5) and Outer (M=42.2; SD=40.1) Lateral Bounds were useful for the \noverall IM PA monitoring task. These ratings were provided before the Day 3 Lateral \nDeviation scenarios. However, at the end of Day 3 controllers were asked: Does anything \nyouve experienced today change any of your previous positions with respect to \nminimum IM PA information for monitoring? Only one controller answered yes, but the \nassociated comment was unrelated to the Lateral Boundaries. Lateral Boundary Exceedance Warning6.6.4\nUnlike in the longitudinal case, a lateral deviation alert only occurred once an aircraft actually \ncrossed a Lateral Boundary. There was no predictive-type alert to provide advance notice that \nan aircraft was likely to cross a boundary. Therefore, after the Lateral Deviation scenarios were xcvii\n complete (QT7), controllers were asked if: Advance notice of an impending exceedance of the lateral bounds would have been \nhelpful.\nAdvance notice of an impending exceedance of the lateral bounds would have been \nessential. Responses are shown for all TRACON (NCT and non-NCT combined) and Tower Only. Response \nMeans and Standard Deviations are summarized in Table 5-64. Scale responses are shown in \nFigure 5-76. Table 5-64. Controller Responses to Helpfulness of Lateral Boundary Crossing Advance Notice Participant Experience TRACON Tower\nHelpful Sample Size (n) 10 2 Mean (M) 90.3 90.0 Standard Deviation (SD) 13.3  Essential\nSample Size (n) 10 2 Mean (M) 64.2 84.0 Standard Deviation (SD) 31.6  Figure 5-76. Advance notice of an impending exceedance of the lateral bounds would have been \n[helpful / essential]. Note: o indicates NCT controller responses. All (100%) TRACON controllers agreed advance notice of an impending exceedance of the \nLateral Boundaries would have been helpful (M=90.3; SD=13.3). A majority (60%) agreed it \nwould have been essential (M=64.2; SD=31.6). xcviii\n As described in Section 5.8.5, a paired-sample T-Test analysis found a significant difference in \ncontroller agreement response. Though controllers agreed for both, stronger agreement was \nobserved for a predictive-type alert for lateral deviations being only helpful. Open-ended comments for this question included: (Non-NCT TRACON) Maybe. Too much info can sometimes divert our attention away \nfrom something that may take more precedence.\n(NCT) Absolutely, it would also give a chance for the controller to advise the pilot to \ncorrect.\n(Non-NCT TRACON) 4:1 aspect ratio did allow time for me to notice impending deviation \nand I found this very useful. On regular STARS display this was not possible and led to no \nadvance warning of a deviation.\n(NCT) With 4:1 ratio its easy to see them start to blunder, without 4:1 its harder.\n(Non-NCT TRACON) I think that due to the proximity of the final approach courses, some \nsort of advance notice of an impending deviation would be essential to ensure a safe \noperation. \n(Non-NCT TRACON) If I see it developing, I have very few options for keeping aircraft \nwithin limits, so I probably won't take action anyway until required. --------------------------------- At the end of each Lateral Deviation scenario (QT6), controllers were asked if the warning (red) \nalert was noticeable enough such that I became aware of it without undue delay in the \nscenario they just experienced. Their responses were examined with respect to monitor \nconfiguration and display type. Response Means and Standard Deviations are summarized in \nTable 5-65. Scale responses are shown in Figure 5-77. Some rows indicate n=9 and n=8 because \nnot all Week 1 controllers experienced all scenarios (see Section 4.5.6.6). The 28L Monitor FMA \ndisplay has n=7 because one of the controllers left the question blank. xcix\n Table 5-65. Controller Responses to Salience of Exceedance Warning Display Type STARS FMA\nCombined 28L/28R Monitor Sample Size (n) 10 10 Mean (M) 93.3 94.3 Standard Deviation (SD) 5.5 5.1 28R Monitor\nSample Size (n) 9 9 Mean (M) 91.0 94.8 Standard Deviation (SD) 12.3 4.5 28L Monitor\nSample Size (n) 8 7 Mean (M) 91.8 95.1 Standard Deviation (SD) 9.7 5.5 Figure 5-77. The warning (red) alert was noticeable enough such that I became aware of it without \nundue delay. Note: o indicates the Tower controller responses for reference. These are not included in the M and SD computations. Some rows \nindicate n=9 and n=8 because not all Week 1 controllers experienced all of the Lateral Deviation scenarios. All (100%) TRACON controllers agreed the warning (red) alert was noticeable enough such that \nthey became aware of it without undue delay for all display type and monitor configurations. \nNo practical difference in workload acceptability was observed. Selected open-ended comments \nfor this question included: (Non-NCT TRACON / 28L/STARS) The alert was noticeable, but which aircraft it applied to \nwas less obvious. Maybe the entire call sign changes to red? [Note: Several controllers
\nsuggested that the blundering aircrafts entire data block should turn red.] c\n (NCT / Combined/STARS) Would be nice if aircraft that blundered the whole data block \nturned red not just \"LAT\" in line zero with up to 4 aircraft on that runway it would stand \nout that much faster. \n(NCT / 28R/STARS) When the line was already red for the first blunder, it took me an \nextra second to notice another guy was blundering.\n(Tower / Combined/STARS) The first violator that was short final took me more time to \nlocate because the red vertical guidance line was more distracting than helpful.\n(Non-NCT TRACON / 28L/FMA) Very noticeable. When two alert simultaneously, it took \nslightly more time to discern who was blundering and who to talk to first.\n(Tower / 28L/FMA) The ILS line lit was obvious, identifying the involved aircraft was less \nso. --------------------------------- At the end of each Lateral Deviation scenario (QT6), controllers were asked if they had sufficient \ntime and situational awareness to choose and execute appropriate corrective action once the \nwarning (red) alert occurred in the scenario they just experienced. Their responses were \nexamined with respect to monitor configuration and display type. Response Means and \nStandard Deviations are summarized in Table 5-66. Scale responses are shown in Figure 5-78. \nSome rows indicate n=9 and n=8 because not all Week 1 controllers experienced all scenarios \n(see Section 4.5.6.6). Table 5-66. Controller Responses to Timeliness of Exceedance Warning Display Type STARS FMA\nCombined 28L/28R Monitor Sample Size (n) 10 10 Mean (M) 69.9 81.8 Standard Deviation (SD) 23.0 18.0 28R Monitor\nSample Size (n) 9 9 Mean (M) 86.6 85.6 Standard Deviation (SD) 16.4 18.5 28L Monitor\nSample Size (n) 8 8 Mean (M) 88.6 89.8 Standard Deviation (SD) 12.9 9.9 ci\n Figure 5-78. In this scenario, I felt I had sufficient time and situational awareness to choose and \nexecute appropriate corrective action once the warning (red) alert occurred. Note: o indicates the Tower controller responses for reference. These are not included in the M and SD computations. Some rows \nindicate n=9 and n=8 because not all Week 1 controllers experienced all of the Lateral Deviation scenarios. All (100%) TRACON controllers agreed they had sufficient time and situational awareness to \nchoose and execute appropriate corrective action once the warning (red) alert occurred for \nboth display types in the 28L position. A majority (89%) of TRACON controllers agreed for both \ndisplay types in the 28R position. For the Combined Monitor configuration, a majority (70%) \nagreed for the STARS display and a majority (90%) also agreed for the FMA display. Overall, no practical differences in exceedance warning timeliness were observed for all display \ntype and monitor configurations, though the lower mean and higher response variability of the \nCombined Monitor position with the STARS display may have been a more challenging condition \nthan the others. Selected open-ended comments for this question included: (Tower / Combined/FMA) Not much time when the 28L guy blunders right. My \nsituational awareness was ok, but no time to make appropriate transmissions & get \nreadbacks. I see this problem being alleviated w/ split monitors.\n(Non-NCT TRACON / 28L/STARS) I pre-planned with the other monitor in case of a \nblunder situation into his final and I was able to see the a/c action and react properly, \nalong with concurrent coordination.\n(Non-NCT TRACON / 28R/STARS) STARS display of lateral bounds is too small to notice \nany impending breach of boundary. 4:1 aspect ratio would improve this. Lateral Deviation Response Times6.6.5\nAs noted in Section 4.5.7.2, the objective data that was collected included controller PTT times, aircraft state, and Lateral Boundary exceedance. This data was used in the \nanalysis of the Lateral Deviation scenarios to examine whether controller monitor cii\n configuration or display type had an effect on controller response time to an aircraft \ncrossing a Lateral Boundary. The PTT data caveats described in Section 5.1.2 apply here. In sum, if the Local controller or \npseudopilot was talking on the frequency, participants could not break in to override. \nThey were, however, told to still click their handsets when they wanted to speak. The \nfirst click that was recorded after an event of interest was used as a proxy for the \ncontroller response time to resolve a situation. Though in the majority of cases clicks \nwere observed shortly after a lateral deviation, there were three observed occasions of \nlonger reaction times (i.e., 11-16 sec versus typically < 5 sec) after a Lateral Boundary \ncrossing. Unfortunately, the limitations in the audio system make it impossible to \nconclusively determine if these longer times reflected controller situation awareness or \nfrequency congestion. As these instances could not conclusively be determined to be a \nresult of this simulation limitation, they were not removed from the analysis data. A summary of the average Lateral Boundary crossing PTT response time data is shown in \nTable 5-67. The response time was defined as the time between an aircraft crossing the \nlateral boundary (triggering the Exceedance Warning) and the next PTT click. The data \ncombines the two types of deviations (Type A Lead/Sharp versus Type B Trail/Shallow \nsee Section 4.5.5.3). During data collection, some controllers were observed to have \nintervened with deviating aircraft before they crossed the lateral boundary and triggered \nthe Exceedance Warning. These cases were not included in the response time data in \nTable 5-67, but are examined separately later in this section. These cases were the \nprimary reason for the different n values; however, data collection issues also resulted \nin some response times not being recorded for some scenarios. Table 5-67. Average Controller PTT Response Time (sec) After Lateral Boundary Crossings Display Type STARS FMA\nCombined Monitor Sample Size (n) 14 13 Mean (M) 2.4 sec 3.1 sec Standard Deviation (SD) 1.2 5.5 Separate Monitors\nSample Size (n) 14 12 Mean (M) 2.1 sec 2.3 sec Standard Deviation (SD) 1.3 3.0 The HITL data shows that on average, controllers responded (via a PTT click) to Lateral \nBoundary crossings within approximately 2-3 seconds. Note this does not suggest \ncontrollers first noticed the boundary crossing 2-3 seconds after it occurred; these values \nonly represent the time between the Exceedance Warning display and the next PTT ciii\n click of the participants handset. \nTo examine whether monitor configuration or display type had an effect on Lateral Boundary crossing response times, a two-factor, repeated measures ANOVA test was \nperformed. Due to the unbalanced sample sizes, the ANOVA was performed via a \nregression analysis with the probability of finding an effect when there was none, alpha (\n), set to 0.05. The results are shown in Table 5-68. Table 5-68. Controller PTT Response Time After Lateral Boundary Crossings: ANOVA Results SS df MS F p-value Significant?\nMonitor Configuration 3.58 1 3.58 0.35 0.56 no Display Type 2.26 1 2.26 0.22 0.64 no\nInteractions 1.24 1 1.24 0.12 0.73 no Within 506.10 49 10.33\nTotal 513.13 52 9.87 The statistical analysis results from the simulation suggest controller response time to lateral \ndeviations was not different as an effect of monitor configuration (p = 0.56) or display \ntype (p = 0.64), nor were there any interaction effects (p = 0.73). --------------------------------- As noted earlier, some controllers were observed to have intervened with deviating aircraft \nbefore they crossed the lateral boundary and triggered the Exceedance Warning. \nControllers usually did not have enough time to watch a Type A (sharp) deviation \ndevelop and the Exceedance Warning was often their first indication of the deviation. \nHowever, controllers had more time to see a Type B (shallow) deviation developing. The \nfrequency of interventions before the Exceedance Warning is shown in Table 5-69. In \nthis case, the PTT response time was defined as the difference in time between when \nthe aircraft first started its lateral deviation to the time of the next controller PTT click. \nDue to the differences in time available to controllers to respond, the results are shown \nseparately for Type A and Type B deviations. civ\n Table 5-69. Average Controller PTT Response Time (sec) for Interventions Before Lateral Boundary \nExceedance Warning Display Type / Deviation Type\nType A (Sharp) Deviation\nType B (Shallow) Deviation\nSTARS FMA STARS FMA Combined Monitor\nSample Size (n) 0 1 1 0 Mean (M) 4.0 sec 3.0 sec  Standard Deviation (SD) - - Separate Monitors\nSample Size (n) 0 1 4 7 Mean (M) 5.0 sec 35.8 sec 28.3 sec Standard Deviation (SD) - 1.0 11.0 The small number of occurrences in which a controller intervened with a deviating aircraft \nbefore the Exceedance Warning was displayed precludes a statistical analysis. However, \nit is notable that the majority (11/14) of occurrences were with the Separate Controller \nconfiguration with Type B (shallow) deviations. A closer examination of the underlying \ndata showed that the majority (10/14) of these overall cases occurred with the same \ntraffic file (O). In this traffic file, the shallow deviation of a Trail Aircraft began shortly \nbefore the sharp deviation of the Lead Aircraft in a different pair. However, the \nExceedance Warning of the (shallow) Trail occurred after the Exceedance Warning of the \n(sharp) Lead. It seems likely that some controllers noticed the (shallow) deviating Trail \nAircraft but waited to take
action. However, once the Exceedance Warning was \ndisplayed for the Lead, some controllers in this scenario may have then also decided to \nthen intervene with the slowly-deviating Trail instead of waiting for it to cross the Lateral \nBoundary. It is also notable that these cases occurred more often in the Separate Monitor \nconfiguration (12/14) versus Combined (2/14). This is likely due to the difference in the \ntiming of the communications between the configurations, especially with the scenarios \ninvolving traffic file O, which comprised ten of these 14 cases. The timing of these O \nscenarios was such that that the shallow-deviating Trail crossed its Lateral Boundary and \ntriggered its Exceedance Warning shortly after the Lead Aircraft (of a different pair) \ntriggered its Exceedance Warning. In the Combined Monitor configuration, the controller \ntypically contacted the sharply-deviating Lead Aircraft first to turn it back, then \ncontacted its Trail Aircraft to instruct its breakout. This was given higher priority than the \nshallow-deviating Trail, and so it then crossed its Lateral Boundary and triggered the \nExceedance Alert before the controller could contact it. In the Separate Monitor cv\n configuration, however, the 28R controller was not required to contact the deviating \nLead Aircraft. Therefore, there was more time for the 28R controller to break out the \nTrail from the deviating lead and then break out the shallow-deviating Trail before it \nactually crossed its Lateral Boundary. As noted in Section 4.5.5.3, the O scenario was deliberately designed as an extreme case. In \nreal world operations, a near-simultaneous lateral deviation of multiple aircraft on CSPR \nis expected to occur rarely, if at all. An investigation of over 1.8 million approach paths \ndid not detect any (Eckstein, Massimini, McNeill, & Niles, 2012), nor was there a record \nof any in an examination of 7790 go-arounds that were logged over multiple years by \nNCT (Stassen, Domino, Hefley, & Weitz, 2019). Still, this was included in the simulation to \nstress the display features and probe for a potential failure point. The findings here, \nthough not conclusive, may suggest controller behavioral differences with respect to \nintervening with aircraft deviating laterally may only be apparent in the most extreme \nsituations. When this occurs, however, the findings are consistent with a general \nexpectation that controllers may be able to take action more quickly when only having \nresponsibility for one arrival. Simulation Evaluation6.7\nAt the end of Day 3 (QT8) controllers were asked about their overall experience in the \nsimulation and its effectiveness in evaluating IM PA. This section summarizes their responses. Controllers were first asked if the training I received was adequate for the IM Clearance \nCompletion and IM PA monitoring tasks. Given their specific experience in the areas being \nsimulated, NCT responses are shown separately. Non-NCT and Tower responses are thus also \nshown as separate categories. Response Means and Standard Deviations are summarized in \nTable 5-70. Scale responses are shown in Figure 5-79. Table 5-70. Controller Responses to Adequacy of Simulation Training by Task Participant Experience Non-NCT NCT Tower IM Clearance Completion\nSample Size (n) 6 4 2 Mean (M) 96.0 88.0 96.5 Standard Deviation (SD) 7.5 5.4  IM PA Monitoring Sample Size (n) 6 4 2 Mean (M) 97.2 90.5 96.0 Standard Deviation (SD) 4.0 2.5  cvi\n Figure 5-79. The training I received was adequate. All controllers responded that the training they received was adequate for both tasks. --------------------------------- Controller participants were also asked whether the overall activity was effective as a context \nfor evaluating the IM Clearance Completion task and IM PA monitoring task. Given their \nspecific experience in the areas being simulated, NCT responses are shown separately. Non-NCT \nand Tower responses are thus also shown as separate categories. Response Means and \nStandard Deviations are summarized in Table 5-71. Scale responses are shown in Figure 5-80. Table 5-71. Controller Responses to Simulation Effectiveness by Task Participant Experience Non-NCT NCT Tower IM Clearance Completion\nSample Size (n) 6 4 2 Mean (M) 95.3 61.5 96.5 Standard Deviation (SD) 7.2 29.8  IM PA Monitoring Sample Size (n) 6 4 2 Mean (M) 96.2 90.5 96.5 Standard Deviation (SD) 5.3 7.8  cvii\n Figure 5-80. The overall activity was effective as a context for evaluating the IM Clearance completion \ntask and the IM PA monitoring task. All controllers agreed the overall activity was effective as a context for evaluating the IM PA \nmonitoring task. The majority (83%) agreed the simulation was effective for the IM Clearance \ncompletion task. One NCT controller neither agreed nor disagreed and commented that Issuing \nthe clearance did not seem realistic. Another NCT controller disagreed and commented: IM \nPA initiation did not take into account how much workload the final controller is doing prior to \nissuing the instructions. --------------------------------- Finally, at the end of Day 3, controllers were asked if there was anything about the simulation \nthat artificially affected using it as a context for evaluating IM PA operations. Four (4) \ncontrollers answered Yes, seven (7) answered No, and one (1) did not provide a response. \nSelected comments included: One Yes comment: (NCT) Lack of practical scenarios in which vectoring and other \nevents are taking place.\nOne Yes comment: (TRACON) At first, too much speed control required to maintain \nseparation between pairs that took focus off IM PA functionality. It did bring to light how \neasy/noticeable the alerts were while focused on other tasks. Note: this was a Week 1 controller response. Scenarios were modified between o\nWeek 1 and Weeks 2-3 to reduce the need for this speed control. One Yes comment: (TRACON) No instant override makes some blunders and overtakes \nlook even worse because of the delay in implementing controllers instructions.\nOne Yes comment: (TRACON) I didn't feel like the aircraft speeds throughout the final \napproach were necessarily realistic. Hypothesis Evaluations6.8\nAs discussed in Section 3.3, six research questions and seven hypotheses were defined prior to cviii\n HITL data collection. This section consolidates and summarizes the findings relevant for each \nhypothesis. As needed, statistical tests were performed on the subjective questionnaire data to \ninform the hypothesis evaluation. H1(RQ1): Given an appropriate tool set, controllers will find it acceptable and 6.8.1\nfeasible to monitor IM PA operations with respect to both minimum and \nmaximum separation limits. This hypothesis was measured via responses to three questions related to monitoring comfort, \nseparation assessment, and task acceptability. The first part of the hypothesis, acceptability, \nwas measured by controller responses to the following Day 1-2 post-run (QT1) question: Given \nthe IM PA-related tools provided in this scenario, I was comfortable monitoring IM PA \noperations when both a CSL and WSL were active at the same time. As described in Section \n5.2.2, nearly all Week 2-3 TRACON controllers agreed they were comfortable monitoring IM PA \noperations with both limits at the same time for both the monitor configurations and IM PA \nTools configurations. Only one controller neither agreed nor disagreed, and this was for the \nSeparate 28R Monitor with IM PA Tools Off configuration. To determine if this resulted in a statistically significant difference between controller responses \nfor the On versus Off IM PA Tool configurations for the Separate 28R Monitor controller, a \npaired-sample T-Test analysis was run on the Week 2-3 TRACON controller agreement ratings \nfor this question. The descriptive statistics (n, M, and SD) are shown in Table 5-4. The probability \nof finding an effect when there was none, alpha (), was set to 0.05. The results of a two-tailed \nT-Test analysis failed to find statistical significance (p = 0.22). This suggests no significant \ndifference in strength of controller agreement between the two IM PA Tool configurations with \nrespect to monitoring IM PA operations when both a CSL and WSL were active at the same time. Acceptability was also measured by controller responses to the following Day 2 end (QT3) \nquestion: The tasks required of each simulation position were acceptable. As described in \nSection 5.2.5.2, nearly all TRACON controllers agreed for the positions that required IM Trail \nAircraft Monitoring (Combined and Separate 28R). One controller neither agreed nor disagreed \n(for the Combined Monitor configuration). --------------------------------- The second part of the hypothesis, feasibility, was measured by controller responses to the \nfollowing Day 2 end (QT3) question: Overall, I was confident that I could assess whether the \nseparation between the IM Trail Aircraft and their Lead Aircraft would be maintained. As \ndescribed in Section 5.2.5, the majority (80%) of TRACON controllers agreed. This self-\nassessment was supported by the objective separation analysis in Section 5.2.5.2, which found \nonly a single instance of a within-pair IM PA separation violation. Conclusion: This hypothesis is supported by the simulation results. Overall, controllers found it \nacceptable and feasible to monitor IM PA operations with respect to both minimum and \nmaximum separation limits. This did not appear to be affected by monitor configuration or IM \nPA Tools configuration. cix\n H2(RQ2): Given an appropriate tool set, controllers will find it acceptable and 6.8.2\nfeasible to provide PA separation with respect to separation values that change \nover the course of an approach. Though not asked this question directly, controllers in every scenario experienced a CSL that \nchanged in
value over the course of an approach and a WSL that initially did not apply for \ncertain aircraft (see Figure 4-6). Several questions were then related to their ability to provide \nseparation with respect to these limits. The first part of the hypothesis, acceptability, was measured by controller responses to the \nfollowing Day 1-2 post-run (QT1) question: I could easily assess whether the IM Trail Aircraft \nwould remain behind the CSL during the approach. As described in Section 5.5.3.1, All Week 2-\n3 TRACON controllers agreed for both monitor configurations and for All IM PA Tools On and All \nIM PA Tools Off. The same question was asked with respect to the WSL: I could easily assess whether the IM \nTrail Aircraft would remain forward of the WSL during the approach, when applicable. \nAlthough, as described in Section 5.5.3.2, all Week 2-3 TRACON controllers agreed for the \nCombined Monitor position with IM PA Tools On, a majority (86%) agreed for the Combined \nMonitor position with IM PA Tools Off. To examine whether there was a statistically significant difference between the CSL and WSL \nresponses for this question, a three-factor ANOVA test was performed on the Week 2-3 \nTRACON controller post-run data with respect to safety limit (CSL versus WSL), Monitor \nconfiguration (Combined versus Separate [28R]), and IM PA Tool configuration (On \nversus Off). The probability of finding an effect when there was none, alpha (), was set \nto 0.05. The descriptive statistics (n, M, and variance) for the three main factors are \nshown in Table 5-72. The ANOVA results are shown in Table 5-73. Table 5-72. Controller Responses to WSL versus CSL Assessment: Factor Summary Factor Level n M Variance\nSafety Limit CSL 28 90.9 92.7 WSL 28 77.1 662.0\nMonitor Configuration 28R 28 80.4 446.1 Combine\nd 28 87.6 379.9 IM PA Tool Configuration Tools Off 28 81.1 635.7\nTools On 28 87.0 199.0 Table 5-73. Controller Responses to WSL versus CSL Assessment: Three-Factor ANOVA Results SS df MS F p-value Significant?\nSafety Limit (A) 2646.88 1 2646.88 6.79 0.01 yes Monitor Configuration (B) 721.45 1 721.45 1.85 0.18 no\n IM PA Tool Configuration (C) 486.16 1 486.16 1.25 0.27 no cx\n A x B 111.45 1 111.45 0.29 0.60 no\nA x C 252.88 1 252.88 0.65 0.42 no\nB x C 19.45 1 19.45 0.05 0.82 no A x B x C 62.16 1 62.16 0.16 0.69 no\nWithin 18722.57 48 390.05 Total 23022.98 55 418.60 The statistical analysis results from the simulation suggest all or most controllers agreed they \ncould easily asses the IM Trail Aircraft with respect to both the CSL versus the WSL, they agreed \nmore strongly for the CSL (p = 0.01). No statistically significant differences were observed \nbetween Monitor and IM PA Tool configurations or any of the factor combinations. The unanimous agreement for the CSL suggests controller participants did not have an issue \nwith it changing over the course of the approach. However, the WSL did appear to increase the \ndifficulty of the monitoring task. Given that no significant difference was found in IM PA Tool \nconfiguration, the challenge was likely due to the CSL being displayed from the start of the \noperation versus the WSL only becoming active late in the operation. Therefore, a Pre-\nActivation feature that starts sooner than that implemented in the HITL would provide \ncontrollers more information about what to expect and therefore likely reduce the challenge of \nmonitoring with respect to the WSL. This is consistent with participant comments as reported in \nSection 5.5.3.2. --------------------------------- The second part of the hypothesis, feasibility, was measured by controller responses to the \nfollowing Day 2 end (QT3) question: Overall, I was confident that I could assess whether the \nseparation between the IM Trail Aircraft and their Lead Aircraft would be maintained. As \ndescribed in Section 5.2.5, the majority (80%) of TRACON controllers agreed. This self-\nassessment was supported by the objective separation analysis in Section 5.2.5.2, which found \nonly a single instance of a within-pair IM PA separation violation. Conclusion: This hypothesis is supported by the simulation results. Overall, controllers found it \nacceptable and feasible to provide PA separation with respect to separation values that change \nover the course of an approach, given an appropriate tool set. This did not appear to be affected \nby monitor configuration. H3(RQ3): Controllers will find a WSL Pre-Activation indication and distances to 6.8.3\nthe CSL and WSL useful, but not minimum requirements. The first part of this hypothesis was measured via responses to questions related to usefulness \nof the WSL-P and WSL Data Block W features. At the end of Day 2 (QT3) controllers were \nasked if the WSL-P was useful for the overall IM PA monitoring task. As described in Section \n5.5.3.2, all (100%) TRACON controllers agreed. In the same questionnaire, half (50%) felt the \nWSL-P should always be on and half felt that it should be user toggleable (Figure 5-69) for the \nIM PA monitoring task. Two controllers indicated in comments that aircraft type differences cxi\n would indicate an active WSL to the controller, which suggests that though helpful, the WSL-P \nmay be an optional feature. When asked in the same questionnaire if the WSL Pre-Active Indication (W) features were \nuseful for the overall IM PA monitoring task, TRACON controller responses were variable and a \nmajority (70%) of TRACON controllers disagreed it was useful, as described in Section 5.5.3.2. To determine if there was a statistically significant difference between controller responses to \nthe two display elements, a paired-sample T-Test analysis was run on the TRACON controller \nagreement ratings for the following two questions: The WSL-P was useful for the overall IM PA monitoring task.\nThe WSL Pre-Active Indication (W) features were useful for the overall IM PA \nmonitoring task. The descriptive statistics (n, M, and SD) for each question are shown in Table 5-43. The \nprobability of finding an effect when there was none, alpha (), was set to 0.05. The \nresults of the two-tailed, paired sample T-Test analysis resulted in a statistically \nsignificant p = 0.0002. This suggests a significant difference in controller agreement for \nthe usefulness of the two elements, with controllers appearing to prefer the WSL-P \ninstead of the WSL Pre-Active Indication (W) feature in the data block. --------------------------------- The second part of this hypothesis was measured via responses to questions related to \nusefulness of the CSL and WSL Data Block Distance feature. At the end of Day 2 (QT3) \ncontrollers were asked if the Data Block Distance to CSL was useful for the overall IM PA \nmonitoring task. As described in Section 5.5.3.1, all but two controllers disagreed. In the same \nquestionnaire, four of ten controllers rated it as not needed and the others suggested it should \nbe user toggleable (Figure 5-69) for the IM PA monitoring task. The same question was asked with respect to the WSL Data Block Distance feature: if the Data \nBlock Distance to WSL was useful for the overall IM PA monitoring task. As described in \nSection 5.5.3.2, all but two controllers disagreed. In the same questionnaire, four of ten \ncontrollers rated it as not needed and the others suggested it should be user toggleable (Figure \n5-69) for the IM PA monitoring task. Conclusion: This hypothesis is partially supported by the simulation results. Controllers did \nappear to find the WSL-P useful, but not a minimum requirement. However, controllers did not \nappear to find the Data Block W Indication useful. Almost all controllers also rated the Data \nBlock Distances to the CSL and WSL as not useful, at least to them. H4(RQ3): A representation of the safety limits and an alert when the IM Trail 6.8.4\nAircraft begins to encroach on the limits will be useful to Monitor controllers. The first part of this hypothesis was measured via responses to questions related to the \nusefulness of the safety limit features. As described in Section 5.5.3.1, at the end of Day 2 (QT3) \nall (100%) TRACON controllers found the CSL Line useful for the overall IM PA monitoring task. \nIn the same questionnaire, all controllers recommended that the CSL Line always be on (Figure cxii\n 5-69) for the monitoring task. The results were the same for the WSL Line, as described in \nSection 5.5.3.2 and Figure 5-69. --------------------------------- The second part of this hypothesis was measured via responses to questions related to \nusefulness of the longitudinal alerting features. Results were examined with respect to the two \nlevels of longitudinal alert presented in the HITL experiment: the Predictive Alert and the \nCaution Alert. As described in Section 4.2.7, controllers were only required to take action in \nresponse to the Caution Alert. At the end of Day 2 (QT3) controllers were asked if the IM PA Predictive Alert and IM PA \nCaution Alert features were useful for the overall IM PA monitoring task. As described in \nSection 5.5.4.1, all (100%) TRACON controllers agreed for the Caution Alert and a majority (90%) \nagreed for the Predictive Alert. In the same questionnaire, a majority of TRACON controllers \n(90%) responded that the Predictive and Caution Alerts should always be on (Figure 5-69)
for \nthe IM PA monitoring task. The other controller suggested it should be user-toggleable. To determine if there was a statistically significant difference between controller responses to \nthe two types of alerts, a paired-sample T-Test analysis was run on the TRACON controller \nagreement ratings for the following two questions: The IM PA Predictive Alert was useful for the overall IM PA monitoring task.\nThe IM PA Caution Alert was useful for the overall IM PA monitoring task. The descriptive statistics (n, M, and SD) for each question are shown in Table 5-47. The \nprobability of finding an effect when there was none, alpha (), was set to 0.05. A one-\ntailed, paired sample T-Test was used in this case as it was expected that if a difference \nwould be observed, it would only be in one direction (i.e., based on their respective \nrequired response procedures, the Predictive Alert would not be expected to be more \nuseful than the Caution Alert). The results of the one-tailed T-Test analysis resulted in a \nstatistically significant p = 0.04. This suggests a significant difference in controller \nagreement with respect to the usefulness of the two elements. Though both were found \nuseful, stronger agreement was observed with the Caution Alert. Conclusion: This hypothesis is supported by the simulation results. On average, controllers \nfound the CSL and WSL lines useful for the IM PA monitoring task and recommended that they \nalways be displayed. They also recommended that the Predictive and Caution Alerts were useful \nand should also always be active for the monitoring task, though responses were more variable \nfor the Predictive Alert than the Caution Alert. H5(RQ4): Controllers will find features such as Lateral Boundaries and an 6.8.5\nExceedance Warning useful to alert them to IM Lead Aircraft and IM Trail \nAircraft lateral path deviations. The first part of this hypothesis was measured via responses to questions related to usefulness \nof the Lateral Boundary feature. As described in Section 5.6.3, at the end of Day 2 (QT3), a \nmajority (60%) of TRACON controllers disagreed the Inner and Outer Lateral Bounds were useful cxiii\n for the overall IM PA monitoring task. As described in Section 5.5.6.1, however, the majority of \nTRACON controllers thought that the Inner Boundary should always be displayed (80%) and the \nOuter Boundary should always be displayed (70%) for the IM PA monitoring task after \nexperiencing the Lateral Deviation scenarios (Figure 5-70). The rest felt the boundaries should \nbe user toggleable. Also as described in Section 5.6.3, at the end of each Lateral Deviation scenario (QT6), \ncontrollers were asked if they could easily assess whether aircraft involved in a PA \noperation were operating within their lateral bounds in the scenario they just \nexperienced. All (100%) TRACON controllers agreed for every monitor configuration with \nthe FMA display. With the STARS display, however, a majority agreed for the Combined \nMonitor (70%), 28R Monitor (67%), and 28L Monitor (50%). To further examine if monitor configuration or display type had an effect on controller \nagreement to this question, a two-factor, repeated measures ANOVA test was \nperformed on the data summarized in Table 5-62. Due to the unbalanced sample sizes, \nthe ANOVA was performed via a regression analysis with the probability of finding an \neffect when there was none, alpha (), set to 0.05. The results are shown in Table 5-74. Table 5-74. Controller Post-Run Lateral Boundary Assessment: ANOVA Results SS df MS F p-value Significant?\nMonitor Configuration 136.8 2 68.42 0.18 0.84 no Display Type 9879.0 1 9879.01 25.79 0.00001 yes\nInteractions 145.6 2 72.80 0.19 0.83 no Within 18384.4 48 383.01\nTotal 28671.0 53 540.96 The statistical analysis results from the simulation suggest there was a significant difference \nwith respect to display Type (p < 0.01) for controller response for whether they could \nassess if aircraft involved in an IM PA operation were operating within their Lateral \nBoundaries. No difference was observed with respect to monitor configuration (p = \n0.84), nor were there any interaction effects (p = 0.83). The results suggest controllers \nfound that the FMA display aided in their Lateral Boundary assessment, but that the \nassessment was not affected by the monitor configuration. --------------------------------- The second part of this hypothesis was measured via responses to questions related to the \nusefulness of the Exceedance Warning feature. As described in Section 5.5.6.1, participants \nappeared to find the Exceedance Warning useful. As shown in Figure 5-70, all (100%) TRACON \ncontrollers felt the red LAT in the data block should always be displayed. A majority (90%) \nthought the Boundary Line color change to red should always occur. As described in Section 5.6.4, at the end of each Lateral Deviation scenario (QT6), controllers \nwere asked if they had sufficient time and situational awareness to choose and execute \nappropriate corrective action once the warning (red) alert occurred in the scenario they cxiv\n just experienced. All (100%) TRACON controllers agreed for both display types in the 28L \nposition. A majority (89%) of TRACON controllers agreed for both display types in the \n28R position. For the Combined Monitor configuration, a majority (70%) agreed for the \nSTARS display and a majority (90%) also agreed for the FMA display. Of interest as well was whether a predictive-type alert would have been helpful or essential \nfor giving controllers advance notice of a potential Lateral Boundary exceedance. To \ndetermine if there was a statistically significant difference between controller responses, \na paired-sample T-Test analysis was run on the TRACON controller agreement ratings for \ntwo separate questions asking if advance notice of an impending exceedance of the \nlateral bounds would have been helpful or essential. The descriptive statistics (n, M, \nand SD) for each question are shown in Table 5-64. The probability of finding an effect \nwhen there was none, alpha (), was set to 0.05. A one-tailed, paired-samples T-Test \nwas used in this case as it was expected that if a difference would be observed, it would \nonly be in one direction (i.e., it was unlikely that if such a predictive-type alert would be \nfound essential but not helpful). The one-tailed T-Test analysis resulted in a statistically \nsignificant p = 0.008. This suggests a significant difference in controller agreement \nresponse. Though controllers agreed for both, stronger agreement was observed for a \npredictive-type alert for lateral deviations being only helpful. Conclusion: This hypothesis is supported by the simulation results. Overall, controllers appeared \nto find the Lateral Boundaries useful, especially with the FMA display. They also found the \nExceedance Warning useful and provided sufficient time and situational awareness to choose \nand execute appropriate corrective action when needed. A predictive-type Exceedance Warning \nis likely to be more helpful than essential. H6(RQ5): Though the workload may be increased, a single, combined Monitor 6.8.6\ncontroller can effectively and acceptably provide separation for CSPR finals \ninvolving IM PA operations, including separation between successive PA pairs. The first part of this hypothesis was measured via responses to questions pertaining to \nworkload between the two monitor configurations. As described in Section 5.5.1.1, the Week 2-\n3 TRACON controllers reported low workload for all three Monitor controller positions. No \npractical workload difference was observed between the Combined and Separate Monitor \nconfigurations. As described in Section 5.4.1, after experiencing the Nominal scenarios, all Week \n2-3 TRACON controllers agreed their overall workload was acceptable for both the Combined \nand Separate Monitor configurations. A similar result was observed after the Lateral Deviation \nscenarios as the majority (90%) of TRACON controllers agreed their workload was acceptable \nacross all display types and monitor configurations (Section 5.6.1). Despite this, some workload \nconcerns were raised in the comments regarding a Combined Monitors ability to intervene with \ntwo aircraft that deviate nearly simultaneously. Overall, however, controller responses did not \nsuggest an appreciable difference in workload between the two monitor configurations. --------------------------------- The second part of this hypothesis was measured via responses to several questions regarding cxv\n the controllers ability to provide separation with respect to aircraft type and monitor \nconfiguration. First, as described in Section 5.2.6, all (100%) TRACON controllers agreed the \ntasks required of the Separate 28R and 28L Monitor positions were acceptable. In the \nCombined Monitor configuration, the majority (90%) of TRACON controllers agreed. As described in Section 5.4.3, all Week 2-3 TRACON controllers agreed they were able to detect \nin a sufficient amount of time when spacing / separation issues were developing Within an IM \nPA Aircraft Pair and Between Other Combinations for both monitor configurations. Though no \npractical differences were observed in the responses between the two monitor configurations, \nthe means were slightly higher and overall response variability was slightly lower for IM PA pairs \nversus other aircraft pair combinations. This was likely due to not having ATPA functionality \navailable in the HITL to assess separation between the non-IM PA pairs. This self-assessment for IM PA was supported by the objective separation analysis in Section \n5.2.5.2, which found only a single instance of a within-pair IM PA separation violation. With \nrespect to between-pair separation, it should first be noted ATPA functionality and data block \nweight category information (other than identifying Heavy aircraft) were not present in the \nsimulation
environment. This made the between-pair separation task more difficult than what \ncontrollers were used to, as several noted in open-ended comments. Across ten Nominal \nscenario occurrences involving between-pair separation assessments, nine involved the \nCombined Monitor configuration. However, the occurrence of the violation in these cases is \nlikely more of an artifact of the slight timing variations between the scenarios and cannot be \nconclusively attributed to monitor configuration. As described in Section 5.4.4, controllers were asked after each Day 1-2 Nominal scenario if IM \nPA operations can be effectively monitored by the number of positions they just experienced. \nAll Week 2-3 TRACON controllers agreed for both configurations, though overall response \nvariability was slightly greater for the Combined Monitor configuration. In the same \nquestionnaire, and as described in the same section, controllers were asked directly if given the \nappropriate training and IM PA-related tools, a single (Combined) Monitor controller can \neffectively ensure separation across both approaches during IM PA operations. The majority \n(90%) of TRACON controllers agreed. At the end of Day 3, after experiencing all scenarios including Lateral Deviations, controllers \nwere asked if they would expect to be able to effectively monitor any number of IM PA pairs, \nup to and including all aircraft pairs performing IM PA (100%). Though majorities of TRACON \ncontrollers agreed for both monitor configurations, higher response variability was observed for \nthe Combined Monitor. To determine if there was a statistically significant difference between \ncontroller responses for each configuration, a paired-sample T-Test analysis was run on the \nTRACON controller agreement ratings for this question. The descriptive statistics (n, M, and SD) \nare shown in Table 5-27. The probability of finding an effect when there was none, alpha (), \nwas set to 0.05. The results of the two-tailed T-Test analysis resulted in a statistically significant \np = 0.049. This suggests a significant difference in controller agreement with respect to the \nstrength of agreement between the two configurations, with controllers appearing to expect to \nbe able to more effectively monitor any number of IM PA pairs in a Separate Monitor \nconfiguration. cxvi\n Conclusion: This hypothesis is partially supported by the simulation results. First, despite some \nworkload concerns raised in the comments regarding a Combined Monitors ability to intervene \nwith two aircraft that deviate nearly simultaneously, controller responses did not suggest an \nappreciable difference in workload rating and acceptability between the two monitor \nconfigurations under nominal conditions. Second, numerous questions were related to the \neffectiveness and acceptability of a Combined Monitor controller ensuring separation across \nboth approaches during IM PA operations. Across these questions, the TRACON controllers \nalmost always agreed the Combined Monitor position was effective and acceptable. When \ncompared to responses to the Separate Monitor configuration, however, the response \nvariability tended to be higher. When analyzing separation violations between and within IM PA \npairs, no differences could be concluded with respect to monitor configuration. In addition, \nafter the Lateral Deviation scenarios, controllers more strongly agreed they would expect to be \nable to effectively monitor any number of IM PA pairs, up to and including all aircraft pairs \nperforming IM PA (100%), when working in a Separate Monitor configuration. H7(RQ6): Final controllers will find the IM PA initiation task, including the use 6.8.7\nof the Partial IM Clearance, acceptable. This hypothesis was first measured via responses to questions pertaining to 28R Final controller \nworkload. As described in Section 5.3.1, the TRACON controllers reported low workload for all \nthree Monitor controller positions. The majority (90%) of TRACON controllers then described \ntheir workload as acceptable, and in the comments some indicated that more tasks could have \nbeen handled. --------------------------------- The second part of this hypothesis was measured via responses to questions regarding the IM \ninitiation task. As described in Section 5.2.5.2, the majority (90%) agreed the tasks required of \nthe 28R Final controller position were acceptable. Also, as described in Section 5.3.2, the \nmajority (80%) of TRACON controllers on average agreed given the appropriate training, and IM \nPA-related tools, Final controllers can acceptably initiate the IM PA operation, though \nresponses were variable. The majority (90%) of TRACON controllers also agreed, that on \naverage, that they had the necessary display elements to provide the appropriate IM \nClearance information to the trail aircraft in an IM PA pair. No practical difference between the \ntwo IM PA Tool configurations were observed for these questions. However, many controllers \nindicated in open-ended comments to several questions, including those in Section 5.3.6, that \nproviding preview CSL and WSL lines before the IM Clearance needs to be sent would improve \nthe IM initiation task. The acceptability of the Partial IM Clearance procedure was measured via responses to two \nquestions regarding the acceptability of the communications, as described in Section 5.3.3. First, \nall (100%) TRACON controllers agreed it is operationally acceptable for the Final controller to \nprovide the IM PA spacing goal, though some had suggestions regarding the specific \nphraseology used. Second, controller responses were variable, but a majority (70%) agreed the \nIM PA spacing goal communication was acceptable. The controllers that disagreed provided \ncomments that suggested their disagreement had more to do with the phraseology and number cxvii\n of override transmissions than providing the Assigned Spacing Goal. Controller concerns regarding the IM PA initiation task had more to do with the available time \nand airspace to perform the task, as simulated in the HITL, versus the particular steps required \nto initiate IM PA. As described in Section 5.3.2, responses were variable to the question of once \nthe IM Trail Aircraft joined the final, I had sufficient time and airspace to initiate IM PA before \ntransferring the aircraft to the Local controller, though a majority (70%) agreed. This response \nvariability also extended to the questions of: given the appropriate training, and the IM PA-\nrelated tools I had available in this scenario, Final controllers can acceptably ensure \nseparation during IM PA operations before transferring aircraft to the Local controller. And, I \nwas comfortable that I was transferring appropriately separated aircraft to the Local \ncontroller. Though majorities of controllers agreed to both questions, several concerns and \nsuggestions were raised here, and in the open-ended comments in Section 5.3.6, regarding the \ninitiation task integration into the scenario airspace. Conclusion: This hypothesis is supported by the simulation results. Overall, controllers found the \nIM PA initiation task, including the use of the Partial IM Clearance, acceptable. However, \nconcerns were raised regarding the phraseology, available CSL and WSL information at the time \nof initiation, and the available time and airspace to perform the task as simulated. Results Summary6.9\nThis section lists and summarizes the overall findings from the HITL subjective questionnaire \ndata and objective analyses. It does not include inputs from the post-simulation debriefs held at \nthe end of Day 3. These are included as appropriate in the Section 6 discussion. Overall Acceptability and Performance6.9.1\nOn average, all or a majority of TRACON controller participants agreed: IM PA is operationally desirable. (Section 5.2.1)\nIM PA is compatible with terminal approach operations. (Section 5.2.1)\nA Final Monitor controller is the most appropriate position to monitor IM PA operations, \nthough this may depend on facility. (Section 5.2.1)\nThey were comfortable monitoring IM PA operations when both a CSL and WSL were \nactive at the same time. (Section 5.2.2 and Section 5.8.1)\nThey were comfortable allowing an IM Trail Aircraft to manage its own speed to achieve \nthe desired spacing goal at the FAF. (Section 5.2.3)\nTheir overall level of traffic awareness was acceptable with respect to all aircraft types \n(IM Lead, IM Trail, and Other Aircraft). (Section 5.2.4)\nThey were confident they could assess whether the separation between the IM Trail \nAircraft and Lead Aircraft would be maintained. (Section 5.2.5) cxviii\n The tasks required of each simulation position (Monitor and Final) were acceptable. \n(Section 5.2.5.2) An analysis of separation violations in Section 5.2.5.2 found:\nOnly a single occurrence within the IM PA pairings, which happened when a controller \nappeared to try to manually assign a speed to keep an IM Trail Aircraft behind the CSL \nand that was ultimately not effective.\nEvery observed instance of a safety limit crossing, whether or not it resulted in an IM PA \nseparation violation, occurred with the shortest alert timing values (25/15 sec).\nFive cases were observed in which an IM Trail Aircraft crossed a safety limit; however, a \ncontroller PTT click was observed between the time of the Caution Alert and the time of \nexceedance. Average controller PTT response before each exceedance was 10.8 seconds \n(SD = 3.6).\nTwelve total separation violations were observed between IM PA pairs across 42 total \nruns. Ten of the 12 involved aircraft arriving to different runways, and nine of the 12 \ninvolved a Category B aircraft in the lead. In at least half of the occurrences, an IM PA \nPredictive or Caution Alert was active on the display at the time of the separation \nviolation, which may have served as either a distraction or was determined to be a \nhigher priority. The separation violation occurrences did not appear to be significantly \ninfluenced by the IM PA Tools or monitor configuration independent variable \nmanipulations. 28R Final Position6.9.2 IM PA
Initiation Task6.9.2.1\nIn the 28R Final controller position, all or a majority of TRACON controller participants agreed \non average that: Workload was low and acceptable. (Section 5.3.1)\nFinal controllers can acceptably initiate the IM PA operation. (Section 5.3.2 and Section \n5.8.7)\nOnce the IM Trail Aircraft joined the final, they had sufficient time and airspace to \ninitiate IM PA before transferring the aircraft to the Local controller. (Section 5.3.2)\nThey had the necessary display elements to provide the appropriate IM Clearance \ninformation to the Trail Aircraft in an IM PA pair. (Section 5.3.2)\nIt is operationally acceptable for the Final controller to provide the IM PA spacing goal. \n(Section 5.3.3)\nThe IM PA spacing goal communication was acceptable. (Section 5.3.3)\nThey were comfortable with the use of the Lead Aircraft call sign in the IM Clearance \ncommunication. (Section 5.3.3) As described in Section 5.5.6.2, on average, the TRACON participants recommended the \nfollowing tools to always be on to help the Final controller complete the IM Clearance: cxix\n CSL Line\nPredictive Alert and Caution Alert\nIM PA Spacing Goal\nLead Aircraft Call Sign\nLead Aircraft Runway On average, the TRACON participants recommended the following tools either always be on or \nuser toggleable to help the Final controller complete the IM Clearance: WSL-P\nTrail Aircraft Status\nIM Status\nInner and Outer Lateral Boundaries 28R Final IM PA Monitoring Task6.9.2.2\nIn the 28R Final controller position, all or a majority of TRACON controller participants agreed \non average that: They were comfortable with the IM Trail Aircraft managing their speeds to achieve the \nspacing goal while in their area. (Section 5.3.4)\nGiven the appropriate training and tools, Final controllers can acceptably ensure \nseparation during IM PA operations before transferring aircraft to the Local controller. \n(Section 5.3.5)\nThey were comfortable that they were transferring appropriately separated aircraft to \nthe Local controller. (Section 5.3.5) Monitor Configurations6.9.3\nOn average, across both monitor configurations, all or a majority of TRACON controller \nparticipants agreed: Overall workload was low (Section 5.5.1.1) and acceptable. (Section 5.4.1)\nRoles and responsibilities were clear with respect to all aircraft in the simulation. \n(Section 5.4.2)\nThey were able to detect in a sufficient amount of time when spacing / separation issues \nwere developing within IM PA and other aircraft pairs. (Section 5.4.3)\nGiven the appropriate training and IM PA-related tools, IM PA operations can be \neffectively monitored by either configuration. (Section 5.4.4) \nGiven the appropriate training and IM PA-related tools, a single (Combined) Monitor \ncontroller can effectively ensure separation across both approaches during IM PA \noperations. (Section 5.4.4)\nThey were comfortable monitoring one aircraft in an IM PA pair, while another controller \nmonitored the other aircraft. (Section 5.4.4) cxx\n They would expect to be able to effectively monitor any number of IM PA pairs, up to \nand including all aircraft pairs performing IM PA. (Section 5.4.4) Lateral Deviation Monitoring6.9.4\nWith respect to the Lateral Deviation scenarios, all or a majority of TRACON controller \nparticipants, on average, agreed: Their workload was acceptable across all display types and monitor configurations. \n(Section 5.6.1)\nThey were confident they could assess whether separation would be maintained \nbetween the IM Trail Aircraft and their Lead aircraft. (Section 5.6.2)\nThey could easily assess whether aircraft involved in an IM PA operation were operating \nwithin their Lateral Boundaries. (Section 5.6.3). Controllers appeared to find the FMA \ndisplay (versus STARS) aided in their Lateral Boundary assessment. (Section 5.8.5)\nAdvance notice of an impending exceedance of the Lateral Boundaries would have been \nmore helpful than essential. (Section 5.6.4 and Section 5.8.5)\nThe lateral Exceedance Warning was noticeable enough such that they became aware of \nit without undue delay. (Section 5.6.4)\nThey had sufficient time and situational awareness to choose and execute appropriate \ncorrective action once the Exceedance Warning occurred. (Section 5.6.4)\nControllers responded (via a PTT click) to Lateral Boundary crossings within \napproximately 2-3 seconds, which did not appear to be affected by monitor \nconfiguration or display type. (Section 5.6.5) IM PA Tools6.9.5 General Effects6.9.5.1\nOn average, a majority of TRACON controller participants did not agree: The Monitor controller should be provided an IM Spacing List. (Section 5.5.5)\nOn average for the Day 1-2 Nominal scenarios, TRACON controller responses suggested there was no apparent difference between IM PA Tool configurations (On versus Off) \nwith respect to:\nWorkload level and acceptability. (Section 5.5.1.1)\nTraffic awareness. (Section 5.5.1.2)\nHaving sufficient time to make a first assessment of separation as the IM PA pairs \nbecame their responsibility. (Section 5.5.2)\nComfort in monitoring IM PA operations when both a CSL and WSL were active at the \nsame time. (Section 5.2.2 and Section 5.8.1)\nAbility of a single (Combined) Monitor controller to effectively ensure separation across \nboth approaches during IM PA operations. (Section 5.4.4) cxxi\n Comfort in monitoring one aircraft while another controller monitored the other. \n(Section 5.4.4)\nTimely detection of any impending exceedance of the WSL or CSL. (Section 5.5.4.2)\nTimely detection of any spacing or separation issues. (Section 5.5.4.2)\n28R Final controller Workload (Section 5.3.1) and IM PA initiation tasks. (Section 5.3.2) On average for the Day 1-2 Nominal scenarios, TRACON controller responses suggested \nthere may have been a difference between IM PA Tool configurations (On versus Off) \nwith respect to:\nIM Speed Control. As described in Section 5.5.1.3, the increased variability for the IM PA \nTools Off configuration suggests that at least for the Combined Monitor position, having \nthe IM PA Tools available may increase controller comfort with IM Trail Aircraft \nmanaging their own speeds.\nSeparation assessment between the IM Trail Aircraft and its Lead. As described in \nSection 5.5.2, the increased variability for the IM PA Tools Off configuration suggests \nthat at least for the Combined Monitor position, having the IM PA Tools available may \nhelp controllers more easily assess the separation between the IM Trail Aircraft and its \nLead.\n28R Final controller ensuring appropriately separated aircraft at handoff to the Local \ncontroller. As described in Section 5.3.5, controller responses were variable, though \nresponse variability was lower with IM PA Tools Off. It is unclear why.\nBeing able to easily tell when an aircraft would require a WSL later in the approach. As \ndescribed in Section 5.5.3.2, for the Separate 28R Monitor configuration position, a \nmajority (57%) of Week 2-3 TRACON controllers agreed they could easily tell with the IM \nPA Tools On. With IM PA Tools Off, a majority (71%) of controllers disagreed. This \ndifference was not observed for the Combined Monitor configuration. Safety Limit Depictions and WSL Pre-Active Notification Features6.9.5.2\nOn average, all or a majority of TRACON controller participants agreed: The CSL Line was useful for the overall IM PA monitoring task. (Section 5.5.3.1)\nThey could easily assess whether the IM Trail Aircraft would remain behind the CSL \nduring the approach. (Section 5.5.3.1)\nThe WSL Line was useful for the overall IM PA monitoring task. (Section 5.5.3.2)\nThey could easily assess whether the IM Trail Aircraft would remain forward of the WSL. \n(Section 5.5.3.2)\nIt was helpful to know whether an aircraft would eventually require an active WSL. \n(Section 5.5.3.2)\nThe WSL-P was useful for the overall IM PA monitoring task. (Section 5.5.3.2)\nIf provided the WSL-P, the WSL W indicator in the data block is not also needed. \n(Section 5.5.3.2) cxxii\n The WSL-P was more useful for the overall IM PA monitoring task than the WSL Pre-\nActive Indication (W) feature in the data block. (Section 5.8.3)\nThe WSL-P first appeared with sufficient lead time to be useful. (Section 5.5.3.2)\nA WSL-P should become available sooner than the 7 NM implemented in the simulation. \n(Section 5.5.3.2) On average, all or a majority of TRACON controller participants did not agree that: The Data Block Distance to the CSL was useful for the overall IM PA monitoring task. \n(Section 5.5.3.1)\nThe Data Block Distance to the WSL was useful for the overall IM PA monitoring task. \n(Section 5.5.3.2)\nThe WSL Pre-Active Indication W feature was useful for the overall IM PA monitoring \ntask. (Section 5.5.3.2)\nIf provided the initial WSL W indicator in the data block, the WSL-P is not needed. \n(Section 5.5.3.2) Longitudinal Alerting6.9.5.3\nOn average, all or a majority of TRACON controller participants agreed: They want to be able to see a situation developing versus only being provided an alert \nwhen they had to take action. (Section 5.5.4.1)\nThe IM PA Predictive Alert and IM PA Caution Alert features were useful for the overall \nIM PA monitoring task. (Section 5.5.4.1)\nControllers felt more strongly that the IM PA Caution Alert was useful for the overall IM \nPA monitoring task than the IM PA Predictive Alert. (Section 5.8.4)\nThe IM PA-related tools allowed for a timely detection of any impending exceedance of \nthe WSL or CSL. (Section 5.5.4.2)\nThe IM PA-related tools allowed for a timely detection of any spacing or separation \nissues. (Section 5.5.4.2)\nIt was helpful to indicate the Predictive Alert and Caution Alert via the data block line 3 \ncolor change. (Section 5.5.4.4)\nIt was helpful to indicate the Predictive Alert and Caution Alert via the CSL or WSL line \ncolor change. (Section 5.5.4.4) \nTheir responsibilities with respect to a Predictive Alert and Caution Alert were clear. \n(Section 5.5.4.5) When different alert timing values were tested: \nThe majority of Week 2-3 TRACON controllers agreed the Predictive (yellow) alert \nprovided sufficient advance notice of an impending Caution Alert at any of the tested \nalert timing values. (Section 5.5.4.2) \nThe majority of Week 2-3 TRACON
controllers agreed the Caution (orange) alert cxxiii\n provided sufficient advance notice of an impending loss of separation at any of the \ntested alert timing values. (Section 5.5.4.2) \nThe Week 2-3 TRACON controllers appeared to agree that they could more easily assess \nwhether the IM PA trail aircraft would remain behind the CSL during the approach for \nthe 45/24 and 35/20 values, as opposed to the 25/15 value. (Section 5.5.4.2)\nThe Week 2-3 TRACON controllers appeared to agree that they could more easily assess \nwhether the IM PA Trail Aircraft would forward of the WSL during the approach for the \n35/20 value, as opposed to the 45/24 and 25/15 values. (Section 5.5.4.2)\nThe majority of Week 2-3 TRACON controllers reported preferring a value of 35 sec for \nthe Predictive Alert with respect to both safety limits, and a 15 or 20 sec value for the \nCaution Alert. (Section 5.5.4.2)\nNo significant difference was observed between average Week 2-3 TRACON controller \nresponse times for any of the three evaluated alert timings. (Section 5.5.4.3) Display Recommendations6.9.5.4\nTable 5-75 summarizes the HITL findings associated with the various IM PA Tools provided to \nthe controllers. For each feature, it repeats the usefulness for monitoring IM PA operations as \nsummarized in prior sections, the display recommendation for that tool (e.g., Always On, User \nToggleable, Not Needed) as summarized in Figure 5-69 and Figure 5-70, and notes any related \nfindings. cxxiv\n Table 5-75. Individual Feature Display Recommendations Feature Useful for Monitoring\nDisplay Recommendation Related Findings Safety Limits\nCSL Line Agree Always On Controllers agreed they could easily assess whether the IM Trail Aircraft would remain behind the CSL during the approach. WSL Line Agree Always On Controllers agreed they could easily assess whether the IM Trail Aircraft would remain forward of the WSL during the approach. WSL-P Line Agree Always On / User Toggleable Controllers agreed it was helpful to know whether an aircraft \nwould eventually require an active WSL, and that the WSL-P was \nmore useful than the WSL (W) in the data block. Lateral Boundaries Agree Always On / User Toggleable\nController increased their display recommendation for the \nBoundaries after experiencing the Lateral Deviation scenarios. Data Block Elements\nIM Trail Aircraft Status Neutral \n User Toggleable / Not Needed Lead Aircraft Status Disagree User Toggleable / Not Needed Distance to CSL Disagree User Toggleable / Not Needed\nControllers disagreed that If the CSL is shown as a graphic line, the \nnumeric distance to it in the data block is also helpful. Distance to WSL Disagree User Toggleable / Not Needed WSL Pre-Active \nIndication (W) Disagree User Toggleable / \nNot Needed Controllers agreed the WSL-P was more useful for the overall IM \nPA monitoring task than the WSL (W) in the data block. Alerts IM PA Predictive \nAlert Agree Always On \nControllers agreed they want to be able to see a CSL or WSL \nexceedance problem developing, versus only being provided an \nalert when they have to take an action. IM PA Caution Alert Agree Always On\nControllers felt more strongly that the IM PA Caution Alert was \nuseful for the overall IM PA monitoring task than the IM PA \nPredictive Alert. Exceedance Warning: \nRed Boundary Line Not directly \nasked1 Always On Controller comments suggested that the line color change was \neffective in indicating a boundary crossing; however, it did not \nclearly identify the deviating aircraft. Exceedance Warning: \nLAT Not directly \nasked1 Always On Controllers suggested that the entire data block should turn red \nduring an exceedance, not just the LAT indication. IM Spacing List\nStatus: Eligible, Active, Terminated Neutral Varied\nControllers did not agree that the Monitor controller should be \ngiven an IM Spacing List. 1Was not included as a separate element in the questionnaire. Simulation Evaluation6.9.6\nOn average, all or a majority of TRACON controller participants agreed: The training they received was adequate, for both the IM Clearance completion and IM \nPA monitoring tasks. (Section 5.7)\nThe overall activity was effective as a context for evaluating the IM PA monitoring task. \n(Section 5.7)\nThe overall activity was effective as a context for evaluating the IM Clearance completion cxxv\n task. (Section 5.7) i\n Discussion7\nThis HITL experiment was the first to examine an update to the IM PA concept that involved \ncontrollers monitoring the operation relative to a separation standard. This requires controllers \nto be able to assess separation within an IM PA pair and take effective action before separation \nis lost. Due to IM PAs safety limits that change over time, and the close inter-aircraft pair \ndistances, it was expected that controllers would likely require new ground tools to detect and \nact on potential exceedances of the safety limits. It was also expected these tools would be \nrequired to allow controllers to provide a timely response to a lateral deviation by either the \nLead or Trail Aircraft. The primary goal of this HITL experiment therefore was to examine the updated IM PA concept \nwith a focus on the new controller monitoring functions. This included an evaluation of the \nterminal controller monitoring task for IM PA aircraft pairs established on final approach, \nespecially with respect to both minimum and maximum separation values that change over the \ncourse of the approach, and lateral deviations. Additionally, an objective was to determine the \nacceptability of a single Monitor controller to manage Lead and Trail Aircraft, or whether \nseparate monitors should be required. The experiment also included an evaluation of prototype \ndisplay features to facilitate this monitoring task. A secondary goal was to examine acceptability \nand information requirements for IM PA initiation. This section discusses the findings from the HITL reported in Section 5 in context with the \nResearch Questions and hypotheses discussed in Section 3.3 and evaluated in Section 5.8. As \nneeded, it includes experimenter observations, participants comments, and outcomes of the \npost-simulation debriefs held at the end of Day 3. IM PA Monitoring Task and Tools7.1\nThe primary objective of the HITL was to evaluate the feasibility of the IM PA ATC monitoring \ntask. The HITL assumed an operation in which a Final Approach controller would initiate the IM \nPA operation and one or two Monitor controllers would provide within-pair and between-pair \nseparation. The feasibility and acceptability for Monitor controllers to do this was examined \nwith respect to multiple metrics. General Effects. From the results, IM PA Monitoring in general appeared to be feasible and \nacceptable, which is consistent with the monitoring results reported in Domino, Tuomey, \nStassen, & Mundra (2014). After monitoring IM PA operations in the scenarios with the two \nMonitor and two IM PA Tool configurations, controllers on average reported: low and \nacceptable workload; acceptable tasks in each of the monitoring positions: acceptable levels of \ntraffic awareness for all types of aircraft; comfort in allowing the IM Trail Aircraft to manage \ntheir own speeds; and confidence that they could assess whether the separation between the \nIM Trail Aircraft and their Lead Aircraft would be maintained. They also agreed IM PA is \noperationally desirable and compatible with terminal approach operations, though real-world \nfacility and airspace integration may be challenging. Consistent with the findings of Mendolia, et \nal. (2016), most controllers reported that a Final Approach Monitor controller is the most ii\n appropriate position to provide separation for IM PA operations. However, real-world \nimplementations may ultimately depend on what is most practical for individual facilities. Separation assurance within IM PA pairs appeared to be a straightforward task for \ncontrollers as only a single violation was observed to occur between an IM Trail Aircraft \nand IM Lead Aircraft, despite the introduction of far more off-nominal deviations than \nwould be expected in actual operations. This instance involved a controller appearing to \nattempt to manually assign a speed to keep an IM Trail Aircraft behind the CSL and \nallowing the IM PA operation to continue. The controller may have then expected the \naircraft to reduce to its final approach speed; however it did not due to a simulation \nartifact. Still, the aircraft crossed the CSL before the controller commanded a break out. \nThough the controller should have terminated IM PA and commanded a break out \nsooner than what occurred, this instance was not a result of the controller failing to \nnotice a developing situation. Separation was also examined between other aircraft combinations (e.g. between the trail \naircraft of a leading pair and the lead aircraft of a following pair). Twelve total separation \nviolations were observed between aircraft pair combinations not performing IM PA. In at \nleast half of the occurrences, an IM PA Predictive or Caution Alert was active on the \ndisplay at the time of the separation violation, which may either have served as a \ndistraction or been deemed a higher priority. The observed separation violations that \noccurred between the IM PA pairs happened under varying circumstances, which makes \nit difficult to conclude that they were significantly influenced by any of the independent \nvariable manipulations. It should be noted that ATPA functionality and data block weight \ncategory information (other than identifying Heavy aircraft) were not present in the \nsimulation environment. This made the between-pair separation task more difficult than \nwhat controllers were used to, as
several noted in open-ended comments. It was \ntherefore unclear if these violations were due to the presence of IM PA in the \noperational environment or were more related to controllers in the simulation not \nhaving certain current separation tools available to them. Although these violations \noccurred in the context of simulation events that were designed to stress test the \nconcept and ground tools, their presence still suggests that tools and procedures need to \nbe fully integrated to ensure that separation between aircraft pairs not performing IM \nPA can be maintained while IM PA operations are in progress. In addition, IM PA setup \nspacing requirements should ensure that between-pair separation can be sufficiently \nmaintained during compression on final. Number of Monitor Controllers. IM PA is intended for operations in IMC and does not depend \non visual separation during the final portion of the approach. Implementing separate L/R \nMonitor controllers, as would be required by current 7110.65 rules, may not be practical or \nfeasible at certain facilities as that would then require separate Local controllers and \nfrequencies. However, facilities with dependent parallel runway operations typically employ \nseparate L/R Final Approach controllers due to the workload involved in vectoring aircraft to \nfinal and other intensive tasks. As it cannot be easily determined whether separate Monitor \ncontroller positions for IM PA would be practical for all facilities, it was necessary to examine iii\n whether a single, combined Monitor controller can effectively provide separation for CSPR finals \ninvolving IM PA operations. Todays Monitor controller workload can be relatively low as they are only required to take \naction if an aircraft penetrates the NTZ. Workload for the IM PA concept as tested in the HITL \nmay be higher, as the Monitor controllers must provide separation for all aircraft on the \napproach, including within and between IM PA pairs, and must monitor for lateral deviations. \nHowever, IM PA will likely involve alerting to tell controllers when to take action for an \nimpending loss of IM PA separation. Therefore, if vectoring to final (or managing aircraft on \nRNAV paths that connect to the final) remains the responsibility of Final Approach controllers, it \nwas hypothesized that a single Monitor controller can effectively and acceptably provide \nseparation for IM PA and non-IM PA aircraft over the course of a long final approach segment. This hypothesis was partially supported by the simulation results. First, controller responses on \naverage did not suggest an appreciable difference in workload rating and acceptability between \nthe two monitor configurations. Across both, they also agreed on average that: their tasks were \nacceptable and roles and responsibilities were clear; they were able to detect in a sufficient \namount of time when spacing / separation issues were developing within IM PA and other \naircraft pairs; and that given the appropriate training and IM PA-related tools, IM PA operations \ncan be effectively monitored by either configuration. However, when compared to responses for the Separate Monitor configuration, the response \nvariability for the Combined Monitor configuration tended to be higher. This suggests \ncontrollers may not have agreed as strongly with the various measures in the Combined \nposition versus when they were working as separate Monitors. Various open-ended comments \nsuggest that as well. Still, at least after the nominal scenarios, controllers appeared to \nsubjectively agree they could effectively provide separation when working in a Combined \nMonitor position. The Lateral Deviation scenarios illuminated a further challenge of combining the monitor \npositions. After experiencing these scenarios, controllers more strongly agreed they would \nexpect to be able to effectively monitor any number of IM PA pairs when working in a Separate \nMonitor configuration (versus Combined), up to and including all aircraft pairs performing IM PA \n(100%). Furthermore, although average controller response time to lateral deviations did not appear to \nbe different between monitor configurations, a small number of occurrences were observed in \nwhich a controller intervened with a deviating aircraft before the Exceedance Warning was \ndisplayed. Most of these occurred in the Separate Monitor configuration in the context of a \nparticular scenario that was deliberately designed as an extreme case to stress the display \nfeatures and probe for a potential failure point. This scenario involved a shallow deviation of a Trail Aircraft beginning shortly before the sharp \ndeviation of the Lead Aircraft in a different pair. However, the Exceedance Warning of the \n(shallow) Trail occurred shortly after the Exceedance Warning of the (sharp) Lead. In effect, this \nresulted in two separate, near-simultaneous lateral deviations. In the Combined Monitor \nconfiguration, the controller typically contacted the sharply-deviating Lead Aircraft first to turn iv\n it back, then contacted its Trail Aircraft to instruct it to break out. This was given higher priority \nthan the shallow-deviating Trail, and so it then crossed its Lateral Boundary and triggered the \nExceedance Alert before the controller could contact it. In the Separate Monitor configuration, \nhowever, the 28R controller was not required to contact the deviating Lead Aircraft. Therefore, \nthere was more time for the 28R controller to break out the Trail from the deviating Lead and \nthen break out the shallow-deviating Trail before it actually crossed its Lateral Boundary. The findings here, though not conclusive, are consistent with a general expectation that \ncontrollers may be able to take action more quickly when only having responsibility for one \narrival flow. This is supported by the open-ended comments, which raised concerns regarding a \nCombined Monitors workload and ability to communicate in a timely manner with two aircraft \nthat deviate nearly simultaneously. This scenario is unlikely to occur in actual operations, \nhowever. An investigation of over 1.8 million approach paths did not detect any simultaneous \nflight path deviations (Eckstein, Massimini, McNeill, & Niles, 2012), nor was there a record of \nany in an examination of 7790 go-arounds that were logged over multiple years by NCT \n(Stassen, Domino, Hefley, & Weitz, 2019). Under most conditions, results suggest a Combined Monitor controller is likely to be able to \neffectively and acceptably provide separation for IM PA and non-IM PA aircraft over the course \nof a long final approach segment. However, further study may be needed to examine whether \nseparate monitors may ultimately be required for safety to manage extreme off-nominal lateral \ndeviation situations. Longitudinal Safety Limit Monitoring. The PA separation standard assumed for the HITL was \ndefined by the minimum (CSL) and maximum (WSL) safety limits. The IM PA monitoring task was \ntherefore evaluated with respect to the acceptability of having two limits active at the same \ntime and that changed over the course of the approach. The IM PA controller monitoring task includes separation assurance within IM PA pairs and \nbetween pairs of arrivals. In these situations, controllers today must ensure that a given aircraft \nmaintains appropriate spacing from an aircraft ahead as well as an aircraft behind. And, given \nthat controllers today have experience with separation minima that can change for a given pair \nof aircraft depending on the situation, they are already used to managing some degree of \ncomplexity in applying the appropriate separation standards to pairs of aircraft. The IM PA Tools designed for, and evaluated in, the HITL experiment were intended to provide a \nclear picture of the PA separation limits applicable to a given IM PA pair at a given moment in \ntime. This information was provided in two ways: graphically and numerically. First, the CSL and \nWSL values were indicated via cyan lines on the IM Trail Aircrafts path that moved with the IM \nLead Aircrafts progression along its path. These were always available on the display, in every \nscenario. Second, the data block was able to display the IM Trail Aircrafts distances to the CSL \nand WSL, which provided controllers with a numeric indication of how much separation was \navailable to the IM Trail Aircraft with respect to each safety limit. This Data Block Distance \navailability was varied as a level of an independent variable. Though IM PA introduces a minimum and maximum separation limit with respect to a single \nleading aircraft, the task of keeping an aircraft within a forward and aft boundary was expected v\n to be a simple extension of this basic controller task. It was therefore hypothesized that \ncontrollers would find IM PA safety limit monitoring both feasible and acceptable. It was further \nhypothesized that changing PA separation limits should also be manageable as long as the \nrequired separation distance minimum is clear at any given time and the trend is generally \npredictable. These hypotheses were supported by the simulation results as controllers agreed \nthey were comfortable monitoring IM PA when both the CSL and WSL were active at the same \ntime. Controllers agreed they could easily assess whether the IM Trail Aircraft would remain \nbehind the CSL and forward of the WSL during the approach and that they were confident that \nthey could assess whether the separation between the IM Trail Aircraft and their Lead Aircraft \nwould be maintained. The strength of agreement did not appear to be affected by monitor \nconfiguration or IM PA Tools configuration, though results suggest the IM PA separation \nassessment
was easier for the CSL than the WSL. This hypothesis was further supported by the \nseparation violation analysis, in which only a single aircraft was observed to exceed one of the \nsafety limits. WSL Monitoring and Preview. Though a CSL always applies and is displayed from the start of \nthe operation through landing, the WSL requirement may depend on facility and approach \ngeometry, wake class pairings, and prevailing crosswinds. Even in conditions where a WSL is \nrequired, it may not apply until the last portion of the approach. This can complicate IM PA \nMonitoring as it reduces controller certainty with respect to: when a WSL is required for an IM \nPA Pair, where it will start to apply, and the IM Trail Aircrafts proximity to it at the time it \nbecomes active. Therefore, there is the potential for controllers to be surprised by a WSL \nsuddenly popping up on the display. Two WSL Pre-Activation display features designed to reduce this uncertainty were evaluated. \nFirst, a WSL-P was implemented to provide an advance indication of where the WSL will appear \nwhen it becomes active. It was represented by a grey line at the location where the WSL would \neventually appear and was first displayed when the IM Trail Aircraft was approximately 7 NM \nfrom the runway threshold. Second, Line 3 in the data block displayed a W with no \ncorresponding numeric value in cases where a WSL would eventually apply, but was not yet \nactive. The availability of these two features was varied as levels of an independent variable. It was hypothesized that one feature would be required by controllers, but not both. However, \nthe underlying WSL may become predictable over time and this additional display feature could \npossibly be considered display clutter by controllers. It was therefore hypothesized that one \nor both of these features may be useful, but not a minimum requirement. Controller uncertainty regarding WSL separation was reflected in various results. Though they \nusually agreed the overall separation task was acceptable with respect to both limits, they \nappeared to agree more strongly with respect to the CSL than the WSL, regardless of which IM \nPA Tools were available. Across their various responses and consistent with the hypothesis, \ncontrollers reported that the WSL-P was helpful for the overall IM PA monitoring task, but that \nthe Data Block W Indication was not. Given the increased variability in the WSL monitoring \nresponses, a WSL-P feature that starts sooner than that implemented in the HITL may reduce \nthe challenge of monitoring with respect to the WSL. The desire for an earlier WSL-P display was \nreflected in several question responses and controller comments. vi\n When deciding whether to display the WSL-P earlier in the operation, it should be considered \nthat at greater groundspeed differentials between the IM Trail Aircraft and IM Lead Aircraft, the \nWSL-P can first appear in front of the IM Trail Aircrafts current position. Then, as the IM Trail \nAircraft catches up, it crosses over the WSL-P. It is possible that this may prove confusing and \nundesirable to controllers. This case was included in the scenarios and no participant controllers \nnoted any concerns in the responses, comments, or debrief discussion. However, the earlier a \nWSL-P is displayed, the further behind it an IM Trail Aircraft may appear. This could eventually \nbecome confusing and counterproductive to the monitoring task. This is an area that would \nbenefit from further evaluation. Longitudinal Alerting. As IM PA intra-pair spacing will be smaller than what controllers are used \nto today, and because the controller will be required to take action before an IM PA Aircraft \nlongitudinally encroaches on either the WSL or CSL, it is expected that alerting will be helpful to \ncontrollers to indicate when an intervention is required. Therefore, the IM PA alerts indicated to \nthe controller when: 1) an IM Trail Aircraft was potentially at risk of encroaching on either of the \nsafety limits (IM PA Predictive Alert), and 2) when the controller must take an action (e.g., \naircraft breakout) to maintain separation (IM PA Caution Alert). The two alert types shared the \nsame logic; only the timing values were different. Based on the fielded ATPA Phase 1 alert \nimplementation, it was hypothesized that a similar IM PA two-level alerting scheme would be \nacceptable to controllers. This hypothesis is supported by the simulation results. Controllers generally found that the \nPredictive and Caution Alerts were useful for the overall IM PA monitoring task and suggested \nthey should always be active. Responses were stronger for the Caution Alert than the Predictive \nAlert. On average the controllers agreed: they wanted to be able to see a situation developing \nversus only being provided an alert when they had to take action; the IM PA-related tools \nallowed for a timely detection of any impending exceedance of the WSL or CSL or spacing or \nseparation issues; and their responsibilities with respect to a both alert types were clear. With \nrespect to display implementation, they appeared to find both the data block line 3 and \nCSL/WSL Line color changes helpful. The default Predictive / Caution alert timings were the same as those implemented for ATPA: 45 \nseconds and 24 seconds, respectively. However, reduced timings may ultimately be used to \nmitigate against nuisance alerts (which would occur more frequently with greater timings). \nTherefore, two additional alert timings were investigated in the HITL to examine whether \nsmaller values than those chosen for ATPA remain acceptable to controllers for the IM PA \nmonitoring task. These were: 35 seconds / 20 seconds and 25 seconds / 15 seconds, for the \nPredictive and Caution Alerts, respectively. The controllers found both alert types to be effective in providing sufficient advance notice \nacross all of the evaluated alert timing values and no significant difference was observed \nbetween average controller response times for any of the timings. The majority of Week \n2-3 TRACON controllers reported preferring a 35 second value for the Predictive Alert \nwith respect to both safety limits, and a 15 or 20 second value for the Caution Alert. This \nsuggests that the default ATPA alert timing value of 45/24 sec could possibly be \nacceptably decreased; however, responses also suggested that the 25/15 sec alert timing vii\n value was the most difficult for controllers to assess whether the IM PA Trail Aircraft \nwould remain behind the CSL and forward of the WSL. Further research is recommended \nin this area to optimize the balance between nuisance alerts and the time available to \ntake action once an alert is triggered. Participant discussions suggested a potentially confusing consequence from how the alerts \nwere designed to be time-based and dependent upon ground speed matching. \nDepending on the speed differences, an alert may not be displayed even if an aircraft \nwas a very short distance to the limit. Then, if there was a sudden change in the ground \nspeed differential between an IM Lead and Trail Aircraft, a Caution Alert could be \ntriggered without a preceding Predictive Alert. Though this behavior was explained to \nthe participants, it still appeared to require some experience with the operations and \nalerts to understand why an aircraft could be physically very close to a limit without a \ncorresponding alert, or to have a Caution Alert suddenly appear. Strategies for \nminimizing the potential for confusion or sudden state changes should be considered in \nthe further design of the IM PA alerting. Longitudinal Alert Response Procedures. Further discussion and open-ended comments \nsuggested that controllers desired more manual control to resolve a situation when it \nbecame clear via speed differences or a Predictive Alert that an aircraft was going to \nencroach upon a safety limit. Several controllers expressed frustration that they were \nunable to manually issue a speed to keep an IM Trail Aircraft within the limits. This was \nbecause issuing a speed to an IM Trail Aircraft terminates the FIM Equipment-generated \nspeeds, and the HITL procedure when that happened was to issue a go-around to the \ntrail. Although it is assumed that the PA separation standard will be designed to not \nrequire IM and FIM Equipment-generated IM Speeds, this HITL procedure was \nimplemented because it seemed unlikely that controllers would be willing to manually \nissue speeds to keep the aircraft within limits due to their workload and other tasking. Several controllers, however, expressed a strong desire to manually provide speeds to the \nIM Trail Aircraft when they observed a spacing situation start to develop. It was \nacceptable to them to keep the aircraft within the safety limits for the remainder of the \napproach and save a go-around. One instance was observed in which a controller \nattempted to do this, but was unsuccessful. This, and five observed instances of safety \nlimit crossings that were not counted as violations due to a PTT click before the aircraft \npassed the line, occurred with the shortest alert timing values (25/15 sec). The average \ncontroller PTT response before each crossing was 10.8 seconds (SD = 3.6). If a future PA \nseparation standard would allow controllers to manually manage Trail Aircraft speeds,
\nfurther alert timing research is recommended to examine values that would ensure \ninterventions can be successfully implemented before a safety limit is exceeded. Though not part of their training, controllers were also observed attempting to assist a \ndeteriorating IM PA operation by modifying the speed of the IM Lead Aircraft to help \nkeep the IM Trail Aircraft within the safety limits. This was at times successful and was \nobserved in both monitor configurations. When acting as Separate 28L / 28R Monitors, \nparticipants were observed to coordinate to make this happen. viii\n Further discussion during the debrief suggested that the ability for controllers to manually \nprovide speeds to assist the IM PA operation may ultimately depend on which position is \nresponsible for providing separation. A dedicated Monitor controller or a Final Approach \ncontroller could be responsible for IM PA, depending on the facility configuration. This \ncontroller would likely have enough spare capacity to manually issue speeds to keep the \nIM Trail Aircraft within the safety limits. However, with a Monitor controller / Local \ncontroller override configuration such as that tested in the HITL, significant concerns \nwere raised with the number of communications that could be required to manage \ndeteriorating IM PA operations. A Tower controller especially noted that it would be \nhighly undesirable or even dangerous for Monitor controllers to override the Local \ncontroller at even a moderate level. Even if the IM PA and the FIM Equipment proves to \nbe highly reliable in keeping the IM Trail Aircraft within the safety limits, the Monitor \ncontrollers will still need frequency time to manage between-pair spacing. Manual PA speed control may not be possible, however, if a Final controller position is \nresponsible for providing IM PA separation. Depending on the task loading and \ncommunications bandwidth, a Final controller may simply not have enough spare \ncapacity to issue speeds to resolve a deteriorating IM PA operation. There may only be \ntime to break out an IM Trail Aircraft once a Caution Alert is triggered. In this case, the \nusefulness of a Predictive Alert may be reduced and so only a Caution Alert would be \nrequired. This suggests the need for at least some of the features may be dependent \nupon the specifics of how a facility may choose to integrate IM PA into their operation \nand which controller position would be responsible for providing separation. Though \ncontrollers overall suggested they would be able and willing to provide speeds to keep \nthe aircraft within the safety limits, the practical considerations with respect to \nmanaging the required communications may make this highly challenging to implement. Finally, upon receiving a Predictive Alert, controllers were often observed to contact the IM Trail \nAircraft to confirm the status of the operation. Though allowed to do this, participants were not \ngiven specific guidance as to what to say. Controllers usually asked for verification their FIM \nEquipment was functioning. They also sometimes advised that the Trail Aircraft had a speed \novertake on the Lead Aircraft. No matter the query, the pseudopilots were instructed to \ncommunicate to the controller that their equipment appeared to be functioning properly and \nthat the operation seemed fine to them. Though appropriate for the HITL, these responses did \nnot appear to be helpful to the controllers as they did not indicate the reason for the \nPredicative Alert nor indicate whether it would transition to a Caution Alert. This controller finding was considered in a companion IM PA HITL that examined the current \noperation from the flight deck perspective (Lewis, Bone, Mendolia, & Nguyen, 2019). The study \nnoted that the FIM Equipment does not provide pilots a way to determine whether they are in \nan overtake situation or whether they are close to the CSL or WSL. Pilot participants disagreed \nthey would be able to verify a speed overtake on the lead if queried by ATC, with most citing the \nlack of ground speed as the reason. In response, the authors recommend that flight crew display \nfeatures continue to be developed to give relevant information to the crew about the progress \nof the IM PA operation such that they can answer ATC queries. As this may or may not prove ix\n sufficient depending on the nature of the controller query, further consideration is \nrecommended for controller and pilot coordination actions and information transfer when the \nIM PA operation appears likely to require a breakout. Lateral Monitoring and Alerting. The CSL and WSL were designed to accommodate some \namount of normal aircraft crosstrack error from the approach path centerline. If either aircraft \nexceeded that amount in either direction (left or right), then it was assumed PA separation \nwould no longer be valid. To indicate to controllers when deviations exceeded the CSL and WSL \nassumptions, Lateral Boundaries, and an associated Exceedance Warning based on current-day \nNTZ alerting, were implemented and evaluated as display features. With respect to the Lateral Deviation scenarios, on average controller participants agreed their \nworkload was acceptable across all display types and monitor configurations and that they were \nconfident they could assess whether separation would be maintained between the IM Trail \nAircraft and their Lead aircraft. They also on average agreed they could easily assess whether \naircraft involved in a PA operation were operating within their Lateral Boundaries and the FMA \ndisplay (versus STARS) appeared to aid in their Lateral Boundary assessment. Controllers on \naverage suggested that advance notice of an impending exceedance of the lateral bounds would \nhave been more helpful than essential, but noted during the discussion that a lateral predictive-\ntype alert may only be practical on an FMA display. Current STARS display features such as PTL \nlines and separation bats (cones) appeared to provide an immediate and salient visual cue \nwhen aircraft ground tracks began to diverge from the approach course. With respect to the lateral Exceedance Warning (red LAT in data block line 0 and Lateral \nBoundary Line color change), controllers agreed on average that it was noticeable enough such \nthat they became aware of it without undue delay. They also agreed on average that they had \nsufficient time and situational awareness to choose and execute appropriate corrective action \nonce the Exceedance Warning occurred. Controllers responded (via a PTT click) to Lateral \nBoundary crossings on average within 2.4 sec (SD=1.2) when working as a Combined Monitor, \nand within approximately 2.1 seconds (SD=1.3) when working as Separate Monitors. These \nresponse times did not appear to be affected by monitor configuration or display type. The \naverages observed in the current HITL are less than the average 4.3 sec (SD=2.7) for qualified \ncontroller response times observed in Cox, Yates, & Savage (2011). It is unclear from the report, \nhowever, the degree to which the experimental conditions were similar. In comments and the debrief discussion, some controllers recommended that the Exceedance \nWarning should be more salient in identifying the deviating aircraft than what was simulated. \nSeveral controllers suggested changing the color of the entire data block instead of only \ndisplaying the red LAT indicator in line 0. Controller comments also suggested that the line \ncolor change was effective in indicating a boundary crossing; however, it did not clearly identify \nthe deviating aircraft. During the debrief discussions, a suggestion was made to consider \nchanging the color only of a line segment in proximity to the deviating aircraft. Overall, it appeared that given the appropriate tools and training, the IM PA lateral separation \nmonitoring task appeared feasible and acceptable to controllers. Though the FMA display was \nfound to significantly aid in the Lateral Boundary assessment, responses did not appear to x\n suggest it should be a minimum requirement. And, as discussed earlier in this section, controller \nresponses indicated that a Combined Monitor position may preclude timely communications \nwith aircraft in the (highly unlikely) event of a simultaneous deviation of two or more aircraft. \nFurther study is recommended to examine whether separate monitors may ultimately be \nrequired to safely manage extreme off-nominal lateral deviation situations. IM PA Initiation Task and Tools7.2\nThe second major HITL objective was to evaluate the IM PA initiation task, especially with \nrespect to Partial IM Clearance procedures. The initial positioning of the aircraft in the arrival \nstream was therefore assumed to have been accomplished at the start of each scenario, before \nthe aircraft arrived in the participant controllers airspace. The HITL used RNAV routes to ensure \nthat aircraft were delivered to the final approach courses in a consistent, reproducible manner. \nThese procedures were developed for the HITL and are not currently in place at SFO. However, \nthey may approximate procedures for a future metering environment. Aircraft were handed off to the final controller when they were on a modified base leg, \napproximately 25 NM from the runway, with the desired initial spacing, and separated in \naltitude by 1000 ft. The HITL assumed that a Feeder Controller had first informed the candidate \nIM Trail Aircraft of the planned IM PA operation, providing the IM Clearance Type (IM PA) and \nIM Lead Aircraft Flight Identification. Using the IM Spacing List and IM information in the \ncandidate Trail
Aircrafts data block, the Final Approach controller provided the IM Trail Aircraft \nits Assigned Spacing Goal once it and its lead were established on the final approach course. \nThis initiated the IM PA operation and the Final Approach controllers then cleared the aircraft \nfor their approaches and instructed the aircraft to change to the Local controller frequency. \nFinal Approach controllers were responsible for providing IM PA separation for the short \nduration of time between IM PA initiation and the aircraft change to the Local controller \nfrequency. Monitor controllers then monitored separation with respect to the CSL and WSL (if \napplicable) until the IM Lead Aircraft crossed its runway threshold. Previous research such as Mendolia, et al. (2016) examined the use of an expect message to \nprovide IM Clearance information before the operation was intended to begin. Controller \nresults suggested that clearance formulation in this manner was acceptable and during further \nconcept development, was modified to the use of a Partial IM Clearance. The feasibility and \nacceptability for Final Approach controllers to do this was examined with respect to multiple \nmetrics. As the intent was the same and the sequence of communications and information \ntransfers was similar to prior work involving expect, it was hypothesized that Final controllers \nwould find the IM initiation task, including the use of Partial IM Clearance procedures, \nacceptable. In the 28R Final controller position, controller participants on average agreed: Final controllers \ncan acceptably initiate the IM PA operation and that their workload was low and acceptable. \nThey also agreed on average that they were comfortable with the IM Trail Aircraft managing \ntheir speeds to achieve the spacing goal while in their area, and that given the appropriate \ntraining and tools, Final controllers can acceptably ensure separation during IM PA operations xi\n before transferring aircraft to the Local controller. However, concerns were raised regarding the \nphraseology, available CSL and WSL information at the time of initiation, and the available time \nand airspace to perform the initiation task as simulated. Each of these concerns is discussed \nnext. Communications. On average, controllers agreed it is operationally acceptable for the Final \ncontroller to provide the IM PA spacing goal and that the IM PA spacing goal communication \nwas acceptable. This suggests that the Partial IM Clearance procedures were acceptable to the \nFinal controllers, though further research is recommended to examine Feeder controller \nacceptability to provide the first part of the clearance. In a companion IM PA flight deck features \nevaluation performed recently, pilots found these Partial IM Clearance procedures acceptable \n(Lewis, Bone, Mendolia, & Nguyen, 2019). However, less than half of the pilots agreed it was \nnecessary to split the clearance information into two messages. Domino, Tuomey, Stassen, & Mundra (2014) found IM PA initiation communications acceptable, \nincluding the use of Expect to convey PA-related information early. In that HITL simulation, \nhowever, the IM Clearance was conveyed with the IM PA 28R approach clearance and did not \nrequire a separate communication. Controllers were required to provide the Lead Aircrafts \nPFAS to the Trail Aircraft, which was not part of the IM PA initiation procedure for the \nevaluation being reported on in this document. In the current simulation, the IM PA operation was initiated via a separate clearance and \nfindings were consistent with the similar procedure used in Mendolia, et al. (2016). Though the \nIM initiation procedure was generally acceptable, several comments in both evaluations noted \nthe IM Clearance phraseology and procedures could be improved and streamlined, and some \nspecific suggestions were made. In the current evaluation, one suggestion was the word Goal \nshould be replaced with your interval spacing. Another suggestion was the Final controller \nshould not have to repeat the IM Lead Aircrafts flight ID when providing the Assigned Spacing \nGoal. Some controllers were observed to combine the Assigned Spacing Goal transmission with \nthe approach clearance. The main concern about the communications appeared to be related to \nthe number of required transmissions on the override frequency. This would be an important \nconsideration for IM PA implementation at a facility, as discussed in Section 6.1. Finally, \ncontrollers in both HITLs on average agreed they were comfortable with the use of the Lead \nAircraft flight ID in the IM Clearance communication. IM PA Initiation Information. On average controllers agreed they had the necessary display \nelements to provide the appropriate IM Clearance information to the trail aircraft in an IM PA \npair. However, many controllers commented on the need for more predictive information, \nearlier. The simulation procedure required the Final controller to first issue the IM Clearance \nand then receive acknowledgement from the IM Trail Aircraft before accepting the proposed \nclearance in the IM Spacing List and activating the IM PA display features. This was designed to \nreduce the potential for controllers to accept the clearance in the automation, but potentially \nget distracted and fail to follow up and actually issue the IM Clearance to the Trail Aircraft. This \nwould result in a situation where the automation is displaying an IM PA operation was being \nperformed, when in reality the candidate IM Trail Aircraft is not following IM Speeds to manage \nits spacing. xii\n In the simulation, however, controllers expressed concerns this procedure did not allow them to \nknow the IM Trail Aircrafts proximity to the safety limits before issuing the IM Clearance. This \nwas exemplified by a scenario event in which a candidate IM Trail Aircraft was ahead of its CSL \nat the time of initiation. This was not displayed to the Final controllers, so they received a \nCaution Alert as soon as they accepted the IM Clearance in the IM Spacing List and then \nimmediately had to terminate. To avoid this, controllers suggested adding a CSL Preview line \non the display to indicate where the IM Trail Aircraft was relative to the CSL before controllers \nneeded to provide the IM Clearance. This would enable a Tower controllers request for the \nability to adjust speeds prior to the start of IM PA to increase the probability of the Trail Aircraft \nachieving its spacing. The suggestion was also made for a WSL-P to be displayed before \ninitiation; however, this may prove confusing and counterproductive as discussed in Section 6.1. Initiation Time. On average controllers agreed once the IM Trail Aircraft joined the final, they \nhad sufficient time and airspace to initiate IM PA before transferring the aircraft to the Local \ncontroller. However, comments and discussion suggested this portion of the operation could be \nimproved over what was implemented in the simulation. One controller suggested a Final \ncontroller should have more airspace to adjust the initial spacing if needed. This controller \nagreed with another controller who suggested a fix with an above crossing altitude. This would \nallow the Final controller to clear for the approach, then assign the spacing goal once \nestablished on final. The participant suggested this would make the timing less critical. Another \ncomment suggested they could better ensure they were transferring appropriately separated \naircraft to the Local controller if the IM Trail was in their area for a longer period following \ninitiation. i\n Conclusions and Recommendations8\nSummary of Conclusions8.1 The FAA, NASA, MITRE CAASD, and others have been conducting research on various aspects of \nPA for over two decades. In 2016, RTCA SC-186 WG 4 decided to make PA an IM application and \ninclude it in the updated FIM Equipment requirements. Through this process, stakeholders \ndetermined controllers must be able to monitor the operation relative to a separation standard. \nThis requires controllers to be able to assess separation within an IM PA pair and take effective \naction before separation is lost. Therefore, the IM PA concept was changed to move the safety \nlimit monitoring function from being a flight crew responsibility and FIM Equipment capability \nto a ground capability. Sponsored by the FAAs SBS Program Office, MITRE CAASD developed and executed a HITL \nexperiment to validate IM PA concept changes, address open controller acceptability and \nfeasibility questions, provide input to air and ground system requirements, and mitigate \ntechnical risks associated with the revised PA concept. The primary goal of this HITL simulation \nwas to examine new controller monitoring functions. This included an evaluation of the \nterminal controller monitoring task for IM PA aircraft pairs established on final approach, \nespecially with respect to both minimum and maximum separation values that change over the \ncourse of the approach, and lateral deviations. Additionally, it examined the acceptability of a \nsingle monitor controller to manage Lead and Trail Aircraft, or whether separate monitors \nshould be required. The experiment also included an evaluation of prototype display features to \nfacilitate this monitoring task. A secondary goal was to examine acceptability and information \nrequirements for IM PA initiation. After initiating and monitoring IM PA operations with varying supporting IM PA (display) Tool \nconfigurations, monitor configurations, and off-nominal deviations, results suggest given the \nappropriate tools and training, the IM PA longitudinal and lateral separation monitoring task \nshould be feasible and acceptable to controllers. IM PA pair-wise separation assurance \nappeared to be a straightforward task for controllers as only a
single violation was observed \nwithin an IM Trail Aircraft and IM Lead Aircraft pairing, despite the introduction of far more off-\nnominal deviations than would be expected in actual operations. This instance involved a \ncontroller appearing to attempt to manually assign a speed to keep an IM Trail Aircraft behind \nthe CSL and allowing the IM PA operation to continue. It was not a result of the controller failing \nto notice a developing situation. Separation was also examined between other aircraft combinations (e.g. between the trail \naircraft of a leading pair and the lead aircraft of a following pair). Twelve total instances of \nseparation violations were observed between aircraft pairs not performing IM PA. It was unclear \nif this was due to the presence of IM PA in the operational environment or was related to \ncontrollers in the simulation not having current separation tools such as ATPA available to them. \nAlthough these violations occurred in the context of simulation events that were designed to \nstress test the concept and ground tools, their presence still suggests that tools and procedures ii\n need to be fully integrated to ensure that separation between aircraft pairs not performing IM \nPA can be maintained while IM PA operations are in progress. In addition, IM PA setup spacing \nrequirements should ensure that between-pair separation can be sufficiently maintained during \ncompression on final. Controller participants on average reported: low and acceptable workload; acceptable tasks in \neach of the monitoring positions; acceptable levels of traffic awareness for all types of aircraft; \ncomfort in allowing the IM Trail Aircraft to manage their own speeds; and confidence they could \nassess whether the separation between the IM Trail Aircraft and Lead Aircraft would be \nmaintained. They also agreed IM PA is operationally desirable and compatible with terminal \napproach operations, though real-world facility and airspace integration may be challenging. \nController participants appeared to be comfortable monitoring IM PA when safety limits that \nchanged over the course of an approach were both active at the same time. Facilities with dependent parallel runway operations typically employ separate L/R Final \nApproach controllers due to the workload involved in vectoring aircraft to final and other \nintensive tasks. Implementing separate L/R Monitor controllers, as would be required by current \n7110.65X rules, may not be practical or feasible at SFO since that would also require separate \nLocal controllers and frequencies, one for each arrival runway. It was therefore of interest to \nexamine whether a single, combined Monitor controller can effectively provide separation for \nCSPR finals involving IM PA operations. Results suggest under nominal conditions, a single, \nCombined Monitor controller is likely to be able to effectively and acceptably provide \nseparation within and between IM PA pairs. However, further study is recommended to \nexamine whether separate monitors may ultimately be required for safety to manage extreme \noff-nominal lateral deviation situations. With respect to the IM PA-related display features and tools introduced for the simulation, the \ngraphic depictions of the CSL and WSL were found useful for the overall monitoring task and \ncontrollers recommended they always be displayed. As the WSL only became active late in the \napproach, controllers found the WSL-P tool helpful in indicating whether an aircraft would \neventually require a WSL and the IM Trail Aircrafts current proximity to it. Half of the TRACON \ncontroller participants felt the WSL-P should always be on and half felt it should be user \ntoggleable. Controllers also suggested the WSL-P should be displayed earlier than what was \nimplemented in the HITL. Controllers on average agreed the IM PA Predictive and Caution Alerts \nwere both were useful, though they agreed more strongly for the Caution Alert. They also \nsuggested the alert timing could be reduced from what was implemented for ATPA. The data \nblock line 3 features, including the current numeric distance to each safety limit, along with a \nW indicating a future WSL, were not found to be useful. The lateral monitoring task appeared feasible and acceptable to controllers, given the \nappropriate tools and training. Current STARS display features such as PTLs and separation \nbats (cones) appeared to provide an immediate and salient visual cue when aircraft ground \ntracks began to diverge from the approach course. Controllers appeared to find the Lateral \nBoundaries useful, especially with the FMA display. Though the FMA display was found to \nsignificantly aid in the Lateral Boundary assessment, responses did not appear to suggest it \nshould be a minimum requirement. Controllers also found the Exceedance Warning useful and iii\n provided sufficient time and situational awareness to choose and execute appropriate \ncorrective action when needed. It could, however, possibly be made more salient by changing \nthe color of the entire data block of the deviating aircraft, plus changing the color of only a \nboundary line segment near to the deviation instead of changing the color of the entire line. On \naverage controllers also suggested a predictive-type Exceedance Warning may be helpful, but \nnot essential. Most controllers reported a Final Monitor controller is the most appropriate position to monitor \nIM PA operations, though this may ultimately depend on the facility. They also expressed a \nstrong desire to manually provide speeds to the IM Trail Aircraft when they observed a spacing \nsituation start to develop. The ability for controllers to manually provide speeds to assist the IM \nPA operation may ultimately depend on which position is responsible for providing separation. \nA dedicated Monitor controller or a Final Approach controller could be responsible for IM PA, \ndepending on the facility configuration. This controller would likely have enough spare capacity \nto manually issues speeds to keep the IM Trail aircraft within the safety limits. However, with a \nMonitor controller / Local controller override configuration such as that tested in the \nsimulation, significant concerns were raised with the number of communications that could be \nrequired to manage deteriorating IM PA operations. Even if the IM PA and the FIM Equipment \nproves to be highly reliable in keeping the IM Trail Aircraft within the safety limits, the Monitor \ncontrollers will still need frequency time to manage between-pair spacing. Manual PA speed control may not be possible, however, if a Final Approach controller position \nis responsible for providing IM PA separation. Depending on the task loading and \ncommunications bandwidth, a Final controller may simply not have enough spare capacity to \nissue speeds to resolve a deteriorating IM PA operation. There may only be time to break out an \nIM Trail Aircraft once a Caution Alert is triggered. In this case, the usefulness of a Predictive \nAlert may be reduced and so only a Caution Alert would be required. This suggests the need for \nat least some of the features may be dependent upon the specifics of how a facility may choose \nto integrate IM PA into their operation and which controller position would be responsible for \nproviding separation. Though controllers overall suggested they would be able and willing to \nprovide speeds to keep the aircraft within the safety limits, the practical considerations with \nrespect to managing the required communications may make this highly challenging to \nimplement. The second major HITL objective was to evaluate the IM PA initiation task, especially with \nrespect to Partial IM Clearance procedures. Controller participants on average agreed Final \ncontrollers can acceptably initiate the IM PA operation and given the appropriate training and \ntools, can acceptably ensure separation during IM PA operations before transferring aircraft to \nthe Local controller. They also agreed they were comfortable with the IM Trail Aircraft \nmanaging their speeds to achieve the spacing goal while in their area. The information \ncontained in the IM Spacing List appeared useful for the IM PA initiation task. Concerns were raised regarding the phraseology, available CSL and WSL information at the time \nof initiation, and the available time and airspace to perform the initiation task as simulated. On \naverage, controllers agreed it is operationally acceptable for the Final controller to provide the \nIM PA spacing goal and the IM PA spacing goal communication was acceptable. This suggests iv\n the Partial IM Clearance procedures were acceptable to the Final controllers, though further \nresearch is recommended to examine Feeder controller acceptability to provide the first part of \nthe clearance. It was recommended, however, the IM Clearance phraseology and procedures \ncould be improved over what was used. Controllers also suggested adding a CSL Preview line \non the display to indicate where the IM Trail Aircraft was relative to the CSL before controllers \nneeded to provide the IM Clearance. This would avoid IM PA initiations with aircraft not in the \ncorrect positions. Finally, although controllers had sufficient time and airspace to initiate IM PA \nbefore transferring the aircraft to the Local controller, they suggested more airspace would \nhave been desirable to adjust the initial spacing if needed and reduce the criticality of the \ntiming. Overall results suggest given the appropriate tools and training, the IM PA longitudinal and \nlateral separation monitoring and initiation tasks should be acceptable to controllers. In a \nrelated IM PA flight deck features evaluation performed in 2018, pilots also found IM
PA to be \ngenerally acceptable, even after experiencing significant lateral deviations by the Lead Aircraft. \nThe current IM PA concept appears feasible and MITRE CAASD recommends the FAA continue \nits development. This study provided initial findings on the initiation of and monitoring of an IM PA operation \nbased on its current ConOps (FAA, 2017b). The results are intended to provide concept \nvalidation for the avionics standard development activities and A-IM ConOps, as well as specific \nrecommendations for the FAA IM Initial Program Requirements document with respect to \ncontroller information needs and supporting ground tools. These results and recommendations \nshould be considered by RTCA SC-186, FAA SBS Program Office, FAA Aircraft Certification, and \nFAA Flight Standards as IM PA proceeds through concept development. Summary of Recommendations8.2\nBased on the results of the HITL experiment, the following 11 recommendations should be \nconsidered in the further development of the IM PA concept and air and ground requirements: Concept development should continue based on results suggesting the IM PA 1.\nlongitudinal and lateral separation monitoring and initiation tasks should be feasible and \nacceptable to controllers given the appropriate tools and training. Final Approach controllers should have an indication of how close the IM Trail Aircraft is 2.\nto the safety limits before they initiate the IM PA operation. This could be in the form of \na preview CSL Line. Further study is recommended as to what may be helpful for wake \nprotection information. IM PA setup spacing requirements should ensure that between-pair separation can be 3.\nsufficiently maintained during compression on final. A single Final Monitor controller is likely to be able to monitor across both approaches 4.\nunder nominal operations. However, further study is needed to examine whether \nseparate Monitor controllers will be required for safety to manage extreme off-nominal \nsituations. v\n Graphic depictions of the CSL and WSL lines should be considered, as opposed to 5.\nnumeric distances in the data blocks. A WSL-P for relevant aircraft should be considered, appearing as early as possible. 6.\nFurther study is recommended to determine at what point this may prove confusing and \ncounterproductive. An alert should be provided for longitudinal monitoring task to indicate when a 7.\ncontroller must take action to stop an aircraft from exceeding a safety limit. The need for \na situation awareness alert that does not require action may depend on the facility \nimplementation and what controllers are able to do in response. Further study is \nrecommended to optimize the balance between the potential for nuisance alerts and \nthe time available to take action once an alert is triggered. Strategies for minimizing the \npotential for sudden state changes should also be considered. For the lateral monitoring task, controllers should be provided an indication for where 8.\nan aircrafts crosstrack error may result in the CSL and WSL no longer providing the \nrequired protection from collision or wake risk. The use of a 4:1 FMA display should be \nconsidered to aid in the controllers lateral deviation assessment. Further examination of the monitoring task and response procedures is recommended 9.\nfor lateral deviations close to the runway (i.e. past the Lateral Bounds). Controllers should be provided with an alert or warning for when PA separation may no 10.\nlonger apply due to a lateral deviation by the IM Lead or Trail Aircraft. Its saliency may \nbe improved by changing the color of the entire data block of the deviating aircraft and \nchanging the color of a boundary line segment near to the deviation instead of changing \nthe color of the entire line. Ground tools and procedures need to be fully integrated to ensure that separation 11.\nbetween aircraft pairs not performing IM PA can be maintained while IM PA operations \nare in progress. A Final Approach controller or a Monitor controller could be responsible for IM PA, 12.\ndepending on the facility configuration and further research is recommended with \nrespect to allowing controllers to manually provide speeds to keep an IM Trail Aircraft \nwithin the safety limits if the FIM Equipment fails. This must be balanced with the \npotential for undesirable frequency overrides and workload. Further consideration is recommended for controller and pilot coordination actions and 13.\ninformation transfer when the IM PA operation appears likely to require an aircraft \nbreak out. i\n References9\nBarmore, B. E., Penhallegon, W. J., Weitz, L. A., Bone, R. S., Levitt, I., Flores-Kriegsfeld, J. A., . . . & Johnson, C. (2016). Interval Management: Development and Implementation of an \nAirborne Spacing Concept. Proceedings of the American Institute of Aeronautics and \nAstronautics Aviation Science and Technology Forum and Exposition (AIAA SciTech). San \nDiego, CA. Bateman, B., Domino, D. A., Hefley, S., Lascara, B., Mundra, A., Nguyen, Q., . . . & Weitz, L. A. \n(2017). Evolutionary Approach to the Implementation of Paired Approach Operations: \nMP170980. McLean, VA: The MITRE Corporation. Bone, R. S., & Mendolia, A. S. (2018). Pilot and Air Traffic Controller use of Interval Management \nduring Terminal Metering Operations. MTR170570. McLean, VA: The MITRE Corporation. Bone, R. S., Mundra, A., & Olmos, O. (2001). Paired Approach Operational Concept. Proceedings \nof the 2001 Institute of Electrical and Electronics Engineers (IEEE)/AIAA 20th Digital \nAvionics Systems Conference (DASC). Daytona, Beach, FL. Cox, G., Yates, J., & Savage, J. (2011). Controller Response Times from the August and December \n2010 Human in the Loop Data Collection Efforts. DOT-FAA-AFS-450-68. Oklahoma City, \nOK: Federal Aviation Administration Flight Systems Laboratory. Domino, D. A., Tuomey, D., Stassen, H. P., & Mundra, A. (2014). Paired Approaches to Closely \nSpaced Runways: Results of Pilot and ATC Simulation. Proceedings of the 33rd Digital \nAvionics Systems Conference. Colorado Springs, CO. Eckstein, A. C., Massimini, S. V., McNeill, G. C., & Niles, F. A. (2012). Frequency and Severity of \nDeviations during Simultaneous Independent Approaches to Parallel Runways 2008 \n2012. MP120414. McLean, VA: The MITRE Corporation. FAA. (2016). Wake Turbulence Recategorization: JO 7110.659C. Washington DC: Federal \nAviation Administration. FAA. (2017a). Air Traffic Control: JO 7110.65X. Washington DC: Federal Aviation Administration. FAA. (2017b). Surveillance and Broadcast Services Program Office Concept of Operations for ADS-\nB In Advanced Interval Management. Rev 1. Washington DC: Federal Aviation \nAdministration. FAA. (2018a). ADS-B In Application Business Case (Presentation to Equip 2020 Working Group). \nWashington DC: Federal Aviation Administration. FAA. (2018b). Simultaneous Dependent Approaches to Closely Spaced Parallel Runways: JO \n7110.308C. Washington DC: Federal Aviation Administration. ii\n FAA. (2018c). United States Standard for Terminal Instrument Procedures (TERPS): Order \n8260.3D. Washington DC: Federal Aviation Administration. Lewis, B. A., Bone, R., Mendolia, A. S., & Nguyen, Q. A. (2019). Pilot Conduct of a Relative \nSpacing Task during Closely Spaced Parallel Runway Operations Interval Management \nPaired Approach Human-in-the-Loop Experiment. MTR190106. McLean, VA: The MITRE \nCorporation. Mendolia, A. S., Domino, D. A., Eftekari, R. R., Hefley, S. A., Stassen, H. P., & Mundra, A. D. \n(2016). Paired Approach Safety Analysis Inputs: Results from an Air Traffic Control \nHuman-In-The-Loop Evaluation of Advanced Interval Management Paired Approach \nNominal and Non-Nominal Procedures. MTR160015. McLean, VA: The MITRE \nCorporation. Penhallegon, W. J., & Stassen, H. P. (2018). Concept of Operations for Advanced Interval \nManagement Applications in an Arrival Metering Environment. Proceedings of the 37th \nDigital Avionics Systems Conference (DASC). London, England, UK. Penhallegon, W. J., Stassen, H. P., Elliott, D., & Gryphon, C. (2016). A-IM Dependent Staggered \nArrival (DSA) Setup Considerations and Benefits: WP 302-05. In MITRE Selected \nAdvanced Interval Management Working Papers Submitted to RTCA SC-186 Working \nGroup 4. MP160410 (pp. 27-76). McLean, VA: The MITRE Corporation. Roscoe, A. H., & Ellis, G. A. (1990). A Subjective Rating Scale for Assessing Pilot Workload in \nFlight: A Decade of Practical Use. TR 90019. Farnborough, England: Royal Aerospace \nEstablishment. RTCA. (2015). Safety, performance, and interoperability requirements document for Airborne \nSpacing Flight Deck Interval Management (ASPA-FIM) (DO-328A). Washington, DC: \nRTCA. RTCA. (2019a). DO-328B (DRAFT): Safety, Performance, and Interoperability Requirements \nDocument for Airborne Spacing Flight-deck Interval Management. Washington DC: \nPrepared by SC-186. RTCA. (2019b). DO-361A: (DRAFT) Minimum Operational Performance Standards for Flight-deck \nInterval Management. Washington DC: Prepared by SC-186. Stassen, H. P., Domino, D. A., Hefley, S., & Weitz, L. A. (2019). Success Rate Objective for Paired \nApproach Operations. MP190176. McLean, VA: The MITRE Corporation. Stassen, H. P., Eftekari, R. R., Mundra, A. D., Domino, D. A., Haltli, B. M., Koch, M. E., . . . & \nTuomey, D. M. (2013). Paired Approach Concept of Operations: Coordination Draft v1.0 \n(MP130081). McLean, VA: The MITRE Corporation. iii\n Stassen, H. P., Haltli, B. M., Lascara, B. J., Nguyen, Q. A., Penhallegon, W. J., Priess, S. A., & Weitz, \nL. A. (2017). Methodologies for the Assessment of the Feasibility and Availability of \nPaired Approach Operations. MP170649. McLean, VA: The MITRE Corporation. Stassen, H. P., Priess, S., & Weitz, L. A. (2016). Modeling Uncertainty in Inter-aircraft Spacing \nBetween the Final Approach Fix and the Runway Threshold. Proceedings of the American \nInstitute of Aeronautics and Astronautics Aviation Science and Technology Forum and \nExposition (AIAA SciTech). San Diego, CA. Williams, M., & Wood, L. (2017). Front-Gate Collision Safety Limit Analysis for Paired Approach \nConcept: SC-186 WP306-08. Washington, DC: RTCA Inc. i\n Abbreviations and AcronymsAppendix A Term Definition A/C or a/c Aircraft AAL American Airlines ABP Achieve-By Point ADS-B Automatic
Dependent Surveillance-Broadcast AFS Flight Standards Service AFS-450 Flight Standards Services, Flight Technologies Division, Flight Systems Lab AIAA American Institute of Aeronautics and Astronautics A-IM Advanced Interval Management AJM (FAA) Surveillance Services Directorate AJV-7 (FAA) Mission Support Services ANG-C (FAA) Next Generation Air Transportation System Portfolio Management & \nTechnology Development Office ANOVA Analysis of Variance ASG Assigned Spacing Goal ASPA-FIM Airborne Spacing Flight Deck Interval Management ATC Air Traffic Control ATPA Automated Terminal Proximity Alert BOS Boston Logan International Airport CAASD Center for Advanced Aviation System Development CAT Category CLE Cleveland Hopkins International Airport Conf Confederate ConOps Concept of Operations CPDLC Controller Pilot Data Link Communications CRJ Canadair Regional Jet CSL Collision Safety Limit CSPO Closely Spaced Parallel Operations CSPR Closely Spaced Parallel Runways ii\n DAL Delta Air Lines DASC Digital Avionics Systems Conference DB Data Block df Degrees of Freedom DSA Dependent Staggered Approaches e.g. for example EWR Newark Liberty International Airport EZ Early Zone F Fisher statistic FAA Federal Aviation Administration FAF Final Approach Fix FIM Flight deck-based Interval Management FMA Final Monitor Aid ft feet HITL Human-in-the-loop i.e. that is IDEA Integration Demonstration and Experimentation for Aeronautics IEEE Institute of Electrical and Electronics Engineers ILS Instrument Landing System ILZ Imbedded Late Zone IM Interval Management IMC Instrument Meteorological Conditions JBU JetBlue Airlines KSFO San Francisco International Airport kt Knots L Left L(A) Lead Active L/R Left/Right LAT Lateral LZ Late Zone M Mean iii\n MEM Memphis International Airport MMC Marginal Meteorological Conditions MOPS Minimum Operational Performance Standards MRS Minimum Radar Separation MS Mean Squares MVA Minimum Vectoring Altitude N/A Not Applicable NAS National Airspace System NASA National Aeronautics and Space Administration NATCA National Air Traffic Controllers Association NCT Northern California TRACON NM Nautical Mile NNZ Non-Normal Zone NTZ No-Transgression Zone OAK Oakland International Airport PA Paired Approach PFAS Planned Final Approach Speed PHL Philadelphia International Airport PIRAT Tailored Oceanic Arrivals PRM Precision Runway Monitor PTL Predicted Track Line PTP Planned Termination Point PTT Push-To-Talk QT Questionnaire Type R Right RECAT Recategorization RNAV Area Navigation RNP Required Navigation Performance RQ Research Question RWY Runway SBS Surveillance Broadcast Services iv\n SC Special Committee SD Standard Deviation SEA Seattle-Tacoma International Airport SEWG Systems Engineering Working Group SFO San Francisco International Airport SJC San Jose International Airport SME Subject Matter Expert SOIA Simultaneous Offset Instrument Approach SPR Safety and Performance Requirements SRS Single Runway Spacing SS Sum of Squares STARS Standard Terminal Automation Replacement System STL St. Louis Lambert International Airport T(A) Trail Active T(E) Trail Eligible TBFM Time-Based Flow Management TBO Trajectory Based Operations TERPS Terminal Instrument Procedures TMC Traffic Management Coordinator TRACON Terminal Radar Approach Control TSAS Terminal Sequencing and Spacing TSE Total System Error UAL United UPS United Parcel Service VFR Visual Flight Rules VMC Visual Meteorological Conditions VRD Virgin America Airlines WG Working Group WSL Wake Safety Limit WSL-P Wake Safety Limit Preview i\n DemographicsAppendix B IM PAIRED APPROACH HITL ATC DEMOGRAPHICS QUESTIONNAIRE Please complete the following background questionnaire. Your identity will be kept confidential and \nwill not be included in any of the material that will be produced as a result of this study. How many years of experience do you have actively controlling air traffic? Years1. How many months out of the past 12 have you actively controlled air traffic? Months2. Age: Years 3. At which facility do you now (or did you last) work? 4. What is your current (or most recent) position? 5. Have you ever worked at a final approach monitor position? (circle one) YES NO6. If yes, approximately how many months / years? If yes, which facility / facilities? If yes, did you monitor parallel runway arrivals? YES NO If yes, were they dependent, independent, or both? DEPENDENT INDEPENDENT BOTH Have you ever worked at a final approach control position? (circle one) YES NO7. If yes, approximately how many months / years? If yes, which facility? If yes, did you control during parallel runway arrivals? YES NO If yes, were they dependent, independent, or both? DEPENDENT INDEPENDENT BOTH What other positions have you held within the FAA (e.g., TMC, airspace operations, etc.)? 8.\n \n (see next page) ii\n Have you ever been a controller at Northern California TRACON (NCT)? (circle one) YES NO9. If yes, which sectors and approximately how many months / years in each: \n \n Have you ever been a controller at the San Francisco International Airport (SFO) air traffic control 10.\ntower? (circle one) YES NO If yes, which position(s) and approximately how many months / years: Have you ever worked at a facility that conducted closely spaced parallel approaches? (circle one) 11.\nYES NO If yes, which facility and position(s): Do you have any experience (such as demos or simulations) with concepts like Interval Management 12.\nand/or Paired Approach? (circle one) YES NO If yes, please describe your previous experience:\n \n \n \n i\n Day 1-2 Post-Run QuestionnairesAppendix C IM PA HITL POST-RUN QUESTIONNAIRE COMBINED MONITOR Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general monitoring task for an IM PA operation \nis the primary area of interest. Although the simulation used certain elements of the SFO \nairspace, your answer should be more of a general consideration of the PA monitoring task, \ninstead of how it might specifically be applied to the SFO environment. Please consider only the current scenario when answering. If you have any questions, please \nask the experimenter. ii\n Workload Using the chart below, how would you rate your average level of workload in this 1.\nscenario? (a) Working up from the bottom left corner, answer each yes/no question and \nfollow the path. (b) Circle the numerical rating that best reflects your experience. My workload in this scenario was acceptable. (draw a line on the scale)2. Comments: \n \n iii\n Operations As the IM PA aircraft pairs became my responsibility, I had sufficient time to make a 3.\nfirst assessment of their separation. (draw a line on the scale) Comments: \n \n I was comfortable with the IM PA trail aircraft managing their speeds to achieve the 4.\nspacing goal assigned by the final controller. (draw a line on the scale) Comments: \n \n I was confident that I could assess whether separation would be maintained 5.\nbetween the IM PA trail aircraft and their Lead Aircraft. (draw a line on the scale) Comments: \n \n iv\n Did you need to terminate an IM PA operation during this scenario? (circle one)6. Yes No If yes, why? \n \n Given the IM PA-related tools I had in this scenario, I had sufficient overall traffic 7.\nsituation awareness. (draw a line on the scale) Comments: \n \n Given the appropriate training and the IM PA-related tools provided in this scenario, 8.\na single monitor controller can effectively ensure separation across both approaches \nduring IM PA operations. (draw a line on the scale) Comments: \n \n Displays With the IM PA-related tools provided in this scenario, I could easily assess the 9.\nseparation between the IM PA trail aircraft and its lead, when they were my \nresponsibility. (draw a line on the scale) Comments: \n \n v\n With the IM PA-related tools provided in this scenario, I could easily assess the 10.\nseparation among all aircraft for which I was responsible. (draw a line on the scale) Comments: \n \n I could easily assess whether the IM PA trail aircraft would remain behind the CSL 11.\nduring the approach. (draw a line on the scale) Comments: \n \n I could easily assess whether the IM PA trail aircraft would remain forward of the 12.\nWSL during the approach, when applicable. (draw a line on the scale) Comments: \n \n I could easily assess whether the lead and trail aircraft would remain within their 13.\nlateral maneuvering bounds during the approach. (draw a line on the scale) Comments: \n \n vi\n The IM PA-related tools provided in this scenario allowed for a timely detection of 14.\nany impending exceedance of the WSL or CSL. (draw a line on the scale) Comments: \n \n The IM PA-related tools provided in this scenario allowed for a timely detection of 15.\nany excessive deviation from the approach course by aircraft involved in a PA \noperation. (draw a line on the scale) Comments: \n \n Given the IM PA-related tools provided in this scenario, I could easily tell when an 16.\naircraft would require a WSL later in the approach. (draw a line on the scale) Comments: \n \n Given the IM PA-related tools provided in this scenario, I was comfortable 17.\nmonitoring IM PA operations when both a CSL and WSL were active at the same \ntime. (draw a line on the scale) Comments: \n \n vii\n Was all of the provided IM PA information in this scenario useful, including that in 18.\nboth the Spacing List and data blocks? (circle one)
Yes No If no, what information was not useful and why? \n \n Was there any operational information not provided in this scenario that you would 19.\nhave found helpful? (circle one) Yes No If yes, what information and why? \n \n Communications Did you experience any IM PA-related communication difficulties? (circle one) 20. Yes No If yes, explain: \n \n Did you have any issues during communications when the Lead Aircraft call sign was 21.\nused? (circle one) Yes No If yes, describe: \n \n viii\n Overall Did you have concerns with any aspect of the IM PA operation in this particular 22.\nscenario, whether in your area or not? (circle one) Yes No If yes, please explain: \n \n If you have any other comments about the IM PA-related tools provided in this 23.\nscenario, please provide them below. \n \n \n \n \n If you have any other comments about this scenario, please provide them below.24.\n \n \n \n \n \n ix\n IM PA HITL POST-RUN QUESTIONNAIRE 28R FINAL CONTROLLER Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the IM PA operation is the primary area of interest. \nAlthough the simulation used certain elements of the SFO airspace, your answer should be \nmore of a general consideration of the IM PA operation, instead of how it might specifically be \napplied to the SFO environment. Also, please consider only the time from which the aircraft were in your area to when you \ntransferred them to the local controller. Please consider only the current scenario when answering. If you have any questions, please \nask the experimenter. x\n Workload Using the chart below, how would you rate your average level of workload in this 1.\nscenario? (a) Working up from the bottom left corner, answer each yes/no question and \nfollow the path. (b) Circle the numerical rating that best reflects your experience. My workload in this scenario was acceptable. (draw a line on the scale)2. Comments: \n \n xi\n Operations Given the appropriate training, and the IM PA-related tools I had available in this 3.\nscenario, final controllers can acceptably initiate the IM PA operation. (draw a line on \nthe scale) Comments: \n \n Once the IM PA aircraft joined the final, I had sufficient time and airspace to initiate 4.\nIM PA before transferring the aircraft to the local controller. (draw a line on the \nscale) Comments: \n \n Given the appropriate training, and the IM PA-related tools I had available in this 5.\nscenario, final controllers can acceptably ensure separation during IM PA operations, \nbefore transferring aircraft to the local controller. (draw a line on the scale) Comments: \n \n xii\n I was comfortable with the IM PA aircraft managing their speeds to achieve the 6.\nspacing goal I assigned, while they were in my area. (draw a line on the scale) Comments: \n \n I was confident that I could assess whether separation would be maintained, in my 7.\nairspace, between the IM PA aircraft and their Lead Aircraft. (draw a line on the \nscale) Comments: \n \n I was comfortable that I was transferring appropriately separated aircraft to the local 8.\ncontroller. (draw a line on the scale) Comments: \n \n Did you need to terminate an IM PA operation in this scenario? (circle one)9. Yes No If yes, why? \n \n Displays xiii\n In this scenario, I had the necessary display elements to provide the appropriate IM 10.\nPA clearance information to the trail aircraft in an IM PA pair. (draw a line on the \nscale) Comments: \n \n With the IM PA-related tools provided in this scenario, I could easily assess the 11.\nseparation between the IM PA trail aircraft and its lead, when they were my \nresponsibility. (draw a line on the scale) Comments: \n \n With the IM PA-related tools provided in this scenario, I could easily assess the 12.\nseparation among all aircraft for which I was responsible. (draw a line on the scale) Comments: \n \n xiv\n The IM PA-related tools provided in this scenario allowed for a timely detection of 13.\nany spacing or separation issues. (draw a line on the scale) Comments: \n \n I could easily assess whether the IM PA trail aircraft would remain behind the CSL 14.\nduring the approach. (draw a line on the scale) Comments: \n \n Was all of the provided IM PA information in this scenario useful, including that in 15.\nboth the Spacing List and data blocks? (circle one) Yes No If no, what information was not useful and why? \n \n Was there any operational information not provided in this scenario that you would 16.\nhave found helpful? (circle one) Yes No If yes, what information and why? \n \n xv\n Communications and Coordination Did you experience any IM PA-related communication difficulties? (circle one) 17. Yes No If yes, explain: \n \n Did you have any issues during communications when the Lead Aircraft call sign was 18.\nused? (circle one) Yes No If yes, describe: \n \n Were there any situations that required coordination with the monitor controller? 19.\n(circle one) Yes No If yes, explain: \n \n Overall Did you have concerns with any aspect of the IM PA operation in this particular 20.\nscenario, whether in your area or not? (circle one) Yes No If yes, please explain: \n \n If you have any other comments about the IM PA-related tools provided in this 21. xvi\n scenario, please provide them below.\n \n \n \n \n \n If you have any other comments about this scenario, please provide them below.22.\n \n \n \n \n \n xvii\n IM PA HITL POST-RUN QUESTIONNAIRE DUAL MONITOR CONFIGURATION (28R MONITOR) Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general monitoring task for an IM PA operation \nis the primary area of interest. Although the simulation used certain elements of the SFO \nairspace, your answer should be more of a general consideration of the PA monitoring task, \ninstead of how it might specifically be applied to the SFO environment. Please consider only the current scenario when answering. If you have any questions, please \nask the experimenter. xviii\n Workload Using the chart below, how would you rate your average level of workload in this 1.\nscenario? (a) Working up from the bottom left corner, answer each yes/no question and \nfollow the path. (b) Circle the numerical rating that best reflects your experience. My workload in this scenario was acceptable. (draw a line on the scale)2. Comments: \n \n xix\n Operations As the IM PA aircraft pairs became my responsibility, I had sufficient time to make a 3.\nfirst assessment of their separation. (draw a line on the scale) Comments: \n \n I was comfortable with the IM PA trail aircraft managing their speeds to achieve the 4.\nspacing goal assigned by the final controller. (draw a line on the scale) Comments: \n \n I was confident that I could assess whether separation would be maintained 5.\nbetween the IM PA trail aircraft and their Lead Aircraft. (draw a line on the scale) Comments: \n \n Did you need to terminate an IM PA operation during this scenario? (circle one)6. Yes No If yes, why? \n \n Given the IM PA-related tools I had in this scenario, I had sufficient overall traffic 7. xx\n situation awareness. (draw a line on the scale) Comments: \n \n I was comfortable monitoring the trail aircraft in an IM PA pair, while another 8.\ncontroller monitored the Lead Aircraft. (draw a line on the scale) Comments: \n \n Displays With the IM PA-related tools provided in this scenario, I could easily assess the 9.\nseparation between the IM PA trail aircraft and its lead, while the IM PA trail aircraft \nwas in my area. (draw a line on the scale) Comments: \n \n xxi\n With the IM PA-related tools provided in this scenario, I could easily assess the 10.\nseparation among all aircraft for which I was responsible. (draw a line on the scale) Comments: \n \n I could easily assess whether the IM PA trail aircraft would remain behind the CSL 11.\nduring the approach. (draw a line on the scale) Comments: \n \n I could easily assess whether the IM PA trail aircraft would remain forward of the 12.\nWSL during the approach, when applicable. (draw a line on the scale) Comments: \n \n I could easily assess whether the lead and trail aircraft would remain within their 13.\nlateral maneuvering bounds during the approach. (draw a line on the scale) Comments: \n \n xxii\n The IM PA-related tools provided in this scenario
allowed for a timely detection of 14.\nany impending exceedance of the WSL or CSL. (draw a line on the scale) Comments: \n \n The IM PA-related tools provided in this scenario allowed for a timely detection of 15.\nany excessive deviation from the approach course by aircraft involved in a PA \noperation. (draw a line on the scale) Comments: \n \n Given the IM PA-related tools provided in this scenario, I could easily tell when an 16.\naircraft would require a WSL later in the approach. (draw a line on the scale) Comments: \n \n Given the IM PA-related tools provided in this scenario, I was comfortable 17.\nmonitoring IM PA operations when both a CSL and WSL were active at the same \ntime. (draw a line on the scale) Comments: \n \n xxiii\n Was all of the provided IM PA information in this scenario useful, including that in 18.\nboth the Spacing List and data blocks? (circle one) Yes No If no, what information was not useful and why? \n \n Was there any operational information not provided in this scenario that you would 19.\nhave found helpful? (circle one) Yes No If yes, what information and why? \n \n Communications and Coordination Did you experience any IM PA-related communication difficulties? (circle one) 20. Yes No If yes, explain: \n \n Did you have any issues during communications when the Lead Aircraft call sign was 21.\nused? (circle one) Yes No If yes, describe: \n \n xxiv\n Were there any situations that required coordination with the 28L monitor 22.\ncontroller? (circle one) Yes No If yes, explain: \n \n Overall Did you have concerns with any aspect of the IM PA operation in this particular 23.\nscenario, whether in your area or not? (circle one) Yes No If yes, please explain: \n \n If you have any other comments about the IM PA-related tools provided in this 24.\nscenario, please provide them below. \n \n \n \n \n If you have any other comments about this scenario, please provide them below.25.\n \n \n \n \n \n xxv\n IM PA HITL POST-RUN QUESTIONNAIRE DUAL MONITOR CONFIGURATION (28L MONITOR) Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general monitoring task for an IM PA operation \nis the primary area of interest. Although the simulation used certain elements of the SFO \nairspace, your answer should be more of a general consideration of the PA monitoring task, \ninstead of how it might specifically be applied to the SFO environment. Please consider only the current scenario when answering. If you have any questions, please \nask the experimenter. xxvi\n Workload Using the chart below, how would you rate your average level of workload in this 1.\nscenario? (a) Working up from the bottom left corner, answer each yes/no question and \nfollow the path. (b) Circle the numerical rating that best reflects your experience. My workload in this scenario was acceptable. (draw a line on the scale)2. Comments: \n \n xxvii\n Operations As aircraft pairs entered my area, I had sufficient time to make a first assessment of 3.\ntheir separation. (draw a line on the scale) Comments: \n \n I was comfortable with the IM PA trail aircraft managing their speeds to achieve the 4.\nspacing goal assigned by the final controller. (draw a line on the scale) Comments: \n \n Did you need to break out an IM PA Lead Aircraft in this scenario? (circle one)5. Yes No If yes, why? \n \n Given the tools I had in this scenario, I had sufficient overall traffic situation 6.\nawareness. (draw a line on the scale) Comments: \n \n xxviii\n I was comfortable monitoring the Lead Aircraft in an IM PA pair, while another 7.\ncontroller monitored the trail aircraft. (draw a line on the scale) Comments: \n \n Displays With the tools provided in this scenario, I could easily assess the separation among 8.\nall aircraft for which I was responsible. (draw a line on the scale) Comments: \n \n I could easily assess whether the Lead Aircraft in an IM PA pair would remain within 9.\ntheir lateral maneuvering bounds during the approach. (draw a line on the scale) Comments: \n \n xxix\n The tools provided in this scenario allowed for a timely detection of any excessive 10.\ndeviation from the approach course by aircraft involved in a PA operation. (draw a \nline on the scale) Comments: \n \n Was all of the provided IM PA information in this scenario useful, including that in 11.\nboth the Spacing List and data blocks? (circle one) Yes No If no, what information was not useful and why? \n \n Was there any operational information not provided in this scenario that you would 12.\nhave found helpful? (circle one) Yes No If yes, what information and why? \n \n Communications and Coordination Did you experience any IM PA-related communication difficulties? (circle one) 13. Yes No If yes, explain: \n \n xxx\n Were there any situations that required coordination with the 28R monitor 14.\ncontroller? (circle one) Yes No If yes, explain: \n \n Overall Did you have concerns with any aspect of the IM PA operation in this particular 15.\nscenario, whether in your area or not? (circle one) Yes No If yes, please explain: \n \n If you have any other comments about the IM PA-related tools provided in this 16.\nscenario, please provide them below. \n \n \n \n \n If you have any other comments about this scenario, please provide them below.17.\n \n \n \n \n \n i\n Day 1-2 End QuestionnaireAppendix D IM PA HITL QUESTIONNAIRE DAY 1 END Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general IM PA operation is the primary area of \ninterest. Although the simulation used certain elements of the SFO airspace, your answer \nshould be more of a general consideration of the IM PA operation, instead of how it might \nspecifically be applied to the SFO environment. Please consider your experience across all of todays scenarios when answering. If you have \nany questions, please ask the experimenter. ii\n For the following questions, please consider your experience ACROSS todays scenarios. My overall workload today was acceptable. (draw a line on the scale)1. Comments: \n \n My overall level of traffic awareness today was acceptable with respect to the: (draw 2.\na line on each scale) IM PA Lead Aircraft: IM PA Trail Aircraft: Other Aircraft: Comments: \n \n Given the appropriate training and IM PA-related tools, IM PA operations can be 3.\neffectively monitored by the number of positions I experienced today. (draw a line \non the scale) Comments: \n \n iii\n When monitoring today, my roles and responsibilities were clear with respect to the: \n(draw a line on the scale) IM PA Lead Aircraft: IM PA Trail Aircraft: Other Aircraft: Comments: \n \n Overall, I was able to detect in a sufficient amount of time when spacing / separation 4.\nissues were developing. (draw a line on each scale) Within an IM PA Aircraft pair: Between any other aircraft combination: Comments: \n \n iv\n Did you experience IM PA-related coordination challenges today, beyond any youve 5.\nalready noted? (circle one) Yes No If yes, explain: \n \n Do you have concerns with any aspect of the IM PA operation you saw today, beyond any 6.\nyouve already noted? (circle one) Yes No If yes, please explain: \n \n If you have any additional general comments about the IM PA-related tools you saw 7.\ntoday, please provide them below. \n \n \n \n \n If you have any other comments about what you saw today overall, please provide 8.\nthem below. \n \n \n \n \n v\n IM PA HITL QUESTIONNAIRE DAY 2 END Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general IM PA operation is the primary area of \ninterest. Although the simulation used certain elements of the SFO airspace, your answer \nshould be more of a general consideration of the IM PA operation, instead of how it might \nspecifically be applied to the SFO environment. This questionnaire consists of two parts:\nPart 1: When answering, consider your experience across todays scenarios only.\nPart 2: When answering, consider your experience across yesterday and todays scenarios. If you have any questions, please ask the experimenter. vi\n vii\n Part 1: For the following questions,
please consider your experience across todays scenarios \nONLY. My overall workload today was acceptable. (draw a line on the scale)13. Comments: \n \n My overall level of traffic awareness today was acceptable with respect to the: (draw 14.\na line on each scale) IM PA Lead Aircraft: IM PA Trail Aircraft: Other Aircraft: Comments: \n \n Given the appropriate training and IM PA-related tools, IM PA operations can be 15.\neffectively monitored by the number of positions I experienced today. (draw a line \non the scale) Comments: \n \n viii\n When monitoring today, my roles and responsibilities were clear with respect to the: 16.\n(draw a line on the scale) IM PA Lead Aircraft: IM PA Trail Aircraft: Other Aircraft: Comments: \n \n Overall today, I was able to detect in a sufficient amount of time when spacing / 17.\nseparation issues were developing. (draw a line on each scale) Within an IM PA Aircraft pair: Between any other aircraft combination: Comments: \n \n ix\n Did you experience IM PA-related coordination challenges today, beyond any youve 18.\nalready noted? (circle one) Yes No If yes, explain: \n \n Do you have concerns with any aspect of the IM PA operation you saw today, 19.\nbeyond any youve already noted? (circle one) Yes No If yes, please explain: \n \n If you have any additional general comments about the IM PA-related tools you saw 20.\ntoday, please provide them below. \n \n \n \n \n If you have any other comments about what you saw today overall, please provide 21.\nthem below. \n \n \n \n \n x\n Part 2: For the following questions, please consider your experience across ALL scenarios, \nyesterday AND today. Monitoring and Operations IM PA is operationally desirable. (draw a line on the scale)1. Comments: \n \n IM PA is compatible with terminal approach operations. (draw a line on the scale)2. Comments: \n \n It is operationally acceptable for the final controller to provide the IM PA spacing 3.\ngoal. (draw a line on the scale) Comments: \n \n I was comfortable allowing an IM PA aircraft to manage its own speed to achieve the 4.\ndesired spacing goal at the Final Approach Fix. (draw a line on the scale) Comments: \n \n Given the appropriate training and the IM PA-related tools, a single monitor 5. xi\n controller can effectively ensure separation across both approaches during IM PA \noperations. (draw a line on the scale) Comments: \n \n Overall, I was comfortable monitoring the trail aircraft in an IM PA pair, while 6.\nanother controller monitored the Lead Aircraft. (draw a line on the scale) Comments: \n \n Overall, I was comfortable monitoring the Lead Aircraft in an IM PA pair, while 7.\nanother controller monitored the trail aircraft. (draw a line on the scale) Comments: \n \n Overall, I was confident that I could assess whether the separation between the IM 8.\nPA trail aircraft and their Lead Aircraft would be maintained. (draw a line on the \nscale) Comments: \n \n xii\n The tasks required of each simulation position were acceptable. (draw a line on each 9.\nscale) Combined 28L/28R Monitor Position: 28L Monitor Position only: 28R Monitor Position only: 28R Final Position: Comments: \n \n Displays For the following questions, consider the IM PA tools per the below figure. The following tools were useful for the overall IM PA monitoring task. (draw a line 10.\non each scale on the next page) xiii\n Safety Limits (were useful) CSL (Blue Line) WSL (Blue Line) WSL Preview (grey line \nappearing before blue WSL) Data Block Elements (were useful) IM PA (Trail) Aircraft Status \n(e.g. [T(A)]) Lead Aircraft Status [L(A)] CSL Distance WSL Distance WSL Pre-Active Indication (\nW) Alerts (were useful) IM PA Predictive Alert \n(Yellow) IM PA Caution Alert \n(Orange) Spacing List (were useful) IM Status \n(i.e. Eligible, Active, Terminated) Lateral Bounds (were useful) Inner Bounds Outer Bounds xiv\n Does the usefulness of any of the tools depend on whether there was single monitor 11.\nfor both approaches, or separate monitors for each approach? (circle one) Yes No If yes, explain: \n \n \n \n If the CSL is shown as a graphic line, the numeric distance to it in the data block is 12.\nalso helpful. (draw a line on the scale) Comments: \n \n It was helpful to know whether an aircraft would eventually require an active WSL. 13.\n(draw a line on the scale) Why? \n \n If provided the initial WSL W indicator in the data block, I do not also need the WSL 14.\nPreview Line. (draw a line on the scale) Comments: \n \n xv\n If provided the WSL Preview Line, I do not also need the initial WSL W indicator in 15.\nthe data block. (draw a line on the scale) Comments: \n \n In the simulation, the WSL Preview Line first appeared with sufficient lead time to be 16.\nuseful. (draw a line on the scale) Approximately how many miles prior to the wake safety limit becoming active should \nthe WSL Preview Line start to be displayed? NM Comments: \n \n My responsibilities with respect to a Predictive (yellow) alert were clear. (draw a line 17.\non the scale) Comments: \n \n The predictive (yellow) alert provided sufficient advance notice of an impending 18.\ncaution alert. (draw a line on the scale) Comments: \n \n xvi\n My responsibilities with respect to a Caution (orange) alert were clear. (draw a line 19.\non the scale) Comments: \n \n The Caution (orange) alert provided sufficient advance notice of an impending loss of 20.\nseparation. (draw a line on the scale) Comments: \n \n xvii\n What combination of tools would you recommend for the IM PA monitor controller, 21.\nand should they always be on or user-selectable? (check the appropriate selections \nin the table, one selection per row) IM PA Tool\nShould always \nbe displayed User should be able \nto toggle on or off Not needed Safety Limits\nCSL (Blue Line) WSL (Blue Line)\nWSL Preview (Grey line) Data Block Elements\nIM PA (Trail) Aircraft Status (e.g. [T(A)]) Lead Aircraft Status [L(A)]\nCSL Distance WSL Distance \nWSL Pre-Active Indication (W) Alerts\nIM PA Predictive Alert (45 sec) IM PA Caution Alert (24 sec)\nSpacing List IM PA Spacing Goal\nLead Aircraft Call Sign\nLead Aircraft Runway Status: Eligible, Active, Terminated\nLateral Bounds Inner Bounds\nOuter Bounds Comments: \n \n Would your selections above comprise an acceptable, complete toolset for 22.\nmonitoring an IM PA operation? (circle one) Yes No If no, what additional information would you require? \n \n What combination of tools would you recommend to help the IM PA final controller 23.\ncomplete the IM Clearance, and should they always be on or user-selectable? (check \nthe appropriate selections in the table, one selection per row) IM PA Tool\nShould always \nbe displayed User should be able \nto toggle on or off Not needed xviii\n Safety Limits\nCSL (Blue Line) WSL (Blue Line) N/A\nWSL Preview (Grey line) Data Block Elements\nIM PA (Trail) Aircraft Status (e.g. [T(A)]) Lead Aircraft Status [L(A)]\nCSL Distance WSL Distance N/A\nWSL Pre-Active Indication (W) Alerts\nIM PA Predictive Alert (45 sec) IM PA Caution Alert (24 sec)\nSpacing List IM PA Spacing Goal\nLead Aircraft Call Sign\nLead Aircraft Runway Status: Eligible, Active, Terminated\nLateral Bounds Inner Bounds\nOuter Bounds Comments: \n \n Would your selections above comprise an acceptable, complete toolset for 24.\ncompleting an IM PA clearance? (circle one) Yes No If no, what additional information would you require? \n \n xix\n The monitor controller should be provided an IM Spacing List. (draw a line on the 25.\nscale) If agree, should it be identical to that of the final controller? (circle one) Yes No Comments: \n \n Communications The IM PA spacing goal communication was acceptable. (draw a line on the scale)26. Comments: \n \n I was comfortable with the use of the Lead Aircraft call sign in the IM Clearance 27.\ncommunication. (draw a line on the scale) Comments: \n \n xx\n Overall What was the most difficult situation to deal with when aircraft were conducting IM 28.\nPA operations? \n \n Was there any aspect of the IM PA operation that you especially liked?29.\n \n \n \n How could the conduct of IM PA operations be improved?30.\n \n \n \n If you have any other comments about IM PA operations, please provide them 31.\nbelow. \n \n \n \n \n i\n Alert Timing QuestionnairesAppendix E IM PA HITL POST-RUN QUESTIONNAIRE ALERT TIMING Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general monitoring task for an IM PA operation \nis the primary area of interest. Although the simulation used certain elements of the SFO \nairspace, your answer should be more of a general consideration of the PA monitoring task, \ninstead of how it might specifically be applied to the SFO environment. Please consider only the current scenario when answering. If you have any questions, please \nask the experimenter. ii\n Workload Using the chart below, how would you rate
your average level of workload in this 1.\nscenario? (a) Working up from the bottom left corner, answer each yes/no question and \nfollow the path. (b) Circle the numerical rating that best reflects your experience. My workload in this scenario was acceptable. (draw a line on the scale)2. Comments: \n \n iii\n Operations and Displays I was confident that I could assess whether separation would be maintained 3.\nbetween the IM PA trail aircraft and their Lead Aircraft. (draw a line on the scale) Comments: \n \n In this scenario, I could easily assess whether the IM PA trail aircraft would remain 4.\nbehind the CSL during the approach. (draw a line on the scale) Comments: \n \n In this scenario, I could easily assess whether the IM PA trail aircraft would remain 5.\nforward of the WSL during the approach, when applicable. (draw a line on the scale) Comments: \n \n The predictive (yellow) alert provided sufficient advance notice of an impending 6.\ncaution alert. (draw a line on the scale) Comments: \n \n iv\n The Predictive (yellow) alert was noticeable enough such that I became aware of it 7.\nwithout undue delay. (draw a line on the scale) Comments: \n \n Was the Predictive alert (yellow) timing about right? (draw a line on each scale)8. The timing before the IM PA aircraft crossed the CSL seemed about right: The timing before the IM PA aircraft crossed the WSL seemed about right: Comments: \n \n The Caution (orange) alert provided sufficient advance notice of an impending loss of 9.\nseparation. (draw a line on the scale) Comments: \n \n v\n Was the Caution alert (orange) timing about right? (draw a line on each scale)10. The timing before the IM PA aircraft crossed the CSL seemed about right: The timing before the IM PA aircraft crossed the WSL seemed about right: Comments: \n \n Overall If you have any other comments about the IM PA alerts provided in this scenario, 11.\nplease provide them below. \n \n \n \n \n If you have any other comments about this scenario, please provide them below.12.\n \n \n \n \n \n vi\n IM PA HITL FINAL QUESTIONNAIRE ALERT TIMING Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general monitoring task for an IM PA operation \nis the primary area of interest. Although the simulation used certain elements of the SFO \nairspace, your answer should be more of a general consideration of the PA monitoring task, \ninstead of how it might specifically be applied to the SFO environment. Please consider all of this mornings scenarios when answering. If you have any questions, \nplease ask the experimenter. vii\n Operations and Displays Across all timings that I experienced, I was confident that I could assess whether 1.\nseparation would be maintained between the IM PA trail aircraft and their Lead Aircraft. \n(draw a line on the scale) Comments: \n \n Across all timings that I experienced, I could easily assess whether the IM PA trail 2.\naircraft would remain behind the CSL during the approach. (draw a line on the scale) Comments: \n \n Across all timings that I experienced, I could easily assess whether the IM PA trail 3.\naircraft would remain forward of the WSL during the approach, when applicable. \n(draw a line on the scale) Comments: \n \n How soon before the IM PA aircraft crosses the limit would you like to see the 4.\nPredictive (yellow) alert? (fill in as needed)\n sec before the CSL is crossed\n sec before the WSL is crossed Comments: \n \n How soon before the IM PA aircraft crosses the limit would you like to see the 5. viii\n Caution (orange) alert? (fill in as needed)\n sec before the CSL is crossed\n sec before the WSL is crossed Comments: \n \n It was helpful to indicate the Predictive (yellow) alert via the: (draw a line on each 6.\nscale) Data Block Line 3 color change: CSL or WSL line color change: Comments: \n \n Would you change anything about the Predictive (yellow) alert presentation? (circle 7.\none) Yes No If yes, what would you change? \n \n ix\n It was helpful to indicate the Caution (orange) alert via the: (draw a line on each 8.\nscale) Data Block Line 3 color change: CSL or WSL line color change: Comments: \n \n Would you change anything about the Caution (orange) alert presentation? (circle 9.\none) Yes No If yes, what would you change? \n \n In a combined-monitor configuration (what you experienced today), at what level 10.\nshould SOP prescribe controller actions to be taken in response to a Caution (orange) \nalert: (check one) The SOP should not constrain the controllers resolution of the impending \nloss of separation. The SOP should specify which aircraft to maneuver in response to any given \nset of conditions, but not how to maneuver it. The SOP should specify which aircraft to maneuver and also specify an initial \nheading and altitude to use. Comments: \n \n x\n In a separate monitor configuration, at what level should SOP prescribe controller 11.\nactions to be taken in response to a Caution (orange) alert: (check one) The SOP should not constrain the controllers resolution of the impending \nloss of separation. The SOP should specify which aircraft to maneuver in response to any given \nset of conditions, but not how to maneuver it. The SOP should specify which aircraft to maneuver and also specify an initial \nheading and altitude to use. Comments: \n \n Overall If you have any other comments about the IM PA alerts provided in this scenario, 12.\nplease provide them below. \n \n \n \n \n If you have any other comments about this scenario, please provide them below.13.\n \n \n \n \n \n i\n Lateral Deviation QuestionnairesAppendix F IM PA HITL POST-RUN QUESTIONNAIRE LATERAL DEVIATIONS Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general monitoring task for an IM PA operation \nis the primary area of interest. Although the simulation used certain elements of the SFO \nairspace, your answer should be more of a general consideration of the PA monitoring task, \ninstead of how it might specifically be applied to the SFO environment. Please consider only the current scenario when answering. If you have any questions, please \nask the experimenter. ii\n Workload My workload in this scenario was acceptable. (draw a line on the scale)1. Comments: \n \n Operations and Displays I was confident that I could assess whether separation would be maintained 2.\nbetween the IM PA trail aircraft and their Lead Aircraft. (draw a line on the scale) Comments: \n \n In this scenario, I could easily assess whether aircraft involved in a PA operation were 3.\noperating within their lateral bounds. (draw a line on the scale) Comments: \n \n iii\n The warning (red) alert was noticeable enough such that I became aware of it 4.\nwithout undue delay. (draw a line on the scale) Comments: \n \n In this scenario, I felt I had sufficient time and situational awareness to choose and 5.\nexecute appropriate corrective action once the warning (red) alert occurred. (draw a \nline on the scale) Comments: \n \n Overall If you have any other comments about the IM PA alerts provided in this scenario, 6.\nplease provide them below. \n \n \n \n \n If you have any other comments about this scenario, please provide them below.7.\n \n \n \n \n \n iv\n IM PA HITL FINAL QUESTIONNAIRE LATERAL DEVIATIONS Instructions: Please answer the questions by drawing a vertical line through the option on each \nof the scales at the point which matched your experience (as shown below) or circling an option \n(e.g., yes / no). Please draw your line like this:Good PoorNOT like this: Good Poor When choosing an option, keep in mind that the general IM PA operation is the primary area of \ninterest. Although the simulation used certain elements of the SFO airspace, your answer \nshould be more of a general consideration of the IM PA operation, instead of how it might \nspecifically be applied to the SFO environment. Please consider your experience across all of todays lateral deviation scenarios when \nanswering. If you have any questions, please ask the experimenter. v\n For the following questions, please consider your experience ACROSS todays lateral deviation \nscenarios. My overall workload today was acceptable. (draw a line on the scale)1. Comments: \n \n My overall level of traffic awareness was acceptable with respect to the: (draw a line 2.\non each scale) IM PA Lead Aircraft: IM PA Trail Aircraft: Other Aircraft: Comments:
\n \n vi\n When monitoring today, my roles and responsibilities were clear with respect to the: 3.\n(draw a line on the scale) IM PA Lead Aircraft: IM PA Trail Aircraft: Other Aircraft: Comments: \n \n Overall, the warning (red) alert was noticeable enough such that I became aware of 4.\nit without undue delay. (draw a line on each scale) Comments: \n \n Advance notice of an impending exceedance of the lateral bounds would have been 5.\nhelpful. (draw a line on each scale) Comments: \n \n vii\n Advance notice of an impending exceedance of the lateral bounds would have been 6.\nessential. (draw a line on each scale) Comments: \n \n There is sufficient time to choose and execute appropriate corrective action once the 7.\nwarning (red) alert occurs. (draw a line on the scale) Combined Monitor controller configuration: Separate Monitor controller configuration: Comments: \n \n There is sufficient situational awareness to choose and execute appropriate 8.\ncorrective action once the warning (red) alert occurs. (draw a line on the scale) Combined Monitor controller configuration: Separate Monitor controller configuration: Comments: \n \n viii\n In terms of handling lateral deviations, what combination of tools would you \nrecommend for the IM PA monitor controller, and should they always be on or user-\nselectable? (check the appropriate selections in the table, one selection per row) IM PA Tool\nShould always \nbe displayed User should be \nable to toggle on or off\nNot needed\nAlerts (upon deviation) Lateral Deviation Alert (Red Bound Line)\nRed LAT (above Data Block) Lateral Bounds\nInner Bounds\nOuter Bounds Comments: \n \n Would your selections above comprise an acceptable, complete toolset for 9.\nmonitoring for lateral deviations? (circle one) Yes No If no, what additional information would you require? \n \n In a combined-monitor configuration, at what level should SOP prescribe controller 10.\nactions to be taken in response to a Lateral Warning (red) alert: (check one) The SOP should not constrain the controllers resolution of the impending \nloss of separation. The SOP should specify which aircraft to maneuver in response to any given \nset of conditions, but not how to maneuver it. The SOP should specify which aircraft to maneuver and also specify an initial \nheading and altitude to use. Comments: \n \n ix\n In a separate monitor configuration, at what level should SOP prescribe controller 11.\nactions to be taken in response to a Lateral Warning (red) alert: (check one) The SOP should not constrain the controllers resolution of the impending \nloss of separation. The SOP should specify which aircraft to maneuver in response to any given \nset of conditions, but not how to maneuver it. The SOP should specify which aircraft to maneuver and also specify an initial \nheading and altitude to use. Comments: \n \n Given the available alerts and displays, a monitor controller can effectively detect 12.\nlateral deviations using the standard STARS display. (draw a line on the scale) On the RNAV Approach outside of a 2-mile final: On the ILS Approach on long final: On the ILS approach closer in (where the lateral bounds narrow): Inside a 2-mile final (where no lateral bounds are shown): Comments: \n \n Given the available alerts and displays, a monitor controller can effectively detect 13.\nlateral deviations using the FMA display. (draw a line on the scale) x\n On the RNAV Approach outside of a 2-mile final: On the ILS Approach on long final: On the ILS approach closer in (where the lateral bounds narrow): Inside a 2-mile final (where no lateral bounds are shown): Comments: \n \n Did you experience coordination challenges related to lateral deviations, beyond any 14.\nyouve already noted? (circle one) Yes No If yes, explain: \n \n xi\n Do you have additional concerns with respect to the handling of lateral deviations? 15.\n(circle one) Yes No If yes, please explain: \n \n Do you have any additional general comments about the lateral deviation displays 16.\nand alerts you saw today, please provide them below. \n \n \n \n \n i\n Simulation Final (Day 3 End)Appendix G IM PA HITL FINAL QUESTIONNAIRE Instructions: Please answer the questions by drawing a vertical line through the option on each of the \nscales at the point which matched your experience (as shown below) or circling an option (e.g., yes / no). Please draw your line like this:Good Poor\nNOT like this: Good Poor When choosing an option, keep in mind that the general monitoring task for an IM PA operation is the \nprimary area of interest. Although the simulation used certain elements of the SFO airspace, your \nanswer should be more of a general consideration of the PA monitoring task, instead of how it might \nspecifically be applied to the SFO environment. Please consider ALL the scenarios, across ALL three days when answering. If you have any questions, \nplease ask the experimenter. ii\n General Operations Does anything youve experienced today change any of your previous positions with 1.\nrespect to: (circle one for each row) IM PA Desirability Yes No Not Sure\nIf Yes, how? \n \n IM PA Compatibility with Terminal \nOperations Yes No Not Sure If Yes, how? \n \n Minimum IM PA Information for \nMonitoring Yes No Not Sure If Yes, how? \n \n Combined vs. Separate Monitor Positions Yes No Not Sure\nIf Yes, how? \n \n Aircraft Managing their Own Speeds Yes No Not Sure\nIf Yes, how? \n \n Communications / Phraseology Yes No Not Sure\nIf Yes, how? \n \n Controller Coordination Yes No Not Sure\nIf Yes, how? \n \n iii\n Does anything youve experienced today change your position about anything else 2.\nfrom the last two days? (circle one) Yes No If yes, what and why? \n \n Which is the most appropriate position to monitor IM PA operations? (circle one)3. Final \nApproach \nMonitor Final \nApproach Control Local \nControlle r Other Why? \n \n I want to be able to see a longitudinal CSL or WSL exceedance problem developing, 4.\nvs. only being provided an alert when I have to take an action. (draw a line on each \nscale) Comments: \n \n I want to be able to see a lateral deviation problem developing, vs only being 5.\nprovided an alert when I have to take an action. (draw a line on each scale) Comments: \n \n iv\n I would expect to be able to effectively monitor any number of IM PA pairs, up to 6.\nand including all aircraft pairs performing IM PA (100%). (draw a line on each scale)\nCombined Monitor Position for Both Approaches: Separate Monitor for Each Approach: Comments: \n \n The more aircraft that are performing IM PA, the easier the overall arrival operation 7.\nshould be to monitor. (draw a line on each scale) Combined Monitor Position for Both Approaches: Separate Monitor for Each Approach: Comments: \n \n If you have any other comments about any aspect of IM PA operations or the HITL 8.\nthat you havent already noted, please provide them below. \n \n v\n Simulation Evaluation The training I received was adequate. (draw a line on each scale)1.\nIM Clearance Completion for Initiation: IM PA Monitoring: Comments: \n \n The overall activity was effective as a context for evaluating the: (draw a line on the 2.\nscale)\nIM PA Initiation Clearance Completion Task: IM PA Monitoring Task: Comments: \n \n Was there anything about the simulation that artificially affected using it as a context 3.\nfor evaluating IM PA operations? (circle one) Yes No No Opinion If yes, explain: \n \n \n \n vi\n Debrief Questions Is there anything you would change about the overall IM PA operation?1. How much do you want to detect a longitudinal or lateral problem developing, vs. 2.\nwaiting for an alert that requires you to take action? Did you notice the CSL value changing over the approach? Did this affect your ability 3.\nto monitor the aircraft separation? Do you think IM PA could be beneficially employed at your facility?4. What would be any operational challenges with using IM PA at your facility?5. What would you change about the HITL, for future participants?6. Are there any other questions we should have asked, but didnt?7. Notice\nThis work was produced for the U.S. Government under Contract DTFAWA-10-C-00080 and is \nsubject to Federal Aviation Administration Acquisition Management System Clause 3.5-13, \nRights In Data-General, Alt. III and Alt. IV (Oct. 1996). The contents of this document reflect the views of the author and The MITRE Corporation and \ndo not necessarily reflect the views of the Federal Aviation Administration (FAA) or the \nDepartment of Transportation (DOT). Neither the FAA nor the DOT makes any warranty or \nguarantee, expressed or implied, concerning the content or accuracy of these views. Approved for Public Release; Distribution Unlimited. Case number: 19-0822. _Hlk869984\n _Hlk2919363\n _Toc4560564\n _Ref527982864\n _Toc4560823\n _Ref535907437\n _Toc4560565\n _Ref2247503\n _Toc4560566\n _Hlk1696707\n _Ref952128\n _Toc4560824\n _Ref535907468\n _Toc4560567\n _Ref536070221\n _Toc4560568\n _Ref348478\n _Ref2244753\n _Toc4560569\n _Ref527984344\n _Toc4560825\n _Ref528143540\n _Toc4560826\n _Ref535897305\n _Toc4560827\n _Toc536519265\n _Ref536089365\n _Ref535907422\n _Ref535907428\n _Toc4560570\n _Toc4560571\n _Ref529963977\n _Toc4560731\n _Toc4560572\n _Ref535906529\n _Toc4560573\n _Ref2225108\n _Ref2227604\n _Toc4560574\n _Ref528146166\n _Toc4560828\n _Ref527969145\n _Toc4560829\n _Ref528146354\n _Toc4560830\n _Toc2048063\n _Ref2254416\n _Toc4560575\n _Ref528148488\n _Ref536426323\n _Toc4560831\n _Toc4560576\n _Ref527973268\n _Toc4560832\n _Ref536073629\n _Toc4560577\n _Ref535997353\n _Toc4560833\n _Toc536519279\n _Toc4560578\n _Toc4560579\n _Ref535906540\n _Toc4560580\n _Ref535906542\n _Toc4560581\n _Ref529963825\n _Toc4560732\n _Ref536068796\n _Toc4560582\n _Hlk2170370\n _Ref528152818\n _Toc4560834\n _Toc4560583\n _Ref2230982\n _Ref2254990\n _Toc4560584\n _Ref2231874\n _Toc4560835\n
_Ref2237936\n _Toc4560836\n _Ref2574374\n _Toc4560585\n _Ref528154285\n _Ref528154592\n _Toc4560837\n _Ref528154607\n _Toc4560838\n _Ref530989883\n _Toc4560839\n _Toc4560586\n _Ref536431018\n _Toc4560587\n _Toc536519286\n _Toc4560588\n _Ref536503159\n _Toc4560589\n _Ref528149095\n _Toc4560590\n _Toc4560591\n _Toc4560592\n _Ref536094146\n _Toc4560840\n _Toc536519292\n _Toc536519293\n _Toc536519294\n _Toc4560593\n _Ref400115539\n _Toc415218319\n _Toc501528697\n _Toc4560841\n _Ref536515663\n _Toc4560594\n _Ref536516296\n _Toc4560842\n _Ref536516512\n _Toc4560843\n _Ref536516721\n _Toc4560844\n _Toc536519297\n _Ref536094116\n _Toc4560595\n _Ref536498278\n _Toc4560596\n _Ref536431409\n _Ref536419865\n _Toc4560845\n _Ref2147692\n _Toc4560597\n _Ref523754072\n _Toc4560846\n _Toc536519301\n _Ref536431468\n _Toc4560598\n _Ref523755615\n _Toc4560847\n _Ref523755630\n _Toc4560848\n _Ref523757922\n _Toc4560849\n _Ref523758037\n _Toc4560850\n _Ref536431480\n _Toc4560599\n _Ref523758372\n _Toc4560851\n _Ref536431485\n _Ref536437454\n _Toc4560600\n _Ref523759697\n _Toc4560852\n _Ref3974027\n _Toc4560601\n _Ref523760369\n _Toc4560853\n _Ref535997654\n _Ref536431498\n _Ref536498376\n _Ref536503582\n _Toc4560602\n _Ref523759928\n _Toc4560854\n _Ref523818642\n _Toc4560855\n _Ref523817524\n _Toc4560856\n _Ref523817572\n _Toc4560857\n _Ref523818247\n _Toc4560858\n _Ref523915923\n _Toc4560603\n _Ref536420328\n _Toc4560604\n _Ref531003711\n _Toc4560859\n _Ref523825485\n _Toc4560860\n _Ref523825497\n _Toc4560861\n _Ref531003872\n _Toc4560862\n _Ref523907968\n _Toc4560863\n _Ref523908009\n _Toc4560864\n _Toc4560605\n _Ref523905395\n _Toc4560865\n _Hlk523908319\n _Ref523908537\n _Toc4560866\n _Ref523908620\n _Toc4560867\n _Ref523909346\n _Toc4560868\n _Ref523909356\n _Toc4560869\n _Toc4560606\n _Ref523819570\n _Toc536519311\n _Ref175953\n _Toc4560607\n _Ref536495993\n _Toc4560870\n _Toc536519313\n _Toc536519314\n _Toc536519315\n _Toc536519316\n _Toc536519317\n _Toc536519318\n _Toc536519319\n _Toc536519320\n _Toc536519321\n _Toc536519322\n _Toc536519323\n _Toc536519324\n _Toc536519325\n _Toc536519326\n _Toc536519327\n _Toc536519328\n _Toc536519329\n _Toc536519330\n _Toc536519331\n _Toc536519332\n _Toc536519333\n _Toc536519334\n _Toc536519335\n _Toc536519336\n _Toc536519337\n _Toc536519338\n _Toc536519339\n _Toc536519340\n _Toc4560608\n _Ref536496027\n _Toc4560871\n _Ref536495936\n _Toc4560609\n _Ref536496090\n _Toc4560733\n _Ref536496129\n _Toc4560872\n _Ref536496160\n _Toc4560734\n _Ref536496813\n _Toc4560610\n _Ref151587\n _Toc4560611\n _Ref535911661\n _Toc4560612\n _Toc536519346\n _Toc4560613\n _Toc536519348\n _Ref523835800\n _Toc4560614\n _Toc4560615\n _Ref1878766\n _Toc4560616\n _Ref535911711\n _Ref535911789\n _Toc4560617\n _Toc4560618\n _Toc536519354\n _Toc4560619\n _Ref531166929\n _Toc4560620\n _Ref3376055\n _Toc4560621\n _Toc536519367\n _Ref2562751\n _Toc4560622\n _Toc536519369\n _Toc536519370\n _Toc536519371\n _Toc536519372\n _Toc536519373\n _Toc536519374\n _Toc536519375\n _Toc536519376\n _Toc536519377\n _Ref536506122\n _Ref152824\n _Toc4560623\n _Hlk527029502\n _Ref523922002\n _Toc4560873\n _Ref159864\n _Ref838745\n _Ref838774\n _Toc4560624\n _Ref536502511\n _Toc4560874\n _Toc4560625\n _Ref1878625\n _Toc4560626\n _Ref1878638\n _Toc4560627\n _Ref536504603\n _Toc4560735\n _Toc536519383\n _Toc536519384\n _Ref536509669\n _Toc4560628\n _Ref529965141\n _Toc4560736\n _Ref532383057\n _Ref2561933\n _Toc4560629\n _Ref529965266\n _Toc4560737\n _Toc4560630\n _Ref529965493\n _Toc4560738\n _Toc4560631\n _Ref527366881\n _Toc4560739\n _Ref527366894\n _Toc4560740\n _Toc4560632\n _Ref527367092\n _Toc4560741\n _Toc4560633\n _Ref527374577\n _Toc4560742\n _Ref527374584\n _Toc4560743\n _Ref769082\n _Toc4560634\n _Ref527374715\n _Toc4560744\n _Toc536519392\n _Toc536519393\n _Ref838751\n _Toc4560635\n _Ref527375128\n _Toc4560745\n _Ref527375250\n _Toc4560746\n _Ref527375260\n _Toc4560747\n _Toc536519428\n _Toc536519429\n _Toc536519430\n _Toc536519431\n _Toc536519432\n _Toc536519433\n _Toc536519434\n _Toc536519435\n _Toc536519436\n _Toc536519437\n _Ref154461\n _Toc4560636\n _Toc4560637\n _Ref1537016\n _Toc4560638\n _Ref1958836\n _Toc4560639\n _Toc468869313\n _Toc468868727\n _Toc293499079\n _Ref2568685\n _Toc4560640\n _Toc4560641\n _Toc4560642\n _Toc4560643\n _Hlk167798\n _Ref1705947\n _Toc4560644\n _Toc4560875\n _Ref401041103\n _Toc401143469\n _Toc415218323\n _Toc501528706\n _Toc4560876\n _Hlk164333\n _Ref527449901\n _Toc4560877\n _Toc4560645\n _Ref527450526\n _Toc4560748\n _Ref1705375\n _Toc4560646\n _Ref1705969\n _Ref2568721\n _Toc4560647\n _Ref1875869\n _Toc4560648\n _Hlk531168352\n _Hlk531168265\n _Ref163145\n _Toc4560749\n _Ref531167746\n _Toc4560878\n _Hlk531168654\n _Ref2043743\n _Toc4560750\n _Ref533157116\n _Ref1452407\n _Toc4560649\n _Ref166266\n _Ref1888678\n _Toc4560751\n _Ref531169613\n _Toc4560879\n _Hlk527378769\n _Ref1876073\n _Toc4560650\n _Ref168876\n _Toc4560752\n _Ref531170715\n _Toc4560880\n _Ref1876241\n _Toc4560651\n _Ref172070\n _Toc4560753\n _Ref531174952\n _Toc4560881\n _Ref1452872\n _Toc4560652\n _Toc4560653\n _Ref172715\n _Toc4560754\n _Ref531174997\n _Toc4560882\n _Ref1705210\n _Ref1888097\n _Toc4560654\n _Ref1453117\n _Ref1708186\n _Ref2307103\n _Toc4560755\n _Ref2399260\n _Toc4560756\n _Ref2396596\n _Toc4560883\n _Ref2405228\n _Toc4560757\n _Ref2407697\n _Toc4560884\n _Ref2408609\n _Toc4560885\n _Ref2409107\n _Toc4560886\n _Ref2409935\n _Toc4560887\n _Ref2410292\n _Toc4560888\n _Ref2414196\n _Toc4560889\n _Ref2414198\n _Toc4560890\n _Ref2415690\n _Toc4560891\n _Ref2415698\n _Toc4560892\n _Hlk2564315\n _Ref2564922\n _Toc4560655\n _Ref174366\n _Toc4560758\n _Ref531175014\n _Toc4560893\n _Ref2047517\n _Toc4560656\n _Hlk232714\n _Ref954646\n _Toc4560657\n _Ref1871993\n _Ref1876610\n _Ref1889397\n _Toc4560658\n _Ref240659\n _Toc4560759\n _Ref531175204\n _Toc4560894\n _Ref241108\n _Toc4560760\n _Ref531175221\n _Toc4560895\n _Ref1872397\n _Ref1876741\n _Ref1889432\n _Toc4560659\n _Ref243700\n _Toc4560761\n _Ref531175253\n _Toc4560896\n _Ref1873203\n _Ref1876887\n _Toc4560660\n _Ref248982\n _Toc4560762\n _Ref531175298\n _Toc4560897\n _Ref255228\n _Toc4560763\n _Ref531175315\n _Toc4560898\n _Ref1877781\n _Toc4560661\n _Ref330215\n _Toc4560764\n _Ref531176343\n _Toc4560899\n _Ref1877844\n _Ref1889625\n _Toc4560662\n _Ref256037\n _Toc4560765\n _Ref531175334\n _Toc4560900\n _Ref1873479\n _Ref1874063\n _Toc4560663\n _Ref2404600\n _Toc4560901\n _Toc4560664\n _Ref322510\n _Toc4560665\n _Ref234568\n _Toc4560766\n _Ref531175105\n _Toc4560902\n _Ref1879346\n _Toc4560666\n _Ref235328\n _Toc4560767\n _Ref531175127\n _Toc4560903\n _Ref1708391\n _Toc4560667\n _Ref236530\n _Toc4560768\n _Ref531175136\n _Toc4560904\n _Ref346786\n _Toc4560668\n _Ref237068\n _Toc4560769\n _Ref531175148\n _Toc4560905\n _Ref238354\n _Toc4560770\n _Ref531175165\n _Toc4560906\n _Ref345885\n _Toc4560771\n _Ref531176911\n _Toc4560907\n _Ref239343\n _Toc4560772\n _Ref531175175\n _Toc4560908\n _Ref347016\n _Toc4560773\n _Ref531177047\n _Toc4560909\n _Ref1704385\n _Toc4560774\n _Ref1704524\n _Toc4560910\n _Toc4560669\n _Toc4560670\n _Ref1707219\n _Toc4560671\n _Ref318424\n _Toc4560775\n _Ref531175360\n _Toc4560911\n _Ref321040\n _Toc4560776\n _Ref531175882\n _Toc4560912\n _Ref321495\n _Toc4560777\n _Ref531175914\n _Toc4560913\n _Ref1887490\n _Toc4560672\n _Ref323200\n _Toc4560778\n _Ref531175927\n _Toc4560914\n _Ref1887693\n _Toc4560673\n _Ref331960\n _Toc4560779\n _Ref531175939\n _Toc4560915\n _Ref2565745\n _Ref2565763\n _Toc4560674\n _Ref339996\n _Toc4560780\n _Ref531176467\n _Toc4560916\n _Ref341692\n _Toc4560781\n _Ref531176582\n _Toc4560917\n _Toc4560675\n _Ref410472\n _Ref1454179\n _Ref1455179\n _Toc4560676\n _Ref404323\n _Toc4560782\n _Ref531177210\n _Toc4560918\n _Ref405098\n _Toc4560783\n _Ref531177262\n _Toc4560919\n _Ref406788\n _Toc4560784\n _Ref531177308\n _Toc4560920\n _Ref409247\n _Toc4560785\n _Ref531177363\n _Toc4560921\n _Ref1454440\n _Ref1455403\n _Ref1463746\n _Toc4560677\n _Ref409909\n _Toc4560786\n _Ref531178048\n _Toc4560922\n _Ref411054\n _Toc4560787\n _Ref531178110\n _Toc4560923\n _Ref413381\n _Toc4560788\n _Ref531178183\n _Toc4560924\n _Ref414530\n _Toc4560789\n _Ref531178219\n _Toc4560925\n _Ref418692\n _Toc4560790\n _Ref531178403\n _Toc4560926\n _Ref420690\n _Toc4560791\n _Ref531178447\n _Toc4560927\n _Ref421593\n _Toc4560792\n _Ref531178494\n _Toc4560928\n _Ref531178536\n _Toc4560929\n _Toc4560678\n _Ref1462622\n _Toc4560679\n _Ref767042\n _Toc4560793\n _Ref531180485\n _Toc4560930\n _Ref767820\n _Toc4560794\n _Ref531180543\n _Toc4560931\n _Ref1900860\n _Ref1900899\n _Toc4560680\n _Ref773508\n _Toc4560795\n _Ref531180753\n _Toc4560932\n _Ref775357\n _Toc4560796\n _Ref531180813\n _Toc4560933\n _Ref769671\n _Toc4560797\n _Ref531180672\n _Toc4560934\n _Ref779017\n _Toc4560798\n _Ref531178261\n _Toc4560935\n _Ref531180894\n _Toc4560936\n _Ref531180930\n _Toc4560937\n _Ref1536513\n _Toc4560681\n _Ref2256932\n _Toc4560799\n _Ref1537464\n _Toc4560800\n _Ref2912722\n _Toc4560801\n _Ref1902007\n _Toc4560682\n _Ref782436\n _Toc4560802\n _Ref531180965\n _Toc4560938\n _Ref788198\n _Toc4560803\n _Ref788631\n _Toc4560939\n _Ref1902137\n _Toc4560683\n _Ref788711\n _Toc4560804\n _Ref788734\n _Toc4560940\n _Ref1902640\n _Toc4560684\n _Ref833006\n _Toc4560805\n _Ref531181214\n _Ref531181195\n _Toc4560941\n _Ref835957\n _Toc4560806\n _Ref531181397\n _Toc4560942\n _Toc4560685\n _Ref1642287\n _Toc4560686\n _Ref531181485\n _Toc4560943\n _Ref1640060\n _Toc4560944\n _Ref1877992\n _Toc4560687\n _Ref531181624\n _Toc4560945\n _Toc4560688\n _Ref317971\n _Ref837024\n _Ref839175\n _Toc4560689\n _Ref1707706\n _Toc4560690\n _Ref839663\n _Toc4560807\n _Ref531181652\n _Toc4560946\n _Ref1880624\n _Toc4560691\n _Ref841645\n _Toc4560808\n _Ref841670\n _Toc4560947\n _Ref1625043\n _Ref1625355\n _Toc4560692\n _Ref844620\n _Toc4560809\n _Ref844869\n _Toc4560948\n _Ref2564634\n _Ref1624063\n _Toc4560810\n _Ref1624133\n _Toc4560949\n _Ref1643086\n _Toc4560693\n _Ref846875\n _Toc4560811\n _Ref531181755\n _Toc4560950\n _Ref848233\n _Toc4560812\n _Ref531181842\n _Toc4560951\n _Ref849482\n _Toc4560813\n _Ref849521\n _Ref849514\n _Toc4560952\n _Ref1536524\n _Toc4560694\n _Ref1437408\n _Toc4560814\n _Ref1442743\n _Toc4560815\n _Ref1445219\n _Toc4560816\n _Ref1705980\n _Toc4560695\n _Ref851963\n _Toc4560817\n _Ref531181961\n _Toc4560953\n _Ref852883\n _Toc4560818\n _Ref531182005\n _Toc4560954\n _Ref1705824\n _Toc4560696\n _Ref1876282\n _Ref1889242\n _Toc4560697\n _Ref2047937\n _Toc4560698\n _Ref1614888\n _Toc4560819\n _Ref1614411\n _Toc4560820\n _Ref1891552\n _Toc4560699\n _Ref1900726\n _Toc4560700\n _Ref1880797\n _Ref1883461\n _Toc4560701\n _Ref1626385\n _Toc4560821\n _Ref2048826\n _Toc4560702\n _Ref2040261\n _Toc4560703\n _Ref2568856\n _Toc4560704\n _Toc4560705\n _Toc4560706\n _Toc4560707\n _Toc4560708\n _Toc4560709\n _Toc4560710\n _Toc4560711\n _Toc4560712\n _Toc4560713\n _Toc4560714\n _Toc4560715\n _Ref531866993\n _Toc4560822\n _Toc4560716\n _Ref1450448\n _Toc4560717\n _Ref2040688\n _Toc4560718\n _Hlk1964796\n _Hlk2218785\n _Toc4560719\n _Toc4560720\n _Toc4560721\n _Hlk3984542\n _Toc4560722\n _Toc4560723\n _Toc468868734\n _Toc468869317\n _Toc4560724\n _Hlk2920576\n _Ref531164826\n _Ref531164852\n _Toc4560725\n _Toc4560726\n _Hlk511043959\n _Hlk510766982\n _Hlk510769516\n _Hlk510254866\n _Hlk510771459\n _Hlk510770287\n _Hlk511046497\n _Hlk510770301\n _Hlk511044143\n _Hlk511044307\n _Hlk510773691\n _Hlk510773485\n _Hlk510771235\n _Hlk511044354\n _Hlk510771269\n _Toc4560727\n _Hlk511154591\n _Hlk510269501\n _Hlk510263436\n _Hlk511236227\n _Hlk510271892\n _Hlk511238501\n _Toc4560728\n _Hlk528924630\n _Hlk510771541\n _Hlk511031452\n _Hlk511031479\n _Toc4560729\n _Ref531164891\n _Toc4560730\n _Hlk511237965\n _GoBack ",
    "text": " Data BAsed Procurment Methods v3f.pdf Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Using Database and Workflow Methods \nfor Statutory and Regulatory Acquisition \nDocuments The MITRE Corporation \nJuly 23, 2018 \nVersion 0.3 \nApproved for Public Release; Distribution Unlimited. \nPublic Release Case Number 18-2212 This technical data deliverable was developed using contract funds under Basic Contract No. W56KGU-18-D-0004. Sponsor: Naval Surface Warfare Center, Office of the Chief Technologist Officer MITRE Dept. No.: P631 Contract No.: W56KGU-17-C-0010 Project No.: 0718V190-RT MITRE Document #: MTR180165 The views, opinions and/or findings contained in this report are those of The MITRE Corporation and should not be \nconstrued as an official government position, policy, or decision, unless designated by other documentation. All rights reserved. McLean, VA iii iv Table of Contents \n Introduction \nFigure 4-1 Occurrence Count of Data Types for a Draft Electronic Acquisition Strategy \nFigure 5-1 Sample E-TEMP Data Record \nFigure 5-2, Sample E-TEMP Data Input Form \nFigure 7-1, Sample Cybersecurity Strategy Program Summary Data Input Format \nFigure 8-1 Summary Phasing Plan, Automated Procurement Documents and Workflows \nFigure 12-1. RTI Process Overview, its standard structure and its phased structure. \nFigure 12-2, Schedule Comparison, Legacy Program Timeline and RTI \nTable 3-1, RTI Acquisition Plan Appendix, as a Data List. \nTable 8-1 STATUTORY Acquisition Requirements and Recommended Data-Based Streamlining Strategy \nTable 8-2 REGULATORY Acquisition Requirements and Recommended Data-based Streamlining Strategy \nTable F-1, T&E Master Plan (TEMP), as a Data List. \nTable E-2 Life Cycle Sustainment Plan, Key Data Elements and Types \nTable E-4 LCSP Analysis Method Data Elements and Types \nMITRE is assisting the Chief Technology Officer (CTO) of the Naval Surface Warfare Center (NSWC) in developing rapid procurement methodologies to allow it and the Naval Undersea Warfare Center (NUWC) to execute a more rapid technology development and procurement in support of material solutions for emerging naval program needs. When creating a new program, the drafting and signature review of regulatory and statutory documentation to support the milestone review process is a major schedule driver. Each documents content contains a significant amount of common information and a small set of information of interest only to the applicable community (contracts, systems engineering, test, cybersecurity, etc.). Based on experience creating the Rapid Technology Insertion (RTI) process, it seems possible that using database and workflow methods for statutory and regulatory documents can dramatically accelerate technology development and procurement. This report documents an analysis task that MITRE started to as an effort to convert RTI project-specific appendices for the Acquisition Plan to an online format. This analysis was subsequently expanded to include using databases and workflow techniques for the other major acquisition documents. Background \nThe accelerating pace of technological change in modern warfare poses an ongoing critical threat to joint forces and a challenge to naval programs in particular. The Navy must be able to rapidly identify, develop, and field new mature technologies into its systems to ensure their continued operational effectiveness. At a recent DAU symposium on training for acquisition professionals, Ms. Ellen Lord, Undersecretary of Defense for Acquisition and Sustainment, made two significant points: Program Managers need to bring data to decisions. What data and metrics do we have  what does the data/trends tell us? Opinions are interesting, but irrelevant. Need good data engineers/analysts. SCO, DIUx, JIDO, and other organizations popped up because 5000.02 didnt do what \nwe needed it to do Starting as early as 2005, the Navy has been moving to a tiered model where the acquisition of subsystems, component technology products, and functionality is procured separately from the large system integration contracts. Over the last several years this has led to various projects, including Small Business Innovative Research (SBIR) projects, Rapid Innovation Fund (RIF) procurements, multiple individual competitive procurements, and Rapid Capability Insertion Projects (RCIP). In most of these cases the procurement approval and Request for Proposals (RFP) have been custom built for each procurement In 2017 the Deputy assistant Secretary of the Navy (DASN) for Research and Engineering (R Distribution Unlimited. Public Release Case Number 18-2212 defense acquisition, including the Rapid Technology Insertion approach for contracting. The RTI process uses a pre-defined set of procurement documents, and shorter template documents, to take the unique amount of information that a program office needs to define a procurement and shrink it into discrete slices of data. The convergence of template use and supplemental appendices with key data, and a request for data driven oversight and management by OSD and DASN leadership, create an opportunity to test the use of data based tools and methods in lieu of the extensive list of paper plans and reports historically used within the Defense Department. This report provides preliminary analysis and findings regarding that shift from piles of paper into files of data. RTI Template Acquisition Plans, Project Appendices, and the \nElectronic-AP Historically, and following the instructions in the DoD 5000.02 instructions for acquisition, a program office would develop their own acquisition plan that describes their problem and planned contracts. Most large programs use a program-based document model, since that allowed them to describe the program once in the front and then add appendices for each procurement. A procurement based model for the program would involve writing several plans, each with a separate approval process, taking between several months and a year or two of schedule and effort. In 2014 the PEO for Littoral Combat Ships (PEO LCS) developed an experimental approach to allow program offices to rapidly procure mature technology products using a standard pre- approved Acquisition Plan (AP) and RFP template package, customized for each project via specific appendices to instantiate the project and request proposals. The templates for the RTI process focus on the program data that is different for each program, which ended up being quite compact. In order to move projects quickly, and simplify the amount of paperwork that needs approval, the RTI process adopted the use of a flipped business model, where a standard procurement process is documented in the Acquisition Plan, and then appendices are used to instantiate the acquisition for each project. By applying this model across an enterprise however, a standard approach is endorsed, and the amount of customization needed to instantiate the program is relatively simple. This allowed the use of a short 3 or 4 page appendix for the program office. When this approach was tested on the RTI process it took about 10 months to develop the overall AP but then only 2 weeks to route and approve the appendix for the first project. The RTI process is further described in Appendix A. The AP appendix format is shown in Appendix B of this report, and includes all of the project specific items needed to supplement the RTI AP. 3.1 Adaptation to a Data Base Format In analyzing the appendix of the RTI Acquisition Plan it becomes evident that now the contents of that plan is essentially several dozen pieces of information that can be adapted into a data base type format. In some cases the data record used is a name, in some cases it is a number or a date. In several cases the data field is a free-text paragraph, which allows managers to still provide explanatory information as needed. The data fields adapted from the RTI Appendix are shown Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 below in Table 3-1. As seen in this listing, the conversion of an acquisition plan into data includes not only the planning dates of a normal plan but a second set of data for actual accomplished dates, which allows for tracking of status and durations for approval timelines. Conversion of the Acquisition Plan into data starts to achieve several objectives. a) It allows use of automation tools such a Sharepoint or Web Logic in order to accumulate \nthe data associated with the program, b) It enables the use of automated workflow based tools to route the procurement plan for \napprovals, which allows tracking and status data to accumulate. This in turn allows leadership insight into how long these documents take to approve. c) It enables backward looking data analytics, so that analysis can determine traits of \nsuccessful programs. These achievements in turn will allow leadership to obtain data-driven answers to such questions as what do successful programs have in common, or what do unsuccessful projects have in common. Statistical correlation techniques can be leveraged to provide strategic oversight and statistical process management. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Table 3-1, RTI Acquisition Plan Appendix, as a Data List. Title Data Type Title Data Type AP Appendix # Text 9.1a Funding Years (List 5 Years) Date Project Title Text 9.2a RDT Distribution Unlimited. Public Release Case Number 18-2212 3.2 AP Material Not Contained in the Data Base For the AP, the data base record is formed using the RTI appendix. For the RTI AP the more descriptive text describing the process was kept in a text file, while the data of
a particular program resides in a data base file. Thus the large template AP contains a significant amount of descriptive text on the how part of the contracting and acquisition, which is not included in the data base. This separation works well for the AP, as that document contains not only project data but also process descriptions. The repetitive process text and project data was already separated into two sections when the RTI process was created. This pattern, or template, could also be applied to other procurement documents that contain a significant mix of data and process text. An example of a subsequent document that may follow this same pattern is the Systems Engineering Plan (SEP). In other documents that were subsequently analyzed, there was a mix of data and information that was retained and information that is recommended for discontinuation. 3.3 Additional Data Needed to Make Effective Decisions As stated, the data base record for the AP is taken from the RTI appendix. In the initial version of this data record an additional set of data has already been added, which is the actual dates for procurement events. This will allow backward-looking analysis to monitor and review approval times. The automated Sharepoint workflow records will also provide a useful record of approval dates, but the date data needs to be captured in the data base in order to do analysis. This will allow oversight executives to review data and answer questions like what is the average creation time for an AP appendix using this method, and what is the average approval time?. This raises the interesting possibility however, on what data is missing from an AP template? What questions would leadership like to ask about the new data-driven process as it starts to run, or on an annual basis, or after 5 years? Once those questions are identified, then the data base can be reviewed to see whether the proper data is included, and if not then it can be added (as long as the cost of gathering that data is considered less than the value in answering the question). A selection of possible strategic questions that might be useful are: a) How long does it take to create and approve a data-based AP? How does that compare to \nlegacy documents? b) What is the average total contract value being created in the new process? \nc) What is the average unit cost of the technology being procured? \nd) How long is it typically taking to get from start of an AP to successful system test? \ne) What is the percentage of achievement in primary engineering measurement parameters? \nf) What is the percentage in achievement in secondary engineering measurement parameters? g) What is the average size of the basic RTI contract award for phase 1 studies? \nh) What is the average over or under-run of the assessment/engineering phase of the RTI contracts when completed? [note additional cost at completion data needed] i) How many times are the systems integration collaborators in place on day-1 when the \nbasic RTI contract starts? [additional data needed] Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 An executive oversight review team should be leveraged to develop the types of questions that they would like to ask. This might be done by handing out index cards to each of them during a steering team meeting and asking them to write down 3 questions that they would like to consider as the process continues. Then those questions can be similarly analyzed. This should be done with other relevant stakeholder groups on each of the documents being converted to a data base approach during the pilot program. The Electronic Acquisition Strategy \nThe Acquisition Strategy was converted into a data based format in a similar manner. The AS contained a large amount of information that is specific to a program, and thus could not leverage the template approach like we did with the RTI AP. Sample screen captures of the E- AS data entry form is shown below in Figure 4-2. For the E-AS the textual data was converted into distinct data fields to capture useful data that could then be searched or tested. This helped reduce the amount of Free Text fields and should provide a more useful data base to DoD leadership. This data set should be reviewed at the end of a pilot program in order to test its utility and completeness. Additional data may be needed in some cases to provide a more rich and useful data base. The Yellow and Blue sections of the data set represent sub-tables of data that are repeat several times for a single program, for waivers to policy and RF signatures. These two would need to be created in a separate record with a unique key that associates the data to a program. A subset of the data, fields, the series numbered 7 to 11, is actually repeated with data in the Acquisition Plan, thus can be automatically filled in from that data. The 100 series of field numbers was chosen for the E-Acquisition Strategy data. The quantity of each data type used in the E-AS data base is shown in Figure 4-1. The actual data fields are provided in Appendix C of this report, as we will be covering this approach for several more documents and the detail fields will evolve as the pilot program tests them. Review of the E-AS data records indicate that essentially all of the Acquisition Strategy information has been captured, although some of the data fields represent an amount of data that was considered useful and required. Similar to the other data sets, this data should be used in a pilot program, tested for completeness by reviewing leadership questions, and tested for utility in case some of it is not being used and thus its collection could stop. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Figure 4-1 Occurrence Count of Data Types for a Draft Electronic Acquisition Strategy Row Labels Count of Data Type Currency 34 Currency/Sum 1 Date 29 Email 5 Link 5 Number 15 percent 6 Pulldown 11 Text 99 Y/N 8 Yes/No 27 (blank) Grand Total 240 Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 The Electronic-TEMP (E-TEMP) \nThe Test and Evaluation Master Plan (TEMP) is another primary acquisition document, and is required by law (statute) for all sized ACAT programs prior to even a Milestone A decision to start a program. The TEMP also serves instead of the Acquisition Strategy (AS) document for ACAT-4 and below sized programs. Again, historically, and following the instructions in the DoD 5000.02 instructions for acquisition, a program office would develop their own TEMP for each program that describes their problem and planned testing, working with stakeholders from the PEO, COMOPTEVFOR OPNAV, and OSD/DOT&E (all of which need to approve the document). There is only a program-based model for the TEMP, so there is no need to try to flip the document model. However, we analyzed the TEMP to assess the amount of data type information that it contained, compared to the amount of process type text. At this point, as the data base already contains the project data of the E-AP, we also analyzed the data to see what was repetitive of data provided by other documents. 5.1 Adaptation to a Data Base Format Looking at what is required in a TEMP, we see a list of 7 general sections, some of which have extensive content in several subsections. Generally the content is lengthy, and oriented towards platforms, not systems. We also see a heavy emphasis on text based content in some sections, and not an approach that collects data. The content also lacks a requirement to show and discuss human subject testing plans, which is commonly required in university and NSF grant proposals. An abbreviated summary of the TEMP content required by ADDM 5000.02 is listed below. 1) Intro: Purpose, Mission description, System description 2) Test Mgt and Schedule: Roles, Database Info, Deficiency reporting, Updating, IT&E \nSchedule 3) T&E Strategy: DT & OT Objectives, Evaluations, Framework, DT Eval approach \nSummary, R&M, Performance, CTPs (Risks, Certs, issues, Objectives, M&S, limitations), Live Fire T&E (approach, objectives, M&S, limits), IOT&E Cert, OPEVAL Approach (schedule, COIs, Objectives, M&S, limits), Other Certs, Reliability, Future T&E. 4) Resource Summary: Intro, Test Articles, Sites, Equipment, Threat, Expendables, Op. \nforces, M Distribution Unlimited. Public Release Case Number 18-2212 Test Plan Content Per DI-NDTI-80566A: 1) Title Page / Admin info \n2) Introduction \n3) Flow Diagrams Describe testing via block diagrams \n4) Milestones (Schedule) Start and completion dates. \n5) Participation Govt. and Contractor roles. \n6) Location of each test event \n7) Schedule When testing occurs. \n8) Security measures \n9) Master Test List Test, location, Spec used, Parameters, Special tests, Functional area, Objectives, Equipment, Support equipment, special test equipment, approach, Instrumentation, data to be recorded, Government facilities. In reviewing the outline of the TEMP and a contractors project test plan, we can make
several observations. The TEMP document is a forward-looking planning process, and does not support \ncollecting statistics and monitoring cost, schedule, or technical success after it happens. Test plans per DID-NDTI-80566 appear to force organizational planning and help \narrange Government support when required. TEMP content appears oriented to full EMD product development and test (e.g. R&M), \nbut would not apply to a rapid prototype project. Parts of the TEMP content contain tables of data that are well suited to adaptation by a \ndata base. Example of this include: range days and type needed, which M Distribution Unlimited. Public Release Case Number 18-2212 series was chosen for the TEMP data in order to help uniquely identify it. The detailed data fields for the E-TEMP are provided in Appendix D. In order to fully cover the required planning content, the initial primary TEMP data list contains over 340 data fields (rows above, or columns in a Sharepoint list). This indicates that the practical size limits of a data base may become a concern. As hundreds of these fields are free text that could be several kilobytes large, the long term integrity of the data base will be a concern as the number of projects grows. This indicates the eventual need for a larger industrial- strength data base in order to handle more than the few dozen projects being considered for the initial pilot programs using data-driven tools. Another option might be to have different repositories or lists for different PEOs, with data-scraping scripts or manual data collection used to aggregate the data and allow back-office type analysis at the Navy-wide (or DoD-wide) strategic level. Using existing enterprise software infrastructure tools, however, could allow the Navy or DoD to implement this type of management tool quite rapidly, using existing staff, without the need for a new MAIS program. Such an approach could even implement a data conversion process, whereby existing documents are converted into data, over a 12 to 18 month process. The implementation of the E-TEMP in Microsoft Server Sharepoint is shown below in Figure 5-1 and 5-2. The implementation of the TEMP in a data base will provide DoD leadership with a considerably more powerful tool to help monitor the results of data-driven policy decisions. Figure 5-1 Sample E-TEMP Data Record Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Figure 5-2, Sample E-TEMP Data Input Form 5.2 TEMP Material Not Included in the Data Record For the TEMP, the data base record was formed by examining each section of the DoD instruction on writing a TEMP. This instruction requested a broad mix of data and information, however several sections either duplicated material from the AP or requested material that seemed to have limited value for a smaller project (non-platform) that was being created quickly. Table 5-1 provides details on data items that are either automatically filled-in from other documents or recommended for deletion. This data indicates that the conversion to a data based approach also allows some reduction in effort associated with creating procurement documents, which should allow greater speed. There is also a likelihood that time will be saved when efforts are not being spent on the wording of individual sentences, as the terse data fields are more compact and the formatting is already being strictly enforced via the data ingest tools. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Table 5-1 Data Filled-In from Other Documents or Not Used (See List for Rationale). 201.3.204 Evolutionary details DO NOT INCLUDE. Repeats 201.3.203 and 201.3.01b 202.4a <TEMP_Update_Tempo> Not used. FASTLane projects are 1-shot per iteration. 203.1 <TE_Strategy_Summary> Not used. Details are in subparagraphs. 203.11 <DT_OT_Objective_Summary> Not used. Details are in subparagraphs. 203.3015 <System_Performance_Aspects> Not used. Duplicates Matrix above and Objectives below. 203.3016 Not used. Duplicates Matrix above and Objectives below. 203.3019 <Technology_not_achieved> Not used. Duplicates Matrix above and status info for each MOE 203.30110 <Design_Stability> Not used. Duplicates Matrix above and status info for each MOE, RGT, and ILS combined. 203.30111 <Key_Issues_and_Scope> Not Used. Duplicates data of 203.3013. 203.310 <Mission_Employment> Not Used. Duplicates info of 201.2 203.311 <Design_Influence_of_Evaluation> Not used. Fastlane projects are for mature tech, not R Distribution Unlimited. Public Release Case Number 18-2212 5.3 Additional TEMP Data Needed for Effective Decisions Similarly as discussed for the AP, the conversion to a data-based approach to procurement management also allows the addition of data fields in order to ask and answer questions about a program or all programs, over a regular time span (e.g. the next quarter) or a long time span (e.g. the last 5 years). An example of data that could be added is the actual dates for test events. Adding this data would allow backward-looking analysis to monitor schedule success. This will allow the executive oversight steering team to review data and answer questions like what test events have not occurred that were supposed to, or what factors correlate to missed schedule events?. It is equally important for the acquisition command and the DT&E leadership to identify the types of questions that they would like to ask regarding T&E events. Once those questions are identified, then the data base can be reviewed to see whether the proper data is included, and if not then it can be added (as long as the cost of gathering that data is considered less than the value in answering the question). A selection of possible strategic questions that might be useful are: a) What DT and OT events are happening in the next quarter? \nb) Which DT and OT events just happened? Did they go well? \nc) When do DT and OT events happen, and is there a pattern during the year? \nd) Are test ranges used evenly throughout the year? \ne) How long does it take, on average, to get a test report completed after a test? \nf) Is the number of test days used typically more or less than the number of test days planned? g) What is the cost of a test day at each of the ranges, and why are they different? If the executive oversight steering team develops an expanded list of questions that it is interested in, then those questions can be similarly analyzed and if needed, additional data fields can be added to the proposed E-TEMP data base. 5.4 Evolving Data and Analysis of a Sample TEMP paragraph As seen in table 4-1, the bulk of the data fields are identified as Text, as the instructions for that paragraph requests a complex description of something. As an example of what comes back, this is a sample paragraph from a recently approved TEMP. As discussed earlier in this TEMP (Sect. x.x.x), the XYZ program is measuring Mean Time Between Critical Operational Mission Failure (MTBCOMF) in order to distinguish between failures that can be quickly repaired and do not disrupt the mission and failures that exceed the MTTR and cause an impact to success. The program is also assessing material availability (Am) by analysis using measured test metrics because that is the parameter used in the Capability Program Document (CPD). Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 This System of Systems (SoS) approach, documented in the Reliability, Availability, Maintainability Cost (RAM-C) Plan, details how the program will demonstrate the Am KPP and the operations and support (O&S) ownership cost KSA. The SoS methodology includes assessment of Program XYZ sustainment plans as well as the RAM/ sustainment capabilities of the subsystems as integrated into the top-level mission profiles. The methodology includes use of a top-down approach to meet system requirements, identify and adjudicate gaps, and allocate additional requirements such as reliability to the participating programs. From this textual paragraph, we then try to identify the specific relevant data and information, which results in: 1. MTBCOMF as a parameter being measured \n2. Am as a parameter being measured - derived from the CPD \n3. There is another document with Am as a KPP \n4. There is analysis to demonstrate the Am KPP From this list, we can try to develop data fields to replace the current text-based paragraph. The E-TEMP already includes a table of critical requirements, that are filled in by the program team, which contains these data fields: 203.24a Eval_Matrix_Key_Requirement 203.24b Eval_Matrix_Crit_Op_Issue 203.24c Eval_Matrix_MoE_MoS 203.24d Eval_Matrix_CTP_name 203.24e Eval_Matrix_CTP_Value 203.24f Eval_Matrix_Test_Method 203.24g Eval_Matrix_Key_Resource 203.24h Eval_Matrix_Decision_Supported 203.24i Avail_at_next_MS 203.24j CTP_Status 203.24k Eval_Matrix_Data_Source_Link This appears to provide the type of fillable data row to include MTBCMF and Am as parameters. The depth of explanation being provided is insightful, but takes time to create, review, clarify, and approve. These items were based on section 3.2.4 of the TEMP instruction and Table 3.1 of that section, the Top Level Evaluation Framework Matrix, and appear to completely cover the data of that table. Although the data fields listed above describe the content of the Table, when comparing them to the sample text, we see a few things: 1) The KPP heritage isnt clear, \n2) The CPD lineage isnt clear, and \n3) There is no
data field available to enter the actual data once the test is over. From a data tracking perspective, it is important to not only enter the planned value or objective, but the value that is actually achieved. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 As discussed previously, phrasing strategic questions about the data helps to consider whether the data set is sufficient to answer those question, and therefore identify what additional data might be necessary that was not collected or identified previously. Examining the sample text and data fields, we can hypothesize the questions that might be important, and then check to see if the data supports them. For a single program, we might ask: a) How long are the missions for this system? \nb) What is the mix of easily fixable problems vs Critical mission failures \nc) What is the overall down-time for the mission from this MTBF and MTBCOMF? \nd) What levels are being achieved now, compared to the value projected or planned? \ne) Has there been a change in the projected or tested value since the last report? Overall the data is not fully supporting these questions, as the change since last report is not included, and the level being achieved is not tracked, only the planning value that is expected. Reviewing at the sample text, and imagining that the data for dozens or hundreds of programs is available, we can ask a different set of questions, such as: a) What are the common program data types or values that correlate to the programs that are \nnot achieving their expected value? What makes some programs more likely to not meet their objectives at a significant level or manner? b) What is the overall trend over several years in achieving projected values? \nc) How do programs or users compensate when projected values are not fully achieved? \nd) Did programs that didnt meet their thresholds know that was coming? If so, what were they doing about it? Based on these questions, then we can add data fields, as long as the additions do not seem too onerous or expensive to collect. Fields that might be added here include: a) Change in value since the last reporting. \nb) Actual Performance Achieved. \nc) Standard deviation for the key parameter. \nd) Actions taken to correct negative trends. This analysis is possible for every paragraph of these major procurement plans and documents, and could help move each text based response away from a set of long descriptive sentences and into a set of data fields that will provide the answers to key questions, often phrased as the W questions. These are why, what, who, when, which, where, and how. This could cause a significant increase in the number of data fields, but also allows comparative analysis of the project from a data and metric perspective. For the near term, the first step is to move away from piles of paper and documents files in a smooth and easily understood manner, and shift toward files of data. For this to happen in a smooth manner, and to allow project using data base methods to start using a new process soon, the methodology should be familiar and easy to understand and transition. This implies that blocks of text type responses are preferred at this time. In the long term, perhaps starting FY20, Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 other community stakeholders should be consulted in moving additional text fields into data type responses where appropriate, and identifying new report formats to capture a subset of text in a short and condensed manner that makes sense. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 An Electronic Life Cycle Sustainment Plan (E-LCSP). \nThe Life Cycle Sustainment Plan (LCSP) was also analyzed to consider the utility in shifting to an electronic data-based format. The LCSP is actually very amenable to this shift, as it primarily consists of tables of data in each section. This allowed a relatively rapid assembly of a prototype E-LCSP that can be packed into a data based form. The results of the conversion for the program-based are shown in Appendix E. Several data fields were also created from the LCSP instruction that were subsequently identified as either redundant or less valuable if a data based approach is being used, which are also shown in Appendix E. The LCSP also requires key data sets be provided for lower-level components and then again separately for each analysis method used. These are also shown in the Appendix. Like the TEMP, this leads to nested tables, which are accomplished by a unique code for each project. One possibility for this unique identifier is to use the budget Program Elements, then add an additional key code to that. Other examples might be a T Distribution Unlimited. Public Release Case Number 18-2212 Figure 6-1 Sample Life Cycle Sustainment Plan Data Input Form Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Cybersecurity Strategy & Program Summary \nThe Cybersecurity Strategy and its attached Program Summary was also converted into a data base format to asses sits functionality in a data base schema. The summary report is document is a 3 page checklist of yes /no data, and relatively simple to convert to a data base format. The header for each data field, however, was very lengthy and had to be shortened to allow simple tracking in a Sharepoint list, as that is always shown in a horizontal manner, not a vertical manner. The resulting data ingest form however, was modified to include the full header text as an instruction, as shown in the Figure 7-1. For this data the 91x series of indices was chosen. Figure 7-1, Sample Cybersecurity Strategy Program Summary Data Input Format Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Other Acquisition Documents \nThe AS, AP, TEMP, LCSP, and Cyber Security Strategy are the primary acquisition authorization documents to start a new program of record, after which an Acquisition Program Baseline and Acquisition Decision Memorandum are created. In order to minimize the amount of planning to a minimum level for projects that are supposed to be moving quickly, it is advisable to minimize the number of plans and documents needed for a new program using data- base methods. The Defense Acquisition University (DAU) provides an online tool that indicates which documents are needed for to authorize a program of record. This was converted to a static Excel File, and is shown below in Table 8-1. Some of these documents are not applicable to certain projects (e.g. the Spectrum Allocation document, which probably do not apply to a logistics software project). Those that are less common should be reserved to last place in efforts to create streamlined methods. The documents that apply to almost all of the projects, such as a Test Plan, were emphasized. A pilot program using data-driven methods could start as soon as the summer of 2018, in which case not all methods can be re-invented that fast, and even if they could the ongoing efforts to adjust, help users, solve problems, and test utility will all take time and imply a limited number of data driven conversions in the near term. Each of these documents was assessed for whether they should be converted to either a data-base method or a common template document method (e.g. RTI AP), and whether that should occur in the initial pilot program (phase 1 use) or later in a fully implemented system (aka phase 2 use). The results of this analysis for the STATUTORY requirements are shown in Table 8-2, and the results for the REGULATORY requirements are shown in Table 8-3. As seen, by leveraging the AS, AP, LCSP, TEMP, and Cyber plans in a data driven mode, all of the data needed to create a program of record are captured. The recommended approach includes phased implementation of program workflows for both data-based management methods and automated routing of legacy type documents, primarily those of external organizations. Table 8-1 below provides the phasing of the recommended implementation for creating automated data-based versions of the required statutory and regulatory program documents. Of the 9 phase-w workflows, 3 have already been prototyped, and three of the remaining items are quite small (the acquisition program baseline, the decision memorandum, and the exit criteria). This leaves the AS, Cybersecurity Strategy, and RFP appendix as still requiring data base list and workflow design efforts. The workflows created to route a legacy style document (uploaded as an attachment) is also quite minimal. Phase 1 SP/WF Phase 1 SPWF Routing Phase 2 SP/WF Phase 2 SPWF Routing Statutory Requirements 3 3 1 1 Regulatory Requirements 6 0 2 9 Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Figure 8-1 Summary Phasing Plan, Automated Procurement Documents and Workflows Table 8-1 STATUTORY Acquisition Requirements and Recommended Data-Based Streamlining Strategy STATUTORY Statutory requirements cannot be waived unless the statute
permits. Lowest ACAT App. FASTLane Strategy Phase 1 SP/WF Phase 1 SPWF Routing Phase 2 SP/WF Phase 2 SPWF Routing 2366A WRITTEN DETERMINATION 201 1C1D N/A, FL not app to MDAP 2366B CERTIFICATION AND DETERMINATION 1 1C1D N/A, FL not app to MDAP ACQUISITION PROGRAM BASELINE (APB) 3 4 Automate Sharepoint Workflow 1 ACQUISITION STRATEGY 4 4 Automate Sharepoint Workflow 1 ANALYSIS OF ALTERNATIVES (AoA) 6 4 Allow deferral to RTI Phase 1 or 2 (multiple award). BANDWIDTH REQUIREMENTS REVIEW 8 (IT, MDAP & MAIS) 4 BENEFIT ANALYSIS AND DETERMINATION (Part of Acquisition Strategy) 9 4 Part of AS CLINGER-COHEN ACT COMPLIANCE 15 (MAIS / IT programs only) 4 Incorporate into AS CONSIDERATION OF TECHNOLOGY ISSUES (Part of Acquisition Strategy) 16\n4 Part of AS CONTRACT-TYPE DETERMINATION (Part of Acquisition Strategy) 17 1C1D Part of AS COOPERATIVE OPPORTUNITIES (Part of Acquisition Strategy) 18 2 Part of AS CORE LOGISTICS DETERMINATION / CORE LOGISTICS AND SUSTAINING WORKLOADS ESTIMATE 19 1,2,4 Part o fLCSP CYBERSECURITY STRATEGY 22 4 Automate Sharepoint Workflow 1 DOT Distribution Unlimited. Public Release Case Number 18-2212 \nTable 8-2 REGULATORY Acquisition Requirements and Recommended Data-based Streamlining Strategy. Green = Potential Workflow Automation Opportunities. Grey = Part of AS, Blue = Part of LCSP. ADDITIONAL Regulatory MDAs may tailor regulatory procedures consistent with sound business practice and the risks associated with the product being acquired. Acquisition Decision Memorandum (ADM) 2 4 Automate Sharepoint Workflow 1 Affordability Analysis 5 4 Incorporate into AS. AoA Study Guidance and AoA Study Plan 7 4 Waive for FL. Could be automated into SPWF. Capability Development Document (CDD) 12 4 OPNAV Document. One of many validated requirements doc. Capability Production Document (CPD) 13 4 OPNAV Document. One of many validated requirements doc. Concept of Operations/Operational Mode Summary/Mission Profile (CONOPS/OMS/MP) 2115 4 Automated ROUTING Sharepoint Workflow (OPTEVFOR Doc) 1 Cost Analysis Requirements Description (CARD) 21 1 Automated ROUTING Sharepoint Workflow (OPTEVFOR Doc) 1 Defense Intelligence Threat Library (Threat Modules) 73 4 Intel Document. One of many validated requirements doc. Development RFP Release Cost Assessment 23 1 Automate Sharepoint Workflow Single Cost Doc. 1 DoD Component Cost Estimate 24 1 Automate Sharepoint Workflow Single Cost Doc. DoD Component Cost Position 25 1 Automate Sharepoint Workflow Single Cost Doc. DoD Component Live Fire Test and Evaluation (LFT Distribution Unlimited. Public Release Case Number 18-2212 Online Web Access and Data Base Tool Options \nThe team working at MITRE used Sharepoint as an initial prototyping tool for this study because it is being widely used for this type of purpose at MITRE and other commercial Corporations and it is already on the Navys NMCI enterprise environment and available to every user at NAVSEA. Other options for implementing this type of data base functionality are platforms like Infusion/Confluence/Jira or MySQL or Web Logic. These tools are being investigated. There are several factors that are involved in creating data base tools for an enterprise, primarily functionality, size and scalability, simultaneous access, and security. For the immediate near term use the Microsoft Sharepoint platform provides the required functionality (data type enforcement on entry, logic testing when creating views, access to the Navys Outlook email directory services and automated email). Whether the software needs to support a large number of projects (e.g. several PEOs) or a small number (e.g. only pilot program use) is an important consideration. For eventual enterprise level use, Sharepoint may have size limitations however, as the file is essentially a large flat-file structure. Creating subfolders for each PEO would solve the size limitation, while still allowing the creation of integrated reports at the enterprise level. Connectivity to a SQL data base would also solve the size limitation issues, and allow improved security and replication (data durability). The Confluence/Jira tools may require more extensive operator efforts to create this type of online repository, and are designed to create online documents, not collect data online. Sharepoint Lists are designed to collect data online, but in small quantities. These types of environments have both had reported security issues when the data bases were not locked down properly. For some of the acquisition documents, such as the Acquisition Plan, we leveraged a standard template and appendix, and focused on adapting the appendix into a data base. In the future it may also be possible to leverage this approach for other documents, providing greater efficiency. Other documents, such as the TEMP and LCSP, were already more data focused and were easily adapted. The draft schema provided in this report can evolve through testing in the pilot program. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 An Expert Assistant for Project Planning and Reviews \nThe shift towards data driven project management tools should also allow project managers the ability to do improved project planning. This can be done three ways: a) The project initiation tool can provide helpful guidance in the instruction on how to structure certain milestones, based on the new structures being put into place to support the data-based acquisition process. b) The project initiation tool can provide an ongoing running average of schedule durations for certain steps, such as data-based project AP approvals, so that a project engineer or manager can see how long certain actions are currently taking and allow a similar time span. (the executive oversight steering Team will also have access to these metrics to monitor progress, set goals, and attempt corrective actions to speed schedule activity). This would require that the planning tool be designed to allow a split screen viewing that allowed the input of new data on the left side of the screen, and display of similar to columns for other projects on the right side of the screen. c) Once several projects have started and are being executed, the project initiation tool could allow project engineers and managers to select projects from the data base that are similar to their project, and see how long actions are taking. This might work a lot like the comparison shopping tool on Amazon.com where you can compare the features of several items before deciding on a purchase. The tool could also ask several questions about the project or observe the parameters that are input first, then provide recommendations as to planning actions and schedules based on the data base of previous project. This also suggests that Program Executives and Program Managers could take advantage of such an expert when they are reviewing projects, either during review meetings or in a background manner. The tool could allow them to compare the project to others in a similar manner as the planning module, and compare execution schedules and success. The data base could also be set up to provide email alerts when an ongoing project and an execution parameter passes a certain threshold or misses a critical milestone in a manner that predicts future problems. Such an expert system will help prevent projects from starting out with poorly planned schedules. Many projects miss schedules or have execution issues because their schedule was designed by matching an almost randomly generated budget profile, dictated by a political decision, generated by a contractors marketing presentation, or guessed by a project team struggling to finish a myriad of other tasks and without any sort of data for comparison. The expert system can also provide useful inputs to new teams that are used to the old schedules that took forever, providing useful suggestions and recommended event metrics based on the new approaches being used. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Summary / Recommendations \nAs part of an improved defense business model, Acquisition Strategies, Acquisition Plans, Test and Evaluation Master Plans, Life Cycle Sustainment Plans, Cyber Security Strategy Plans, and the Acquisition Planning Baseline and Decision Memorandum can all be converted to use a data- based management approach. This will allow automated routing of the projects data for approvals, and also captures project data in its elemental form, thus allowing the application of data analytics to support strategic reviews by NAVSEA management. This approach can also be expanded relatively easily to allow data to be captured and re-used for the Requests for Proposals (e.g. product names, reference specifications or drawing numbers, quantities required, period of performance, etc). This approach may not always work for every procurement or major platforms, but could allow rapid actions for a large number of projects. The draft schema provided in this report can evolve through testing in the pilot program. Shifting to a data-based approach to procurement planning and project management at NAVSEA should allow data-based projects to move faster and provide project and management data to senior leadership that will allow metric based decisions and pilot tools that could be used in a larger number of Navy programs. MITRE Recommends that the project data base functionality be tested on several platforms (e.g. Sharepoint and Confluence/Jira), if possible, and assessed for usability and functionality. The technical features of the hosting environments can be assessed and measured or rated, and then a final decision can be
made if the approach is continued or expanded. This report and the prototypes that were created position a team of software developers to build this type of functionality in the current web server environment, in a relatively fast manner (estimated as just a few months). If successful, the pilot program could be expanded on a service-wide or even DoD wide basis. Once the data base is established, data based records for new programs would replace current methods of routing documents for approval. It would also be possible to request programs to convert their current documents to the new system and enter the relevant data, which could be done in a phased manner over 12 to 18 months. This would allow earlier use of data analytics and correlation based statistical analysis. In summary, an electronic data-based version of current defense procurement planning documents should not be just a direct translation of the current reports, since that misses an opportunity to collect certain new data that is critical to creating more valuable management tools. The transition also provides the option or ability to streamline the current documentation, eliminating less useful components like organization charts or graphical schedules that were hard to read, and collects data sets that will allow better planning and comparative oversight using data analytics. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 References/Bibliography \n[1] Defense Acquisition University Milestone Document Tool, https://www.dau.mil/mdid/Pages/Default.aspx [2] Department of Defense Instruction 5000.02, Defense Acquisition https://www.dau.mil/mdid/Pages/Default.aspx Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Appendix A Summary, Rapid Technology Insertion Process \nThe Navy continues to require methods to rapidly adopt and procure mature technology in order to counter evolving and complex threats and implement its adopt/buy/develop strategy to provide new functionality to naval ship combat systems. An Acquisition Plan (AP) has been developed that adopts and improves the Rapid Technology Insertion (RTI) method developed by PEO LCS for use by the Naval Warfare Center enterprise. The RTI process provides for the acquisition of product adaptation and project transition engineering in a broad range of topical areas related to the development of new or upgraded naval warfare capabilities. The RTI method involves the steps as shown in Figure 2-1, which includes the following activities. a) Identification of a problem or need, with a validated technical definition and context. b) Completion of a short RTI Appendix to authorize the procurement action. c) Completion of technical documentation or problem statements and associated GFI. d) A draft RFP is posted, with a request for White Paper responses. e) White papers are evaluated and feedback is provided. f) The Final RFP is posted, and proposals are received and evaluated. g) One or more contracts are awarded, with a firm fixed-price Transition Study as the basic \naward. h) Integration and ship design agent expertise is leveraged to evaluate the project and \nestimate associated resources to complete an integrated solution. i) If multiple awards were made, a down-select to one contract is made, if desired. j) Associated integrator or shipyard agent tasks are created and funded. k) A contract option for the engineering and assessment phase is awarded, and the \ncontractor works with the integrator to develop the technology solution and deliver a test article. l) Government testing is conducted to formally assess the technology or solution. m) If the testing was successful, additional (up to 3 years of) contract options are exercised \nto produce and deliver units. n) Field support is enabled, and preparations are made for follow-on production contracts if \nnecessary. These actions were designed to account for several typical problems and allow most programs to rapidly leverage them and achieve a standard program structure. The process also allows program teams the flexibility to customize the RFP as much as it needs to, although the amount of time needed to review, edit, approve, and process documents will also increase as the level of customization increases. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Figure 12-1. RTI Process Overview, its standard structure and its phased structure. \nUsing the pre-approved standard document approach, the RTI appendix to authorize a project was reduce to just a 3 page appendix, which was routed and approved in just 2 weeks. A sample schedule comparison is shown in Figure 3-1, where the timeline from a trade study, writing an AP and an RFP, and contract award typically take about 3 years. The RTI approach, which folds the trade study into the procurement process and uses standard documents, should take less than 15 months. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Figure 12-2, Schedule Comparison, Legacy Program Timeline and RTI Appendix B RTI Project Appendix Format Distribution Unlimited. Public Release Case Number 18-2212 APPENDIX RTI-tbd RTI Project: Appendix Template FOR OFFICIAL USE ONLY ACQUISITION PLAN NUMBER: NSWC/NUWC 18-01 REV: 0 RTI PROJECT TITLE: ACAT ACQUISITION PROGRAM MANAGER: CODE CAPABILITIES/REQUIREMENTS DOCUMENT: See Section 6 of this appendix. . ACQUISITION STRATEGY APPROVAL: See Section 6 of this appendix. DESCRIPTION OF PROGRAM: See Section 7 of this appendix. APPROVED BY: HCA, PEO, or DRPM (include title) Date Chief of Contracting Office Date Contracting Officer Date Program Manager Date Questions concerning this AP should be referred to Dr. Megan Fillinich, NSWC Chief Technology Officer, at (202) 781-3937, Megan.Fillinich@navy.mil. The cutoff date for information contained in this Acquisition Plan is xx March, 2018. Questions about this specific RTI project should be referred to , at (202) 781-xxxx, @navy.mil. The cutoff date for information contained in this appendix to the RTI Acquisition Plan is 201x. mailto: @navy.mil Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 CHANGE / PROJECT AUTHORIZATION, ACQUISITION PLAN NO. NSWC/NUWC 18-01. Appendix A: Project Specific Appendix for (Insert RTI Topic Name Here ) 1. Topic Name: Provide the RTI topic or project name 1a. Prototype: _Yes or No. 1b. ACAT: _1 to 4_ 1c. MDAP: Yes or No. 2. Technology Focus Area: Which focus area is this RTI project associated with? 3. DoD Product or Services Description Code: 4. Lead Program Office: Identify the lead PMO. 5. Lead Contracting Office: Specific Warfare Center or Naval Activity. 6.1 Statement of need. Introduce the plan by a brief statement of need (referencing generic RTI Section 1 authority is sufficient). Include status of any applicable Acquisition Strategy, Acquisition Decision Memorandum, Defense Acquisition Board, and/or any other internal service reviews. 6.2 Historical Summary: Provide one or several paragraphs describing the background for this RTI project. Identify the capabilities (e.g., Capability Development Document (CDD) or requirements (e.g., Operational Requirements Document (ORD)) or other document that authorizes program initiation, include approval date, and revalidation date, if applicable (referencing generic RTI Section 1 authority is sufficient). 6.3 Previous Contract History: Identify any previous related contracts over the past 5 years (contract number, contractor, contract type, supply/service description (title only), quantities, period of performance, historical or estimated contract value and whether a sole source or competitive contract award). 6.4 RTI Rationale: Provide a rationale as to why the RTI approach is appropriate and a discussion on what Government resources are available to award and manage the procurement and why they are sufficient and adequate (e.g. the approach was used on similar projects). Identify the likely or possible system or platform integrators, if needed, for the project, the annual resources they will need each year, and the contact at the relevant program office that has agreed to coordinate and support the project. 7. Project Objective: Describe the project in brief, non-technical language; e.g., a brief description similar to that forwarded in the Congressional data sheets with the annual budget. Characterize that the project is just starting RTI process. Include a project description, likely quantity to be procured in the RTI contract (including the fielding/production phase). Provide the primary and secondary engineering measurement parameters being used for this RTI procurement. Describe the tradeoffs or inter-relationships between the primary and secondary parameters. 8. Significant Patents or Copyrights: Describe any significant items with intellectual property issues or limitations and how they affect the procurement. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 9. Estimated Budget & Costs: The funds in this chart represent the funding considered adequate to execute the proposed RTI project. Table A.1 shows the funding available by fiscal year. Table A.2 shows the RTI funding by project phase and planned procurement quantities. FY1x FY1x FY1x FY1x FY1x Total RDT&E,N Funding $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX OP,N $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX O&M,N $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX SC,N $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX Total Funding $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX Table A-1: RTI Topic Budget Data ($K) FY FY1x FY1x FY1x FY1x FY1x Total Phase 1, Transition Study & Eng. Svcs, Est.Cost $X,XXX $X,XXX Phase II, Assessment & NRE, Est. Cost $X,XXX
$X,XXX Phase III, T&E Support Svc, Est. Cost $X,XXX $X,XXX $X,XXX $X,XXX Phase IV: Fielding/ Production, Est. Cost $X,XXX $X,XXX $X,XXX $X,XXX Phase IV, Production Quantities: ## ## ## ## Phase IV: Fielding / Repair Svcs, Est. Cost ($K) $X,XXX $X,XXX $X,XXX $X,XXX Total Est. Cost $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX $X,XXX Table A-2: RTI Topic Budget Data ($K) Notes: Provide estimating methodology here for estimated costs. 10. Point of Contact for Cost Performance Appraisal Reporting System (CPARS): The CPARS POC is at 202-781- , @Navy.mil. 11. MILESTONES FOR THE ACQUISITION CYCLE (update dates are sample dates). Step # \nSchedule Event Elapsed Time (Days) Cumulative Time (Days) 1. Purchase Request Receipt 0 0 2. Issue Synopsis with Draft RFP Distribution Unlimited. Public Release Case Number 18-2212 Step # \nSchedule Event Elapsed Time (Days) Cumulative Time (Days) a. MDA approval of the Technology Development Strategy Prior to PR b. \nMDA approval of the Acquisition Strategy and RFP \nPrior to PR c. \nCompletion of any applicable peer review (appendices) Prior to PR 1. Purchase Request Receipt 0 0 2. Issue Synopsis with Draft RFP & Call for White Papers 15 15 3. Issuance of Final/Full Solicitation (RFP) 60 75 4. Proposals Received 60 135 5. RTI Contract Award 90 225 d. Transition Study (RTI Phase 1 Complete) 90 315 e. Completion of all Milestone B requirements 15 330 f. \nCompletion of a Pre-EMD peer review. 15 \n345 6. \nRTI Assessment / NRE Option Award 20 \n365 Table A-4, Objective Schedule, ACAT 1-IV Projects. 12. Prospective Sources (AP Section 5.3) Provide a listing of any known or potential sources for this acquisition. Provide a discussion on what other Government contracts were considered, including a discussion on whether this RTI project should be limited to small business responses in a small-business set-aside procurement. 13. Risk Areas (Ref. AP Section 3.3): Discuss the risks that may exist to achieving success. 14. Government Furnished Property. Discuss any planned Requisitioned Government Furnished Property (GFP) and/or Scheduled GFP. Ensure compliance with requirements of DFARS PGI 245.103-72 (i.e. ensure DoD-required GFP forms are completed and submitted with any purchase request). 15. Government Furnished Information. Discuss any planned provision of Government Furnished Information. Ensure compliance with NAVSEA Instruction 4340.1A. Ensure a completed NAVSEA form 4340/02 is completed and submitted with any purchase request. 16. Foreign and International Corporations. Discuss whether foreign corporations will be able to bid on the procurement, and whether any aspects of the technology are considered off-limits to foreign corporations. 17. Major Defense Acquisition Program Considerations (MDAP Programs Only): MDAP Programs will address each of the following additional considerations: Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 17.1 (a) National industrial base considerations and foreign \nparticipation guidance, on a case by case basis (AP Para 2.3.6.1). Address the availability of essential raw materials, special alloys, composite materials, components, tooling, and production test equipment for the sustained production of systems fully capable of meeting the performance objectives established for those systems; the uninterrupted maintenance and repair of such systems; and the sustained operation of such systems. (b) The identification of items that are available only from \nsources outside the national technology and industrial base. (c) The availability of alternatives for obtaining such items from \nwithin the national technology and industrial base if such items become unavailable from sources outside the national technology and industrial base; and an analysis of any military vulnerability that could result from the lack of reasonable alternatives. (d) The effects on the national technology and industrial base \nthat result from foreign acquisition of firms in the United States. 17.2 Use of commercial systems. (AP Para 2.3.6.9). Address the acquisition of major weapon systems as commercial items. 17.3 Industrial Capability Strategy. (AP Para 2.3.6.10). Provide the programs Industrial Capability (IC) strategy that assesses the capability of the U.S. industrial base to achieve identified surge and mobilization goals. If no IC strategy has been developed, provide supporting rationale for this position. i. If, in the IC strategy, the development of a detailed IC \nplan was determined to be applicable, include the plan by text or by reference. If the development of the IC plan was determined not to be applicable, summarize the details of the analysis forming the basis of this decision. If the program involves peacetime and wartime hardware configurations that are supported by logistics support plans, identify their impact on the IC plan. 17.4 Preservation of special Tooling. (AP Para 2.3.6.12). Include a plan for the preservation and storage of special tooling associated with the production of hardware for major defense acquisition programs through the end of the service life of the related weapons system. The plan shall include the identification of any contract clauses, facilities, and funding required for the preservation and storage of such tooling. 17.5 Other MDAP Considerations (AP Para 2.4.4): (i) Competitive prototyping. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 (ii) Dual-sourcing. \n(iii) Unbundling of contracts. \n(iv) Funding of next-generation prototype systems or subsystems. (v) Use of modular, open architectures to enable \ncompetition for upgrades. (vi) Use of build-to-print approaches to enable production \nthrough multiple sources. (vii) Acquisition of complete technical data packages. \n(viii) Periodic competitions for subsystem upgrades. \n(ix) Licensing of additional suppliers. \n(x) Periodic system or program reviews to address long- term competitive effects of program decisions. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Appendix C Electronic Acquisition Strategy Data Fields Figure C-1 Acquisition Strategy Data Records (page 1 of 2) A001 AP Appendix # (Text) 6.3a Previous Contract (Text) 104.1 Acquisition Policy Tailoring (Text) A002 Project Title (Text) 6.3b Previous Contractor (Text) 104.2 Acquisition Policy Waiver (Number) A003 Document Date (Text) 6.3c Previous Contract Type (Text) 11a MDA TDS Approval Date (Date) A004 Acquisiton Category Level (ACAT) (Text) 6.3d Previous Contract Code (Text) 11b MDA Acquisition Strategy (Text) A005 Technical Project Manager (PM) (Text) 6.3e Prev. Contract, Quantity (Number) 11d MDA Peer Review Date (Date) A006 Approval Date, Technical Manager (Date) 6.3f Prev Contract Award Date (Date) AS 11e Purchase Request Receipt Date (Date) A007 Local Warfare Center Project Office Manager (Text) 6.f Prev Contract, PoP End Date (Date) 105 11h White Paper 5. Lead Contracting Office (Code) (Text) 7.4a Secondary EMP Name (Text) 12a Prospective Sources (Text) 6.1 Statement of Need (Text) 7.4b S-EMP Objective Value (Text) 12b Other Considered contracts (Text) 6.2a Historical Summary, Background (Text) 7.5 EMP Tradeoffs (Text) 12c Small Business Set-Aside Only? (Yes/No) 102.1a 6.2b Historical Summary, Requirement (Text) 8a Relevant Patents (Text) 106.1 13 Risks (Text) 102.1b Interoperability / Joint Drivers (Text) 8b Relevant Copyrights (Text) 106.2 Interdependency Issues (Text) 102.2a Expected User (Text) 9.1a Funding Years (List 5 Years) (Date) 106.2a Interdependency Programs: Links (link) 102.2b CONOPS Summary (Text) 9.2a RDT Distribution Unlimited. Public Release Case Number 18-2212 107.2b Industry Day or Conference Presentation (Yes/No) 110.3b Potential Impact to APUC if FMS approved (percent) 107.3a Advance Procurement planned (Yes/No) 111.1a Will Program sustain a key Industrial Base (Yes/No) 107.3b Dollar Value of procurement in advance of MS (Currency) 111.1b Describe Ind. Base issue and impact (Text) 107.41a Dollar value of Depot sustainment contracts (Currency) 111.4 Planned or Completed MOAs (Text) 107.41b Dollar value of Intermed sustainment contracts (Currency) 112a (Number) of Life Cycle RF Signatures Involved (Number) 107.41c Competitive award of D/I contracts (Yes/No) 112b Link to Life Cycle RF Signature Tables (Links) 107.41d Rationale for sole source D/I contracts if SS (Text) 112c Life Cycle Signature Funding Requirements (Yes/No) 107.42a Contractor support required for sustainment (Yes/No) 113 General Equipment Valuation Accounting Applic (Yes/No) 107.42b Contractors in Operational or Diplomatic Areas (Yes/No) 113.1 Existence of PWBS Tables (they will link up) (Yes/No) 107.42c Rationale for contractor support (Text) 113.2 End Item Name with APUC/$100k (Text) 107.431 Sust. Contract Performance Measures (Text) 113.3 GFP Per Unit End Item (Text) 107.432 System components covered by Sust. Contracts (Text) 113.4 Other Deliverables Accompanying Unit (Text) 107.433 Re-use of existing support Capability (Text) 113.5 Other Deliverables Not Accompanying Unit (Text) 107.434a Impact to current force manpower? (Yes/No) 107.434b Impact in # Op/Maint hours per year per system (Number) 107.434c Impact to current spare parts inventory? Yes/No 107.434d Cost for O/I/D spare parts per system? (Number) 107.437 Estimated P3I/ECP cost per year for program. (Currency) REPEATING SUBTABLE ; 107.439a Interim Contractor Support needed? (Yes/No) 104.2a Program Element plus (Number) Unique ID (Text) 107.439b ICS Duration (years) (Number) 104.2b Requirement to be Waivered (Text) 107.43A Contractor Logistics Support needed (Yes/No) 104.2c Type (Statutory / Regulatory) (pulldown) 107.5a (Number) of major contracts planned (Number) 104.2d Granting authority (Text) 107.5b Links to Major Contract APs (link) 104.2e Rationale (Text) 108.1a Total NRE funding required (Currency) 104.2f Required by Date Dare ; 108.1b Planned Production Quantity (Number) 104.2g Statys (Approved, In Draft, Submitted) (pulldown) 108.1c Average Production Unit Cost at that Qty (Currency) 108.1d Planned Life expectancy of use (Number) REPEATING SUBTABLE, Life Cycle Signatures ; 108.1e Average Annual Op Support Cost / Unit (Currency) 112.1a Mission Type (pulldown) 107.1f Total Simplified ACAT Cost Estimate Currency/Sum ; 112.1b
Mission Type Category (pulldown) 107.1g Resulting Simplified ACATA Category (Number) 112.1c Domain (pulldown) 107.1h Perct. of 5 years Cost in last Approved 5y Budget (percent) 112.1d Domain Subcategory (pulldown) 107.1i PE of RDT Distribution Unlimited. Public Release Case Number 18-2212 Figure C-1 Acquisition Strategy Data Record (page 2 of 2) Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Appendix D Electronic Test and Evaluation Master Plan Data Table F-1, T Distribution Unlimited. Public Release Case Number 18-2212 Table F-1, T Distribution Unlimited. Public Release Case Number 18-2212 Table D-1, T Distribution Unlimited. Public Release Case Number 18-2212 Table D-1, T Distribution Unlimited. Public Release Case Number 18-2212 Table D-2 Developmental Test (DT) Event Data Fields Data Name Data Type TEIN # Text 203.322a DT_Event_Number Number 203.322b DT_Event_Name Text 203.322c DT_Event_Date_Start Date 203.322d DT_Event_Date_End Date 203.322e DT_Event_Summary_Objectives Text 203.322f DT_Event_Scenarios_Reference Text 203.322g DT_Event_Design_Concept Text 203.322h DT_Event_Test_Hours Number 203.322i DT_Event_Test_Articles Text 203.322j DT_Event_Test_Location_Range Text 203.322k DT_Event_Targets_Sims_Used Text 203.322l DT_Event_Targets_Unit_Cost Currency 203.322m DT_Event_Range_Cost_per_day Currency 203.322n DT_Event_Total_Cost Currency 203.322o DT_Event_Op_Environment_Tested Text 203.322p DT_Event_Linked_COI Link 203.322q DT_Event_Linked_Milestone Link 203.322r DT_Event_Reliability_Test_Strategy Text 203.322s DT_Event_Reliability_Goal_target Text 203.322t DT_Event_Limitations Text 203.322u DT_LFTE_Impacts Text 203.322v DT_Other_GFE_GFI_Needed Text 203.322w DT_Event_Contractor_Support Text 203.322x DT_Event_Op_Forces_Resources Text 203.322y DT_Event_Reports_Created Text Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 \nTable D-3 Operational Test Event Data Fields \nTable D-4 Developmental Evaluation Framework (DEF) Data Fields Data Name Data Type 203.60a OT_Event_Number Text 203.60b OT_Event_Name Text 203.60c OT_Event_Date_Start Date 203.60d OT_Event_Date_End Date 203.361 OT_Event_Summary_Objectives Text 203.611 OT_Event_Scenarios_Reference Text 203.612a OT_Event_Design_Concept Text 203.612b OT_Event_Test_Hours Number 203.612c OT_Event_Test_Articles Text 203.612d OT_Event_Test_Location_Range Text 203.612e OT_Event_Targets_Sims_Used Text 203.614a OT_Event_Targets_Unit_Cost Currency 203.614b OT_Event_Range_Cost_per_day Currency 203.614c OT_Event_Total_Cost Currency 203.615a OT_Event_Op_Environment_Tested Text 203.615b OT_Event_Linked_COI Text 203.615c OT_Event_Linked_Milestone Link 203.615d OT_Event_Reliability_Test_Strategy Text 203.615e OT_Event_Reliability_Goal_target Text 203.615f OT_Event_Limitations Text 203.615g OT_LFTE_Impacts Text 203.615g2 OT_LFTE_Notes Text 203.615h OT_Mod_Sim_Used, Notes Text 203.615i OT_Other_GFE_GFI_Needed Text 203.615j OT_Event_Contractor_Resources Text 203.615k OT_Event_Op_Forces_Resources Text 203.615l OT_Event_Reports_Created Text 203.62 OT_Mod_Sim Text 203.621 OT_Mod_Sim_Objectives Text Data Name Data Type TEIN # Text Project Name Text Framework # Number Associated DT or OT event Text 203.24a Eval_Matrix_Key_Requirement Text 203.24b Eval_Matrix_Crit_Op_Issue Text 203.24c Eval_Matrix_MoE_MoS Text 203.24d Eval_Matrix_CTP_name Text 203.24e Eval_Matrix_CTP_Value Number 203.24f Eval_Matrix_Test_Method Text 203.24g Eval_Matrix_Key_Resource Text 203.24h Eval_Matrix_Decision_Supported Link 203.2i Avail_at_next_MS Number 203.24j CTP_Status Text 203.24k Eval_Matrix_Data_Source_Link Link Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Appendix E Electronic Life Cycle Sustainment Plan Data Table E-2 Life Cycle Sustainment Plan, Key Data Elements and Types LCSP Data Element Data Type LCSP Data Element Data Type 301 Title Text 2. Technology Focus Area Pulldown 302 PEplusID Number 3. DOD Product of Services Descriptive Code Number 303 Project Title Text 4. Program Office (Code) Text 304 Document Date Date 6.1 Statement of Need Text 305 Version Text 310a Sustainment Summary Text 306 ACAT Number 310b Associated SoS System Links Link 307a Product Support Manager (PSM) Name 331a Deminishing Source Applicable Yes/no 307b Approval Date, PSM Date 3315 Other Factors and Notes Text 307c Local Warfare Center Project Office Manager Name 333a Product Support Contract Name Text 307d Approval Date, Local WC POM Date 334b PSC CLIN Text 307e Approval by Project Contract Officer Name 334c PSC CLIN Type Text 307f Approval Date, PCO Date 334d Managing Org Text 307g Approved, Business Financial Manager Name 334e Org POC Name 307h Approval Date, BFM Date 334f Contractor Text 307i Approval, Program Lead Engineer (PLE) Name 334g Start Date Date 307j Approval Date, PLE Date 334h Current End Date Date 307k Approval, Program Manager Name 334i Success Metric Text 307l Approval Date, PM Date 334j CSDR Status Text 307m Approval, Program Executive Office Name 371a Fixed OS Cost Factors Text 307n Approval Date, PEO Date 371b Fixed OS Annual Cost Currency 307o Approval, Sustainment Command Rep Name 371d OS Cost Factor /Unit Driver Text 307p Approval Date, SC Date 371e OS Cost Factor /Unit Cost Currency 307q Approval, DoD Comp. Acqu. Exec. Name 371f OS Cost Factor /Site Driven Text 307r Approval Date, DAE Date 371g OS Cost Factor /Site Cost Currency 1a. Prototype Status? Yes/No 371h OS Cost Reduction Initiatives Text 1c. MDAP Status Yes/No 381 Product Support Manager Email Email 382 Link to Project's Risk Mgt List Text Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Table E-3 LCSP Component Breakdown Data Elements and Types Table E-4 LCSP Analysis Method Data Elements and Types E.1 LCSP Content Not Included in the Data Record. Within the LCSP there were also several sections and content items of the LCSP that did not transform to an E-version in the same way. Notable exceptions to the simple transfer were: a) Section 2.2 calls for a table of achieved performance data that related to logistics. Instead \nof creating a duplicate set of data, a value achieved and test event columns were added to the earlier LCSP section on key variables. b) Section 3, 2nd paragraph, calls to \" List all supplemental support elements that will be \npresent in the O&S Phase (e.g., training simul tors, system integration labs, server farms, mock-ups) and whether they are a PSMs responsibility for support or supported via other means (e.g., memorandum of agreement). This material is duplicative with other data collected and identified in the LCSP. c) Section 3 calls to Briefly discuss specific programmatic interdependencies with other \nprograms. This should be replaced by another column in the component breakdown LCSP Component Breakdown Data Element Data Type LCSP Component Breakdown Data Element Data Type 301 Title Text 330p PHS Distribution Unlimited. Public Release Case Number 18-2212 table, that identifies the interdependent programs associated with each subsystem, and whether it is dependent on or being depended on. [[Added data needed]]. d) The data table 3-1 of Section 3 has codes to indicate how the organic-level or \nintermediate-level support is being provided, primarily F for full organic, L for limited, or C for contractor support. This table could be modified in a data base to include the dates when the status will be achieved, either as events (e.g. IOC, FRP), or in terms of months before or after the final material support date (e.g. -3, 0, 0, 2, 4, 2). The need for three levels within the O, I, and D level also is a bit lower level than a plan, and should be controlled at a lower data base level. e) Table 3-3 in Section 3.1.2 requires another separate table that shows planned competition \nfor support, including small business considerations. This data was incorporated into the 330 series data as another column, 3312a and 3312b, for each component subsystem, instead of being shown in a separate table as depicted. f) Section 3.1.3 requires a description of all systems used to track Government property for \nthe program. This was not included, as the data is already captured and managed by individual property management agents, e.g. DCMAO for contractors under their control and individual Government agents such as DLA or NSPCC, Philadelphia. Duplication of this data is not needed in this type plan. g) Section 3.1.4 requests for appropriate data from the cybersecurity Program Protection \nPlan. Duplication of this data is not needed in the LCSP data base, as the Cybersecurity Strategy document data is already captured in a separate part of the data base records. h) Table 3-6 of Section 3.3.2 requires a table of data that shows what products are supported \nvia Memorandum of Agreement (MOA) with Organic Support activities. The table calls for the organization name, subsystem, activity, documentation, and metrics. Instead of a new table, several data columns were added to the 330 series component breakdown table, to provide the performance metrics, Government or Contractor status, and organization name. This prevents duplication and allows better analysis of data trends. i) Section 4 requires a discussion of program issues and corrective actions that were taken \nto resolve them. This is not included as LCSP content as it converts a planning document into a long-term active data-base of issues. This type of content should be incorporated into a larger program issues tracking system that includes technical problems, T&E event issues, COM ECPs, and budget cuts or bumps as well as logistics program issues. [[Separate Data Base Content needed]]. j) Section 5 requires a discussion and table of key design and sustainment requirements \nrelating to sustainment. This section is not needed as a separate data set as long as key logistics and sustainment issues are captured in the 220 series of key performance parameters in other portions of the data base. Treating the sustainment requirements here, instead of being integral to the technical requirements, allows them to be treated as secondary requirements. k) Section 6 is the Integrated Program Schedule. This is not needed as an LCSP section or \ndata series since it is also already captured in other data sections (e.g. AP, TEMP). The overall schedule section of the data base should include specific logistics sustainment dates such as MSD or training readiness dates. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 l) Section 7 contains several tables of data on program
cost and sustainment cost drivers. \nThis section needs to be integrated into the Life Cycle Cost data records. The tables with program cost become obsolete within weeks or months of the LCSP being signed. The LCSP section should only include inputs that are leveraged by the other cost sections of the data base as numerical factor inputs, such as the fixed and variable operating cost of the depot or repair facility, as a part of the component breakdown data. Some sample data (371a 371h). m) Section 8 requires information about the program office and its organization. This data is \nnot needed here, as it is already contained in the AP sections of the data base, as well as organizational records of the PEO. The name of the product support manager and Program Manager are in the front part of the E-LCSP data record. n) Section 9.1 requires design interface information. This data should be incorporated into \nthe component breakdown data series, as separate columns to indicate the effect and criticality of a failed interface. [[Added data 391-393 in component breakdown]]. o) Section 9.1.1 requires duplication of data from the SEP. This is not needed, as the SEP \ndata should be captured in a separate section and not duplicated. When data reports are created as views of the data the different data sections can be integrated together as needed. Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Appendix F Abbreviations and Acronyms AP Acquisition Plan AS Acquisition Strategy CSPP LCSP PEO PMO TEMP Cybersecurity Protection Plan Life Cycle Sustainment Plan Program Executive Office Program Management Office Test and Evaluation Master Plan Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 Digital Acquisition for FASTLane r10f.pdf D a ve L e c h n e r, Th e M I TR E C o r p o r a t i o n R 1 0 , O c t o b e r 1 , 2 0 1 8 Digital Acquisition Data Base \nfor Defense Acquisition Programs Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212 This technical data deliverable was developed using contract funds under Basic Contract No. W56KGU-18-D-0004. Sponsor: Naval Surface Warfare Center, Office of the Chief Technologist Officer MITRE Dept. No.: P631 Contract No.: W56KGU-17-C-0010 Project No.: 0718V190-RT | 2 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' BLUF Objective for Today: Review Digital Acquisition data schema and proposed tools developed by MITRE under FASTLane initiative. Obtain leadership feedback and concurrence to start use via pilot program. Proposed approach shifts most acquisition documents from piles of paper and pdf files to a data base. COTS Software approach allows rapid use in pilot programs. Using digital acquisition should allow faster program creation, improved planning, and better oversight. | 3 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Introduction Early FY17, MITRE was supporting DASD/DT Distribution Unlimited. Public Release Case Number 18-2212' Background: Per Ms. Ellen Lord, Undersecretary of Defense for Acquisition and Sustainment, at the DAU Training Symposium (April 3, 2018) Program Managers need to bring data to decisions. What data and metrics do we have  what does the data/trends tell us? Opinions are interesting, but irrelevant. Need good data engineers/analysts. SCO, DIUx, JIDO, and other organizations popped up because 5000.02 didnt do what we needed it to do In 2017 the Deputy assistant Secretary of the Navy (DASN) for RDT Distribution Unlimited. Public Release Case Number 18-2212' Converted the AP Appendix into Project Specific Data Base Schema RTI AP: Data centric Approximately 100 pieces of information. Mix of text, dates, numbers, and yes/no values. | 6 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' E-AP (RTI) Ported to Sharepoint No real program data yet. Used MITRE Partnership Web Site. Navy site in-process. | 7 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Motivation for Data Base Use: Accumulate the acquisition data associated with Navy programs. Enables the use of automated workflow based tools to route \napprovals, track activity and accumulate metrics, ( allowing \ninsight into how long these documents take for approval). Enables backward looking data analytics analysis can \ndetermine traits of successful programs. Could provide data to help answer questions such as: \n What do successful programs have in common? What do unsuccessful projects have in common? Allow data-driven answers using statistical correlation \ntechniques to make strategic policy decisions Allows much faster program creation and \napproval and improves program oversight and management. | 8 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' To Improve Planning or Oversight We Needed to Add Some Data Started out with basic AP data. Added data to provide more useful information and improve decision making. What questions would PMs and PEOs ask in an AP review? How does the program compare to other similar programs that succeeded or failed? Have similar programs been protested or awarded without discussions? (add award success) Have similar programs experienced cost over-runs? (add CPI after award) How has this PMO done on their last few programs? How are the programs in this PEOs portfolio executing? What is the experience level of the PMO team? Data schema will evolve based on use Distribution Unlimited. Public Release Case Number 18-2212' Then: Created an Electronic Acquisition Strategy (E-AS) Schema Only needed for new programs of record, per DoD 5000 Somewhat larger 240 pieces of information (initial data set). Two repeating sub-tables of data, for 1) Policy Waivers and 2) RF Signatures. Used 100 series data codes. (we need a unique data code for each item). 99 Text Fields: Less useful data, but retains familiarity Distribution Unlimited. Public Release Case Number 18-2212' Electronic T Distribution Unlimited. Public Release Case Number 18-2212' Created Data Schema for Several Other Acquisition Documents Cyber Security Strategy completed Cyber Security Program Plan In \nprocess Life Cycle Sustainment Plan \ncompleted Acquisition Decision Memorandum \ncompleted. APB - In process NAVSEA TEMPALTS FLEX Data \nPackage completed. RTI Source Selection Plan \ncompleted. 40+ More DoD 5000.02 Documents\n 35+ Seem applicable to data base conversion. An initial pilot assessment is possible \nwith current list. | 12 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Web Tools Distribution Unlimited. Public Release Case Number 18-2212' Longer Term, When we have data Potential Expert Wizard (aka Turbo-Tax) For Project Planning: Could provide comparison data based on current timespans for approval schedule data, allow default. Could recommend data based on project data, goals, and objective timelines. Could allow engineer or PM to pick similar to projects to see their data and make informed decisions. For Program Management and Reviews: Could allow PEO or PM to compare the project to others in a similar manner as the planning module, and compare execution schedules and success. Could provide email alerts for an ongoing project, when an execution parameter passes a certain threshold or misses a critical milestone in a manner that predicts future problems. Illustrative Graphics Not real data. | 14 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Potential Comparison Tool for Planning or Reviewing Projects Distribution Unlimited. Public Release Case Number 18-2212' Sample Executive Dashboard Functioning on MITRE internal web site. Targeting Navy servers - Currently working through technical \nissues to link online data base tools to create informative \ndashboard graphics. Pilot program needed to test real data. Illustrative Graphics Not real data. | 16 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Preliminary Comparative LOE Model Model assumes medium sized program of record efforts. Tracks meta-time, not associated with contractor efforts. 16 month to initiate Distribution Unlimited. Public Release Case Number 18-2212' Near Term Work, FY19, Low LOE Clean up data base ensure uniform approach. Test iNAVSEA and InFusion tools Ensure forms work, pass data, and provide Assess DoD server options. Assess data privileges and PMO/data security. Who can see what data Create workflow Test project review and approval tool with users. Simulate a document review and approval. Test project planning tools with users. Refine dashboards in consultation with SYSCOM/PEO leadership. Develop training package (online) for each user type. Several months of engineering still required prior to use on pilot projects. Currently only low LOE effort is funded. | 18 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Implementation Options Three options to implement pilot programs\n Low LOE: FASTLane only. A few programs, a few documents (funded FY19) Mid 1 SYSCOM, Multiple documents. More user testing and user support. Larger LOE: 4 SYSCOMs over 2 years. Start with 1 PEO, then 1 SYSCOM, then add a \nSYSCOM each quarter. Add more documents as data modules each month. Existing Navy software infrastructure is adequate for a pilot \nprogram. If successful, PMOs could eventually convert old data currently \ncaptured in legacy paper plans. Completed Socialization with NAVSEA, NAVAIR, & SPWAR. Full support so far from all 3 of these SYSCOMs MARCORPS SYSCOM
discussions in process Can be phased, monitored for progress, and canceled/adjusted \nif full gains are not met. Below the size of a Major AIS system by leveraging COTS SW. | 19 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Summary / Conclusions Acquisition Documents can be converted to a Digital Acquisition Data Base. \n Workflows allow automated routing and let the Navy collect metrics. About 800 data items now, including about 40% (limited) Free-text. Automation should allow faster creation and approval of programs, as long as this replaces the plans. Process is not just a direct translation of the current reports.\n Duplicate data is deleted. Pilot process will help define what additional data is needed. Automation should allow better planning via wizard tools. Creates tools to continue execution management and oversight, enables predictive analytics. Authority will be needed to enable pilot projects to use DB instead of current plans. | 20 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' BACKUP | 21 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Recent Socialization of DA Concepts NAVAIR: Current PMT tools provide some of the source data \nneeded. Working on Turbo Acquisition to eliminate duplicate paragraph \nsections between acquisition documents. Goal is to set up an instantiation \nof this by 12/18. Views proposed Data Base tool as the next logical step and \nwould consider collaborating on a pilot implementation. Would consider \nleverage of MITRE data schema in current efforts. SPAWARSYSCOM Does not have a data base initiative in place yet. Has a \ntool to build an RFP using template paragraphs, focused on acquisition of \nservices. Would consider piloting the proposed data base. MARCOR SYSCOM Discussions still in progress. NAVSEA SYSCOM Originated concept under FASTlane. In process of \ntesting schema on navy servers. One project considering pilot testing \n(Deployable Family of Systems). Seeking other additional projects. Discussions suggested that SYSCOMS could collaborate on standard \ncontract templates and provide common documents in areas of expertise \nfor subsystems and services (not platforms) | 22 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Digital Acquisition Implementation Options September 26, 2018 | 23 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Low-Sized Implementation, 1 SYSCOM LOE: 1 MITRE Staff member, Existing Navy staff A few programs, pilot usage (e.g. FAST lane). Focus on near term tasks with current E-plans Clean up data base, test security, permissions, and widgets Usability testing Distribution Unlimited. Public Release Case Number 18-2212' Mid-Sized Implementation, 1 SYSCOM Larger effort, more deliberate implementation Start with 1 PEO and 2 or 3 programs, allow others 3Q/4Q Open to a full SYSCOM by 4Q Implement several documents on several programs. Allows faster implementation, better usage testing and metrics ~ 2 MITRE Staff members, 2 SYSCOM Staff members FY19 FY20 FY21 Continued NAVSEA X Pilots 1 PEO +1 PEO / Qtr | 25 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Large-Scale Implementation Option A larger 2 to 4 SYSCOM implementation is possible Still require pilot programs to test usability and help programs \nthrough socialization issues Phased approach would start at 1 PEO per SYSCOM for 3 \nmonths, grow usage in stages Expand to additional PEO each quarter (phased roll-out, not a \nbig-bang). Allow more PEOs to adapt DA tools if they want to. Challenges: Give viewers a familiar look and feel to legacy documents, Integrate with other data systems (ERP), Develop useful data dashboards and presentations, Keep people in control of the data (not vs. versa), security Distribution Unlimited. Public Release Case Number 18-2212' Implementation Notes: MITRE Staff: 1 to 3 STE team (Data Scientist, Programmer, HCI SME) Focus on Data Schema, Cross-SYSCOM Architecture, DoN level data usage. Conduct Usability Testing Ensure cross-SYSCOM cohesion and upward integration 4 SYSCOM Teams: 1 Data Scientist Distribution Unlimited. Public Release Case Number 18-2212' Summary / Conclusions Low LOE - Funded, Will continue to work out implementation issues with a few documents. Mid-Sized LOE Allows more deliberate implementation and user socialization (a difficult problem). Larger LOE implementation: Would accelerate usage and productivity, enable faster savings in time and $. Would leverage all SYSCOM expertise to evolve faster solution. Still well below the size of a Major AIS system if commercial infrastructure is leveraged. | 28 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Data Not Included in the E-TEMP About 51 Data Fields Mostly duplicate data. Same data linked to AP and AS data base. Gold Rule of Data Bases Only keep data once, in one place. Link to it. Some data was the same data, in a different format. | 29 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Additional TEMP Data Needed? Considering additions to support hypothetical questions, e.g.: What DT and OT events are happening in the next quarter? Which DT and OT events just happened? Did they go well? When do DT and OT events happen, and is there a pattern during the year? Are test ranges used evenly throughout the year? How long does it take, on average, to get a test report completed after a test? Is the number of test days used typically more or less than the number of test days planned? What is the cost of a test day at each of the ranges, and why are they different? | 30 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' E-Life Cycle Sustainment Plan (E-LCSP) LCSP structure easily \nported. Already a series \nof data tables. Approximately 60 data \nitems. Used 300 series \nnumbers, to assign unique \ndata codes to each data \nfield. Two nested tables, for the \nLCSP Component \nBreakdown and LSA \nAnalysis Method. 15 subsections \nrecommended for \ndiscontinuation. \n(Obsolete, duplicate, or \nappears inappropriate to \nmodern LCSP needs.) | 31 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Cybersecurity Strategy Similarly ported, essentially in total. CS Plan and CS Status \nChecklist, as two separate data structures. | 32 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Required Statutory Documents 16 of 32 Requirements prototyped on MITRE site using Sharepoint data structure. 8 Documents are MDAP Only. | 33 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' Required Regulatory Documents 11 of 32 Requirements could be prototyped using Sharepoint data structures. 9 documents could use Workflow tools to route and track them. ADDITIONAL Regulatory MDAs may tailor regulatory procedures consistent with sound business practice and the risks associated with the product being acquired. Acquisition Decision Memorandum (ADM) 2 4 Automate Sharepoint Workflow 1 Affordability Analysis 5 4 Incorporate into AS. AoA Study Guidance and AoA Study Plan 7 4 Waive for FL. Could be automated into SPWF. Capability Development Document (CDD) 12 4 OPNAV Document. One of many validated requirements doc. Capability Production Document (CPD) 13 4 OPNAV Document. One of many validated requirements doc. Concept of Operations/Operational Mode Summary/Mission Profile (CONOPS/OMS/MP) 2115 4 Automated ROUTING Sharepoint Workflow (OPTEVFOR Doc) 1 Cost Analysis Requirements Description (CARD) 21 1 Automated ROUTING Sharepoint Workflow (OPTEVFOR Doc) 1 Defense Intelligence Threat Library (Threat Modules) 73 4 Intel Document. One of many validated requirements doc. Development RFP Release Cost Assessment 23 1 Automate Sharepoint Workflow Single Cost Doc. 1 DoD Component Cost Estimate 24 1 Automate Sharepoint Workflow Single Cost Doc. DoD Component Cost Position 25 1 Automate Sharepoint Workflow Single Cost Doc. DoD Component Live Fire Test and Evaluation (LFT Distribution Unlimited. Public Release Case Number 18-2212' Sample ACAT-3 Document Comparison Statutory Documents Required per DAU, IDd for DFOS Pilot Document Identified for ACAT-3 new Start, D-5000.3 Pre-MS-C Decision Add to Data Tool Alternate By ? Program Information Description X FY21 Analysis of Alternatives X Waiver? Clinger Cohen Act Compliance X Competition Analysis Memo 4QFY19 Frequency Allocation Application Legacy Data Tool in FY20 Interop/Support Cert of CDD X OT Test Plan OPTEVFOR Doc Prog. Env., Safety, and Health Eval. (PESHE) Distribution Unlimited. Public Release Case Number 18-2212' Sample ACAT-3 Document Comparison Regulatory Documents Required per DAU, IDd for DFOS Pilot | 36 | 'Approved for Public Release; Distribution Unlimited. Public Release Case Number 18-2212' RTI and the Flipped Model: APs Historically each program had its own acquisition plan, providing details on the program, and a chapter or appendix for the procurement method. Rapid Technology Insertion (RTI) started in PEO LCS in 2014, Used flipped model, with an Acquisition Plan that detailed the process, and a thin appendix specific to the project. General AP with a 3-page appendix filled with project specific data (approved in 2 weeks). ",
    "text": " Microsoft Word 277498 MITRE Submission to FAAMAs Managing the Skies for September/October edition 1 \n \nApproved for Public Release, Unlimited Distribution (Case Number: 19-2492) New Approach for Detecting Airborne and Surface Events The National Airspace System (NAS) is on the precipice of new operational paradigms that demand new risk identification and mitigation approaches. Driving these changes are the increasingly complex operations taking place in the nation's airspace: new entrants such as unmanned aircraft systems and commercial space vehicles; increased air traffic; more sophisticated aircraft performance and equipage; and the availability of increased computing power and artificial intelligence. While existing regulations, compliance checks, and safety data collection and analysis efforts have produced the safest decade of air travel in the nation's history, new approaches are needed to address the safety issues that these increasingly complex operations introduce. The MITRE Corporation, which operates the FAA's federally funded research and development center, is working to help the FAA meet this evolving need. Using advanced data analytics, data fusion, and machine learning techniques, MITRE and the FAA have been researching and prototyping a capability for the last four years that automatically identifies aviation events warranting safety review and prioritizes them for daily examination. The capability, known as Aviation Risk Identification and Assessment (ARIA), ingests radar data and makes it available for near real-time analysis. The FAA is now working with MITRE to refine and validate the new system. While not operational in day-to-day business yet, ARIA capabilities are currently being used to evaluate both airborne and surface events by examining factors like aircraft location, speed, and trajectory to predict whether aircraft are on a path that may represent a safety concerneven if technically deemed a compliant operation. ARIA Benefits MITRE Submission to FAAMAs Managing the Skies for September/October edition 2 \n \nApproved for Public Release, Unlimited Distribution (Case Number: 19-2492) Identifying and Assessing Risks While still requiring deeper investigation, the module of ARIA that detects airborne events has been running continuously on FAA computer hardware since September 2018. Currently, each evening, detected events are published to an FAA computer system. Each morning, the FAA Quality Assurance team has access to ARIA results they can then use to help perform their quality assurance and quality control efforts as the FAA further explores ARIAs full potential. In addition to airborne events, MITRE researchers are also working with FAA subject matter experts from both the Quality Assurance and Runway Safety departments to validate the algorithms used to detect and assess safety events on or near the airport surface. Detected events include two aircraft operating on the same runway, risk of runway overrun, aircraft crossing active runways, and missed approaches due to occupied runways. The system also detects risk-based encounters that do not represent compliance violations, such as aircraft taking off near helicopters. Expanding the Safety View to Expedite Review and Risk-Based Decision Making ARIA is already providing benefits both to the FAA and the flying public because it captures much more of the traffic that occurs in regions with radar coveragesomething previously not possible with data from flights operating under visual flight rules, many of which are general aviation aircraft flights. With data from those flights, ARIA provides Quality Assurance personnel with a more complete safety picture. ARIA is also enabling FAA Quality Assurance offices to perform their jobs more efficiently. It is a time-consuming process to sift through unsorted reports to identify events warranting more scrutiny. ARIA eliminates this need by automatically ranking events. This allows review panels to focus their time and effort on what matters mostidentifying risk in the system. Additionally, much like a Google search that delivers more results than you require, ARIA identifies more events each day than just the most egregious. And, by capturing all events, the system is creating a sizable historic dataset for future analysis. That historic dataset will provide hard data to inform risk-based decision making about everything from widespread operational trends to localized problems or issues affecting only a certain class of aircraft. Integrating Analysis with Compliance ARIA also enables a risk-based approach for safety analysis processes. This goes beyond the traditional processes, which focus primarily on compliance with existing rules and regulations and enables action to ensure the operation is returned to compliance. With ARIA, it is becoming possible to evaluate risk alongside compliance to form a more complete risk picture. For example, if the operation is in compliance with the rule, yet risk is still observed, that may indicate that a rule is ineffective at achieving the desired level of safety. On the other hand, if the operation is noncompliant, and no risk is detected, that may be an indication that the rule is overly conservative and warrants re-evaluation. MITRE Submission to FAAMAs Managing the Skies for September/October edition 3 \n \nApproved for Public Release, Unlimited Distribution (Case Number: 19-2492) So, by associating measures of risk with non-adherence to specific rules or regulations, the FAA can both identify risky behaviors as well as evaluate its own rules and regulations to determine which warrant review, revision, or simply greater emphasis. Over the next several months, MITRE will be working with the FAA to explore how to incorporate ARIA with existing FAA systems and processes. According to Mike Balder, National Quality Assurance Manager for the FAA, ARIA is a game changer. It will enable us to change the conversation around safety and focus on identifying and mitigating the most significant risk in the system. We will have a 360 view of air traffic risk in the NAS and provide targeted, actionable information to the operation and support organizations to make air travel even safer in the future. About the MITRE Corporation MITREs mission-driven teams are dedicated to solving problems for a safer world. Through public-private partnerships, as well as the operation of federally funded R&D centers, we work across government to tackle challenges to the safety, stability, and well-being of our nation. MITRE operates the Center for Advanced Aviation System Development, which has supported the FAA for more than 50 years. In addition, MITRE provides technical expertise to various international civil aviation authorities, airport operators, airlines, and other aviation organizations in air traffic management systems engineering, aviation operations, airspace design, and systems automation and integration. Learn more at www.mitre.org. \nThis is the copyright work of The MITRE Corporation and was produced for the U.S. Government under Contract Number \nDTFAWA-10-C-00080 and is subject to Federal Aviation Administration Acquisition Management System Clause 3.5-13, Rights in \nData-General, Alt. III and Alt. IV (Oct. 1996). No other use other than that granted to the U.S. Government, or to those acting on \nbehalf of the U.S. Government, under that Clause is authorized without the express written permission of The MITRE Corporation. \nFor further information, please contact The MITRE Corporation, Contract Office, 7515 Colshire Drive, McLean, VA 22102, (703) \n983-6000. \nThe contents of this material reflect the views of the author and/or the Director of the Center for Advanced Aviation System \nDevelopment, and do not necessarily reflect the views of the Federal Aviation Administration (FAA) or Department of Transportation \n(DOT). Neither the FAA nor the DOT makes any warranty or guarantee, or promise, expressed or implied, concerning the content \nor accuracy of the views expressed herein. \nThe Government retains a nonexclusive, royalty-free right to publish or reproduce this document, or to allow others to do so, for \nGovernment Purposes Only. http://www.mitre.org/ New Approach for Detecting Airborne and Surface Events ",
    "text": " Paper Title (use style: paper title) Approved for Public Release; Distribution Unlimited. Public Release Case Number 19-2029 This technical data was produced for the U. S. Government under Contract No. FA8702-19-C-0001, and is subject to the Rights in Technical Data-Noncommercial Items Clause DFARS (FEB 2014) DNS Tunneling Detection with Supervised Learning Richard Preston The MITRE Corporation, Bedford, MA and Tufts University, Medford, MA rhpreston@mitre.org AbstractThis paper presents an advanced analytic capable of detecting general DNS tunneling behavior with high precision and recall. It explores the application of supervised machine learning to a recently introduced technique for analyzing DNS traffic: classifying primary domains instead of queries. This approach is enabled by a partially synthetic dataset generated with a structurally configurable DNS tunneling tool. KeywordsDNS, DNS tunneling, threat detection, data analytics, machine learning, traffic generation I. INTRODUCTION The Domain Name System (DNS) is commonly referred \nto as the phonebook of the Internet. When you type \nwww.ieee.org into your browser, a query is sent to a DNS \nresolver to determine the location, or IP address, of the \ndomain. This happens for most online activity, and therefore, \nDNS traffic is prevalent on all networks that connect to the \nInternet. Unfortunately, the DNS protocol is fraught with \nsecurity vulnerabilities, and efforts to fix the 1980s technology \nhave largely failed [1]. According to a recent survey, 33% of \norganizations suffered data theft via DNS in 2018, costing an \naverage of $715,000 per incident [2]. The combination of a \ncolossal legacy system and sophisticated evolving threats \nmeans more advanced approaches are needed to protect \nenterprises from attackers. One of the most glaring and difficult problems with the \nDNS is that it can be hijacked to transmit arbitrary data. The \nDNS does not consist of a single database of all the IP \naddresses in the network. Instead, it is a distributed, dynamic \nsystem allowing new domains to be registered as they come \nonline. This means that it is trivially easy to add a new name \nserver that you control to the system. For example, if you \nregister the domain evil.com, then any new queries to \n<subdomain>.evil.com will be directed to your server. \nThen, any computer in the world can send a message to you \nby making a DNS query with the data encoded in the \nsubdomain field. The server can respond with any resource \nrecord, including IP addresses or arbitrary text. Fig. 1 \nillustrates this threat, which is known as DNS tunneling. Over the last decade, academic and industry research has \nproduced techniques for identifying and responding to DNS \ntunneling [3]. However, detection of evasive protocols has \nproven difficult and is only now being integrated into \ncommercial devices and software, where the design is often \nobscured, and the solutions can be prohibitively expensive. In \nJune 2018, Nadler et al. introduced a new approach that \nenables detection of low-throughput data exfiltration over \nDNS [4]. The work presented here reproduces and extends \ntheirs by applying supervised machine learning to similar \nstatistical features extracted from a partially synthesized \ndataset representing a broad spectrum of DNS tunneling protocols. This effectively improves the precision and recall \nof the classifier without overfitting to a particular malware \nfamily. II. APPROACH A. Background The challenge in detecting DNS tunneling behavior in \ngeneral is that each malware family may behave differently, \nusing its own application-layer protocols and performing a \ndistinct set of activities. However, there are three common \nthreads: 1. Malicious actors use DNS tunneling to transmit \ninformation. 2. The outgoing information is encoded in the \nsubdomain field of the DNS queries. Fig. 1. Simplified example of how DNS tunneling can be used as a \ncommunication channel. Note the outgoing data payload is contained in the subdomain field of the DNS query. 3. Two or more queries that are part of a transmission \nbetween a client and server must contain the same \nprimary domain (e.g. evil.com). Obviously, statistical metrics highlighting information \ncontent of DNS queries are informative, but the salient \ningenuity of Nadler et al. comes from an understanding of \npoint 3. They proposed that the queries be first grouped by \nprimary domain, and then features extracted from the list of \nsubdomains contained in each group. In other words, attempt \nto classify malicious domains instead of malicious queries. \nFraming the problem this way grants more flexibility in the \nmachine learning features that can be extracted, as discussed \nin the next section. B. Machine Learning Features 1) Character Entropy: Information (Shannon) entropy as shown in (1) applied to the subdomains taken as a string of characters. = \n \n \n (1) \n is the normalized frequency of \n in , or the number of occurrences of \n in divided by the number of elements in . In this case, is the concatenation of the \nsubdomain fields for a given list of queries grouped by primary domain, and is the set of characters seen therein. This feature is intended to measure information content, and therefore domains involved in DNS tunneling are expected to exhibit a higher character entropy. 2) Alphanumeric Content Ratio: The number of lowercase alphabetic or numeric characters (the characters officially sanctioned in the DNS protocol) in divided by the number of characters in (where is as specified in Character Entropy). Normal DNS traffic should only use alphanumeric characters, so this feature may highlight odd behavior such as the use of base64 encoding. 3) Unique Query Volume: The number of unique queries in the group, normalized with (2), where x is the unique query volume, and c is equal to 20. = 1 \n\n (2) The more queries are sent, the more information can be transmitted. Therefore, a high unique query volume may correlate with DNS tunneling. 4) Unique Query Ratio: The number of unique queries divided by the total number of queries in the group. For typical use of DNS, identical queries may be made over time to access the same resources repeatedly. With DNS tunneling, the queries are expected to vary in order to transmit new data and to prevent DNS caching. 5) Average Subdomain Length: The average number of characters (bytes) in the subdomains, normalized with (2), where x is the average subdomain length, and c is equal to 50. The longer the subdomain is, the more data can be encoded therein. 6) Average Longest Meaningful Word Length Ratio: The longest meaningful word length ratio is the length of the longest English word contained in a string divided by the length of the string. This was computed for each subdomain in the group, and the average was taken as the feature. Typical normal subdomains are English words, but those used for DNS tunneling are not likely to be meaningful to a human. 7) Average English Content Ratio: The intention of this feature is to estimate the proportion of characters in the subdomains that compose English words, and therefore are unlikely to be used for data transmission. The heuristic in Fig. 2 was used to determine the English Content Ratio (ECR) of each subdomain. The feature was taken as the average ECR over all the subdomains in the group. 8) Average Similarity Ratio: The similarity ratio between two strings is the number of characters they share divided by the number of characters in total. For example, the simality ratio between abcd and cdef is 0.5. Note that only non- overlapping matching subsequences are considered when counting shared characters. For example, the ratio between abcd and cdab is still just 0.5. Rather than compute this for every pair of subdomains in the group, a sliding window approach was used. For each subdomain, the average of the similarity ratios between it and the subsequent N subdomains in the list were taken. (In the trials discussed in this paper, N=20.) These values were averaged to obtain the feature. This is perhaps the most interesting statistic, because it gets to the heart of the difference between normal use of DNS, where subdomains follow some easily-recognizable pattern, and DNS tunneling, where each subdomain represents a data transmission packet and may be totally unrelated to others under the same primary domain. C. Normal DNS Data The University of Southern Californias LANDER project annually collects large volumes of Internet traffic as part of their Day in the Life of the Internet effort [5]. A sample of DNS queries requesting A, AAAA, and TXT records was taken from their 2018 dataset to represent normal DNS behavior. To mitigate the concern that the sample may be contaminated by a small portion of DNS tunneling traffic, anomalies were filtered out with an Isolation Forest classifier 1 algorithm ECR is 2 input: string S 3 output: number that is the ECR of S 4 5 M := predefined minimum word length 6 L := length of S 7 while True do 8 W := longest meaningful word in S 9 if length of W is less than M break 10 remove W from S 11 return 1 (length of S) / L \nFig. 2. Greedy algorithm implementing ECR approximation. This
design emphasizes performance and simplicity over accuracy. using the features from the previous section, and the remainder was used for supervised learning. In the end, over 30 million DNS queries were paired down and preprocessed to make up six sets of ~80,000 benign-domain feature vectors each. The data was broken up this way to enable repeated trials when testing the efficacy of the approach. D. DNS Tunneling Tool A typical route for recording malicious traffic is to run one or more malware samples in a controlled environment and watch their behavior. This method was explored but abandoned for the simple reason that known malware families and tunneling protocols may not be representative of future attacks. Instead, a tool was developed in Node.js to perform DNS tunneling over a local network and simulate domains exhibiting various behaviors. This exercise provided the following insights into the adversarial perspective and some of the key constraints when working inside the DNS protocol: 1) Length Restrictions: DNS queries cannot be arbitrarily long. A single QNAME is limited to 253 bytes, including label separators (periods). Messages longer than this must be broken into multiple packets. An adversary may also limit the number of bytes used to avoid detection and decrease the risk of dropped packets. DNS also limits the number of bytes in each label to 63. This complicates the process of sending a datagram as a DNS query, because periods must be inserted every 63 characters, which in turn increases the total query length. 2) Limitations to UDP: DNS queries are typically served over UDP, in which IPv4 packets are limited to 512 bytes (on some systems). This is not a problem for the client, since a QNAME is limited to 253 bytes. However, the server must be aware of how many bytes its answer is adding before sending the response, or a CONNREFUSED error may be triggered. In other words, there is a limit to how much data can be encoded in a server reply; multiple queries are necessary when dealing with large server-to-client transmissions. This problem is resolved in the wild by switching to TCP if more than 512 bytes are needed. It can also be mitigated with the use of message compression, which uses the space in a DNS packet more efficiently [6]. (The tool did not support TCP or message compression.) 3) Valid Characters: Restrictions are imposed on what characters can constitute a valid hostname [6]. Specifically, only letters, digits, and hyphens are allowed (with no hyphen at the beginning of a label). However, this is only technically enforceable at the domain registration level, meaning that subdomains (the portion of the FQDN carrying the data in DNS tunneling) might get away with other characters. The risk is that lack of support or deliberate filtering by DNS infrastructure between the client and server may cause packets to be dropped. 4) Caching: Many layers of potential caching exist in the DNS (i.e., places where the result of a query may be saved and retrieved upon subsequent identical queries). Therefore, each query must be unique to ensure it arrives at the server. The tool accomplishes this by inserting a random English word of pre-specified length into the subdomain. 5) Client-only Originiation: Due to the nature of the DNS protocol, all transmissions must conform to a question-and- answer format. In other words, the client must originate all communication with the server. This can be tricky to work around; in some cases, the client must simply poll the server until it receives an indication to stop. Fig. 3 offers a small window into how this works in practice. The tool was designed for many uses and configurations so that it could synthesize a robust and diverse dataset. The following client behaviors (commands) were supported: Ping the server. \n Send a short message to the server. \n Send a short message to the server and receive the same message as a response. Send a long message to the server. \n Transmit a file to the server. \n Retrieve a file from the server. The following parameters were varied in the simulation: Command (ping, short message, etc.). \n Resource record type (A, AAAA, TXT). \n Character encoding (base64, base32, hex, utf8). \n Encryption (AES or none). \n Message length. \n Number of commands per domain. \n File transmitted (empty, text, image, etc.). \n Length of anti-caching string. A simulation was designed to synthesize DNS traffic for domains exhibiting each of the supported behaviors with randomly chosen configurations. A single run produces 4,800 domains, each having a different number of queries. Six runs were conducted to complement the benign-domain feature sets, for a total of about 4 million DNS tunneling queries. E. Threat Classification The parsing and feature extraction infrastructure was written in Python so that the application could make use of the excellent scikit-learn library [7]. This design choice enabled the exploration of six machine learning algorithms: Random Forest, Gradient Boosting, AdaBoost, Bagging, Support Vector Classifier (SVC), and Stochastic Gradient Descent (SGD). For each, 80% of the preprocessed and labeled dataset was used for training and validation, and 20% was held out for testing. Fig. 3. Combined log outputs of DNS tunneling tool resulting from starting the server evil.com and executing the ping command from the client. The hyperparameters of the estimators were selected with randomized parameter optimization and 3-fold cross validation using the F1 score (the weighted harmonic mean of precision and recall). The final results were determined by the performance of the classifiers on the hold-out set. III. RESULTS A. Feature Value Distribution Fig. 4 gives a rough picture for each of the features of how the distributions of benign and malicious samples differ. It shows that most are quite good at distinguishing benign and malicious traffic, except for those that try to analyze the content of the query based on an expectation of what normal DNS traffic is supposed to look like (Alphanumeric Content Ratio, Average LMW Length Ratio, and Average English Content Ratio). This suggests that our intuitions about the typical use of DNS may not exactly match the reality. It bears noting that the Unique Query Ratio (UQR) plot contains a spike of benign domains at 0.5. There are several potential reasons for this phenomenon, including redirects, a single-retry policy, or domains with exactly two total queries. Regardless, it represents a potential vulnerability with this feature, as a malicious actor might mask itself by tuning its UQR to 0.5. B. Classifier Performance The gathered datasets allowed for six tests. The following hyperparameters were selected based on the validation step for one of the six datasets (the same were used for all tests to be consistent):1 AdaBoost: n_estimators=175, learning_rate=1.5 \n Bagging: n_estimators=75, max_samples=1.0, max_features=6 1 See scikit-learn.org for documentation of each parameter. GradientBoosting: n_estimators=200, \nmax_features=None, max_depth=5, loss=exponential, criterion=friedman_mse RandomForest: n_estimators=100, \nmax_features=None, max_depth=10, criterion=entropy, class_weight=None SVC: shrinking=False, kernel=rbf, gamma=scale, \nclass_weight=None, C=1.05 SGD: tol=0.1, penalty=l1, max_iter=200, \nloss=hinge, class_weight=None Fig. 5 shows the average precision and recall for each classifier over all the trials. In this case, precision is the portion of domains classified as malicious that actually came from the DNS tunneling dataset, and recall is the portion of actually malicious domains that were classified correctly. In other words, precision measures the confidence of the model when it flags a domain as malicious, and recall measures how likely the model is to detect a malicious domain when it is given one. These results indicate that the application of supervised learning to this problem greatly improves the performance of the analytic. For comparison, the same tests were run for the Isolation Forest classifier, the unsupervised learner used by Nadler et al. It achieved an average precision of 0.8834 and an average recall of 0.7992 with the following hyperparameters: n_estimators=175, max_samples=0.0625, max_features=4, contamination=0.05 The training time for each trial was also recorded. Fig. 6 shows the average runtime for the training step of each estimator. When selecting a machine learning algorithm to use in an operational analytic, the tradeoff between fidelity and speed must be considered. For example, if training is conducted often and with large datasets, SGD may be a better choice even though it exhibits lower recall. Fig. 4. Distrubution of feature values for benign and malicious samples. The charts are histograms with bins of width 0.1. Blue represents benign samples, and orange represents malicious samples. \nFig. 5. Average precision and recall over six trials. Error bars represent one standard deviation. 0.99 0.991 0.992 0.993 0.994 0.995 0.996 0.997 0.998 0.999 1 Precision Recall C. Efficacy Confirmation To verify the benign set was representative of queries in an operational environment, another trial was conducted with confidential enterprise DNS traffic instead of the USC sample. Though there were some small differences in the feature value distribution (i.e., Fig. 4 looked slightly different), the classifiers exhibited only a marginal performance degradation. Perhaps a greater concern is that the DNS tunneling tool is not diverse enough to capture the behavior of real malware. To validate the effectiveness of the
classifier at detecting DNS tunneling in the wild, a Python script was written to imitate three malware families as described in security blog posts [8] [9] [10]. This resulted in nearly 20,000 queries spanning 400 domains, all of which were correctly classified as malicious by the model. (The test was conducted with a previously trained Random Forest classifier that never saw the malware data.) IV. DISCUSSION A. Individual Domain Analysis Some insight can be gained by looking at the behavior of incorrectly classified domains. For example, in the sixth trial, all the supervised models mistook computerkolkata.com as malicious and mal643.com as benign. The unprocessed DNS queries to these domains are listed below. computerkolkata.com: upg9.computerkolkata.com upg10.computerkolkata.com mal643.com: bbnoa.mal643.com bbnoa.mal643.com bbboa.mal643.com bbroa.mal643.com bbboa.mal643.com bbfoa.mal643.com To a human, it seems relatively obvious that the first group of queries is normal and the second is odd (and for reasons besides the presence of the word mal in the primary domain recall that we are only looking at the subdomains). Indeed, upg9 and upg10 appear simply to be redundant name servers, which is a common practice in DNS. Meanwhile, the latter queries were generated by a DNS tunneling tool pinging mal643.com. However, consider their feature values as shown in Table I. On most features, computerkolkata.com lands in the orange regions of Fig. 3, and mal643.com lands in the blue regions. So, it is no surprise that they were classified in this manner. This highlights the need for even more granular approaches, such as sequence detection. The challenge is that each new decision in the model represents both an additional computation cost and a potential vulnerability to be exploited. As usual, a compromise must be reached depending on the application. For cases with a small false positive rate, a simple whitelist is probably suitable. B. Effectiveness of the Approach The goal of this effort was to develop an analytic capable of detecting DNS tunneling behavior generally. The question must be asked, Whats to prevent an adversary from modifying his behavior to avoid detection? In short, nothing. If an actor is using the DNS protocol as intended (or appears to in every meaningful sense), then this method cannot identify him. In other words, this analytic is not a blanket fix for DNS security. Instead, it offers visibility into a particular behavior (DNS tunneling) that is a hallmark of malicious activity. To be clear though, any attempt to evade this analytic would severely cripple client-server transmissions, which is (by definition) what attackers use DNS tunneling for. As an example, suppose an enterprise periodically runs this analytic on the past five hours of DNS traffic. An adversary could limit himself to just a few queries every five hours, but then his data throughput would be somewhere around 1 byte per minute. Or, he could forgo an anti-caching mechanism and send more duplicate queries, but then he could lose packets if they are not forwarded to the server. He could increase the English content in the subdomains, but this would require more or longer queries to transmit the same amount of data. Thus, the attacker is faced with difficult tradeoffs that restrict him to ultra-low throughput applications such as extremely basic command and control. V. CONCLUSION The use of supervised machine learning, enabled by synthesized malicious data from a configurable DNS tunneling tool, greatly improved the precision and recall of DNS tunneling classifiers as compared with unsupervised learning. Keeping in mind the tradeoff between performance and training time, one of the estimators discussed can be used as an advanced analytic to detect DNS tunneling in query traffic. The success of the approach taken affirms the recommendation of Nadler et al. to attempt to classify malicious primary domains instead of individual queries. It also establishes the effectiveness of the statistical features discussed in this paper at distinguishing DNS tunneling behavior from normal usage. TABLE I. FEATURE VALUES FOR EXAMPLE DOMAINS Domain \nFeature ENT ACR UQV UQR ASL LMW ECR SMR computerkolkata.com 0.481 1.0 0.095 1.0 0.086 0.450 0.450 0.667 mal643.com 0.390 1.0 0.181 0.667 0.095 0.567 0.900 0.827 Fig. 6. Average execution time for training step over six trials, with worst case removed. Error bars represent one standard deviation. This work leaves open the exploration of more powerful machine learning methods, such as neural networks. There also may be other features or sources of data that would be useful in this effort. For example, the contents of the query response could be an additional vector for determining the amount of data being transmitted between a client and server. This may enable detection of even the most discrete activities, such as ultra-low throughput command and control. ACKNOWLEDGMENT The author would like Randy Charland, Kyle Nolan, and \nKevin Grace for guidance and support on the project, and Dr. \nKaren Panetta for academic mentorship. REFERENCES [1] S. Ariyapperuma and C. J. Mitchell, \"Security vulnerabilities in DNS and DNSSEC,\" in The Second International Conference on Availability, Reliability and Security (ARES'07), Vienna, 2007. [2] EfficientIP, \"Global DNS Threat Report,\" 2018. Available: https://www.efficientip.com/resources/dns-security-survey-2018/. [Accessed 2 May 2019] [3] M. Aiello, M. Mongelli and G. Papaleo, \"Basic classifiers for DNS tunneling detection,\" in 2013 IEEE Symposium on Computers and Communications (ISCC), 2013. [4] A. Nadler, A. Aminov and A. Shabtai, \"Detection of Malicious and Low Throughput Data Exfiltration Over the DNS Protocol,\" arXiv.org, 2018. [5] USC/B-Root Operations with USC/LANDER project, Day In the Life of The Internet (DITL), 2018. [6] P. Mockapetris, \"Domain Names Implementation and Specification,\" November 1987. [Online]. Available: https://tools.ietf.org/html/rfc1035. [Accessed 14 May 2019]. [7] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos and D. Cournapeau, \"Scikit-learn: Machine Learning in Python,\" Journal of Machine Learning Research, vol. 12, p. 28252830, 2011. [8] G DATA Blog, \"New FrameworkPOS variant exfiltrates data via DNS requests,\" G DATA, 15 October 2014. [Online]. Available: https://www.gdatasoftware.com/blog/2014/10/23942-new- frameworkpos-variant-exfiltrates-data-via-dns-requests. [Accessed 14 May 2019]. [9] A. Shulmin and S. Yunakovsky, \"Use of DNS Tunneling for C&C Communications,\" Kaspersky Lab, 28 April 2017. [Online]. Available: https://securelist.com/use-of-dns-tunneling-for-cc- communications/78203/. [Accessed 14 May 2019]. [10] S. Yunakovsky and I. Pomerantsev, \"Denis and Co.,\" Kaspersky Lab, 25 January 2018. [Online]. Available: https://securelist.com/denis-and-company/83671/. [Accessed 14 May 2019]. Introduction\n Approach\n Background\n Machine Learning Features\n Character Entropy: Information (Shannon) entropy as shown in (1) applied to the subdomains taken as a string of characters.\n 0 = ( )\n Alphanumeric Content Ratio: The number of lowercase alphabetic or numeric characters (the characters officially sanctioned in the DNS protocol) in divided by the number of characters in (where is as specified in Character Entropy).\n Unique Query Volume: The number of unique queries in the group, normalized with (2), where x is the unique query volume, and c is equal to 20.\n Unique Query Ratio: The number of unique queries divided by the total number of queries in the group.\n Average Subdomain Length: The average number of characters (bytes) in the subdomains, normalized with (2), where x is the average subdomain length, and c is equal to 50.\n Average Longest Meaningful Word Length Ratio: The longest meaningful word length ratio is the length of the longest English word contained in a string divided by the length of the string.\n Average English Content Ratio: The intention of this feature is to estimate the proportion of characters in the subdomains that compose English words, and therefore are unlikely to be used for data transmission.\n Average Similarity Ratio: The similarity ratio between two strings is the number of characters they share divided by the number of characters in total. Normal DNS Data\n DNS Tunneling Tool\n Length Restrictions: DNS queries cannot be arbitrarily long.\n Limitations to UDP: DNS queries are typically served over UDP, in which IPv4 packets are limited to 512 bytes (on some systems).\n Valid Characters: Restrictions are imposed on what characters can constitute a valid hostname [6].\n Caching: Many layers of potential caching exist in the DNS (i.e., \\)\n Client-only Originiation: Due to the nature of the DNS protocol, all transmissions must conform to a question-and-answer format. Threat Classification Results\n Feature Value Distribution\n Classifier Performance\n Efficacy Confirmation Discussion\n Individual Domain Analysis\n Effectiveness of the Approach Conclusion\n Acknowledgment\n References [1] ",
    "text": " Health FFRDC Short Template Title (50 words): National Test Collaborative to Advance Health Information Technology\nAuthors:\nMaria Michaels1, Rakhee Palekar2, Maeve Kokolus2, Marc Hadley2, Suzette Stoutenburg2, Elise Caruso1, Jina Dcruz1, Melia Haile1, Christopher Voegeli1 1Centers for Disease Control and Prevention, Atlanta, Georgia, United States\n2The MITRE Corporation, Atlanta, Georgia, United States Abstract (250 words)\nThe Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 promoted the adoption of health information technology (IT) to improve the quality of clinical care.[footnoteRef:1] This shepherded in an era of widespread use of health IT and a need to robustly test new applications before their introduction into clinical environments. Such testing should simulate the complexity of real-world clinical data, clinical workflow, and human interaction with health IT applications. [1: https://www.hhs.gov/hipaa/for-professionals/special-topics/hitech-act-enforcement-interim-final-rule/index.html, Accessed 04/02/2019] To address this critical and growing need, the Centers for Disease Control and Prevention (CDC) is proposing the development of a marketplace connecting test originators and test executors, notionally called a National Test Collaborative (NTC) for health IT. CDC envisions that test originators (e.g., federal agencies, researchers, providers, health IT developers) would define health IT testing needs, specify the parameters for testing (e.g., test types, clinical setting options, patient cohorts), and then share this information with potential test executors (e.g., electronic health record and other health IT developers, clinical providers, public health departments). Incentivized test executors would agree to conduct the testing in their local environments according to pre-specified parameters and share the results of the tests with the originator. Once this model for real-world testing is established, it could be used any time a new health IT application needs to be tested in real-world settings. \nTo ensure success, careful thought should be given to the challenges faced in prior efforts. Broad engagement of stakeholders and a phased approach that incorporates lessons learned will be essential to success. Main body of paper (4000 words)\nIntroduction\nBackground\nThe Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 incentivized clinical providers to adopt health information technology (IT) such as electronic health records (EHRs), and it promoted the use of health IT to improve the quality of clinical care.[endnoteRef:1] These investments have led to important increases in health IT adoption and use.[endnoteRef:2] However, as the demands on EHRs grow (e.g., reporting of electronic clinical quality measures [eCQMs] by clinical providers, addition of clinical decision support [CDS] tools to EHRs, and data extraction from EHRs for public health and research), there is a critical need for real-world clinical testing of health IT applications. [1: HHS, HITECH Act Enforcement Interim Final Rule, [Online]. Available: https://www.hhs.gov/hipaa/for-professionals/special-topics/hitech-act-enforcement-interim-final-rule/index.html. [Accessed 2 April 2019].] [2: J. Adler-Milstein and A. K. Jha, HITECH Act Drove Large Gains In Hospital Electronic Health Record Adoption, Health Aff (Millwood), vol. 36, no. 8, pp. 1416-1422, Aug 1, 2017.] Indeed, the 21st Century Cures Act[endnoteRef:3] mandates acceleration in developing new health IT products to stimulate health information exchange. To that end, the Office of the National Coordinator for Health Information Technology (ONC) is engaged in a process with industry to develop the Trusted Exchange Framework and Common Agreement (TEFCA).[endnoteRef:4] This framework, which has invited numerous rounds of public comment,[endnoteRef:5] proposes to increase the exchange of health information by developing a common agreement to be used among diverse stakeholders. TEFCA has three high-level goals (1) provide a single on-ramp to nationwide connectivity, (2) enable electronic health information to securely follow the patient where needed, and (3) support nationwide scalability.4,[endnoteRef:6],[endnoteRef:7] Successful adoption and implementation of TEFCA would address some of the challenges encountered to date with trust and interoperable data exchange between health IT systems. [3: 21st Century Cures Act, U. S. Congress H.R. 34, 2016.] [4: G. Morris, Trusted Exchange Framework and Common Agreement: A Common Sense Approach to Achieving Health Information Interoperability, [Online]. Available: https://www.healthit.gov/buzz-blog/interoperability/trusted-exchange-framework-common-agreement-common-sense-approach-achieving-health-information-interoperability. [Accessed 15 April 2019].] [5: HHS, HHS Announces Next Steps in Advancing Interoperability of Health Information, [Online]. Avialable: https://www.hhs.gov/about/news/2019/04/19/hhs-announces-next-steps-in-advancing-interoperability-of-health-information.html. [Accessed 4 June 2019].] [6: ONC, A Users Guide to Understanding the Draft Trusted Exchange Network, [Online]. Available: https://www.healthit.gov/sites/default/files/draft-guide.pdf. [Accessed 7 May 2019].] [7: ONC, Trusted Exchange Framework and Common Agreement Draft 2, [Online]. Available: https://www.healthit.gov/sites/default/files/page/2019-04/FINALTEFCAQTF41719508version.pdf. [Accessed 5 May 2019].] Testing health IT capabilities is an important step toward advancing interoperability. Currently, there are a variety of environments for testing some aspects of interoperability and functionality of health IT applications using synthetic data. Examples of these test environment sandboxes include the Centers for Medicare and Medicaid Services (CMS) BlueButton Sandbox,[endnoteRef:8] AEGIS Touchstone,[endnoteRef:9] Cypress,[endnoteRef:10] the National Quality Forum (NQF) Measure Incubator,[endnoteRef:11] the SMART Platform,[endnoteRef:12] Inferno,[endnoteRef:13] and sandboxes hosted by Logica Health[endnoteRef:14] and the CDCs Public Health Informatics Research Lab.[endnoteRef:15] While synthetic data sandboxes provide an opportunity to test some aspects of functionality, they do not adequately reflect real-world clinical workflows or human interaction with health IT applications, which are often difficult to simulate.[endnoteRef:16] Several analyses have shown that even with up-front synthetic testing, real-world implementation of systems can result in unanticipated challenges to true interoperability.[endnoteRef:17], [endnoteRef:18], [endnoteRef:19] [8: CMS, Blue Button 2.0: Improving Medicare Beneficiary Access to Their Health Information, [Online]. Available: https://www.cms.gov/research-statistics-data-and-systems/cms-information-technology/blue-button/index.html. [Accessed 16 April 2019].] [9: AEGIS, Touchstone, [Online]. Available: https://touchstone.aegis.net/touchstone/. [Accessed 31 May 2019].] [10: CMS, Cypress, [Online]. Available: https://www.healthit.gov/cypress/. [Accessed 15 April 2019].] [11: National Quality Forum, NQF Measure Incubator, [Online]. Available: https://www.qualityforum.org/NQF_Measure_Incubator.aspx. [Accessed 15 April 2019].] [12: SMART: An App Platform for Healthcare, [Online]. Available: https://smarthealthit.org/. [Accessed 15 April 2019].] [13: Inferno, Inferno, [Online]. Available: https://inferno.healthit.gov/inferno/. [Accessed 31 May 2019].] [14: Healthcare Services Platform Consortium, FHIR Sandbox, [Online]. Available: https://www.hspconsortium.org/developers/sandbox/. [Accessed 2 April 2019].] [15: CDC, Public Health Informatics Research Lab, [Online]. Available: https://www.philab.cdc.gov. [Accessed 15 May 2019]. ] [16: J. Chen et al., The validity of clinical synthetic data: a validation study of a leading synthetic data generator (Synthea) using clinical quality measures, BMC Medical Informatics and Decision Making, vo. 19, no. 44, March 2019.] [17: T. R. Yackel and P. J. Embi, Unintended errors with EHR-based result management: a case series, J Am Med Inform Assoc, vol. 17, no. 1, pp. 104-7, Jan-Feb 2010.] [18: A. Wright et al., Analysis of clinical decision support system malfunctions: a case series and survey, J Am Med Inform Assoc, vol. 23, no. 6, pp. 1068-1076, Nov 2016.] [19: D. W. Meeks, M. W. Smith, L. Taylor, D. F. Sittig, J. M. Scott, and H. Singh, An analysis of electronic health record-related patient safety concerns, J Am Med Inform Assoc, vol. 21, no. 6, pp. 1053-9, Nov-Dec 2014.] The need for better capabilities for testing health IT applications in EHRs using real-world clinical data, clinical team members, and clinical workflows is reflected in the 21st Century Cures Act and detailed in a rule proposed by ONC in early 2019. This rule included, among other requirements, the need for health IT products to be tested in the real world in order to maintain ONC certification.[endnoteRef:20] Such efforts to test health IT using real-world clinical data will help application errors to be detected earlier in the development process (i.e., fail early) and for usability to be more adequately incorporated into testing efforts. Increasing clinician usability should lead to faster implementation of these health IT applications into clinical environments and ultimately could reduce clinician burden and improve clinician productivity. [20: ONC, 21st Century Cures Act: Interoperability, Information Blocking, and the ONC Health IT Certification Program, [Online]. Available: https://www.govinfo.gov/content/pkg/FR-2019-03-04/pdf/2019-02224.pdf. [Accessed 15 May 2019]. ] There have been at least two attempts by CMS to develop a real-world testing environment for eCQMs, which were based upon the voluntary participation of clinical providers and EHR and other health IT developers. Unfortunately, these attempts were not fully implemented in part, due to insufficient early stakeholder engagement and lack of consensus among stakeholders; the associated time requirements and opportunity costs for participants; the challenges associated with legal and technical aspects of privacy, security, and data sharing; and lack of development of a sustainable business model early in the development and implementation phases. Another ongoing, relevant effort, although not exclusively for testing health IT applications, is the Accelerating Change and Transformation in Organization and Networks (ACTION) Network, spearheaded by the Agency for Healthcare Research and Quality (AHRQ).[endnoteRef:21] This network is a U.S. government-contracting mechanism (infinite delivery/infinite quantity [IDIQ]) that is successfully bringing together pre-selected organizations to bid on federal proposals to answer healthcare research questions using real-world clinical data.[endnoteRef:22] Another effort in the private sector is NODE.Health, a network that brings together clinical providers/EHR and other health IT developers with those needing to test their new digital technologies.[endnoteRef:23] While these latter two networks are not currently testing health IT, they offer a model that could be replicated for testing health IT. For example, if the next iteration of the ACTION Network (i.e., ACTION IV) included health IT testing, this mechanism could be leveraged by federal agencies to fulfill the functions of a national test collaborative. [21: AHRQ, Accelerating Change and Transformation in Organizations and Networks III, [Online]. Available: https://www.ahrq.gov/research/findings/factsheets/translating/action3/index.html. [Accessed 29 April 2019].] [22: AHRQ, ACTION IIIs Partnerships, [Online]. Available: https://www.ahrq.gov/research/findings/factsheets/translating/action3/actionIIIpartners.html. [Accessed 29 April 2019].] [23:
NODE.Health, Homepage, [Online]. Available: https://nodehealth.org/validate-your-solution/. [Accessed 30 May 2019]. ] Purpose\nCDC has a need for testing a variety of health IT applications to help support and positively impact the publics health. This paper describes CDCs vision for a National Test Collaborative (NTC)a robust and sustainable national testbed infrastructure for real-world testing of health IT applications in a clinical setting. To advance this vision, CDC engaged the CMS Alliance to Modernize Healthcare (Health FFRDC) operated by MITRE to summarize lessons learned from prior efforts; document the essential building blocks for a successful NTC; determine the barriers and facilitators to the development, implementation, sustainability, governance, and scalability of an NTC; and recommend next steps toward establishing an NTC.\nCDC Vision and Goals for an NTC\nCDC envisions an NTC as a dynamic network of organizations that are available and capable of supporting real-world clinical testing of a variety of health IT applications (e.g., eCQMs, CDS, EHR data extractors) to assess functionality and ensure more thorough testing before full implementation in a production environment. Participating organizations could include clinical organizations, federal agencies, public health departments, and EHR and other health IT developers. By establishing a network of organizations (with appropriate agreements in place before testing needs arise), an NTC could provide a pre-vetted mechanism to test health IT applications and avoid the costly and time-consuming processes associated with establishing one-off real-world clinical testing sites to meet a single health IT applications needs.\nFigure 1 shows an NTCs components at a high level. There are two major roles envisioned in this approach: test originators and test executors. The idea is that test originators (e.g., federal agencies, researchers, health IT developers, etc.) would define health IT testing needs and specify the parameters for testing (e.g., test types, clinical setting options, patient cohorts). The test originator would share this information with potential test executors (e.g., EHR and other health IT developers, clinical sites, public health departments, etc.). The test executors would accept the tests they were interested in and capable of conducting, conduct the testing in their local test and production environments according to pre-specified parameters, and share the testing results with the test originator. The test executor would receive an incentive for conducting the testing. The participants and data flows in this model could vary depending on the use case. Figure 1. National Test Collaborative System Components For example, in tests of eCQMs, the test originator would be the eCQM developer and the test executor would be a selected clinical site or sites. The eCQM developer would specify the test type, clinical setting options, and cohort and would share the eCQM specification with the clinical site. The clinical site would test the eCQM locally, first in a test environment and then in a production environment, and iteratively send results back to the eCQM developer. In this case, Protected Health Information (PHI) would not leave the clinical site. This use case is depicted in Figure 2. Figure 2. National Test Collaborative: eCQM Testing Example\nHQMF: Health Quality Measure Format\nCQL: Clinical Quality Language\nQDM: Quality Data Model This model could be applied for other testing needs as well, such as the extraction of clinical data from EHRs to populate clinical data registries. In this latter case, the test originator could be the CDC, which would specify information about the test, including information about patient tracking, providers, patient cohorts, selected registry, and associated information, and then would send those required elements to test participants. In this case, multiple participants would be part of test execution, including a clinical site or sites and a registry. Test data would be shared between clinical sites and the registry, and test results would be shared with CDC. This use case is depicted at a high level in Figure 3. Figure 3. National Test Collaborative: Clinical Registry Testing Example It is important to note that an NTC is envisioned to use existing infrastructure to the extent possible, as shown in Figure 1 and in the examples depicted in Figures 2 and 3. Over time, as its functionality grows, an NTC could support the testing needs of both the public and private sectors and either have a self-sustaining infrastructure or exist as a public-private partnership.\nMethodology\nFive sources of information were used to develop this paper. First, the CDC developed and published an eight-question Request for Information (RFI) in October 2018.[endnoteRef:24] A total of 17 responses were received from EHR and other health IT developers; non-profit organizations; private consulting firms; and professional associations representing many individual participants (i.e., hospitals, clinical informaticists, and clinicians). Second, the CDC and the Health FFRDC (federally funded research and development center) hosted a discussion on April 22, 2019 to gather information from key federal stakeholders, including representatives from AHRQ, CDC, CMS, the Food and Drug Administration, the Health Resources and Services Administration, the National Institutes of Health, and ONC. Finally, the Health FFRDC performed outreach to AHRQ to better understand the ACTION Network, conducted research to identify previous field-testing efforts that used real-world clinical data and previous efforts to establish a national testbed infrastructure, and consulted with Health FFRDC subject matter experts. [24: CDC, Request for Information 75D301-19-Q-69537 National Test Collaborative, [Online]. Available: https://www.fbo.gov/index?s=opportunity&mode=form&id=0519b3fa81ee77c6c4aad95f2369f3d1&tab=core&_cview=1. [Accessed 15 April 2019].] Essential Building Blocks for a Successful NTC\nTo establish a successful NTC, there are at least four critical needs(1) a multi-disciplinary governance group, (2) incentives for participants, (3) privacy, security, and data sharing solutions, and (4) a sustainable business model. \nMulti-disciplinary Governance Group\nA representative, multi-disciplinary group of key stakeholders should set the policies and standards for an NTC and develop implementation and evaluation plans. Discussions with stakeholders and subject matter experts revealed that past efforts have failed, in part, due to insufficient early stakeholder engagement and lack of consensus among stakeholders. Forming an NTC with diverse perspectives represented from the outset will help ensure successful implementation and sustainability. This governance group should include, but is not limited to:\nClinical providers\nClinical and public health informaticists \nEHR and other health IT developers \nFederal, state, local, tribal, and territorial agencies (including public health departments)\nPatients and patient advocacy groups\nHealthcare and public health lawyers\nPayors\nProfessional associations (e.g., American Medical Association, American Hospital Association, Federation of American Hospitals, Association of State and Territorial Health Officials) \nStandards developers\nIncentives for Participants\nIt will be important to demonstrate to participants the benefits of participation, including the return on investment. Past efforts in which participants engaged as volunteers or with minimal monetary compensation were unsuccessful due to the associated time requirements and opportunity costs. \nSeveral incentive schemes have been suggested to remunerate participants in these types of efforts; these include financial remuneration for each longitudinal clinical record included in the testing and production environment (e.g., $1 USD per longitudinal record included in the test) or a CMS performance incentive (e.g., Promoting Interoperability Programs for Hospitals or Merit-based Incentive Payments, or an NTC application-certification process). \nPrivacy and Security and Data Sharing Solutions\nBased on stakeholder feedback, the legal and technical aspects of privacy, security, and data sharing are key to an NTCs early development, given that past attempts to establish real-world testing have encountered challenges in these areas. \nFirst, in terms of protection of PHI, if clinical providers and EHR and other health IT developers test data within their own environments, these challenges could be minimized because the data would remain protected behind established firewalls. If PHI leaves the local EHR environment, it will be essential to develop technical mechanisms (e.g., hashing, pseudonymization, deidentification) to protect the PHI and ensure that all processes comply with appropriate privacy and security laws at the federal, state, and local levels, as well as with applicable organizational policies. \nIt should be noted that any testing that is part of a research protocol under the Health Insurance Portability and Accountability Act (HIPAA) might require Institutional Review Board (IRB) review. In these cases, developing testing protocols that are pre-approved by federal agencies and participating organization IRBs could minimize the efforts needed for projects with similar testing protocols. \nSecond, in terms of data sharing, if PHI is shared outside of the EHR environment, it would be helpful to develop universal data sharing agreements that are pre-approved by the participating organizations. Universal data sharing agreements will facilitate and expedite the exchange of information, and those being developed as part of current federal projects could serve as a template for these efforts. Additionally, the NTC governance body in collaboration with the participating covered entities could develop a standard business associate agreement (BAA) that could be signed with any health IT product developer. This BAA could allow for the sharing of PHI without patient authorization, in accordance with the HIPAA privacy rules.[endnoteRef:25] [25: HHS, Understanding some of HIPAAs Permitted Uses and Disclosures, [Online]. Available:\nhttps://www.hhs.gov/hipaa/for-professionals/privacy/guidance/permitted-uses/index.html. [Accessed 14 May 2019]. \n] Sustainable Business Model\nBased on discussions with stakeholders, it is likely that an NTC would initially be established with federal funds. As it matures, business models grounded in public and private sector collaboration would provide a strong path toward sustainability. \nPossible business models include an on-demand model (i.e., fee for service) or a subscription model (i.e.,
monthly fee for either unlimited use or a predefined number of uses). Ultimately, a public-private partnership could increase the likelihood of an NTCs longevity and allow scalability as new testing demands are recognized. Per discussions with stakeholders, past federal efforts did not consider this aspect early in the development and implementation phases. \nBarriers and Facilitators to the Development, Implementation, Sustainability, Governance, and Scalability of an NTC\nIn order to develop, implement, sustain, govern, and scale an NTC, it will be important to consider the barriers that might exist, as well as the potential facilitators. This section details these barriers and facilitators. \nNTC Establishment\nBarriers to Establishment\nThe barriers to the establishment of an NTC include the following:\nLack of stakeholder engagement and buy-in to the proposal due to concerns about scale of the proposal, protection of PHI, return on investment for test executors, and effects on clinical workflow\nLack of meaningful incentives for participants\nComplexity of developing legal agreements and mechanisms that will adequately protect PHI if data are exchanged outside of a clinical providers EHR environment\nCompeting priorities among stakeholders for which use cases to establish first \nAcquiring enough funding to establish an NTC and fund it on an ongoing basis\nSecuring arrangements with, and engaging enough, diverse EHR and other health IT developers, clinical providers, patients, and potentially other types of participants to allow thorough assessment of health IT applications, including of edge use cases\nDeveloping pre-defined patient cohorts for each use case\nFacilitators to Establishment\nActivities that would facilitate the establishment of an NTC include the following:\nEngaging a diverse group of stakeholders at an NTC concept development phase\nBuilding on existing health IT infrastructure at clinical sites\nConsidering a top down approach within Health and Human Services (HHS) to ensure traction for the effort at the highest level of leadership \nApplying a phased approach to the introduction of use cases \nProviding frequent feedback to stakeholders about the advances of an NTC\nAllocating government funding for the piloting phase of an NTC \nEngaging many diverse types of clinical practices\nIncentivizing participants of an NTC\nApplying standard processes to address legal issues related to PHI use (e.g., HHS IRB pre-approved forms, TEFCA)\nBuilding on lessons learned from previous attempts to use real-world data to test health IT applications\nUtilizing the IDIQ vehicle established by AHRQs ACTION network\nEngaging patients and patient advocates to learn how an NTC could support their needs\nNTC Implementation\nBarriers to Implementation\nThe barriers to the implementation of an NTC include the following:\nDifficulties maintaining stakeholder engagement\nSecuring funds for expansion and maintenance of an NTC \nEnsuring PHI requirements are met (e.g., IRB approval for research projects)\nAddressing lack of interoperability across systems\nDeveloping patient cohorts for each use case\nFacilitators of Implementation\nActivities that would facilitate the implementation of an NTC include the following:\nProviding frequent feedback to NTC participants \nLeveraging ONC efforts to implement the 10-Year Interoperability Roadmap[endnoteRef:26] [26: ONC, Connecting Health and Care for the Nation: A Shared Nationwide Interoperability Roadmap, [Online]. Available: https://www.healthit.gov/sites/default/files/hie-interoperability/Roadmap-Executive%20Summary-100115-4pm.pdf. [Accessed 6 May 2019].\n] Developing standard HHS pre-approved IRB protocols (i.e., for research)\nIdentifying methods to deliver value to payors\nExamining and/or implementing HIPAA-permitted uses and disclosures that would support the disclosure of PHI to another covered entity without patient authorization[endnoteRef:27] [27: HHS, Understanding Some of HIPAAs Permitted Uses and Disclosures, [Online]. Available: https://www.hhs.gov/hipaa/for-professionals/privacy/guidance/permitted-uses/index.html. [Accessed 6 May 2019]. NOTICE This (software/technical data) was produced for the U. S. Government under Contract Number HHSM-500-2012-00008I, and is subject to Federal Acquisition Regulation Clause 52.227-14, Rights in Data-General. \nNo other use other than that granted to the U. S. Government, or to those acting on behalf of the U. S. Government under that Clause is authorized without the express written permission of The MITRE Corporation. \nFor further information, please contact The MITRE Corporation, Contracts Management Office, 7515 Colshire Drive, McLean, VA 22102-7539, (703) 983-6000. \n \nApproved for public release. Distribution unlimited [19-3507].\n] Utilizing modern standards, such as Fast Healthcare Interoperability Resources (FHIR)\nSustainability\nBarriers to Sustainability\nThe barriers to sustainability of an NTC include the following:\nRisk of dependence on government funding (i.e., need to develop a business model that ensures financial independence of an NTC)\nPerception of insufficient return on investment for test executors\nPerception that NTC may not meet the needs of all stakeholders\nRisk of difficulty sustaining stakeholder engagement\nFacilitators to Sustainability\nActivities that would facilitate the sustainability of an NTC include the following:\nProviding frequent feedback to NTC participants\nProviding evidence-based progress reports to the stakeholders\nDeveloping strong multi-stakeholder governance\nDeveloping a stable business model for funding that is not exclusively governmental but based upon public-private partnerships (i.e., viable revenue model)\nGovernance\nBarriers to Governance\nThe barriers to governance of an NTC include the following:\nStakeholders varying and sometimes competing priorities\nSpecifying the governance body (e.g., federal governance versus public-private governance)\nCost to establish a governing body and governance model\nFacilitators to Governance\nActivities that would facilitate the governance of an NTC include the following:\nEngaging a diverse group of stakeholders who are committed to an NTC\nEnsuring a transparent and open process of decision making\nPromoting a public-private partnership\nExamining existing efforts for national governance of health IT by ONC such as the TEFCA\nScalability\nBarriers to Scalability\nThe barriers to scalability of an NTC include the following:\nEnsuring funds from sources outside the federal government to support NTC maintenance\nLack of interoperability across systems\nFacilitators to Scalability\nActivities that would facilitate the scalability of an NTC include the following:\nDeveloping a payment model for participation/use (e.g., participant fees, use fees)\nDeveloping a public-private partnership from the beginning of the NTC development process\nLimitations\nThis analysis was limited to qualitative input from five sourcesa self-selected group of RFI respondents; a group of federal stakeholders within HHS; Health FFRDC subject matter experts; web-based research; and additional outreach to AHRQ. \nSummary\nEstablishing an NTC will be a complex, multi-dimensional effort that will require robust design, sustained stewardship, and financial support. As described, prior efforts in this space failed to become viable options; some of the factors cited as reasons for these failuresinsufficient early stakeholder engagement and lack of consensus among stakeholders; the associated time requirements and opportunity costs for participants; the challenges associated with legal and technical aspects of privacy, security, and data sharing; and lack of development of a sustainable business model early in the development and implementation phasesare key areas that must be addressed and have solutions in place to build a viable NTC. Critical building blocks will include the following: organizing a multi-disciplinary stakeholder group for governance, developing incentives that induce participation, developing solutions for PHI protection and data sharing agreements, and securing a stable funding source to help build a sustainable infrastructure. \nBased upon this initial analysis, the Health FFRDC recommends the actions listed in the following section to further the goal of establishing an NTC. \nRecommendations\nThe following recommendations were generated as part of this analysis regarding next steps to achieve the NTC.\nConduct a thorough assessment of prior efforts to develop scalable real-world testbeds and tools, including landscape analyses and data calls for information generated from prior efforts to understand the root cause of failed efforts.\nEngage stakeholders to determine stakeholder interests, needs, expectations, and level of interest/influence. This will assist in targeting key stakeholders given limited resources.\nIdentify and engage with interested stakeholders from the critical stakeholder list to form a governance group; consider engaging HHS stakeholders at all organizational levels (i.e., from executive to staff level) to create more visibility and buy-in for an NTC.\nEngage with stakeholders from AHRQs ACTION network to assess the viability of building on their contracting mechanism through the possible inclusion of additional and NTC-relevant organizations.\nDevelop an incentive plan to engage participants. Leverage this plan to develop a summary document for participants and other stakeholders to understand how they may benefit from participation in an NTC.\nDevelop a vetting and triage checklist to assess potential participants.\nPlan the implementation of an NTC as a phased approach, starting with a pilot, to ensure opportunities to build on lessons learned at each implementation phase.\nDevelop a business plan that will ensure sustainability of an NTC (e.g., public-private partnership). Acknowledgements Special thanks to the following individuals for their contributions to the analysis of the responses to the RFI on the NTC: Matthew Eblen\nLaura Mann\nAbigail Viall 2 References NTC Test Executor\nTest Executor Test Executor(s) Test \nEnvironment Production \nEnvironment Test Originator 1. Available Test Type Options\n2. Available Clinical Setting Options\n3. Available Cohort Options\n Test\nSpecification Test\nResults 1. Selected Test Type Options\n2. Selected Clinical Setting Options\n3. Selected Cohort Options\n NTC Test Executor\nTest Executor Clinical Site(s) EHR\nTest Environment EHR\nProduction Environment eCQM Developer eCQM\nSpecification eCQM\nResults 1. Available eCQM Test Types\n2. Available Clinical Setting Options\n3. Available Cohort Options\n 1. HQMF eCQM, CQL logic, \nQDM data model\n2. Ambulatory Provider\n3. Diabetic Patients\n NTC Clinical Site\nClinical Site RegistryClinical Site(s) EHR\nTest Environment EHR\nProduction Environment CDC Test \nEnvironment Production \nEnvironment Data Import\nStatus\nReport Required Data\nElements and \nRegistry Info Extraction\nStatus\nReport Required Data\nElements and \nSource Info 1. Available Registry Test Types\n2. Available Clinical Setting Options\n3. Available Cohort Options\n 1. Patient Tracking\n2. Ambulatory Provider\n3. Diabetic Patients\n Test\nData ",
    "text": " Technical Document Deliverable, 2019 Sponsor: US European Command, Director J39\nDept. No.: P663 \nContract No.: W56KGU-18-D-004-S120\nProject No.: 0719S120-J3 The views, opinions and/or findings contained in this report are those of The MITRE Corporation and should not be construed as an official government position, policy, or decision, unless designated by other documentation. Approved for Public Release; Distribution Unlimited. Public Release Case Number 19-2694. \nAll rights reserved. McLean, VA Mp190571 \nMITRE PRODUCT Operational Art/Operational Maneuver Groups in Space Conceptualizing a Potential Russian Approach Author: Timothy L. Thomas August 2019 xii Abstract\nThis article considers Russias potential use of operational art in space for three reasons. First, Russian Defense Minister Shoygu has called aerospace the new center of gravity for future conflicts. Second, Russias military is testing how to maneuver satellites to conduct space operations, since destroying the enemys group of satellites and depriving him of communications, navigation, and reconnaissance capabilities determines victory today in the militarys opinion. Finally, Russian analysts expect the emergence of new forms of military operations in near space to defeat orbital alignments of forces, suppress radio communication systems in space, and block orbital alignments of forces and means in specific areas of space. Executive Summary\nWhile it is not known for certain whether Russia utilizes operational art in space, there is growing circumstantial evidence supporting that contention. First, Russia considers space as a theater of military operations (TVD), within the boundaries of which operations of a strategic force can be organized and conducted. This TVD hosts Russian satellites of various types that gather and pass information, conduct reconnaissance and communication functions, and maneuver alone or in groups, among other functions. Second, in a 2009 article in Russias Air-Space Defense, one author was identified as a teacher of the spacecraft launch and command and control forces operational art and tactics department of the Military-Space Academy. Third, Russian Defense Minister Sergey Shoygu has called aerospace operations, of which space is an important element in Russian theory, the center of gravity of future conflicts. Fourth, in a 2018 article in the journal Military Thought on modern methods of aerospace and air defense practices, the author stated such forces must (not may, must!) use the theory and practice of operational art and its methods and techniques. Finally, satellites and other equipment are capable of employing the principles of operational art, which include the conduct of deep operations, envelopment, and maneuver; and attacking weak flanks in an integrated and planned fashion, in space. These principles could be carried out in the following way:\nDeep operations could involve Russian strikes against satellites in space or against underwater cables or the use of special operations to destroy critical infrastructure targets (SODCIT) criteria. Satellites perform maneuver operations often to inspect other satellites or to perform other missions.\nSpace is underdeveloped at the moment, which indicates it could remain for some time as a place for maneuver.\nMoving satellites to more favorable positions enable either strikes against adversary equipment or the achievement of a strategic position in a specific orbit, such as to conduct inspections of other satellites.\nThe use of satellites as an operational maneuver group would be an unconventional form of using such assets and would consist of both ground and space-based weapons that can influence the TVD.\nRussian analysts write that practically every US weapon is hooked to satellite communications, GPS navigation, and the mobile Internet. Russian EW operators claim to be able to shut these space channels down with ease. \nSpace may now be considered a flank for planetary operations.\nSpace assets that maneuver in the form of groups can operate in deep space to envelop an opponent. The majority of these operations are present in the planning of Russian aerospace operations today. \nThe actual equipment employed in space or on the ground (and aimed at space objects) at the moment includes the following items that are capable of conducting maneuver and deep/planetary operations in near or deep space:\nInspector satellites, such as the Kosmos 2521\nKiller satellites\nTirada-2s, to thwart communications\nRudolf, anti-satellite strike system\nNudol, anti-satellite and missile system\nPeresvet combat laser\nGround stations that can jam objects in space\nMiG-31armed with anti-satellite missiles\nSpace junk that comes alive\nReconnaissance-strike complexes or information-strike systems\nAlso, ground based hackers should be included, since they have attempted to take control of satellites, such as theoretically occurred in 1998.\nRussian authors contend that satellites can guide weaponry to distant shores or be the focal point from which an operation unfolds. In a global conflict the destruction of the enemys group of satellites is vital to success, since it deprives him of communications, navigation, and the capability to conduct reconnaissance. The following citation indicates what distant targets might include:\nIt is possible to use various space systems in support of each of these operations. Thus, supporting a strategic operation to destroy critically important enemy targets necessitates the use of space-based means of reconnoitering these targets; electronic intelligence assets; meteorological reconnaissance assets in the interests of a proper selection of attack weapons and their combat employment methods; and space-based navigation, communications, relay, and strike evaluation systems.[footnoteRef:1] [1: Vasiliy Y. Dolgov,and Yuriy D. Podgornykh, Space As a Theater of Military Operations: On Possible Forms and Methods of Combat Employment of Space Command Forces and Assets, Vozdushno-Kosmicheskaya Oborona Online, 10 April 2013.] Therefore, the emergence of new forms of military operations in near space can be expected that would aim to block and defeat orbital alignments of forces while suppressing radio communication systems in specific areas of space. Satellites, due to their ability to maneuver and move singularly or in swarms, could be capable of acting as an operational maneuver groups (OMG) in space. A contemporary space OMG potentially would consist of reconnaissance-strike units, satellites of various types, counter communication units, and other assets combined into a single organism. These assets are available but it is unclear if the Operational Art Department at the General Staff Academy has plans for using space assets in a space TVD. Table of Contents \n1 Introduction 1\n1.1 Definitions of Operational Terms 3\n1.2 Operational Art: Summaries of a Few Important Discussions 5\n2 The Writings of General of the Army Makhmut Gareyev 12\n3 US Experts Jacob Kipp and David Glantz on Russian Operational Art 14\n4 Russian Use of Operational Art and Maneuver in Space 16\n5 Conclusions 21 Introduction\nToday, circling high above Earth, are over 2,000 satellites. Some are of commercial origin and some military. In the latters case, they are responsible for watching military equipment and troop movements in other nations, coordinating command and control activities, and helping weapons and forces navigate their way across the globe, among other issues. Their importance to the way nations plan to deter or conduct modern warfare is hard to overestimate. \nRussias military is and has been deeply embedded in the study and use of such space activities, from the launch of Sputnik in 1957 to todays US reliance on Russian rockets to send astronauts to the International Space Station. In addition, Russian military thinkers are probing deeper into finding ways to use space for military advantage. This domain continues to escalate in importance. In 2015, Russian Defense Minister Sergey Shoygu conceded that aerospace is now the center of gravity (COG) of future wars,[footnoteRef:2] a reference made even earlier in 2011 by Makhmut Gareyev, a long-time prominent military theorist who is a General of the Army and President of the Academy of Military Science.[footnoteRef:3] In 2018 Shoygu added that precision-guided munitions and reconnaissance and electronic warfare systems are exerting ever greater influence on the development of operational art.[footnoteRef:4] Another 2018 article on modern methods of aerospace and air defense practices noted that these forces must (not may, must!) use the theory and practice of operational art and its methods and techniques.[footnoteRef:5] [2: Interfax (in English), 3 August 2015.] [3: M. A. Gareyev, On the Organization of the Russian Federations Aerospace Defense, Journal of the Academy of Military Science, No. 2 2011, p. 40.] [4: No author provided, Russian Federation Defense Minister Sergey Shoygu Opened Russian Federation Armed Forces Operational-Mobilization Leadership Conference, Ministry of Defense of the Russian Federation, 12 February 2019.] [5: A. P. Korabelnikov, Modern Methods of Aerospace and Air Defense of Facilities and Prospective Development Trends, Military Thought (in English), Volume 1 2019.] The thoughts of such Russian experts and leaders make it appear imperative for the West to study and conceptualize how operational art might be applied to the aerospace domain where many of these new capabilities or their control mechanisms are found. Questions abound as a result. Would the use of such a domain be considered separately or, more likely, in conjunction with other operations such as ground-based maneuver brigades? What would joint domain operations look like and how would they be implemented? What would be the configuration of an operational maneuver group (OMG) in space? \nRussian authors have noted in the past that operational art, which includes the preparation and planning of missions for large-strategic formations, should not stand still or degrade[footnoteRef:6] and many authors support this contention. In 2012, for example, Gareyev noted that OMGs, a popular Soviet
operational term of the 1980s, were liquidated with the fall of the Soviet Union but that OMGs will obviously be used in some form or another in the future.[footnoteRef:7] Such observations most likely have created a mandate for the Operations Department of the General Staff or professors at the General Staff Academys Department of Operational Art to continue to work on this theory. Now, as opposed to past developments, theorists must take into consideration the impact of a series of technological advancements that not only affect the theorys content but also its reach, which can extend to the heavens (satellites) or under the oceans (cables, submarines, etc.). [6: V. K. Kopytko, The Evolution of Military Art, Military Thought (in English), Volume 1 2008.] [7: M. A. Gareyev, The Living Embodiment of the Brain of the Army, Arsenal Otechestva, No. 2 2012, published 17 June 2013 at http://arsenal-otechestva.ru/article/111-mozg-armii. ] Maneuver, deep operations, and breakthroughs are traits that have long characterized operational arts ground operations. They work in space as well. Satellites maneuver and conduct operations such as extended reconnaissance, inspection, navigation, and other activities. Since operational art planners are not standing still, they may well be working on coordinated and integrated methods to align capabilities with operations in this or in other domains. An operational group, it must be remembered, is a temporary large strategic formation that consists of front forces operating on a separate operational direction or sector of the front,[footnoteRef:8] which in this proposed case would be a space axis. Thus, while the focus is often on Russian maneuver brigades creating an optimal fighting force on the ground, Russian planners may simultaneously be creating an optimal fighting force in space. [8: S. F. Akromeev, main editor, Military Encyclopedic Dictionary, Second Edition, Moscow: Military Publishing House, 1986, p. 513.] Before developing operational art theory, Russian planners look to the future through the prism of trends and forecasting. Operational art theory is then adjusted based on the results of the inquiry to ensure it remains ahead of the present strong technological curve that is driving advances in capabilities. Russias host of new technological achievements in weaponry that President Vladimir Putin touted in March 2018 offer proposed guarantees of strategic stability and parity with other nations for the Kremlin. These new achievements also affect the preparation and planning of operational art for specific new domains, such as space.\nThis article will attempt to refocus attention on how operational art might be applied to the space domain in Russias planning process. Thinking in such terms opens up other vectors for planners to consider beyond just ground operations. These variants can add input to contested environment operations as well, such as when examining Russias potential operations in the Baltic and Central Europeans areas or even beyond to global operations.\nA brief discussion of Russias concept of an operation in general and operational art in particular is offered, along with the added concepts of an operational plan and a concept of operations, the components of operational art. That initial discussion of definitions is followed with some limited comments on operational art by the noted Soviet theoreticians Aleksandr A. Svechin and Georgiy Isserson. The views of other prominent Soviet military theorists views on operational art can be found elsewhere.[footnoteRef:9] Svechin and Issersons discussion is followed by more recent discussions on operational art since 1999, which have been few in number. These Russian sources are followed by the work of two US experts, David Glantz and Jacob Kipp, both of whom have written many articles, and even books, on the concept. Their analysis is important, even though truncated here, for it looks at Russian military literature on the topic of operational art from 1914 to more recent times. The article then concludes with a look at Russian satellite and space operations, to include how that nation has tested maneuvering satellites and preparations and plans for operations in space. [9: See, for example, Wilson C. Blythes interesting discussion of other prominent Russian officers views on operational art in World War II and earlier time periods (includes the views of Mikhail Tukhachevsky, N. E. Varfolomeev, Vladimir Triandafillov, etc.) in his work A History of Operational Art, Military Review, November-December 2018, pp. 37-49. The discussion covers US and other nations views on operational art in addition to Russian views.] Definitions of Operational Terms \nThere are a few examples of what might be termed official definitions of Russian terms, and they can be found in Russias Military Encyclopedic Dictionary and its Military Encyclopedia. There are only a few differences in the two sources used here, the 1986 Military Encyclopedic Dictionary and the eight volumes written between 1995-2003 that compose the most recent Military Encyclopedia. In the latter case only small snapshots of the definition are offered. The point of the comparison of the two sets of definitions is simply to demonstrate consistency, and therefore should be skimmed.\nOperational art is defined in the Soviet Unions 1986 Military Encyclopedic Dictionary as Encompassing the theory and practice of preparing for and conducting combined-arms, joint, and independent operations (combat actions) by large strategic formations of the armed forces by various branches.[footnoteRef:10] Its tasks include the following: [10: S. F. Akromeev, main editor, Military Encyclopedic Dictionary, Second Edition, Moscow: Military Publishing House, 1986, p. 513.] An investigation of the mechanisms, content, and nature of modern operations and other forms of the operational employment of large strategic formations;\nAn elaboration of the means of preparing for and conducting operations, the means and methods of organizing and maintaining coordination, the comprehensive support of troops taking part in operations, and the command and control of them; \nAn elaboration of the operational requirements for organizing and arming large strategic formations;\nThe development of recommendations for the operational equipping of theaters of military operations;\nThe study of the views of potential adversaries for the conduct of military actions on an operational-scale.[footnoteRef:11] [11: Ibid.] The term operational art was first used in 1922. The division of military art into strategy, operational art, and tactics did not take place until 1926. During World War II, operational art evolved further in the preparation for and conduct of operations.[footnoteRef:12] In the post-war period, new areas developed in connection with the following: [12: Ibid.] Equipping the Armed Forces with new weaponry and military equipment;\nIncreasing the combat capabilities of troops;\nThe increased scale and intensity of warfare and the mutual penetration and interlacing of the various types of operations;\nAnd the need to conduct principal operations with the joint efforts of the various branches of the Armed Forces.[footnoteRef:13] [13: Ibid., p. 514.] Operational art was defined in 2002 in Russias Military Encyclopedia as Encompassing the theory and practice of preparing for and conducting military operations on an operational scale (operations, battles, combat operations, strikes) by large formations of various branches of the armed forces. Operational art occupies an intermediate position between strategy and tactics[footnoteRef:14] [14: S. B. Ivanov, Main Editor, Military Encyclopedia, Moscow: Military Publishing House, Vol. 6 2002, p. 63. The entire discussion of operational art was on pages 63-67.] An operation was defined in the 1986 Military Encyclopedic Dictionary as \nAn aggregate of battles, engagements, strikes, and maneuvers, coordinated and interlinked in objective, task, place, and time by various force organizations, conducted simultaneously and sequentially according to a common concept and plan, to accomplish missions in a theater (theaters) of military actions, a strategic or operational direction (in a specific area or zone) within a specified period of time; a form of military action.[footnoteRef:15] [15: Akromeev, pp. 514-515.] Designations include strategic, front, and army, which can be further differentiated as offensive and defensive or initial and subsequent according to time and sequence of execution. Principal indicators include the number of troops taking part, the width of a zone of action, and the depth or rate of advance. Influence on the content of operations is exerted by war aims and the nature of operational missions performed, military-economic capabilities of the state, and the combat capabilities of both sides.[footnoteRef:16] [16: Ibid., p. 515.] An operation was defined in the 2002 Military Encyclopedia as \nAn aggregate of battles, engagements, strikes, and maneuvers, coordinated and interlinked in objective, task, place, and time by various force organizations, conducted simultaneously and sequentially according to a common concept and plan to accomplish strategic, operational-strategic, operational, or operational-tactical missions in a theater of military operations, a strategic or operational direction, or in a specific vast area (zone) within a specified period of time; a form of military operation.[footnoteRef:17] [17: S. B. Ivanov, Main Editor, Military Encyclopedia, Moscow: Military Publishing House, Vol. 6 2002, p. 77. ] An operational plan was defined in the 1986 Military Encyclopedic Dictionary as \nthe manner, procedure, order and methods of accomplishing military missions as determined by a commander. It includes the concept of operation (s) (commanders concept), missions of the troops, fundamentals of coordination, support, and the organization of command and control. The operation plan (battle) is the basis of the command and control of troops. It is made as a result of sizing up
military missions and an estimate of the situation. Data for decision-making is prepared by the staff, chiefs of combat arms, special troops, and services. Operational planning is usually done with a map and refined on the terrain at the first opportunity. In ground force subunits all work connected with decision-making is as a rule performed on the terrain. The operation plan (battle) is detailed in the operational planning process; it is formally articulated on a map, with an explanatory note appended.[footnoteRef:18] [18: Ibid., p. 634.] In 2003 the Military Encyclopedia defined an operational plan as\nthe manner, procedure, order, and methods of accomplishing military missions as determined by a commander. It includes the concept of operation (s) (commanders concept), missions of the troops, basic questions for coordination, and the basic organization of command and control.[footnoteRef:19] [19: S. B. Ivanov, Main Editor, Military Encyclopedia, Moscow: Military Publishing House, Vol. 7 2003, p. 229.] A concept of operations was defined in the 1986 Military Encyclopedic Dictionary as \nbasic decisions about forthcoming combat operations. It determines: the direction or axis of the main attack and other thrusts (areas of concentration of main efforts); the sequence and methods of defeating an adversary; the order for delivering fire for effect and, in a nuclear war, nuclear weapons of destruction; group and operational orders of battle (battle disposition).[footnoteRef:20] [20: Akromeev, p. 264.] The 1995 Military Encyclopedia defined a concept of operations more explicitly as follows:\nThe basis for a decision to conduct an operation (battle); the main idea for the method by which a force grouping conducts an assigned strategic, operational, or tactical combat mission in a military theater, along a strategic (or operational) axis, or in an area of terrain. In the zone of operation (battle) the following are defined: the areas where the main efforts are concentrated (the axes of the primary and other strikes); the methods for defeating the enemy (which force groupings, where, in what sequence, and how the defeat will be accomplished; the kind of fire or nuclear strike, and measures to deceive the enemy); the force grouping and their operational composition (order of battle).[footnoteRef:21] [21: P. S. Grachev, main editor, Military Encyclopedia, Moscow: Military Publishing House, Vol. 3 1995, p. 238.] Operational Art: Summaries of a Few Important Discussions\nIf Russia ever did decide to intervene in Europe, whether it be in the Baltics or by attacking Central European countries, or if it decided to conduct operations on a global scale in conjunction with an ally, it is reasonable to assume that the planning of operations and operational art would be a focal point. Operational art is of special interest for its use of front and army operations on a large-scale. The latter has been evident in Russias yearly exercises in specific military districts (south in 2016, west in 2017, east in 2018, central upcoming in September 2019) or their special operational pairing with Chinas military. And not to be forgotten is whether, on a mass scale that includes space, Russia would consider the use of operational art on a planetary scale. \nThe analysis that follows will initially look at two short summaries from the works of General Aleksander Svechin and General Georgiy Isserson, two of the most prominent Soviet authors on operational art in the pre-World War II period. Their short summaries are followed by several works on operational art in Russia over the past 18 years. Surprisingly, very little has been written on the issue recently. Still, the articles that did appear offer several elements of operational art to consider when theorizing what a larger Russian campaign may look like.\nGeneral Aleksander Svechin\nIn the 1927 work Strategy by Aleksandr A. Svechin, the noted Russian theorist, there was a section on operational art. Svechin noted that tactical creativity is governed by operational art, and that operational art sets forth a series of tactical missions and logistical requirements based on the goal of an operation. Operational art depends on the manner in which an operation is conducted, material available, time allotted for tactical missions, forces deployed for battle on a certain front, and the nature of the operation itself. Operational art must take into account the possibilities presented by the immediate rear (front logistics). Only on occasion is an ultimate goal achieved in a single battle with combat operations. Rather, it requires a series of operations separated by pauses in different areas of a theater, due to the immediate goals of forces in these areas. An operation consists of drawing up a plan; logistical preparations; the concentration of forces at the starting position; the building of defensive fortifications; marching; fighting battles that encircle or destroy a portion of an adversarys force and force the withdrawal of other forces due to an envelopment, breakthrough, or holding of a line in a geographical area. An operation can become an act of war if the efforts of troops are directed toward the achievement of a certain intermediate goal in a certain theater of military operations without any interruptions.[footnoteRef:22] Svechins comments provided much of the initial impetus behind the concept of operational art and strongly influenced the years of work on the concept that followed. [22: A. A. Svechin, Strategy, Military Bulletin 1927, as translated and published by East View Publications, Minneapolis Minnesota, 1992, Kent Lee editor, pp. 68-69. The work is preceded with introductory essays on Svechin written by Russian Major-General (retired, now deceased) V. V. Larionov; former Russian Security Council Chief and Deputy Minister of Defense A. A. Kokoshin; former Soviet Chief of the General Staff V. N. Lobov, and noted US historian of Russias military, Jacob W. Kipp.] General Georgiy Isserson\nIsserson is well known for his seminal work entitled The Evolution of Operational Art. In his preface to the second edition of the work, in May 1936, he wrote the following:\nThe very essence of operational art presupposes freedom of methods and forms which should be carefully chosen each time to fit a concrete situation. All the propositions we advance in the field of modern operational art should be treated as orienting ideas, which find this or that concrete expression only in a given genuine situation.\nTherefore, the present work would be of negative value if the ideas it advocates were treated as ready-made schemes. There can be no such schemes in operational art. We aim to show essential distinctions between the conditions of our era with its new forms of the deep operation and the operational art of the past. This is the only significance ascribed to the propositions advanced in the present work.[footnoteRef:23] [23: For a translation of this work, see https://www.armyupress.army.mil/Portals/7/combat-studies-institute/csi-books/OperationalArt.pdf.] Issersons comments accord with the well-established Russian view that there should be no stereotyping in the development of military affairs, a view reiterated by a host of contemporary military theorists. \nMajor-General E. G. Korotchenko, retired\nIn 1999, writing in Voennaya Mysl (Military Thought), Korotchenko described where operational art was heading. He noted that the revolution in military art has launched a radical revision of ideas of the place and role, forms and methods of armed, information, and psychological confrontation.[footnoteRef:24] An important trend is that warfare is switching to a functional-structural and selective impact type of operation. This represents a departure from a principle of using force on force to one using the principle of asymmetrical threats. Assets designed to disorganize command and control of an enemy task force are now important, where a key trend is the evolution of operational forms and means of warfare and the emergence of new ones.[footnoteRef:25] The growing potentials of air and space warfare are increasingly influencing the theory and practice of operational art.[footnoteRef:26] The prevention of an enemys domination in space is now important and commanders must employ the potentials of our space-based systems to the utmost when preparing operations and waging hostilities.[footnoteRef:27] This is because the course and outcome of operations are dominated by space and missile forces. [24: E. G. Korotchenko, Operational Art Today: Where It Goes, Voennaya Mysl (Military Thought), No. 1, 1999 (in English), p. 13.] [25: Ibid., p. 14.] [26: Ibid., p. 15.] [27: Ibid.] Maneuver, a typical trend of operational art, has a more important role to play under the current advanced technological situation. Commanders will have to adopt ways to ensure freedom of maneuver. This requires the constant interaction among all services during an operation and an increased reliance on timely logistics. Warfare may be constantly waged along the entire depth of a large strategic formations operational deployment. Finally, there is a trend toward greater complexity in operational planning due to the shorter time for preparations. An adversary can prepare the ground for an operation with information and other techniques long before a military conflict begins. Thus, it is important to study how all of these factors affect operational art and to identify the direction in which it is heading.[footnoteRef:28] [28: Ibid., pp. 15-18.] Colonel-General V. Zherebtsov of the Operational Art Department\nOn 11 April 2001 the Department of Operational Art at the Military Academy of the Russian Federation Armed Forces General
Staff celebrated its 65th anniversary. In recognition of that event, the chief of the department, Colonel-General Vyacheslav Zherebtsov, penned an article on operational art for the paper Krasnaya Zvezda (Red Star). He wrote that discussing operational art was now an obligation, since the large battles of World War II had been replaced with different armed conflicts (internal, border, etc.) due to separatism and the escalation of such conflicts, such as in Chechnya, on the soil of interethnic, territorial, religious, and other differences.[footnoteRef:29] This has required securing victory through skill and ability instead of just by numbers, and required a reassessment of how to implement operational art. Peacekeeping, for example, has become a new direction for operational art. A pressing issue has become the adaptation of the theory and practice of operational art to the radical changes in the military-political situation at the turn of the century, and the need to learn lessons and draw conclusions from the experience of local wars and armed conflicts of recent decades[footnoteRef:30] [29: Vyacheslav Zherebtsov, Military School: Ensuring That the Thinking Is Ahead of the Times, Krasnaya Zvezda (Red Star), 7 April 2001, p. 2.] [30: Ibid.] The direction of military art in the next 10-15 years, Zherebtsov predicted, would take the following directions:\nArmed struggle will transform into an information-focused armed confrontation;\nThere will be a new perception of operational arts content, to include its principles, forms, and methods of conducting operations under conditions of an information-focused confrontation and the massive use of precision weapons;\nNew ways and means of resolving tasks will be unveiled to confront modern interstate and intrastate opposition;\nReliable nuclear deterrence must be ensured and there must be an increase in the combat capability and combat readiness of force groupings;\nProblems associated with repulsing strikes by superior enemy forces must be resolved;\nThe quality of command and control must be enhanced along with support for combat operations and for the mental and psychological preparation of personnel.[footnoteRef:31] [31: Ibid.] All of his predictions have proven to be correct.\nLieutenant-General A. N. Stolyarov of the Operational Art Department\nIn 2006 Lieutenant-General A. N. Stolyarov was appointed as the head of the Operational Art Department at the General Staff Military Academy. In 2007 he wrote an article for the journal Voennaya Mysl (Military Thought) on the history of the department since its founding in the 1930s. Near the beginning of World War II there were a few significant studies produced on operational art. They were:\nG. S. Issersons three works, The Evolution of Operational Art, Fundamental Principles of an In-Depth Operation; and The Initial War Period;\nE. A. Shilovskys three works, The Operation, Breakthrough and Exploitation, and Fundamental Principles of an Offensive Army Operation; and\nA. V. Kirpichnikovs Operations by Modern Mobile Armies[footnoteRef:32] [32: A. An. Stolyarov, The Evolution and Development of the Theory and Practice of Operational Art at the General Staff Military Academy, Military Thought (in English), Volume 3 2007. It is likely that this was an East View publication.] The Operational Art Department contributed to military theorys development during WWII. Professors closely followed wartime experience, identifying new trends and patterns in military arts evolution, and developing recommendations for the conduct of operations, battles, and engagements. In 1948, experiences from the war were included in an in-depth study of new socio-political factors, modern warfare, changes in combat configurations of large strategic formations, and how the organizational structure of military units would affect operational art. These results were used to examine major aspects of the organization and conduct of operations for the initial period of war.[footnoteRef:33] [33: Ibid.] At the end of the first post-war period, 1945-1953, A Comprehensive Course in the Operational Art was produced. From 1954-1961 the department studied problems of operational art with respect to nuclear warfare. It also produced a theoretical work titled A Course in the Operational Art in four volumes, published between 1957-1959. From 1962-1971, work was performed on developing forms and methods of training and indoctrination for military personnel. Further, new texts were produced on front and army operations dealing with matters concerning the preparation and conduct of operations with the use of nuclear and other types of new weapons, to include future ones.[footnoteRef:34] [34: Ibid.] During the period 1972-1990, attention was given to breakthroughs in the development of conventional weaponry and to new forms and methods of operations using them. In particular this pertained to precision weaponry and its impact on future operations. From 1988-1996 the Operational Art Department developed 16 concepts (not specified further) that were enshrined in legally enforceable documents of the General Staff.[footnoteRef:35] However, it was noted that changes in that period did include those associated with meeting engagements and counter assault and counter insurgency operations, as well as operational concealment, deception, and camouflage. In 1993, it was noted that research regarding local wars and armed conflicts and peacekeeping operations was expanded along with the interaction of branches and arms of service and a priority focus provided to the preparation and conduct of front and army operations in a large-scale war with reduced-strength formations.[footnoteRef:36] [35: Ibid.] [36: Ibid.] At the start of the 21st century, a new evolution of operational art took place, Stolyarov added. This was due to the growing evidence of the threat not only of armed conflicts and large-scale terrorist attacks, but also local and regional wars affecting the Russian Federation.[footnoteRef:37] A significant landmark in 2002 was the publication of the work Operational Art: The Present and the Future. Developed by a team of writers, to include Lieutenant-General A. N. Zakharov and Major-General E. G. Korotchenko, the work identified trends and problems with improving the concept. A few years later, new textbooks were produced on the fundamentals of operational art. Defensive and offensive operations were praised, as was a chapter on the basic principles of operational art. Combined-arms operations, forms of military action, effective engagements of enemy forces, and a substantiation of combat strength levels of force in strategic sectors were also addressed.[footnoteRef:38] [37: Ibid.] [38: Ibid.] Stolyarov noted that operational art faces new tasks, such as containing an aggressor at an early stage of a crisis situation, and conducting large-scale operations simultaneously in several regions amid a wide use of new weaponry. This may also include the employment of unconventional forms and methods of combat action, he noted. There exists a pressing need for conducting air and defensive operations by operational-strategic groupings in strategic sectors, and information warfare operations must also be countered. The countering of weaponry includes precision guided weapons, automated command and control, and reconnaissance systems. The operational art department is concentrating its efforts on developing new, unconventional forms and methods of employing large strategic formations and groupings of forces in both large-scale and local wars, as well as in armed conflicts.[footnoteRef:39] The department is analyzing and forecasting the consequences of expected trends in military developments as a whole and operational art in particular. The author ended this article in 2007 noting that in the very near future, substantial changes will occur in the theory and practice of operational art.[footnoteRef:40] [39: Ibid.] [40: Ibid.] Major-General V. K. Kopytko of the Operational Art Department\nMajor-General V. K. Kopytko became a professor at the Operational Art Department of the General Staff in 2000. He wrote in 2008 on the Evolution of Operational Art for the journal Military Thought and defined operational art as a system of theoretical knowledge and practical recommendations on how to prepare and conduct different forms of military operations at the operational-strategic, operational, and operational-tactical levels.[footnoteRef:41] His article was broken down into specific sections addressing the issue of military art; a history of the development of operational art (from WW I to 2008); a definition of operational art; a breakdown of the theory and practice of operational art and the tasks that accompanied them; the structure of operational art at the current stage; and the impact of objective and subjective causes and conditions that assist in the modern development of operational art. This section will only address the last two elements of Kopytkos article, since many of the historical aspects were covered in Stolyarovs presentation. [41: V. K. Kopytko, The Evolution of Military Art, Military Thought (in English), Volume 1 2008.] Kopytko wrote that operational art is composed of the following: combined arms operational art (combined arms of large strategic formations), operational art of the services and the centrally controlled arms (Strategic Missile Troops, Airborne Troops, and Space Troops), and operational art of the operational rear services. The structure is not constant but develops in line with the evolution of both weaponry and new combat arms and forces. The impact of subjective factors on operational art is considerable but only if analysts fully and comprehensively estimate the objective factors before them.[footnoteRef:42] [42: Ibid.] The influence of objective factors on operational art include a host of issues, such as: \nThe military-political situation in the world; \nQualitative and quantitative improvements in weaponry and equipment; \nThe states internal economic, political, demographic, and social condition; \nThe state of the Armed Forces; \nThe composition and state of the Armed Forces of
potential adversaries (and shifts in their methods of preparation and conduct of operations); \nThe evolution of strategy and forms and methods of its employment; \nAnd the historical experiences (lessons learned) of wars and armed conflicts.[footnoteRef:43] [43: Ibid.] The newest objective factor in 2008, naturally, was the all-round informatization of military affairs.[footnoteRef:44] Information confrontation in general, Kopytko noted, is emerging as a major component of all types of future warfare. Information-related advances in capabilities and other changes offer the possibility to automate the collection and processing of data on an opponent; the ability to react practically in real-time to changes in the situation; and the ability to assign missions to troops quickly and to supervise the efficiency of fire strikes.[footnoteRef:45] [44: Ibid.] [45: Ibid.] Subjective factors influencing the development of operational art were the activities of top political and military personnel that influence the development of the military organization and doctrine of the state; the level of ideas associated with the development of operational art and its implementation; training of troops; and the state of military science and the educational component of its leaders.[footnoteRef:46] [46: Ibid.] Other Sources\nOther than these longer discussions of operational art, there has hardly been any mention of the topic of operational art except for only a few scant references. A 2006 Military Thought article noted that the content of an operational method would include troop distribution, regions where the mission is to be accomplished (plus various modes of doing so and in what time); task force development and their operational formations; and troop maneuver means and material.[footnoteRef:47] A 2015 Novaya Gazeta article stated that Russian operational art has traditionally been built on the rapid pace of offensive operations supported by the constant buildup of troops efforts by means of rear echelons and the reserve, and the expenditure of ammunition in accordance with established destruction norms and densities.[footnoteRef:48] A 2018 article on modern methods of aerospace and air defense practices was the most useful. It noted that aerospace and air defense forces must use the theory and practice of operational art and its methods and techniques. This is a new premise for operational art, the issues of aerospace and air defense tactics. Operational art remains the issue of changing the situation in aerospace in ones favor. It is further enriched with tactical methods and techniques.[footnoteRef:49] [47: V. V. Barvinenko and V. R. Lyapin, On the Correlation of Operational Concepts and Methods, Military Thought (in English), Volume 4 2006.] [48: Vladimir Denisov, We Have Given Our Adversary a 15-year Advantage and We Cannot Win It Back, Novaya Gazeta Online, 2 December 2018.] [49: A. P. Korabelnikov, Modern Methods of Aerospace and Air Defense of Facilities and Prospective Development Trends, Military Thought (in English), Volume 1 2019.] The Writings of General of the Army Makhmut Gareyev\nRussian General of the Army Makhmut Gareyev is the author of numerous works on topics ranging from strategic deterrence to training to future warfare. He served at the Battle of Kursk in World War II and celebrated his 96th birthday on 23 July 2019. Dont be fooled by his age. He is still the President of the Academy of Military Science and often advises members of the General Staff. At major parades in Red Square he can usually be found sitting next to President Putin. Two of his works are chosen here (his work on aerospace issues is included later) for their references to operations and operational art. \nOn Frunze and Operational Art\nIn a 1985 book titled M. V. Frunze: Military Theorist,[footnoteRef:50] Gareyev outlined the military thoughts of Mikhail Vasilyevich Frunze on the latters centennial birthday. He believes that Frunze was able to correctly analyze historical processes and their impact on the development of military affairs. He credits Frunze for his continued use of historical examples and their application to contemporary thought. For example, Frunze pointed to the importance of intuition and scientific prediction as well as the need to grasp the inner logic of complex events. Conforming to the situational context is a major law of military art.[footnoteRef:51] Frunze did not favor a strategy of starvation or destruction, but rather, depending on the situation, the use of either strategy. He agreed with Marx that the offensive, with other conditions being equal, was better than the defense.[footnoteRef:52] [50: M. A. Gareyev, M. V. Frunze: Military Theorist, Moscow: Military Publishing House, 1985.] [51: Ibid., pp. 146, 148.] [52: Ibid., pp. 172-173.] Frunze considered the most effective method of countering enemy counterstrikes to be the use of preemptive active operations to thwart the concentration of enemy counterstrike groupings and the destruction of these piecemeal.[footnoteRef:53] Gareyev writes that one of the most difficult tasks is to foresee the possible nature of an enemys plans at a wars outset (the initial period of war) and work out methods to increase both combat readiness and the strategic deployment of the Armed Forces.[footnoteRef:54] This focus on the initial period of war appeared elsewhere in the book and indicates the importance that this lesson learned had for the Soviet Union when Gareyev authored this volume. At one point he stated that the role of the initial period of war will increase further and this may be the main and decisive period which largely predetermines the outcome of the entire war.[footnoteRef:55] Further, he added that the importance of past lessons act as particles of insipient new methods of conducting armed combat.[footnoteRef:56] The advent of the information and digital age has most likely only reinforced this belief in the mind of Gareyev and other Russia military planners. [53: Ibid., p. 177.] [54: Ibid., p. 229.] [55: Ibid., p. 237.] [56: Ibid., p. 238.] Gareyev wrote that operational arts theory arose when an operation began to be viewed as an aggregate of battles and engagements unified in a single overall plan broken in space and time. Developments in both operational and tactical maneuver made it possible to more thoroughly elaborate the methods for preparing and conducting operations.[footnoteRef:57] The basis of both operational and tactical maneuver, according to Frunze, was attacks against the weakest points (the enemy flanks and rear) and the envelopment and outflanking of enemy groupings combined with attacks from the front.[footnoteRef:58] He focused attention on encircling and destroying the enemy. Decisive actions would be possible with bold maneuvers. This meant carrying out operations without operational pauses, thereby preventing an enemy to get their bearings or to bring up reserves, and to organize the defense. Breakthroughs, Marshall of the Soviet Union G. K. Zhukov noted, offer opportunities for freedom of maneuver and the opportunity to hit the enemy from the worst sector (from the enemys perspective).[footnoteRef:59] [57: Ibid., pp. 200, 202.] [58: Ibid., p. 204.] [59: Ibid., p. 234.] Gareyev writes that In comparison with previous experience, this was a completely new phenomenon in operational art. For this reason, it was considered advisable to prepare ahead of time new troop groupings, to plan the maneuvering of resources, and increase the effort by committing reserves to battle.[footnoteRef:60] The focus on a new phenomenon could indicate Gareyev is implying interest in the concept of the OMG, but this was not specifically stated. [60: Ibid., p. 209.] On Marshall of the Soviet Union Nikolai Ogarkov\nWriting in Arsenal Otechestva in 2012, Gareyev discussed the career of General Staff Chief and Marshall of the Soviet Union Nikolai Ogarkov, who was Gareyevs boss in the 1980s. He writes that Ogarkov was inquisitive, innovative, and creative, and in possession of the ability to perceive new problems of military art. It was thus no surprise to Gareyev that Ogarkov served as General Staff Chief for seven years, dedicating much time on improving the organizational structure and work of commanders and staffs at both the operational-strategic and operational levels.[footnoteRef:61] [61: M. A. Gareyev, The Living Embodiment of the Brain of the Army, Arsenal Otechestva, No. 2 2012, published 17 June 2013 at http://arsenal-otechestva.ru/article/111-mozg-armii. ] Ogarkovs development of the forms and methods of operational preparation were most important. New problems in strategy and operational art were verified and developed, often through the use of exercises. He also worked to improve the relationship with political leaders but this did not end well. Gareyev writes that in 1979 Ogarkov told the Politburo that the introduction of Soviet troops into Afghanistan may have serious international consequences. He was interrupted by I. V. Andropov, head of the KGB at the time, who told him We have people who take care of politics; you solve the military task assigned to you.[footnoteRef:62] [62: Ibid.] Ogarkov continued to examine operational issues. He helped create the Center for Operational-Strategic research in the General Staff, a center later headed by General-Colonel V. V. Korobushin. Under Ogarkovs leadership, a five-volume Principles of the Preparation and Conduct of Operations was developed, volumes that contained important tenets of military art and operational-strategic principles of military doctrine. Gareyev added that the maneuvers conducted in 1981 were a creative effort on Ogarkovs part to introduce new operational-strategic ideas for the Armed Forces leadership. These maneuvers proposed an
aggressive advancement in the direction of the flanks as well as into the depths of the opposing force. To accomplish such tasks, formations and units were required to have high maneuverability, independence, and initiative in resolving combat assignments.[footnoteRef:63] [63: Ibid.] Most important of all, however, was the decision to create OMGs that could fulfill Ogarkovs developments, and Gareyev specifically mentioned the concept and its contents as follows: \nThe main difference between former mobile groups and them [OMGs] was that not only tank armies and divisions were used, but also separate army corps with special organizations, specially created to act as operational maneuver groups, where tank, motorized rifle, artillery, and other units outfitted with the latest equipment, amphibious combat infantry vehicles and armored transports, and self-propelled artillery were combined into a single organism. For the first time, an airborne-assault regiment and army aviation were included in the make-up of these corps.[footnoteRef:64] [64: Ibid.] Gareyev added that OMGs were liquidated with the fall of the Soviet Union but that operational maneuver groups will obviously be used in some form or another in the future. The main priority in the entire system of military development remains the operational-strategic vector.[footnoteRef:65] Again, it is important for a Western analyst to know what Gareyev meant by a form, for without this understanding, the potential realization of the concept is not clear.[footnoteRef:66] Thus, it is possible that OMGs could even be developed for space operations in some form or another. [65: Ibid.] [66: For an explanation of a form, see Timothy Thomas, Russias Forms and Methods of Military Operations, Military Review, May/June 2018, pp. 30-37.] US Experts Jacob Kipp and David Glantz on Russian Operational Art \nDr. Jacob Kipp was an analyst and then the director of the Foreign Military Studies Office at Fort Leavenworth, Kansas in past years. He is the author of numerous papers on Russian strategy and operational art and has served as a long-time consultant on Russian military affairs for numerous Pentagon offices. Kipp defined operational art as the conduct of war at echelons above corps and on the scale of theater-strategic campaigns.[footnoteRef:67] The term came into use, he notes, due to the development of new weaponry that not only extended the breadth and depth of the battlefield, but fires increased lethality. These weapons caused havoc in the development and application of combined arms, and offered new opportunities for maneuver. This forced more dependence on a commanders intellect (instead of just eyeballing a situation), which reduced chance to a question of probability. Calculations became based on an assessment of the mission, theater terrain, the enemys force, ones own forces, and time. All of these circumstances had to be taken into account as operations became more complex.[footnoteRef:68] [67: Jacob W. Kipp, The Origins of Soviet Operational Art: 1917-1936, in Historical Perspectives of the Operational Art, Michael D. Krause and R. Cody Phillips, General Editors, Center of Military History, Washington DC, 2005, p. 213. ] [68: Ibid., pp. 219-220.] Kipp added that operational art was defined by Aleksandr A. Svechin in a series of lectures on strategy in 1923-1924. These lectures described operational art as the bridge between tactics and strategy. N. Varfolomeev, a deputy head of the Department of Strategy during Svechins time, noted that the operation, which had become the base for understanding operational art, was the totality of maneuvers and battles in a given sector of a theater of military action to achieve a common objective.[footnoteRef:69] It was this concept of maneuver that appeared to take center stage in many discussions. It seemed that the less developed a theater of war, the greater were the opportunities of employing maneuver forms of combat. Maneuver was meant to disorganize and demoralize an opponent.[footnoteRef:70] [69: Ibid., pp. 214-215.] [70: Ibid., p. 224.] Svechins era, Kipp notes, was the time that the study of past campaigns, current trends in weapons development, and force structure requirements coalesced around the concept of operational art.[footnoteRef:71] Svechin, for example, had formulated two competing posturesannihilation and attritionas issues regarding the relationship between operational art and future war paradigms. Thoughts focused on combining breakthrough and deep pursuit operations in the conduct of annihilation operations. In such operations logistics became of critical importance in the accomplishment of operational art.[footnoteRef:72] [71: Ibid., p. 229.] [72: Ibid., pp. 230-231.] Noted Soviet General V. K. Triandafillov became an important advocate of operational art as well. He laid out in theoretical detail the military context for successive deep operations. Success in such operations, in accordance with the imprint of operational art, required an effective command and control system that would coordinate the operations of several fronts and the establishment of realistic logistical norms. Another Soviet General of renown, M. N. Tukhachevsky, was another advocate of operational art, arguing that it required the complete militarization of the national economy.[footnoteRef:73] [73: Ibid., pp. 233-234.] David Glantz, author of the popular work Soviet Military Operational Art: In Pursuit of Deep Battle, noted that between 1932 and 1936 the Red Armys theoretical and practical work on operational art created a model of offensive combat that has endured to the present.[footnoteRef:74] This thought was supplemented with a focus on maneuvering due to the mechanization and motorization of ground forces. Operational maneuver was noted to be the organized shifting of distinct groups of forces during an operation to achieve a more favorable position with regards to an enemy in order to strike a blow against him or repel an enemy attack.[footnoteRef:75] Glantz went on to describe how the Soviet Union then incorporated the development of nuclear weapons into the maneuver concept. He quotes Colonel F. D. Sverdlov, a leading maneuver specialist in Russia, as the author behind the defining of the concept known as antinuclear maneuver, which is the withdrawing of subunits from under the possible blows of an enemy nuclear strike.[footnoteRef:76] [74: David M. Glantz, Soviet Operational Art since 1936: The Triumph of Maneuver War, in Historical Perspectives of the Operational Art, Michael D. Krause and R. Cody Phillips, General Editors, Center of Military History, Washington DC, 2005, p. 249. ] [75: Ibid., p. 269.] [76: Ibid., p. 271.] The Soviet Unions perilous political and economic situation in the early 1990s caused the military to switch to a concept dubbed defense sufficiency. This was a military strategy based on premeditated defense. But as the nation gradually improved and moved into the 21st century, the military began to discuss vertical maneuver and envelopment by air assault and the conduct of operational and tactical maneuver again.[footnoteRef:77] This has apparently led to the works in Military Thought discussed above in relation to operational art. [77: Ibid., p. 278.] Russian Use of Operational Art and Maneuver in Space\nBased on the discussion above of operational art, several points stand out. Operational art is defined as the preparation and conduct of combined-arms, joint, and independent operations for large-strategic formations. The discussion indicated in several places that a principal element of the concept was the preparation of such operations in peacetime in order to be prepared for the initial period of war, a period now marked by increased speed due to the impact of advanced technology in the information age and its impact on the development of weaponry, reconnaissance assets, and frequency interference capabilities. Being in a superior position during the initial period of war clears the way for the use of operational art in space and helps ensure success.\nOther important points are listed below. The initial sentence in each bullet is from the discussion above. It is followed by another sentence (from this author, in brackets) which is a conceptualization indicating how satellites and space would fit each concept:\nManeuver, deep operations, breakthroughs, and integrated operations were listed several times each. [Deep operations could involve Russian strikes against satellites in space or against underwater cables or the use of SODCIT criteria. Satellites perform maneuver operations often to inspect other satellites or to perform other missions.]\nIt was noted that the less developed a theater of war, the greater were the opportunities of employing maneuver forms of combat. [Space is underdeveloped at the moment, which indicates it could remain for some time as a place for maneuver.]\nIt was argued that an effective command and control system was needed for operational art. [Russia has established such a system with its National Defense Management Center in Moscow.] \nDavid Glantz wrote that operational maneuver was the organized shifting of distinct groups of forces during an operation to achieve a more favorable position with regards to an enemy in order to strike a blow against him or repel an enemy attack.[footnoteRef:78] [Moving satellites against other satellites to either strike a blow against them or to simply achieve a strategic position in a specific orbit, such as to conduct inspections of other satellites, relate to Glantzs thought.] [78: Glantz, p. 269.] The operational art department is concentrating its efforts on developing new, unconventional forms and methods of employing large strategic formations and groupings of forces in both large-scale and local wars, as well as in armed
conflicts.[footnoteRef:79] [The use of satellites as an operational maneuver group would be an unconventional form of using such assets.] [79: Stolyarov.] The basis of both operational and tactical maneuver, according to Frunze, was attacks against the weakest points (the enemy flanks and rear) and the envelopment and outflanking of enemy groupings combined with attacks from the front.[footnoteRef:80] [Russian leaders state that they consider the weakest links in Western systems to be their links to space systems, which can be considered a flank.] [80: M. V. Frunze, p. 204.] Ground maneuvers proposed an aggressive advancement in the direction of the flanks as well as into the depths of the opposing force.[footnoteRef:81] [Space may now be considered a flank for planetary operations.] [81: The Living Embodiment] Operational maneuver groups will obviously be used in some form or another in the future.[footnoteRef:82] [Space assets that maneuver in the form of groups can involve the movement of space assets to assist in enveloping an opponent.] [82: The Living Embodiment] The majority of these operations are present in the planning of aerospace operations today. It was noted earlier that two important military leaders (Gareyev in 2011 and Shoygu in 2015) have stated that aerospace is the new center of gravity. A short summary of how Russias military is discussing concepts related to operational art in space, from a few sources, is summarized below.\nIn 2009 a report noted that in the future a space strike echelon will accomplish combat missions and carry out combat support of land-based operations. The information-strike operation and a space operation are the result of the change in the nature of armed combat. They will precede air, naval, and land offensive operations. The information-strike operation was defined as \nan automated weapons system, which is designed for the highly effective destruction of one, several, or many facilities (targets) using precision-guided strike weapons at great distances in accordance with the operations (combat operations, battle, strike, or engagement) plan or its concept of operations.[footnoteRef:83] [83: Igor Vitalyevich Morozov, Sergey Valentinovich Baushev, and Oleg Eduardovich Kaminskiy, Space and the Nature of Contemporary Operations: Gaining and Maintaining Supremacy in the Information and Space Sphere Has a Decisive Impact on the Course and Outcome of a Contemporary High-Tech Armed Confrontation, Vozdushino-Kosmicheskaya Oborona (Air-Space Defense), 14 July 2009, pages unknown.] Targets of an information-strike operation include the command and control posts and communication centers of combined formations and formations, aircraft, the missile troops and artillery, reconnaissance-strike (weapon) complexes, reconnaissance, air defense and electronic warfare.[footnoteRef:84] The reconnaissance-strike complex was defined as an automated weapon complex designed for the destruction of ground-based facilities using missiles, aircraft, and other forces immediately upon detection.[footnoteRef:85] [84: Ibid.] [85: Ibid.] In 2011, Gareyev, writing in the Journal of the Academy of Military Science, noted that the center of gravity of armed struggle is shifting to the aerospace domain, elements of which are increasingly more interconnected. An aerospace defense (VKO) campaign, Gareyev writes, would consist of a series of air operations. They would include bomb, rocket, radio-electronic and other strikes against an adversarys aviation, rocket and naval forces, air defense systems, command posts, industrial, energy, and other important infrastructure objectives and, finally, against the main ground force groupings. This is planned at the very beginning of a war.[footnoteRef:86] [86: M. A. Gareyev, On the Organization of the Russian Federations Aerospace Defense, Journal of the Academy of Military Science, No. 2 2011, p. 40.] Thwarting an opponents aerospace attack is of primary significance, since the course and outcome of a war depend on this. Such defensive conditions extend into the space domain. VKO missions include reconnaissance of the aerospace domain (an aerospace theater of military operations can be under consideration) to identify enemy attacks; the implementation of an antisatellite struggle; control over the space domain; and defense against strikes from space as well as an anti-rocket and air defense plan that confronts both strategic and nonstrategic attacks. These are dynamic operations that are acquiring greater importance.[footnoteRef:87] [87: Ibid.] Gareyev noted that a probable adversarys command and control system, to include aerospace attack means, is usually located in space. It thus becomes a primary target, where it is necessary\nTo direct the main scientific and technological efforts towards seeking out the resources and methods aimed at bringing down the entire space communications and command and control system. This will not only create favorable conditions to successfully resolve VKO tasks, but also violate the principal base on which the opposing side structures its entire network-centric system of command and control.[footnoteRef:88] [88: Ibid., p. 42.] Such a system requires the creation of an operational group of specialists from the Main Air Force Staff, the Space Force Command, and other command and control organs in the General Staff Military Academy for the assessment of the actual conditions of forces and means.[footnoteRef:89] [89: Ibid.] In October 2013 Russia published its latest, at the time of this writing, military doctrine. It was noted that two principal tasks of the Armed Forces were to provide air and space defense of important structure of the Russian Federation while being ready to repel strikes from aerospace attacks; and to deploy and maintain in the strategic space zone orbital spacecraft groupings that support Armed Forces activities.[footnoteRef:90] Whether these groupings were OMGs is not known, but again the possibility remains. [90: B. D. Kazakhov and G. K. Isaev, Recommendations to Clarify the Conceptual Apparatus Used to Describe the Subject Area Tactics as a Component of Military Science, Vestnik Akademii Voenykh nauk (Journal of the Academy of Military Science), No. 3 2018, pp. 30-35] In November 2017 Russia announced it was developing two advanced anti-satellite weapons: Rudolf, a mobile anti-satellite strike system and the Tirada-2S, a mobile anti-communication satellite electronic warfare system.[footnoteRef:91] The Tirada-2S conducts the radio-electronic suppression of satellite communications, even from Earth.[footnoteRef:92] [91: No author or title provided, Interfax, 30 November 2017.] [92: No author or title provided, Interfax (in English), 9 January 2019.] In 2017, journalists reported on the use of Russias Space troops to test a maneuvering military inspection satellite. The satellite undocked from a Kosmos-2519 space platform and it began an autonomous flight. It first changed its orbit, then returned to the Kosmos platform and inspected it. Such a capability can allow for determining the functional purpose of a foreign satellite and, when required, turn into a space interceptor than can deploy missiles. Independent military expert Valeriy Mukhin stated that such a system can become a deterrence factor for potential enemies, as it can check whether a satellites stated function corresponds to reality.[footnoteRef:93] [93: S. Valchenko, N. Surov, and A. Ramm, Russia Sends Inspector into Orbit: Military Test Operations of Maneuvering Identification and Intercept Satellite, Izvestiya Online, 26 October 2017.] In 2018 a Wired magazine article discussed the threat of a war high above the earth among satellites. The article stated that in 2014 the US military noted that a piece of Russian space junk, Object 2014-28E, began to act strangely. It performed complicated maneuvers and came alive. It sided up to American commercial communication satellites. The Object has been joined in years since by similar space objects of Russian provenance.[footnoteRef:94] The same year a MiG-31 appeared on the Internet with a mockup of a new type (not identified further) of an anti-satellite missile under the fuselage. It would be guided to its target by the Krona space object recognition station at Kazakhstans Saryshagan range.[footnoteRef:95] Further, the Peresvet combat laser system was advertised as capable of fighting satellites in orbit according to the Russian Defense Ministry, and it has been supplied to the Space Forces.[footnoteRef:96] [94: Garrett M. Graff, The Outer Limits of War, Wired Magazine, July 2018, pp. 48-49.] [95: Anton Valagin, Photos: MiG-31 Tests Satellite Killer, Rossiyskaya Gazeta Online, 30 September 2018.] [96: No author or title provided, Interfax (in English), 5 December 2018.] Another 2018 report noted that a Soyuz-2 launch vehicle fitted with a Fregat upper stage can put into orbit up to 15 inspector satellites. Foreign media, it noted, had dubbed these inspector satellites to be killer satellites. Russian media reported that a Kosmos-2521 inspector satellite had shifted position after some months in orbit to draw close to and photograph various foreign satellites, American ones included. The article then noted that preparations to repulse a possible attack utilizing the capabilities of an orbital satellite grouping are under way in all the worlds leading states both in space and on Earth.[footnoteRef:97] These vehicles can spend years in space and, on command, instantly mount an attack due to an adversarys aggression. On Earth, techniques are under investigation to suppress satellite signals and create interference.[footnoteRef:98] [97: Irina Dronina, The Militarization of Space Threatens Undesirable Consequences for Everyone. A Single Medium-Class Launch Vehicle Can Put 15 Special-Purpose Satellites into Space, Nezavisimaya Gazeta Online, 19 June 2018.] [98: Ibid.] A final 2018 report listed the essence and content of the employment of tactical formations that are organizationally part of the space forces. The authors note that space force formations in peacetime are designed to carry
out the following missions: implementing continuous control of axes in the space domain that are in danger of operations of ground radar stations of the missile -attack warning system; conducting continuous reconnaissance of regions for the launch of ballistic missiles; detecting space objects and cataloging them; controlling space ships in orbital flight and safeguarding the deployment of orbital space ship groupings while maintaining them in a combat-ready condition; and other tasks. Scientific studies should be aimed at the following: taking into account the opposing sides being equipped with new means of armed struggle and the influence of other operational (tactical) factors; and developing operational-tactical requirements for new and modernized complexes and systems.[footnoteRef:99] Thus operational issues are under continuous reevaluation. [99: Kasakhov and Isaev, pp. 30-35.] In 2019, Russian analysts offered a brief description of the Nudol missile defense system. It is designed to repulse a nuclear strike at distant approaches to Russia, and it is being deployed on the ground and in space. There it can strike at satellites and missiles.[footnoteRef:100] Nudol is said to be a two-stage missile, with solid-fuel engines for both stages and a warhead equipped with maneuver engines. Equipped with both a conventional and nuclear warhead, the missile can strike targets at a distance of up to 1500 kilometers and with a speed of intercept of Mach 10. By operating against both missiles and satellites, Nudol can eliminate both reconnaissance and target designation satellites of an opponent, which eliminates them from seeing anything. Moscows layered ballistic missile defense system would thus include satellite groupings, a network of ground-based, long-range radar detections stations, and Nudol, thus becoming an aerospace defense system covering air and space.[footnoteRef:101] [100: Viktor Sokirko, Intelligence Late to Report: US Pinpoints Killer of its Satellites Three Years after the Event. Bad News for the Pentagon: Russia Successfully Testing Nudol System, Svobodnaya Pressa, 20 January 2019.] [101: Dmitriy Popov, The Killer Satellite with a Nice Name: The United States Has Nothing to Counter the Latest Nudol System, Armeyskiy Standart, 25 January 2019.] Finally, also in 2019, President Putin stated that nearly 80 percent of Russias military and dual-use satellites had been replaced.[footnoteRef:102] Defense Minister Shoygu stated that the throughput of communication channels for Russias military satellite grouping will increase 2.5 times by 2025 and will raise their jamming resistance.[footnoteRef:103] Thus, the improvement in space systems is a clear indication of its growing importance. [102: No author or title provided, Interfax, 16 May 2019.] [103: No author or title provided, Interfax (in English), 3 June 2019.] With these concepts as background, a truncated potential lineup of equipment that Russian theorists might consider as components of a space OMG that can maneuver and conduct deep/planetary operations in near or deep space include the following, based on the articles used above:\nInspector satellites, such as the Kosmos 2521\nKiller satellites\nTirada-2s, to thwart communications\nRudolf, anti-satellite strike system\nNudol, anti-satellite and missile system\nPeresvet combat laser\nGround stations that can jam objects in space\nMiG-31armed with anti-satellite missiles\nSpace junk that comes alive\nReconnaissance-strike complexes and information-strike system\nGround based hackers who attempt to take control of satellites, such as theoretically occurred in 1998[footnoteRef:104] [104: No author provided, Using the Force, The Economist, 20 July 2019, p. 19.] Conclusions\nWestern analysts should consider whether the deep operations of operational art normally associated with ground forces are now finding new life in a deep space dimension of Russian planning; and whether the theory is further buttressed by Russias SODCIT (special operations for the destruction of critical infrastructure targets) concept that aims to take out another nations economic base or links to space operations in the initial period of war (IPW). Perhaps Russia has even developed a space OMG, the potential components of which were listed for consideration. What is apparent from just these three points (SODCIT, IPW, OMG) is that Russias military has different focal points of thought than does the West, and they must be considered when developing Western responses to Russian threat indicators in space.\nRecent Russian military literature has focused primarily on weapons based on new physical principals (NPP), electronic warfare, artificial intelligence, and other weapon-related interests. Yet ever since the 1920s, Soviet and now Russian military theorists have adjusted operational art to new discoveries in weaponry. Operational arts past characteristics of maneuver, breakthroughs, and deep operations are all applicable to space. These developments are taking place at a time and place (space) that has an unfolding environmental context. There are no rules of space warfare that would be equivalent to the rules of land warfare (although many believe space in the interim should abide by land warfare rules until space rules are developed). To date there is only the Outer Space Treaty of 1967 and not a rule of law. The treaty appears to leave much room for interpretation and was, naturally, unable to envision two things: the current space environment that includes commercial and private spacecraft in addition to government developed ones; and its high-technology equipment (lasers, antisatellite missiles, etc.) that is able to do things (inspect other equipment in space, for example) never before considered. \nThe four officers who wrote longer articles on operational art made references to both operational art and its characteristics, and also discussed the aerospace domain. Korotchenko stated that the growing potentials of air and space warfare are increasingly influencing the theory and practice of operational art.[footnoteRef:105] The prevention of an enemys domination in space is now important and commanders must employ the potentials of our space-based systems to the utmost when preparing operations and waging hostilities[footnoteRef:106] since the course and outcome of operations are dominated by space and missile forces. Maneuver, he noted, is a typical trend of operational art and has a more important role to play under the current advanced technological situation.[footnoteRef:107] Zherebtsov stated that there will be a new perception of operational arts content, to include its principles, forms, and methods of conducting operations under conditions of an information-focused confrontation and the massive use of precision weapons; and that new ways and means of resolving tasks will be unveiled to confront modern interstate and intrastate opposition.[footnoteRef:108] Stolyarov noted that the operational art department is concentrating its efforts on developing new, unconventional forms and methods of employing large strategic formations and groupings of forces in both large-scale and local wars, as well as in armed conflicts.[footnoteRef:109] He noted that in the very near future, substantial changes will occur in the theory and practice of operational art.[footnoteRef:110] Kopytko stated that operational art includes combined arms operational art (combined arms of large strategic formations); operational art of the services and the centrally controlled arms (Strategic Missile Troops, Airborne Troops, and Space Troops); and operational art of the operational rear services. The structure is not constant but develops in line with the evolution of both weaponry and new combat arms and forces.[footnoteRef:111] [105: Korotchenko, p. 15.] [106: Ibid.] [107: Ibid.] [108: Zherebtsov.] [109: Stolyarov.] [110: Ibid.] [111: Kopytko.] The last section of the article, on the use of operational art in space, noted that being in a superior position during the initial period of war is the primary element that clears the way for the use of operational art in space and helps ensure success. Putting the proper equipment in space during peacetime prepares Russias military for the initial period of war. Large-strategic formations would be composed of equipment that includes lasers, satellites, anti-satellite missiles, counter communication, and other pieces of equipment instead of tanks, artillery, and aviation units. Numerous similarities in the characteristics surrounding the use of operational art in ground operations (weaknesses on flanks, etc.) are present in space, which provide further rational for Russia conceptualizing the use of operational art or even perhaps OMGs in that domain. \nToday, equipment orbits above us and cables wrap the globe together under the seas. Space objects, suspended in orbit, are equipped with capabilities that offer the opportunity to form OMGs in space in a suspended status, awaiting further orders for their activation or integration much like a computer virus. As was noted above by one Russian author, modern methods of aerospace and air defense practices contain forces that must (not maybe, but must) use the theory and practice of operational art and its methods and techniques.[footnoteRef:112] [112: A. P. Korabelnikov, Modern Methods of Aerospace and Air Defense of Facilities and Prospective Development Trends, Military Thought (in English), Volume 1 2019.] A recent US report suggested how the nation might incentivize Russia to fall in line with an international space traffic management (STM) scheme. These recommendations were:\nEstablish red lines in space surrounding critical satellites to quickly and clearly assign liability, when an undesirable space conjunction occurs. \nWith the best data and skills, DoD should take the initiative to develop specific space traffic standards and best practices pertaining to military security in STM. Otherwise, economic agencies and commercial operators could favor economic prosperity over military security. \nThe United States should submit an amendment to the Liability Convention to change the current fault-based liability for damage in space by a space object to absolute liability,
just the same as liability for damage on Earth by a space object. The change would also facilitate the rules pertaining to the red lines in 1. to become customary international laws, regulations, and enforcement in STM. \nThe United States should deploy bodyguard spacecraft to get ready in time to protect satellites against the rapidly emerging and growing robotic ASATs. \nFor fairness, the United States should take the lead to make all spacefaring nations have the same indemnification and other provisions in their third-party liability insurance.[footnoteRef:113] [113: Brian G. Chow, Commercial Space: Space Controls and the Invisible Hand, provided by Henry Sokolski, e-mail on 5 August 2019.\n] These are all solid recommendations. \nBefore incentivizing Russia, however, it is mandatory to understand how their space theory differs from ours. That is required for without it, how do we know just what it is the West is trying to incentivize? Another set of recommendations is thus required based on the analysis above. First, the implications of Russias understanding of emerging space trends and the follow-on forecasting of how to use maneuvering satellites and a SODCIT or space OMG should be studied. Russian leaders state that they consider the weakest links in Western systems to be the ones to space systems. How do you incentivize an opponent who believes they have found your weakest link? Further, an understanding of how Russia is developing the proper correlation of forces in space should be developed. If Russia considers space a flank to its more traditional terrestrial focus, then it would also be a place for operational art to unfold and influence events. All of these issues indicate how Russia is preparing to establish superiority in space with equipment to win the IPW and how it is developing its version of the rules of space conflict. Russia will demand equal security in space as they do on the ground. \nSecond, Western Red Team scenarios depicting Russias space contingent must take these points into consideration. Western discussions should focus on Russias negotiation techniques about space deployments, on the structure they envision to put in place, and on the operational art it plans to implement along with how Russia considers the impact of new trends leading to space conflicts. \nThird, analysts have to stop shortchanging themselves with mirror-imaging their space priorities with those of Russia. Too few Western analysts apply Russian thought to space, instead relying on their own understanding and noting only that Russia is conducting hybrid warfare against them. While it appears that Russia is seriously considering the use of operational art in space, have Western analysts considered such use? In the exercises available to date in unclassified form, that does not seem to be the case. The West would be wise to deeply consider how Russias military thinks and applies its traditional concepts to the new era, especially how new aspects of military art might be applied in space. ",
    "text": " Technical Document Template for Deliverables Design for a Low-Cost K-Band \nCommunication Satellite \nConstellation Author: Peyton D. Strickland \nSeptember 2019 MIT R E T E C H N IC A L R E P OR T Sponsor: Missile Defense Agency Dept. No.: P652 Contract No.: W56KGU-18-D-0004 Project No.: 0719B1TD-TD The views, opinions and/or findings contained in this report are those of The MITRE Corporation and should not be construed as an official government position, policy, or decision, unless designated by other documentation. Approved for Public Release; Distribution Unlimited. Public Release Case Number 19-3626 DISTRIBUTION STATEMENT A Approved for Public Release; Distribution is Unlimited. Approved for Public Release 19-MDA-10267 (14 Nov 19) All rights reserved. Huntsville, AL Approved By signed 14 Nov 19 Mike Russell, T843 Date Group Lead, Model-Based Architecture & Eng. iii Abstract MITRE funded analysis was conducted on the feasibility of using a 72-satellite constellation at an altitude of 1000 km to communicate with both low flying objects and low Earth orbiting (LEO) satellites. In addition, the satellites would be designed to communicate with ground terminal locations using radio frequency (RF) transmitters. The proposed satellite constellation would provide comprehensive communications coverage across the continental United States. The results of this analysis have shown the impracticability of such a solution at this time due to the satellites power budget. For this design, the satellite is required to use a heritage radio frequency data transmitter to communicate resulting in a cost of almost $5 billion for the satellite constellation with a design life of 13 years. Comparison to the historical example of the FireSat II satellite provided the validation for the sizing and design of the proposed satellite. The satellite sizing models used equations found in Space Mission Engineering: The New SMAD [1]. Lastly, the cost estimate was provided by the 2010 version of the Small Satellite Cost Model developed by The Aerospace Corporation. iv v Table of Contents Introduction \n2.1 Introduction \n2.2 Constellation Parameters \n2.3 Coverage Model \n2.3.2 Methodology \n2.3.3 Coverage Model Output \n2.5 Power System Model \n2.5.2 Power System GUI Design \n2.5.3 Solar Panel Sizing \n2.5.4 Battery Sizing \n2.5.5 Power System Model Outputs \n2.7 Spacecraft Bus Dry Mass Estimate \n2.8 Propulsion System Mass Model \n2.9 First Order Estimate of Satellite Dimensions \n2.10 ADCS Model \n2.10.2 Determination Transmitters \n2.10.3 Attitude and Control System (ACS) Initiation File \n2.10.4 ACS Sizing Function \n2.10.4.2 Solar Radiation Pressure (SRP) Torque Calculation \n2.10.4.3 Atmospheric Drag Torque Calculation \n2.10.4.4 Magnetic Torque Calculation \n2.10.4.5 Gravity-Gradient Torque Calculation \n2.10.4.6 Reaction Wheel Sizing \n2.10.4.7 ACS Propulsion Sizing \n2.10.4.8 ACS Model Outputs \n3.1 Introduction \n3.2 Satellite Power System Model \n3.3 Propulsion System Mass Model \n3.4 ADCS Model \n4.1 Coverage Model \n4.2 Satellite Power Budget \n4.3 Satellite Power System Results \n4.4 Satellite Mass Results \n4.5 Satellite Dimensions \n4.6 Satellite Cost Model \n6.1 Laser Communication \n6.2 SolidWorks Drawing \n6.3 SSCM \nFigure 2-1. Coverage Model Output. \nFigure 2-2. Satellite Power System GUI \nFigure 2-4. Beginning-of-Life Power Equation. \nFigure 2-5. End-of-Life Power & Solar Array Area Equations. \nFigure 2-7. Satellite Power System Model Output. \nFigure 2-8. Propellant Mass Equation. \nFigure 2-10. Propellant Tank & Feed System Sizing Equations. \nFigure 2-11. SRP Torque Equation. \nFigure 2-14. Magnetic Torque Equation. \nFigure 2-16. Thrust Per Momentum Dump Equation. \nFigure 2-17. ACS Fuel Required Equation. \nFigure 2-19. FireSat II SSCM Excel File \nFigure 2-20. Total Lot Cost Equation. \nFigure 4-2. Satellite SolidWorks Assembly \nFigure 4-3. Satellite Cost Results. \nTable 2-1. Average Power by Subsystem for 4 Types of Spacecraft. \nTable 2-5. SSCM Earth Orbiting Total Non-reccuring Cost Equations. \nTable 3-2. FireSat II Example Vs Propulsion System Mass Model. \nTable 4-1. Average % Coverage Over CONUS Per Number of Transmitters on Each Satellite. 4-1 \nTable 4-2. Final Power Budget. \nTable 4-3. Spacecraft Bus Dry Mass Estiamte Using SME: The New SMAD Eqns.. \nTable 4-5. Satellite Dimensions. \nFigure 2-1 Coverage Model Output 2.4 First-Order Satellite Power Estimate Once the coverage model was completed and the optimal number of transmitters per satellite was selected, a first-order power estimate was generated. There are two approaches for determining a spacecrafts mass and power covered in SME: The New SMAD. For the first approach, as described in section 14.7.1 SCS Example on page 432, one can begin with a target mass for the entire system and then determine the mass and power available for the spacecraft. Conversely, as described in section 14.7.2 FireSat II Example on page 435, one can start with the payload and then determine the mass and power for the spacecraft. While the first method is great for flexible mission objectives, the FireSat II example is used in this analysis 2-6 since the payloads of RF transmitters and laser communication units have already been defined by MITRE and the results of the coverage model. Using Table 2-1, the Low-Earth-Orbit with propulsion spacecraft section is used to generate a total power estimate (page 424 of SME: The New SMAD [1]). Subsystem (% of Total Power) No Prop LEO Prop High Earth Planetary Payload 43% 46% 35% 22% Structure and Mechanisms 0% 1% 0% 1% Thermal Control 5% 10% 14% 15% Power (Incl. harness) 10% 9% 7% 10% Telemetry, Tracking, & Command (TT&C) 11% 12% 16% 18% On-board Processing 13% 12% 10% 11% Attitude Determination and Control 18% 10% 16% 12% Propulsion 0% 0% 2% 11% Average Power (W) 299 794 691 749 According to the chart, 46% of the total power is used by the payload. With a total payload power consumption already known, the total power for the spacecraft is estimated by dividing the payload power by 0.46. This first-order estimate proves to be highly effective in that the final estimate for the power consumption of the satellite is significantly close to the final estimate that will be derived in the results section. Lastly, in order to accurately model the situation that the satellite will not always be operating at full power, it is assumed that the satellite operates a third of the day at full-power, a third of the day at half-power, and a third of the day at no-power. Table 2-1 Average Power by Subsystem for 4 Types of Spacecraft 2-7 Furthermore, it is assumed that you can only communicate at full-power during sunlight periods where the satellite is able to use power from both batteries and the solar panels. 2.5 Power System Model 2.5.1 Purpose With a power requirement computed, a system to meet the power demand can be developed. The power system is comprised of two components: solar cells and batteries. There is a plethora of factors that influence the size and type of solar panels to be used. The first factor that affects the size needed is that the surface of the solar array may be eclipsed for extended durations of time depending on the satellites altitude and inclination. Subsequently, a MATLAB program developed by the author was used to calculate the sunlight and eclipse periods for the satellites defined orbit to determine how much time the satellites solar panels will have to collect sunlight. Furthermore, there are three types of solar cells that are generally used for satellite applications (Gallium Arsenide, Multijunction, and Silicon). These three types of solar cells provide varying efficiency levels (higher efficiency, less area) and cost. As a result, the surface area of a solar panel needed to produce enough power to fulfill the satellites power requirements require calculation for all three types to compare the surface area needed and the cost for each case to ensure that the optimal solution is being selected. Lastly, the batteries must be designed to store the energy derived from the solar panels. To accomplish this task, a MATLAB graphical user interface (GUI) linked to STK was created. The following design method was derived from Section 21.2 Power on page 641 of SME: The New SMAD [1]. 2-8 2.5.2 Power System GUI Design The first step in creating this model was to design a GUI that is easy to use. Designing the GUI first also defines the outputs for the program in an orderly manner which streamlines the coding process. Keeping in mind that conducting trade-studies is a key goal for this model, the GUI allows any user to quickly view results for various power budgets, orbits, design life, and battery quantities. The GUI developed for this analysis is shown below. 2.5.3 Solar Panel Sizing For the program to calculate the solar panel area needed, the user first must input the following information: power needed during eclipse, power needed during daylight, orbit altitude, orbit inclination, and mission duration. Mission duration and the average power requirements are the two key design considerations in sizing the solar array because photovoltaic Figure 2-2 Satellite Power System GUI 2-9 systems are sized at end-of-life (EOL) to ensure that adequate power can be supplied for the entire duration of the mission. Once the following design parameters have been input, the power the solar array must provide during daylight to power the spacecraft along with recharging the batteries must be calculated. = + \n\n\n For
direct energy transfer, the eclipse path efficiency and daylight path efficiency were approximated as 0.65 and 0.85, respectively; for peak-power tracking, eclipse path efficiency is estimated at 0.60 while daylight path efficiency is estimated at 0.80 (page 643 of SME: The New SMAD [1]). STK was used to calculate the length of the eclipse and daylight periods per orbit, and the required power production from the solar array was calculated. Generally, the third step in the solar array design process is the selection of the type of solar cell; however, since the model for this analysis is conducting a trade-study to determine the best solar cell balancing area and cost, all three solar cells were included. Table 2-2 details solar cell efficiencies for each type (page 645 of SME: The New SMAD [1]). Cell Type Silicon Gallium Arsenide Multijunction Theoretical Efficiency 29% 23.5% 40+% Achieved Efficiency: Production Efficiency Best Laboratory 22% 24.7% 18.5% 21.8% 30.0% 33.8% = \n = ! = \"# $ \n %& ! = \"# $ %& \n ' = \n \n$$# \n ' = \n$$# Table 2-2 Performance Comparison for Photovoltaic Solar Cells Figure 2-3 Solar Array Power Equation 2-10 While silicon cells are mature in their development and can have lower cost in environments where radiation is not a concern, multijunction cells have become the standard for space applications despite their high cost. What makes them the #1 choice is their high efficiency resulting in less area required to produce the same amount of power comparative to silicon cells. Using the best laboratory efficiencies provided above, the power output for each solar cell is calculated by multiplying the efficiency by the solar constant 1,368 W/(). \n Next, the beginning-of-life (BOL) power per unit area is determined using the following equation: *+, = -.\n cos 2 The solar cell power output calculation is provided in the previous step when the solar cell type is selected. Inherent degradation quantifies the loss in performance and is assumed to be 0.77 (page 644 of SME: The New SMAD [1]). Lastly, the sun incidence angle is the angle between the vector normal to the surface of the array and the Sun line. Although, the solar panel is configured to minimize this cosine loss, it is assumed that theta is equal to 23.5 degrees in order to model an industry standard worst-case Sun angle assumption to ensure power production requirements are always met (page 647 of SME: The New SMAD [1]). The last step is the calculation of the EOL power per unit area which can then be used in conjunction with the solar array power calculated in the first step to calculate the area required. = 3 4 %5 5 6 78 : ; = ;## # < = 35# ;## =# Figure 2-4 Beginning-of-Life Power Equation 2-11 >\n = 1 A, \n B+, = *+,>\n C = B+, Several factors degrade a solar panels performance. Lifetime degradation of the solar panel occurs due to thermal cycling, material degradation, and space debris impact among others. First, the lifetime degradation can be calculated by the first equation in Figure 2-5 for which the degradation per year for silicon, gallium arsenide, and multijunction are 3.75%, 2.75%, and 0.5%, respectively (page 647 of SME: The New SMAD [1]). Next, the end-of-life power was calculated using the beginning-of-life power and lifetime degradation (2nd equation in Figure 2- 5). Finally, the solar array area can be calculated by dividing the solar array power by the end- of-life power, and the mass of the solar array is estimated by multiplying the solar array power by .04. 2.5.4 Battery Sizing Energy storage plays a vital role in the electrical-power subsystem allowing the spacecraft to continue operating in eclipse periods and peak-power demands. For the satellite under consideration with a thirteen-year design life, secondary (rechargeable) batteries were selected. Although Nickel-Cadmium and Nickel-Hydrogen are commonly used secondary batteries, Lithium-Ion was selected based on its significant volumetric and energy density advantages. \" = \"$ 7 # = # D E = 3 \"$ 7 D \n%\" = \n# $ \"$ 6 78 : F%\" = F### $ \"$ 6 78 : = = 3 = = 78 = 3 = \nFigure 2-5 End-of-Life Power and Solar Array Area Equation 2-12 The spacecrafts orbital parameters, especially altitude, determine the number of charge/discharge cycles the battery must support. According to page 650 of SME: The New SMAD [1], the depth-of-discharge (DOD) is limited to 30% for LEO spacecraft. As a result, the cycle life is increased but the amount of energy available from the batteries during each cycle is decreased. To determine the size of the batteries (battery capacity), only one equation is required. G = AHAIJ The eclipse power and length of eclipse per orbit are defined in the solar panel sizing portion of the code. Next, the DOD is estimated at 0.30 based on the LEO orbit. Lastly, the number of batteries is generally set at two or more for redundancy, and the transmission efficiency is estimated at 90% (page 653 of SME: The New SMAD [1]). 2.5.5 Power System Model Outputs With all equations and variables defined, the power system model is complete. The solar array and battery information was outputted in the GUI that accomplishes the trade-study task. Figure 2-7 shows an example output. 4 = F 4 (W-hr) = \n ! = \"# $ \n %& % = $ 6 78 : = 57& $ F # = !#7# \n$$# \nFigure 2-6 Battery Capacity Equation 2-13 2.6 Delta-V (V) Estimate Working with the rocket equation, the V budget was used to create a propellant budget and estimate the propellant mass required for the space mission. Higher orbits require more propellant for orbit acquisition and de-orbit but less propellant for on-orbit maintenance. With an altitude of 1000 km, an accurate estimation method is needed. On page 253 of SME: The New SMAD [1], Figure 10-16 provides V budget as a function of altitude for LEO. Using this figure, at an orbit of 1000 km, the V budget is estimated at 691.22 m/s for a design life of thirteen years. Figure 2-7 Satellite Power System Model Output 2-14 2.7 Spacecraft Bus Dry Mass Estimate With first order estimates of the payload mass, power system mass, and the V budget, a first order dry mass estimate was derived so that an ADCS could be designed. First, the payload total mass was calculated by adding the weight of the RF transmitters and the laser communication units. Once the payload mass was calculated, all other first order mass estimates, excluding the power mass estimate (which has already been calculated) were derived from the usage of Table 2-3 (page 422 of SME: The New SMAD [1]). Subsystem (% of Dry Mass) No Prop LEO Prop High Earth Planetary Payload 41% 31% 32% 15% Structure and Mechanisms 20% 27% 24% 25% Thermal Control 2% 2% 4% 6% Power (Incl. harness) 19% 21% 17% 21% TT&C 2% 2% 4% 7% On-board Processing 5% 5% 3% 4% Attitude Determination and Control 8% 6% 6% 6% Propulsion 0% 3% 7% 13% Other (balance + launch) 3% 3% 3% 3% Total 100% 100% 100% 100% Propellant 0% 27% 72% 110% The total dry mass was estimated by dividing the payload weight by the percent of dry mass for the payload subsystem. For this specific scenario, 64.5 kg would be divided by 0.31 Table 2-3 Average Mass by Subsystem for 4 Types of Spacecraft 2-15 (average payload percentage of dry mass for LEO spacecraft with propulsion) to calculate a total dry mass. Once this total dry mass has been estimated, the percentage for each subsystem was multiplied by the total dry mass until all subsystems masses were calculated. The total dry estimate listed in the results is slightly greater than the estimate provided using this method due to the power mass estimate from the satellite power system model being used instead of the 21% listed in SME: The New SMAD [1]. 2.8 Propulsion System Mass Model The spacecraft dry mass and V budget estimates allow for the estimation of the propulsion systems mass. For preliminary design, the rocket equation was utilized to estimate the propellant mass. KL = KM[OQ RSTUVW 1] The V needed is within the range for monopropellant thrusters. Subsequently, hydrazine was selected as the fuel resulting in a modest .L estimate of 218 seconds. All remaining variables are \nknown from previous calculations, and the propellant mass was computed. Next, KL_Z[\\ was defined as the propellant mass plus the fuel needed for attitude \ncontrol. The fuel needed for attitude control is much smaller than the propellant mass needed to meet the V, so for a first order estimate, it was assumed to be 9% of the total propellant mass. Not all the propellant loaded into a tank is usable however. As a result, a 3% margin is applied to the usable propellant to account for propellant trapped in the tank, feed lines, or valves [3]. Furthermore, there
is a measurement uncertainty of about 0.5% on propellant loaded. Thus, the total propellant loaded is ] = # ] ^ ]$ = ] ^ _ = ` 7/ ; = 3$ ;75 b = cd 3 \"d 7/ \nFigure 2-8 Propellant Mass Equation 2-16 KLefghih = KLjSgkei1.0 + 0.03 + 0.005 With the true value of loaded propellant mass calculated, the propellant tank and feed system can be sized. pL_,-\n\n = KL_\\-\n\n qMZ\\W pL_Z[\\ = 0.97pL_\\-\n\n pL_Z\\\\U = pL_Z[\\ t 1u pv-v\\ = 1.2pL_\\-\n\n + pL_Z\\\\U Kvxy = 2.7086O|}pv-v\\~ 6.1703O|\u007fpv-v\\) + 6.629O|)pv-v\\ + 1.3192 KLZxv = 1.2pLjeegi .01qLZxv KM\n_ = 0.156KLefghih + KvZv + KLZxv: Kvxy \nFigure 2-10 Propellant Tank and Feed System Sizing Equations First, the volume of fuel was calculated by dividing the loaded amount of propellant by the density of the fuel. The density of the fuel (Hydrazine) is 1.01 kg/L at 293 K (Table 18-8 of SME: The New SMAD [1]). Naturally, not all the fuel will be consumed. It is estimated that 97% of the volume is usable [3]. Next, the ullage volume was calculated using the usable volume and the blow-down ratio. The blow-down ratio, defined as the final ullage volume over the initial ullage volume or the initial pressurant pressure over the final pressurant pressure, was assumed to be four, a typical value for modern blow-down propellant tanks. The final total volume was calculated adding the loaded volume and the ullage volume and adding a customary 20% margin. Finally, the tank mass is now sized using the final total volume using a curve fit of commercially available propellant management devices (PMD) propellant tanks. `_ = `57 $ 5 \" `_5& = & 5 `57 \" \n F = F # `_5 = `57 \" ` = ! !#^ `57 \" ] #^ = !#^ ] ^ ]5# = 5# ] ^ ]$_ = 3 7 ] ^ ] 5 = !5 ] ^ Figure 2-9 Loaded Propellant Mass Equation 2-17 After computing the mass of the tank and the propellants, the mass of the pressurant and feed system require calculation. Currently, the initial operating pressure for the tank is unknown; however, an estimation was made from the operating pressure ranges of two candidate thrusters: MRE-1.0 and Monarc 445. The operating range for the MRE-1.0 is 0.055 to 3.9 MPa while the operating range for the Monarc 445 is 0.5 to 3.1 MPa [4] [5]. A 20% margin over the 3.9 MPa was carried so the initial pressure was estimated at 4.7 MPa and the initial temperature at 323 K. The pressurant selected was Helium (He). According to the NIST Chemistry WebBook, the density for He under those conditions is assumed to be 6.87 kg/(~ [6]. The equations for the \nmass of the pressurant and the feed system can now be solved. To complete the propulsion system model, the mass of the thrusters needed was estimated. For this specific scenario, four thrusters for unloading momentum from the reaction wheels and one main thruster for primary propulsion were selected following the example of the FireSat II. For the attitude control maneuvers, the candidate thruster selected was the flight- proven MRE-1.0. The MRE-1.0 has a mass of 0.5 kg, average thrust of 3.4 N, and maximum thrust of 5.0 N. For the primary propulsion thruster, the potential candidate thruster is the Monarc-445 which has a mass of 1.6 kg and steady state thrust of 445 N. While these thrusters should meet thrust requirements, a final decision can be made after more information on thrust levels is gathered from the completion of the ADCS model. 2.9 First Order Estimate of Satellite Dimensions A first order estimate of the satellites dimensions and mass minus the attitude and control system are needed to size the ADCS. With the first order mass estimates finalized and the size of several subsystems known a priori, the satellites dimensions were calculated through a first order approximation process. Although, the ADCS cannot be sized prior to the calculation, it 2-18 constitutes a very small percentage of the overall size and mass of the satellite. As a result, the satellite was sized with a small portion of the volume reserved. To create an estimate of the satellites dimensions, the author utilized an Excel spreadsheet to document the dimensions of each of the parts needed. With an Excel spreadsheet listing the dimensions of each part, SolidWorks, a solid modeling computer-aided design and computer-aided engineering computer program, can be utilized to create a 3D model to estimate the overall dimensions of the satellite body needed to store all the parts. 2.10 ADCS Model 2.10.1 Introduction The final subsystem to be sized was the Attitude Determination and Control Subsystem (ADCS). First, the determination transmitters were selected based off the pointing requirements. Once the determination transmitters were selected, the MATLAB model was initialized. The MATLAB model required vehicle, orbital, and Earth properties as input to generate the cyclical and secular angular momentum per orbit, a single reaction wheel mass, the fuel required for momentum dumping over the satellite lifetime, and the thrust required for each momentum dumping event. 2.10.2 Determination Transmitters The driving force behind the selection of the determination transmitters was the pointing requirements of the payload. The RF transmitter described by MITRE has a 45-degree half-angle cone; however, the laser communication system does not have this ability afforded to it. Laser communication systems often require pointing accuracy to 1. As a result, a star tracker was 2-19 selected due to its ability to meet this accuracy requirement. Furthermore, a sun sensor was also selected in conjunction with the star tracker for redundancy of data and for its ability to help with determination during maneuvers such as detumbling. 2.10.3 Attitude and Control System (ACS) Initiation File The purpose of the initiation file was to establish satellite properties and to call the functions that will determine the torques on the satellite and subsequently size the reaction wheels and thrusters accordingly. The vehicle properties utilized by the program included physical dimensions, center of gravity, mass, surface material code, and the lifespan of the vehicle. Next, the orbital elements for the proposed satellite were input. The last information input was the properties of Earth. Finally, the ACS Sizing function was called by the MATLAB script, and the torques and the ACS size were estimated. 2.10.4 ACS Sizing Function 2.10.4.1 Introduction The ACS Sizing function requires inputs of the orbital elements, vehicle parameters, and planet parameters to compute the cyclical and secular angular momentum, the reaction wheel mass, the ACS fuel mass required, and the thrust required per momentum dump. Several steps are required to accomplish this task. First, the vehicles 2nd moment of inertia and the time for one orbit were calculated thereby enabling calculation and summation of the solar radiation, aerodynamic, magnetic, and gravity torques. This process was completed for the entire angular range of the orbit (0 to 360 degrees). Using the computed torques, the maximum torques around the orbit were integrated to find the total angular moment which was then used to find the cyclical and secular angular momentums. Lastly, the reaction wheel was sized using the cyclical angular momentum while the ACS propellant mass and thrust required for momentum dumping 2-20 were sized using the secular momentum dumping. The calculated torques were displayed on a polar graph for visualization purposes. 2.10.4.2 Solar Radiation Pressure (SRP) Torque Calculation Sunlight (i.e. photons) has momentum, and therefore exerts pressure when it strikes an object. The more absorptive the material, the more momentum absorbed resulting in a certain pressure force. If the sunlight is reflected, the pressure force felt is twice as much as the pressure force if all the sunlight is absorbed. While it is extremely difficult to estimate the true SRP because of the varying surfaces used on a satellite, a good first-order estimate can be made by assuming uniform reflectance. With uniform reflectance assumed, the following equation is appropriate: = C1 + ( cos 2 Figure 2-11 SRP Torque Equation The solar constant was assumed to be 1,366 W/(). The surface material number was one of the \ninputs gathered at the beginning of the ACS Model. Using an Excel spread sheet, the MATLAB function gathered the reflectance factor (q) corresponding to the surface material number input by the user. Lastly, the angle of incidence of the sun was assumed to be zero degrees (worst- case). Listed below are the reflectance factors for possible spacecraft surface materials. ! = 3 !5 7 = 3 4# # /78 \n c = Speed of Light m/s = = 35# 35$ = 7 = $ # = 4# $ 3 m 7 = 4# $ ] 7 < = 35# ;## =# 2-21 2.10.4.3 Atmospheric Drag Torque Calculation Just as photons have momentum and create pressure upon impacting a spacecraft, air particles also have momentum and create pressure when they impact a spacecraft. The density of air and pressure decrease exponentially with increasing altitude. As a result, only spacecraft in Name
Material Number Absorptance Reflectance Aluminized FEP 1 0.16 0.84 Aluminized Teflon 2 0.163 0.837 Aluminum Tape 3 0.21 0.79 Black Paint 4 0.95 0.05 Goldized Kapton 5 0.25 0.75 Optical Solar Reflector 6 0.07 0.93 Polished Beryllium 7 0.44 0.56 Quartz over Silver 8 0.077 0.923 Silver Coated FEP 9 0.08 0.92 Silver Paint 10 0.37 0.63 Silvered Teflon 11 0.08 0.92 Solar Cells, GaAs 12 0.88 0.12 Solar Cells, Silicon 13 0.75 0.25 Titanium (Polished) 14 0.6 0.4 White Paint (Silicate) 15 0.12 0.88 White Paint (Silicone) 16 0.26 0.74 Table 2-4 Reflectance Factors for Commonly Used Spacecraft Materials [7] 2-22 LEO encounter enough particles to justify an atmospheric drag torque calculation. The atmospheric drag was estimated by: = 12 qG\nCp) ( Figure 2-12 Atmospheric Drag Torque Equation Like SRP, when the center of atmospheric pressure, determined by the spacecraft area exposed to the atmosphere in the direction of the orbital velocity (i.e. ram direction), is not aligned with the center of mass, a torque occurs. The density of air is estimated using an upper atmospheric model derived by NASA: = 131.21 + .00299 = 2.488 + 273.1216.6 |.~}} q = .2869 + 273.1 Figure 2-13 Upper Atmospheric Air Model Equations [8] The drag coefficient was estimated at a constant 2.2 (as is common practice for a LEO flying satellite). The ram area was calculated for the worst-case scenario by determining the largest area of all the sides. Lastly, the maximum distance from the aerodynamic center of pressure to the center of mass was calculated. 2.10.4.4 Magnetic Torque Calculation The Earths liquid core is a dynamo that induces a magnetic field. This magnetic field is strong enough to generate effects on the space surrounding Earth, so strong in fact that it ! = = 7 !5 7 q = # $ = ^/7 \n 4 = 4$$# 7 = = 7 = 78 ` = ` 78 = =#7 5 4# 7 7 = 4# $ ] 7 ! = !7 5 ) = 5 ^ = # $ ^/7 2-23 interacts with the satellites weak magnetic residual moment. When the satellites residual moment is not aligned to the local magnetic field from Earth, the satellite experiences a magnetic torque that attempts to align the two. The magnitude of this magnetic torque can be calculated using the equation presented in Figure 2-14. = At = A K~ Figure 2-14 Magnetic Torque Equation This equation models the Earths magnetic field as a dipole. The spacecrafts dipole moment is assumed to be 1 for a small, uncompensated spacecraft. Earths magnetic constant is estimated at 7.18 10\u007f Tm~. Lastly, lambda is a unitless function of the magnetic latitude that ranges from 1 \nat the magnetic equator to 2 at the magnetic poles. 2.10.4.5 Gravity-Gradient Torque Calculation The final torque requiring computation was the gravity-gradient torque. Gravity-gradient torques arise when the spacecrafts center of gravity is not aligned with its center of mass with respect to the local vertical. The gravity-gradient torque increases as a function of the angle between the local vertical and the spacecrafts principal axes with the gravity-gradient torque always trying to align the minimum principal axis with the local vertical. Figure 2-15 provides a simplified equation for the gravity-gradient torque for a spacecraft with the minimum principal axis in its Z- direction is shown below. Earths gravitational constant of 3.986 10 \nequal to 45 degrees (i.e. worst-case scenario) are selected. ! = cd c# !5 7 = cd # 4# # 7/ \n = # \n 4# 7 \n ; = ]7# $ ;# &5 ^ 78 \n ; = ]7# $ ;# &5 ^ 78 \n < = =# & # ` # = 2-24 U = 32~ |. .| sin 22 Figure 2-15 Gravity-Gradient Torque Equation 2.10.4.6 Reaction Wheel Sizing The reaction wheels were sized for cyclical momentum storage. To determine the mass of a reaction wheel, data was collected on several commercially available reaction wheels. With the data gathered in MATLAB, a fourth-order polynomial curve was fit to the data to compare the momentum storage capabilities of the reaction wheels and their weight in kilograms. From the polynomial curve, an approximate mass was selected based off the momentum storage capabilities. 2.10.4.7 ACS Propulsion Sizing The ACS propulsion sizing requires five inputs: the mass of the spacecraft, the center of gravity, satellite lifetime, the saturation point of a reaction wheel (secular angular momentum), and the rate of saturation of a reaction wheel. These were used to compute the momentum dumping fuel mass required over the satellite lifetime and the thrust required for a single momentum dump. Although the proposed design includes four thrusters for momentum dumping and one main thruster, this code utilizes six thrusters (one on each side) and chooses the shortest moment arm which will require the largest thrust to design for the worst-case scenario. The author assumed that the thruster required for momentum dumping will fire for one second. With the worst-case moment arm calculated, the thrust required to dump the momentum is calculated (per pulse) using the following equation. = > Figure 2-16 Thrust Per Momentum Dump Equation ! = cd c# !5 7 = cd # 4# # 7/ \n = # \n 4# 7 \n ; = ]7# $ ;# &5 ^ 78 \n ; = ]7# $ ;# &5 ^ 78 \n < = =# & # ` # = ! = !5 = 3 ]7# 57 7/ \n \" = !5 ]7# =7 7 \n = F5# !7 2-25 The propellant mass required for ACS over the satellite lifetime is then calculated with these equations. Z\\ = 3 >Ov 365.25. O (MZ\\ = Z\\ .L Z\\ is the total number of thruster firings required throughout the lifetime of the spacecraft \nto ensure that the reaction wheels can control the attitude of the spacecraft. The numerator of the first equation in Figure 2-17 has a factor of 3 because three reaction wheels will need to be desaturated each time a momentum dump is required. Lastly, since hydrazine was selected as the fuel of choice, the .L is 218 seconds. \n2.10.4.8 ACS Model Outputs This completes the ACS model process. In the Command Window of MATLAB, the following items are printed: cyclical angular momentum per orbit, secular angular momentum per orbit, reaction wheel mass, the fuel required for momentum dumping, and the thrust required per momentum dump. In addition, a polar graph showing the individual and total torques over the entire orbit is displayed. An example output screen is shown in Figure 2-18. 5 = # $ !5 # \"$3 = 3 \"$# \n S . = 3 5 # . 7=43$5 = =43 5 ^ \n ! = !5 \n = !7 \n ; = 3$ ;75 \n = cd 3 \"d 7/8 Figure 2-17 ACS Fuel Required Equation 2-26 Figure 2-18 ACS Model Output 2.11 Cost Model With the satellite designed, a parametric cost estimating model can be selected to price the constellation. A publicly available special purpose model was selected due to its free nature. While SME: The New SMAD [1] presents several publicly available special purpose cost 2-27 estimating models, the SSCM is selected because of its usefulness in pricing spacecraft weighing less than 500 kg. Developed by The Aerospace Corporation, it is assumed that these cost estimating relationships (CERs) include the cost of contractor program management, systems engineering, product assurance, and I&T. The equations used to determine the CERS are shown below, and FY10 dollars have been adjusted to FY18 when utilized. SME-SMAD WBS Element CER Y = total non-recurring cost of development plus one protoflight flight unit in FY10 $K Cost Driver(s) Cost Driver Input Range Standard Error of Estimate (absolute) FY10 $K 1.1 Spacecraft Bus (Alternate CER if no component information available) Y = 1,064 + 35.5.) X = Spacecraft Bus Dry \nWeight (kg) 2-400 kg 3,696 1.1.1 Structure Y = 407 + 19.3X + ln X= Structure Weight (kg) 5-100 kg 1,097 \n1.1.2 Thermal Control Y = 335 + 5.7) X = Thermal Control Weight (kg) 5-12 kg 119 1.1.3 ADCS Y = 1,850 + 11.7) X = ADCS Dry Weight \n(kg) 1-25 kg 1,113 1.1.4 Electrical Power Supply (EPS) \nY = 1,261 + 539.) X = EPS Weight (kg) 7-70 kg 910 1.1.5 Propulsion (Reaction Control) \nY = 89 + 3.0.) X = Spacecraft Bus Dry Weight (kg) 20-400 kg 310 1.1.6a Telemetry, Tracking, & Command (TT&C) Y = 486 + 55.5.~\u007f X = TT&C Weight (kg) 3-30 kg 629 \n1.1.6b Command & Data Handling (CD&H) \nY = 658 + 75.~\u007f X = CD&H Weight (kg) 3-30 kg 854 1.2 Payload Y = 0.4X X = Spacecraft Bus Total Cost ($K) 2,600-69,000 ($K) 1.3 Integration, Assembly, & Test Y = 0.139X X = Spacecraft Bus Total Cost ($K) 2,600-69,000 ($K) 4.0 Program Level Y = 0.229X X = Spacecraft Bus Total Cost ($K) 2,600-69,000 ($K) 5.0 Launch & Orbital Operations Support (LOOS) Y = 0.061X X = Spacecraft Bus Total Cost ($K)
2,600-69,000 ($K) 6.0 Ground Support Equipment (GSE) Y = 0.066X X = Spacecraft Bus Total Cost ($K) 2,600-69,000 ($K) Table 2-5 SSCM Earth Orbiting Total Non-Recurring Cost Equations (Development Plus One Protoflight Unit) 2-28 In addition to providing the equations, SME: The New SMAD [1] also provides an interactive Excel sheet for the SSCM that is ready to use. Figure 2-19 presents a screenshot of the Excel file used to estimate the cost of the FireSat II spacecraft. \nFigure 2-19 FireSat II SSCM Excel File To estimate the cost of the entire constellation (total lot cost), the following equation can be used. > G = 1 I ) Figure 2-20 Total Lot Cost Equation ! \" 4 = 4# # 4 $ ! = ! # 4 3 \n = 57& $ 3 \n 3 = \"## 45d 3 2-29 The theoretical first unit cost is predicted by the SSCM Research, Development, Testing, and Evaluation (RDT however, caution should be used with this method. Volume constraints also become a concern when dealing with such a high quantity of satellites. After adding the SSCM estimate and the launch vehicle(s) cost, the design- to-orbit cost is complete. 3-1 Validation Efforts 3.1 Introduction While the entire design cannot be validated due to its specific mission objectives, several of the developed models can be validated against the FireSat II spacecraft, a textbook example from SME: The New SMAD [1]. Overall, the satellite power system model, the propulsion system mass model, and the ADCS Model were validated. 3.2 Satellite Power System Model An example test run was executed using the data provided by Table 21-12 Solar Array Design Process and Table 21-19 Steps in the Energy Storage Subsystem Design in SME: The New SMAD [1] for the FireSat II spacecraft. The results of the validation test are shown in Table 3-1. FireSat II Model % Difference Solar Array Area (() 2.0 1.99 0.5 \nSolar Array Mass (kg) 9.6 9.42 1.88 Battery Capacity (Whr) 119 116.34 2.24 With a maximum difference of 2.24 %, the satellite power system has been verified to be accurate. 3.3 Propulsion System Mass Model To verify the propulsion system mass model, data provided in section 18.8 of SME: The New SMAD [1] was utilized. Table 3-2 contains the results of the comparison between the FireSat II spacecraft and the model. Table 3-1 FireSat II Example Vs Satellite Power System Model 3-2 Table 3-2 FireSat II Example Vs Propulsion System Mass Model FireSat II Model Tank (kg) 8.2 8.2 Feed System (kg) 3.6 3.6 Propellant (kg) 41.5 41.5 Pressurant (kg) 0.13 0.13 As expected, no difference exists between the two because the same equations were used and no values were dynamically computed unlike the satellite power system where STK had to be used to solve for a daylight and eclipse period length that changes constantly based on the time period for the scenario of interest. Subsequently, the propulsion system mass model has been verified as being accurate when given the correct dry mass, ACS fuel estimate, and V values. 3.4 ADCS Model Verification of the ADCS model was made difficult due to the FireSat II spacecrafts lack of information directly related to using thrusters for momentum dumping. Upon researching other potential verification methods, Space Mission and Design (SMAD) [9] had information on the cyclical angular momentum per orbit and the fuel required for ACS for the original FireSat spacecraft. The numbers used for verification of the model are found in Table 11-13 Simplified Equations for Preliminary Sizing of Thruster Systems. 3-3 FireSat Example ADCS Model % Difference Cyclical Angular Momentum Per Orbit (Nms) 0.4 0.3815 4.625 ACS Fuel Required (kg) 2.43 2.38 2.06 While this verification has the highest percent difference, less than five percent difference is more than acceptable. Table 3-3 FireSat Example Vs ADCS Model 4-1 Results 4.1 Coverage Model The results from the six iterations are shown below. Number of Transmitters Transmitter Orientation(s) Average Percent Coverage (%) Average Area Covered (km) 1 Down Towards Earth 0.011944 10,579.33 \n2 Down Towards Earth and Left Face of Satellite 32.89 29,132,691.79 3 Down Towards Earth and Left and Right Face of Satellite 55.12 48,822,630.89 \n4 Down Towards Earth and Left, Right, and Front Face of Satellite 76.014 67,329,614.69 5 Down Towards Earth and Left, Right, Front, and Back Face of Satellite 94.69 83,870,816.93 \n6 All Sides 94.69 83,870,816.93 Initial estimates of a reasonable percentage coverage over CONUS to justify the cost of this program were placed at a minimum of 90 percent by MITRE personnel. Based on the numbers gathered through the analysis shown above, five transmitters are the optimal number. After Table 4-1 Average % Coverage Over CONUS Per Number of Transmitters on Each Satellite 4-2 reviewing the power consumption requirements per transmitter (389 Watts), it quickly became apparent that five transmitters on each satellite is not effective due to the increased size of solar panels needed to produce enough power for a five sensor orientation. As the solar panels grow in scale, the rest of the satellite would also have to grow to support the added weight and thermal needs. As a result, a two-transmitter orientation with one transmitter looking down and one transmitter on one of the sides of the satellite was selected. Because of this orientation, the satellite would require an orientation maneuver to communicate with any space object that is not in the field of view of one of the two RF transmitters at a given instance to provide an acceptable percentage coverage. 4.2 Satellite Power Budget Using the equations from SME: The New SMAD [1], a first order power estimate for the satellite was placed at 2,387 Watts. This estimate is reasonably close to the following final power budget which was derived through the design iteration process. Item Watts (W) Quantity Needed Total Power Required (W) RF Transmitter 389 2 778 RF Transmitter Computer 178 1 178 ConLCT (Laser) [10] 80 4 320 Reaction Wheels (Blue Canyon Tech RWP500) [11] 6 3 18 Star Tracker VST-41M [12] 2.5 1 2.5 Fine Sun Transmitter [13] 0.25 1 0.25 Main Thruster (Monarc-445) 58 1 58 Momentum Dumping Thrusters (MRE-1.0) 15 4 60 Thermal Control 238.7 1 238.7 On-Board Processing 286.44 1 286.43 Power 214.83 1 214.83 Structure and Mechanism 23.87 1 23.87 Total 2178.58 Table 4-2 Final Power Budget 4-3 As previously discussed, in order to accurately model the situation that the satellite will not always be operating at full power, it is assumed that the satellite operates a third of the day at full-power, a third of the day at half-power, and a third of the day at no-power. Furthermore, it is assumed that you can only communicate at full-power during sunlight periods where the satellite is able to use power from both batteries and the solar panels. Thus, the power used for all subsequent calculations for the final design is 1,089.3 Watts. 4.3 Satellite Power System Results Using the 1,089.3 Watts estimate, the Satellite Power System model is used to calculate the solar array area, solar array mass, battery capacity, and battery mass. Figure 4-1 shows the results of the satellite power system model. \nFigure 4-1 Satellite Power System Results 4-4 Based on these results, multi-junction cells using direct energy transfer were selected for the final design. An estimated 5.43 () of solar array weighing 66.42 kg is required to meet the \ndaylight and eclipse power requirements. Furthermore, to store the energy from the solar array, a battery with a capacity of 1,303.5 Whr weighing 10.43 kg is needed. 4.4 Satellite Mass Results With the results from the coverage model and the satellite power system model, the spacecraft bus dry mass results using the equations from SME: The New SMAD [1] are shown below for the satellite designed to complete MITREs proposed mission. Mass (kg) Payload 64.5 Structure 56.25 Thermal 4.16 Power 76.85 TT&C 4.16 On-Board Processing 10.41 ADCS 12.49 Propulsion 6.24 Other 6.24 Total Dry 241.3 Again, this dry mass estimation method proves extremely effective compared to the final dry mass estimate derived from a part list created after multiple iterations of the design process. Table 4-4 shows the final dry and wet mass estimates. Table 4-3 Spacecraft Bus Dry Mass Estimate Using SME: The New SMAD [1] Equations 4-5 Item Quantity Mass (kg) Total Mass (kg) RF Transmitter 2 2.27 4.54 RF Computer 1 2.27 2.27 ConLCT (Laser) 4 15 60 Reaction Wheels (Blue Canyon Tech RWP500) 3 0.75 2.25 Star Tracker VST-41M 1 0.9 0.9 Fine Sun Transmitter 1 0.375 0.375 Main Thruster (Monarc-445) 1 1.59 1.59 Momentum Dumping Thrusters (MRE-1.0) 4 1 4 Surface Tension Propellant Tank OST 33/0 [14] 1 13.5 13.5 Propellant Feed System 1 5.87 5.87 Solar Panels 1 66.42 66.42 VES 180 Batteries [15] 7 1.11 7.77 VES 100 Battery [15] 1 0.81 0.81 Structure 1 56.21 56.21 Thermal Control 1 4.16 4.16 TT&C 1 4.16 4.16 On-Board Processing 1 10.41 10.41 Other (Balance+Launch) 1 6.25 6.25 Total Dry Mass 251.49 Propellant for V Budget 1 95.54 95.54
Propellant for Momentum Dumping 1 7.59 7.59 Table 4-4 Satellite Dry and Wet Mass Results 4-6 Total Wet Mass 103.13 Total Mass 354.62 With a total mass of 354.62 kg, the satellite remains in the SSCM range. 4.5 Satellite Dimensions During the creation of the satellites part list, the dimensions of each part is also recorded. Using this part list, a SolidWorks assembly was created to estimate the overall dimensions of the satellite, leaving a small portion of volume for parts whose size could not be easily estimated. The dimensions of the various parts and a picture of the SolidWorks assembly are shown below (Note: The solar panels are not shown). Item Dimensions (m or ()) \nRF Transmitter Length: 0.127; Width: 0.089; Height: 0.165 RF Computer Length: 0.14; Width: 0.131; Height: 0.159 ConLCT (Laser) Length: 0.76; Width: 0.29; Height: 0.435 Reaction Wheels (Blue Canyon Tech RWP500) Length: 0.11; Width: 0.11; Height: 0.038 Star Tracker VST-41M Length: 0.08; Width: 0.10; Height: 0.18 Fine Sun Transmitter Length: 0.108; Width: 0.108; Height: 0.0525 Main Thruster (Monarc-445) Length: 0.41; Exit Diameter: 0.148 Momentum Dumping Thrusters (MRE-1.0) Length: 0.188; Width: 0.114 Surface Tension Propellant Tank OST 33/0 Height: 0.896; Diameter: 0.6 Solar Panels Area: 5.43 VES 180 Battery Height: 0.25; Diameter: 0.053 Table 4-5 Satellite Dimensions 4-7 VES 100 Battery Height: 0.185; Diameter: 0.054 Overall Dimensions (Structure): Length: 1.143; Width: 0.724; Height: 0.635 Due to time constraints, some simplifications were made for a few of the part drawings. For example, the thrusters are simplified as cylinders. Lastly, as stated earlier, some of the volume is reserved for parts that could not be sized easily as shown in Figure 4-2. 4.6 Satellite Cost Model Finally, the SSCM was utilized to price the proposed satellite constellation. The estimated cost for the research, development, test, and evaluation (RDT however, a constellation design-to-orbit cost of $3.467 B is likely limiting. The satellite design processes undertaken in this technical report provide insight into possible satellite design improvements. The primary objective has been generating useful results that can aid MITRE and its sponsors in the systems engineering process at the preliminary design and verification level. The goals of the design process have been to optimize the cost of the satellite while at the same time meeting the desired performance requirements. Upon review of the results, the satellite design does meet the requirements provided by MITRE. Coverage over CONUS is provided at an acceptable rate; however, the cost of the constellation is limiting. The initial goal for total constellation cost was between $500 M and $1 B. This optimized satellite design employs conventional forms of subsystem designs based on heritage satellite technology. It is likely that additional improvements in technology will develop between now and implementation of such a satellite. The use of composite materials along with improvements in monopropellants could bring about better performing and more cost-effective solutions. 6-1 Recommended Improvements 6.1 Laser Communication Although MITRE established a requirement that RF transmitters be used for communication between the satellite, low-flying objects, LEO satellites and the ground terminals, the ability to use the laser communication system for all communications would drastically reduce the size of the satellite. The power requirements of the RF transmitters are almost half of the total power budget. If the power budget could be reduced by half, the solar panel area will decrease greatly which will also cause a significant decrease in the mass of the satellite. This mass savings will also decrease the mass of other systems allowing for a significant cost savings to occur. 6.2 SolidWorks Drawing The SolidWorks drawing should be updated to include more accurate renderings of a few of the parts. Time constraints resulted in some approximation methods being utilized such as thrusters being approximated by a cylinder. More accurate renderings would allow for better visualization and center of mass approximations. 6.3 SSCM The SSCM is considered the best small satellite cost model living up to its namesake. While the latest version of SME: The New SMAD [1] was utilized, the SSCM provided in the textbook is the 1996 version. Since the 1996 version was released, society has seen the creation and exponential growth in the development of cubesats, microsatellites, and small satellites thus greatly decreasing the cost to design and build a satellite. The latest version of SSCM should be acquired from The Aerospace Corporation to verify and update the cost model. 7-1 References \n[1] Wertz, J.R., W.J. Larson. 2011. Space Mission Engineering: The New SMAD. 1st ed. Microcosm Press [2] Aerospace Corporation. 1996. Small Satellite Cost Model (SSCM). El Segundo, CA: The \nAerospace Corp. [3] Brown, Charles D. Elements of Spacecraft Design. American Institute of Aeronautics and \nAstronautics. Inc., 2002. ISBN: 1-56347- 524-3 [4] Northrop Grumman. (2018, December 31). MRE-1.0 Monopropellant Thruster, \nNorthrop Grumman. Available: www.northropgrumman.com/Capabilities/PropulsionProductsandServices/Documents/MR E-10_MonoProp_Thruster.pdf [5] Moog. (2018, December 31). Monopropellant Thrusters, Moog. Available: \nhttp://www.moog.com/content/dam/moog/literature/Space_Defense/Spacecraft/Monoprop ellant_Thrusters_Rev_0613.pdf [6] NIST Chemistry WebBook. 2011. Website [7] Fortescue et al. 2003. Spacecraft Systems Engineering. 3rd ed. Wiley [8] Benson, Tom. Earth Atmosphere Model, Metric Units, NASA Glenn Research Center [9] Wertz, J. and W. Larson. 1999. Space Mission Analysis and Design. 3rd ed. Hawthorne, \nCA: Microcosm Press and Springer. [10] Virtual Market Place. (2018, December 31). ConLCT, Available: \nhttps://virtualmarket.ila-berlin.de/en/ConLCT,p1017337 [11] Blue Canyon Technologies. (2018, December 31). RWP500 Available: \nbluecanyontech.com/rwp500/ [12] Vectronic Aerospace. (2018, December 31). Star Tracker VST-41M Available: \nhttps://vectronic-aerospace.com/space-applications/star-transmitter [13] Bradford. (2018, December 31). Fine Sun Transmitter Available: bradford-\nspace.com/assets/pdf/be_datasheet_fss_2017jan.pdf [14] Ariane Group. (2018, December 31). Surface Tension Propellant Tank OST 33/0 \nAvailable: www.space-propulsion.com/brochures/propellant-tanks/176lt-n2h4-tank-ost-33- 0.pdf [15] Saft. (2018, December 31). Rechargeable Li-ion battery systems Available: \nwww.houseofbatteries.com/documents/VES.pdf https://virtualmarket.ila-berlin.de/en/ConLCT,p1017337\nhttps://vectronic-aerospace.com/space-applications/star-sensor 7-2 A-1 Appendix A Acronyms ACS Attitude and Control System ADCS BOL CERs Attitude, Determination, and Control System Beginning-of-Life Cost Estimating Relationships CONUS V DOD EOL GUI He PMD RF RDT&E STK SMAD SSCM SRP Continental United States Delta-V Depth-of-Discharge End-of-Life Graphical User Interface Helium Propellant Management Devices Radio Frequency Research, Development, Test, and Evaluation Systems Tool Kit Space Mission Analysis and Design Small Satellite Cost Model Solar Radiation Pressure Introduction\n Approach\n Introduction\n Constellation Parameters\n Coverage Model\n Purpose\n Methodology\n Coverage Model Output First-Order Satellite Power Estimate\n Power System Model\n Purpose\n Power System GUI Design\n Solar Panel Sizing\n Battery Sizing\n Power System Model Outputs Delta-V (V) Estimate\n Spacecraft Bus Dry Mass Estimate\n Propulsion System Mass Model\n First Order Estimate of Satellite Dimensions\n ADCS Model\n Introduction\n Determination Transmitters\n Attitude and Control System (ACS) Initiation File\n ACS Sizing Function\n Introduction\n Solar Radiation Pressure (SRP) Torque Calculation\n Atmospheric Drag Torque Calculation\n Magnetic Torque Calculation\n Gravity-Gradient Torque Calculation\n Reaction Wheel Sizing\n ACS Propulsion Sizing\n ACS Model Outputs Cost Model Validation Efforts\n Introduction\n Satellite Power System Model\n Propulsion System Mass Model\n ADCS Model Results\n Coverage Model\n Satellite Power Budget\n Satellite Power System Results\n Satellite Mass Results\n Satellite Dimensions\n Satellite Cost Model Conclusion\n Recommended Improvements\n Laser Communication\n SolidWorks Drawing\n SSCM References\n Acronyms ",
    "text": " Microsoft Word 289292 i MITREs mission-driven teams are dedicated to solving problems for a safer world. Through our federally funded R&D centers and public-private partnerships, we work across government to tackle challenges to the safety, stability and well-being of our nation. ii Table of Contents Background \nhttps://accelerate.mitre.org/\nhttps://www.mitre.org/publications/technical-papers/defense-agile-acquisition-guide-tailoring-dod-it-acquisition-program\nhttps://playbook.cio.gov/techfar/\nhttps://playbook.cio.gov/ 10 RFP Patterns and Techniques for Successful Contracting Contracting Guidance to Support Modular Development SAFe 4.6 GAOs (12-681) Software Development: Effective Practices and Federal Challenges in Applying Agile Methods SEIs RFP Patterns and Techniques for Successful Agile Contracting Defense Innovation Board (DIB) Software Acquisition and Practices (SWAP) Study Familiarization with these publications equips the workforce with all of the foundational knowledge needed to achieve acquisition flexibility and prevent them from having to reinvent the wheel. 8. Inject Training and Experience to Support a Flexible Agile Approach: Agile coaches, with deep experience in managing agile programs, provide the needed expertise to guide program teams. Observations/Challenges: It is an understatement to say that, applying an Agile approach to software development is not easy. The need for an experienced, co-located Agile coach in a clearly defined visible role is made more and more apparent every day. Programs frequently encounter difficult or unique situations that require training, experience, and guidance. Recommendation: The Defense Acquisition University (DAU) offers some short courses that provide acquisition and source selection teams with tools to help understand the different methodologies of Agile software development. One important continuous learning course, Continuous learning module CLE076 Introduction to Agile Software Development for Defense, includes Agile approaches, and benefits and risks of Agile development. DAU also offers a series of short videos produced by DAUs Agile subject matter experts (SMEs), Mr. Chris Collins and Mr. Robert Thomas. Additional videos on the site include Agile Software Development and Scrum 101. These videos cover basic principles of Agile software development. By investing time in these course offerings and understanding principles of Agile development, an organization will be better positioned to write requirements or define higher level objectives for a SOO with flexible and open parameters. Moreover, understanding the intricacies of standing up a large Agile development program, particularly one with many levels and comprising a large solution, requires a Sherpa who has done similar work in the past. It is not sufficient to learn on the job with so much at stake. The coach can also have bigger impact with a clearly defined role on the program. https://resources.sei.cmu.edu/asset_files/SpecialReport/2016_ 63.pdf\nhttps://obamawhitehouse.archives.gov/sites/default/files/omb/procurement/guidance/modular-approaches-for-information-technology.pdf\nhttps://www.scaledagileframework.com/agile-contracts/\nhttps://www.gao.gov/assets/600/593091.pdf\nhttps://www.gao.gov/assets/600/593091.pdf\nhttps://resources.sei.cmu.edu/asset_files/SpecialReport/2016_ 63.pdf\nhttps://media.defense.gov/2019/Apr/30/ /-1/-1/0/SOFTWAREISNEVERDONE_REFACTORINGTHEACQUISITIONCODEFORCOMPETITIVEADVANTAGE_FINAL.SWAP.REPORT.PDF\nhttps://media.defense.gov/2019/Apr/30/ /-1/-1/0/SOFTWAREISNEVERDONE_REFACTORINGTHEACQUISITIONCODEFORCOMPETITIVEADVANTAGE_FINAL.SWAP.REPORT.PDF 11 Agile purists are not able to deliver success or positive change. The best Agile development implementations tailor the methods to the needs of the organization. The best coaches understand the principles and know what to tailor to help the organization progress and become more efficient, while not tailoring away the goodness that is enabled by the agile methods. Additionally, program teams should reply upon a Sherpa who can guide the program and keep it on a path to success. Agile coaches, with deep experience in managing agile programs, provide the needed expertise to guide program teams; they should be integrated into the Governments program management team and empowered. Programs must adopt and include a co-located agile coach in a clearly defined, visible role. This role should not be provided by the contractor who is leading the development effort. 9. Institute a Change Management Process: Change management needs to continue throughout the lifecycle of the program, and programs should continuously look to adopt such practices at a larger scale. Observations/Challenges: In many cases, a program team establishes a clear and disciplined roadmap to achieving program success but are less disciplined when an unexpected change disrupts the teams plans. This, in turn, could result in extended delays and additional unnecessary costs. Implementing Agile Development requires change in organizations. This includes change to their planning processes, change to their deliverables, change in the way testing is accomplished, and change in how deployments are managed. It is insufficient to enable changes in one area and expect each of the other areas to change themselves. This change should be accomplished as part of the DevSecOps Tactics, Techniques, and Procedures (TTPs). Recommendation: The introduction of flexibility into acquisition processes does not mean that the processes should be undisciplined. Brown and Hegarty provide a sound recommendation and caution the Government to continuously Anticipate the unexpected and include language to govern contract extensions.7 This not only ensures that contractors are fully prepared to adapt to evolving needs, but also encourages them to build a plan in response to the Government request for proposal (RFP) describing how the contractor will deal with inevitable changes to avoid having to re-negotiate the contract. 7 Brown, A. a requirements backlog meets this need. Finally, the established change management process must include repeatable processes for evaluating and reprioritizing the backlog (or equivalent) on a regular basis. Establishing this normalized rhythm of reprioritization will minimize many of the negative effects that evolving requirements generate. Change management needs to continue throughout the lifecycle of the program, and programs should continuously look to adopt such practices at a larger scale. Furthermore, it is imperative that programs are aware and build relationships with supporting organizations to help make and support change throughout the programs lifecycle. 10. Enforce a Robust Requirements Elicitation and Development Process: It is imperative to time-box requirement elicitation, and most importantly, to have all of the stakeholders in the room, working collaboratively on defining these requirements. 8 RFP Patterns and Techniques for Successful Agile Contracting, Software Engineering Institute, November 2016. https://resources.sei.cmu.edu/asset_files/SpecialReport/2016_ 63.pdf 9 Ibid. 10 Brown, A. however, if the Government does not want to create this definition upfront, it should require offerors to include that definition as part of their Agile proposal or the proposed process. Ultimately, this definition, tied with a well-defined vision, will be used to accept or reject the contractors output at the end of each sprint and will maintain boundaries to promote greater flexibility within. 12. Identify the Right Agile Development Metrics: Practitioners must define metrics to determine value to the end user. Observations/Challenges: Pursuant to Section 872 of the 2018 NDAA, the Defense Innovation Board (DIB) conducted a study on Software Acquisition Practices (SWAP). The first of three (3) fundamental themes discussed how Speed and cycle time are the most important metrics for managing software.13 This aligns to the 2018 National Defense Strategy to ensure that the U.S. Government executes acquisition and development faster than its adversaries. However, finding the right metrics to use for evaluating a program can be challenging and must progress beyond estimating complexity based on Source Lines of Code and in terms of programmer productivity.14 Recommendation: The DIB Metrics for Software Development report stipulates that different software types (e.g., commercial, custom, or blends) will drive different metrics to evaluate program success. Consequently, the report recommends deployment rate, response rate, code quality, and program management as four (4) necessary categories of metrics, while providing discrete examples that can be incorporated into both acquisition strategies and plans to maintain accountability for program success. Finally, practitioners must define metrics to determine value to the end user in relation to the aforementioned four (4) general categories to align programmatic and mission success. As with the Vision, and definition of Done, strong metrics help to communicate clear reasonable boundaries, allowing for greater variability of activities and flexibility within those limits. 13. Develop an Overall Vision: The Product Vision, coupled with the use of a SOO, provides flexibility. 13 Defense Innovation Board (DIB) Software Acquisition and Practices (SWAP) Report. https://innovation.defense.gov/software/ 14 Defense Innovation Board (DIB) Metrics for Software Development. https://media.defense.gov/2019/May/02/ /-1/-1/0/DEFENSEINNOVATIONBOARDMETRICSFORSOFTWAREDEVELOPMENT.PDF 15 Observations/Challenges: FAR 15.203(a)(1) requires Requests for Proposals (RFPs) to describe the Governments requirements; however, it is significantly more difficult to define tasks and develop a work statement for an Agile-like requirement due the evolving nature of solution development and employment. Recommendation: In 2014, Scrum.inc hosted a presentation on Agile Contracts: The Foundation of Successful Partnering, led by Alex Brown and Christopher Hegarty, which suggested that agencies specify overall vision and context in the Statement of Objectives (SOO) versus stipulating the required process.15 This approach enables the Government to articulate a framework and award flexible contracts that meet the Governments vision. The TechFAR also recommends the use of a Product Vision, which establishes a high-level definition of the scope of the project, specifies expected outcomes, and produces high level budgetary estimates. This Product Vision, coupled with the use of a SOO, provides flexibility and allows vendors to develop innovative solutions.16 14. When in Agile, Act Like an 874: Tailor programs to reduce contract requirements for DoD software development. Observations/Challenges: The role of these 874 pilots is to write the book on how Agile can be best integrated into the current Department of Defense (DoD) acquisition system to help streamline delivery of software intensive developments. Just because a program or project is not explicitly designated as a formal 874 project doesnt mean that agencies cannot utilize 874 Agile best practices to build a better solution. Recommendation: If a program
is selected as one of a handful of annual NDAA Section 874 Software Development Pilot Programs using Agile best practices, then it will innately be more flexible when acquiring Agile software development services. This program allows DoD to leverage Agile acquisition methods to reduce certain contract requirements for DoD software development \nhttps://www.dhs.gov/person/soraya-correa\nhttps://34slpa7u66f159hfp1fhl9aur1-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Agile-Contracts.pdf\nhttps://34slpa7u66f159hfp1fhl9aur1-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Agile-Contracts.pdf\nhttps://obamawhitehouse.archives.gov/sites/default/files/omb/procurement/guidance/modular-approaches-for-information-technology.pdf\nhttps://obamawhitehouse.archives.gov/sites/default/files/omb/procurement/guidance/modular-approaches-for-information-technology.pdf\nhttps://innovation.defense.gov/software/\nhttps://media.defense.gov/2019/May/02/ /-1/-1/0/DEFENSEINNOVATIONBOARDMETRICSFORSOFTWAREDEVELOPMENT.PDF\nhttps://media.defense.gov/2019/May/02/ /-1/-1/0/DEFENSEINNOVATIONBOARDMETRICSFORSOFTWAREDEVELOPMENT.PDF\nhttps://playbook.cio.gov/#play5\nhttps://www.gao.gov/assets/600/593091.pdf\nhttps://fcw.com/articles/2014/06/26/buying-agile-without-jumping-through-hoops.aspx\nhttps://www.mitre.org/publications/technical-papers/defense-agile-acquisition-guide-tailoring-dod-it-acquisition-program\nhttps://www.mitre.org/publications/technical-papers/defense-agile-acquisition-guide-tailoring-dod-it-acquisition-program\nhttps://assets.kpmg/content/dam/kpmg/pdf/2012/07/the-power-of-procurement-a-global-survey-of-procurement-functions.pdf\nhttps://assets.kpmg/content/dam/kpmg/pdf/2012/07/the-power-of-procurement-a-global-survey-of-procurement-functions.pdf\nhttps://resources.sei.cmu.edu/asset_files/SpecialReport/2016_ 63.pdf\nhttps://section809panel.org/media/updates/\nhttps://techfarhub.cio.gov/assets/files/TechFAR Handbook_2014-08-07.pdf\nhttps://www.oversight.gov/sites/default/files/oig-reports/VAOIG-18-04266-115.pdf\nhttps://www.oversight.gov/sites/default/files/oig-reports/VAOIG-18-04266-115.pdf 24 Acronym List AWF Acquisition Workforce BOA Basic Ordering Agreement BPA Blanket Purchase Agreement CDD Capability Development Document ChBA Challenge-Based Acquisition CLIN Contract Line Item Number DAU Defense Acquisition University DHS Department of Homeland Security DIB Defense Innovation Board DISA Defense Information Systems Agency DoD Department of Defense DoDI Department of Defense Instruction EVM Earned Value Management FAR Federal Acquisition Regulation GAO Government Accountability Office IDIQ Indefinite Delivery/Indefinite Quantity IPT Integrated Product Team IT Information technology MVP Minimal Viable Products NDAA National Defense Authorization Acts OIG Office of Inspector General OMB Office of Management and Budget OSD Office of the Secretary of Defense OT Other Transaction OTA Other Transactional Authority PI Program Increment PM Program Manager POC Point of contact RFP Request for Proposal SAFe Scaled Agile Framework SOO Statement of Objectives SOW Statement of Work SME Subject matter expert SWAP Software Acquisition and Practices T&M Time-and-Materials TO Task Order TTP Tactics, Techniques, and Procedures U.S. United States VA Veterans Administration 25 Background\n Scope\n Problem Statement\n The Acquisition Environment and How We Got Here\n Recommendations\n Identify a Champion to Enable a Flexible Agile Approach:\n Establish a Flexible, Agile Development and DevSecOps Culture:\n Put \"the Right\" Acquisition Team in Place:\n Bring End-Users into the Fold:\n Give the Acquisition Office(s) a Prominent Seat at the Table:\n Create and Implement Defined Processes:\n Research Exemplars and Gain a Foundational Understanding of Agile Practices:\n Inject Training and Experience to Support a Flexible Agile Approach:\n Institute a Change Management Process:\n Enforce a Robust Requirements Elicitation and Development Process:\n Create a \"Definition of Done\":\n Identify the Right Agile Development Metrics:\n Develop an Overall Vision:\n When in Agile, Act Like an 874:\n Maximize Use of Inherently Flexible Acquisition Vehicles:\n Consider Using Challenge-Based Acquisition Processes:\n Utilize a Statement of Objectives (SOO) to Define Requirements:\n Tailor the Pricing Structure:\n Maximize Use of Options:\n Enforce Automation, Testing, and Quality:\n Frame the Solution as a Modular Service:\n Clearly Articulate Intent and Requirement:\n Carefully Craft Contract Modifications: Conclusion\n References\n Acronym List ",
    "text": " Technical Document Deliverable, 2019 Author(s): Joseph Mahakian Scott Holmdahl Quadri Bada Steffani Silva Zach Tretler The views, opinions and/or findings contained in this report are those of The MITRE Corporation and should not be construed as an official government position, policy, or decision, unless designated by other documentation. McLean, VA January 2020 AWS GovCloud Resource and Cost Analysis \n ii iii Executive Summary \nThis technical report outlines many of the most impactful principles and techniques for reducing the cost of hosting a program on Amazon Web Services (AWS) GovCloud. In full production, cloud-hosted IT systems have the potential to incur significant annual costs associated with operation and maintenance, so in order to optimize resource allocation and achieve significant cost savings, the Program Management Office (PMO) should leverage cost-saving techniques and services which are designed to complement AWS dynamic cloud environment. PMOs can realize cost savings and institute effective cost management practices by focusing on three areas: deployment strategies, cost management tools, and programmatic best practices. The scope of these considerations includes both architecture design decisions as well as the integration of services to improve the PMOs insight into billing. To validate the cost saving techniques outlined in this technical report, a proof of concept was performed using a prototypical AWS DevSecOps account. The account currently costs an estimated $7,059 per month, whereas by applying the principles, the estimated bill was reduced by 43% to $4,001 per month while maintaining identical functionality. Because EC2 and RDS instances account for 97% of the bill for the example DevSecOps account, the majority of the implemented cost saving techniques were related to EC2 and RDS instances. Not all of this reports cost saving techniques could be applied to a typical DevSecOps account, but should be considered nonetheless. Focusing on the compute cost component, one of the most practical and effective techniques for the PMO to reduce annual costs is the utilization of Reserved Instances, which offer significant discounts based on time commitment and payment method, instead of On-Demand Instances. To understand the potential cost savings of using a Reserved Instance, a calculation was performed for a representative instance of a typical program (a Linux c5.xlarge EC2 instance in the GovCloud US-EAST region). Figure 1 Cost Comparison of On-Demand and Reserved Instances As demonstrated in Figure 1, the PMO can immediately realize cost savings of 37% by switching to one-year Reserved Instances, or 60% by switching to three-year Reserved Instances. Even further cost savings can be achieved with other tools such as auto-scaling groups. 149.33 149.33 149.3394.17 89.37 87.8459.13 55.22 51. No Upfront Partial Upfront All UpfrontEffective Monthly CostOn-Demand (currently utilized) 1 Year Reserved 3 Year Reserved iv Table of Contents Introduction \n2.1 AWS GovCloud \n3.1 Reserved Instances \n3.2 Spot Instances \n3.3 Auto Scaling and Automating Elasticity \n3.4 S3 Object Lifecycle Management \n3.5 Instance States and Stopping Instances \n3.6 Tagging \n3.7 AWS Config \n3.8 AWS Organizations \n3.9 EC2 Right Sizing \n4.1 AWS Billing and Cost Management \n4.2 AWS Cost Explorer \n4.3 AWS Trusted Advisor \n4.4 AWS Budgets \n4.5 AWS CloudWatch \n4.6 AWS CloudTrail \n4.7 Cost Optimization Monitor \n4.8 AWS Cost and Usage Report \n5.1 Architecture \n5.2 DevOps \n5.3 Lean Culture \n5.4 AWS-Oriented Business Process Re-Engineering \n5.5 Policy-Driven Automation \n6.1 Current Cost Estimate \n6.2 Cost Conscious Improvements \n6.2.2 Auto-Scaling Groups \n6.2.3 Stopped Instances \n6.3 Cost Management \nAppendix B Cloud Computing \nB.1.1 IaaS \nB.1.2 SaaS \nB.1.3 PaaS \nB.2.1 Cloud \nB.2.2 On Premise \nB.2.3 Hybrid \nAppendix D Abbreviations and Acronyms \nFigure 1 Cost Comparison of On-Demand and Reserved Instances \nFigure 2 Cost Comparison of On-Demand and Reserved Instances \nFigure 3 EC2 Instance Prices \nFigure 4 S3 Object Mobility \nFigure 5 Sample Lifecycle Management for Application Logging on S3 \nFigure 6 Transitions Between Instance States \nFigure 7 Cost Optimization Monitor architecture \nFigure 8 On-Demand Compared to Reserved Pricing \nFigure 9 Cost Reduction using Auto-scaling \nFigure 10 Relationship Between Regions and Availability Zones \nTable 1 S3 Storage Classes \nTable 2 Instance States and Billing \nTable 3 AWS Services in a DevSecOps Account \nTable 4 Cost Comparison of DevSecOps Instance Types \nTable 5 Application of Reserved Instances to DevSecOps Account \nTable 6 Cost of a Single GitLab Runner \nMany government programs interact with one or more IT systems of systems that is developed, operated, and maintained by several government stakeholder groups. In a cloud-hosted IT stack, many of the technical components of the programs system may be hosted in Amazon Web Services (AWS) GovCloud. In full production, there are often significant costs incurred by utilizing GovCloud services. With the large volume of services being used to create the programs IT system, it is imperative to evaluate their use in a dynamic and scalable cloud environment to ensure maximum cost effectiveness while maintaining full operational capability. The scope of this paper is limited to data and applications hosted in GovCloud and does not address cost optimization for systems hosted outside of GovCloud, including external data transferring into or out of GovCloud. Although many government programs run solely in GovCloud regions, the paper may include tools and services which have not yet been released in GovCloud regions at this time. There is usually a delay before AWS services for publicly available regions are accredited and become available for use in GovCloud. This technical report is broken into three themes of cost optimization: cost deployment strategies, cost management tools, and programmatic best practices. The cost deployment strategies sections discusses nine AWS recommended management strategies to limit the costs associated with running instances in the cloud environment. The cost management tools section defines the AWS services available to implement these cost-management strategies. Finally, the programmatic best practices defines recommended actions to introduce and maintain a cost- effective cloud environment to an organization. The report culminates in an evaluation of an sample GovCloud DevSecOps environment and how the utilization of these management strategies can significantly reduce program costs. 9 Optimize for the Cloud \nIn a traditional datacenter environment, teams were limited to either design architectures within the constraints of existing hardware or request additional resources, which is often an arduous task. Datacenter procurements require the purchase of enough servers to support an application during peak hours, which results in a misallocation of resources while equipment sits idle during non-peak hours. The cloud is fundamentally different from a traditional datacenter in that it offers virtually unlimited scalable capacity with tremendous opportunity for increased design flexibility. In the cloud cost model, one only pays for the resources one uses. In order to maximize the benefits of hosting systems in a cloud environment, cloud-based applications should be architected in a method that is appropriate and economical for the environment it is hosted in. This operating model requires an IT strategy which is cloud conscious. 2.1 AWS GovCloud AWS GovGloud regions are isolated cloud regions of Amazon Web Services for workloads with direct or indirect ties to U.S. Government functions or services. All customers who use GovCloud must either be Government organizations or other approved private entities in Government-related industries such as Aerospace, Law Enforcement, and Healthcare. Currently there are two GovCloud regions, US-West and US-East. The regions are physically located in the United States and are designed to allow U.S. government agencies and customers to move sensitive workloads into the cloud by addressing their specific regulatory and compliance requirements, including Federal Risk and Management Program (FedRAMP), High Department of Defense Security Requirements Guide (DoD SRG), Impact Level 5, and Criminal Justice Services (CJIS). 10 Cost Optimization AWS Deployment Strategies \nThis section of the technical report describes cost-saving strategies and practices for resources deployed in an AWS cloud environment. While many of the concepts described in this section are cloud-provider agnostic, the exact tools discussed are AWS-specific. Nine strategies discussed in this section include: Reserved Instances: instances set in advance at a discounted rate \n Spot Instances: instances that can be bid on and will run until cost exceeds bid price \n Auto Scaling and Automating Elasticity: scaling instances based on volume demand \n S3 Object Lifecycle Management: storage type changes by object lifecycle and access frequency Instance States and Stopping Instances: billing only occurs during running states \n Tagging: labels applied to resources to maintain visibility for cost management \n AWS Config: change management of AWS resource configurations \n AWS Organizations: managing policies and monitoring of all AWS accounts within an organization EC2 Right Sizing: appropriately sizing EC2 instance type and size based on usage \ndemand 3.1 Reserved Instances Many programs workloads on GovCloud have a predictable usage pattern, with consistent downtimes and long term utility. For these stable applications, the PMO can achieve significant cost savings by converting these instances from On-Demand Instances to Reserved Instances. Reserved Instances enable organizations to commit to usage parameters for a specified amount of time (either one year or three years) in exchange for significant cost savings compared to On- Demand Instances. Functionally, Reserved Instances are identical to On-Demand Instances and are available for services including EC2, RDS, Redshift, and more. The discount rate is a
function of time commitment (one year or three years) and payment method (no upfront, partially upfront, or entirely upfront), with maximum savings occurring for three year commitments paid entirely upfront. To understand the potential cost savings of using a Reserved Instance, a proof of concept has been calculated for a Linux c5.xlarge EC2 instance on the GovCloud (US-EAST) region. This instance features 4 vCPU and 8GB Memory. The graph below shows the monthly cost associated with running this EC2 instance given the different pricing models. 11 \nFigure 2 Cost Comparison of On-Demand and Reserved Instances Currently, a c5.xlarge On-Demand Instance costs $149.33 per month in the cloud. If that exact instance were transitioned to the Reserved Instance price model for a three year agreement, with no upfront payment, the price is reduced to $59.13 per month, which represents more than 60% savings. Even further savings could be realized with a partially or entirely upfront payment. 3.2 Spot Instances In addition to On-Demand and Reserved Instances, AWS also offers EC2 Spot instances, which allow one to bid on spare EC2 computing capacity at a significantly discounted rate compared to On-Demand and Reserved Instances. Figure 3 illustrates the significant discount rate Spot Instances offer when compared to the other EC2 types. The figure displays monthly costs for deploying a c5.xlarge instance in the GovCloud (US-EAST) region for all variations of On- Demand, Reserved, and Spot instances. The c5.xlarge and the collective c-series EC2 family are the most commonly deployed EC2 instances in the example programs DevSecOps architecture (see Section 6). 149.33 149.33 149.3394.17 89.37 87.8459.13 55.22 51. No Upfront Partial Upfront All UpfrontEffective Monthly CostOn-Demand 1 Yr Reserved 3 Yr Reserved 12 \nFigure 3 EC2 Instance Prices Unlike the discounted Reserved Instances, Spot Instances do not require an upfront commitment or upfront payment. However, because Spot Instances can be terminated if the Spot price exceeds your maximum bid price or if no capacity is available for the specified instance type, they are best for flexible workloads. By properly architecting specific workloads, you can take advantage of Spot pricing for a wide range of needs. 3.3 Auto Scaling and Automating Elasticity In cloud environments such as AWS, resources are elastic and can immediately scale up or down to match application requirements. This elasticity allows cloud administrators to match the supply of resources, to demand, which optimizes cost in the process. There are two primary types of elasticity, time-based and volume-based. Time-based elasticity implies turning off instances when they are not being used (see Section Error! Reference source not found.), while volume- based elasticity involves matching the scale of resources to the intensity of demand. Amazon provides tools to automate both volume and time-based elasticity. Section Error! Reference source not found. discusses strategies for automating time-based elasticity. The best tool to automating volume-based elasticity is Auto Scaling, which automatically increases or decreases the number of EC2 instances during demand spikes and lulls. Auto Scaling monitors your applications and automatically adjusts capacity to maintain performance based on thresholds set by the cloud administrator. Applications that have stable demand patterns such as predicable workloads on a hourly, daily, or weekly basis, are excellent candidates to be configured with an Auto Scaling configuration. To enable Auto Scaling, an Auto-Scaling Group (ASG) can be configured. An ASG is AWS managed service which provides a set of EC2 instances with automatic scaling logic to launch or 149.33 94.17 89.37 87.84 59.13 55.22 51.64 14. On-Demand 1 YrReserved, NoUpfrontPayment 1 YrReserved,PartialUpfrontPayment 1 YrReserved, AllUpfrontPayment 3 YrReserved, NoUpfrontPayment 3 YrReserved,ParialUpfrontPayment 3 YrReserved, AllUpfrontPayment SpotInstanceMonthly Cost for EC2 Instance Types 13 terminate instances according to computing requirements. ASGs enable AWS users to instantiate business rules which, for example, launch additional EC2 instances when the current set of EC2 instances exceeds 80% capacity for more than 30 seconds. The cost savings associated with ASGs are realized when they are implemented on applications that have variable usage patterns. For example, Gitlab Runners require significant computing capacity when running jobs, but sit idle for long durations between jobs. With an ASG in place, the Gitlab Runners can utilize just one EC2 instance when idle between jobs, then scale up to multiple, appropriately-sized EC2 instances when jobs arrive. 3.4 S3 Object Lifecycle Management Amazon Simple Storage Service (S3) is an object storage service with virtually unlimited storage capacity. There are a number of S3 storage classes that offer different degrees of durability and availability at different price points. It is common for many applications on AWS to store logs and other information, which are referred to as objects, in an S3 bucket. Since S3 has numerous storage classes which are each optimized for different use cases, it is important to manage objects with lifecycle configurations so they are stored in appropriate S3 classes to minimize storage costs. By enabling lifecycle configurations, one can define rules to transition objects from one storage class to another cheaper storage class to save on storage costs. The different storage classes, their use cases, and their associated cost for GovCloud US-East (calculated for 50 TB of storage or less) are listed in Table 1. The different mobility options for transferring objects between storage classes are illustrated in Figure 4. \nTable 1 S3 Storage Classes Storage Class Designed For \nDurability (Designed For) Availability (Designed For) Cost (Month) STANDARD Frequently accessed data \n99.999999999% 99.99% $0.039 per GB STANDARD_IA Long-lived, infrequently accessed data \n99.999999999% 99.9% $0.02 per GB INTELLIGENT_TIERING Long-lived data with changing or unknown access patterns 99.999999999% 99.9% $0.039 per GB ONEZONE_IA Long-lived, infrequently accessed, non-critical data \n99.999999999% 99.5% $0.016 per GB GLACIER Long-term data archiving with retrieval times ranging from minutes to hours 99.999999999% 99.99% (after you restore objects) $0.006 per GB DEEP_ARCHIVE Archiving rarely accessed data with a default retrieval time of 12 hours 99.999999999% 99.99% (after you restore objects) $0.0024 per GB 14 \nFigure 4 S3 Object Mobility To manage object storage in a cost effective manner, S3 lifecycle configurations should be configured which define actions (e.g., transfer, expire) that S3 applies to a group of objects. Log files are generally good candidates for S3 lifecycle management since logs are often required for a specified amount of time, after which they can be either archived for infrequent use and regulatory compliance, or expired (i.e., deleted). An example lifecycle for application logs can been seen in Figure 5. \nFigure 5 Sample Lifecycle Management for Application Logging on S3 Hypothetically, if 50TB of logs and artifacts were produced in an enterprise environment with lifecycle management not configured, the cost to store 50TB in a Standard storage class would cost $1,950 per month. Alternatively, if the logs were transferred to Glacier after 30 days (i.e., only the most recent 30 days of logs were stored in a Standard storage class), the cost would be reduced to $437.50 per month. This represents a 78% reduction of S3 storage costs. Application S3Standard S3Glacier ExpireOn Create 30 Days 365 days 15 3.5 Instance States and Stopping Instances Amazon EC2 and RDS services have a number of possible states in their lifecycle from Launch to Termination. These states and the procedures that associated with each state are illustrated in Error! Reference source not found.. \nFigure 6 Transitions Between Instance States EC2 and RDS instances are billed on either a per-second or per-hour basis, and billing is applied only during certain states. An important observation is that instances are not billed when they are stopped. A complete table of billing policies per instance state can be seen in Error! Reference source not found.. When an instance is stopped by an administrator, it enters the stopping state, and then the stopped state. Amazon does not charge usage or data transfer fees for the instance after it has been stopped, however Amazon does charge for the storage of any Amazon EBS volumes attached to the instance since they are not destroyed and remain operational when an instance is stopped. The billing structure of instance states and stopped instances provides an opportunity for drastic cost savings for certain types of workflows. EC2 or RDS systems, which are used infrequently or for intermittent jobs, such as batch processing, are ideal candidates for this type of procedure. Dev and Test environments which are only used during working hours are also prime candidates to be stopped while they are not being used. The instances can be stopped while they are not in use to pause their billing accrual, then restarted when needed. Instances can be stopped programmatically through an API call, which allows this process to be scripted. Likewise AWS offers tools such as an EC2 scheduler which automates the start/stop procedure through CloudFormation templates. Furthermore, instances retain their private IPv4 address, which means that an Elastic IP address associated with the private IPv4 address or network interface will still be associated with your instance after a stop/start procedure. 16 \nTable 2 Instance States and Billing Instance State Description Instance usage billing pending The instance is preparing to enter the running state. An instance
enters the pending state when it launches for the first time, or when it is restarted after being in the stopped state. Not billed running The instance is running and ready for use. Billed stopping The instance is preparing to be stopped or stop-hibernated. Not billed if preparing to stop Billed if preparing to hibernate stopped The instance is shut down and cannot be used. The instance can be restarted at any time. Not billed shutting-down The instance is preparing to be terminated. Not billed terminated The instance has been permanently deleted and cannot be restarted. Not billed Note: Reserved Instances that applied to terminated instances are billed until the end of their term according to their payment option. See Section 6.2.3 for a discussion of how stopping and re-starting instances would be implemented on the example DevSevOps account. 3.6 Tagging A tag is a label which contains custom metadata that either the user or AWS assigns to an AWS resource. Each tag consists of a key and value pair, where each key can have one or multiple values. Each resource can have up to 50 user-applied tags, such as [createdBy = employee90440]. Tagging resources is an essential component of effective cost management in the cloud since it enables administrators to streamline resource management, access management, and cost allocation by allowing for detailed cost tracking. Tagging gives direct accountability and visibility into IT costs by team and application. Cost allocation tags are an optional form of tagging that can be activated in the Billing & Cost Management Dashboard. After cost allocation tags have been activated, AWS uses the tags to organize resources in a cost allocation report so one can understand the cause and quantity of charges associated with each resource. For example, if you tag resources with an application name, you can track the total cost of a single application. This would allow the system administrators to directly track costs of different applications and use that information to drive future decisions. You can also use tags to filter views in Cost Explorer for further insight into system costs. 17 3.7 AWS Config AWS Config is a service which provides a detailed view of the configuration of AWS resources in your AWS account. When enabled, Config discovers resources that exist in your account, records their current configuration, and captures any changes to these configurations. This includes how the resources are related to one another and how they were configured in the past, which enables administrators to understand how configurations and relationships change over time. This ability provides numerous benefits including continuous assessment, change management, compliance monitoring, operational troubleshooting, and cost understanding. To effectively manage costs in the cloud, cloud administrators must understand exactly what is running in the cloud and for what purpose. Although this concept may appear obvious, it is often overlooked in cloud deployments as it is fundamentally different from on premise datacenter deployments where infrastructure costs are fixed, making resource evaluation less critical. Monitoring resources with methods such as Tagging and AWS Config reduces the likelihood of misallocated resources and inefficient architectures. 3.8 AWS Organizations Organizations or applications that use multiple AWS accounts to fulfill their IT needs may choose to enroll in AWS Organizations at no additional cost. AWS Organizations provides central governance and management across multiple AWS accounts. It allows you to create groups of accounts, apply policies for governance, automate account creation, and consolidate billing. Amazon offers volume discounts for services purchased in large quantities. Most of the common services such as EC2 and S3 have volume pricing tiers across certain usage dimensions that provides lower prices the more one uses the service. Below is an example of the volume discounts offered for S3. S3 Standard Storage Pricing First 50 TB / Month $0.023 per GB Next 250 TB / Month $0.022 per GB Over 500 TB / Month $0.021 per GB Enabling AWS Organizations will allow organizations with multiple accounts to take advantage of the discount volume pricing. For billing purposes, AWS treats all the accounts in the organization as if they were one account, combing the usage from all accounts to determine which volume pricing tiers apply. In addition to volume discounts, AWS Organizations also allows for consolidated billing with a unified billing dashboard which shows a view of charges incurred by all accounts. Enrolling multiple GovCloud accounts in AWS Organizations would reduce current and future costs as the system expands in production, as it has the potential to reduce programmatic costs through volume discounts. Additionally, it will provide administrators more insight into incurred costs through the consolidated billing dashboards and reports. AWS Organizations was deployed 18 on GovCloud in April of 2019 and should be incorporated into most programs GovCloud strategy. 3.9 EC2 Right Sizing Right sizing is a key mechanism for optimizing costs on AWS, but is often ignored when migrating or developing systems in the cloud. Right sizing is the process of matching instance types and size to workload demands and capacity requirements in order to minimize costs. Right sizing also includes the process of monitoring existing instances and identifying opportunities to eliminate or downsize without compromising reliability and other requirements. Historically, IT systems were provisioned to be able to accommodate traffic during peak hours. This approach is not optimized for the cloud and should not be used when deploying instances in GovCloud. To minimize costs, instances should take advantage of the elasticity offered by cloud environments and should be provisioned based on average usage rather than peak usage with supplemental tools such as auto-scaling to ensure appropriate performance during peak hours. The first step to right sizing is to monitor and analyze the current use of existing services and infrastructure to gain insight into performance and usage patterns. When monitoring instances, the most important hardware considerations to monitor are CPU, Memory, Network, and Storage including disk read/write operations. These metrics should be collected and analyzed to determine not only the most appropriate EC2 size, but also instance family (General Purpose, Compute Optimized, Memory Optimized, Storage Optimized, Accelerated Compute). Amazon recommends that instances with a maximum CPU usage and memory usage of less than 40% over a four-week period are candidates for downsizing to smaller instances. As a general rule of thumb, they recommend EC2 instances which meet this threshold can safely be cut in half. For example, a c4.8xlarge which uses less than 40% of available CPU over a 4 week period, can be moved to a c4.4xlarge which would save approximately $570 every month. 19 Cost Optimization Cost Management Tools \nAWS services have a complex costing model resulting due to the clouds abilities to scale based on resource utilization. This allows users to quickly adjust services and save money based on utilization. By consistently monitoring system infrastructure and reacting to changes as they occur, an IT system can work efficiently while maintaining low costs. To help the PMO take advantage of this structure, Amazon offers tools that monitor utilization, set thresholds, and provide detailed cost breakdowns. By understanding cloud cost management and utilizing Amazons cost management tools, the government program can effectively scale resources while maintaining system security and performance, ultimately resulting in significant cost savings. 4.1 AWS Billing and Cost Management For many government programs, different AWS accounts will be used with different root users, users, access, and AWS services. AWS Consolidated Billing can be used to aggregate the billing of services across multiple accounts for the purposes of cost savings and centralized cost management. To utilize this feature, AWS Organizations should be used as an account management service so that one master account can pay the charges across member accounts. Each GovCloud account must map to a commercial account, and those commercial accounts must be part of one single master commercial organization through the Organizations service. The master commercial account can view resource usage and activity information for all the AWS GovCloud accounts in the AWS Management Console. This master commercial account is also the account to which all charges will be billed for both commercial and GovCloud, which enables the PMO to reap the cost saving and management benefits of consolidated billing. 4.2 AWS Cost Explorer AWS Cost Explorer helps one track spending via default or custom reports which are accessible via console or API. For example, one can see which services, accounts, or regions are most expensive and quickly analyze on ones resources, such as the utilization of EC2 instances. One can also get more in-depth guidance such as forecasting, resource optimization, and Reserved Instance purchase recommendations. The cost per request is $0.01, which can be generated hourly and/or daily. 4.3 AWS Trusted Advisor AWS Trusted Advisor scans ones AWS environment and recommends improvements specific to ones architecture. Without signing up or paying for the service, all AWS customers are entitled to seven core Trusted Adviser checks which focus on permissions, EBS and RDS public snapshots, and service limits. These checks are accessible through dashboards in the console or via API and can
come with a weekly notification email with updates on Trusted Advisor check statuses and potential savings. In the console, cost optimization can be selected to view suggested cost-reducing system changes. By tracking recent changes and checks such as low utilization Amazon EC2 Instances, Trusted Advisor helps reduce costs in ones AWS environment. 20 4.4 AWS Budgets AWS Budgets can be used to automate the continuous monitoring of costs. Rather than constantly checking costs or usage, the Budgets tool can be utilized to alert the team when thresholds are reached that may lead to unexpected spending. The team can choose to monitor based on estimated costs and predicted costs, but can also set up alerts for monitoring the utilization of resources, such as a Reserved Instance. Using this in conjunction with AWS Organizations and CloudWatch alarms, the PMO can allow users to create account-specific budgets which can then be viewed through the budget dashboard and monitored via alerts from email, Slack, or Amazon Chime. Utilizing AWS Budgets costs $0.02 per day per account. 4.5 AWS CloudWatch While Budgets focuses on monitoring cost and utilization thresholds, AWS CloudWatch monitors and automatically reacts to system health and performance issues. CloudWatch consolidates logs and metrics generated by each AWS service to provide quickly-digestible information to the team in the dashboard and through alerts. Beyond simply alerting the team to take action, CloudWatch allows users to set automated actions in which workflows are triggered by either user-specified thresholds or anomalies detected by Amazons machine learning algorithms. For instance, changes in resource demand could trigger CloudWatch to enable auto- scaling for an EC2 instance. CloudWatch can provide extreme granularity, collecting metrics as frequently as every second and publishing them every minute. The information CloudWatch publishes in this process is available via the CloudWatch dashboard and API. 4.6 AWS CloudTrail AWS CloudTrail is necessary to help the team manage security and compliance across accounts by monitoring account activity and mitigating risk. Through this service, account activity is tracked and workflows can be triggered to maintain high security with minimal oversight. For example, if an API call makes an S3 bucket public, CloudTrail will log this event and can respond by automatically adding specific security policies to the S3 bucket. In the white paper Security at Scale: Logging in AWS, Amazon demonstrates how easy it is to track and retrieve activity data for auditing and enforcing compliance standards. CloudTrail comes free of charge, though S3 storage is needed to store log data. 4.7 Cost Optimization Monitor The AWS Cost Optimization Monitor consolidates billing reports into an S3 bucket and presses the data for viewing and retrieval in an Elasticsearch service. With this feature enabled, users can utilize Kibana dashboards to search and visualize aggregated cost data as seen in Figure 5. For example, the teams Kibana dashboard may display cost by EC2 hours per dollar invested, instances running per hour, or cost by instance type. The Cost Optimization Monitor tool is available to the account that makes payments through the consolidated billing feature (see 21 Section 4.1). To use this feature, the team launches the Cost Optimization Monitor stack and then configures the payment account to save billing reports to a designated S3 bucket. Charges for this service are billed by Amazon Elasticsearch instance hours and storage, Amazon EC2 usage and licensing, and Elastic Load Balancing base pricing. The cost per hour will also fluctuate depending on deployment size, master node count and type, and data node count and type. The lowest cost per hour is estimated to be $0.40 and the highest cost per hour is estimated to be $3.83. \nFigure 7 Cost Optimization Monitor architecture 4.8 AWS Cost and Usage Report AWS Cost and Usage Reports are another method for reviewing each accounts spending. This report type focuses on views by product, usage type, operations, more detailed information by Reserved Instance type, and the unique combinations of each of these attributes. By using the Consolidated Billing feature from AWS Organizations, the master account will have access to cost and usage reports for each linked account. These reports can be downloaded from the S3 console, accessed through the AWS Billing and Cost Management API, or queried through an Amazon service such as Redshift, QuickSight, or Athena. While there is no cost to access these reports, storing reports in S3 will incur normal S3 storage costs. Up to ten cost reports can be created per account which make cumulative estimated costs available throughout the month with information aggregated by the hour or the day. One finalized report will be provided by Amazon each month containing final calculations for all blended (affected by instance type and rate) and unblended rates, usage, and cost changes (e.g., due to refunds or credits). 22 Cost Optimization Programmatic Best Practices \nBefore deploying services and cost optimization tools, it is better to first examine the programs current practices and work to craft a cost-conscious system. A Cloud Center of Excellence (CCoE) team should be appointed to monitor and enact the following practices and services within the programs environment. The following best practices will help guide the project toward being more cost-aware and, ultimately, minimize cloud-related expenses. 5.1 Architecture Every government program needs to be deliberate about where it houses data and how it transfers data. Begin with a consumption model to determine current computing requirements based on the programs historical usage, then modify these requirements using cost optimization tools such as AWS Auto Scaling and Cost Explorer. Once these cost optimization tools have been introduced, there should be periodic reviews of the architecture to determine potential areas of improvement. 5.2 DevOps The fundamental principle of any DevOps system is the ability to frequently release updates in order to shorten delivery time to the customer. In addition to time savings, an effective DevOps pipeline should reduce program costs over the entirety of its lifecycle, including the operation and maintenance phases. Sharing resources in the cloud environment during the integration phase can save on costs as well, while limiting to only necessary resources and keeping unused resources shut down. DevOps allows for continuous testing and monitoring which can find software bugs and apply fixes quicker. This can also be used for tracking cost optimization models to ensure they are running the correct instances and deploying resources only when needed to maximize cost reduction. 5.3 Lean Culture Lean culture focuses on reducing waste by defining value, mapping value streams, creating flow, establishing pull-based systems, and pursuing perfection. Government agencies should implement a lean culture which clearly delineates its customer value and continuously tweaks its business process to maximize that value. Any processes that are deemed unnecessary for the customer should be reduced or eliminated. The process should be regularly evaluated to ensure a steady flow of progress is maintained across teams, enabling employees to adapt to changing customer needs. A pull-based system is defined as a system where the customers product is delivered when the products are needed and limiting the amount of in-progress items. Finally, always test and improve upon any products delivered to the customer. In an agile system, it is important to get a functioning product released, then re-evaluate and perfect the system by reviewing customer feedback. 23 5.4 AWS-Oriented Business Process Re-Engineering In order to facilitate cost savings, the government program can collect usage statistics for its AWS services and consider re-engineering its business process to minimize expenditures. For example, if certain data is housed for longer than necessary, the business process could be re- engineered to reduce storage duration (and therefore overall storage volume). In accordance with lean principles, when re-engineering the business process is important to minimize task duration by eliminating low-value tasks and appropriately dividing or combining tasks based on the size and time to completion. On top of this, tasks should be ordered based on required delivery date, available work capacity, and size. Tasks can either be done sequentially or in parallel depending on if it relies on information from external sources to complete the task. Employees should be given more control in the decision making process for their assigned tasks. It will save time and reduce overhead costs if employees are comfortable making decisions without requiring constant authorization and oversight. 5.5 Policy-Driven Automation Utilize business policies to track automated processes, enable easily-adjustable automation, and understand the holistic effects of automation. Additionally, usage metrics can inform business policies and enable smarter policies. Incorporate methods to monitor GovCloud usage and determine which processes can (and cannot) be automated. Monitoring can be done using tags to track instance usage and filter by both application type and deployment zone (i.e., region or availability zone). There should be one centralized system or tool to monitor the GovCloud environment. 24 DevSecOps GovCloud Evaluation \nThis section provides an evaluation of the state of a standard DevSecOps GovCloud environment with the information that was available at the time of this technical report. Some assumptions were made in order to fill in missing information for certain items,
such as storage size. Each assumption was made based off estimates of existing systems. After the baseline environment was captured, the relevant principles described in this paper were conceptually applied to demonstrate the potential cost savings that can be achieved. All of the cost saving measures that are applied in this section preserve the full operational capabilities of the account and would not negatively affect performance. 6.1 Current Cost Estimate A total of 61 individual AWS services are used in the operation of the example DevSecOps account. A complete table of all services, their descriptions, and associated costs can be found in Table 3. Costs were calculated for each service using the AWS Simple Monthly Calculator, and all costs were calculated for the GovCloud US-EAST region. By summing the cost for each individual service, an estimated monthly cost of $7,059.25 was calculated for a DevSecOps account. \nTable 3 AWS Services in a DevSecOps Account Service ID Description Instance Type Storage \nInstance Cost \nStorage Cost EC2 1 SCCA SRX c4.2xlarge 180GB 298.66 23.76 EC2 2 Bastion Host c5.large 180GB 149.33 23.76 EC2 3 Bastion Host (Windows) c5.large 150GB 142.01 19.80 EC2 4 Nginx Reverse Proxy N/A N/A N/A N/A EC2 5 GitLab A c5.xlarge 180GB 149.33 23.76 EC2 6 GitLab B c5.xlarge 180GB 149.33 23.76 EC2 7 Artifactory A c5.large 180GB 74.67 23.76 EC2 8 Artifactory B c5.large 180GB 74.67 23.76 EC2 9 XRAY A c5.2xlarge 180GB 298.66 23.76 EC2 10 XRAY B c5.2xlarge 180GB 298.66 23.76 EC2 11 AD Admin c5.large 150GB 74.67 19.80 EC2 12 AD CS c5.large 150GB 74.67 19.80 EC2 13 BIND A c5.large 180GB 74.67 23.76 EC2 14 BIND B c5.large 180GB 74.67 23.76 EC2 15 WSUS c5.large 150GB + 500GB 74.67 85.80 EC2 16 Jira A c5.xlarge 180GB 149.33 23.76 EC2 17 Jira B c5.xlarge 180GB 149.33 23.76 EC2 18 SonarQube c5.large 180GB 74.67 23.76 EC2 19 CheckMarx c5.large 150GB 74.67 23.76 EC2 20 Confluence A c5.xlarge 180GB 149.33 23.76 EC2 21 Confluence B c5.xlarge 180GB 149.33 23.76 EC2 22 Chef c5.xlarge 180GB 149.33 23.76 EC2 23 Chef Automate c5.2xlarge 180GB 298.66 23.76 EC2 24 RunnerA01 c5.large 180GB 74.67 23.76 EC2 25 RunnerA02 c5.large 180GB 74.67 23.76 EC2 26 RunnerA03 c5.large 180GB 74.67 23.76 EC2 27 RunnerA04 c5.large 180GB 74.67 23.76 EC2 28 RunnerA05 c5.large 180GB 74.67 23.76 25 EC2 29 RunnerA06 c5.large 180GB 74.67 23.76 EC2 30 RunnerA07 c5.large 180GB 74.67 23.76 EC2 31 RunnerA08 c5.large 180GB 74.67 23.76 EC2 32 RunnerA09 c5.large 180GB 74.67 23.76 EC2 33 RunnerA10 c5.large 180GB 74.67 23.76 EC2 34 RunnerB01 c5.large 180GB 74.67 23.76 EC2 35 RunnerB02 c5.large 180GB 74.67 23.76 EC2 36 RunnerB03 c5.large 180GB 74.67 23.76 EC2 37 RunnerB04 c5.large 180GB 74.67 23.76 EC2 38 RunnerB05 c5.large 180GB 74.67 23.76 EC2 39 RunnerB06 c5.large 180GB 74.67 23.76 EC2 40 RunnerB07 c5.large 180GB 74.67 23.76 EC2 41 RunnerB08 c5.large 180GB 74.67 23.76 EC2 42 RunnerB09 c5.large 180GB 74.67 23.76 EC2 43 RunnerB10 c5.large 180GB 74.67 23.76 ENI 1 Public Interface N/A N/A N/A N/A ENI 2 Management Interface N/A N/A N/A N/A ENI 3 Private Interface N/A N/A N/A N/A EFS 1 GitLab App A N/A N/A N/A N/A EFS 2 GitLab App B N/A N/A N/A N/A RDS 1 GitLab db.m4.large 200GB 175.07 27.60 RDS 2 Artifactory db.m4.xlarge 200GB 175. 07 27.60 RDS 3 XRAY db.m4.large 200GB 175. 07 27.60 RDS 4 SonarQube db.m4.large 200GB 175. 07 27.60 RDS 5 Jira db.m4.large 200GB 175. 07 27.60 RDS 6 Confluence db.m4.large 200GB 175. 07 27.60 ELB 1 GitLab N/A N/A N/A N/A ELB 2 Artifactory N/A N/A N/A N/A ELB 3 Jira N/A N/A N/A N/A ELB 4 SonarQube N/A N/A N/A N/A ELB 5 Confluence N/A N/A N/A N/A ElastiCache 1 GitLab N/A N/A N/A N/A Directory Service 1 AWS Directory Service N/A 180GB 74.67 23.76 Total: 5821.81 1237.44 \n Total: 7059.25 The most common and costliest services in the example DevSecOps account are the use of EC2 and RDS instances. Collectively, the EC2 and RDS instances account for $6,862.39 of the total $7,059.25, or 97% of the accounts monthly cost. Therefore the majority of the conscious cost improvements are related to EC2 and RDS services, but the other cost saving techniques outlined in this paper are still viable for environments using a broader set of managed services across multiple AWS accounts. 6.2 Cost Conscious Improvements 6.2.1 Reserved Instances The single most effective recommendation for cost optimization in the prototypical DevSecOps account, which can also be applied to any other accounts in the government program, is the use of Reserved Instances in place of On-Demand Instances. A more detailed description of Reserved Instances can be found in Section 3.1. 26 Table 4 lists all EC2 and RDS instance types that are used in the modeled DevSecOps accounts, along with their monthly costs for On-Demand and Reserved types, respectively. The table also lists the difference in cost and the percent discount of using a Reserved Instance rather than the On-Demand Instances, which are currently utilized for all of the example programs EC2 and RDS instances. Figure 8 shows a visual comparison of the pricing difference. \nTable 4 Cost Comparison of DevSecOps Instance Types Instance Type On Demand \n3 Year Reserved (No Upfront) Cost Reduction Percent of Costs Saved c5.large $74.67 $29.93 $44.74 60.0% c5.xlarge $149.33 $59.13 $90.20 60.4% c5.2xlarge $298.66 $118.99 $179.67 60.2% db.m5.large $152.82 $134.23 $18.59 12.2% db.m5.xlarge $302.88 $165.62 $137.26 45.3% \nFigure 8 On-Demand Compared to Reserved Pricing Table 5 shows the application of switching all EC2 and RDS instances from On-Demand to Reserved Instance types. The price difference is calculated for each type of instance existing in the account then multiplied by the quantity deployed. Costs for 3-year Reserved Instances with no upfront payment were used to calculate the cost savings. By using 3-year, no upfront payment instances, there is no additional immediate capital required to initiate this strategy. \nTable 5 Application of Reserved Instances to DevSecOps Account 74.67 149.33 298.66 152.82 302.8829.93 59.13 118.99 134.23 350 c5.large c5.xlarge c5.2xlarge db.m5.large db.m5.xlargeMontly CostOn Demand Reserved 27 Instance Type \nQuantity Deployed Reserved Savings per Instance \nTotal Savings c5.large 31 $44.74 $1386.94 c5.xlarge 8 $90.20 $721.6 c5.2xlarge 4 $179.67 $718.68 db.m5.large 5 $18.59 $92.95 db.m5.xlarge 1 $137.26 $137.26 Total 49 $3057.43 By utilizing Reserved Instances in a DevSecOps account, the total monthly bill was reduced from $7,059.25 to $4,001.82, which represents $3057.43 in cost savings. Reserved Instances were able to achieve a 43% savings with no upfront cost or performance reduction. 6.2.2 Auto-Scaling Groups Another powerful technique for saving operational costs in a cloud environment is the implementation of Auto-Scaling Groups (ASG), which is an AWS managed service that utilizes automated scaling logic to launch or terminate instances according to computing requirements. ASGs enable AWS users to instantiate business rules which, for example, launch additional EC2 instances when the current set of EC2 instances exceeds 80% capacity for more than a specified amount of time. A detailed description of ASGs can be found in Section 3.3 Auto Scaling and Automating Elasticity. The cost savings associated with ASGs are realized when they are implemented on applications that have variable usage patterns. For example, Gitlab Runners (or equivalent tools) require significant computing capacity when running jobs, but sit idle for long durations between jobs. With an ASG in place, the Gitlab Runners can utilize just one EC2 instance (instead of twenty) when idle between jobs, then scale up to multiple, appropriately-sized EC2 instances when Gitlab Runner jobs arrive. In practice, the GitLab runners are often used for an hour or less per day, but they are required to be left running due to security scans. In this cost calculation exercise, we will assume the runners are only used for 1 hour a day (a liberal estimate), and the remaining 19 instances are set behind an auto-scaling group. In practice, the remaining instances could scale to be more or less than 19 instances, and their instance type could vary to accommodate jobs, but we will hold this assumption to show equivalent compute capacity of the current state at a reduced cost. To reconfigure the runners behind an auto-scaling group, one runner is running 24x7 so there is never any downtime when starting a job. When a job is submitted, the single runner will have a demand that exceeds capacity, and the auto-scaling group will be initiated. The remaining 19 instances will be deployed in a matter of minutes, and the workload can be distributed between them. This generates a total of \n\n = 1 \n 24 +19 \n 1 = 43 \n , when compared to the current state of all 20 \ninstances running 24 hours a day, or \n\n = 20 \n 24 =480 \n . The use of auto-scaling groups reduces the billable time for the runners by \n91 percent, reducing the monthly bill for the runners from $1,493.28 to $133.78. 28 \nFigure 9 Cost Reduction using Auto-scaling 6.2.3 Stopped Instances If Reserved Instances are not adopted, an alternative strategy would be stopping and starting instances based
on utilization, particularly for the GitLab Runner instances. If Reserved Instances are used, stopping instances has no useful application since Reserved Instances are billed regardless of their usage. In contrast, On-Demand Instances can be stopped and started with no additional charges incurred. See Error! Reference source not found. for a complete evaluation of when instances are billed. Stopping instances can be done programmatically through an API, and likewise can be started again through an API which allows for the entire stop-and-restart procedure to be automated. When an instance is stopped and restarted, it has the ability to retain its private IPv4 address, which means an Elastic IP address associated with the private IPv4 address will remain preserved for each instance after a stop-and-restart procedure. If appropriate, workloads could be batched to run at scheduled times during the day when the Gitlab Runners are active. Alternatively the Gitlab Runners could be started when the script detects and incoming workload and automatically turned off when the workload is complete. \nTable 6 Cost of a Single GitLab Runner Instance Type Compute Cost Storage Cost Total c5.large $74.67 $23.76 $98.43 The cost of a single Gitlab Runner is an estimated $98.43 per month, with the majority of the cost coming from the compute cost (i.e., when the instance is running). If the instances are only used for 2 hours a day, stopping the instances could reduce the compute cost of each Gitlab Runner by 92%, or $68.71 per month. When applied to each of the 20 Gitlab Runners, this strategy could result in a total savings of $1,374.20 per month. 01600 Category 1Runners with AutoscalingCurrent Autoscaling 29 6.2.4 AWS Organizations and Consolidated Billing The use of AWS Organizations allows organizations with multiple accounts, such as government organizations, to consolidate billing to a single dashboard, while also taking advantage of volume discounts for services including EC2 and S3. For billing purposes, AWS treats all the accounts in the organization as if they were one account. It is recommended to consider the adoption of AWS Organizations to take advantage of volume discounts and potentially simplify the billing process. At a minimum, the Consolidated Billing features will provide greater insight to organizational costs of running on GovCloud. 6.3 Cost Management By using Cost Explorer and Cost and Usage Reports in conjunction with organizations, the PMO can easily view and track detailed account-specific spending reports. By utilizing the Cost Optimization Monitor with Kibana dashboards, the team can search and visualize this cost data. To reduce time spent manually monitoring these reports and ensure the team is alerted when thresholds are reached that may lead to unexpected spending, AWS Budgets should be implemented with AWS Organizations so the team can push account-specific alerts to team members through email, Slack, or Amazon Chime. To automatically respond to changes in spending, CloudWatch should be used to trigger workflows such as auto-scaling EC2 instances based on changes in resource demand. Beyond implementing these measures for cost management, the team should also opt into the free Trusted Advisor notifications feature to receive weekly notification emails with updates on potential savings specific to the program architecture for continuous improvement in the future. 30 Conclusion and Next Steps \nWith an increasing number of emerging Government IT systems being deployed in the cloud, and legacy systems migrating to the cloud, it is vital to architect these systems in a fashion that leverages the scalable nature of the cloud and capitalizes on the opportunities offered by cloud services. There are a number of important design considerations, cost management tools, and programmatic best practices that should be considered when architecting a program in GovCloud or other cloud platforms. The successful implementation of the tools and practices outlined in this report can significantly reduce the cost of running workloads in the cloud, which was conceptually demonstrated in an evaluation of a standard DevSecOps GovCloud account. \nA cloud centric deployment of both new systems, and legacy applications being migrated to the cloud, often requires the support and guidance of the PMO to enable greater integration of cloud native services. Often times when deploying both new and legacy systems to the cloud, precedence is given to ensuring the systems are operational, with other considerations such as resource and cost optimization occurring after. When deploying new applications to the cloud, it is recommended that the PMO considers applying optimization strategies such as the ones outlined in this report. Legacy systems which are migrated to the cloud should also be reviewed for potential cloud efficiencies as appropriate. The most impactful efficiencies and cost strategies discussed in the report include utilizing AWS Organizations to consolidate billing and volume discounts, identifying long-term workloads which can benefit from Reserved Instances, identifying fluctuating workloads which can benefit from Auto-Scaling groups, applying lifecycle management configurations for S3 storage, and monitoring environments with AWS native cost management tools. 31 Appendix A References AWS GovCloud o https://aws.amazon.com/govcloud-us/ o https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/welcome.html Figure 4 S3 Object Mobility o https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general- considerations.html \n Error! Reference source not found. o https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html Figure 7 Cost Optimization Monitor architecture o https://aws.amazon.com/solutions/cost-optimization-monitor/ DevOps o https://www.business2community.com/cloud-computing/how-to-use-9-cloud-\ndevops-best-practices-for-cost-control-02163854 Lean Culture o https://theleanway.net/The-Five-Principles-of-Lean Business Process Re-engineering o https://www.ijcaonline.org/archives/volume44/number23/6424-8653 o https://www.inteqgroup.com/blog/6-key-business-process-reengineering-steps Figure 10 Relationship Between Regions and Availability Zones o https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-\nzones.html Security at Scale: Logging in AWS o https://d0.awsstatic.com/whitepapers/compliance/AWS_Security_at_Scale_Logging\n_in_AWS_Whitepaper.pdf Laying the Foundation (1/7) o https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-laying-the-\nfoundation/introduction.html Cost Management in the AWS Cloud (2/7) o https://docs.aws.amazon.com/whitepapers/latest/cost-management/introduction.html Amazon EC2 Reserved Instances and Other AWS Service Reservation Models (3/7) o https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-reservation-\nmodels/introduction.html https://aws.amazon.com/govcloud-us/\nhttps://docs.aws.amazon.com/govcloud-us/latest/UserGuide/welcome.html\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general-considerations.html\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general-considerations.html\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html\nhttps://aws.amazon.com/solutions/cost-optimization-monitor/\nhttps://www.business2community.com/cloud-computing/how-to-use-9-cloud-devops-best-practices-for-cost-control-02163854\nhttps://www.business2community.com/cloud-computing/how-to-use-9-cloud-devops-best-practices-for-cost-control-02163854\nhttps://theleanway.net/The-Five-Principles-of-Lean\nhttps://www.ijcaonline.org/archives/volume44/number23/6424-8653\nhttps://www.inteqgroup.com/blog/6-key-business-process-reengineering-steps\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html\nhttps://d0.awsstatic.com/whitepapers/compliance/AWS_Security_at_Scale_Logging_in_AWS_Whitepaper.pdf\nhttps://d0.awsstatic.com/whitepapers/compliance/AWS_Security_at_Scale_Logging_in_AWS_Whitepaper.pdf\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-laying-the-foundation/introduction.html\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-laying-the-foundation/introduction.html\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-management/introduction.html\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-reservation-models/introduction.html\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-reservation-models/introduction.html 32 Leveraging Amazon EC2 Spot Instances at Scale (4/7) o https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-\nspot-instances/introduction.html Creating a Culture of Cost Transparency and Accountability (5/7) o https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-transparency-\naccountability/introduction.html?did=wp_card&trk=wp_card Automating Elasticity (6/7) o https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-automating-\nelasticity/introduction.html?did=wp_card&trk=wp_card Right Sizing (7/7) o https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-right-\nsizing/introduction.html?did=wp_card&trk=wp_card https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/introduction.html\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/introduction.html\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-transparency-accountability/introduction.html?did=wp_card&trk=wp_card\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-transparency-accountability/introduction.html?did=wp_card&trk=wp_card\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-automating-elasticity/introduction.html?did=wp_card&trk=wp_card\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-automating-elasticity/introduction.html?did=wp_card&trk=wp_card\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-right-sizing/introduction.html?did=wp_card&trk=wp_card\nhttps://docs.aws.amazon.com/whitepapers/latest/cost-optimization-right-sizing/introduction.html?did=wp_card&trk=wp_card 33 Appendix B Cloud Computing \nCloud computing is providing developers and IT departments with the ability to focus on what matters most and avoid undifferentiated work like procurement, maintenance, and capacity planning. Specific user needs require different models and deployment strategies, with each type of cloud service and deployment method providing you with different levels of control, flexibility, and management. Understanding the differences between Infrastructure as a Service (IaaS), Software as a Service (SaaS), and Platform as a Service (PaaS), as well as what deployment strategies you can use, can help you decide what set of services is right for your needs. B.1 Compute Models There are three main models for cloud computing. Each model represents a different part of the cloud computing stack. B.1.1 IaaS Infrastructure as a Service contains the basic building blocks for cloud IT and typically provide access to networking features, computers (virtual or on dedicated hardware), and data storage space. Infrastructure as a Service provides you with the highest level of flexibility and management control over your IT resources and is most similar to existing IT resources. B.1.2 SaaS Software as a Service provides you with a completed product that is run and managed by AWS. In most cases, people referring to Software as a Service are referring to end-user applications. With Software as a Service, you only need to think about how you will use that particular piece software, not how it is maintained or how the infrastructure is managed. B.1.3 PaaS Platforms as a Service remove the need to manage the underlying infrastructure (e.g. hardware and operating systems) and instead focus on the deployment and management of your applications. This increases efficiency as you dont need to worry about resource procurement, capacity planning, software maintenance, patching, or any of the other undifferentiated heavy lifting involved in running your application. B.2 Deployment Models B.2.1 Cloud A cloud-based application is fully deployed and run in the cloud, with applications in the cloud either having been created in the cloud or migrated to the cloud from an existing infrastructure. Cloud-based applications can be built on low-level infrastructure pieces or can use higher level services that provide abstraction from the management, architecting, and scaling requirements of core infrastructure. 34 B.2.2 On Premise On-premises deployment is used for its ability to provide dedicated resources, but does not provide as many benefits as cloud computing. In most cases this deployment model is the same as legacy IT infrastructure, while using application management and virtualization technologies to maximize utilization of resources. Using virtualization and resource management tools, this process of on-premise deployment is sometimes called the private cloud. B.2.3 Hybrid A hybrid deployment is a way to connect infrastructure and applications between cloud-based resources and local resources. This hybrid deployment between the cloud and existing on- premises infrastructure extends an organization's infrastructure into the cloud while connecting resources from the cloud to its internal system. 35 Appendix C AWS Overview \nThe AWS cloud is hosted worldwide in AWS Regions and Availability Zones (AZ). Each AWS Region is separate consisting of multiple Availability Zones (typically 3). The example program operates within the GovCloud (US-East) region. Each Availability Zone is a fully isolated partition of the AWS infrastructure that consists of discrete data centers which are fully redundant. \nFigure 10 Relationship Between Regions and Availability Zones Cloud administrators have the option to choose which geographic
region and availability zone will host their service (although some resources are region agnostic). Each region has its own unique pricing model per service, and not all regions offer the same services. A cloud administrator chooses which region to deploy services to based on considerations including latency, redundancy, data requirements, service availability, and price. 36 Appendix D Abbreviations and Acronyms API Application Programming Interface AWS Amazon Web Services AZ Availability Zone CJIS Criminal Justice Information Services COTS Commercial Off-the-Shelf CSP Cloud Service Provider CUI Controlled Unclassified Information DevOps Development and Operations DevSecOps Development Security and Operations EBS Elastic Block Store EC2 Elastic Cloud Compute FedRAMP Federal Risk and Authorization Management Program IaaS Infrastructure as a Service IT Information Technology PaaS Platform as a Service RDS Relational Database Service RI Reserved Instance S3 Simple Storage Service SaaS Software as a Service SRG Security Requirements Guide 37 Introduction\n Optimize for the Cloud\n AWS GovCloud Cost Optimization AWS Deployment Strategies\n Reserved Instances\n Spot Instances\n Auto Scaling and Automating Elasticity\n S3 Object Lifecycle Management\n Instance States and Stopping Instances\n Tagging\n AWS Config\n AWS Organizations\n EC2 Right Sizing Cost Optimization Cost Management Tools\n AWS Billing and Cost Management\n AWS Cost Explorer\n AWS Trusted Advisor\n AWS Budgets\n AWS CloudWatch\n AWS CloudTrail\n Cost Optimization Monitor\n AWS Cost and Usage Report Cost Optimization Programmatic Best Practices\n Architecture\n DevOps\n Lean Culture\n AWS-Oriented Business Process Re-Engineering\n Policy-Driven Automation DevSecOps GovCloud Evaluation\n Current Cost Estimate\n Cost Conscious Improvements\n Reserved Instances\n Auto-Scaling Groups\n Stopped Instances\n AWS Organizations and Consolidated Billing Cost Management Conclusion and Next Steps\n References\n Cloud Computing\n Compute Models\n IaaS\n SaaS\n PaaS Deployment Models\n Cloud\n On Premise\n Hybrid AWS Overview\n Abbreviations and Acronyms ",
